{
    "intents": [
        {
            "tag": "java",
            "question": [
                "Why is processing a sorted array faster than processing an unsorted array?",
                "Here is a piece of C++ code that shows some very peculiar behavior.\nFor some reason, sorting the data (before the timed region) miraculously makes the primary loop almost six times faster:\n#include &..."
            ],
            "url": "https://stackoverflow.com/questions/11227809",
            "answer": [
                "You are a victim of branch prediction fail.Consider a railroad junction:Image by Mecanismo, via Wikimedia Commons. Used under the CC-By-SA 3.0 license.Now for the sake of argument, suppose this is back in the 1800s - before long-distance or radio communication.You are a blind operator of a junction and you hear a train coming. You have no idea which way it is supposed to go. You stop the train to ask the driver which direction they want. And then you set the switch appropriately.Trains are heavy and have a lot of inertia, so they take forever to start up and slow down.Is there a better way? You guess which direction the train will go!If you guess right every time, the train will never have to stop.\nIf you guess wrong too often, the train will spend a lot of time stopping, backing up, and restarting.Consider an if-statement: At the processor level, it is a branch instruction:You are a processor and you see a branch. You have no idea which way it will go. What do you do? You halt execution and wait until the previous instructions are complete. Then you continue down the correct path.Modern processors are complicated and have long pipelines. This means they take forever to \"warm up\" and \"slow down\".Is there a better way? You guess which direction the branch will go!If you guess right every time, the execution will never have to stop.\nIf you guess wrong too often, you spend a lot of time stalling, rolling back, and restarting.This is branch prediction. I admit it's not the best analogy since the train could just signal the direction with a flag. But in computers, the processor doesn't know which direction a branch will go until the last moment.How would you strategically guess to minimize the number of times that the train must back up and go down the other path? You look at the past history! If the train goes left 99% of the time, then you guess left. If it alternates, then you alternate your guesses. If it goes one way every three times, you guess the same...In other words, you try to identify a pattern and follow it. This is more or less how branch predictors work.Most applications have well-behaved branches. Therefore, modern branch predictors will typically achieve >90% hit rates. But when faced with unpredictable branches with no recognizable patterns, branch predictors are virtually useless.Further reading: \"Branch predictor\" article on Wikipedia.Notice that the data is evenly distributed between 0 and 255. When the data is sorted, roughly the first half of the iterations will not enter the if-statement. After that, they will all enter the if-statement.This is very friendly to the branch predictor since the branch consecutively goes the same direction many times. Even a simple saturating counter will correctly predict the branch except for the few iterations after it switches direction.Quick visualization:However, when the data is completely random, the branch predictor is rendered useless, because it can't predict random data. Thus there will probably be around 50% misprediction (no better than random guessing).What can be done?If the compiler isn't able to optimize the branch into a conditional move, you can try some hacks if you are willing to sacrifice readability for performance.Replace:with:This eliminates the branch and replaces it with some bitwise operations.(Note that this hack is not strictly equivalent to the original if-statement. But in this case, it's valid for all the input values of data[].)Benchmarks: Core i7 920 @ 3.5 GHzC++ - Visual Studio 2010 - x64 ReleaseJava - NetBeans 7.1.1 JDK 7 - x64Observations:A general rule of thumb is to avoid data-dependent branching in critical loops (such as in this example).Update:GCC 4.6.1 with -O3 or -ftree-vectorize on x64 is able to generate a conditional move, so there is no difference between the sorted and unsorted data - both are fast.(Or somewhat fast: for the already-sorted case, cmov can be slower especially if GCC puts it on the critical path instead of just add, especially on Intel before Broadwell where cmov has 2 cycle latency: gcc optimization flag -O3 makes code slower than -O2)VC++ 2010 is unable to generate conditional moves for this branch even under /Ox.Intel C++ Compiler (ICC) 11 does something miraculous. It interchanges the two loops, thereby hoisting the unpredictable branch to the outer loop. Not only is it immune to the mispredictions, it's also twice as fast as whatever VC++ and GCC can generate! In other words, ICC took advantage of the test-loop to defeat the benchmark...If you give the Intel compiler the branchless code, it just outright vectorizes it... and is just as fast as with the branch (with the loop interchange).This goes to show that even mature modern compilers can vary wildly in their ability to optimize code...",
                "Branch prediction.With a sorted array, the condition data[c] >= 128 is first false for a streak of values, then becomes true for all later values. That's easy to predict. With an unsorted array, you pay for the branching cost.",
                "The reason why performance improves drastically when the data is sorted is that the branch prediction penalty is removed, as explained beautifully in Mysticial's answer.Now, if we look at the codewe can find that the meaning of this particular if... else... branch is to add something when a condition is satisfied. This type of branch can be easily transformed into a conditional move statement, which would be compiled into a conditional move instruction: cmovl, in an x86 system. The branch and thus the potential branch prediction penalty is removed.In C, thus C++, the statement, which would compile directly (without any optimization) into the conditional move instruction in x86, is the ternary operator ... ? ... : .... So we rewrite the above statement into an equivalent one:While maintaining readability, we can check the speedup factor.On an Intel Core i7-2600K @ 3.4\u00a0GHz and Visual Studio 2010 Release Mode, the benchmark is:x86x64The result is robust in multiple tests. We get a great speedup when the branch result is unpredictable, but we suffer a little bit when it is predictable. In fact, when using a conditional move, the performance is the same regardless of the data pattern.Now let's look more closely by investigating the x86 assembly they generate. For simplicity, we use two functions max1 and max2.max1 uses the conditional branch if... else ...:max2 uses the ternary operator ... ? ... : ...:On an x86-64 machine, GCC -S generates the assembly below.max2 uses much less code due to the usage of instruction cmovge. But the real gain is that max2 does not involve branch jumps, jmp, which would have a significant performance penalty if the predicted result is not right.So why does a conditional move perform better?In a typical x86 processor, the execution of an instruction is divided into several stages. Roughly, we have different hardware to deal with different stages. So we do not have to wait for one instruction to finish to start a new one. This is called pipelining.In a branch case, the following instruction is determined by the preceding one, so we cannot do pipelining. We have to either wait or predict.In a conditional move case, the execution of conditional move instruction is divided into several stages, but the earlier stages like Fetch and Decode do not depend on the result of the previous instruction; only the latter stages need the result. Thus, we wait a fraction of one instruction's execution time. This is why the conditional move version is slower than the branch when the prediction is easy.The book Computer Systems: A Programmer's Perspective, second edition explains this in detail. You can check Section 3.6.6 for Conditional Move Instructions, entire Chapter 4 for Processor Architecture, and Section 5.11.2 for special treatment for Branch Prediction and Misprediction Penalties.Sometimes, some modern compilers can optimize our code to assembly with better performance, and sometimes some compilers can't (the code in question is using Visual Studio's native compiler). Knowing the performance difference between a branch and a conditional move when unpredictable can help us write code with better performance when the scenario gets so complex that the compiler can not optimize them automatically.",
                "If you are curious about even more optimizations that can be done to this code, consider this:Starting with the original loop:With loop interchange, we can safely change this loop to:Then, you can see that the if conditional is constant throughout the execution of the i loop, so you can hoist the if out:Then, you see that the inner loop can be collapsed into one single expression, assuming the floating point model allows it (/fp:fast is thrown, for example)That one is 100,000 times faster than before.",
                "No doubt some of us would be interested in ways of identifying code that is problematic for the CPU's branch-predictor. The Valgrind tool cachegrind has a branch-predictor simulator, enabled by using the --branch-sim=yes flag. Running it over the examples in this question, with the number of outer loops reduced to 10000 and compiled with g++, gives these results:Sorted:Unsorted:Drilling down into the line-by-line output produced by cg_annotate we see for the loop in question:Sorted:Unsorted:This lets you easily identify the problematic line - in the unsorted version the if (data[c] >= 128) line is causing 164,050,007 mispredicted conditional branches (Bcm) under cachegrind's branch-predictor model, whereas it's only causing 10,006 in the sorted version.Alternatively, on Linux you can use the performance counters subsystem to accomplish the same task, but with native performance using CPU counters.Sorted:Unsorted:It can also do source code annotation with dissassembly.See the performance tutorial for more details.",
                "I just read up on this question and its answers, and I feel an answer is missing.A common way to eliminate branch prediction that I've found to work particularly good in managed languages is a table lookup instead of using a branch (although I haven't tested it in this case).This approach works in general if:Background and whyFrom a processor perspective, your memory is slow. To compensate for the difference in speed, a couple of caches are built into your processor (L1/L2 cache). So imagine that you're doing your nice calculations and figure out that you need a piece of memory. The processor will get its 'load' operation and loads the piece of memory into cache -- and then uses the cache to do the rest of the calculations. Because memory is relatively slow, this 'load' will slow down your program.Like branch prediction, this was optimized in the Pentium processors: the processor predicts that it needs to load a piece of data and attempts to load that into the cache before the operation actually hits the cache. As we've already seen, branch prediction sometimes goes horribly wrong -- in the worst case scenario you need to go back and actually wait for a memory load, which will take forever (in other words: failing branch prediction is bad, a memory load after a branch prediction fail is just horrible!).Fortunately for us, if the memory access pattern is predictable, the processor will load it in its fast cache and all is well.The first thing we need to know is what is small? While smaller is generally better, a rule of thumb is to stick to lookup tables that are <= 4096 bytes in size. As an upper limit: if your lookup table is larger than 64K it's probably worth reconsidering.Constructing a tableSo we've figured out that we can create a small table. Next thing to do is get a lookup function in place. Lookup functions are usually small functions that use a couple of basic integer operations (and, or, xor, shift, add, remove and perhaps multiply). You want to have your input translated by the lookup function to some kind of 'unique key' in your table, which then simply gives you the answer of all the work you wanted it to do.In this case: >= 128 means we can keep the value, < 128 means we get rid of it. The easiest way to do that is by using an 'AND': if we keep it, we AND it with 7FFFFFFF; if we want to get rid of it, we AND it with 0. Notice also that 128 is a power of 2 -- so we can go ahead and make a table of 32768/128 integers and fill it with one zero and a lot of 7FFFFFFFF's.Managed languagesYou might wonder why this works well in managed languages. After all, managed languages check the boundaries of the arrays with a branch to ensure you don't mess up...Well, not exactly... :-)There has been quite some work on eliminating this branch for managed languages. For example:In this case, it's obvious to the compiler that the boundary condition will never be hit. At least the Microsoft JIT compiler (but I expect Java does similar things) will notice this and remove the check altogether. WOW, that means no branch. Similarly, it will deal with other obvious cases.If you run into trouble with lookups in managed languages -- the key is to add a & 0x[something]FFF to your lookup function to make the boundary check predictable -- and watch it going faster.The result of this case",
                "As data is distributed between 0 and 255 when the array is sorted, around the first half of the iterations will not enter the if-statement (the if statement is shared below).The question is: What makes the above statement not execute in certain cases as in case of sorted data? Here comes the \"branch predictor\". A branch predictor is a digital circuit that tries to guess which way a branch (e.g. an if-then-else structure) will go before this is known for sure. The purpose of the branch predictor is to improve the flow in the instruction pipeline. Branch predictors play a critical role in achieving high effective performance!Let's do some bench marking to understand it betterThe performance of an if-statement depends on whether its condition has a predictable pattern. If the condition is always true or always false, the branch prediction logic in the processor will pick up the pattern. On the other hand, if the pattern is unpredictable, the if-statement will be much more expensive.Let\u2019s measure the performance of this loop with different conditions:Here are the timings of the loop with different true-false patterns:A \u201cbad\u201d true-false pattern can make an if-statement up to six times slower than a \u201cgood\u201d pattern! Of course, which pattern is good and which is bad depends on the exact instructions generated by the compiler and on the specific processor.So there is no doubt about the impact of branch prediction on performance!",
                "One way to avoid branch prediction errors is to build a lookup table, and index it using the data.  Stefan de Bruijn discussed that in his answer.But in this case, we know values are in the range [0, 255] and we only care about values >= 128.  That means we can easily extract a single bit that will tell us whether we want a value or not: by shifting the data to the right 7 bits, we are left with a 0 bit or a 1 bit, and we only want to add the value when we have a 1 bit.  Let's call this bit the \"decision bit\".By using the 0/1 value of the decision bit as an index into an array, we can make code that will be equally fast whether the data is sorted or not sorted.  Our code will always add a value, but when the decision bit is 0, we will add the value somewhere we don't care about.  Here's the code:This code wastes half of the adds but never has a branch prediction failure.  It's tremendously faster on random data than the version with an actual if statement.But in my testing, an explicit lookup table was slightly faster than this, probably because indexing into a lookup table was slightly faster than bit shifting.  This shows how my code sets up and uses the lookup table (unimaginatively called lut for \"LookUp Table\" in the code).  Here's the C++ code:In this case, the lookup table was only 256 bytes, so it fits nicely in a cache and all was fast.  This technique wouldn't work well if the data was 24-bit values and we only wanted half of them... the lookup table would be far too big to be practical.  On the other hand, we can combine the two techniques shown above: first shift the bits over, then index a lookup table.  For a 24-bit value that we only want the top half value, we could potentially shift the data right by 12 bits, and be left with a 12-bit value for a table index.  A 12-bit table index implies a table of 4096 values, which might be practical.The technique of indexing into an array, instead of using an if statement, can be used for deciding which pointer to use.  I saw a library that implemented binary trees, and instead of having two named pointers (pLeft and pRight or whatever) had a length-2 array of pointers and used the \"decision bit\" technique to decide which one to follow.  For example, instead of:this library would do something like:Here's a link to this code: Red Black Trees, Eternally Confuzzled",
                "In the sorted case, you can do better than relying on successful branch prediction or any branchless comparison trick: completely remove the branch.Indeed, the array is partitioned in a contiguous zone with data < 128 and another with data >= 128. So you should find the partition point with a dichotomic search (using Lg(arraySize) = 15 comparisons), then do a straight accumulation from that point.Something like (unchecked)or, slightly more obfuscatedA yet faster approach, that gives an approximate solution for both sorted or unsorted is: sum= 3137536; (assuming a truly uniform distribution, 16384 samples with expected value 191.5) :-)",
                "The above behavior is happening because of Branch prediction.To understand branch prediction one must first understand an Instruction Pipeline.The the steps of running an instruction can be overlapped with the sequence of steps of running the previous and next instruction, so that different steps can be executed concurrently in parallel. This technique is known as instruction pipelining and is used to increase throughput in modern processors. To understand this better please see this example on Wikipedia.Generally, modern processors have quite long (and wide) pipelines, so many instruction can be in flight.  See Modern Microprocessors\nA 90-Minute Guide! which starts by introducing basic in-order pipelining and goes from there.But for ease let's consider a simple in-order pipeline with these 4 steps only.\n(Like a classic 5-stage RISC, but omitting a separate MEM stage.)4-stage pipeline in general for 2 instructions.Moving back to the above question let's consider the following instructions:Without branch prediction, the following would occur:To execute instruction B or instruction C the processor will have to wait (stall) till the instruction A leaves the EX stage in the pipeline, as the decision to go to instruction B or instruction C depends on the result of instruction A.  (i.e. where to fetch from next.) So the pipeline will look like this:Without prediction: when if condition is true:Without prediction: When if condition is false:As a result of waiting for the result of instruction A, the total CPU cycles spent in the above case (without branch prediction; for both true and false) is 7.So what is branch prediction?Branch predictor will try to guess which way a branch (an if-then-else structure) will go before this is known for sure. It will not wait for the instruction A to reach the EX stage of the pipeline, but it will guess the decision and go to that instruction (B or C in case of our example).In case of a correct guess, the pipeline looks something like this:If it is later detected that the guess was wrong then the partially executed instructions are discarded and the pipeline starts over with the correct branch, incurring a delay.\nThe time that is wasted in case of a branch misprediction is equal to the number of stages in the pipeline from the fetch stage to the execute stage. Modern microprocessors tend to have quite long pipelines so that the misprediction delay is between 10 and 20 clock cycles. The longer the pipeline the greater the need for a good branch predictor.In the OP's code, the first time when the conditional, the branch predictor does not have any information to base up prediction, so the first time it will randomly choose the next instruction. (Or fall back to static prediction, typically forward not-taken, backward taken).  Later in the for loop, it can base the prediction on the history.\nFor an array sorted in ascending order, there are three possibilities:Let us assume that the predictor will always assume the true branch on the first run.So in the first case, it will always take the true branch since historically all its predictions are correct.\nIn the 2nd case, initially it will predict wrong, but after a few iterations, it will predict correctly.\nIn the 3rd case, it will initially predict correctly till the elements are less than 128. After which it will fail for some time and the correct itself when it sees branch prediction failure in history.In all these cases the failure will be too less in number and as a result, only a few times it will need to discard the partially executed instructions and start over with the correct branch, resulting in fewer CPU cycles.But in case of a random unsorted array, the prediction will need to discard the partially executed instructions and start over with the correct branch most of the time and result in more CPU cycles compared to the sorted array.Further reading:",
                "An official answer would be fromYou can also see from this lovely diagram why the branch predictor gets confused.Each element in the original code is a random valueso the predictor will change sides as the std::rand() blow.On the other hand, once it's sorted, the predictor will first move into a state of strongly not taken and when the values change to the high value the predictor will in three runs through change all the way from strongly not taken to strongly taken.",
                "In the same line (I think this was not highlighted by any answer) it's good to mention that sometimes (specially in software where the performance matters\u2014like in the Linux kernel) you can find some if statements like the following:or similarly:Both likely() and unlikely() are in fact macros that are defined by using something like the GCC's __builtin_expect to help the compiler insert prediction code to favour the condition taking into account the information provided by the user. GCC supports other builtins that could change the behavior of the running program or emit low level instructions like clearing the cache, etc. See this documentation that goes through the available GCC's builtins.Normally this kind of optimizations are mainly found in hard-real time applications or embedded systems where execution time matters and it's critical. For example, if you are checking for some error condition that only happens 1/10000000 times, then why not inform the compiler about this? This way, by default, the branch prediction would assume that the condition is false.",
                "Frequently used Boolean operations in C++ produce many branches in the compiled program. If these branches are inside loops and are hard to predict they can slow down execution significantly. Boolean variables are stored as 8-bit integers with the value 0 for false and 1 for true.Boolean variables are overdetermined in the sense that all operators that have Boolean variables as input check if the inputs have any other value than 0 or 1, but operators that have Booleans as output can produce no other value than 0 or 1. This makes operations with Boolean variables as input less efficient than necessary.\nConsider example:This is typically implemented by the compiler in the following way:This code is far from optimal. The branches may take a long time in case of mispredictions. The Boolean operations can be made much more efficient if it is known with certainty that the operands have no other values than 0 and 1. The reason why the compiler does not make such an assumption is that the variables might have other values if they are uninitialized or come from unknown sources. The above code can be optimized if a and b has been initialized to valid values or if they come from operators that produce Boolean output. The optimized code looks like this:char is used instead of bool in order to make it possible to use the bitwise operators (& and |) instead of the Boolean operators (&& and ||). The bitwise operators are single instructions that take only one clock cycle. The OR operator (|) works even if a and b have other values than 0 or 1. The AND operator (&) and the EXCLUSIVE OR operator (^) may give inconsistent results if the operands have other values than 0 and 1.~ can not be used for NOT. Instead, you can make a Boolean NOT on a variable which is known to be 0 or 1 by XOR'ing it with 1:can be optimized to:a && b cannot be replaced with a & b if b is an expression that should not be evaluated if a is false ( && will not evaluate b, & will). Likewise, a || b can not be replaced with a | b if b is an expression that should not be evaluated if a is true.Using bitwise operators is more advantageous if the operands are variables than if the operands are comparisons:is optimal in most cases (unless you expect the && expression to generate many branch mispredictions).",
                "That's for sure!...Branch prediction makes the logic run slower, because of the switching which happens in your code! It's like you are going a straight street or a street with a lot of turnings, for sure the straight one is going to be done quicker!...If the array is sorted, your condition is false at the first step: data[c] >= 128, then becomes a true value for the whole way to the end of the street. That's how you get to the end of the logic faster. On the other hand, using an unsorted array, you need a lot of turning and processing which make your code run slower for sure...Look at the image I created for you below. Which street is going to be finished faster?So programmatically, branch prediction causes the process to be slower...Also at the end, it's good to know we have two kinds of branch predictions that each is going to affect your code differently:1. Static2. DynamicStatic branch prediction is used by the microprocessor the first time\na conditional branch is encountered, and dynamic branch prediction is\nused for succeeding executions of the conditional branch code.In order to effectively write your code to take advantage of these\nrules, when writing if-else or switch statements, check the most\ncommon cases first and work progressively down to the least common.\nLoops do not necessarily require any special ordering of code for\nstatic branch prediction, as only the condition of the loop iterator\nis normally used.",
                "This question has already been answered excellently many times over. Still I'd like to draw the group's attention to yet another interesting analysis.Recently this example (modified very slightly) was also used as a way to demonstrate how a piece of code can be profiled within the program itself on Windows. Along the way, the author also shows how to use the results to determine where the code is spending most of its time in both the sorted & unsorted case. Finally the piece also shows how to use a little known feature of the HAL (Hardware Abstraction Layer) to determine just how much branch misprediction is happening in the unsorted case.The link is here:\nA Demonstration of Self-Profiling",
                "As what has already been mentioned by others, what behind the mystery is Branch Predictor.I'm not trying to add something but explaining the concept in another way. \nThere is a concise introduction on the wiki which contains text and diagram.\nI do like the explanation below which uses a diagram to elaborate the Branch Predictor intuitively.In computer architecture, a branch predictor is a\n  digital circuit that tries to guess which way a branch (e.g. an\n  if-then-else structure) will go before this is known for sure. The\n  purpose of the branch predictor is to improve the flow in the\n  instruction pipeline. Branch predictors play a critical role in\n  achieving high effective performance in many modern pipelined\n  microprocessor architectures such as x86.Two-way branching is usually implemented with a conditional jump\n  instruction. A conditional jump can either be \"not taken\" and continue\n  execution with the first branch of code which follows immediately\n  after the conditional jump, or it can be \"taken\" and jump to a\n  different place in program memory where the second branch of code is\n  stored. It is not known for certain whether a conditional jump will be\n  taken or not taken until the condition has been calculated and the\n  conditional jump has passed the execution stage in the instruction\n  pipeline (see fig. 1).Based on the described scenario, I have written an animation demo to show how instructions are executed in a pipeline in different situations.Without branch prediction, the processor would have to wait until the\n  conditional jump instruction has passed the execute stage before the\n  next instruction can enter the fetch stage in the pipeline.The example contains three instructions and the first one is a conditional jump instruction. The latter two instructions can go into the pipeline until the conditional jump instruction is executed.It will take 9 clock cycles for 3 instructions to be completed.It will take 7 clock cycles for 3 instructions to be completed.It will take 9 clock cycles for 3 instructions to be completed.The time that is wasted in case of a branch misprediction is equal to\n  the number of stages in the pipeline from the fetch stage to the\n  execute stage. Modern microprocessors tend to have quite long\n  pipelines so that the misprediction delay is between 10 and 20 clock\n  cycles. As a result, making a pipeline longer increases the need for a\n  more advanced branch predictor.As you can see, it seems we don't have a reason not to use Branch Predictor.It's quite a simple demo that clarifies the very basic part of Branch Predictor. If those gifs are annoying, please feel free to remove them from the answer and visitors can also get the live demo source code from BranchPredictorDemo",
                "Branch-prediction gain!It is important to understand that branch misprediction doesn't slow down programs. The cost of a missed prediction is just as if branch prediction didn't exist and you waited for the evaluation of the expression to decide what code to run (further explanation in the next paragraph).Whenever there's an if-else \\ switch statement, the expression has to be evaluated to determine which block should be executed. In the assembly code generated by the compiler, conditional branch instructions are inserted.A branch instruction can cause a computer to begin executing a different instruction sequence and thus deviate from its default behavior of executing instructions in order (i.e. if the expression is false, the program skips the code of the if block) depending on some condition, which is the expression evaluation in our case.That being said, the compiler tries to predict the outcome prior to it being actually evaluated. It will fetch instructions from the if block, and if the expression turns out to be true, then wonderful! We gained the time it took to evaluate it and made progress in the code; if not then we are running the wrong code, the pipeline is flushed, and the correct block is run.Let's say you need to pick route 1 or route 2. Waiting for your partner to check the map, you have stopped at ## and waited, or you could just pick route1 and if you were lucky (route 1 is the correct route), then great you didn't have to wait for your partner to check the map (you saved the time it would have taken him to check the map), otherwise you will just turn back.While flushing pipelines is super fast, nowadays taking this gamble is worth it. Predicting sorted data or a data that changes slowly is always easier and better than predicting fast changes.",
                "On ARM, there is no branch needed, because every instruction has a 4-bit condition field, which tests (at zero cost) any of 16 different different conditions that may arise in the Processor Status Register, and if the condition on an instruction is false, the instruction is skipped. This eliminates the need for short branches, and there would be no branch prediction hit for this algorithm. Therefore, the sorted version of this algorithm would run slower than the unsorted version on ARM, because of the extra overhead of sorting.The inner loop for this algorithm would look something like the following in ARM assembly language:But this is actually part of a bigger picture:CMP opcodes always update the status bits in the Processor Status Register (PSR), because that is their purpose, but most other instructions do not touch the PSR unless you add an optional S suffix to the instruction, specifying that the PSR should be updated based on the result of the instruction. Just like the 4-bit condition suffix, being able to execute instructions without affecting the PSR is a mechanism that reduces the need for branches on ARM, and also facilitates out of order dispatch at the hardware level, because after performing some operation X that updates the status bits, subsequently (or in parallel) you can do a bunch of other work that explicitly should not affect (or be affected by) the status bits, then you can test the state of the status bits set earlier by X.The condition testing field and the optional \"set status bit\" field can be combined, for example:Most processor architectures do not have this ability to specify whether or not the status bits should be updated for a given operation, which can necessitate writing additional code to save and later restore status bits, or may require additional branches, or may limit the processor's out of order execution efficiency: one of the side effects of most CPU instruction set architectures forcibly updating status bits after most instructions is that it is much harder to tease apart which instructions can be run in parallel without interfering with each other. Updating status bits has side effects, therefore has a linearizing effect on code. ARM's ability to mix and match branch-free condition testing on any instruction with the option to either update or not update the status bits after any instruction is extremely powerful, for both assembly language programmers and compilers, and produces very efficient code.When you don't have to branch, you can avoid the time cost of flushing the pipeline for what would otherwise be short branches, and you can avoid the design complexity of many forms of speculative evalution. The performance impact of the initial naive imlementations of the mitigations for many recently discovered processor vulnerabilities (Spectre etc.) shows you just how much the performance of modern processors depends upon complex speculative evaluation logic. With a short pipeline and the dramatically reduced need for branching, ARM just doesn't need to rely on speculative evaluation as much as CISC processors. (Of course high-end ARM implementations do include speculative evaluation, but it's a smaller part of the performance story.)If you have ever wondered why ARM has been so phenomenally successful, the brilliant effectiveness and interplay of these two mechanisms (combined with another mechanism that lets you \"barrel shift\" left or right one of the two arguments of any arithmetic operator or offset memory access operator at zero additional cost) are a big part of the story, because they are some of the greatest sources of the ARM architecture's efficiency. The brilliance of the original designers of the ARM ISA back in 1983, Steve Furber and Roger (now Sophie) Wilson, cannot be overstated.",
                "It's about branch prediction. What is it?A branch predictor is one of the ancient performance-improving techniques which still finds relevance in modern architectures. While the simple prediction techniques provide fast lookup and power efficiency they suffer from a high misprediction rate.On the other hand, complex branch predictions \u2013either neural-based or variants of two-level branch prediction \u2013provide better prediction accuracy, but they consume more power and complexity increases exponentially.In addition to this, in complex prediction techniques, the time taken to predict the branches is itself very high \u2013ranging from 2 to 5 cycles \u2013which is comparable to the execution time of actual branches.Branch prediction is essentially an optimization (minimization) problem where the emphasis is on to achieve lowest possible miss rate, low power consumption, and low complexity with minimum resources.There really are three different kinds of branches:Forward conditional branches - based on a run-time condition, the PC (program counter) is changed to point to an address forward in the instruction stream.Backward conditional branches - the PC is changed to point backward in the instruction stream. The branch is based on some condition, such as branching backwards to the beginning of a program loop when a test at the end of the loop states the loop should be executed again.Unconditional branches - this includes jumps, procedure calls, and returns that have no specific condition. For example, an unconditional jump instruction might be coded in assembly language as simply \"jmp\", and the instruction stream must immediately be directed to the target location pointed to by the jump instruction, whereas a conditional jump that might be coded as \"jmpne\" would redirect the instruction stream only if the result of a comparison of two values in a previous \"compare\" instructions shows the values to not be equal. (The segmented addressing scheme used by the x86 architecture adds extra complexity since jumps can be either \"near\" (within a segment) or \"far\" (outside the segment). Each type has different effects on branch prediction algorithms.)Static/dynamic Branch Prediction: Static branch prediction is used by the microprocessor the first time a conditional branch is encountered, and dynamic branch prediction is used for succeeding executions of the conditional branch code.References:Branch predictorA Demonstration of Self-ProfilingBranch Prediction ReviewBranch Prediction (Using wayback machine)",
                "Besides the fact that the branch prediction may slow you down, a sorted array has another advantage:You can have a stop condition instead of just checking the value, this way you only loop over the relevant data, and ignore the rest.\nThe branch prediction will miss only once.",
                "Sorted arrays are processed faster than an unsorted array, due to a phenomena called branch prediction.The branch predictor is a digital circuit (in computer architecture) trying to predict which way a branch will go, improving the flow in the instruction pipeline. The circuit/computer predicts the next step and executes it.Making a wrong prediction leads to going back to the previous step, and executing with another prediction. Assuming the prediction is correct, the code will continue to the next step. A wrong prediction results in repeating the same step, until a correct prediction occurs.The answer to your question is very simple.In an unsorted array, the computer makes multiple predictions, leading to an increased chance of errors.\nWhereas, in a sorted array, the computer makes fewer predictions, reducing the chance of errors.\nMaking more predictions requires more time.Sorted Array: Straight RoadUnsorted Array: Curved RoadBranch prediction: Guessing/predicting which road is straight and following it without checkingAlthough both the roads reach the same destination, the straight road is shorter, and the other is longer. If then you choose the other by mistake, there is no turning back, and so you will waste some extra time if you choose the longer road. This is similar to what happens in the computer, and I hope this helped you understand better.Also I want to cite @Simon_Weaver from the comments:It doesn\u2019t make fewer predictions - it makes fewer incorrect predictions. It still has to predict for each time through the loop...",
                "I tried the same code with MATLAB 2011b with my MacBook Pro (Intel i7, 64 bit, 2.4 GHz) for the following MATLAB code:The results for the above MATLAB code are as follows:The results of the C code as in @GManNickG I get:Based on this, it looks MATLAB is almost 175 times slower than the C implementation without sorting and 350 times slower with sorting. In other words, the effect (of branch prediction) is 1.46x for MATLAB implementation and 2.7x for the C implementation.",
                "The assumption by other answers that one needs to sort the data is not correct.The following code does not sort the entire array, but only 200-element segments of it, and thereby runs the fastest.Sorting only k-element sections completes the pre-processing in linear time, O(n), rather than the O(n.log(n)) time needed to sort the entire array.This also \"proves\" that it has nothing to do with any algorithmic issue such as sort order, and it is indeed branch prediction.",
                "Bjarne Stroustrup's Answer to this question:That sounds like an interview question. Is it true? How would you know? It is a bad idea to answer questions about efficiency without first doing some measurements, so it is important to know how to measure.So, I tried with a vector of a million integers and got:I ran that a few times to be sure. Yes, the phenomenon is real. My key code was:At least the phenomenon is real with this compiler, standard library, and optimizer settings. Different implementations can and do give different answers. In fact, someone did do a more systematic study (a quick web search will find it) and most implementations show that effect.One reason is branch prediction: the key operation in the sort algorithm is \u201cif(v[i] < pivot]) \u2026\u201d or equivalent. For a sorted sequence that test is always true whereas, for a random sequence, the branch chosen varies randomly.Another reason is that when the vector is already sorted, we never need to move elements to their correct position. The effect of these little details is the factor of five or six that we saw.Quicksort (and sorting in general) is a complex study that has attracted some of the greatest minds of computer science. A good sort function is a result of both choosing a good algorithm and paying attention to hardware performance in its implementation.If you want to write efficient code, you need to know a bit about machine architecture.",
                "This question is rooted in branch prediction models on CPUs. I'd recommend reading this paper:Increasing the Instruction Fetch Rate via Multiple Branch Prediction and a Branch Address Cache  (But real CPUs these days still don't make multiple taken branch-predictions per clock cycle, except for Haswell and later effectively unrolling tiny loops in its loop buffer.  Modern CPUs can predict multiple branches not-taken to make use of their fetches in large contiguous blocks.)When you have sorted elements, branch prediction easily predicts correctly except right at the boundary, letting instructions flow through the CPU pipeline efficiently, without having to rewind and take the correct path on mispredictions.",
                "An answer for quick and simple understanding (read the others for more details)This concept is called branch predictionBranch prediction is an optimization technique that predicts the path the code will take before it is known with certainty. This is important because during the code execution, the machine prefetches several code statements and stores them in the pipeline.The problem arises in conditional branching, where there are two possible paths or parts of the code that can be executed.When the prediction was true, the optimization technique worked out.When the prediction was false, to explain it in a simple way, the code statement stored in the pipeline gets proved wrong and the actual code has to be completely reloaded, which takes up a lot of time.As common sense suggests, predictions of something sorted are way more accurate than predictions of something unsorted.branch prediction visualisation:sorted\n\nunsorted",
                "It is a branch prediction failure. You don't need to sort the array, but you just need to partition it with the value 128. Sorting is n*log(n), whereas partitioning is just linear. Basically it is just one run of the quick sort partitioning step with the pivot chosen to be 128. Unfortunately in C++ there is just nth_element function, which partition by position, not by value.The answer to this question is that it auto-vectorizes. As usual compilers don't pick perfect strategies. (Although GCC's might be optimal for SSE2 or SSE4.)"
            ]
        },
        {
            "tag": "git",
            "question": [
                "How do I undo the most recent local commits in Git?",
                "I accidentally committed the wrong files to Git, but didn't push the commit to the server yet.\n\nHow do I undo those commits from the local repository?"
            ],
            "url": "https://stackoverflow.com/questions/927358",
            "answer": [
                "Alternatively, to edit the previous commit (or just its commit message), commit --amend will add changes within the current index to the previous commit.To remove (not revert) a commit that has been pushed to the server, rewriting history with git push origin main --force[-with-lease] is necessary. It's almost always a bad idea to use --force; prefer --force-with-lease instead, and as noted in the git manual:You should understand the implications of rewriting history if you [rewrite history] has already been published.You can use git reflog to determine the SHA-1 for the commit to which you wish to revert. Once you have this value, use the sequence of commands as explained above.HEAD~ is the same as HEAD~1. The article What is the HEAD in git? is helpful if you want to uncommit multiple commits.",
                "Undoing a commit is a little scary if you don't know how it works.  But it's actually amazingly easy if you do understand. I'll show you the 4 different ways you can undo a commit.Say you have this, where C is your HEAD and (F) is the state of your files.You want to destroy commit C and also throw away any uncommitted changes.  You do this:The result is:Now B is the HEAD.  Because you used --hard, your files are reset to their state at commit B.Maybe commit C wasn't a disaster, but just a bit off.  You want to undo the commit but keep your changes for a bit of editing before you do a better commit.  Starting again from here, with C as your HEAD:Do this, leaving off the --hard:In this case, the result is:In both cases, HEAD is just a pointer to the latest commit.  When you do a git reset HEAD~1, you tell Git to move the HEAD pointer back one commit.  But (unless you use --hard) you leave your files as they were.  So now git status shows the changes you had checked into C.  You haven't lost a thing!For the lightest touch, you can even undo your commit but leave your files and your index:This not only leaves your files alone, it even leaves your index alone.  When you do git status, you'll see that the same files are in the index as before.  In fact, right after this command, you could do git commit and you'd be redoing the same commit you just had.One more thing: Suppose you destroy a commit as in the first example, but then discover you needed it after all?  Tough luck, right?Nope, there's still a way to get it back.  Type thisand you'll see a list of (partial) commit shas (that is, hashes) that you've moved around in.  Find the commit you destroyed, and do this:You've now resurrected that commit.  Commits don't actually get destroyed in Git for some 90 days, so you can usually go back and rescue one you didn't mean to get rid of.",
                "There are two ways to \"undo\" your last commit, depending on whether or not you have already made your commit public (pushed to your remote repository):Let's say I committed locally, but now I want to remove that commit.To restore everything back to the way it was prior to the last commit, we need to reset to the commit before HEAD:Now git log will show that our last commit has been removed.If you have already made your commits public, you will want to create a new commit which will \"revert\" the changes you made in your previous commit (current HEAD).Your changes will now be reverted and ready for you to commit:For more information, check out Git Basics - Undoing Things.",
                "Add/remove files to get things the way you want:Then amend the commit:The previous, erroneous commit will be edited to reflect the new index state - in other words, it'll be like you never made the mistake in the first place.Note that you should only do this if you haven't pushed yet. If you have pushed, then you'll just have to commit a fix normally.",
                "This will add a new commit which deletes the added files.Or you can rewrite history to undo the last commit.Warning: this command will permanently remove the modifications to the .java files (and any other files) that you committed -- and delete all your changes from your working directory:The hard reset to HEAD-1 will set your working copy to the state of the commit before your wrong commit.",
                "Replace the files in the index:Then, if it's a private branch, amend the commit:Or, if it's a shared branch, make a new commit:(To change a previous commit, use the awesome interactive rebase.)ProTip\u2122: Add *.class to a gitignore to stop this happening again.Amending a commit is the ideal solution if you need to change the last commit, but a more general solution is reset.You can reset Git to any commit with:Where N is the number of commits before HEAD, and @~ resets to the previous commit.Instead of amending the commit, you could use:Check out git help reset, specifically the sections on --soft --mixed and --hard, for a better understanding of what this does.If you mess up, you can always use the reflog to find dropped commits:",
                "Use git revert <commit-id>.To get the commit ID, just use git log.",
                "If you are planning to undo a local commit entirely, whatever you change you did on the commit, and if you don't worry anything about that, just do the following command.(This command will ignore your entire commit and your changes will be lost completely from your local working tree). If you want to undo your commit, but you want your changes in the staging area (before commit just like after git add) then do the following command.Now your committed files come into the staging area. Suppose if you want to upstage the files, because you need to edit some wrong content, then do the following commandNow committed files to come from the staged area into the unstaged area. Now files are ready to edit, so whatever you change, you want to go edit and added it and make a fresh/new commit.More (link broken) (Archived version)",
                "If you have Git Extras installed, you can run git undo to undo the latest commit. git undo 3 will undo the last three commits.",
                "I wanted to undo the latest five commits in our shared repository. I looked up the revision id that I wanted to rollback to. Then I typed in the following.",
                "I prefer to use git rebase -i for this job, because a nice list pops up where I can choose the commits to get rid of. It might not be as direct as some other answers here, but it just feels right.Choose how many commits you want to list, then invoke like this (to enlist last three)Sample listThen Git will remove commits for any line that you remove.",
                "Use git-gui (or similar) to perform a git commit --amend. From the GUI you can add or remove individual files from the commit. You can also modify the commit message.Just reset your branch to the previous location (for example, using gitk or git rebase). Then reapply your changes from a saved copy. After garbage collection in your local repository, it will be like the unwanted commit never happened. To do all of that in a single command, use git reset HEAD~1.Word of warning: Careless use of git reset is a good way to get your working copy into a confusing state. I recommend that Git novices avoid this if they can.Perform a reverse cherry pick (git-revert) to undo the changes.If you haven't yet pulled other changes onto your branch, you can simply do...Then push your updated branch to the shared repository.The commit history will show both commits, separately.Also note: You don't want to do this if someone else may be working on the branch.Clean up your branch locally then repush...In the normal case, you probably needn't worry about your private-branch commit history being pristine.  Just push a followup commit (see 'How to undo a public commit' above), and later, do a squash-merge to hide the history.",
                "If you want to permanently undo it and you have cloned some repository.The commit id can be seen by:Then you can do like:",
                "If you have committed junk but not pushed,HEAD~1 is a shorthand for the commit before head. Alternatively you can refer to the SHA-1 of the hash if you want to reset to. --soft option will delete the commit but it will leave all your changed files \"Changes to be committed\", as git status would put it.If you want to get rid of any changes to tracked files in the working tree since the commit before head use \"--hard\" instead.ORIf you already pushed and someone pulled which is usually my case, you can't use git reset. You can however do a git revert,This will create a new commit that reverses everything introduced by the accidental commit.",
                "On SourceTree (GUI for GitHub), you may right-click the commit and do a 'Reverse Commit'. This should undo your changes.On the terminal:You may alternatively use:Or:",
                "A single command:It works great to undo the last local commit!",
                "Just reset it doing the command below using git:Explain: what git reset does, it's basically reset to any commit you'd like to go back to, then if you combine it with --soft key, it will go back, but keep the  changes in your file(s), so you get back to the stage which the file was just added, HEAD is the head of the branch and if you combine with ~1 (in this case you also use HEAD^), it will go back only one commit which what you want...I create the steps in the image below in more details for you, including all steps that may happens in real situations and committing the code:",
                "\"Reset the working tree to the last commit\"\"Clean unknown files from the working tree\"see - Git Quick ReferenceNOTE: This command will delete your previous commit, so use with caution! git reset --hard is safer.",
                "How to undo the last Git commit?To restore everything back to the way it was prior to the last commit, we need to reset to the commit before HEAD.If you don't want to keep your changes that you made:If you want to keep your changes:Now check your git log. It will show that our last commit has been removed.",
                "Use reflog to find a correct stateREFLOG BEFORE RESETSelect the correct reflog (f3cb6e2 in my case) and typeAfter that the repo HEAD will be reset to that HEADid\n\nLOG AFTER RESETFinally the reflog looks like the picture belowREFLOG FINAL",
                "First run:It will show you all the possible actions you have performed on your repository, for example, commit, merge, pull, etc.Then do:",
                "git reset --soft HEAD^ or git reset --soft HEAD~This will undo the last commit.Here --soft means reset into staging.HEAD~ or HEAD^ means to move to commit before HEAD.It will replace the last commit with the new commit.",
                "Another way:Checkout the branch you want to revert, then reset your local working copy back to the commit that you want to be the latest one on the remote server (everything after it will go bye-bye). To do this, in SourceTree I right-clicked on the and selected \"Reset BRANCHNAME to this commit\".Then navigate to your repository's local directory and run this command:This will erase all commits after the current one in your local repository but only for that one branch.",
                "Type git log and find the last commit hash code and then enter:",
                "In my case I accidentally committed some files I did not want to. So I did the following and it worked:Verify the results with gitk or git log --stat",
                "Simple, run this in your command line:",
                "I am just adding two cents for @Kyralessa's answer:If you are unsure what to use go for --soft (I used this convention to remember it --soft for safe).If you choose --hard by mistake you will LOSE your changes as it wasn't before.\nIf you choose --soft by mistake you can achieve the same results of --hard by applying additional commandsCredits goes to @Kyralessa.",
                "There are many ways to do it:Git command to undo the last commit/ previous commits:Warning: Do Not use --hard if you do not know what you are doing.\n--hard is too dangerous, and it might delete your files.Basic command to revert the commit in Git is:orCOMMIT-ID: ID for the commitn:  is the number of last commits you want to revertYou can get the commit id as shown below:where d81d3f1 and be20eb8 are commit id.Now, let's see some cases:Suppose you want to revert the last commit 'd81d3f1'.  Here are two options:orSuppose you want to revert the commit 'be20eb8':For more detailed information, you can refer to and try out some other commands too for resetting the head to a specified state:",
                "There are two main scenariosYou haven't pushed the commit yetIf the problem was extra files you commited (and you don't want those on repository), you can remove them using git rm and then commiting with --amendYou can also remove entire directories with -r, or even combine with other Bash commandsAfter removing the files, you can commit, with --amend optionThis will rewrite your recent local commit removing the extra files, so, these files will never be sent on push and also will be removed from your local .git repository by GC.You already pushed the commitYou can apply the same solution of the other scenario and then doing git push with the -f option, but it is not recommended since it overwrites the remote history with a divergent change (it can mess your repository).Instead, you have to do the commit without --amend (remember this about -amend`: That option rewrites the history on the last commit).",
                "or if you do not remember exactly in which commit it is, you might useThe proper way of removing files from the repository history is using git filter-branch. That is,But I recomnend you use this command with care. Read more at git-filter-branch(1) Manual Page."
            ]
        },
        {
            "tag": "git",
            "question": [
                "How do I delete a Git branch locally and remotely?",
                "Failed Attempts to Delete a Remote Branch:\n$ git branch -d remotes/origin/bugfix\nerror: branch 'remotes/origin/bugfix' not found.\n\n$ git branch -d origin/bugfix\nerror: branch 'origin/bugfix' not found...."
            ],
            "url": "https://stackoverflow.com/questions/2003505",
            "answer": [
                "Note: In most cases, <remote_name> will be origin.To delete the local branch use one of the following:As of Git v1.7.0, you can delete a remote branch usingwhich might be easier to remember thanwhich was added in Git v1.5.0 \"to delete a remote branch or a tag.\"Starting with Git v2.8.0, you can also use git push with the -d option as an alias for --delete. Therefore, the version of Git you have installed will dictate whether you need to use the easier or harder syntax.From Chapter 3 of Pro Git by Scott Chacon:Suppose you\u2019re done with a remote branch \u2014 say, you and your collaborators are finished with a feature and have merged it into your remote\u2019s main branch (or whatever branch your stable code-line is in). You can delete a remote branch using the rather obtuse syntax git push [remotename] :[branch]. If you want to delete your server-fix branch from the server, you run the following:Boom. No more branches on your server. You may want to dog-ear this page, because you\u2019ll need that command, and you\u2019ll likely forget the syntax. A way to remember this command is by recalling the git push [remotename] [localbranch]:[remotebranch] syntax that we went over a bit earlier. If you leave off the [localbranch] portion, then you\u2019re basically saying, \u201cTake nothing on my side and make it be [remotebranch].\u201dI issued git push origin: bugfix and it worked beautifully. Scott Chacon was right\u2014I will want to dog ear that page (or virtually dog ear by answering this on Stack\u00a0Overflow).Then you should execute this on other machinesto propagate changes.",
                "Matthew\u2019s answer is great for removing remote branches and I also appreciate the explanation, but to make a simple distinction between the two commands:to remove a local branch from your machine: git branch -d {local_branch} (use -D instead to force deleting the branch without checking merged status);to remove a remote branch from the server: git push origin -d {remote_branch}.Reference: Git: Delete a branch (local or remote).",
                "If you want more detailed explanations of the following commands, then see the long answers in the next section.When you're dealing with deleting branches both locally and remotely, keep in mind that there are three different branches involved:The original poster used:Which only deleted his local remote-tracking branch origin/bugfix, and not the actual remote branch bugfix on origin.To delete that actual remote branch, you needThe following sections describe additional details to consider when deleting your remote and remote-tracking branches.Note that deleting the remote branch X from the command line using a git push will also remove the local remote-tracking branch origin/X, so it is not necessary to prune the obsolete remote-tracking branch with git fetch --prune or git fetch -p. However, it wouldn't hurt if you did it anyway.You can verify that the remote-tracking branch origin/X was also deleted by running the following:If you didn't delete your remote branch X from the command line (like above), then your local repository will still contain (a now obsolete) remote-tracking branch origin/X. This can happen if you deleted a remote branch directly through GitHub's web interface, for example.A typical way to remove these obsolete remote-tracking branches (since Git version 1.6.6) is to simply run git fetch with the --prune or shorter -p. Note that this removes all obsolete local remote-tracking branches for any remote branches that no longer exist on the remote:Here is the relevant quote from the 1.6.6 release notes (emphasis mine):\"git fetch\" learned --all and --multiple options, to run fetch from\nmany repositories, and --prune option to remove remote tracking\nbranches that went stale.  These make \"git remote update\" and \"git\nremote prune\" less necessary (there is no plan to remove \"remote\nupdate\" nor \"remote prune\", though).Alternatively, instead of pruning your obsolete local remote-tracking branches through git fetch -p, you can avoid making the extra network operation by just manually removing the branch(es) with the --remotes or -r flags:",
                "For deleting the remote branch:For deleting the local branch, you have three ways:Explain: OK, just explain what's going on here!Simply do git push origin --delete to delete your remote branch only, add the name of the branch at the end and this will delete and push it to remote at the same time...Also, git branch -D, which simply delete the local branch only!...-D stands for --delete --force which will delete the branch even it's not merged (force delete), but you can also use -d which stands for --delete which throw an error respective of the branch merge status...I also create the image below to show the steps:",
                "You can also use the following to delete the remote branchWhich does the same thing asbut it may be easier to remember.",
                "It's very simple:To delete the remote branchOr-- You can also delete tags with this syntaxTo forcefully delete local branchNote: do a git fetch --all --prune on other machines after deleting remote branch, to remove obsolete tracking branches.Exampleto remove local branchto remove remote branchWith the new version of git, its also possible to remove branch withTIP:\nif you want to see all available branches you can use git branch -a,and to see just remote branches, you can use git branch -r",
                "Tip: When you delete branches usingoronly the references are deleted. Even though the branch is actually removed on the remote, the references to it still exists in the local repositories of your team members. This means that for other team members the deleted branches are still visible when they do a git branch -a.To solve this, your team members can prune the deleted branches withThis is typically git remote prune origin.",
                "If you want to delete a branch, first checkout to the branch other than the branch to be deleted.Deleting the local branch:Deleting the remote branch:",
                "This is simple: Just run the following command:To delete a Git branch both locally and remotely, first delete the local branch using this command:(Here example is the branch name.)And after that, delete the remote branch using this command:",
                "Another approach is:WARNING: This will delete all remote branches that do not exist locally. Or more comprehensively,will effectively make the remote repository look like the local copy of the repository (local heads, remotes and tags are mirrored on remote).",
                "I use the following in my Bash settings:Then you can call:",
                "Delete locally:To delete a local branch, you can use:To delete a branch forcibly, use -D instead of -d.Delete remotely:There are two options:I would suggest you use the second way as it is more intuitive.",
                "If you want to complete both these steps with a single command, you can make an alias for it by adding the below to your ~/.gitconfig:Alternatively, you can add this to your global configuration from the command line usingNOTE: If using -d (lowercase d), the branch will only be deleted if it has been merged. To force the delete to happen, you will need to use -D (uppercase D).",
                "Since January 2013, GitHub included a Delete branch button next to each branch in your \"Branches\" page.Relevant blog post: Create and delete branches",
                "To delete your branch locally and remotelyCheckout to master branch -  git checkout masterDelete your remote branch - git push origin --delete <branch-name>Delete your local branch - git branch --delete <branch-name>",
                "You can also do this using git remote prune originIt prunes and deletes remote-tracking branches from a git branch -r listing.",
                "In addition to the other answers, I often use the git_remote_branch tool. It's an extra install, but it gets you a convenient way to interact with remote branches. In this case, to delete:I find that I also use the publish and track commands quite often.",
                "A one-liner command to delete both local, and remote:Or add the alias below to your ~/.gitconfig. Usage: git kill branch-name",
                "Deleting BranchesLet's assume our work on branch \"contact-form\" is done and we've already integrated it into \"master\". Since we don't need it anymore, we can delete it (locally):And for deleting the remote branch:",
                "Delete remote branchgit push origin :<branchname>Delete local branchgit branch -D <branchname>Delete local branch steps:",
                "Simply say:",
                "To delete locally - (normal)If your branch is in a rebasing/merging progress and that was not done properly, it means you will get an error, Rebase/Merge in progress, so in that case, you won't be able to delete your branch.So either you need to solve the rebasing/merging. Otherwise, you can do force delete by using,To delete in remote:You can do the same using:Graphical representation:",
                "Now you can do it with the GitHub Desktop application.After launching the applicationSwitch to the branch you would like to deleteFrom the \"Branch\" menu, select, \"Unpublish...\", to have the branch deleted from the GitHub servers.From the \"Branch\" menu, select, 'Delete \"branch_name\"...', to have the branch deleted off of your local machine (AKA the machine you are currently working on)",
                "is easier to remember than",
                "This won't work if you have a tag with the same name as the branch on the remote:In that case you need to specify that you want to delete the branch, not the tag:Similarly, to delete the tag instead of the branch you would use:",
                "Many of the other answers will lead to errors/warnings. This approach is relatively fool proof although you may still need git branch -D branch_to_delete if it's not fully merged into some_other_branch, for example.Remote pruning isn't needed if you deleted the remote branch. It's only used to get the most up-to-date remotes available on a repository you're tracking. I've observed git fetch will add remotes, not remove them. Here's an example of when git remote prune origin will actually do something:User A does the steps above. User B would run the following commands to see the most up-to-date remote branches:",
                "I got sick of googling for this answer, so I took a similar approach to the answer that crizCraig posted earlier.I added the following to my Bash profile:Then every time I'm done with a branch (merged into master, for example) I run the following in my terminal:...which then deletes my-branch-name from origin as as well as locally.",
                "According to the latest document using a terminal we can delete in the following way.Delete in local:Delete in remote location:",
                "Before executingmake sure you determine first what the exact name of the remote branch is by executing:This will tell you what to enter exactly for <branch> value. (branch is case sensitive!)"
            ]
        },
        {
            "tag": "git",
            "question": [
                "What is the difference between 'git pull' and 'git fetch'?",
                "What are the differences between git pull and git fetch?"
            ],
            "url": "https://stackoverflow.com/questions/292357",
            "answer": [
                "In the simplest terms, git pull does a git fetch followed by a git merge.git fetch updates your remote-tracking branches under refs/remotes/<remote>/. This operation is safe to run at any time since it never changes any of your local branches under refs/heads.git pull brings a local branch up-to-date with its remote version, while also updating your other remote-tracking branches.From the Git documentation for git pull:git pull runs git fetch with the given parameters and then depending on configuration options or command line flags, will call either git rebase or git merge to reconcile diverging branches.It is helpful to keep in mind that when working on any Git respository on any particular machine, the repository contains a copy of all branches from all remotes as well as a copy of each local branch you have done some work on.You can see this using git branch -a, which should show your local branches, including master, and all branches from all remotes.Above, I have indicated the existance of a remote origin repo as well as another remote by another name another-remote-machine.Note you do not necessarily have to have a copy of each branch on all repositories. (Remotes and local.) It will depend on when you have synchronized things by running git pull, git push, git fetch, from the different machines/repositories involved.",
                "git pull tries to automatically merge after fetching commits. It is context sensitive, so all pulled commits will be merged into your currently active branch.  git pull automatically merges the commits without letting you review them first. If you don\u2019t carefully manage your branches, you may run into frequent conflicts.git fetch gathers any commits from the target branch that do not exist in the current branch and stores them in your local repository. However, it does not merge them with your current branch. This is particularly useful if you need to keep your repository up to date, but are working on something that might break if you update your files. To integrate the commits into your current branch, you must use git merge afterwards.",
                "It is important to contrast the design philosophy of git with the philosophy of a more traditional source control tool like SVN.Subversion was designed and built with a client/server model. There is a single repository that is the server, and several clients can fetch code from the server, work on it, then commit it back to the server. The assumption is that the client can always contact the server when it needs to perform an operation.Git was designed to support a more distributed model with no need for a central repository (though you can certainly use one if you like). Also git was designed so that the client and the \"server\" don't need to be online at the same time. Git was designed so that people on an unreliable link could exchange code via email, even. It is possible to work completely disconnected and burn a CD to exchange code via git.In order to support this model git maintains a local repository with your code and also an additional local repository that mirrors the state of the remote repository. By keeping a copy of the remote repository locally, git can figure out the changes needed even when the remote repository is not reachable.  Later when you need to send the changes to someone else, git can transfer them as a set of changes from a point in time known to the remote repository.git fetch is the command that says \"bring my local copy of the remote repository up to date.\"git pull says \"bring the changes in the remote repository to where I keep my own code.\"Normally git pull does this by doing a git fetch to bring the local copy of the remote repository up to date, and then merging the changes into your own code repository and possibly your working copy.The take away is to keep in mind that there are often at least three copies of a project on your workstation. One copy is your own repository with your own commit history. The second copy is your working copy where you are editing and building. The third copy is your local \"cached\" copy of a remote repository.",
                "Here is Oliver Steele's image of how all it all fits together:",
                "One use case of git fetch is that the following will tell you any changes in the remote branch since your last pull... so you can check before doing an actual pull, which could change files in your current branch and working copy.See git diff documentation regarding the double- .. and triple-dot ... syntax.",
                "It cost me a little bit to understand what was the difference, but this is a simple explanation. master in your localhost is a branch.When you clone a repository you fetch the entire repository to you local host. This means that at that time you have an origin/master pointer to HEAD and master pointing to the same HEAD.when you start working and do commits you advance the master pointer to HEAD + your commits. But the origin/master pointer is still pointing to what it was when you cloned.So the difference will be:",
                "Sometimes a visual representation helps.",
                "Even more brieflygit fetch fetches updates but does not merge them.git pull does a git fetch under the hood and then a merge.Brieflygit fetch is similar to pull but doesn't merge. i.e. it fetches remote updates (refs and objects) but your local stays the same (i.e. origin/master gets updated but master stays the same) .git pull pulls down from a remote and instantly merges.Moregit clone clones a repo.git rebase saves stuff from your current branch that isn't in the upstream branch to a temporary area. Your branch is now the same as before you started your changes. So, git pull -rebase will pull down the remote changes, rewind your local branch, replay your changes over the top of your current branch one by one until you're up-to-date.Also, git branch -a will show you exactly what\u2019s going on with all your branches - local and remote.This blog post was useful:The difference between git pull, git fetch and git clone (and git rebase) - Mike Pearceand covers git pull, git fetch, git clone and git rebase.I thought I'd update this to show how you'd actually use this in practice.Update your local repo from the remote (but don't merge):After downloading the updates, let's see the differences:If you're happy with those updates, then merge:Notes:On step 2: For more on diffs between local and remotes, see: How to compare a local Git branch with its remote branchOn step 3: It's probably more accurate (e.g. on a fast changing repo) to do a git rebase origin here. See @Justin Ohms comment in another answer.See also: http://longair.net/blog/2009/04/16/git-fetch-and-merge/Note also: I've mentioned a merge during a pull however you can configure a pull to use a rebase instead.",
                "You would pull if you want the histories merged, you'd fetch if you just 'want the codez' as some person has been tagging some articles around here.",
                "OK, here is some information about git pull and git fetch, so you can understand the actual differences... in few simple words, fetch gets the latest data, but not the code changes and not going to mess with your current  local branch code, but pull get the code changes and merge it your local branch, read on to get more details about each:It will download all refs and objects and any new branches to your local Repository...Fetch branches and/or tags (collectively, \"refs\") from one or more\nother repositories, along with the objects necessary to complete their\nhistories. Remote-tracking branches are updated (see the description\nof  below for ways to control this behavior).By default, any tag that points into the histories being fetched is\nalso fetched; the effect is to fetch tags that point at branches that\nyou are interested in. This default behavior can be changed by using\nthe --tags or --no-tags options or by configuring\nremote..tagOpt. By using a refspec that fetches tags explicitly,\nyou can fetch tags that do not point into branches you are interested\nin as well.git fetch can fetch from either a single named repository or URL or\nfrom several repositories at once if  is given and there is a\nremotes. entry in the configuration file. (See git-config1).When no remote is specified, by default the origin remote will be\nused, unless there\u2019s an upstream branch configured for the current\nbranch.The names of refs that are fetched, together with the object names\nthey point at, are written to .git/FETCH_HEAD. This information may be\nused by scripts or other git commands, such as git-pull.It will apply the changes from remote to the current branch in local...Incorporates changes from a remote repository into the current branch.\nIn its default mode, git pull is shorthand for git fetch followed by\ngit merge FETCH_HEAD.More precisely, git pull runs git fetch with the given parameters and\ncalls git merge to merge the retrieved branch heads into the current\nbranch. With --rebase, it runs git rebase instead of git merge.should be the name of a remote repository as passed to\ngit-fetch1.  can name an arbitrary remote ref (for example,\nthe name of a tag) or even a collection of refs with corresponding\nremote-tracking branches (e.g., refs/heads/:refs/remotes/origin/),\nbut usually it is the name of a branch in the remote repository.Default values for  and  are read from the\n\"remote\" and \"merge\" configuration for the current branch as set by\ngit-branch --track.I also create the visual below to show you how git fetch and git pull working together...",
                "The short and easy answer is that git pull is simply git fetch followed by git merge.It is very important to note that git pull will automatically merge whether you like it or not. This could, of course, result in merge conflicts. Let's say your remote is origin and your branch is master. If you git diff origin/master before pulling, you should have some idea of potential merge conflicts and could prepare your local branch accordingly.In addition to pulling and pushing, some workflows involve git rebase, such as this one, which I paraphrase from the linked article:If you find yourself in such a situation, you may be tempted to git pull --rebase. Unless you really, really know what you are doing, I would advise against that. This warning is from the man page for git-pull, version 2.3.5:This is a potentially dangerous mode of operation. It rewrites\n  history, which does not bode well when you published that history\n  already. Do not use this option unless you have read git-rebase(1)\n  carefully.",
                "You can fetch from a remote repository, see the differences and then pull or merge.This is an example for a remote repository called origin and a branch called master tracking the remote branch origin/master:",
                "This interactive graphical representation is very helpful in understanging git: http://ndpsoftware.com/git-cheatsheet.htmlgit fetch just \"downloads\" the changes from the remote to your local repository. git pull downloads the changes and merges them into your current branch. \"In its default mode, git pull is shorthand for git fetch followed by git merge FETCH_HEAD.\"",
                "In speaking of pull & fetch in the above answers, I would like to share an interesting trick,This above command is the most useful command in my git life which saved a lots of time.Before pushing your new commits to server, try this command and it will automatically sync latest server changes (with a fetch + merge) and will place your commit at the top in git log. No need to worry about manual pull/merge.Find details at: http://gitolite.com/git-pull--rebase",
                "I like to have some visual representation of the situation to grasp these things. Maybe other developers would like to see it too, so here's my addition. I'm not totally sure that it all is correct, so please comment if you find any mistakes.Some major advantages for having a fetched mirror of the remote are:",
                "The Difference between GIT Fetch and GIT Pull can be explained with the following scenario:\n(Keeping in mind that pictures speak louder than words!, I have provided pictorial representation)Let's take an example that you are working on a project with your team members. So there will be one main Branch of the project and all the contributors must fork it to their own local repository and then work on this local branch to modify/Add modules then push back to the main branch.So,\nInitial State of the two Branches when you forked the main project on your local repository will be like this- (A, B and C are Modules already completed of the project)Now, you have started working on the new module (suppose D)  and when you have completed the D module you want to push it to the main branch, But meanwhile what happens is that one of your teammates has developed new Module E, F and modified C.\nSo now what has happened is that your local repository is lacking behind the original progress of the project and thus pushing of your changes to the main branch can lead to conflict and may cause your Module D to malfunction.To avoid such issues and to work parallel with the original progress of the project there are Two ways:1. Git Fetch- This will Download all the changes that have been made to the origin/main branch project which are not present in your local branch. And will wait for the Git Merge command to apply the changes that have been fetched to your Repository or branch.So now You can carefully monitor the files before merging it to your repository. And you can also modify D if required because of Modified C.2. Git Pull- This will update your local branch with the origin/main branch i.e. actually what it does is a combination of Git Fetch and Git merge one after another.\nBut this may Cause Conflicts to occur, so it\u2019s recommended to use Git Pull with a clean copy.",
                "I have struggled with this as well.  In fact I got here with a google search of exactly the same question.  Reading all these answers finally painted a picture in my head and I decided to try to get this down looking at the state of the 2 repositories and 1 sandbox and actions performed over time while watching the version of them.  So here is what I came up with.  Please correct me if I messed up anywhere.The three repos with a fetch:The three repos with a pullThis helped me understand why a fetch is pretty important.",
                "In simple terms, if you were about to hop onto a plane without any Internet connection\u2026 before departing you could just do git fetch origin <branch>. It would fetch all the changes into your computer, but keep it separate from your local development/workspace.On the plane, you could make changes to your local workspace and then merge it with what you've previously fetched and then resolve potential merge conflicts all without a connection to the Internet. And unless someone had made new changes to the remote repository then once you arrive at the destination you would do git push origin <branch> and go get your coffee.From this awesome Atlassian tutorial:The git fetch command downloads commits, files, and refs from a\nremote repository into your local repository.Fetching is what you do when you want to see what everybody else has\nbeen working on. It\u2019s similar to SVN update in that it lets you see\nhow the central history has progressed, but it doesn\u2019t force you to\nactually merge the changes into your repository. Git isolates\nfetched content as a from existing local content, it has absolutely\nno effect on your local development work. Fetched content has to be explicitly checked out using the git checkout command. This makes\nfetching a safe way to review commits before integrating them with\nyour local repository.When downloading content from a remote repository, git pull and git fetch commands are available to accomplish the task. You can consider\ngit fetch the 'safe' version of the two commands. It will download\nthe remote content, but not update your local repository's working state,\nleaving your current work intact. git pull is the more aggressive\nalternative, it will download the remote content for the active local\nbranch and immediately execute git merge to create a merge commit\nfor the new remote content. If you have pending changes in progress\nthis will cause conflicts and kickoff the merge conflict resolution\nflow.With git pull:Hmmm...so if I'm not updating the working copy with git fetch, then where am I making changes? Where does Git fetch store the new commits?Great question. First and foremost, the heads or remotes don't store the new commits. They just have pointers to commits. So with git fetch you download the latest git objects (blob, tree, commits. To fully understand the objects watch this video on git internals), but only update your remotes pointer to point to the latest commit of that branch.  It's still isolated from your working copy, because your branch's pointer in the heads directory hasn't updated. It will only update upon a merge/pull. But again where? Let's find out.In your project directory (i.e., where you do your git commands) do:ls. This will show the files & directories. Nothing cool, I know.Now do ls -a. This will show dot files, i.e., files beginning with . You will then be able to see a directory named: .git.Do cd .git. This will obviously change your directory.Now comes the fun part; do ls. You will see a list of directories. We're looking for refs. Do cd refs.It's interesting to see what's inside all directories, but let's focus on two of them. heads and remotes. Use cd to check inside them too.Any git fetch that you do will update the pointer in the /.git/refs/remotes directory. It won't update anything in the /.git/refs/heads directory.Any git pull will first do the git fetch and update items in the /.git/refs/remotes directory.  It will then also merge with your local and then change the head inside the /.git/refs/heads directory.A very good related answer can also be found in Where does 'git fetch' place itself?.Also, look for \"Slash notation\" from the Git branch naming conventions post. It helps you better understand how Git places things in different directories.Just do:If the remote master was updated you'll get a message like this:If you didn't fetch and just did git checkout master then your local git wouldn't know that there are 2 commits added. And it would just say:But that's outdated and incorrect. It's because git will give you feedback solely based on what it knows. It's oblivious to new commits that it hasn't pulled down yet...Some IDEs (e.g. Xcode) are super smart and use the result of a git fetch and can annotate the lines of code that have been changed in remote branch of your current working branch. If that line has been changed by both local changes and remote branch, then that line gets annotated with red. This isn't a merge conflict. It's a potential merge conflict. It's a headsup that you can use to resolve the future merge conflict before doing git pull from the remote branch.If you fetched a remote branch e.g. did:Then this would go into your remotes directory. It's still not available to your local directory. However, it simplifies your checkout to that remote branch by DWIM (Do what I mean):you no longer need to do:For more on that read here",
                "We simply say:If you run git pull, you do not need to merge the data to local. If you run git fetch, it means you must run git merge for getting the latest code to your local machine. Otherwise, the local machine code would not be changed without merge.So in the Git Gui, when you do fetch, you have to merge the data. Fetch itself won't make the code changes at your local. You can check that when you update the code by fetching\nonce fetch and see; the code it won't change. Then you merge... You will see the changed code.",
                "git fetch pulls down the code from the remote server to your tracking branches in your local repository.  If your remote is named origin (the default) then these branches will be within origin/, for example origin/master, origin/mybranch-123, etc.  These are not your current branches, they are local copies of those branches from the server.git pull does a git fetch but then also merges the code from the tracking branch into your current local version of that branch.  If you're not ready for that changes yet, just git fetch first.",
                "git fetch will retrieve remote branches so that you can git diff or git merge them with the current branch. git pull will run fetch on the remote brach tracked by the current branch and then merge the result. You can use git fetch to see if there are any updates to the remote branch without necessary merging them with your local branch.",
                "Git FetchYou download changes to your local branch from origin through fetch. Fetch asks the remote repo for all commits that others have made but you don't have on your local repo. Fetch downloads these commits and adds them to the local repository.Git MergeYou can apply changes downloaded through fetch using the merge command. Merge will take the commits retrieved from fetch and try to add them to your local branch. The merge will keep the commit history of your local changes so that when you share your branch with push, Git will know how others can merge your changes.Git PullFetch and merge run together often enough that a command that combines the two, pull, was created. Pull does a fetch and then a merge to add the downloaded commits into your local branch.",
                "The only difference between git pull and git fetch is that :git pull pulls from a remote branch and merges it.git fetch only fetches from the remote branch but it does not mergei.e. git pull = git fetch + git merge ...",
                "Git allows chronologically older commits to be applied after newer commits.\nBecause of this, the act of transferring commits between repositories is split into two steps:Copying new commits from remote branch to copy of this remote branch inside local repo.(repo to repo operation) master@remote >> remote/origin/master@localIntegrating new commits to local branch(inside-repo operation) remote/origin/master@local >> master@localThere are two ways of doing step 2. You can:In git terminology, step 1 is git fetch, step 2 is git merge or git rebasegit pull is git fetch and git merge",
                "The git pull command is actually a shortcut for git fetch followed by the git merge or the git rebase command depending on your configuration. You can configure your Git repository so that git pull is a fetch followed by a rebase.",
                "Git obtains the branch of the latest version from the remote to the local using two commands:git fetch: Git is going to get the latest version from remote to local,  but it do not automatically merge.\n\u00a0\u00a0\u00a0\u00a0\ngit fetch origin master\ngit log -p master..origin/master\ngit merge origin/masterThe commands above mean that download latest version of the main branch from origin from the remote to origin master branch. And then compares the local master branch and origin master branch. Finally, merge.git pull: Git is going to get the latest version from the remote and merge into the local.git pull origin masterThe command above is the equivalent to git fetch and git merge. In practice, git fetch maybe more secure because before the merge we can see the changes and decide whether to merge.",
                "What is the difference between git pull and git fetch?To understand this, you first need to understand that your local git maintains not only your local repository, but it also maintains a local copy of the remote repository.git fetch brings your local copy of the remote repository up to date. For example, if your remote repository is GitHub - you may want to fetch any changes made in the remote repository to your local copy of it the remote repository. This will allow you to perform operations such as compare or merge.git pull on the other hand will bring down the changes in the remote repository to where you keep your own code. Typically, git pull will do a git fetch first to bring the local copy of the remote repository up to date, and then it will merge the changes into your own code repository and possibly your working copy.",
                "A simple Graphical Representation for Beginners,here,will fetch code from repository and rebase with your local... in git pull there is possibility of new commits getting created.but in ,git fetchwill fetch code from repository and we need to rebase it manually by using git rebaseeg: i am going to fetch from server master and rebase it in my local master.1) git pull ( rebase will done automatically):here origin is your remote repo master is your branch2) git fetch (need to rebase manually):it will fetch server changes from origin. and it will be in your local until you rebase it on your own. we need to fix conflicts manually by checking codes.this will rebase code into local. before that ensure you're in right branch.",
                "Actually Git maintains a copy of your own code and \nthe remote repository.The command git fetch makes your local copy up to date by getting data from remote repository. The reason we need this is because somebody else might have made some changes to the code and you want to keep yourself updated.The command git pull brings the changes in the remote repository to where you keep your own code. Normally, git pull does this by doing a \u2018git fetch\u2019 first to bring the local copy of the remote repository up to date, and then it merges the changes into your own code repository and possibly your working copy.",
                "git pull == ( git fetch + git merge)git fetch does not changes to local branches.If you already have a local repository with a remote set up for the desired project, you can grab all branches and tags for the existing remote using git fetch . ... Fetch does not make any changes to local branches, so you will need to merge a remote branch with a paired local branch to incorporate newly fetch changes. from github"
            ]
        },
        {
            "tag": "python",
            "question": [
                "What does the \"yield\" keyword do?",
                "What is the use of the yield keyword in Python? What does it do?\nFor example, I'm trying to understand this code1:\ndef _get_child_candidates(self, distance, min_dist, max_dist):\n    if self._leftchild ..."
            ],
            "url": "https://stackoverflow.com/questions/231767",
            "answer": [
                "To understand what yield does, you must understand what generators are. And before you can understand generators, you must understand iterables.When you create a list, you can read its items one by one. Reading its items one by one is called iteration:mylist is an iterable. When you use a list comprehension, you create a list, and so an iterable:Everything you can use \"for... in...\" on is an iterable; lists, strings, files...These iterables are handy because you can read them as much as you wish, but you store all the values in memory and this is not always what you want when you have a lot of values.Generators are iterators, a kind of iterable you can only iterate over once. Generators do not store all the values in memory, they generate the values on the fly:It is just the same except you used () instead of []. BUT, you cannot perform for i in mygenerator a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end calculating 4, one by one.yield is a keyword that is used like return, except the function will return a generator.Here it's a useless example, but it's handy when you know your function will return a huge set of values that you will only need to read once.To master yield, you must understand that when you call the function, the code you have written in the function body does not run. The function only returns the generator object, this is a bit tricky.Then, your code will continue from where it left off each time for uses the generator.Now the hard part:The first time the for calls the generator object created from your function, it will run the code in your function from the beginning until it hits yield, then it'll return the first value of the loop. Then, each subsequent call will run another iteration of the loop you have written in the function and return the next value. This will continue until the generator is considered empty, which happens when the function runs without hitting yield. That can be because the loop has come to an end, or because you no longer satisfy an \"if/else\".Generator:Caller:This code contains several smart parts:The loop iterates on a list, but the list expands while the loop is being iterated. It's a concise way to go through all these nested data even if it's a bit dangerous since you can end up with an infinite loop. In this case, candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) exhausts all the values of the generator, but while keeps creating new generator objects which will produce different values from the previous ones since it's not applied on the same node.The extend() method is a list object method that expects an iterable and adds its values to the list.Usually, we pass a list to it:But in your code, it gets a generator, which is good because:And it works because Python does not care if the argument of a method is a list or not. Python expects iterables so it will work with strings, lists, tuples, and generators! This is called duck typing and is one of the reasons why Python is so cool. But this is another story, for another question...You can stop here, or read a little bit to see an advanced use of a generator:Note: For Python 3, useprint(corner_street_atm.__next__()) or print(next(corner_street_atm))It can be useful for various things like controlling access to a resource.The itertools module contains special functions to manipulate iterables. Ever wish to duplicate a generator?\nChain two generators? Group values in a nested list with a one-liner? Map / Zip without creating another list?Then just import itertools.An example? Let's see the possible orders of arrival for a four-horse race:Iteration is a process implying iterables (implementing the __iter__() method) and iterators (implementing the __next__() method).\nIterables are any objects you can get an iterator from. Iterators are objects that let you iterate on iterables.There is more about it in this article about how for loops work.",
                "When you see a function with yield statements, apply this easy trick to understand what will happen:This trick may give you an idea of the logic behind the function, but what actually happens with yield is significantly different than what happens in the list-based approach. In many cases, the yield approach will be a lot more memory efficient and faster too. In other cases, this trick will get you stuck in an infinite loop, even though the original function works just fine. Read on to learn more...First, the iterator protocol - when you writePython performs the following two steps:Gets an iterator for mylist:Call iter(mylist) -> this returns an object with a next() method (or __next__() in Python 3).[This is the step most people forget to tell you about]Uses the iterator to loop over items:Keep calling the next() method on the iterator returned from step 1. The return value from next() is assigned to x and the loop body is executed. If an exception StopIteration is raised from within next(), it means there are no more values in the iterator and the loop is exited.The truth is Python performs the above two steps anytime it wants to loop over the contents of an object - so it could be a for loop, but it could also be code like otherlist.extend(mylist) (where otherlist is a Python list).Here mylist is an iterable because it implements the iterator protocol. In a user-defined class, you can implement the __iter__() method to make instances of your class iterable. This method should return an iterator. An iterator is an object with a next() method. It is possible to implement both __iter__() and next() on the same class, and have __iter__() return self. This will work for simple cases, but not when you want two iterators looping over the same object at the same time.So that's the iterator protocol, many objects implement this protocol:Note that a for loop doesn't know what kind of object it's dealing with - it just follows the iterator protocol, and is happy to get item after item as it calls next(). Built-in lists return their items one by one, dictionaries return the keys one by one, files return the lines one by one, etc. And generators return... well that's where yield comes in:Instead of yield statements, if you had three return statements in f123() only the first would get executed, and the function would exit. But f123() is no ordinary function. When f123() is called, it does not return any of the values in the yield statements! It returns a generator object. Also, the function does not really exit - it goes into a suspended state. When the for loop tries to loop over the generator object, the function resumes from its suspended state at the very next line after the yield it previously returned from, executes the next line of code, in this case, a yield statement, and returns that as the next item. This happens until the function exits, at which point the generator raises StopIteration, and the loop exits.So the generator object is sort of like an adapter - at one end it exhibits the iterator protocol, by exposing __iter__() and next() methods to keep the for loop happy. At the other end, however, it runs the function just enough to get the next value out of it, and puts it back in suspended mode.Usually, you can write code that doesn't use generators but implements the same logic. One option is to use the temporary list 'trick' I mentioned before. That will not work in all cases, for e.g. if you have infinite loops, or it may make inefficient use of memory when you have a really long list. The other approach is to implement a new iterable class SomethingIter that keeps the state in instance members and performs the next logical step in its next() (or __next__() in Python 3) method. Depending on the logic, the code inside the next() method may end up looking very complex and prone to bugs. Here generators provide a clean and easy solution.",
                "Think of it this way:An iterator is just a fancy sounding term for an object that has a next() method.  So a yield-ed function ends up being something like this:Original version:This is basically what the Python interpreter does with the above code:For more insight as to what's happening behind the scenes, the for loop can be rewritten to this:Does that make more sense or just confuse you more?  :)I should note that this is an oversimplification for illustrative purposes. :)",
                "The yield keyword is reduced to two simple facts:In a nutshell: Most commonly, a generator is a lazy, incrementally-pending list, and yield statements allow you to use function notation to program the list values the generator should incrementally spit out. Furthermore, advanced usage lets you use generators as coroutines (see below).Basically, whenever the yield statement is encountered, the function pauses and saves its state, then emits \"the next return value in the 'list'\" according to the python iterator protocol (to some syntactic construct like a for-loop that repeatedly calls next() and catches a StopIteration exception, etc.). You might have encountered generators with generator expressions; generator functions are more powerful because you can pass arguments back into the paused generator function, using them to implement coroutines. More on that later.Let's define a function makeRange that's just like Python's range. Calling makeRange(n) RETURNS A GENERATOR:To force the generator to immediately return its pending values, you can pass it into list() (just like you could any iterable):The above example can be thought of as merely creating a list which you append to and return:There is one major difference, though; see the last section.An iterable is the last part of a list comprehension, and all generators are iterable, so they're often used like so:To get a better feel for generators, you can play around with the itertools module (be sure to use chain.from_iterable rather than chain when warranted). For example, you might even use generators to implement infinitely-long lazy lists like itertools.count(). You could implement your own def enumerate(iterable): zip(count(), iterable), or alternatively do so with the yield keyword in a while-loop.Please note: generators can actually be used for many more things, such as implementing coroutines or non-deterministic programming or other elegant things. However, the \"lazy lists\" viewpoint I present here is the most common use you will find.This is how the \"Python iteration protocol\" works. That is, what is going on when you do list(makeRange(5)). This is what I describe earlier as a \"lazy, incremental list\".The built-in function next() just calls the objects .__next__() function, which is a part of the \"iteration protocol\" and is found on all iterators. You can manually use the next() function (and other parts of the iteration protocol) to implement fancy things, usually at the expense of readability, so try to avoid doing that...Coroutine example:A coroutine (generators which generally accept input via the yield keyword e.g. nextInput = yield nextOutput, as a form of two-way communication) is basically a computation which is allowed to pause itself and request input (e.g. to what it should do next). When the coroutine pauses itself (when the running coroutine eventually hits a yield keyword), the computation is paused and control is inverted (yielded) back to the 'calling' function (the frame which requested the next value of the computation). The paused generator/coroutine remains paused until another invoking function (possibly a different function/context) requests the next value to unpause it (usually passing input data to direct the paused logic interior to the coroutine's code).You can think of python coroutines as lazy incrementally-pending lists, where the next element doesn't just depend on the previous computation, but also on input you may opt to inject during the generation process.Normally, most people would not care about the following distinctions and probably want to stop reading here.In Python-speak, an iterable is any object which \"understands the concept of a for-loop\" like a list [1,2,3], and an iterator is a specific instance of the requested for-loop like [1,2,3].__iter__(). A generator is exactly the same as any iterator, except for the way it was written (with function syntax).When you request an iterator from a list, it creates a new iterator. However, when you request an iterator from an iterator (which you would rarely do), it just gives you a copy of itself.Thus, in the unlikely event that you are failing to do something like this...... then remember that a generator is an iterator; that is, it is one-time-use. If you want to reuse it, you should call myRange(...) again. If you need to use the result twice, convert the result to a list and store it in a variable x = list(myRange(5)). Those who absolutely need to clone a generator (for example, who are doing terrifyingly hackish metaprogramming) can use itertools.tee (still works in Python 3) if absolutely necessary, since the copyable iterator Python PEP standards proposal has been deferred.",
                "What does the yield keyword do in Python?yield is only legal inside of a function definition, and the inclusion of yield in a function definition makes it return a generator.The idea for generators comes from other languages (see footnote 1) with varying implementations. In Python's Generators, the execution of the code is frozen at the point of the yield. When the generator is called (methods are discussed below) execution resumes and then freezes at the next yield.yield provides an\neasy way of implementing the iterator protocol, defined by the following two methods:\n__iter__ and __next__.  Both of those methods\nmake an object an iterator that you could type-check with the Iterator Abstract Base\nClass from the collections module.Let's do some introspection:The generator type is a sub-type of iterator:And if necessary, we can type-check like this:A feature of an Iterator is that once exhausted, you can't reuse or reset it:You'll have to make another if you want to use its functionality again (see footnote 2):One can yield data programmatically, for example:The above simple generator is also equivalent to the below - as of Python 3.3 you can use yield from:However, yield from also allows for delegation to subgenerators,\nwhich will be explained in the following section on cooperative delegation with sub-coroutines.yield forms an expression that allows data to be sent into the generator (see footnote 3)Here is an example, take note of the received variable, which will point to the data that is sent to the generator:First, we must queue up the generator with the builtin function, next. It will\ncall the appropriate next or __next__ method, depending on the version of\nPython you are using:And now we can send data into the generator. (Sending None is\nthe same as calling next.) :Now, recall that yield from is available in Python 3. This allows us to delegate coroutines to a subcoroutine:And now we can delegate functionality to a sub-generator and it can be used\nby a generator just as above:Now simulate adding another 1,000 to the account plus the return on the account (60.0):You can read more about the precise semantics of yield from in PEP 380.The close method raises GeneratorExit at the point the function\nexecution was frozen. This will also be called by __del__ so you\ncan put any cleanup code where you handle the GeneratorExit:You can also throw an exception which can be handled in the generator\nor propagated back to the user:Raises:I believe I have covered all aspects of the following question:What does the yield keyword do in Python?It turns out that yield does a lot. I'm sure I could add even more\nthorough examples to this. If you want more or have some constructive criticism, let me know by commenting\nbelow.The top/accepted answer is a very incomplete answer.The grammar currently allows any expression in a list comprehension.Since yield is an expression, it has been touted by some as interesting to use it in comprehensions or generator expression - in spite of citing no particularly good use-case.The CPython core developers are discussing deprecating its allowance.\nHere's a relevant post from the mailing list:On 30 January 2017 at 19:05, Brett Cannon  wrote:On Sun, 29 Jan 2017 at 16:39 Craig Rodrigues  wrote:I'm OK with either approach.  Leaving things the way they are in Python 3\nis no good, IMHO.My vote is it be a SyntaxError since you're not getting what you expect from\nthe syntax.I'd agree that's a sensible place for us to end up, as any code\nrelying on the current behaviour is really too clever to be\nmaintainable.In terms of getting there, we'll likely want:Cheers, Nick.--  Nick Coghlan   |   ncoghlan at gmail.com   |   Brisbane, AustraliaFurther, there is an outstanding issue (10544) which seems to be pointing in the direction of this never being a good idea (PyPy, a Python implementation written in Python, is already raising syntax warnings.)Bottom line, until the developers of CPython tell us otherwise: Don't put yield in a generator expression or comprehension.In Python 3:In a generator function, the return statement indicates that the generator is done and will cause StopIteration to be raised. The returned value (if any) is used as an argument to construct StopIteration and becomes the StopIteration.value attribute.Historical note, in Python 2:\n\"In a generator function, the return statement is not allowed to include an expression_list. In that context, a bare return indicates that the generator is done and will cause StopIteration to be raised.\"\nAn expression_list is basically any number of expressions separated by commas - essentially, in Python 2, you can stop the generator with return, but you can't return a value.The languages CLU, Sather, and Icon were referenced in the proposal\nto introduce the concept of generators to Python. The general idea is\nthat a function can maintain internal state and yield intermediate\ndata points on demand by the user. This promised to be superior in performance\nto other approaches, including Python threading, which isn't even available on some systems.This means, for example, that range objects aren't Iterators, even though they are iterable, because they can be reused. Like lists, their __iter__ methods return iterator objects.yield was originally introduced as a statement, meaning that it\ncould only appear at the beginning of a line in a code block.\nNow yield creates a yield expression.\nhttps://docs.python.org/2/reference/simple_stmts.html#grammar-token-yield_stmt\nThis change was proposed to allow a user to send data into the generator just as\none might receive it. To send data, one must be able to assign it to something, and\nfor that, a statement just won't work.",
                "yield is just like return - it returns whatever you tell it to (as a generator). The difference is that the next time you call the generator, execution starts from the last call to the yield statement. Unlike return, the stack frame is not cleaned up when a yield occurs, however control is transferred back to the caller, so its state will resume the next time the function is called.In the case of your code, the function get_child_candidates is acting like an iterator so that when you extend your list, it adds one element at a time to the new list.list.extend calls an iterator until it's exhausted. In the case of the code sample you posted, it would be much clearer to just return a tuple and append that to the list.",
                "There's one extra thing to mention: a function that yields doesn't actually have to terminate. I've written code like this:Then I can use it in other code like this:It really helps simplify some problems, and makes some things easier to work with.",
                "For those who prefer a minimal working example, meditate on this interactive Python session:",
                "TL;DRWhenever you find yourself building a list from scratch, yield each piece instead.This was my first \"aha\" moment with yield.yield is a sugary way to saybuild a series of stuffSame behavior:Different behavior:Yield is single-pass: you can only iterate through once. When a function has a yield in it we call it a generator function. And an iterator is what it returns. Those terms are revealing. We lose the convenience of a container, but gain the power of a series that's computed as needed, and arbitrarily long.Yield is lazy, it puts off computation. A function with a yield in it doesn't actually execute at all when you call it. It returns an iterator object that remembers where it left off. Each time you call next() on the iterator (this happens in a for-loop) execution inches forward to the next yield. return raises StopIteration and ends the series (this is the natural end of a for-loop).Yield is versatile. Data doesn't have to be stored all together, it can be made available one at a time. It can be infinite.If you need multiple passes and the series isn't too long, just call list() on it:Brilliant choice of the word yield because both meanings apply:yield \u2014 produce or provide (as in agriculture)...provide the next data in the series.yield \u2014 give way or relinquish (as in political power)...relinquish CPU execution until the iterator advances.",
                "Yield gives you a generator.As you can see, in the first case foo holds the entire list in memory at once. It's not a big deal for a list with 5 elements, but what if you want a list of 5 million? Not only is this a huge memory eater, it also costs a lot of time to build at the time that the function is called.In the second case, bar just gives you a generator. A generator is an iterable--which means you can use it in a for loop, etc, but each value can only be accessed once. All the values are also not stored in memory at the same time; the generator object \"remembers\" where it was in the looping the last time you called it--this way, if you're using an iterable to (say) count to 50 billion, you don't have to count to 50 billion all at once and store the 50 billion numbers to count through.Again, this is a pretty contrived example, you probably would use itertools if you really wanted to count to 50 billion. :)This is the most simple use case of generators. As you said, it can be used to write efficient permutations, using yield to push things up through the call stack instead of using some sort of stack variable. Generators can also be used for specialized tree traversal, and all manner of other things.",
                "It's returning a generator. I'm not particularly familiar with Python, but I believe it's the same kind of thing as C#'s iterator blocks if you're familiar with those.The key idea is that the compiler/interpreter/whatever does some trickery so that as far as the caller is concerned, they can keep calling next() and it will keep returning values - as if the generator method was paused. Now obviously you can't really \"pause\" a method, so the compiler builds a state machine for you to remember where you currently are and what the local variables etc look like. This is much easier than writing an iterator yourself.",
                "There is one type of answer that I don't feel has been given yet, among the many great answers that describe how to use generators. Here is the programming language theory answer:The yield statement in Python returns a generator. A generator in Python is a function that returns continuations (and specifically a type of coroutine, but continuations represent the more general mechanism to understand what is going on).Continuations in programming languages theory are a much more fundamental kind of computation, but they are not often used, because they are extremely hard to reason about and also very difficult to implement. But the idea of what a continuation is, is straightforward: it is the state of a computation that has not yet finished. In this state, the current values of variables, the operations that have yet to be performed, and so on, are saved. Then at some point later in the program the continuation can be invoked, such that the program's variables are reset to that state and the operations that were saved are carried out.Continuations, in this more general form, can be implemented in two ways. In the call/cc way, the program's stack is literally saved and then when the continuation is invoked, the stack is restored.In continuation passing style (CPS), continuations are just normal functions (only in languages where functions are first class) which the programmer explicitly manages and passes around to subroutines. In this style, program state is represented by closures (and the variables that happen to be encoded in them) rather than variables that reside somewhere on the stack. Functions that manage control flow accept continuation as arguments (in some variations of CPS, functions may accept multiple continuations) and manipulate control flow by invoking them by simply calling them and returning afterwards. A very simple example of continuation passing style is as follows:In this (very simplistic) example, the programmer saves the operation of actually writing the file into a continuation (which can potentially be a very complex operation with many details to write out), and then passes that continuation (i.e, as a first-class closure) to another operator which does some more processing, and then calls it if necessary. (I use this design pattern a lot in actual GUI programming, either because it saves me lines of code or, more importantly, to manage control flow after GUI events trigger.)The rest of this post will, without loss of generality, conceptualize continuations as CPS, because it is a hell of a lot easier to understand and read.Now let's talk about generators in Python. Generators are a specific subtype of continuation. Whereas continuations are able in general to save the state of a computation (i.e., the program's call stack), generators are only able to save the state of iteration over an iterator. Although, this definition is slightly misleading for certain use cases of generators. For instance:This is clearly a reasonable iterable whose behavior is well defined -- each time the generator iterates over it, it returns 4 (and does so forever). But it isn't probably the prototypical type of iterable that comes to mind when thinking of iterators (i.e., for x in collection: do_something(x)). This example illustrates the power of generators: if anything is an iterator, a generator can save the state of its iteration.To reiterate: Continuations can save the state of a program's stack and generators can save the state of iteration. This means that continuations are more a lot powerful than generators, but also that generators are a lot, lot easier. They are easier for the language designer to implement, and they are easier for the programmer to use (if you have some time to burn, try to read and understand this page about continuations and call/cc).But you could easily implement (and conceptualize) generators as a simple, specific case of continuation passing style:Whenever yield is called, it tells the function to return a continuation.  When the function is called again, it starts from wherever it left off. So, in pseudo-pseudocode (i.e., not pseudocode, but not code) the generator's next method is basically as follows:where the yield keyword is actually syntactic sugar for the real generator function, basically something like:Remember that this is just pseudocode and the actual implementation of generators in Python is more complex. But as an exercise to understand what is going on, try to use continuation passing style to implement generator objects without use of the yield keyword.",
                "Here is an example in plain language. I will provide a correspondence between high-level human concepts to low-level Python concepts.I want to operate on a sequence of numbers, but I don't want to bother my self with the creation of that sequence, I want only to focus on the operation I want to do. So, I do the following:This is what a generator does (a function that contains a yield); it starts executing on the first next(), pauses whenever it does a yield, and when asked for the next() value it continues from the point it was last. It fits perfectly by design with the iterator protocol of Python, which describes how to sequentially request values.The most famous user of the iterator protocol is the for command in Python. So, whenever you do a:it doesn't matter if sequence is a list, a string, a dictionary or a generator object like described above; the result is the same: you read items off a sequence one by one.Note that defining a function which contains a yield keyword is not the only way to create a generator; it's just the easiest way to create one.For more accurate information, read about iterator types, the yield statement and generators in the Python documentation.",
                "While a lot of answers show why you'd use a yield to create a generator, there are more uses for yield.  It's quite easy to make a coroutine, which enables the passing of information between two blocks of code.  I won't repeat any of the fine examples that have already been given about using yield to create a generator.To help understand what a yield does in the following code, you can use your finger to trace the cycle through any code that has a yield.  Every time your finger hits the yield, you have to wait for a next or a send to be entered.  When a next is called, you trace through the code until you hit the yield\u2026 the code on the right of the yield is evaluated and returned to the caller\u2026 then you wait.  When next is called again, you perform another loop through the code.  However, you'll note that in a coroutine, yield can also be used with a send\u2026 which will send a value from the caller into the yielding function. If a send is given, then yield receives the value sent, and spits it out the left hand side\u2026 then the trace through the code progresses until you hit the yield again (returning the value at the end, as if next was called).For example:",
                "There is another yield use and meaning (since Python 3.3):From PEP 380 -- Syntax for Delegating to a Subgenerator:A syntax is proposed for a generator to delegate part of its operations to another generator. This allows a section of code containing 'yield' to be factored out and placed in another generator. Additionally, the subgenerator is allowed to return with a value, and the value is made available to the delegating generator.The new syntax also opens up some opportunities for optimisation when one generator re-yields values produced by another.Moreover this will introduce (since Python 3.5):to avoid coroutines being confused with a regular generator (today yield is used in both).",
                "All great answers, however a bit difficult for newbies.I assume you have learned the return statement.As an analogy, return and yield are twins. return means 'return and stop' whereas 'yield` means 'return, but continue'Run it:See, you get only a single number rather than a list of them. return never allows you prevail happily, just implements once and quit.Replace return with yield:Now, you win to get all the numbers.Comparing to return which runs once and stops, yield runs times you planed.\nYou can interpret return as return one of them, and yield as return all of them. This is called iterable.It's the core about yield.The difference between a list return outputs and the object yield output is:You will always get [0, 1, 2] from a list object but only could retrieve them from 'the object yield output' once. So, it has a new name generator object as displayed in Out[11]: <generator object num_list at 0x10327c990>.In conclusion, as a metaphor to grok it:",
                "From a programming viewpoint, the iterators are implemented as thunks.To implement iterators, generators, and thread pools for concurrent execution, etc. as thunks, one uses messages sent to a closure object, which has a dispatcher, and the dispatcher answers to \"messages\".\"next\" is a message sent to a closure, created by the \"iter\" call.There are lots of ways to implement this computation. I used mutation, but it is possible to do this kind of computation without mutation, by returning the current value and the next yielder (making it referential transparent).  Racket uses a sequence of transformations of the initial program in some intermediary languages, one of such rewriting making the yield operator to be transformed in some language with simpler operators.Here is a demonstration of how yield could be rewritten, which uses the structure of R6RS, but the semantics is identical to Python's. It's the same model of computation, and only a change in syntax is required to rewrite it using yield of Python.",
                "Here are some Python examples of how to actually implement generators as if Python did not provide syntactic sugar for them:As a Python generator:Using lexical closures instead of generatorsUsing object closures instead of generators (because ClosuresAndObjectsAreEquivalent)",
                "I was going to post \"read page 19 of Beazley's 'Python: Essential Reference' for a quick description of generators\", but so many others have posted good descriptions already.Also, note that yield can be used in coroutines as the dual of their use in generator functions.  Although it isn't the same use as your code snippet, (yield) can be used as an expression in a function.  When a caller sends a value to the method using the send() method, then the coroutine will execute until the next (yield) statement is encountered.Generators and coroutines are a cool way to set up data-flow type applications.  I thought it would be worthwhile knowing about the other use of the yield statement in functions.",
                "Here is a simple example:Output:I am not a Python developer, but it looks to me yield holds the position of program flow and the next loop start from \"yield\" position. It seems like it is waiting at that position, and just before that, returning a value outside, and next time continues to work.It seems to be an interesting and nice ability :D",
                "Here is a mental image of what yield does.I like to think of a thread as having a stack (even when it's not implemented that way).When a normal function is called, it puts its local variables on the stack, does some computation, then clears the stack and returns. The values of its local variables are never seen again.With a yield function, when its code begins to run (i.e. after the function is called, returning a generator object, whose next() method is then invoked), it similarly puts its local variables onto the stack and computes for a while. But then, when it hits the yield statement, before clearing its part of the stack and returning, it takes a snapshot of its local variables and stores them in the generator object. It also writes down the place where it's currently up to in its code (i.e. the particular yield statement).So it's a kind of a frozen function that the generator is hanging onto.When next() is called subsequently, it retrieves the function's belongings onto the stack and re-animates it. The function continues to compute from where it left off, oblivious to the fact that it had just spent an eternity in cold storage.Compare the following examples:When we call the second function, it behaves very differently to the first. The yield statement might be unreachable, but if it's present anywhere, it changes the nature of what we're dealing with.Calling yielderFunction() doesn't run its code, but makes a generator out of the code. (Maybe it's a good idea to name such things with the yielder prefix for readability.)The gi_code and gi_frame fields are where the frozen state is stored. Exploring them with dir(..), we can confirm that our mental model above is credible.",
                "Imagine that you have created a remarkable machine that is capable of generating thousands and thousands of lightbulbs per day. The machine generates these lightbulbs in boxes with a unique serial number. You don't have enough space to store all of these lightbulbs at the same time, so you would like to adjust it to generate lightbulbs on-demand.Python generators don't differ much from this concept. Imagine that you have a function called barcode_generator that generates unique serial numbers for the boxes. Obviously, you can have a huge number of such barcodes returned by the function, subject to the hardware (RAM) limitations. A wiser, and space efficient, option is to generate those serial numbers on-demand.Machine's code:Note the next(barcode) bit.As you can see, we have a self-contained \u201cfunction\u201d to generate the next unique serial number each time. This function returns a generator! As you can see, we are not calling the function each time we need a new serial number, but instead we are using next() given the generator to obtain the next serial number.To be more precise, this generator is a lazy iterator! An iterator is an object that helps us traverse a sequence of objects. It's called lazy because it does not load all the items of the sequence in memory until they are needed. The use of next in the previous example is the explicit way to obtain the next item from the iterator. The implicit way is using for loops:This will print barcodes infinitely, yet you will not run out of memory.In other words, a generator looks like a function but behaves like an iterator.Finally, real-world applications? They are usually useful when you work with big sequences. Imagine reading a huge file from disk with billions of records. Reading the entire file in memory, before you can work with its content, will probably be infeasible (i.e., you will run out of memory).",
                "An easy example to understand what it is: yieldThe output is:",
                "Like every answer suggests, yield is used for creating a sequence generator. It's used for generating some sequence dynamically. For example, while reading a file line by line on a network, you can use the yield function as follows:You can use it in your code as follows:Execution Control Transfer gotchaThe execution control will be transferred from getNextLines() to the for loop when yield is executed. Thus, every time getNextLines() is invoked, execution begins from the point where it was paused last time.Thus in short, a function with the following codewill print",
                "(My below answer only speaks from the perspective of using Python generator, not the underlying implementation of generator mechanism, which involves some tricks of stack and heap manipulation.)When yield is used instead of a return in a python function, that function is turned into something special called generator function. That function will return an object of generator type. The yield keyword is a flag to notify the python compiler to treat such function specially. Normal functions will terminate once some value is returned from it. But with the help of the compiler, the generator function can be thought of as resumable. That is, the execution context will be restored and the execution will continue from last run. Until you explicitly call return, which will raise a StopIteration exception (which is also part of the iterator protocol), or reach the end of the function. I found a lot of references about generator but this one from the functional programming perspective is the most digestable.(Now I want to talk about the rationale behind generator, and the iterator based on my own understanding. I hope this can help you grasp the essential motivation of iterator and generator. Such concept shows up in other languages as well such as C#.)As I understand, when we want to process a bunch of data, we usually first store the data somewhere and then process it one by one. But this naive approach is problematic. If the data volume is huge, it's expensive to store them as a whole beforehand. So instead of storing the data itself directly, why not store some kind of metadata indirectly, i.e. the logic how the data is computed.There are 2 approaches to wrap such metadata.Either way, an iterator is created, i.e. some object that can give you the data you want. The OO approach may be a bit complex. Anyway, which one to use is up to you.",
                "In summary, the yield statement transforms your function into a factory that produces a special object called a generator which wraps around the body of your original function. When the generator is iterated, it executes your function  until it reaches the next yield then suspends execution and evaluates to the value passed to yield. It repeats this process on each iteration until the path of execution exits the function. For instance,simply outputsThe power comes from using the generator with a loop that calculates a sequence, the generator executes the loop stopping each time to 'yield' the next result of the calculation, in this way it calculates a list on the fly, the benefit being the memory saved for especially large calculationsSay you wanted to create a your own range function that produces an iterable range of numbers, you could do it like so,and use it like this;But this is inefficient becauseLuckily Guido and his team were generous enough to develop generators so we could just do this;Now upon each iteration a function on the generator called next() executes the function until it either reaches a 'yield' statement in which it stops and  'yields' the value or reaches the end of the function. In this case on the first call, next() executes up to the yield statement and yield 'n', on the next call it will execute the  increment statement, jump back to the 'while', evaluate it, and if true, it will stop and yield 'n' again, it will continue that way until the while condition returns false and the generator jumps to the end of the function.",
                "Yield is an objectA return in a function will return a single value.If you want a function to return a huge set of values, use yield.More importantly, yield is a barrier.like barrier in the CUDA language, it will not transfer control until it gets\n  completed.That is, it will run the code in your function from the beginning until it hits yield. Then, it\u2019ll return the first value of the loop.Then, every other call will run the loop you have written in the function one more time, returning the next value until there isn't any value to return.",
                "Many people use return rather than yield, but in some cases yield can be more efficient and easier to work with.Here is an example which yield is definitely best for:return (in function)yield (in function)Calling functionsBoth functions do the same thing, but yield uses three lines instead of five and has one less variable to worry about.This is the result from the code:As you can see both functions do the same thing. The only difference is return_dates() gives a list and yield_dates() gives a generator.A real life example would be something like reading a file line by line or if you just want to make a generator.",
                "The yield keyword simply collects returning results. Think of yield like return +=",
                "yield is like a return element for a function. The difference is, that the yield element turns a function into a generator. A generator behaves just like a function until something is 'yielded'. The generator stops until it is next called, and continues from exactly the same point as it started. You can get a sequence of all the 'yielded' values in one, by calling list(generator())."
            ]
        },
        {
            "tag": "json",
            "question": [
                "Which JSON content type do I use?",
                "There are many \"standards\" for the JSON content type:\napplication/json\napplication/x-javascript\ntext/javascript\ntext/x-javascript\ntext/x-json\n\nWhich one do I use, and where? I assume ..."
            ],
            "url": "https://stackoverflow.com/questions/477816",
            "answer": [
                "For JSON text:The MIME media type for JSON text is application/json. The default encoding is UTF-8. (Source: RFC 4627)For JSONP (runnable JavaScript) with callback:Here are some blog posts that were mentioned in the relevant comments:",
                "IANA has registered the official MIME Type for JSON as application/json.When asked about why not text/json, Crockford seems to have said JSON is not really JavaScript nor text and also IANA was more likely to hand out application/* than text/*.More resources:",
                "For JSON:For JSON-P:",
                "Of course, the correct MIME media type for JSON is application/json, but it's necessary to realize what type of data is expected in your application.For example, I use Ext GWT and the server response must go as text/html but contains JSON data.Client side, Ext GWT form listenerIn case of using application/json response type, the browser suggests me to save the file.Server side source code snippet using Spring MVC",
                "Response is dynamically generated data, according to the query parameters passed in the URL.Example:Content-Type: application/jsonJSON with padding.\nResponse is JSON data, with a function call wrapped around it.Example:Content-Type: application/javascript",
                "If you are using Ubuntu or Debian and you serve .json files through Apache, you might want to serve the files with the correct content type. I am doing this primarily because I want to use the Firefox extension JSONViewThe Apache module mod_mime will help to do this easily. However, with Ubuntu you need to edit the file /etc/mime.types and add the lineThen restart Apache:",
                "If you're calling ASP.NET Web Services from the client-side you have to use application/json for it to work. I believe this is the same for the jQuery and Ext frameworks.",
                "The right content type for JSON is application/json UNLESS you're using JSONP, also known as JSON with Padding, which is actually JavaScript and so the right content type would be application/javascript.",
                "There is no doubt that application/json is the best MIME type for a JSON response.But I had some experience where I had to use application/x-javascript because of some compression issues. My hosting environment is shared hosting with GoDaddy. They do not allow me to change server configurations. I had added the following code to my web.config file for compressing responses.By using this, the .aspx pages was compressed with g-zip but JSON responses were not. I addedin the static and dynamic types sections. But this does not compress JSON responses at all.After that I removed this newly added type and addedin both the static and dynamic types sections, and changed the response type in.ashx (asynchronous handler) toAnd now I found that my JSON responses were compressed with g-zip. So I personally recommend to useonly if you want to compress your JSON responses on a shared hosting environment. Because in shared hosting, they do not allow you to change IIS configurations.",
                "Only when using application/json as the MIME type I have the following (as of November 2011 with the most recent versions of Chrome, Firefox with Firebug):",
                "Not everything works for content type application/json.If you are using Ext\u00a0JS form submit to upload file, be aware that the server response is parsed by the browser to create the document for the <iframe>.If the server is using JSON to send the return object, then the Content-Type header must be set to text/html in order to tell the browser to insert the text unchanged into the document body.See the Ext JS 3.4.0 API documentation.",
                "JSON is a domain-specific language (DSL) and a data format independent of JavaScript, and as such has its own MIME type, application/json. Respect for MIME types is of course client driven, so text/plain may do for transfer of bytes, but then you would be pushing up interpretation to the vendor application domain unnecessarily - application/json. Would you transfer XML via text/plain?But honestly, your choice of MIME type is advice to the client as to how to interpret the data- text/plain or text/HTML (when it's not HTML) is like type erasure- it's as uninformative as making all your objects of type Object in a typed language.No browser runtime I know of will take a JSON document and automatically make it available to the runtime as a JavaScript accessible object without intervention, but if you are working with a crippled client, that's an entirely different matter. But that's not the whole story- RESTful JSON services often don't have JavaScript runtimes, but it doesn't stop them using JSON as a viable data interchange format. If clients are that crippled... then I would consider perhaps HTML injection via an Ajax templating service instead.Application/JSON!",
                "If you're in a client-side environment, investigating about the cross-browser support is mandatory for a well supported web application.The right HTTP Content-Type would be application/json, as others already highlighted too, but some clients do not handle it very well, that's why jQuery recommends the default text/html.",
                "The correct answer is:",
                "As many others have mentioned, application/json is the correct answer.But what haven't been explained yet is what the other options you proposed mean.application/x-javascript: Experimental MIME type for JavaScript before application/javascript was made standard.text/javascript: Now obsolete. You should use application/javascript when using javascript.text/x-javascript: Experimental MIME type for the above situation.text/x-json: Experimental MIME type for JSON before application/json got officially registered.All in all, whenever you have any doubts about content types, you should check this link",
                "In JSP, you can use this in page directive:The correct MIME media type for JSON is application/json.  JSP will use it for sending a response to the client.",
                "\u201capplication/json\u201d is the correct JSON content type.",
                "The IANA registration for application/json saysApplications that use this media type:  JSON has been used to\n     exchange data between applications written in all of these\n     programming languages: ActionScript, C, C#, Clojure, ColdFusion,\n     Common Lisp, E, Erlang, Go, Java, JavaScript, Lua, Objective CAML,\n     Perl, PHP, Python, Rebol, Ruby, Scala, and Scheme.You'll notice that IANA.org doesn't list any of these other media types, in fact even application/javascript is now obsolete. So application/json is really the only possible correct answer.Browser support is another thing.The most widely supported non-standard media types are text/json or text/javascript. But some big names even use text/plain.Even more strange is the Content-Type header sent by Flickr, who returns JSON as text/xml. Google uses text/javascript for some of it's ajax apis.Examples:Output: Content-Type: text/javascriptOutput: Content-Type: text/xml",
                "The right MIME type is application/jsonBUTI experienced many situations where the browser type or the framework user needed:",
                "I use the below",
                "The Content-Type header should be set to 'application/json' when posting. Server listening for the request should include \"Accept=application/json\".\nIn Spring MVC you can do it like this:Add headers to the response:",
                "The application/json works great in PHP to store an array or object\n  data.I use this code to put data in JSON on Google Cloud Storage (GCS) which is set publically viewable:To get back the data is straight forward:",
                "In Spring you have a defined type: MediaType.APPLICATION_JSON_VALUE which is equivalent to application/json.",
                "For JSON, I am using:This is described in the IETF's JSON Data Interchange Format 7158 proposal, Section 1.2: Specifications of JSON.",
                "If the JSON is with padding then it will be application/jsonp. If the JSON is without padding then it will be application/json.To deal with both, it is a good practice to use: 'application/javascript' without bothering whether it is with padding or without padding.",
                "Extending the accepted responses, when you are using JSON in a REST context...There is a strong argument about using application/x-resource+json and application/x-collection+json when you are representing REST resources and collections.And if you decide to follow the jsonapi specification, you should use of application/vnd.api+json, as it is documented.Altough there is not an universal standard, it is clear that the added semantic to the resources being transfered justify a more explicit Content-Type than just application/json.Following this reasoning, other contexts could justify a more specific Content-Type.",
                "If you get data from REST API in JSON, you have to use Content-Type:",
                "PHP developers use this:",
                "JSON (JavaScript Object Notation) and JSONP (\"JSON with padding\") formats seems to be very similar and therefore it might be very confusing which MIME type they should be using. Even though the formats are similar, there are some subtle differences between them.So whenever in any doubts, I have a very simple approach (which works perfectly fine in most cases), namely, go and check corresponding RFC document.JSON\nRFC 4627 (The application/json Media Type for JavaScript Object Notation (JSON)) is a specifications of JSON format. It says in section 6, that the MIME media type for JSON text isJSONP\nJSONP (\"JSON with padding\") is handled different way than JSON, in a browser. JSONP is treated as a regular JavaScript script and therefore it should use application/javascript, the current official MIME type for JavaScript. In many cases, however, text/javascript MIME type will work fine too.Note that text/javascript has been marked as obsolete by RFC 4329 (Scripting Media Types) document and it is recommended to use application/javascript type instead. However, due to legacy reasons, text/javascript is still widely used and it has cross-browser support (which is not always a case with application/javascript MIME type, especially with older browsers)."
            ]
        },
        {
            "tag": "javascript",
            "question": [
                "How can I remove a specific item from an array?",
                "How do I remove a specific value from an array? Something like:\narray.remove(value);\n\nI have to use core JavaScript. Frameworks are not allowed."
            ],
            "url": "https://stackoverflow.com/questions/5767325",
            "answer": [
                "Find the index of the array element you want to remove using indexOf, and then remove that index with splice.The splice() method changes the contents of an array by removing\nexisting elements and/or adding new elements.const array = [2, 5, 9];\n\nconsole.log(array);\n\nconst index = array.indexOf(5);\nif (index > -1) { // only splice array when item is found\n  array.splice(index, 1); // 2nd parameter means remove one item only\n}\n\n// array = [2, 9]\nconsole.log(array);The second parameter of splice is the number of elements to remove. Note that splice modifies the array in place and returns a new array containing the elements that have been removed.For the reason of completeness, here are functions. The first function removes only a single occurrence (i.e. removing the first match of 5 from [2,5,9,1,5,8,5]), while the second function removes all occurrences:function removeItemOnce(arr, value) {\n  var index = arr.indexOf(value);\n  if (index > -1) {\n    arr.splice(index, 1);\n  }\n  return arr;\n}\n\nfunction removeItemAll(arr, value) {\n  var i = 0;\n  while (i < arr.length) {\n    if (arr[i] === value) {\n      arr.splice(i, 1);\n    } else {\n      ++i;\n    }\n  }\n  return arr;\n}\n// Usage\nconsole.log(removeItemOnce([2,5,9,1,5,8,5], 5))\nconsole.log(removeItemAll([2,5,9,1,5,8,5], 5))In TypeScript, these functions can stay type-safe with a type parameter:",
                "Edited on 2016 OctoberIn this code example I use array.filter(...) function to remove unwanted items from an array. This function doesn't change the original array and creates a new one. If your browser doesn't support this function (e.g. Internet Explorer before version 9, or Firefox before version 1.5), consider polyfilling with core-js.IMPORTANT ECMAScript 6 () => {} arrow function syntax is not supported in Internet Explorer at all, Chrome before version 45, Firefox before version 22, and Safari before version 10. To use ECMAScript 6 syntax in old browsers you can use BabelJS.An additional advantage of this method is that you can remove multiple itemsIMPORTANT array.includes(...) function is not supported in Internet Explorer at all, Chrome before version 47, Firefox before version 43, Safari before version 9, and Edge before version 14 but you can polyfill with core-js.If the \"This-Binding Syntax\" proposal is ever accepted, you'll be able to do this:Try it yourself in BabelJS :)Reference",
                "I don't know how you are expecting array.remove(int) to behave. There are three possibilities I can think of that you might want.To remove an element of an array at an index i:If you want to remove every element with value number from the array:If you just want to make the element at index i no longer exist, but you don't want the indexes of the other elements to change:",
                "It depends on whether you want to keep an empty spot or not.If you do want an empty slot:If you don't want an empty slot:And if you need the value of that item, you can just store the returned array's element:If you want to remove at either end of the array, you can use array.pop() for the last one or array.shift() for the first one (both return the value of the item as well).If you don't know the index of the item, you can use array.indexOf(item) to get it (in a if() to get one item or in a while() to get all of them). array.indexOf(item) returns either the index or -1 if not found.",
                "A friend was having issues in Internet\u00a0Explorer\u00a08 and showed me what he did. I told him it was wrong, and he told me he got the answer here. The current top answer will not work in all browsers (Internet\u00a0Explorer\u00a08 for example), and it will only remove the first occurrence of the item.It loops through the array backwards (since indices and length will change as items are removed) and removes the item if it's found. It works in all browsers.",
                "There are two major approachessplice(): anArray.splice(index, 1);delete: delete anArray[index];Be careful when you use the delete for an array. It is good for deleting attributes of objects, but not so good for arrays. It is better to use splice for arrays.Keep in mind that when you use delete for an array you could get wrong results for anArray.length. In other words, delete would remove the element, but it wouldn't update the value of the length property.You can also expect to have holes in index numbers after using delete, e.g. you could end up with having indexes 1, 3, 4, 8, 9, and 11 and length as it was before using delete. In that case, all indexed for loops would crash, since indexes are no longer sequential.If you are forced to use delete for some reason, then you should use for each loops when you need to loop through arrays. As the matter of fact, always avoid using indexed for loops, if possible. That way the code would be more robust and less prone to problems with indexes.",
                "Array.prototype.removeByValue = function (val) {\n  for (var i = 0; i < this.length; i++) {\n    if (this[i] === val) {\n      this.splice(i, 1);\n      i--;\n    }\n  }\n  return this;\n}\n\nvar fruits = ['apple', 'banana', 'carrot', 'orange'];\nfruits.removeByValue('banana');\n\nconsole.log(fruits);\n// -> ['apple', 'carrot', 'orange']",
                "There isn't any need to use indexOf or splice. However, it performs better if you only want to remove one occurrence of an element.Find and move (move):Use indexOf and splice (indexof):Use only splice (splice):Run-times on Node.js for an array with 1000 elements (averaged over 10,000 runs):indexof is approximately 10 times slower than move. Even if improved by removing the call to indexOf in splice, it performs much worse than move.",
                "This provides a predicate instead of a value.NOTE: it will update the given array, and return the affected rows.",
                "You can do it easily with the filter method:function remove(arrOriginal, elementToRemove){\n    return arrOriginal.filter(function(el){return el !== elementToRemove});\n}\nconsole.log(remove([1, 2, 1, 0, 3, 1, 4], 1));This removes all elements from the array and also works faster than a combination of slice and indexOf.",
                "John Resig posted a good implementation:If you don\u2019t want to extend a global object, you can do something like the following, instead:But the main reason I am posting this is to warn users against the alternative implementation suggested in the comments on that page (Dec 14, 2007):It seems to work well at first, but through a painful process I discovered it fails when trying to remove the second to last element in an array. For example, if you have a 10-element array and you try to remove the 9th element with this:You end up with an 8-element array. I don't know why, but I confirmed John's original implementation doesn't have this problem.",
                "You can use ES6. For example to delete the value '3' in this case:Output :",
                "Underscore.js can be used to solve issues with multiple browsers. It uses in-build browser methods if present. If they are absent like in the case of older Internet\u00a0Explorer versions it uses its own custom methods.A simple example to remove elements from array (from the website):",
                "Using filter is an elegant way to achieve this requirement.\nfilter will not mutate the original array.const num = 3;\nlet arr = [1, 2, 3, 4];\nconst arr2 = arr.filter(x => x !== num);\nconsole.log(arr); // [1, 2, 3, 4]\nconsole.log(arr2); // [1, 2, 4]You can use filter and then assign the result to the original array if you want to achieve a mutation removal behaviour.const num = 3;\nlet arr = [1, 2, 3, 4];\narr = arr.filter(x => x !== num);\nconsole.log(arr); // [1, 2, 4]By the way, filter will remove all of the occurrences matched in the condition (not just the first occurrence) like you can see in the following exampleconst num = 3;\nlet arr = [1, 2, 3, 3, 3, 4];\narr = arr.filter(x => x !== num);\nconsole.log(arr); // [1, 2, 4]In case, you just want to remove the first occurrence, you can use the splice methodconst num = 3;\nlet arr = [1, 2, 3, 3, 3, 4];\narr.splice(arr.indexOf(num), 1);\nconsole.log(arr); // [1, 2, 3, 3, 4]",
                "Here are a few ways to remove an item from an array using JavaScript.All the method described do not mutate the original array, and instead create a new one.Suppose you have an array, and you want to remove an item in position i.One method is to use slice():const items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst i = 3\nconst filteredItems = items.slice(0, i).concat(items.slice(i+1, items.length))\n\nconsole.log(filteredItems)slice() creates a new array with the indexes it receives. We simply create a new array, from start to the index we want to remove, and concatenate another array from the first position following the one we removed to the end of the array.In this case, one good option is to use filter(), which offers a more declarative approach:const items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst valueToRemove = 'c'\nconst filteredItems = items.filter(item => item !== valueToRemove)\n\nconsole.log(filteredItems)This uses the ES6 arrow functions. You can use the traditional functions to support older browsers:const items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst valueToRemove = 'c'\nconst filteredItems = items.filter(function(item) {\n  return item !== valueToRemove\n})\n\nconsole.log(filteredItems)or you can use Babel and transpile the ES6 code back to ES5 to make it more digestible to old browsers, yet write modern JavaScript in your code.What if instead of a single item, you want to remove many items?Let's find the simplest solution.You can just create a function and remove items in series:const items = ['a', 'b', 'c', 'd', 'e', 'f']\n\nconst removeItem = (items, i) =>\n  items.slice(0, i-1).concat(items.slice(i, items.length))\n\nlet filteredItems = removeItem(items, 3)\nfilteredItems = removeItem(filteredItems, 5)\n//[\"a\", \"b\", \"c\", \"d\"]\n\nconsole.log(filteredItems)You can search for inclusion inside the callback function:const items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst valuesToRemove = ['c', 'd']\nconst filteredItems = items.filter(item => !valuesToRemove.includes(item))\n//\u00a0[\"a\", \"b\", \"e\", \"f\"]\n\nconsole.log(filteredItems)splice() (not to be confused with slice()) mutates the original array, and should be avoided.(originally posted on my site https://flaviocopes.com/how-to-remove-item-from-array/)",
                "If you want a new array with the deleted positions removed, you can always delete the specific element and filter out the array. It might need an extension of the array object for browsers that don't implement the filter method, but in the long term it's easier since all you do is this:It should display [1, 2, 3, 4, 6].",
                "Check out this code. It works in every major browser.remove_item = function(arr, value) {\n var b = '';\n for (b in arr) {\n  if (arr[b] === value) {\n   arr.splice(b, 1);\n   break;\n  }\n }\n return arr;\n};\n\nvar array = [1,3,5,6,5,9,5,3,55]\nvar res = remove_item(array,5);\nconsole.log(res)",
                "Removing a particular element/string from an array can be done in a one-liner:where:theArray: the array you want to remove something particular fromstringToRemoveFromArray: the string you want to be removed and 1 is the number of elements you want to remove.NOTE: If \"stringToRemoveFromArray\" is not located in the array, this will remove the last element of the array.It's always good practice to check if the element exists in your array first, before removing it.Depending if you have newer or older version of Ecmascript running on your client's computers:ORWhere '3' is the value you want to be removed from the array.\nThe array would then become : ['1','2','4','5','6']",
                "This post summarizes common approaches to element removal from an array as of ECMAScript 2019 (ES10).| In-place: Yes | \n| Removes duplicates: Yes(loop), No(indexOf) | \n| By value / index: By index |If you know the value you want to remove from an array you can use the splice method. First, you must identify the index of the target item. You then use the index as the start element and remove just one element.| In-place: No | \n| Removes duplicates: Yes | \n| By value / index: By value |The specific element can be filtered out from the array, by providing a filtering function. Such function is then called for every element in the array.| In-place: Yes/No (Depends on implementation) | \n| Removes duplicates: Yes/No (Depends on implementation) | \n| By value / index: By index / By value (Depends on implementation) |The prototype of Array can be extended with additional methods. Such methods will be then available to use on created arrays.Note: Extending prototypes of objects from the standard library of JavaScript (like Array) is considered by some as an antipattern.| In-place: Yes | \n| Removes duplicates: No | \n| By value / index: By index |Using the delete operator does not affect the length property. Nor does it affect the indexes of subsequent elements. The array becomes sparse, which is a fancy way of saying the deleted item is not removed but becomes undefined.The delete operator is designed to remove properties from JavaScript objects, which arrays are objects.| In-place: No | \n| Removes duplicates: Yes | \n| By value / index: By value |ES10 introduced Object.fromEntries, which can be used to create the desired Array from any Array-like object and filter unwanted elements during the process.| In-place: Yes | \n| Removes duplicates: No | \n| By value / index: N/A |JavaScript Array elements can be removed from the end of an array by setting the length property to a value less than the current value. Any element whose index is greater than or equal to the new length will be removed.| In-place: Yes | \n| Removes duplicates: No | \n| By value / index: N/A |The pop method removes the last element of the array, returns that element, and updates the length property. The pop method modifies the array on which it is invoked, This means unlike using delete the last element is removed completely and the array length reduced.| In-place: Yes | \n| Removes duplicates: No | \n| By value / index: N/A |The .shift() method works much like the pop method except it removes the first element of a JavaScript array instead of the last. When the element is removed the remaining elements are shifted down.| In-place: Yes | \n| Removes duplicates: N/A | \n| By value / index: N/A |The fastest technique is to set an array variable to an empty array.Alternatively technique from 2.1.1 can be used by setting length to 0.",
                "You can use lodash _.pull (mutate array), _.pullAt (mutate array) or _.without (does't mutate array),",
                "ES6 & without mutation:  (October 2016)const removeByIndex = (list, index) =>\r\n      [\r\n        ...list.slice(0, index),\r\n        ...list.slice(index + 1)\r\n      ];\r\n         \r\noutput = removeByIndex([33,22,11,44],1) //=> [33,11,44]\r\n      \r\nconsole.log(output)",
                "Today (2019-12-09) I conduct performance tests on macOS v10.13.6 (High Sierra) for chosen solutions. I show delete (A), but I do not use it in comparison with other methods, because it left empty space in the array.The conclusionsIn tests, I remove the middle element from the array in different ways. The A, C solutions are in-place. The B, D, E, F, G, H solutions are immutable.Results for an array with 10 elementsIn Chrome the array.splice (C) is the fastest in-place solution. The array.filter (D) is the fastest immutable solution. The slowest is array.slice (F). You can perform the test on your machine here.Results for an array with 1.000.000 elementsIn Chrome the array.splice (C) is the fastest in-place solution (the delete (C) is similar fast - but it left an empty slot in the array (so it does not perform a 'full remove')). The array.slice-splice (H) is the fastest immutable solution. The slowest is array.filter (D and E). You can perform the test on your machine here.var a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];\nvar log = (letter,array) => console.log(letter, array.join `,`);\n\nfunction A(array) {\n  var index = array.indexOf(5);\n  delete array[index];\n  log('A', array);\n}\n\nfunction B(array) {\n  var index = array.indexOf(5);\n  var arr = Array.from(array);\n  arr.splice(index, 1)\n  log('B', arr);\n}\n\nfunction C(array) {\n  var index = array.indexOf(5);\n  array.splice(index, 1);\n  log('C', array);\n}\n\nfunction D(array) {\n  var arr = array.filter(item => item !== 5)\n  log('D', arr);\n}\n\nfunction E(array) {\n  var index = array.indexOf(5);\n  var arr = array.filter((item, i) => i !== index)\n  log('E', arr);\n}\n\nfunction F(array) {\n  var index = array.indexOf(5);\n  var arr = array.slice(0, index).concat(array.slice(index + 1))\n  log('F', arr);\n}\n\nfunction G(array) {\n  var index = array.indexOf(5);\n  var arr = [...array.slice(0, index), ...array.slice(index + 1)]\n  log('G', arr);\n}\n\nfunction H(array) {\n  var index = array.indexOf(5);\n  var arr = array.slice(0);\n  arr.splice(index, 1);\n  log('H', arr);\n}\n\nA([...a]);\nB([...a]);\nC([...a]);\nD([...a]);\nE([...a]);\nF([...a]);\nG([...a]);\nH([...a]);\nThis snippet only presents code used in performance tests - it does not perform tests itself.Comparison for browsers: Chrome v78.0.0, Safari v13.0.4, and Firefox v71.0.0",
                "OK, for example you have the array below:And we want to delete number 4. You can simply use the below code:If you are reusing this function, you write a reusable function which will be attached to the native array function like below:But how about if you have the below array instead with a few [5]s in the array?We need a loop to check them all, but an easier and more efficient way is using built-in JavaScript functions, so we write a function which use a filter like below instead:Also there are third-party libraries which do help you to do this, like Lodash or Underscore. For more information, look at lodash _.pull, _.pullAt or _.without.",
                "I'm pretty new to JavaScript and needed this functionality. I merely wrote this:Then when I want to use it:Output - As expected.\n[\"item1\", \"item1\"]You may have different needs than I, so you can easily modify it to suit them. I hope this helps someone.",
                "I want to answer based on ECMAScript\u00a06. Assume you have an array like below:If you want to delete at a special index like 2, write the below code:But if you want to delete a special item like 3 and you don't know its index, do like below:Hint: please use an arrow function for filter callback unless you will get an empty array.",
                "If you have complex objects in the array you can use filters? \nIn situations where $.inArray or array.splice is not as easy to use. Especially if the objects are perhaps shallow in the array.E.g. if you have an object with an Id field and you want the object removed from an array:",
                "Update: This method is recommended only if you cannot use ECMAScript 2015 (formerly known as ES6). If you can use it, other answers here provide much neater implementations.This gist here will solve your problem, and also deletes all occurrences of the argument instead of just 1 (or a specified value).Usage:",
                "You should never mutate your array as this is against the functional programming pattern. You can create a new array without referencing the one you want to change data of using the ECMAScript\u00a06 method filter;Suppose you want to remove 5 from the array, you can simply do it like this:This will give you a new array without the value you wanted to remove. So the result will be:For further understanding you can read the MDN documentation on Array.filter.",
                "A more modern, ECMAScript 2015 (formerly known as Harmony or ES 6) approach. Given:Then:Yielding:You can use Babel and a polyfill service to ensure this is well supported across browsers.",
                "You can do a backward loop to make sure not to screw up the indexes, if there are multiple instances of the element.var myElement = \"chocolate\";\nvar myArray = ['chocolate', 'poptart', 'poptart', 'poptart', 'chocolate', 'poptart', 'poptart', 'chocolate'];\n\n/* Important code */\nfor (var i = myArray.length - 1; i >= 0; i--) {\n  if (myArray[i] == myElement) myArray.splice(i, 1);\n}\nconsole.log(myArray);"
            ]
        },
        {
            "tag": "git",
            "question": [
                "How do I rename a local Git branch?",
                "How do I rename a local branch which has not yet been pushed to a remote repository?\nRelated:\n\nRename master branch for both local and remote Git repositories\nHow do I rename both a Git local and ..."
            ],
            "url": "https://stackoverflow.com/questions/6591213",
            "answer": [
                "To rename the current branch:To rename a branch while pointed to any branch:-m is short for --move.To push the  local branch and reset the upstream branch:To delete the  remote branch:To create a git rename alias:On Windows or another case-insensitive filesystem, use -M if there are only capitalization changes in the name. Otherwise, Git will throw a \"branch already exists\" error.",
                "The above command will change your branch name, but you have to be very careful using the renamed branch, because it will still refer to the old upstream branch associated with it, if any.If you want to push some changes into master after your local branch is renamed into new_branch_name (example name):git push origin new_branch_name:master (now changes will go to master branch but your local branch name is new_branch_name)For more details, see \"How to rename your local branch name in Git.\"",
                "To rename your current branch:",
                "Here are the steps to rename the branch:EDIT (12/01/2017): Make sure you run command git status and check that the newly created branch is pointing to its own ref and not the older one. If you find the reference to the older branch, you need to unset the upstream using:",
                "Rename the branch will be useful once your branch is finished. Then new stuff is coming, and you want to develop in the same branch instead of deleting it and create the new one.From my experience, to rename a local and remote branch in Git you should do the following steps.Quoting from Multiple States - Rename a local and remote branch in\n  gitIf you are on the branch you want to rename:If you are on a different branch:",
                "The answers so far have been correct, but here is some additional information:One can safely rename a branch with '-m' (move), but one has to be careful with '-M', because it forces the rename, even if there is an existing branch with the same name already. Here is the excerpt from the 'git-branch' man page:With a -m or -M option, <oldbranch> will be renamed to <newbranch>. If <oldbranch> had a corresponding reflog, it is renamed to match <newbranch>, and a reflog entry is created to remember the branch renaming. If <newbranch> exists, -M must be used to force the rename to happen.",
                "If it is your current branch, just doIf it is another branch you want to rename- If your branch was pushed, then after renaming you need to delete it from the remote Git repository and ask your new local to track a new remote branch:",
                "I foolishly named a branch starting with a hyphen, and then checked out master.  I didn't want to delete my branch, I had work in it.Neither of these worked:git checkout -dumb-namegit checkout -- -dumb-name\"s, 's and \\s didn't help either.  git branch -m doesn't work.Here's how I finally fixed it. Go into your working copy's .git/refs/heads, find the filename \"-dumb-name\", get the hash of the branch.  Then this will check it out, make a new branch with a sane name, and delete the old one.",
                "Just three steps to replicate change in name on remote as well as on GitHub:Step 1 git branch -m old_branchname new_branchnameStep 2 git push origin :old_branchname new_branchnameStep 3 git push --set-upstream origin new_branchname",
                "To rename a branch locally:Now you'll have to propagate these changes on your remote server as well.To push changes of the deleted old branch:To push changes of creation of new branch:",
                "Trying to answer specifically the question (at least the title).You can also rename the local branch, but keep tracking the old name on the remote.Now, when you run git push, the remote old_branch ref is updated with your local new_branch.You have to know and remember this configuration. But it can be useful if you don't have the choice for the remote branch name, but you don't like it (oh, I mean, you've got a very good reason not to like it !) and prefer a clearer name for your local branch.Playing with the fetch configuration, you can even rename the local remote-reference. i.e, having a refs/remote/origin/new_branch ref pointer to the branch, that is in fact the old_branch on origin. However, I highly discourage this, for the safety of your mind.",
                "Update 2022Before we begin, make sure you\u2019ve selected the branch you want to rename:If you want to see all of your local branches, use the following command:When you\u2019re all clear, follow these steps:Using the Git rename branch command will require you to add an -m option to your command:You can also rename a local branch from another branch by using the following two commands:Lastly, this command will list all \u2014 both local and remote \u2014 branches to verify that it has been renamed:Although it isn\u2019t possible to rename a remote branch directly, the process of renaming one involves these two easy steps:To start, you will need to rename a local branch by following the previous steps.\n2.Then delete the old branch and push the new one. You can do this easily with the following command:Reset the upstream branch for your new local branch, and you will be all set:",
                "Rename the branch using this command:-m: It renames/moves the branch. If there is already a branch, you will get an error.If there is already a branch and you want to rename with that branch, use:For more information about help, use this command in the terminal:or",
                "Advanced Git users can rename manually using:",
                "If you are on the branch you want to rename:If you are on a different branch:git push origin :old-name new-namegit push origin -u new-nameOr for a fast way to do that, you can use these 3 steps:# Rename branch locally# Delete the old remote branch# Push the new branch, set local branch to track the new remoteReferance: https://www.w3docs.com/snippets/git/how-to-rename-git-local-and-remote-branches.html",
                "Here are three steps: A command that you can call inside your terminal and change branch name.If you need more: step-by-step, How To Change Git Branch Name is a good article about that.",
                "Probably as mentioned by others, this will be a case mismatch in branch naming.If you have such a situation, I can guess that you're on Windows which will also lead you to:Then you have to do an intermediate step:Nothing more.",
                "Changing the branch locally is quite easy...If you are on the branch you want to change the name for, simply do this:Otherwise, if you are on master or any other branch other than the one you'd like to change the name, simply do:Also, I create the image below to show this in action on a command line. In this case, you are on master branch, for example:",
                "To rename the current branch (except for detached HEAD state) you can also use this alias:",
                "Since you do not want to push the branch to a remote server, this example will be useful:Let's say you have an existing branch called \"my-hot-feature,\" and you want to rename it to \"feature-15.\"First, you want to change your local branch. This couldn't be easier:For more information, you can visit Locally and Remotely Renaming a Branch in Git.",
                "If you are willing to use SourceTree (which I strongly recommend), you can right click your branch and chose 'Rename'.",
                "This will set the new name for the current branch you are working with.Here you have to provide the old branch name and the new branch name.",
                "Another option is not to use the command line at all. Git GUI clients such as SourceTree take away much of the syntactical learning curve / pain that causes questions such as this one to be amongst the most viewed on Stack Overflow.In SourceTree, right click on any local branch in the \"Branches\" pane on the left and select \"Rename ...\".",
                "A simple way to do it:For more, see this.",
                "Git version 2.9.2If you want to change the name of the local branch you are on:If you want to change the name of a different branch:If you want to change the name of a different branch to a name that already exists:Note: The last command is destructive and will rename your branch, but you will lose the old branch with that name and those commits because branch names must be unique.",
                "If you want to change the name of the current branch, run:If you want to delete the old remote branch, run:If you want to delete the old remote branch and create a new remote branch, run:",
                "Actually you have three steps because the local branch has a duplicate on the server so we have one step for local on two steps on the server:",
                "Git branch rename can be done by using:git branch -m oldBranch newBranchgit branch -M oldBranch ExistingBranchThe difference between -m and -M:-m: if you're trying to rename your branch with an existing branch name using -m.\nIt will raise an error saying that the branch already exists. You need to give unique name.But,-M: this will help you to force rename with a given name, even it is exists. So an existing branch will overwrite entirely with it...Here is a Git terminal example,",
                "All of the previous answers are talking about git branch -m. Of course, it's easy to operate, but for me, it may be a little hard to remember another Git command. So I tried to get the work done by the command I was familiar with. Yeah, you may guessed it.I use git branch -b <new_branch_name>. And if you don't want to save the old branch now you can execute git branch -D <old_branch_name> to remove it.I know it may be a little tedious, but it's easier to understand and remember. I hope it\u2018s helpful for you.",
                "For Git GUI users it couldn't be much simpler.\nIn Git GUI, choose the branch name from the drop down list in the \"Rename Branch\" dialog box created from the menu item Branch:Rename, type a New Name, and click \"Rename\". I have highlighted where to find the drop down list."
            ]
        },
        {
            "tag": "git",
            "question": [
                "How do I undo 'git add' before commit?",
                "I mistakenly added files to Git using the command:\ngit add myfile.txt\n\nI have not yet run git commit. How do I undo this so that these changes will not be included in the commit?"
            ],
            "url": "https://stackoverflow.com/questions/348170",
            "answer": [
                "Undo git add for uncommitted changes with:That will remove the file from the current index (the \"about to be committed\" list) without changing anything else.To unstage all changes for all files:In old versions of Git, the above commands are equivalent to git reset HEAD <file> and git reset HEAD respectively, and will fail if HEAD is undefined (because you haven't yet made any commits in your repository) or ambiguous (because you created a branch called HEAD, which is a stupid thing that you shouldn't do). This was changed in Git 1.8.2, though, so in modern versions of Git you can use the commands above even prior to making your first commit:\"git reset\" (without options or parameters) used to error out when\nyou do not have any commits in your history, but it now gives you\nan empty index (to match non-existent commit you are not even on).Documentation: git reset",
                "You want:Reasoning:When I was new to this, I first tried(to undo my entire initial add), only to get this (not so) helpful message:It turns out that this is because the HEAD ref (branch?) doesn't exist until after the first commit. That is, you'll run into the same beginner's problem as me if your workflow, like mine, was something like:git status... lots of crap scrolls by ...=> Damn, I didn't want to add all of that.google \"undo git add\"=> find Stack Overflow - yaygit reset .=>    fatal: Failed to resolve 'HEAD' as a valid ref.It further turns out that there's a bug logged against the unhelpfulness of this in the mailing list.And that the correct solution was right there in the Git status output (which, yes, I glossed over as 'crap)And the solution indeed is to use git rm --cached FILE.Note the warnings elsewhere here - git rm deletes your local working copy of the file, but not if you use --cached.  Here's the result of git help rm:--cached\n      Use this option to unstage and remove paths only from the index.\n      Working tree files, whether modified or not, will be left.I proceed to useto remove everything and start again. Didn't work though, because while add . is recursive, turns out rm needs -r to recurse. Sigh.Okay, now I'm back to where I started. Next time I'm going to use -n to do a dry run and see what will be added:I zipped up everything to a safe place before trusting git help rm about the --cached not destroying anything (and what if I misspelled it).",
                "If you type:Git will tell you what is staged, etc., including instructions on how to unstage:I find Git does a pretty good job of nudging me to do the right thing in situations like this.Note: Recent Git versions (1.8.4.x) have changed this message:",
                "To clarify: git add moves changes from the current working directory to the staging area (index).This process is called staging. So the most natural command to stage the changes (changed files) is the obvious one:git add is just an easier-to-type alias for git stagePity there is no git unstage nor git unadd commands. The relevant one is harder to guess or remember, but it is pretty obvious:We can easily create an alias for this:And finally, we have new commands:Personally I use even shorter aliases:",
                "An addition to the accepted answer, if your mistakenly-added file was huge, you'll probably notice that, even after removing it from the index with 'git reset', it still seems to occupy space in the .git directory.This is nothing to be worried about; the file is indeed still in the repository, but only as a \"loose object\". It will not be copied to other repositories (via clone, push), and the space will be eventually reclaimed - though perhaps not very soon. If you are anxious, you can run:Update (what follows is my attempt to clear some confusion that can arise from the most upvoted answers):So, which is the real undo of git add?git reset HEAD <file> ?orgit rm --cached <file>?Strictly speaking, and if I'm not mistaken: none.git add cannot be undone - safely, in general.Let's recall first what git add <file> actually does:If <file> was not previously tracked, git add adds it to the cache, with its current content.If <file> was already tracked, git add saves the current content (snapshot, version) to the cache. In Git, this action is still called add, (not mere update it), because two different versions (snapshots) of a file are regarded as two different items: hence, we are indeed adding a new item to the cache, to be eventually committed later.In light of this, the question is slightly ambiguous:I mistakenly added files using the command...The OP's scenario seems to be the first one (untracked file),  we want the \"undo\" to remove the file (not just the current contents) from the tracked items. If this is the case, then it's ok to run  git rm --cached <file>.And we could also run git reset HEAD <file>. This is in general preferable, because it works in both scenarios: it also does the undo when we wrongly added a version of an already tracked item.But there are two caveats.First: There is (as pointed out in the answer) only one scenario in which git reset HEAD doesn't work, but git rm --cached does: a new repository (no commits). But, really, this a practically irrelevant case.Second: Be aware that git reset HEAD  can't magically recover the previously cached file contents, it just resynchronises it from the HEAD. If our misguided git add overwrote a previous staged uncommitted version, we can't recover it. That's why, strictly speaking, we cannot undo [*].Example:Of course, this is not very critical if we just follow the usual lazy workflow of doing 'git add' only for adding new files (case 1), and we update new contents via the commit, git commit -a command.* (Edit: the above is practically correct, but still there can be some slightly hackish/convoluted ways for recovering changes that were staged, but not committed and then overwritten - see the comments by Johannes Matokic and iolsmit)",
                "Undo a file which has already been added is quite easy using Git. For resetting myfile.txt, which have already been added, use:Explanation:After you staged unwanted file(s), to undo, you can do git reset. Head is head of your file in the local and the last parameter is the name of your file.I have created the steps in the image below in more details for you, including all steps which may happen in these cases:",
                "will \"un-add\" everything you've added from your current directory recursively",
                "Git has commands for every action imaginable, but it needs extensive knowledge to get things right and because of that it is counter-intuitive at best...What you did before:What you want:Remove the file from the index, but keep it versioned and left with uncommitted changes in working copy:Reset the file to the last state from HEAD, undoing changes and removing them from the index:This is needed since git reset --hard HEAD won't work with single files.Remove <file> from index and versioning, keeping the un-versioned file with changes in working copy:Remove <file> from working copy and versioning completely:",
                "Runand remove all the files manually or by selecting all of them and clicking on the unstage from commit button.",
                "The question is not clearly posed. The reason is that git add has two meanings:If in doubt, useBecause it does the expected thing in both cases.Warning: if you do git rm --cached file on a file that was modified (a file that existed before in the repository), then the file will be removed on git commit! It will still exist in your file system, but if anybody else pulls your commit, the file will be deleted from their work tree.git status will tell you if the file was a new file or modified:",
                "As per many of the other answers, you can use git resetBUT:I found this great little post that actually adds the Git command (well, an alias) for git unadd: see git unadd for details or..Simply,Now you canAlternatively / directly:",
                "will remove a file named filename.txt from the current index (also called the \u201cstaging area\u201d, which is where changes \u201cabout to be committed\u201d are saved), without changing anything else (the working directory is not overwritten).",
                "If you're on your initial commit and you can't use git reset, just declare \"Git bankruptcy\" and delete the .git folder and start over",
                "As pointed out by others in related questions (see here, here, here, here, here, here, and here), you can now unstage a single file with:and unstage all files (from the root of the repo) with:git restore was introduced in July 2019 and released in version 2.23.\nWith the --staged flag, it restores the content of the index (what is asked here).When running git status with staged uncommitted file(s), this is now what Git suggests to use to unstage file(s) (instead of git reset HEAD <file> as it used to prior to v2.23).",
                "Use git add -i to remove just-added files from your upcoming commit.  Example:Adding the file you didn't want:Going into interactive add to undo your add (the commands typed at git here are \"r\" (revert), \"1\" (first entry in the list revert shows), 'return' to drop out of revert mode, and \"q\" (quit):That's it!  Here's your proof, showing that \"foo\" is back on the untracked list:",
                "Here's a way to avoid this vexing problem when you start a new project:Git makes it really hard to do git reset if you don't have any commits.  If you create a tiny initial commit just for the sake of having one, after that you can git add -A and git reset as many times as you want in order to get everything right.Another advantage of this method is that if you run into line-ending troubles later and need to refresh all your files, it's easy:",
                "Note that if you fail to specify a revision then you have to include a separator. Example from my console:(Git version 1.7.5.4)",
                "Maybe Git has evolved since you posted your question.Now, you can try:This should be what you are looking for.",
                "To remove new files from the staging area (and only in case of a new file), as suggested above:Use rm --cached only for new files accidentally added.",
                "To reset every file in a particular folder (and its subfolders), you can use the following command:",
                "Use the * command to handle multiple files at a time:etc.",
                "Just type git reset it will revert back and it is like you never typed git add . since your last commit. Make sure you have committed before.",
                "Suppose I create a new file, newFile.txt:Suppose I add the file accidentally, git add newFile.txt:Now I want to undo this add, before commit, git reset newFile.txt:",
                "You can unstage or undo using the git command or GUI Git.Single fileMultiple filesSuppose you have added Home.js, ListItem.js, Update.js by mistake,and want to undo/reset =>The same example using Git GUIOpens a window. Uncheck your files from Staged changes (will commit)",
                "For a specific file:For all added files:Note: checkout changes the code in the files and moves to the last updated (committed) state. reset doesn't change the codes; it just resets the header.",
                "To undo git add, use:",
                "There is also interactive mode:Choose option 3 to un add files. In my case I often want to add more than one file, and with interactive mode you can use numbers like this to add files. This will take all but 4: 1, 2, 3, and 5To choose a sequence, just type 1-5 to take all from 1 to 5.Git staging files",
                "This command will unstash your changes:You can also useto add parts of files.",
                "Will remove a file named filename.txt from the current index, the \"about to be committed\" area, without changing anything else.",
                "git add myfile.txt # This will add your file into the to-be-committed listQuite opposite to this command is,so, you will be in the previous state. Specified will be again in untracked list (previous state).It will reset your head with that specified file. so, if your head doesn't have it means, it will simply reset it."
            ]
        },
        {
            "tag": "c++",
            "question": [
                "What is the \"-->\" operator in C++?",
                "After reading Hidden Features and Dark Corners of C++/STL on comp.lang.c++.moderated, I was completely surprised that the following snippet compiled and worked in both Visual Studio 2008 and G++ 4.4.\n..."
            ],
            "url": "https://stackoverflow.com/questions/1642028",
            "answer": [
                "--> is not an operator. It is in fact two separate operators, -- and >.The conditional's code decrements x, while returning x's original (not decremented) value, and then compares the original value with 0 using the > operator.To better understand, the statement could be written as follows:",
                "Or for something completely different... x slides to 0.Not so mathematical, but... every picture paints a thousand words...",
                "That's a very complicated operator, so even ISO/IEC JTC1 (Joint Technical Committee 1) placed its description in two different parts of the C++ Standard.Joking aside, they are two different operators: -- and > described respectively in \u00a75.2.6/2 and \u00a75.9 of the C++03 Standard.",
                "x can go to zero even faster in the opposite direction in C++:8 6 4 2You can control speed with an arrow!90 80 70 60 50 40 30 20 10;)",
                "It's equivalent tox-- (post decrement) is equivalent to x = x-1 (but returning the original value of x), so the code transforms to:",
                "It'sJust the space makes the things look funny, -- decrements and > compares.",
                "The usage of --> has historical relevance. Decrementing was (and still is in some cases), faster than incrementing on the x86 architecture. Using --> suggests that x is going to 0, and appeals to those with mathematical backgrounds.",
                "Utterly geek, but I will be using this:",
                "is how that's parsed.",
                "One book I read (I don't remember correctly which book) stated: Compilers try to parse expressions to the biggest token by using the left right rule.In this case, the expression:Parses to biggest tokens:The same rule applies to this expression:After parse:",
                "This is exactly the same as",
                "Anyway, we have a \"goes to\" operator now. \"-->\" is easy to be remembered as a direction, and \"while x goes to zero\" is meaning-straight.Furthermore, it is a little more efficient than \"for (x = 10; x > 0; x --)\" on some platforms.",
                "This code first compares x and 0 and then decrements x. (Also said in the first answer: You're post-decrementing x and then comparing x and 0 with the > operator.) See the output of this code:We now first compare and then decrement by seeing 0 in the output.If we want to first decrement and then compare, use this code:That output is:",
                "My compiler will print out 9876543210 when I run this code.As expected. The while( x-- > 0 ) actually means while( x > 0). The x-- post decrements x.is a different way of writing the same thing.It is nice that the original looks like \"while x goes to 0\" though.",
                "There is a space missing between -- and >. x is post decremented, that is, decremented after checking the condition x>0 ?.",
                "-- is the decrement operator and > is the greater-than operator.The two operators are applied as a single one like -->.",
                "It's a combination of two operators. First -- is for decrementing the value, and > is for checking whether the value is greater than the right-hand operand.The output will be:",
                "C and C++ obey the \"maximal munch\" rule. The same way a---b is translated to (a--) - b, in your case  x-->0 translates to (x--)>0.What the rule says essentially is that going left to right, expressions are formed by taking the maximum of characters which will form a valid token.",
                "Actually, x is post-decrementing and with that condition is being checked. It's not -->, it's (x--) > 0Note: value of x is changed after the condition is checked, because it post-decrementing. Some similar cases can also occur, for example:",
                "Instead of regular arrow operator (-->) you can use armor-piercing arrow operator: --x> (note those sharp barbs on the arrow tip). It adds +1 to armor piercing, so it finishes the loop 1 iteration faster than regular arrow operator. Try it yourself:",
                "For larger numbers, C++20 introduces some more advanced looping features.\nFirst to catch i we can build an inverse loop-de-loop and deflect it onto the std::ostream. However, the speed of i is implementation-defined, so we can use the new C++20 speed operator <<i<< to speed it up. We must also catch it by building wall, if we don't, i leaves the scope and de referencing it causes undefined behavior. To specify the separator, we can use:and there we have a for loop from 67 to 1.",
                "Why all the complication?The simple answer to the original question is just:It does the same thing. I am not saying you should do it like this, but it does the same thing and would have answered the question in one post.The x-- is just shorthand for the above, and > is just a normal greater-than operator. No big mystery!There are too many people making simple things complicated nowadays  ;)",
                "Conventional way we define condition in while loop parenthesis\"()\" and terminating condition inside the braces\"{}\", but this -- & > is a way one defines all at once.\nFor example:It says, decrement a and run the loop till the time a is greater than 0Other way it should have been like:Both ways, we do the same thing and achieve the same goals.",
                "(x --> 0) means (x-- > 0).Output:  9 8 7 6 5 4 3 2 1Output: 9 8 7 6 5 4 3 2 1 0Output: 9 8 7 6 5 4 3 2 1 0Output: 9 8 7 6 5 4 3 2 1 0Likewise, you can try lot of methods to execute this command successfully.",
                "This --> is not an operator at all. We have an operator like ->, but not like -->. It is just a wrong interpretation of while(x-- >0) which simply means x has the post decrement operator and this loop will run till it is greater than zero.Another simple way of writing this code would be while(x--). The  while loop will stop whenever it gets a false condition and here there is only one case, i.e., 0. So it will stop when the x value is decremented to zero.",
                "Here -- is the unary post decrement operator.",
                "--> is not an operator, it is the juxtaposition of -- (post-decrement) and > (greater than comparison).The loop will look more familiar as:This loop is a classic idiom to enumerate values between 10 (the excluded upper bound) and 0 the included lower bound, useful to iterate over the elements of an array from the last to the first.The initial value 10 is the total number of iterations (for example the length of the array), and one plus the first value used inside the loop. The 0 is the last value of x inside the loop, hence the comment x goes to 0.Note that the value of x after the loop completes is -1.Note also that this loop will operate the same way if x has an unsigned type such as size_t, which is a strong advantage over the naive alternative for (i = length-1; i >= 0; i--).For this reason, I am actually a fan of this surprising syntax: while (x --> 0). I find this idiom eye-catching and elegant, just like for (;;) vs: while (1) (which looks confusingly similar to while (l)). It also works in other languages whose syntax is inspired by C: C++, Objective-C, java, javascript, C# to name a few.",
                "That's what you mean.We heard in childhood,Stop don't, Let Go (\u0631\u0648\u06a9\u0648 \u0645\u062a\u060c \u062c\u0627\u0646\u06d2 \u062f\u0648)Where a Comma makes confusionStop, don't let go. (\u0631\u0648\u06a9\u0648\u060c \u0645\u062a \u062c\u0627\u0646\u06d2 \u062f\u0648)Same Happens in Programming now, a SPACE makes confusion. :D",
                "The operator you use is called \"decrement-and-then-test\". It is defined in the C99 standard, which is the latest version of the C programming language standard. The C99 standard added a number of new operators, including the \"decrement-and-then-test\" operator, to the C language. Many C++ compilers have adopted these new operators as extensions to the C++ language.Here is how the code without using the \"decrement-and-then-test\" operator:In this version of the code, the while loop uses the > operator to test whether x is greater than 0. The x-- statement is used to decrement x by 1 at the end of each iteration of the loop."
            ]
        },
        {
            "tag": "json",
            "question": [
                "Can comments be used in JSON?",
                "Can I use comments inside a JSON file? If so, how?"
            ],
            "url": "https://stackoverflow.com/questions/244777",
            "answer": [
                "No.JSON is data-only. If you include a comment, then it must be data too.You could have a designated data element called \"_comment\" (or something) that should be ignored by apps that use the JSON data.You would probably be better having the comment in the processes that generates/receives the JSON, as they are supposed to know what the JSON data will be in advance, or at least the structure of it.But if you decided to:",
                "No, comments of the form //\u2026 or /*\u2026*/ are not allowed in JSON. This answer is based on:",
                "Include comments if you choose; strip them out with a minifier before parsing or transmitting.I just released JSON.minify() which strips out comments and whitespace from a block of JSON and makes it valid JSON that can be parsed. So, you might use it like:When I released it, I got a huge backlash of people disagreeing with even the idea of it, so I decided that I'd write a comprehensive blog post on why comments make sense in JSON. It includes this notable comment from the creator of JSON:Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser. - Douglas Crockford, 2012Hopefully that's helpful to those who disagree with why JSON.minify() could be useful.",
                "Comments were removed from JSON by design.I removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability. I know that the lack of comments makes some people sad, but it shouldn't.Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser.Source: Public statement by Douglas Crockford on G+",
                "JSON does not support comments. It was also never intended to be used for configuration files where comments would be needed.Hjson is a configuration file format for humans. Relaxed syntax, fewer mistakes, more comments.See hjson.github.io for JavaScript, Java, Python, PHP, Rust, Go, Ruby, C++ and C# libraries.",
                "DISCLAIMER: YOUR WARRANTY IS VOIDAs has been pointed out, this hack takes advantage of the implementation of the spec. Not all JSON parsers will understand this sort of JSON. Streaming parsers in particular will choke.It's an interesting curiosity, but you should really not be using it for anything at all. Below is the original answer.I've found a little hack that allows you to place comments in a JSON file that will not affect the parsing, or alter the data being represented in any way.It appears that when declaring an object literal you can specify two values with the same key, and the last one takes precedence. Believe it or not, it turns out that JSON parsers work the same way. So we can use this to create comments in the source JSON that will not be present in a parsed object representation.If we apply this technique, your commented JSON file might look like this:The above code is valid JSON. If you parse it, you'll get an object like this:Which means there is no trace of the comments, and they won't have weird side-effects.Happy hacking!",
                "Consider using YAML. It's nearly a superset of JSON (virtually all valid JSON is valid YAML) and it allows comments.",
                "You can't. At least that's my experience from a quick glance at json.org.JSON has its syntax visualized on that page. There isn't any note about comments.",
                "Comments are not an official standard, although some parsers support C++-style comments. One that I use is JsonCpp. In the examples there is this one:jsonlint does not validate this. So comments are a parser specific extension and not standard.Another parser is JSON5.An alternative to JSON TOML.A further alternative is jsonc.The latest version of nlohmann/json has optional support for ignoring comments on parsing.",
                "Here is what I found in the Google Firebase documentation that allows you to put comments in JSON:",
                "You should write a JSON schema instead. JSON schema is currently a proposed Internet draft specification. Besides documentation, the schema can also be used for validating your JSON data.Example:You can provide documentation by using the description schema attribute.",
                "If you are using Jackson as your JSON parser then this is how you enable it to allow comments:Then you can have comments like this:And you can also have comments starting with # by setting:But in general (as answered before) the specification does not allow comments.",
                "NO. JSON used to support comments but they were abused and removed from the standard.From the creator of JSON:I removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability.  I know that the lack of comments makes some people sad, but it shouldn't.  - Douglas Crockford, 2012The official JSON site is at JSON.org. JSON is defined as a standard by ECMA International. There is always a petition process to have standards revised. It is unlikely that annotations will be added to the JSON standard for several reasons.JSON by design is an easily reverse-engineered (human parsed) alternative to XML. It is simplified even to the point that annotations are unnecessary. It is not even a markup language. The goal is stability and  interoperablilty.Anyone who understands the \"has-a\" relationship of object orientation can understand any JSON structure - that is the whole point. It is just a  directed acyclic graph (DAG) with node tags (key/value pairs), which is a near universal data structure.This only annotation required might be \"//These are DAG tags\". The key names can be as informative as required, allowing arbitrary semantic arity.Any platform can parse JSON with just a few lines of code. XML requires complex OO libraries that are not viable on many platforms.Annotations would just make JSON less interoperable. There is simply nothing else to add unless what you really need is a markup language (XML), and don't care if your persisted data is easily parsed.BUT as the creator of JSON also observed, there has always been JS pipeline support for comments:Go ahead and insert all the comments you like.\nThen pipe it through JSMin before handing it to your JSON parser. - Douglas Crockford, 2012",
                "If you are using the Newtonsoft.Json library with ASP.NET to read/deserialize you can use comments in the JSON content://\"name\": \"string\"//\"id\": intor/* This is acomment example */PS: Single-line comments are only supported with 6+ versions of Newtonsoft Json.Additional note for people who can't think out of the box: I use the JSON format for basic settings in an ASP.NET web application I made. I read the file, convert it into the settings object with the Newtonsoft library and use it when necessary.I prefer writing comments about each individual setting in the JSON file itself, and I really don't care about the integrity of the JSON format as long as the library I use is OK with it.I think this is an 'easier to use/understand' way than creating a separate 'settings.README' file and explaining the settings in it.If you have a problem with this kind of usage; sorry, the genie is out of the lamp. People would find other usages for JSON format, and there is nothing you can do about it.",
                "If your text file, which is a JSON string, is going to be read by some program, how difficult would it be to strip out either C or C++ style comments before using it?Answer: It would be a one liner. If you do that then JSON files could be used as configuration files.",
                "The idea behind JSON is to provide simple data exchange between applications. These are typically web based and the language is JavaScript.It doesn't really allow for comments as such, however, passing a comment as one of the name/value pairs in the data would certainly work, although that data would obviously need to be ignored or handled specifically by the parsing code.All that said, it's not the intention that the JSON file should contain comments in the traditional sense. It should just be the data.Have a look at the JSON website for more detail.",
                "JSON does not support comments natively, but you can make your own decoder or at least preprocessor to strip out comments, that's perfectly fine (as long as you just ignore comments and don't use them to guide how your application should process the JSON data).JSON does not have comments. A JSON encoder MUST NOT output comments.\nA JSON decoder MAY accept and ignore comments.Comments should never be used to transmit anything meaningful. That is\nwhat JSON is for.Cf: Douglas Crockford, author of JSON spec.",
                "I just encountering this for configuration files. I don't want to use XML (verbose, graphically, ugly, hard to read), or \"ini\" format (no hierarchy, no real standard, etc.) or Java \"Properties\" format (like .ini).JSON can do all they can do, but it is way less verbose and more human readable - and parsers are easy and ubiquitous in many languages. It's just a tree of data. But out-of-band comments are a necessity often to document \"default\" configurations and the like. Configurations are never to be \"full documents\", but trees of saved data that can be human readable when needed.I guess one could use \"#\": \"comment\", for \"valid\" JSON.",
                "It depends on your JSON library. Json.NET supports JavaScript-style comments, /* commment */.See another Stack\u00a0Overflow question.",
                "Yes, the new standard, JSON5 allows the C++ style comments, among many other extensions:The JSON5 Data Interchange Format (JSON5) is a superset of JSON that aims to alleviate some of the limitations of JSON. It is fully backwards compatible, and using it is probably better than writing the custom non standard parser, turning non standard features on for the existing one or using various hacks like string fields for commenting. Or, if the parser in use supports, simply agree we are using JSON 5 subset that is JSON and C++ style comments. It is much better than we tweak JSON standard the way we see fit.There is already npm package, Python package, Java package and C library available. It is backwards compatible. I see no reason to stay with the \"official\" JSON restrictions.I think that removing comments from JSON has been driven by the same reasons as removing the operator overloading in Java: can be used the wrong way yet some clearly legitimate use cases were overlooked. For operator overloading, it is matrix algebra and complex numbers. For JSON comments, its is configuration files and other documents that may be written, edited or read by humans and not just by parser.",
                "JSON makes a lot of sense for config files and other local usage because it's ubiquitous and because it's much simpler than XML.If people have strong reasons against having comments in JSON when communicating data (whether valid or not), then possibly JSON could be split into two:JSON-DOC will allow comments, and other minor differences might exist such as handling whitespace. Parsers can easily convert from one spec to the other.With regards to the remark made by Douglas Crockford on this issues (referenced by @Artur Czajka)Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser.We're talking about a generic config file issue (cross language/platform), and he's answering with a JS specific utility!Sure a JSON specific minify can be implemented in any language,\nbut standardize this so it becomes ubiquitous across parsers in all languages and platforms so people stop wasting their time lacking the feature because they have good use-cases for it, looking the issue up in online forums, and getting people telling them it's a bad idea or suggesting it's easy to implement stripping comments out of text files.The other issue is interoperability. Suppose you have a library or API or any kind of subsystem which has some config or data files associated with it. And this subsystem is\nto be accessed from different languages.  Then do you go about telling people: by the way\ndon't forget to strip out the comments from the JSON files before passing them to the parser!",
                "If you use JSON5 you can include comments.JSON5 is a proposed extension to JSON that aims to make it easier for humans to write and maintain by hand. It does this by adding some minimal syntax features directly from ECMAScript\u00a05.",
                "The Dojo Toolkit JavaScript toolkit (at least as of version 1.4), allows you to include comments in your JSON. The comments can be of /* */ format. Dojo Toolkit consumes the JSON via the dojo.xhrGet() call.Other JavaScript toolkits may work similarly.This can be helpful when experimenting with alternate data structures (or even data lists) before choosing a final option.",
                "JSON is not a framed protocol. It is a language free format. So a comment's format is not defined for JSON.As many people have suggested, there are some tricks, for example, duplicate keys or a specific key _comment that you can use. It's up to you.",
                "Disclaimer: This is sillyThere is actually a way to add comments, and stay within the specification (no additional parser needed). It will not result into human-readable comments without any sort of parsing though.You could abuse the following:Insignificant whitespace is allowed before or after any token.\nWhitespace is any sequence of one or more of the following code\npoints: character tabulation (U+0009), line feed (U+000A), carriage\nreturn (U+000D), and space (U+0020).In a hacky way, you can abuse this to add a comment. For instance: start and end your comment with a tab. Encode the comment in base3 and use the other whitespace characters to represent them. For instance.(hello base three in ASCII) But instead of 0 use space, for 1 use line feed and for 2 use carriage return.This will just leave you with a lot of unreadable whitespace (unless you make an IDE plugin to encode/decode it on the fly).I never even tried this, for obvious reasons and neither should you.",
                "You can have comments in JSONP, but not in pure JSON. I've just spent an hour trying to make my program work with this example from Highcharts.If you follow the link, you will seeSince I had a similar file in my local folder, there were no issues with the Same-origin policy, so I decided to use pure JSON\u2026 and, of course, $.getJSON was failing silently because of the comments.Eventually I just sent a manual HTTP request to the address above and realized that the content-type was text/javascript since, well, JSONP returns pure JavaScript. In this case comments are allowed. But my application returned content-type application/json, so I had to remove the comments.",
                "JSON doesn't allow comments, per se. The reasoning is utterly foolish, because you can use JSON itself to create comments, which obviates the reasoning entirely, and loads the parser data space for no good reason at all for exactly the same result and potential issues, such as they are: a JSON file with comments.If you try to put comments in (using // or /* */ or # for instance), then some parsers will fail because this is strictly not\nwithin the JSON specification. So you should never do that.Here, for instance, where my image manipulation system has saved image notations and some basic formatted (comment) information relating to them (at the bottom):",
                "This is a \"can you\" question. And here is a \"yes\" answer.No, you shouldn't use duplicative object members to stuff side channel data into a JSON encoding. (See \"The names within an object SHOULD be unique\" in the RFC).And yes, you could insert comments around the JSON, which you could parse out.But if you want a way of inserting and extracting arbitrary side-channel data to a valid JSON, here is an answer. We take advantage of the non-unique representation of data in a JSON encoding. This is allowed* in section two of the RFC under \"whitespace is allowed before or after any of the six structural characters\".*The RFC only states \"whitespace is allowed before or after any of the six structural characters\", not explicitly mentioning strings, numbers, \"false\", \"true\", and \"null\". This omission is ignored in ALL implementations.First, canonicalize your JSON by minifying it:Then encode your comment in binary:Then steg your binary:Here is your output:",
                "In my case, I need to use comments for debug purposes just before the output of the JSON. So I put the debug information in the HTTP header, to avoid breaking the client:",
                "We are using strip-json-comments for our project. It supports something like:Simply npm install --save strip-json-comments to install and use it like:"
            ]
        },
        {
            "tag": "memory-management",
            "question": [
                "What and where are the stack and heap?",
                "What are the stack and heap?\nWhere are they located physically in a computer's memory?\nTo what extent are they controlled by the OS or language run-time?\nWhat is their scope?\nWhat determines their ..."
            ],
            "url": "https://stackoverflow.com/questions/79923",
            "answer": [
                "The stack is the memory set aside as scratch space for a thread of execution.  When a function is called, a block is reserved on the top of the stack for local variables and some bookkeeping data.  When that function returns, the block becomes unused and can be used the next time a function is called.  The stack is always reserved in a LIFO (last in first out) order; the most recently reserved block is always the next block to be freed.  This makes it really simple to keep track of the stack; freeing a block from the stack is nothing more than adjusting one pointer.The heap is memory set aside for dynamic allocation.  Unlike the stack, there's no enforced pattern to the allocation and deallocation of blocks from the heap; you can allocate a block at any time and free it at any time.  This makes it much more complex to keep track of which parts of the heap are allocated or free at any given time; there are many custom heap allocators available to tune heap performance for different usage patterns.Each thread gets a stack, while there's typically only one heap for the application (although it isn't uncommon to have multiple heaps for different types of allocation).To answer your questions directly:To what extent are they controlled by the OS or language runtime?The OS allocates the stack for each system-level thread when the thread is created.  Typically the OS is called by the language runtime to allocate the heap for the application.What is their scope?The stack is attached to a thread, so when the thread exits the stack is reclaimed.  The heap is typically allocated at application startup by the runtime, and is reclaimed when the application (technically process) exits.What determines the size of each of them?The size of the stack is set when a thread is created.  The size of the heap is set on application startup, but can grow as space is needed (the allocator requests more memory from the operating system).What makes one faster?The stack is faster because the access pattern makes it trivial to allocate and deallocate memory from it (a pointer/integer is simply incremented or decremented), while the heap has much more complex bookkeeping involved in an allocation or deallocation.  Also, each byte in the stack tends to be reused very frequently which means it tends to be mapped to the processor's cache, making it very fast. Another performance hit for the heap is that the heap, being mostly a global resource, typically has to be multi-threading safe, i.e. each allocation and deallocation needs to be - typically - synchronized with \"all\" other heap accesses in the program.A clear demonstration:\n\nImage source: vikashazrati.wordpress.com",
                "Stack:Heap:Example:",
                "The most important point is that heap and stack are generic terms for ways in which memory can be allocated.  They can be implemented in many different ways, and the terms apply to the basic concepts.In a stack of items, items sit one on top of the other in the order they were placed there, and you can only remove the top one (without toppling the whole thing over).The simplicity of a stack is that you do not need to maintain a table containing a record of each section of allocated memory; the only state information you need is a single pointer to the end of the stack.  To allocate and de-allocate, you just increment and decrement that single pointer.  Note: a stack can sometimes be implemented to start at the top of a section of memory and extend downwards rather than growing upwards.In a heap, there is no particular order to the way items are placed.  You can reach in and remove items in any order because there is no clear 'top' item.Heap allocation requires maintaining a full record of what memory is allocated and what isn't, as well as some overhead maintenance to reduce fragmentation, find contiguous memory segments big enough to fit the requested size, and so on.  Memory can be deallocated at any time leaving free space.  Sometimes a memory allocator will perform maintenance tasks such as defragmenting memory by moving allocated memory around, or garbage collecting - identifying at runtime when memory is no longer in scope and deallocating it.These images should do a fairly good job of describing the two ways of allocating and freeing memory in a stack and a heap.  Yum!To what extent are they controlled by the OS or language runtime?As mentioned, heap and stack are general terms, and can be implemented in many ways.  Computer programs typically have a stack called a call stack which stores information relevant to the current function such as a pointer to whichever function it was called from, and any local variables.  Because functions call other functions and then return, the stack grows and shrinks to hold information from the functions further down the call stack.  A program doesn't really have runtime control over it; it's determined by the programming language, OS and even the system architecture.A heap is a general term used for any memory that is allocated dynamically and randomly; i.e. out of order.  The memory is typically allocated by the OS, with the application calling API functions to do this allocation.  There is a fair bit of overhead required in managing dynamically allocated memory, which is usually handled by the runtime code of the programming language or environment used.What is their scope?The call stack is such a low level concept that it doesn't relate to 'scope' in the sense of programming.  If you disassemble some code you'll see relative pointer style references to portions of the stack, but as far as a higher level language is concerned, the language imposes its own rules of scope.  One important aspect of a stack, however, is that once a function returns, anything local to that function is immediately freed from the stack.  That works the way you'd expect it to work given how your programming languages work.  In a heap, it's also difficult to define.  The scope is whatever is exposed by the OS, but your programming language probably adds its rules about what a \"scope\" is in your application.  The processor architecture and the OS use virtual addressing, which the processor translates to physical addresses and there are page faults, etc.  They keep track of what pages belong to which applications.  You never really need to worry about this, though, because you just use whatever method your programming language uses to allocate and free memory, and check for errors (if the allocation/freeing fails for any reason).What determines the size of each of them?Again, it depends on the language, compiler, operating system and architecture.  A stack is usually pre-allocated, because by definition it must be contiguous memory.  The language compiler or the OS determine its size.  You don't store huge chunks of data on the stack, so it'll be big enough that it should never be fully used, except in cases of unwanted endless recursion (hence, \"stack overflow\") or other unusual programming decisions.A heap is a general term for anything that can be dynamically allocated.  Depending on which way you look at it, it is constantly changing size.  In modern processors and operating systems the exact way it works is very abstracted anyway, so you don't normally need to worry much about how it works deep down, except that (in languages where it lets you) you mustn't use memory that you haven't allocated yet or memory that you have freed.What makes one faster?The stack is faster because all free memory is always contiguous.  No list needs to be maintained of all the segments of free memory, just a single pointer to the current top of the stack.  Compilers usually store this pointer in a special, fast register for this purpose.  What's more, subsequent operations on a stack are usually concentrated within very nearby areas of memory, which at a very low level is good for optimization by the processor on-die caches.",
                "(I have moved this answer from another question that was more or less a dupe of this one.)The answer to your question is implementation specific and may vary across compilers and processor architectures. However, here is a simplified explanation.Can a function be allocated on the heap instead of a stack?No, activation records for functions (i.e. local or automatic variables) are allocated on the stack that is used not only to store these variables, but also to keep track of nested function calls.How the heap is managed is really up to the runtime environment. C uses malloc and C++ uses new, but many other languages have garbage collection.However, the stack is a more low-level feature closely tied to the processor architecture. Growing the heap when there is not enough space isn't too hard since it can be implemented in the library call that handles the heap. However, growing the stack is often impossible as the stack overflow only is discovered when it is too late; and shutting down the thread of execution is the only viable option.",
                "In the following C# codeHere's how the memory is managedLocal Variables that only need to last as long as the function invocation go in the stack. The heap is used for variables whose lifetime we don't really know up front but we expect them to last a while. In most languages it's critical that we know at compile time how large a variable is if we want to store it on the stack.Objects (which vary in size as we update them) go on the heap because we don't know at creation time how long they are going to last. In many languages the heap is garbage collected to find objects (such as the cls1 object) that no longer have any references.In Java, most objects go directly into the heap. In languages like C / C++, structs and classes can often remain on the stack when you're not dealing with pointers.More information can be found here:The difference between stack and heap memory allocation \u00ab  timmurphy.organd here:Creating Objects on the Stack and HeapThis article is the source of picture above: Six important .NET concepts: Stack, heap, value types, reference types, boxing, and unboxing - CodeProjectbut be aware it may contain some inaccuracies.",
                "The Stack\nWhen you call a function the arguments to that function plus some other overhead is put on the stack. Some info (such as where to go on return) is also stored there.\nWhen you declare a variable inside your function, that variable is also allocated on the stack.Deallocating the stack is pretty simple because you always deallocate in the reverse order in which you allocate. Stack stuff is added as you enter functions, the corresponding data is removed as you exit them. This means that you tend to stay within a small region of the stack unless you call lots of functions that call lots of other functions (or create a recursive solution).The Heap\nThe heap is a generic name for where you put the data that you create on the fly. If you don't know how many spaceships your program is going to create, you are likely to use the new (or malloc or equivalent) operator to create each spaceship. This allocation is going to stick around for a while, so it is likely we will free things in a different order than we created them.Thus, the heap is far more complex, because there end up being regions of memory that are unused interleaved with chunks that are - memory gets fragmented. Finding free memory of the size you need is a difficult problem. This is why the heap should be avoided (though it is still often used).Implementation\nImplementation of both the stack and heap is usually down to the runtime / OS. Often games and other applications that are performance critical create their own memory solutions that grab a large chunk of memory from the heap and then dish it out internally to avoid relying on the OS for memory.This is only practical if your memory usage is quite different from the norm - i.e for games where you load a level in one huge operation and can chuck the whole lot away in another huge operation.Physical location in memory\nThis is less relevant than you think because of a technology called Virtual Memory which makes your program think that you have access to a certain address where the physical data is somewhere else (even on the hard disc!). The addresses you get for the stack are in increasing order as your call tree gets deeper. The addresses for the heap are un-predictable (i.e implimentation specific) and frankly not important.",
                "Other answers just avoid explaining what static allocation means. So I will explain the three main forms of allocation and how they usually relate to the heap, stack, and data segment below. I also will show some examples in both C/C++ and Python to help people understand.\"Static\" (AKA statically allocated) variables are not allocated on the stack. Do not assume so - many people do only because \"static\" sounds a lot like \"stack\". They actually exist in neither the stack nor the heap. They are part of what's called the data segment.However, it is generally better to consider \"scope\" and \"lifetime\" rather than \"stack\" and \"heap\".Scope refers to what parts of the code can access a variable. Generally we think of local scope (can only be accessed by the current function) versus global scope (can be accessed anywhere) although scope can get much more complex.Lifetime refers to when a variable is allocated and deallocated during program execution. Usually we think of static allocation (variable will persist through the entire duration of the program, making it useful for storing the same information across several function calls) versus automatic allocation (variable only persists during a single call to a function, making it useful for storing information that is only used during your function and can be discarded once you are done) versus dynamic allocation (variables whose duration is defined at runtime, instead of compile time like static or automatic).Although most compilers and interpreters implement this behavior similarly in terms of using stacks, heaps, etc, a compiler may sometimes break these conventions if it wants as long as behavior is correct. For instance, due to optimization a local variable may only exist in a register or be removed entirely, even though most local variables exist in the stack. As has been pointed out in a few comments, you are free to implement a compiler that doesn't even use a stack or a heap, but instead some other storage mechanisms (rarely done, since stacks and heaps are great for this).I will provide some simple annotated C code to illustrate all of this. The best way to learn is to run a program under a debugger and watch the behavior. If you prefer to read python, skip to the end of the answer :)A particularly poignant example of why it's important to distinguish between lifetime and scope is that a variable can have local scope but static lifetime - for instance, \"someLocalStaticVariable\" in the code sample above. Such variables can make our common but informal naming habits very confusing. For instance when we say \"local\" we usually mean \"locally scoped automatically allocated variable\" and when we say global we usually mean \"globally scoped statically allocated variable\". Unfortunately when it comes to things like \"file scoped statically allocated variables\" many people just say... \"huh???\".Some of the syntax choices in C/C++ exacerbate this problem - for instance many people think global variables are not \"static\" because of the syntax shown below.Note that putting the keyword \"static\" in the declaration above prevents var2 from having global scope. Nevertheless, the global var1 has static allocation. This is not intuitive! For this reason, I try to never use the word \"static\" when describing scope, and instead say something like \"file\" or \"file limited\" scope. However many people use the phrase \"static\" or \"static scope\" to describe a variable that can only be accessed from one code file. In the context of lifetime, \"static\" always means the variable is allocated at program start and deallocated when program exits.Some people think of these concepts as C/C++ specific. They are not. For instance, the Python sample below illustrates all three types of allocation (there are some subtle differences possible in interpreted languages that I won't get into here).",
                "Others have answered the broad strokes pretty well, so I'll throw in a few details.Stack and heap need not be singular. A common situation in which you have more than one stack is if you have more than one thread in a process.  In this case each thread has its own stack. You can also have more than one heap, for example some DLL configurations can result in different DLLs allocating from different heaps, which is why it's generally a bad idea to release memory allocated by a different library.In C you can get the benefit of variable length allocation through the use of alloca, which allocates on the stack, as opposed to alloc, which allocates on the heap. This memory won't survive your return statement, but it's useful for a scratch buffer.Making a huge temporary buffer on Windows that you don't use much of is not free. This is because the compiler will generate a stack probe loop that is called every time your function is entered to make sure the stack exists (because Windows uses a single guard page at the end of your stack to detect when it needs to grow the stack. If you access memory more than one page off the end of the stack you will crash). Example:",
                "Others have directly answered your question, but when trying to understand the stack and the heap, I think it is helpful to consider the memory layout of a traditional UNIX process (without threads and mmap()-based allocators). The Memory Management Glossary web page has a diagram of this memory layout.The stack and heap are traditionally located at opposite ends of the process's virtual address space. The stack grows automatically when accessed, up to a size set by the kernel (which can be adjusted with setrlimit(RLIMIT_STACK, ...)). The heap grows when the memory allocator invokes the brk() or sbrk() system call, mapping more pages of physical memory into the process's virtual address space.In systems without virtual memory, such as some embedded systems, the same basic layout often applies, except the stack and heap are fixed in size. However, in other embedded systems (such as those based on Microchip PIC microcontrollers), the program stack is a separate block of memory that is not addressable by data movement instructions, and can only be modified or read indirectly through program flow instructions (call, return, etc.). Other architectures, such as Intel Itanium processors, have multiple stacks. In this sense, the stack is an element of the CPU architecture.",
                "What is a stack?A stack is a pile of objects, typically one that is neatly arranged.Stacks in computing architectures are regions of memory where data is added or removed in a last-in-first-out manner. \nIn a multi-threaded application, each thread will have its own stack.What is a heap?A heap is an untidy collection of things piled up haphazardly.In computing architectures the heap is an area of dynamically-allocated memory that is managed automatically by the operating system or the memory manager library. \nMemory on the heap is allocated, deallocated, and resized regularly during program execution, and this can lead to a problem called fragmentation. \nFragmentation occurs when memory objects are allocated with small spaces in between that are too small to hold additional memory objects. \nThe net result is a percentage of the heap space that is not usable for further memory allocations.Both togetherIn a multi-threaded application, each thread will have its own stack. But, all the different threads will share the heap. \nBecause the different threads share the heap in a multi-threaded application, this also means that there has to be some coordination between the threads so that they don\u2019t try to access and manipulate the same piece(s) of memory in the heap at the same time.Which is faster \u2013 the stack or the heap? And why?The stack is much faster than the heap. \nThis is because of the way that memory is allocated on the stack. \nAllocating memory on the stack is as simple as moving the stack pointer up.For people new to programming, it\u2019s probably a good idea to use the stack since it\u2019s easier. \nBecause the stack is small, you would want to use it when you know exactly how much memory you will need for your data, or if you know the size of your data is very small. \nIt\u2019s better to use the heap when you know that you will need a lot of memory for your data, or you just are not sure how much memory you will need (like with a dynamic array).The stack is the area of memory where local variables (including method parameters) are stored. When it comes to object variables, these are merely references (pointers) to the actual objects on the heap.\nEvery time an object is instantiated, a chunk of heap memory is set aside to hold the data (state) of that object. Since objects can contain other objects, some of this data can in fact hold references to those nested objects.",
                "The stack is a portion of memory that can be manipulated via several key assembly language instructions, such as 'pop' (remove and return a value from the stack) and 'push' (push a value to the stack), but also call (call a subroutine - this pushes the address to return to the stack) and return (return from a subroutine - this pops the address off of the stack and jumps to it).  It's the region of memory below the stack pointer register, which can be set as needed.  The stack is also used for passing arguments to subroutines, and also for preserving the values in registers before calling subroutines.The heap is a portion of memory that is given to an application by the operating system, typically through a syscall like malloc.  On modern OSes this memory is a set of pages that only the calling process has access to.The size of the stack is determined at runtime, and generally does not grow after the program launches.  In a C program, the stack needs to be large enough to hold every variable declared within each function.  The heap will grow dynamically as needed, but the OS is ultimately making the call (it will often grow the heap by more than the value requested by malloc, so that at least some future mallocs won't need to go back to the kernel to get more memory.  This behavior is often customizable)Because you've allocated the stack before launching the program, you never need to malloc before you can use the stack, so that's a slight advantage there.  In practice, it's very hard to predict what will be fast and what will be slow in modern operating systems that have virtual memory subsystems, because how the pages are implemented and where they are stored is an implementation detail.",
                "I think many other people have given you mostly correct answers on this matter.One detail that has been missed, however, is that the \"heap\" should in fact probably be called the \"free store\".  The reason for this distinction is that the original free store was implemented with a data structure known as a \"binomial heap.\"  For that reason, allocating from early implementations of malloc()/free() was allocation from a heap.  However, in this modern day, most free stores are implemented with very elaborate data structures that are not binomial heaps.",
                "You can do some interesting things with the stack.  For instance, you have functions like alloca (assuming you can get past the copious warnings concerning its use), which is a form of malloc that specifically uses the stack, not the heap, for memory.That said, stack-based memory errors are some of the worst I've experienced.  If you use heap memory, and you overstep the bounds of your allocated block, you have a decent chance of triggering a segment fault.  (Not 100%: your block may be incidentally contiguous with another that you have previously allocated.)  But since variables created on the stack are always contiguous with each other, writing out of bounds can change the value of another variable.  I have learned that whenever I feel that my program has stopped obeying the laws of logic, it is probably buffer overflow.",
                "Simply, the stack is where local variables get created. Also, every time you call a subroutine the program counter (pointer to the next machine instruction) and any important registers, and sometimes the parameters get pushed on the stack. Then any local variables inside the subroutine are pushed onto the stack (and used from there). When the subroutine finishes, that stuff all gets popped back off the stack. The PC and register data gets and put back where it was as it is popped, so your program can go on its merry way.The heap is the area of memory dynamic memory allocations are made out of (explicit \"new\" or \"allocate\" calls). It is a special data structure that can keep track of blocks of memory of varying sizes and their allocation status.In \"classic\" systems RAM was laid out such that the stack pointer started out at the bottom of memory, the heap pointer started out at the top, and they grew towards each other. If they overlap, you are out of RAM. That doesn't work with modern multi-threaded OSes though. Every thread has to have its own stack, and those can get created dynamicly.",
                "From WikiAnwser.When a function or a method calls another function which in turns calls another function, etc., the execution of all those functions remains suspended until the very last function returns its value.This chain of suspended function calls is the stack, because elements in the stack (function calls) depend on each other.The stack is important to consider in exception handling and thread executions.The heap is simply the memory used by programs to store variables.\nElement of the heap (variables) have no dependencies with each other and can always be accessed randomly at any time.",
                "StackHeap",
                "A stack is used for static memory allocation and a heap for dynamic memory allocation, both stored in the computer's RAM.The StackThe stack is a \"LIFO\" (last in, first out) data structure, that is managed and optimized by the CPU quite closely. Every time a function declares a new variable, it is \"pushed\" onto the stack. Then every time a function exits, all of the variables pushed onto the stack by that function, are freed (that is to say, they are deleted). Once a stack variable is freed, that region of memory becomes available for other stack variables.The advantage of using the stack to store variables, is that memory is managed for you. You don't have to allocate memory by hand, or free it once you don't need it any more. What's more, because the CPU organizes stack memory so efficiently, reading from and writing to stack variables is very fast.More can be found here.The HeapThe heap is a region of your computer's memory that is not managed automatically for you, and is not as tightly managed by the CPU. It is a more free-floating region of memory (and is larger). To allocate memory on the heap, you must use malloc() or calloc(), which are built-in C functions. Once you have allocated memory on the heap, you are responsible for using free() to deallocate that memory once you don't need it any more.If you fail to do this, your program will have what is known as a memory leak. That is, memory on the heap will still be set aside (and won't be available to other processes). As we will see in the debugging section, there is a tool called Valgrind that can help you detect memory leaks.Unlike the stack, the heap does not have size restrictions on variable size (apart from the obvious physical limitations of your computer). Heap memory is slightly slower to be read from and written to, because one has to use pointers to access memory on the heap. We will talk about pointers shortly.Unlike the stack, variables created on the heap are accessible by any function, anywhere in your program. Heap variables are essentially global in scope.More can be found here.Variables allocated on the stack are stored directly to the memory and access to this memory is very fast, and its allocation is dealt with when the program is compiled. When a function or a method calls another function which in turns calls another function, etc., the execution of all those functions remains suspended until the very last function returns its value. The stack is always reserved in a LIFO order, the most recently reserved block is always the next block to be freed. This makes it really simple to keep track of the stack, freeing a block from the stack is nothing more than adjusting one pointer.Variables allocated on the heap have their memory allocated at run time and accessing this memory is a bit slower, but the heap size is only limited by the size of virtual memory. Elements of the heap have no dependencies with each other and can always be accessed randomly at any time. You can allocate a block at any time and free it at any time. This makes it much more complex to keep track of which parts of the heap are allocated or free at any given time.You can use the stack if you know exactly how much data you need to allocate before compile time, and it is not too big. You can use the heap if you don't know exactly how much data you will need at runtime or if you need to allocate a lot of data.In a multi-threaded situation each thread will have its own completely independent stack, but they will share the heap. The stack is thread specific and the heap is application specific. The stack is important to consider in exception handling and thread executions.Each thread gets a stack, while there's typically only one heap for the application (although it isn't uncommon to have multiple heaps for different types of allocation).At run-time, if the application needs more heap, it can allocate memory from free memory and if the stack needs memory, it can allocate memory from free memory allocated memory for the application.Even, more detail is given here and here.Now come to your question's answers.To what extent are they controlled by the OS or language runtime?The OS allocates the stack for each system-level thread when the thread is created. Typically the OS is called by the language runtime to allocate the heap for the application.More can be found here.What is their scope?Already given in top.\"You can use the stack if you know exactly how much data you need to allocate before compile time, and it is not too big. You can use the heap if you don't know exactly how much data you will need at runtime or if you need to allocate a lot of data.\"More can be found in here.What determines the size of each of them?The size of the stack is set by OS when a thread is created. The size of the heap is set on application startup, but it can grow as space is needed (the allocator requests more memory from the operating system).What makes one faster?Stack allocation is much faster since all it really does is move the stack pointer. Using memory pools, you can get comparable performance out of heap allocation, but that comes with a slight added complexity and its own headaches.Also, stack vs. heap is not only a performance consideration; it also tells you a lot about the expected lifetime of objects.Details can be found from here.",
                "OK, simply and in short words, they mean ordered and not ordered...!Stack: In stack items, things get on the top of each-other, means gonna be faster and more efficient to be processed!...So there is always an index to point the specific item, also processing gonna be faster, there is relationship between the items as well!...Heap: No order, processing gonna be slower and values are messed up together with no specific order or index... there are random and there is no relationship between them... so execution and usage time could be vary...I also create the image below to show how they may look like:",
                "stack, heap and data of each process in virtual memory:",
                "In the 1980s, UNIX propagated like bunnies with big companies rolling their own.\nExxon had one as did dozens of brand names lost to history.\nHow memory was laid out was at the discretion of the many implementors.A typical C program was laid out flat in memory with\nan opportunity to increase by changing the brk() value.\nTypically, the HEAP was just below this brk value\nand increasing brk increased the amount of available heap.The single STACK was typically an area below HEAP which was a tract of memory\ncontaining nothing of value until the top of the next fixed block of memory.\nThis next block was often CODE which could be overwritten by stack data\nin one of the famous hacks of its era.One typical memory block was BSS (a block of zero values)\nwhich was accidentally not zeroed in one manufacturer's offering.\nAnother was DATA containing initialized values, including strings and numbers.\nA third was CODE containing CRT (C runtime), main, functions, and libraries.The advent of virtual memory in UNIX changes many of the constraints.\nThere is no objective reason why these blocks need be contiguous,\nor fixed in size, or ordered a particular way now.\nOf course, before UNIX was Multics which didn't suffer from these constraints.\nHere is a schematic showing one of the memory layouts of that era.",
                "A couple of cents: I think, it will be good to draw memory graphical and more simple:Arrows - show where grow stack and heap, process stack size have limit, defined in OS, thread stack size limits by parameters in thread create API usually. Heap usually limiting by process maximum virtual memory size, for 32 bit 2-4\u00a0GB for example.So simple way: process heap is general for process and all threads inside, using for memory allocation in common case with something like malloc().Stack is quick memory for store in common case function return pointers and variables, processed as parameters in function call, local function variables.",
                "Since some answers went nitpicking, I'm going to contribute my mite.Surprisingly, no one has mentioned that multiple (i.e. not related to the number of running OS-level threads) call stacks are to be found not only in exotic languages (PostScript) or platforms (Intel Itanium), but also in fibers, green threads and some implementations of coroutines.Fibers, green threads and coroutines are in many ways similar, which leads to much confusion.  The difference between fibers and green threads is that the former use cooperative multitasking, while the latter may feature either cooperative or preemptive one (or even both). For the distinction between fibers and coroutines, see here.In any case, the purpose of both fibers, green threads and coroutines is having multiple functions executing concurrently, but not in parallel (see this SO question for the distinction) within a single OS-level thread, transferring control back and forth from one another in an organized fashion.When using fibers, green threads or coroutines, you usually have a separate stack per function. (Technically, not just a stack but a whole context of execution is per function. Most importantly, CPU registers.) For every thread there're as many stacks as there're concurrently running functions, and the thread is switching between executing each function according to the logic of your program. When a function runs to its end, its stack is destroyed. So, the number and lifetimes of stacks are dynamic and are not determined by the number of OS-level threads!Note that I said \"usually have a separate stack per function\". There're both stackful and stackless implementations of couroutines. Most notable stackful C++ implementations are Boost.Coroutine and Microsoft PPL's async/await. (However, C++'s resumable functions (a.k.a. \"async and await\"), which were proposed to C++17, are likely to use stackless coroutines.)Fibers proposal to the C++ standard library is forthcoming. Also, there're some third-party libraries. Green threads are extremely popular in languages like Python and Ruby.",
                "I have something to share, although the major points are already covered.StackHeapInteresting note:",
                "Wow! So many answers and I don't think one of them got it right...1) Where and what are they (physically in a real computer's memory)?The stack is memory that begins as the highest memory address allocated to your program image, and it then decrease in value from there. It is reserved for called function parameters and for all temporary variables used in functions.There are two heaps: public and private.The private heap begins on a 16-byte boundary (for 64-bit programs) or a 8-byte boundary (for 32-bit programs) after the last byte of code in your program, and then increases in value from there. It is also called the default heap.If the private heap gets too large it will overlap the stack area, as will the stack overlap the heap if it gets too big. Because the stack starts at a higher address and works its way down to lower address, with proper hacking you can get make the stack so large that it will overrun the private heap area and overlap the code area. The trick then is to overlap enough of the code area that you can hook into the code. It's a little tricky to do and you risk a program crash, but it's easy and very effective.The public heap resides in it's own memory space outside of your program image space. It is this memory that will be siphoned off onto the hard disk if memory resources get scarce.2) To what extent are they controlled by the OS or language runtime?The stack is controlled by the programmer, the private heap is managed by the OS, and the public heap is not controlled by anyone because it is an OS service -- you make requests and either they are granted or denied.2b) What is their scope?They are all global to the program, but their contents can be private, public, or global.2c) What determines the size of each of them?The size of the stack and the private heap are determined by your compiler runtime options. The public heap is initialized at runtime using a size parameter.2d) What makes one faster?They are not designed to be fast, they are designed to be useful. How the programmer utilizes them determines whether they are \"fast\" or \"slow\"REF:https://norasandler.com/2019/02/18/Write-a-Compiler-10.htmlhttps://learn.microsoft.com/en-us/windows/desktop/api/heapapi/nf-heapapi-getprocessheaphttps://learn.microsoft.com/en-us/windows/desktop/api/heapapi/nf-heapapi-heapcreate",
                "A lot of answers are correct as concepts, but we must note that a stack is needed by the hardware (i.e. microprocessor) to allow calling subroutines (CALL in assembly language..). (OOP guys will call it methods)On the stack you save return addresses and call \u2192 push / ret \u2192 pop is managed directly in hardware.You can use the stack to pass parameters.. even if it is slower than using registers (would a microprocessor guru say or a good 1980s BIOS book...)Stack usage is faster as:",
                "Where and what are they (physically in a real computer's memory)?ANSWER: Both are in RAM.ASIDE:RAM is like a desk and HDDs/SSDs (permanent storage) are like bookshelves. To read anything, you must have a book open on your desk, and you can only have as many books open as fit on your desk. To get a book, you pull it from your bookshelf and open it on your desk. To return a book, you close the book on your desk and return it to its bookshelf.Stack and heap are names we give to two ways compilers store different kinds of data in the same place (i.e. in RAM).What is their scope?\nWhat determines the size of each of them?\nWhat makes one faster?ANSWER:The stack is for static (fixed size) dataa. At compile time, the compiler reads the variable types used in your code.i. It allocates a fixed amount of memory for these variables.\nii. This size of this memory cannot grow.b. The memory is contiguous (a single block), so access is sometimes faster than the heapc. An object placed on the stack that grows in memory during runtime beyond the size of the stack causes a stack overflow errorThe heap is for dynamic (changing size) dataa. The amount of memory is limited only by the amount of empty space available in RAM\ni. The amount used can grow or shrink as needed at runtimeb. Since items are allocated on the heap by finding empty space wherever it exists in RAM, data is not always in a contiguous section, which sometimes makes access slower than the stackc. Programmers manually put items on the heap with the new keyword and MUST manually deallocate this memory when they are finished using it.\ni. Code that repeatedly allocates new memory without deallocating it when it is no longer needed leads to a memory leak.ASIDE:The stack and heap were not primarily introduced to improve speed; they were introduced to handle memory overflow. The first concern regarding use of the stack vs. the heap should be whether memory overflow will occur. If an object is intended to grow in size to an unknown amount (like a linked list or an object whose members can hold an arbitrary amount of data), place it on the heap. As far as possible, use the C++ standard library (STL) containers vector, map, and list as they are memory and speed efficient and added to make your life easier (you don't need to worry about memory allocation/deallocation).After getting your code to run, if you find it is running unacceptably slow, then go back and refactor your code and see if it can be programmed more efficiently. It may turn out the problem has nothing to do with the stack or heap directly at all (e.g. use an iterative algorithm instead of a recursive one, look at I/O vs. CPU-bound tasks, perhaps add multithreading or multiprocessing).I say sometimes slower/faster above because the speed of the program might not have anything to do with items being allocated on the stack or heap.To what extent are they controlled by the OS or language run-time?ANSWER:The stack size is determined at compile time by the compiler.The heap size varies during runtime. (The heap works with the OS during runtime to allocate memory.)ASIDE:Below is a little more about control and compile-time vs. runtime operations.Each computer has a unique instruction set architecture (ISA), which are its hardware commands (e.g. \"MOVE\", \"JUMP\", \"ADD\", etc.).An OS is nothing more than a resource manager (controls how/when/ and where to use memory, processors, devices, and information).The ISA of the OS is called the bare machine and the remaining commands are called the extended machine. The kernel is the first layer of the extended machine. It controls things likeWhen we say \"compiler\", we generally mean the compiler, assembler, and linker togetherThe machine code gets passed to the kernel when executed, which determines when it should run and take control, but the machine code itself contains ISA commands for requesting files, requesting memory, etc. So the code issues ISA commands, but everything has to pass by the kernel.",
                "The stack is essentially an easy-to-access memory that simply manages its items \n  as a - well - stack. Only items for which the size is known in advance can go onto the stack. This is the case for numbers, strings, booleans.The heap is a memory for items of which you can\u2019t predetermine the\n  exact size and structure. Since objects and arrays can be mutated and\n  change at runtime, they have to go into the heap.Source: Academind",
                "CPU stack and heap are physically related to how CPU and registers works with memory, how machine-assembly language works, not high-level languages themselves, even if these languages can decide little things.All modern CPUs work with the \"same\" microprocessor theory: they are all based on what's called \"registers\" and some are for \"stack\" to gain performance. All CPUs have stack registers since the beginning and they had been always here, way of talking, as I know. Assembly languages are the same since the beginning, despite variations... up to Microsoft and its Intermediate Language (IL) that changed the paradigm to have a OO virtual machine assembly language. So we'll be able to have some CLI/CIL CPU in the future (one project of MS).CPUs have stack registers to speed up memories access, but they are limited compared to the use of others registers to get full access to all the available memory for the processus. It why we talked about stack and heap allocations.In summary, and in general, the heap is hudge and slow and is for \"global\" instances and objects content, as the stack is little and fast and for \"local\" variables and references (hidden pointers to forget to manage them).So when we use the new keyword in a method, the reference (an int) is created in the stack, but the object and all its content (value-types as well as objects) is created in the heap, if I remember. But local elementary value-types and arrays are created in the stack.The difference in memory access is at the cells referencing level: addressing the heap, the overall memory of the process, requires more complexity in terms of handling CPU registers, than the stack which is \"more\" locally in terms of addressing because the CPU stack register is used as base address, if I remember.It is why when we have very long or infinite recurse calls or loops, we got stack overflow quickly, without freezing the system on modern computers...C# Heap(ing) Vs Stack(ing) In .NETStack vs Heap: Know the DifferenceStatic class memory allocation where it is stored C#What and where are the stack and heap?https://en.wikipedia.org/wiki/Memory_managementhttps://en.wikipedia.org/wiki/Stack_registerAssembly language resources:Assembly Programming TutorialIntel\u00ae 64 and IA-32 Architectures Software Developer Manuals",
                "Thank you for a really good discussion but as a real noob I wonder where instructions are kept? In the BEGINNING scientists were deciding between two architectures (von NEUMANN where everything is considered DATA and HARVARD where an area of memory was reserved for instructions and another for data). Ultimately, we went with the von Neumann design and now everything is considered 'the same'. This made it hard for me when I was learning assembly \nhttps://www.cs.virginia.edu/~evans/cs216/guides/x86.html\nbecause they talk about registers and stack pointers.Everything above talks about DATA. My guess is that since an instruction is a defined thing with a specific memory footprint, it would go on the stack and so all 'those' registers discussed in assembly are on the stack. Of course then came object oriented programming with instructions and data comingled into a structure that was dynamic so now instructions would be kept on the heap as well?",
                "When a process is created then after loading code and data OS setup heap start just after data ends and stack to top of address space based on architectureWhen more heap is required OS will allocate dynamically and heap chunk is always virtually contiguousPlease see brk(), sbrk() and alloca() system call in linux"
            ]
        },
        {
            "tag": "git",
            "question": [
                "How do I force \"git pull\" to overwrite local files?",
                "How do I force an overwrite of local files on a git pull? My local repository contains a file of the same filename as on the server.\n\nerror: Untracked working tree file 'example.txt' would be ..."
            ],
            "url": "https://stackoverflow.com/questions/1125968",
            "answer": [
                "Any uncommitted local changes to tracked files will be lost.Any local files that are not tracked by Git will not be affected.First, update all origin/<branch> refs to latest:Backup your current branch (e.g. master):Jump to the latest commit on origin/master and checkout those files:git fetch downloads the latest from remote without trying to merge or rebase anything.git reset resets the master branch to what you just fetched. The --hard option changes all the files in your working tree to match the files in origin/master.[*]: It's worth noting that it is possible to maintain current local commits by creating a branch from master before resetting:After this, all of the old commits will be kept in new-branch-to-save-current-commits.Uncommitted changes, however (even staged), will be lost. Make sure to stash and commit anything you need. For that you can run the following:And then to reapply these uncommitted changes:",
                "This will remove all uncommitted changes and then pull:",
                "WARNING: git clean deletes all your untracked files/directories and can't be undone.Sometimes just clean -f does not help. In case you have untracked DIRECTORIES, -d option also needed:WARNING: git clean deletes all your untracked files/directories and can't be undone.Consider using -n (--dry-run) flag first. This will show you what will be deleted without actually deleting anything:Example output:",
                "Like Hedgehog I think the answers are terrible. But though Hedgehog's answer might be better, I don't think it is as elegant as it could be.  The way I found to do this is by using fetch and merge with a defined strategy. Which should make it so that your local changes are preserved as long as they are not one of the files that you are trying to force an overwrite with.-X is an option name, and theirs is the value for that option. You're choosing to use their changes (the other option is ours changes) if there is a conflict.",
                "Instead of doing:I'd advise doing the following:No need to fetch all remotes and branches if you're going to reset to the origin/master branch right?",
                "It looks like the best way is to first do:To delete all untracked files and then continue with the usual git pull...",
                "Warning, doing this will permanently delete your files if you have any directory/* entries in your gitignore file.Some answers seem to be terrible. Terrible in the sense of what happened to @Lauri by following David Avsajanishvili suggestion.Rather (git > v1.7.6):Later you can clean the stash history.Manually, one-by-one:Brutally, all-at-once:Of course if you want to go back to what you stashed:",
                "You might find this command helpful to throw away local changes:And then do a cleanup (removes untracked files from the working tree):If you want to remove untracked directories in addition to untracked files:",
                "Instead of merging with git pull, try this:git fetch --allfollowed by:git reset --hard origin/master.",
                "The only thing that worked for me was:This will take you back five commits and then withI found that by looking up how to undo a Git merge.",
                "The problem with all these solutions is that they are all either too complex or, an even bigger problem, is that they remove all untracked files from the webserver, which we don't want since there are always needed configuration files which are on the server and not in the Git repository.Here is the cleanest solution which we are using:The first command fetches the newest data.The second command checks if there are any files that are being added to the repository and deletes those untracked files from the local repository which would cause conflicts.The third command checks-out all the files which were locally modified.Finally, we do a pull to update to the newest version, but this time without any conflicts, since untracked files which are in the repo don't exist anymore and all the locally modified files are already the same as in the repository.",
                "First of all, try the standard way:Warning: Above commands can results in data/files loss only if you don't have them committed! If you're not sure, make the backup first of your whole repository folder.Then pull it again.If above won't help and you don't care about your untracked files/directories (make the backup first just in case), try the following simple steps:This will REMOVE all git files (excempt .git/ dir, where you have all commits) and pull it again.Why git reset HEAD --hard could fail in some cases?Custom rules in .gitattributes fileHaving eol=lf rule in .gitattributes could cause git to modify some file changes by converting CRLF line-endings into LF in some text files.If that's the case, you've to commit these CRLF/LF changes (by reviewing them in git status), or try: git config core.autcrlf false to temporary ignore them.File system incompabilityWhen you're using file-system which doesn't support permission attributes.\nIn example you have two repositories, one on Linux/Mac (ext3/hfs+) and another one on FAT32/NTFS based file-system.As you notice, there are two different kind of file systems, so the one which doesn't support Unix permissions basically can't reset file permissions on system which doesn't support that kind of permissions, so no matter how --hard you try, git always detect some \"changes\".",
                "I had the same problem. No one gave me this solution, but it worked for me.I solved it by:Now it works.",
                "In speaking of pull/fetch/merge in the previous answers, I would like to share an interesting and productive trick,This above command is the most useful command in my Git life which saved a lot of time.Before pushing your newly commit to server, try this command and it will automatically synchronise the latest server changes (with a fetch + merge) and will place your commit at the top in the Git log. There isn't any need to worry about manual pull/merge.Find details in What does \"git pull --rebase\" do?.",
                "Here is a generic solution if you do not always want to paste the branch name or you want to automate this within a scriptIf you want to reset your local changes too:You also could add a bash alias using this command:",
                "I had a similar problem.  I had to do this:",
                "I summarized other answers. You can execute git pull without errors:Warning: This script is very powerful, so you could lose your changes.",
                "Based on my own similar experiences, the solution offered by Strahinja Kustudic above is by far the best.  As others have pointed out, simply doing hard reset will remove all the untracked files which could include lots of things that you don't want removed, such as config files.  What is safer, is to remove only the files that are about to be added, and for that matter, you'd likely also want to checkout any locally-modified files that are about to be updated.That in mind, I updated Kustudic's script to do just that.  I also fixed a typo (a missing ' in the original).",
                "I had the same problem and for some reason, even a git clean -f -d would not do it. Here is why: For some reason, if your file is ignored by Git (via a .gitignore entry, I assume), it still bothers about overwriting this with a later pull, but a clean will not remove it, unless you add -x.",
                "I believe there are two possible causes of conflict, which must be solved separately, and as far as I can tell none of the above answers deals with both:Local files that are untracked need to be deleted, either manually (safer) or as suggested in other answers, by git clean -f -dLocal commits that are not on the remote branch need to be deleted as well. IMO the easiest way to achieve this is with: git reset --hard origin/master (replace 'master' by whatever branch you are working on, and run a git fetch origin first)",
                "It seems like most answers here are focused on the master branch; however, there are times when I'm working on the same feature branch in two different places and I want a rebase in one to be reflected in the other without a lot of jumping through hoops.Based on a combination of RNA's answer and torek's answer to a similar question, I've come up with this which works splendidly:Run this from a branch and it'll only reset your local branch to the upstream version.This can be nicely put into a git alias (git forcepull) as well:git config alias.forcepull \"!git fetch ; git reset --hard @{u}\"Or, in your .gitconfig file:Enjoy!",
                "An easier way would be to:This will override your local file with the file on git",
                "I just solved this myself by:where the last command gives a list of what your local changes were. Keep modifying the \"tmp\" branch until it is acceptable and then merge back onto master with:For next time, you can probably handle this in a cleaner way by looking up \"git stash branch\" though stash is likely to cause you trouble on the first few tries, so do first experiment on a non-critical project...",
                "I have a strange situation that neither git clean or git reset works. I have to remove the conflicting file from git index by using the following script on every untracked file:Then I am able to pull just fine.",
                "I know of a much easier and less painful method:That's it!",
                "I am not sure why anyone did not talk about FETCH_HEAD yet.If you want to put it in an alias, the command would be:",
                "Requirements:Solution:Fetch with a clean of files and directories ignoring .gitignore and hard reset to origin.",
                "Just doSo you avoid all unwanted side effects, like deleting files or directories you wanted to keep, etc.",
                "Despite the original question, the top answers can cause problems for people who have a similar problem, but don't want to lose their local files. For example, see Al-Punk and crizCraig's comments.The following version commits your local changes to a temporary branch (tmp), checks out the original branch (which I'm assuming is master) and merges the updates. You could do this with stash, but I've found it's usually easier to simply use the branch / merge approach.where we assume the other repository is origin master.",
                "Reset the index and the head to origin/master, but do not reset the working tree:"
            ]
        },
        {
            "tag": "html",
            "question": [
                "Why does HTML think \u201cchucknorris\u201d is a color?",
                "Why do certain random strings produce colors when entered as background colors in HTML?\nFor example, bgcolor=\"chucknorris\" produces a red background:\n\r\n\r\n<body bgcolor=\"chucknorris\"> ..."
            ],
            "url": "https://stackoverflow.com/questions/8318911",
            "answer": [
                "It\u2019s a holdover from the Netscape days:Missing digits are treated as 0[...]. An incorrect digit is simply interpreted as 0. For example the values #F0F0F0, F0F0F0, F0F0F, #FxFxFx and FxFxFx are all the same.It is from the blog post A little rant about Microsoft Internet Explorer's color parsing which covers it in great detail, including varying lengths of color values, etc.If we apply the rules in turn from the blog post, we get the following:Replace all nonvalid hexadecimal characters with 0\u2019s:Pad out to the next total number of characters divisible by\u00a03 (11\u00a0\u2192 12):Split into three equal groups, with each component representing the corresponding colour component of an RGB colour:Truncate each of the arguments from the right down to two characters.Which, finally, gives the following result:Here\u2019s an example demonstrating the bgcolor attribute in action, to produce this \u201camazing\u201d colour swatch:<table>\n  <tr>\n    <td bgcolor=\"chucknorris\" cellpadding=\"8\" width=\"100\" align=\"center\">chuck norris</td>\n    <td bgcolor=\"mrt\"         cellpadding=\"8\" width=\"100\" align=\"center\" style=\"color:#ffffff\">Mr T</td>\n    <td bgcolor=\"ninjaturtle\" cellpadding=\"8\" width=\"100\" align=\"center\" style=\"color:#ffffff\">ninjaturtle</td>\n  </tr>\n  <tr>\n    <td bgcolor=\"sick\"  cellpadding=\"8\" width=\"100\" align=\"center\">sick</td>\n    <td bgcolor=\"crap\"  cellpadding=\"8\" width=\"100\" align=\"center\">crap</td>\n    <td bgcolor=\"grass\" cellpadding=\"8\" width=\"100\" align=\"center\">grass</td>\n  </tr>\n</table>This also answers the other part of the question: Why does bgcolor=\"chucknorr\" produce a yellow colour? Well, if we apply the rules, the string is:Which gives a light yellow gold colour. As the string starts off as 9\u00a0characters, we keep the second\u00a0\u2018C\u2019 this time around, hence it ends up in the final colour value.I originally encountered this when someone pointed out that you could do color=\"crap\" and, well, it comes out brown.",
                "I'm sorry to disagree, but according to the rules for parsing a legacy color value posted by Yuhong Bao, chucknorris does not equate to #CC0000, but rather to #C00000, a very similar but slightly different hue of red. I used the Firefox ColorZilla add-on to verify this.The rules state:I was able to use these rules to correctly interpret the following strings:The original answerers who said the color was #CC0000 have since edited their answers to include the correction.",
                "The reason is the browser can not understand it and try to somehow translate it to what it can understand and in this case into a hexadecimal value!...chucknorris starts with c which is recognised character in hexadecimal, also it's converting all unrecognised characters into 0!So chucknorris in hexadecimal format becomes: c00c00000000, all other characters become 0 and c remains where they are...Now they get divided by 3 for RGB(red, green, blue)... R: c00c, G: 0000, B:0000...But we know valid hexadecimal for RGB is just 2 characters, means R: c0, G: 00, B:00So the real result is:I also added the steps in the image as a quick reference for you:",
                "Most browsers will simply ignore any non-hexadecimal values in your color string, substituting non-hexadecimal digits with zeros.ChuCknorris translates to c00c0000000.  At this point, the browser will divide the string into three equal sections, indicating Red, Green and Blue values: c00c 0000 0000.  Extra bits in each section will be ignored, which makes the final result #c00000 which is a reddish color.Note, this does not apply to CSS color parsing, which follow the CSS standard.<p><font color='chucknorris'>Redish</font></p>\n<p><font color='#c00000'>Same as above</font></p>\n<p><span style=\"color: chucknorris\">Black</span></p>",
                "The browser is trying to convert chucknorris into hexadecimal colour code, because it\u2019s not a valid value.This seems to be an issue primarily with Internet\u00a0Explorer and Opera\u00a0(12) as both Chrome\u00a0(31) and Firefox\u00a0(26) just ignore this.P.S. The numbers in brackets are the browser versions I tested on.Similarly, Rajnikanth (Indian Chuck Noris) converse to a shade of black:0a00 00a0 0000 => #0a0000On a lighter noteChuck Norris doesn\u2019t conform to web standards. Web standards conform\nto him. #BADA55",
                "The WHATWG HTML specification has the exact algorithm for parsing a legacy color value.The code Netscape Classic used for parsing color strings is open source: netscape/lib/layout/layimage.c.For example, notice that each character is parsed as a hex digit and then is shifted into a 32-bit integer without checking for overflow. Only eight hex digits fit into a 32-bit integer, which is why only the last 8 characters are considered. After parsing the hex digits into 32-bit integers, they are then truncated into 8-bit integers by dividing them by 16 until they fit into 8-bit, which is why leading zeros are ignored.This code does not exactly match what is defined in the spec, but the only difference there is a few lines of code. I think it is these lines that were added (in Netscape 4):",
                "chucknorris starts with c, and the browser reads it into a hexadecimal value.Because A, B, C, D, E, and F are characters in hexadecimal.The browser converts chucknorris to a hexadecimal value, C00C00000000.Then the C00C00000000 hexadecimal value is converted to RGB format (divided by 3):C00C00000000\u00a0\u21d2 R:C00C, G:0000, B:0000The browser needs only two digits to indicate the colour:R:C00C, G:0000, B:0000\u00a0\u21d2 R:C0, G:00, B:00\u00a0\u21d2 C00000Finally, show bgcolor = C00000 in the web browser.Here's an example demonstrating it:<table>\n  <tr>\n    <td bgcolor=\"chucknorris\" cellpadding=\"10\" width=\"150\" align=\"center\">chucknorris</td>\n    <td bgcolor=\"c00c00000000\" cellpadding=\"10\" width=\"150\" align=\"center\">c00c00000000</td>\n    <td bgcolor=\"c00000\" cellpadding=\"10\" width=\"150\" align=\"center\">c00000</td>\n  </tr>\n</table>",
                "The rules for parsing colors on legacy attributes involves additional steps than those mentioned in existing answers. The truncate component to 2 digits part is described as:Some examples:Below is a partial implementation of the algorithm. It does not handle errors or cases where the user enters a valid color.function parseColor(input) {\r\n  // todo: return error if input is \"\"\r\n  input = input.trim();\r\n  // todo: return error if input is \"transparent\"\r\n  // todo: return corresponding #rrggbb if input is a named color\r\n  // todo: return #rrggbb if input matches #rgb\r\n  // todo: replace unicode code points greater than U+FFFF with 00\r\n  if (input.length > 128) {\r\n    input = input.slice(0, 128);\r\n  }\r\n  if (input.charAt(0) === \"#\") {\r\n    input = input.slice(1);\r\n  }\r\n  input = input.replace(/[^0-9A-Fa-f]/g, \"0\");\r\n  while (input.length === 0 || input.length % 3 > 0) {\r\n    input += \"0\";\r\n  }\r\n  var r = input.slice(0, input.length / 3);\r\n  var g = input.slice(input.length / 3, input.length * 2 / 3);\r\n  var b = input.slice(input.length * 2 / 3);\r\n  if (r.length > 8) {\r\n    r = r.slice(-8);\r\n    g = g.slice(-8);\r\n    b = b.slice(-8);\r\n  }\r\n  while (r.length > 2 && r.charAt(0) === \"0\" && g.charAt(0) === \"0\" && b.charAt(0) === \"0\") {\r\n    r = r.slice(1);\r\n    g = g.slice(1);\r\n    b = b.slice(1);\r\n  }\r\n  if (r.length > 2) {\r\n    r = r.slice(0, 2);\r\n    g = g.slice(0, 2);\r\n    b = b.slice(0, 2);\r\n  }\r\n  return \"#\" + r.padStart(2, \"0\") + g.padStart(2, \"0\") + b.padStart(2, \"0\");\r\n}\r\n\r\n$(function() {\r\n  $(\"#input\").on(\"change\", function() {\r\n    var input = $(this).val();\r\n    var color = parseColor(input);\r\n    var $cells = $(\"#result tbody td\");\r\n    $cells.eq(0).attr(\"bgcolor\", input);\r\n    $cells.eq(1).attr(\"bgcolor\", color);\r\n\r\n    var color1 = $cells.eq(0).css(\"background-color\");\r\n    var color2 = $cells.eq(1).css(\"background-color\");\r\n    $cells.eq(2).empty().append(\"bgcolor: \" + input, \"<br>\", \"getComputedStyle: \" + color1);\r\n    $cells.eq(3).empty().append(\"bgcolor: \" + color, \"<br>\", \"getComputedStyle: \" + color2);\r\n  });\r\n});\nbody { font: medium monospace; }\r\ninput { width: 20em; }\r\ntable { table-layout: fixed; width: 100%; }\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js\"></script>\r\n\r\n<p><input id=\"input\" placeholder=\"Enter color e.g. chucknorris\"></p>\r\n<table id=\"result\">\r\n  <thead>\r\n    <tr>\r\n      <th>Left Color</th>\r\n      <th>Right Color</th>\r\n    </tr>\r\n  </thead>\r\n  <tbody>\r\n    <tr>\r\n      <td>&nbsp;</td>\r\n      <td>&nbsp;</td>\r\n    </tr>\r\n    <tr>\r\n      <td>&nbsp;</td>\r\n      <td>&nbsp;</td>\r\n    </tr>\r\n  </tbody>\r\n</table>"
            ]
        },
        {
            "tag": "javascript",
            "question": [
                "How do I check if an element is hidden in jQuery?",
                "How do I toggle the visibility of an element using  .hide(), .show(), or .toggle()?\nHow do I test if an element is visible or hidden?"
            ],
            "url": "https://stackoverflow.com/questions/178325",
            "answer": [
                "Since the question refers to a single element, this code might be more suitable:It is the same as twernt's suggestion, but applied to a single element; and it matches the algorithm recommended in the jQuery FAQ.We use jQuery's is() to check the selected element with another element, selector or any jQuery object. This method traverses along the DOM elements to find a match, which satisfies the passed parameter. It will return true if there is a match, otherwise return false.",
                "You can use the hidden selector:And the visible selector:",
                "The above method does not consider the visibility of the parent. To consider the parent as well, you should use .is(\":hidden\") or .is(\":visible\").For example,The above method will consider div2 visible while :visible not. But the above might be useful in many cases, especially when you need to find if there is any error divs visible in the hidden parent because in such conditions :visible will not work.",
                "None of these answers address what I understand to be the question, which is what I was searching for, \"How do I handle items that have visibility: hidden?\". Neither :visible nor :hidden will handle this, as they are both looking for display per the documentation.  As far as I could determine, there is no selector to handle CSS visibility.  Here is how I resolved it (standard jQuery selectors, there may be a more condensed syntax):",
                "From How do I determine the state of a toggled element?You can determine whether an element is collapsed or not by using the :visible and :hidden selectors.If you're simply acting on an element based on its visibility, you can just include :visible or :hidden in the selector expression. For example:",
                "Often when checking if something is visible or not, you are going to go right ahead immediately and do something else with it. jQuery chaining makes this easy.So if you have a selector and you want to perform some action on it only if is visible or hidden, you can use filter(\":visible\") or filter(\":hidden\") followed by chaining it with the action you want to take.So instead of an if statement, like this:Or more efficient, but even uglier:You can do it all in one line:",
                "The :visible selector according to the jQuery documentation:Elements with visibility: hidden or opacity: 0 are considered to be visible, since they still consume space in the layout.This is useful in some cases and useless in others, because if you want to check if the element is visible (display != none), ignoring the parents visibility, you will find that doing .css(\"display\") == 'none' is not only faster, but will also return the visibility check correctly.If you want to check visibility instead of display, you should use: .css(\"visibility\") == \"hidden\".Also take into consideration the additional jQuery notes:Because :visible is a jQuery extension and not part of the CSS specification, queries using :visible cannot take advantage of the performance boost provided by the native DOM querySelectorAll() method. To achieve the best performance when using :visible to select elements, first select the elements using a pure CSS selector, then use .filter(\":visible\").Also, if you are concerned about performance, you should check Now you see me\u2026 show/hide performance (2010-05-04). And use other methods to show and hide elements.",
                "How element visibility and jQuery works;An element could be hidden with display:none, visibility:hidden or opacity:0. The difference between those methods:opacity:0 hides the element as \"visibility:hidden\", and it still takes up space in the layout; the only difference is that opacity lets one to make an element partly transparent;Useful jQuery toggle methods:",
                "This works for me, and I am using show() and hide() to make my div hidden/visible:",
                "You can also do this using plain JavaScript:Notes:Works everywhereWorks for nested elementsWorks for CSS and inline stylesDoesn't require a framework",
                "I would use CSS class .hide { display: none!important; }.For hiding/showing, I call .addClass(\"hide\")/.removeClass(\"hide\"). For checking visibility, I use .hasClass(\"hide\").It's a simple and clear way to check/hide/show elements, if you don't plan to use .toggle() or .animate() methods.",
                "Demo Link$('#clickme').click(function() {\n  $('#book').toggle('slow', function() {\n    // Animation complete.\n    alert($('#book').is(\":visible\")); //<--- TRUE if Visible False if Hidden\n  });\n});\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<div id=\"clickme\">\n  Click here\n</div>\n<img id=\"book\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/87/Google_Chrome_icon_%282011%29.png\" alt=\"\" width=\"300\"/>Source (from my blog):Blogger Plug n Play - jQuery Tools and Widgets: How to See if Element is hidden or Visible Using jQuery",
                "ebdiv should be set to style=\"display:none;\". It works for both show and hide:",
                "One can simply use the hidden or visible attribute, like:Or you can simplify the same with is as follows.",
                "Another answer you should put into consideration is if you are hiding an element, you should use jQuery, but instead of actually hiding it, you remove the whole element, but you copy its HTML content and the tag itself into a jQuery variable, and then all you need to do is test if there is such a tag on the screen, using the normal if (!$('#thetagname').length).",
                "When testing an element against :hidden selector in jQuery it should be considered that an absolute positioned element may be recognized as hidden although their child elements are visible.This seems somewhat counter-intuitive in the first place \u2013 though having a closer look at the jQuery documentation gives the relevant information:Elements can be considered hidden for several reasons: [...] Their width and height are explicitly set to 0. [...]So this actually makes sense in regards to the box-model and the computed style for the element. Even if width and height are not set explicitly to 0 they may be set implicitly.Have a look at the following example:console.log($('.foo').is(':hidden')); // true\r\nconsole.log($('.bar').is(':hidden')); // false\n.foo {\r\n  position: absolute;\r\n  left: 10px;\r\n  top: 10px;\r\n  background: #ff0000;\r\n}\r\n\r\n.bar {\r\n  position: absolute;\r\n  left: 10px;\r\n  top: 10px;\r\n  width: 20px;\r\n  height: 20px;\r\n  background: #0000ff;\r\n}\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\r\n<div class=\"foo\">\r\n  <div class=\"bar\"></div>\r\n</div>Update for jQuery 3.x:With jQuery 3 the described behavior will change! Elements will be considered visible if they have any layout boxes, including those of zero width and/or height.JSFiddle with jQuery 3.0.0-alpha1:http://jsfiddle.net/pM2q3/7/The same JavaScript code will then have this output:",
                "$(document).ready(function() {\n  if ($(\"#checkme:hidden\").length) {\n    console.log('Hidden');\n  }\n});\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<div id=\"checkme\" class=\"product\" style=\"display:none\">\n  <span class=\"itemlist\"><!-- Shows Results for Fish --></span> Category:Fish\n  <br>Product: Salmon Atlantic\n  <br>Specie: Salmo salar\n  <br>Form: Steaks\n</div>",
                "To check if it is not visible I use !:Or the following is also the sam, saving the jQuery selector in a variable to have better performance when you need it multiple times:",
                "Using classes designated for \"hiding\" elements is easy and also one of the most efficient methods. Toggling a class 'hidden' with a Display style of 'none' will perform faster than editing that style directly. I explained some of this pretty thoroughly in Stack Overflow question Turning two elements visible/hidden in the same div.Here is a truly enlightening video of a Google Tech Talk by Google front-end engineer Nicholas Zakas:",
                "After all, none of examples suits me, so I wrote my own.Tests (no support of Internet\u00a0Explorer filter:alpha):a) Check if the document is not hiddenb) Check if an element has zero width / height / opacity or display:none / visibility:hidden in inline stylesc) Check if the center (also because it is faster than testing every pixel / corner) of element is not hidden by other element (and all ancestors, example: overflow:hidden / scroll / one element over another) or screen edgesd) Check if an element has zero width / height / opacity or display:none / visibility:hidden in computed styles (among all ancestors)Tested onAndroid 4.4 (Native browser/Chrome/Firefox), Firefox (Windows/Mac), Chrome (Windows/Mac), Opera (Windows Presto/Mac WebKit), Internet\u00a0Explorer (Internet\u00a0Explorer 5-11 document modes + Internet\u00a0Explorer 8 on a virtual machine), and Safari (Windows/Mac/iOS).How to use:",
                "Example of using the visible check for adblocker is activated:$(document).ready(function(){\r\n  if(!$(\"#ablockercheck\").is(\":visible\"))\r\n    $(\"#ablockermsg\").text(\"Please disable adblocker.\").show();\r\n});\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\r\n<div class=\"ad-placement\" id=\"ablockercheck\"></div>\r\n<div id=\"ablockermsg\" style=\"display: none\"></div>\"ablockercheck\" is a ID which adblocker blocks. So checking it if it is visible you are able to detect if adblocker is turned On.",
                "You need to check both... Display as well as visibility:If we check for $(this).is(\":visible\"), jQuery checks for both the things automatically.",
                "$(document).ready(function() {\n   var visible = $('#tElement').is(':visible');\n\n   if(visible) {\n      alert(\"visible\");\n                    // Code\n   }\n   else\n   {\n      alert(\"hidden\");\n   }\n});\n<script src=\"https://code.jquery.com/jquery-1.10.2.js\"></script>\n\n<input type=\"text\" id=\"tElement\" style=\"display:block;\">Firstname</input>",
                "Simply check visibility by checking for a boolean value, like:I used this code for each function. Otherwise you can use is(':visible') for checking the visibility of an element.",
                "Because Elements with visibility: hidden or opacity: 0 are considered visible, since they still consume space in the layout (as described for jQuery :visible Selector) - we can check if element is really visible in this way:",
                "But what if the element's CSS is like the following?So this answer to Stack Overflow question How to check if an element is off-screen should also be considered.",
                "A function can be created in order to check for visibility/display attributes in order to gauge whether the element is shown in the UI or not.Working Fiddle",
                "Also here's a ternary conditional expression to check the state of the element and then to toggle it:"
            ]
        },
        {
            "tag": "javascript",
            "question": [
                "What does \"use strict\" do in JavaScript, and what is the reasoning behind it?",
                "Recently, I ran some of my JavaScript code through Crockford's JSLint, and it gave the following error:\n\nProblem at line 1 character 1: Missing \"use strict\" statement.\n\nDoing some searching, ..."
            ],
            "url": "https://stackoverflow.com/questions/1335851",
            "answer": [
                "Inside native ECMAScript modules (with import and export statements) and ES6 classes, strict mode is always enabled and cannot be disabled.This article about Javascript Strict Mode might interest you: John Resig - ECMAScript 5 Strict Mode, JSON, and MoreTo quote some interesting parts:Strict Mode is a new feature in ECMAScript 5 that allows you to place a program, or a function, in a \"strict\" operating context. This strict context prevents certain actions from being taken and throws more exceptions.And:Strict mode helps out in a couple ways:Also note you can apply \"strict mode\" to the whole file... Or you can use it only for a specific function (still quoting from John Resig's article):Which might be helpful if you have to mix old and new code ;-)So, I suppose it's a bit like the \"use strict\" you can use in Perl (hence the name?): it helps you make fewer errors, by detecting more things that could lead to breakages.Strict mode is now supported by all major browsers.",
                "It's a new feature of ECMAScript 5. John Resig wrote up a nice summary of it.It's just a string you put in your JavaScript files (either at the top of your file or inside of a function) that looks like this:Putting it in your code now shouldn't cause any problems with current browsers as it's just a string. It may cause problems with your code in the future if your code violates the pragma.  For instance, if you currently have foo = \"bar\" without defining foo first, your code will start failing...which is a good thing in my opinion.",
                "The statement \"use strict\";  instructs the browser to use the Strict mode, which is a reduced and safer feature set of JavaScript.Disallows global variables. (Catches missing var declarations and typos in variable names)Silent failing assignments will throw error in strict mode (assigning NaN = 5;)Attempts to delete undeletable properties will throw (delete Object.prototype)Requires all property names in an object literal to be unique (var x = {x1: \"1\", x1: \"2\"})Function parameter names must be unique (function sum (x, x) {...})Forbids octal syntax (var x = 023; some devs assume wrongly that a preceding zero does nothing to change the number.)Forbids the with keywordeval in strict mode does not introduce new variablesForbids deleting plain names (delete x;)Forbids binding or assignment of the names eval and arguments in any formStrict mode does not alias properties of the arguments object with the formal parameters. (e.g. in function sum (a,b) { return arguments[0] + b;} This works because arguments[0] is bound to a and so on. ) (See examples section below to understand the difference)arguments.callee is not supported[Ref: Strict mode, Mozilla Developer Network]Examples:",
                "If people are worried about using use strict it might be worth checking out this article:ECMAScript 5 'Strict mode' support in browsers. What does this mean?\nNovoGeek.com - Krishna's weblogIt talks about browser support, but more importantly how to deal with it safely:",
                "A word of caution, all you hard-charging programmers:  applying \"use strict\" to existing code can be hazardous!  This thing is not some feel-good, happy-face sticker that you can slap on the code to make it 'better'.  With the \"use strict\" pragma, the browser will suddenly THROW exceptions in random places that it never threw before just because at that spot you are doing something that default/loose JavaScript happily allows but strict JavaScript abhors!  You may have strictness violations hiding in seldom used calls in your code that will only throw an exception when they do eventually get run - say, in the production environment that your paying customers use!If you are going to take the plunge, it is a good idea to apply \"use strict\" alongside comprehensive unit tests and a strictly configured JSHint build task that will give you some confidence that there is no dark corner of your module that will blow up horribly just because you've turned on Strict Mode.  Or, hey, here's another option:  just don't add \"use strict\" to any of your legacy code, it's probably safer that way, honestly.  DEFINITELY DO NOT add \"use strict\" to any modules you do not own or maintain, like third party modules.I think even though it is a deadly caged animal, \"use strict\" can be good stuff, but you have to do it right.  The best time to go strict is when your project is greenfield and you are starting from scratch. Configure JSHint/JSLint with all the warnings and options cranked up as tight as your team can stomach, get a good build/test/assert system du jour rigged like Grunt+Karma+Chai, and only THEN start marking all your new modules as \"use strict\".  Be prepared to cure lots of niggly errors and warnings.  Make sure everyone understands the gravity by configuring the build to FAIL if JSHint/JSLint produces any violations.My project was not a greenfield project when I adopted \"use strict\".  As a result, my IDE is full of red marks because I don't have \"use strict\" on half my modules, and JSHint complains about that.  It's a reminder to me about what refactoring I should do in the future.  My goal is to be red mark free due to all of my missing \"use strict\" statements, but that is years away now.",
                "The JavaScript strict mode is a feature in ECMAScript 5. You can enable the strict mode by declaring this in the top of your script/function.When a JavaScript engine sees this directive, it will start to interpret the code in a special mode. In this mode, errors are thrown up when certain coding practices that could end up being potential bugs are detected (which is the reasoning behind the strict mode).Consider this example:In their obsession to line up the numeric literals, the developer has inadvertently initialized variable b with an octal literal. Non-strict mode will interpret this as a numeric literal with value 24 (in base 10). However, strict mode will throw an error.For a non-exhaustive list of specialties in strict mode, see this answer.In my new JavaScript application: Absolutely! Strict mode can be used as a whistleblower when you are doing something stupid with your code.In my existing JavaScript code: Probably not! If your existing JavaScript code has statements that are prohibited in strict-mode, the application will simply break. If you want strict mode, you should be prepared to debug and correct your existing code. This is why using 'use strict'; does not suddenly make your code better.Insert a 'use strict'; statement on top of your script:Note that everything in the file myscript.js will be interpreted in strict mode.Or, insert a 'use strict'; statement on top of your function body:Everything in the lexical scope of function doSomething will be interpreted in strict mode. The word lexical scope is important here. For example, if your strict code calls a function of a library that is not strict, only your code is executed in strict mode, and not the called function. See this answer for a better explanation.I found a nice article describing several things that are prohibited in strict mode (note that this is not an exhaustive list):Historically, JavaScript has been confused about how functions\nare scoped. Sometimes they seem to be statically scoped, but some\nfeatures make them behave like they are dynamically scoped. This is\nconfusing, making programs difficult to read and understand.\nMisunderstanding causes bugs. It also is a problem for performance.\nStatic scoping would permit variable binding to happen at compile\ntime, but the requirement for dynamic scope means the binding must be\ndeferred to runtime, which comes with a significant performance\npenalty.Strict mode requires that all variable binding be done statically.\nThat means that the features that previously required dynamic binding\nmust be eliminated or modified. Specifically, the with statement is\neliminated, and the eval function\u2019s ability to tamper with the\nenvironment of its caller is severely restricted.One of the benefits of strict code is that tools like YUI Compressor\ncan do a better job when processing it.JavaScript has implied global variables. If\nyou do not explicitly declare a variable, a global variable is\nimplicitly declared for you. This makes programming easier for\nbeginners because they can neglect some of their basic housekeeping\nchores. But it makes the management of larger programs much more\ndifficult and it significantly degrades reliability. So in strict\nmode, implied global variables are no longer created. You should\nexplicitly declare all of your variables.There are a number of situations that could cause this\nto be bound to the global object. For example, if you forget to\nprovide the new prefix when calling a constructor function, the\nconstructor's this will be bound unexpectedly to the global object, so\ninstead of initializing a new object, it will instead be silently\ntampering with global variables. In these situations, strict mode will\ninstead bind this to undefined, which will cause the constructor to\nthrow an exception instead, allowing the error to be detected much\nsooner.JavaScript has always had read-only properties, but you\ncould not create them yourself until ES5\u2019s Object.createProperty\nfunction exposed that capability. If you attempted to assign a value\nto a read-only property, it would fail silently. The assignment would\nnot change the property\u2019s value, but your program would proceed as\nthough it had. This is an integrity hazard that can cause programs to\ngo into an inconsistent state. In strict mode, attempting to change a\nread-only property will throw an exception.The octal (or base 8) representation of numbers was extremely\nuseful when doing machine-level programming on machines whose word\nsizes were a multiple of 3. You needed octal when working with the CDC\n6600 mainframe, which had a word size of 60 bits. If you could read\noctal, you could look at a word as 20 digits. Two digits represented\nthe op code, and one digit identified one of 8 registers. During the\nslow transition from machine codes to high level languages, it was\nthought to be useful to provide octal forms in programming languages.In C, an extremely unfortunate representation of octalness was\nselected: Leading zero. So in C, 0100 means 64, not 100, and 08 is an\nerror, not 8. Even more unfortunately, this anachronism has been\ncopied into nearly all modern languages, including JavaScript, where\nit is only used to create errors. It has no other purpose. So in\nstrict mode, octal forms are no longer allowed.The arguments pseudo array becomes a little bit more\narray-like in ES5. In strict mode, it loses its callee and caller\nproperties. This makes it possible to pass your arguments to untrusted\ncode without giving up a lot of confidential context. Also, the\narguments property of functions is eliminated.In strict mode, duplicate keys in a function literal will produce a\nsyntax error. A function can\u2019t have two parameters with the same name.\nA function can\u2019t have a variable with the same name as one of its\nparameters. A function can\u2019t delete its own variables. An attempt to\ndelete a non-configurable property now throws an exception. Primitive\nvalues are not implicitly wrapped.ECMAScript 5 adds a list of reserved words. If you use them as variables or arguments, strict mode will throw an error. The reserved words are:implements, interface, let, package, private, protected, public, static, and yield",
                "I strongly recommend every developer to start using strict mode now. There are enough browsers supporting it that strict mode will legitimately help save us from errors we didn\u2019t even know were in your code.Apparently, at the initial stage there will be errors we have never encountered before. To get the full benefit, we need to do proper testing after switching to strict mode to make sure we have caught everything. Definitely we don\u2019t just throw use strict in our code and assume there are no errors. So the churn is that it\u2019s time to start using this incredibly useful language feature to write better code.For example,JSLint is a debugger written by Douglas Crockford. Simply paste in your script, and it\u2019ll quickly scan for any noticeable issues and errors in your code.",
                "I would like to offer a somewhat more founded answer complementing the other answers. I was hoping to edit the most popular answer, but failed. I tried to make it as comprehensive and complete as I could.You can refer to the MDN documentation for more information.\"use strict\" a directive introduced in ECMAScript 5.Directives are similar to statements, yet different.The use strict directive indicates that the following code (in a script or a function) is strict code.\nThe code in the highest level of a script (code that is not in a function) is considered strict code when the script contains a use strict directive.\nThe content of a function is considered strict code when the function itself is defined in a strict code or when the function contains a use strict directive.\nCode that is passed to an eval() method is considered strict code when eval() was called from a strict code or contains the use strict directive itself.The strict mode of ECMAScript 5 is a restricted subset of the JavaScript language, which eliminates relevant deficits of the language and features more stringent error checking and higher security. The following lists the differences between strict mode and normal mode (of which the first three are particularly important):Also when a function is invoked with call() or apply in strict mode, then this is exactly the value of the first argument of the call()or apply() invocation. (In normal mode null and undefined are replaced by the global Object and values, which are not objects, are cast into objects.)In strict mode you will get a TypeError, when you try to assign to readonly properties or to define new properties for a non extensible object. (In normal mode both simply fail without error message.)In strict mode, when passing code to eval(), you cannot declare or define variables or functions in the scope of the caller (as you can do it in normal mode). Instead, a new scope is created for eval() and the variables and functions are within that scope. That scope is destroyed after eval() finishes execution.In strict mode the arguments-object of a function contains a static copy of the values, which are passed to that function. In normal mode the arguments-object has a somewhat \"magical\" behaviour: The elements of the array and the named function parameters reference both the same value.In strict mode you will get a SyntaxError when the delete operator is followed by a non qualified identifier (a variable, function or function parameter). In normal mode the delete expression would do nothing and is evaluated to false.In strict mode you will get a TypeError when you try to delete a non configurable property. (In normal mode the attempt simply fails and the delete expression is evaluated to false).In strict mode it is considered a syntactical error when you try to define several properties with the same name for an object literal. (In normal mode there is no error.)In strict mode it is considered a syntactical error when a function declaration has multiple parameters with the same name. (In normal mode there is no error.)In strict mode octal literals are not allowed (these are literals that start with 0. (In normal mode some implementations do allow octal literals.)In strict mode the identifiers eval and arguments are treated like keywords. You cannot change their value, cannot assign a value to them, and you cannot use them as names for variables, functions, function parameters or identifiers of a catch block.In strict mode are more restrictions on the possibilities to examine the call stack. arguments.caller and arguments.callee cause a TypeError in a function in strict mode. Furthermore, some caller- and arguments properties of functions in strict mode cause a TypeError when you try to read them.",
                "My two cents:One of the goals of strict mode is to allow for faster debugging of issues. It helps the developers by throwing exception when certain wrong things occur that can cause silent & strange behaviour of your webpage. The moment we use  use strict, the code will throw out errors which helps developer to fix it in advance.Few important things which I have learned after using  use strict :Prevents Global Variable Declaration:\"use strict\";\nvar tree1Data = { name: 'Banana Tree',age: 100,leafCount: 100000};\n\nfunction Tree(typeOfTree) {\n    var age;\n    var leafCount;\n\n    age = typeOfTree.age;\n    leafCount = typeOfTree.leafCount;\n    nameoftree = typeOfTree.name;\n};\n\nvar tree1 = new Tree(tree1Data);\nconsole.log(window);Now,this code creates nameoftree in global scope which could be accessed using window.nameoftree. When we implement use strict the code would throw error.Uncaught ReferenceError: nameoftree is not definedEliminates with statement :with statements can't be minified using tools like uglify-js. They're also deprecated and removed from future JavaScript versions.Sample:\"use strict\";\nvar tree1Data = {\n    name: 'Banana Tree',\n    age: 100,\n    leafCount: 100000\n};\n\nfunction Tree(typeOfTree) {\n    var age;\n    var leafCount;\n\n    age = typeOfTree.age;\n    leafCount = typeOfTree.leafCount;\n   // nameoftree = typeOfTree.name;\n\n    for (var i = 0; i < 2; ++i) {\n       // let(leafCount = i) { /*do something*/ }\n    }\n    for (var i = 0; i < 2; ++i) {\n        with(leafCount = i) { /*do something*/ }\n    }\n};\n\nvar tree1 = new Tree(tree1Data);\nconsole.log(window);Prevents Duplicates :When we have duplicate property, it throws an exceptionUncaught SyntaxError: Duplicate data property in object literal not\nallowed in strict mode\"use strict\";\nvar tree1Data = {\n    name: 'Banana Tree',\n    age: 100,\n    leafCount: 100000,\n    name:'Banana Tree'\n};There are few more but I need to gain more knowledge on that.",
                "If you use a browser released in the last year or so then it most likely supports JavaScript Strict mode. Only older browsers around before ECMAScript 5 became the current standard don't support it.The quotes around the command make sure that the code will still work in older browsers as well (although the things that generate a syntax error in strict mode will generally just cause the script to malfunction in some hard to detect way in those older browsers).",
                "When adding \"use strict\";, the following cases will throw a SyntaxError before the script is executing:Paving the way for future ECMAScript versions, using one of the newly reserved keywords (in prevision for ECMAScript 6): implements, interface, let, package, private, protected, public, static, and yield.Declaring function in blocksOctal syntaxthis point to the global object.Declaring twice the same name for a property name in an object literalThis is no longer the case in ECMAScript 6 (bug 1041128).Declaring two function arguments with the same name functionSetting a value to an undeclared variableUsing delete on a variable name delete myVariable;Using eval or arguments as variable or function argument nameSources:Transitioning to strict mode on MDNStrict mode on MDNJavaScript\u2019s Strict Mode and Why You Should Use It on Colin J. Ihrig's blog (archived version)",
                "Strict mode makes several changes to normal JavaScript semantics:eliminates some JavaScript silent errors by changing them\nto throw errors.fixes mistakes that make it difficult for JavaScript\nengines to perform optimizations.prohibits some syntax likely to be defined in future\nversions of ECMAScript.for more information vistit Strict Mode- Javascript",
                "\"Use Strict\"; is an insurance that programmer will not use the loose or the bad properties of JavaScript. It is a guide, just like a ruler will help you make straight lines. \"Use Strict\" will help you do \"Straight coding\".Those that prefer not to use rulers to do their lines straight usually end up in those pages asking for others to debug their code.Believe me. The overhead is negligible compared to poorly designed code. Doug Crockford, who has been a senior JavaScript developer for several years, has a very interesting post here. Personally, I like to return to his site all the time to make sure I don't forget my good practice.Modern JavaScript practice should always evoke the \"Use Strict\"; pragma. The only reason that the ECMA Group has made the \"Strict\" mode optional is to permit less experienced coders access to JavaScript and give then time to adapt to the new and safer coding practices.",
                "Including use strict in the beginning of your all sensitive JavaScript files from this point is a small way to be a better JavaScript programmer and avoid random variables becoming global and things change silently.",
                "Quoting from w3schools:The \"use strict\" directive is new in JavaScript 1.8.5 (ECMAScript\n  version 5).It is not a statement, but a literal expression, ignored by earlier\n  versions of JavaScript.The purpose of \"use strict\" is to indicate that the code should be\n  executed in \"strict mode\".With strict mode, you can not, for example, use undeclared variables.Strict mode makes it easier to write \"secure\" JavaScript.Strict mode changes previously accepted \"bad syntax\" into real errors.As an example, in normal JavaScript, mistyping a variable name creates\n  a new global variable. In strict mode, this will throw an error,\n  making it impossible to accidentally create a global variable.In normal JavaScript, a developer will not receive any error feedback\n  assigning values to non-writable properties.In strict mode, any assignment to a non-writable property, a\n  getter-only property, a non-existing property, a non-existing\n  variable, or a non-existing object, will throw an error.Please refer to http://www.w3schools.com/js/js_strict.asp to know more",
                "\"use strict\" makes JavaScript code to run in strict mode, which basically means everything needs to be defined before use. The main reason for using strict mode is to avoid accidental global uses of undefined methods.Also in strict mode, things run faster, some warnings or silent warnings throw fatal errors, it's better to always use it to make a neater code.\"use strict\" is widely needed to be used in ECMA5, in ECMA6 it's part of JavaScript by default, so it doesn't need to be added if you're using ES6.Look at these statements and examples from MDN:The \"use strict\" Directive The \"use strict\" directive is new in\n  JavaScript 1.8.5 (ECMAScript version 5). It is not a statement, but a\n  literal expression, ignored by earlier versions of JavaScript. The\n  purpose of \"use strict\" is to indicate that the code should be\n  executed in \"strict mode\". With strict mode, you can not, for example,\n  use undeclared variables.Examples of using \"use strict\":\n  Strict mode for functions: Likewise, to invoke strict mode for a\n  function, put the exact statement \"use strict\"; (or 'use strict';) in\n  the function's body before any other statements.1) strict mode in functions2) whole-script strict mode3) Assignment to a non-writable globalYou can read more on MDN.",
                "There's a good talk by some people who were on the ECMAScript committee: Changes to JavaScript, Part 1: ECMAScript 5\" about how incremental use of the \"use strict\" switch allows JavaScript implementers to clean up a lot of the dangerous features of JavaScript without suddenly breaking every website in the world.Of course it also talks about just what a lot of those misfeatures are (were) and how ECMAScript 5 fixes them.",
                "Small examples to compare:Non-strict mode:for (i of [1,2,3]) console.log(i)\r\n    \r\n// output:\r\n// 1\r\n// 2\r\n// 3Strict mode:'use strict';\r\nfor (i of [1,2,3]) console.log(i)\r\n\r\n// output:\r\n// Uncaught ReferenceError: i is not definedNon-strict mode:String.prototype.test = function () {\r\n  console.log(typeof this === 'string');\r\n};\r\n\r\n'a'.test();\r\n\r\n// output\r\n// falseString.prototype.test = function () {\r\n  'use strict';\r\n  \r\n  console.log(typeof this === 'string');\r\n};\r\n\r\n'a'.test();\r\n\r\n// output\r\n// true",
                "Note that use strict was introduced in EcmaScript 5 and was kept since then.Below are the conditions to trigger strict mode in ES6 and ES7:",
                "The main reasons why developers should use \"use strict\" are:Prevents accidental declaration of global variables.Using \"use strict()\" will make sure that variables are declared with var before use. \nEg:The string \"arguments\" cannot be used as a variable:Will restrict uses of keywords as variables. Trying to use them will throw errors.In short will make your code less error prone and in turn will make you write good code.To read more about it you can refer here.",
                "use strict is a way to make your code safer, because you can't use dangerous features that can work not as you expect. And, as was written before, it makes code more strict.",
                "JavaScript \u201cstrict\u201d mode was introduced in ECMAScript 5.Writing \"use strict\"; at the very top of your JS file turns on strict\nsyntax checking. It does the following tasks for us:shows an error if you try to assign to an undeclared variablestops you from overwriting key JS system librariesforbids some unsafe or error-prone language featuresuse strict also works inside of individual functions. It is always a better practice to include use strict in your code.Browser compatibility issue: \nThe \"use\" directives are meant to be backwards-compatible. Browsers that do not support them will just see a string literal that isn't referenced further. So, they will pass over it and move on.",
                "\"use strict\"; is the ECMA effort to make JavaScript a little bit more robust. It brings in JS an attempt to make it at least a little \"strict\" (other languages implement strict rules since the 90s). It actually \"forces\" JavaScript developers to follow some sort of coding best practices.\nStill, JavaScript is very fragile. There is no such thing as typed variables, typed methods, etc.\nI strongly recommend JavaScript developers to learn a more robust language such as Java or ActionScript3, and implement the same best practices in your JavaScript code, it will work better and be easier to debug.",
                "Normally, JavaScript does not follow strict rules, hence increasing chances of errors. After using \"use strict\", the JavaScript code should follow strict set of rules as in other programming languages such as use of terminators, declaration before initialization, etc.If \"use strict\" is used, the code should be written by following a strict set of rules, hence decreasing the chances of errors and ambiguities.",
                "Use Strict is used to show common and repeated errors so that it is handled differently , and changes the way java script runs , such changes are :Prevents accidental globalsNo duplicatesEliminates withEliminates this coercionSafer eval()Errors for immutablesyou can also read this article for the details",
                "\"use strict\"; Defines that JavaScript code should be executed in\n   \"strict mode\".All modern browsers support \"use strict\" except Internet Explorer 9 and lower.DisadvantageIf a developer used a library that was in strict mode, but the developer was used to working in normal mode, they might call some actions on the library that wouldn\u2019t work as expected.Worse, since the developer is in normal mode, they don\u2019t have the advantages of extra errors being thrown, so the error might fail silently.Also, as listed above, strict mode stops you from doing certain things.People generally think that you shouldn\u2019t use those things in the first place, but some developers don\u2019t like the constraint and want to use all the features of the language.For basic example and for reference go through :https://www.tutorialsteacher.com/javascript/javascript-strict",
                "JavaScript was designed and implemented hastily because of the browser wars and bad management. As a result many poor design decisions, un-intuitive syntax and confusing semantics found their way into the language. Strict mode aims to amend some of these mistakes.But fixing these mistakes without creating alternative interpretation breaks backward compatibility. So, \"use strict\" directive creates that alternative interpretation of the code while communicating it to the programmer.For example, this keywords refers to the object in a method definition, like this or self in other languages.this has no purpose outside the method context but all JavaScript functions have this keyword whether they are methods or not:Here this resolves to the global object which does not make sense and serves no purpose because global object is already available in the scope.In strict mode this in a global function resolves to undefined, which is what we expect.Some mistakes can not be fixed even in strict mode because syntax should be valid for older browsers since they ignore \"strict mode\" directive. This is by design.",
                "Strict mode can prevent memory leaks.Please check the function below written in non-strict mode:In this function, we are using a variable called name inside the function. Internally, the compiler will first check if there is any variable declared with that particular name in that particular function scope. Since the compiler understood that there is no such variable, it will check in the outer scope. In our case, it is the global scope. Again, the compiler understood that there is also no variable declared in the global space with that name, so it creates such a variable for us in the global space. Conceptually, this variable will be created in the global scope and will be available in the entire application.Another scenario is that, say, the variable is declared in a child function. In that case, the compiler checks the validity of that variable in the outer scope, i.e., the parent function. Only then it will check in the global space and create a variable for us there.\nThat means additional checks need to be done. This will affect the performance of the application.Now let's write the same function in strict mode.We will get the following error.Here, the compiler throws the reference error. In strict mode, the compiler does not allow us to use the variable without declaring it. So memory leaks can be prevented. In addition, we can write more optimized code.",
                "Strict mode eliminates errors that would be ignored in non-strict mode, thus making javascript \u201cmore secured\u201d.Is it considered among best practices?Yes, It's considered part of the best practices while working with javascript to include Strict mode. This is done by adding the below line of code in your JS file.'use strict';in your code.What does it mean to user agents?Indicating that code should be interpreted in strict mode specifies to user agents like browsers that they should treat code literally as written, and throw an error if the code doesn't make sense.For example: Consider in your .js file you have the following code:Scenario 1: [NO STRICT MODE]Scenario 2: [NO STRICT MODE]So why does the variable name is being printed in both cases?Without strict mode turned on, user agents often go through a series of modifications to problematic code in an attempt to get it to make sense. On the surface, this can seem like a fine thing, and indeed, working outside of strict mode makes it possible for people to get their feet wet with JavaScript code without having all the details quite nailed down. However, as a developer, I don't want to leave a bug in my code, because I know it could come back and bite me later on, and I also just want to write good code. And that's where strict mode helps out.Scenario 3: [STRICT MODE]Additional tip: To maintain code quality using strict mode, you don't need to write this over and again especially if you have multiple .js file. You can enforce this rule globally in eslint rules as follows:Filename: .eslintrc.jsOkay, so what is prevented in strict mode?Using a variable without declaring it will throw an error in strict mode. This is to prevent unintentionally creating global variables throughout your application. The example with printing Chicago covers this in particular.Deleting a variable or a function or an argument is a no-no in strict mode.Duplicating a parameter name is not allowed in strict mode.Reserved words in the Javascript language are not allowed in strict mode. The words are implements interface, let, packages, private, protected, public. static, and yieldFor a more comprehensive list check out the MDN documentation here: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Strict_mode",
                "strict mode enables strict features in the v8 engine. Short example of some features:You can enable it globally by writing:Per function you just include in function:es6 features are enabled (this is browser dependent), for node v4+ this is important.Performance, in some cases, is better.There are more features as well, check here for more!"
            ]
        },
        {
            "tag": "git",
            "question": [
                "How do I check out a remote Git branch?",
                "Somebody pushed a branch called test with git push origin test to a shared repository. I can see the branch with git branch -r. How do I check out the remote test branch? I've tried:\n\ngit checkout ..."
            ],
            "url": "https://stackoverflow.com/questions/1783405",
            "answer": [
                "The answer has been split depending on whether there is one remote repository configured or multiple. The reason for this is that for the single remote case, some of the commands can be simplified as there is less ambiguity.Updated for Git 2.23: For older versions, see the section at the end.In both cases, start by fetching from the remote repository to make sure you have all the latest changes downloaded.This will fetch all of the remote branches for you. You can see the branches available for checkout with:The branches that start with remotes/* can be thought of as read only copies of the remote branches. To work on a branch you need to create a local branch from it. This is done with the Git command switch (since Git 2.23) by giving it the name of the remote branch (minus the remote name):In this case Git is guessing (can be disabled with --no-guess) that you are trying to checkout and track the remote branch with the same name.In the case where multiple remote repositories exist, the remote repository needs to be explicitly named.As before, start by fetching the latest remote changes:This will fetch all of the remote branches for you. You can see the branches available for checkout with:With the remote branches in hand, you now need to check out the branch you are interested in with -c to create a new local branch:For more information about using git switch:I also created the image below for you to share the differences, look at how to fetch works, and also how it's different to pull:git switch was added in Git 2.23, prior to this git checkout was used to switch branches.To checkout out with only a single remote repository:if there there are multiple remote repositories configured it becomes a bit longer",
                "Sidenote: With modern Git (>= 1.6.6), you are able to use just(note that it is 'test' not 'origin/test') to perform magical DWIM-mery and create local branch 'test' for you, for which upstream would be remote-tracking branch 'origin/test'.The * (no branch) in git branch output means that you are on unnamed branch, in so called \"detached HEAD\" state (HEAD points directly to commit, and is not symbolic reference to some local branch).  If you made some commits on this unnamed branch, you can always create local branch off current commit:A more modern approach as suggested in the comments:@Dennis: git checkout <non-branch>, for example git checkout origin/test results in detached HEAD / unnamed branch, while git checkout test or git checkout -b test origin/test results in local\nbranch test (with remote-tracking branch origin/test as upstream) \u2013\nJakub Nar\u0119bski Jan 9 '14 at 8:17emphasis on git checkout origin/test",
                "In this case, you probably want to create a local test branch which is tracking the remote test branch:In earlier versions of git, you needed an explicit --track option, but that is the default now when you are branching off a remote branch.To create the local branch and switch to it, use:",
                "While the first and selected answer is technically correct, there's the possibility you have not yet retrieved all objects and refs from the remote repository. If that is the case, you'll receive the following error:fatal: git checkout: updating paths is incompatible with switching branches.\n  Did you intend to checkout 'origin/remote_branch' which can not be resolved as commit?If you receive this message, you must first do a git fetch origin where origin is the name of the remote repository prior to running git checkout remote_branch. Here's a full example with responses:As you can see, running git fetch origin retrieved any remote branches we were not yet setup to track on our local machine. From there, since we now have a ref to the remote branch, we can simply run git checkout remote_branch and we'll gain the benefits of remote tracking.",
                "I tried the above solution, but it didn't work. Try this, it works:This will fetch the remote branch and create a new local branch (if not exists already) with name local_branch_name and track the remote one in it.",
                "This will DWIM for a remote not named origin (documentation):To add a new remote, you will need to do the following first:The first tells Git the remote exists, the second gets the commits.",
                "Use:Other answers do not work with modern Git in my benign case. You might need to pull first if the remote branch is new, but I haven't checked that case.",
                "You basically see the branch, but you don't have a local copy yet!...You need to fetch the branch...You can simply fetch and then checkout to the branch, use the one line command below to do that:I also created the image below for you to share the differences, look at how fetch works and also how it's different to pull:",
                "To clone a Git repository, do:The above command checks out all of the branches, but only the master branch will be initialized. If you want to checkout the other branches, do:This command checks out the remote branch, and your local branch name will be same as the remote branch.If you want to override your local branch name on checkout:Now your local branch name is enhancement, but your remote branch name is future_branch.",
                "You can tryor",
                "I was stuck in a situation seeing error: pathspec 'desired-branch' did not match any file(s) known to git. for all of the suggestions above. I'm on Git version 1.8.3.1.So this worked for me:The explanation behind is that I've noticed that when fetching the remote branch, it was fetched to FETCH_HEAD:",
                "I always do:git fetch origin && git checkout --track origin/branch_name",
                "First, you need to do:git fetch # If you don't know about branch nameSecond, you can check out remote branch into your local by:-b will create new branch in specified name from your selected remote branch.",
                "I use the following command:",
                "Commandsare equal toand thenBoth will create a latest fixes_for_dev from development",
                "Simply run git checkout with the name of the remote branch. Git will automatically create a local branch that tracks the remote one:However, if that branch name is found in more than one remote, this won't work as Git doesn't know which to use. In that case you can use either:orIn 2.19, Git learned the checkout.defaultRemote configuration, which specifies a remote to default to when resolving such an ambiguity.",
                "The git remote show <origin name> command will list all branches (including un-tracked branches). Then you can find the remote branch name that you need to fetch.Example:Use these steps to fetch remote branches:Example:",
                "If the branch is on something other than the origin remote I like to do the following:This will checkout the next branch on the upstream remote in to a local branch called second/next. Which means if you already have a local branch named next it will not conflict.",
                "None of these answers worked for me. This worked:",
                "git fetch && git checkout your-branch-name",
                "git branch -r says the object name is invalid, because that branch name isn't in Git's local branch list. Update your local branch list from origin with:And then try checking out your remote branch again.This worked for me.I believe git fetch pulls in all remote branches, which is not what the original poster wanted.",
                "Fetch from the remote and checkout the branch.E.g.:git fetch origin && git checkout feature/XYZ-1234-Add-alerts",
                "Other guys and gals give the solutions, but maybe I can tell you why.git checkout test which does nothingDoes nothing doesn't equal doesn't work, so I guess when you type 'git checkout test' in your terminal and press enter key, no message appears and no error occurs. Am I right?If the answer is 'yes', I can tell you the cause.The cause is that there is a file (or folder) named 'test' in your work tree.When git checkout xxx parsed,",
                "To get newly created branchesTo switch into another branch",
                "git checkout -b \"Branch_name\" [ B means Create local branch]git branch --allgit checkout -b \"Your Branch name\"git branchgit pull origin \"Your Branch name\"successfully checkout from the master branch to dev branch",
                "There are many alternatives, for example:Alternative 1:It's the simplest way.Alternative 2:It's the same, but in two steps.",
                "TL;DRUsing git switch rather than git checkout. More details are on this page.I think the answer is obsolete. Git split some functions of checkout to switch and restore now.The following is my summary:If you want to update something for a remote branch, you should create a local branch to \"track\" the remote branch. You can update anything you want in local and finally push to remote. If you check out to the remote branch directly after cloning your repository, you may see the \"detached HEAD\" status and the following message from Git:So how can we create a local branch to track a remote branch?To create a local branch to track a remote branch, you can use git checkout <remote branch name> or git switch <remote branch name>. If you have a file or folder has same name as your remote branch name, git checkout would output some error message, but git switch can work normally!Example:See all branches, and we want to create a local branch to track the remote branch remotes/origin/asd, and we also have the file name asd:The filename is same as remote branch, and Git should output some error messages if we are using the git checkout command to create a local branch to track a remote branchIt works if we are using git switch!",
                "I used that one:",
                "To get all remote branches, use this:Then check out to the branch:",
                "For us, it seems the remote.origin.fetch configuration gave a problem. Therefore, we could not see any other remote branches than master, so git fetch [--all] did not help. Neither git checkout mybranch nor git checkout -b mybranch --track origin/mybranch did work, although it certainly was at remote.The previous configuration only allowed master to be fetched:Fix it by using * and fetch the new information from origin:Now we could git checkout the remote branch locally.I don't have any idea how this configuration ended up in our local repository."
            ]
        },
        {
            "tag": "python",
            "question": [
                "What does if __name__ == \"__main__\": do?",
                "What does this do, and why should one include the if statement?\nif __name__ == \"__main__\":\n    print(\"Hello, World!\")\r\nIf you are trying to close a question where someone should be ..."
            ],
            "url": "https://stackoverflow.com/questions/419163",
            "answer": [
                "It's boilerplate code that protects users from accidentally invoking the script when they didn't intend to. Here are some common problems when the guard is omitted from a script:If you import the guardless script in another script (e.g. import my_script_without_a_name_eq_main_guard), then the latter script will trigger the former to run at import time and using the second script's command line arguments. This is almost always a mistake.If you have a custom class in the guardless script and save it to a pickle file, then unpickling it in another script will trigger an import of the guardless script, with the same problems outlined in the previous bullet.To better understand why and how this matters, we need to take a step back to understand how Python initializes scripts and how this interacts with its module import mechanism.Whenever the Python interpreter reads a source file, it does two things:it sets a few special variables like __name__, and thenit executes all of the code found in the file.Let's see how this works and how it relates to your question about the __name__ checks we always see in Python scripts.Let's use a slightly different code sample to explore how imports and scripts work.  Suppose the following is in a file called foo.py.When the Python interpreter reads a source file, it first defines a few special variables. In this case, we care about the __name__ variable.When Your Module Is the Main ProgramIf you are running your module (the source file) as the main program, e.g.the interpreter will assign the hard-coded string \"__main__\" to the __name__ variable, i.e.When Your Module Is Imported By AnotherOn the other hand, suppose some other module is the main program and it imports your module. This means there's a statement like this in the main program, or in some other module the main program imports:The interpreter will search for your foo.py file (along with searching for a few other variants), and prior to executing that module, it will assign the name \"foo\" from the import statement to the __name__ variable, i.e.After the special variables are set up, the interpreter executes all the code in the module, one statement at a time. You may want to open another window on the side with the code sample so you can follow along with this explanation.AlwaysIt prints the string \"before import\" (without quotes).It loads the math module and assigns it to a variable called math. This is equivalent to replacing import math with the following (note that __import__ is a low-level function in Python that takes a string and triggers the actual import):It prints the string \"before function_a\".It executes the def block, creating a function object, then assigning that function object to a variable called function_a.It prints the string \"before function_b\".It executes the second def block, creating another function object, then assigning it to a variable called function_b.It prints the string \"before __name__ guard\".Only When Your Module Is the Main ProgramOnly When Your Module Is Imported by AnotherAlwaysSummaryIn summary, here's what'd be printed in the two cases:You might naturally wonder why anybody would want this.  Well, sometimes you want to write a .py file that can be both used by other programs and/or modules as a module, and can also be run as the main program itself.  Examples:Your module is a library, but you want to have a script mode where it runs some unit tests or a demo.Your module is only used as a main program, but it has some unit tests, and the testing framework works by importing .py files like your script and running special test functions. You don't want it to try running the script just because it's importing the module.Your module is mostly used as a main program, but it also provides a programmer-friendly API for advanced users.Beyond those examples, it's elegant that running a script in Python is just setting up a few magic variables and importing the script. \"Running\" the script is a side effect of importing the script's module.Question: Can I have multiple __name__ checking blocks?  Answer: it's strange to do so, but the language won't stop you.Suppose the following is in foo2.py.  What happens if you say python foo2.py on the command-line? Why?",
                "When your script is run by passing it as a command to the Python interpreter,all of the code that is at indentation level 0 gets executed.  Functions and classes that are defined are, well, defined, but none of their code gets run.  Unlike other languages, there's no main() function that gets run automatically - the main() function is implicitly all the code at the top level.In this case, the top-level code is an if block.  __name__ is a built-in variable which evaluates to the name of the current module.  However, if a module is being run directly (as in myscript.py above), then __name__ instead is set to the string \"__main__\".  Thus, you can test whether your script is being run directly or being imported by something else by testingIf your script is being imported into another module, its various function and class definitions will be imported and its top-level code will be executed, but the code in the then-body of the if clause above won't get run as the condition is not met. As a basic example, consider the following two scripts:Now, if you invoke the interpreter asThe output will beIf you run two.py instead:You getThus, when module one gets loaded, its __name__ equals \"one\" instead of \"__main__\".",
                "Create the following two files:Now run each file individually.Running python a.py:When a.py is executed, it imports the module b. This causes all the code inside b to run. Python sets globals()['__name__'] in the b module to the module's name, b.Running python b.py:When only the file b.py is executed, Python sets globals()['__name__'] in this file to \"__main__\". Therefore, the if statement evaluates to True this time.",
                "To outline the basics:The global variable, __name__, in the module that is the entry point to your program, is '__main__'. Otherwise, it's the name you import the module by.So, code under the if block will only run if the module is the entry point to your program.It allows the code in the module to be importable by other modules, without executing the code block beneath on import.Why do we need this?Say you're writing a Python script designed to be used as a module:You could test the module by adding this call of the function to the bottom:and running it (on a command prompt) with something like:However, if you want to import the module to another script:On import, the do_important function would be called, so you'd probably comment out your function call, do_important(), at the bottom.And then you'll have to remember whether or not you've commented out your test function call. And this extra complexity would mean you're likely to forget, making your development process more troublesome.The __name__ variable points to the namespace wherever the Python interpreter happens to be at the moment.Inside an imported module, it's the name of that module.But inside the primary module (or an interactive Python session, i.e. the interpreter's Read, Eval, Print Loop, or REPL) you are running everything from its \"__main__\".So if you check before executing:With the above, your code will only execute when you're running it as the primary module (or intentionally call it from another script).There's a Pythonic way to improve on this, though.What if we want to run this business process from outside the module?If we put the code we want to exercise as we develop and test in a function like this and then do our check for '__main__' immediately after:We now have a final function for the end of our module that will run if we run the module as the primary module.It will allow the module and its functions and classes to be imported into other scripts without running the main function, and will also allow the module (and its functions and classes) to be called when running from a different '__main__' module, i.e.This idiom can also be found in the Python documentation in an explanation of the __main__ module. That text states:This module represents the (otherwise anonymous) scope in which the\n  interpreter\u2019s main program executes \u2014 commands read either from\n  standard input, from a script file, or from an interactive prompt. It\n  is this environment in which the idiomatic \u201cconditional script\u201d stanza\n  causes a script to run:",
                "if __name__ == \"__main__\" is the part that runs when the script is run from (say) the command line using a command like python myscript.py.",
                "__name__ is a global variable (in Python, global actually means on the module level) that exists in all namespaces. It is typically the module's name (as a str type).As the only special case, however, in whatever Python process you run, as in mycode.py:the otherwise anonymous global namespace is assigned the value of '__main__' to its __name__.Thus, including the final lineswill cause your script's uniquely defined main function to run.Another benefit of using this construct: you can also import your code as a module in another script and then run the main function if and when your program decides:",
                "There are lots of different takes here on the mechanics of the code in question, the \"How\", but for me none of it made sense until I understood the \"Why\". This should be especially helpful for new programmers.Take file \"ab.py\":And a second file \"xy.py\":What is this code actually doing?When you execute xy.py, you import ab. The import statement runs the module immediately on import, so ab's operations get executed before the remainder of xy's. Once finished with ab, it continues with xy.The interpreter keeps track of which scripts are running with __name__. When you run a script - no matter what you've named it - the interpreter calls it \"__main__\", making it the master or 'home' script that gets returned to after running an external script.Any other script that's called from this \"__main__\" script is assigned its filename as its __name__ (e.g., __name__ == \"ab.py\"). Hence, the line if __name__ == \"__main__\": is the interpreter's test to determine if it's interpreting/parsing the 'home' script that was initially executed, or if it's temporarily peeking into another (external) script. This gives the programmer flexibility to have the script behave differently if it's executed directly vs. called externally.Let's step through the above code to understand what's happening, focusing first on the unindented lines and the order they appear in the scripts. Remember that function - or def - blocks don't do anything by themselves until they're called. What the interpreter might say if mumbled to itself:The bottom two lines mean: \"If this is the \"__main__\" or 'home' script, execute the function called main()\". That's why you'll see a def main(): block up top, which contains the main flow of the script's functionality.Why implement this?Remember what I said earlier about import statements? When you import a module it doesn't just 'recognize' it and wait for further instructions - it actually runs all the executable operations contained within the script. So, putting the meat of your script into the main() function effectively quarantines it, putting it in isolation so that it won't immediately run when imported by another script.Again, there will be exceptions, but common practice is that main() doesn't usually get called externally. So you may be wondering one more thing: if we're not calling main(), why are we calling the script at all? It's because many people structure their scripts with standalone functions that are built to be run independent of the rest of the code in the file. They're then later called somewhere else in the body of the script. Which brings me to this:But the code works without itYes, that's right. These separate functions can be called from an in-line script that's not contained inside a main() function. If you're accustomed (as I am, in my early learning stages of programming) to building in-line scripts that do exactly what you need, and you'll try to figure it out again if you ever need that operation again ... well, you're not used to this kind of internal structure to your code, because it's more complicated to build and it's not as intuitive to read.But that's a script that probably can't have its functions called externally, because if it did it would immediately start calculating and assigning variables. And chances are if you're trying to re-use a function, your new script is related closely enough to the old one that there will be conflicting variables.In splitting out independent functions, you gain the ability to re-use your previous work by calling them into another script. For example, \"example.py\" might import \"xy.py\" and call x(), making use of the 'x' function from \"xy.py\". (Maybe it's capitalizing the third word of a given text string; creating a NumPy array from a list of numbers and squaring them; or detrending a 3D surface. The possibilities are limitless.)(As an aside, this question contains an answer by @kindall that finally helped me to understand - the why, not the how. Unfortunately it's been marked as a duplicate of this one, which I think is a mistake.)",
                "The code under if __name__ == '__main__': will only be executed if the module is invoked as a script.As an example, consider the following module my_test_module.py:First possibility: Import my_test_module.py in another moduleNow if you invoke main.py:Note that only the top-level print() statement in my_test_module is executed.Second possibility: Invoke my_test_module.py as a scriptNow if you run my_test_module.py as a Python script, both print() statements will be executed:For a more comprehensive explanation, you can read What does if __name__ == '__main__' do in Python.",
                "When there are certain statements in our module (M.py) we want to be executed when it'll be running as main (not imported), we can place those statements (test-cases, print statements) under this if block.As by default (when module running as main, not imported) the __name__ variable is set to \"__main__\", and when it'll be imported the __name__ variable will get a different value, most probably the name of the module ('M').\nThis is helpful in running different variants of a modules together, and separating their specific input & output statements and also if there are any test-cases.In short, use this 'if __name__ == \"main\" ' block to prevent (certain) code from being run when the module is imported.",
                "Put simply, __name__ is a variable defined for each script that defines whether the script is being run as the main module or it is being run as an imported module.So if we have two scripts;andThe output from executing script1 isAnd the output from executing script2 is:As you can see, __name__ tells us which code is the 'main' module.\nThis is great, because you can just write code and not have to worry about structural issues like in C/C++, where, if a file does not implement a 'main' function then it cannot be compiled as an executable and if it does, it cannot then be used as a library.Say you write a Python script that does something great and you implement a boatload of functions that are useful for other purposes. If I want to use them I can just import your script and use them without executing your program (given that your code only executes within the  if __name__ == \"__main__\": context). Whereas in C/C++ you would have to portion out those pieces into a separate module that then includes the file. Picture the situation below;The arrows are import links. For three modules each trying to include the previous modules code there are six files (nine, counting the implementation files) and five links. This makes it difficult to include other code into a C project unless it is compiled specifically as a library. Now picture it for Python:You write a module, and if someone wants to use your code they just import it and the __name__ variable can help to separate the executable portion of the program from the library part.",
                "To be short, you need to know several points:import a action actually runs all that can be run in a.py, meaning each line in a.pyBecause of point 1, you may not want everything to be run in a.py when importing itTo solve the problem in point 2, Python allows you to use a condition check__name__ is an implicit variable in all .py modules:The important thing that Python is special at is point 4! The rest is just basic logic.I've been reading so much throughout the answers on this page. I would say, if you know the thing, for sure you will understand those answers, otherwise, you are still confused.",
                "Let's look at the answer in a more abstract way:Suppose we have this code in x.py:Blocks A and B are run when we are running x.py.But just block A (and not B) is run when we are running another module, y.py for example, in which x.py is imported and the code is run from there (like when a function in x.py is called from y.py).",
                "When you run Python interactively the local __name__ variable is assigned a value of __main__. Likewise, when you execute a Python module from the command line, rather than importing it into another module, its __name__ attribute is assigned a value of __main__, rather than the actual name of the module. In this way, modules can look at their own __name__ value to determine for themselves how they are being used, whether as support for another program or as the main application executed from the command line. Thus, the following idiom is quite common in Python modules:",
                "Consider:It checks if the __name__ attribute of the Python script is \"__main__\". In other words, if the program itself is executed, the attribute will be __main__, so the program will be executed (in this case the main() function).However, if your Python script is used by a module, any code outside of the if statement will be executed, so if __name__ == \"__main__\" is used just to check if the program is used as a module or not, and therefore decides whether to run the code.",
                "Before explaining anything about if __name__ == '__main__' it is important to understand what __name__ is and what it does.__name__ is a DunderAlias - can be thought of as a global variable (accessible from modules) and works in a similar way to global.It is a string (global as mentioned above) as indicated by type(__name__) (yielding <class 'str'>), and is an inbuilt standard for both Python 3 and Python 2 versions.It can not only be used in scripts but can also be found in both the interpreter and modules/packages.test_file.py:Resulting in __main__somefile.py:test_file.py:Resulting in somefileNotice that when used in a package or module, __name__ takes the name of the file.  The path of the actual module or package path is not given, but has its own DunderAlias __file__, that allows for this.You should see that, where __name__, where it is the main file (or program) will always return __main__, and if it is a module/package, or anything that is running off some other Python script, will return the name of the file where it has originated from.Being a variable means that it's value can be overwritten (\"can\" does not mean \"should\"), overwriting the value of __name__ will result in a lack of readability.  So do not do it, for any reason.  If you need a variable define a new variable.It is always assumed that the value of __name__ to be __main__ or the name of the file.  Once again changing this default value will cause more confusion that it will do good, causing problems further down the line.It is considered good practice in general to include the if __name__ == '__main__' in scripts.Now we know the behaviour of __name__ things become clearer:An if is a flow control statement that contains the block of code will execute if the value given is true. We have seen that __name__ can take either\n__main__ or the file name it has been imported from.This means that if __name__ is equal to __main__ then the file must be the main file and must actually be running (or it is the interpreter), not a module or package imported into the script.If indeed __name__ does take the value of __main__ then whatever is in that block of code will execute.This tells us that if the file running is the main file (or you are running from the interpreter directly) then that condition must execute.  If it is a package then it should not, and the value will not be __main__.__name__ can also be used in modules to define the name of a moduleIt is also possible to do other, less common but useful things with __name__, some I will show here:You can also use it to provide runnable help functions/utilities on packages and modules without the elaborate use of libraries.It also allows modules to be run from the command line as main scripts, which can be also very useful.",
                "I think it's best to break the answer in depth and in simple words:__name__: Every module in Python has a special attribute called __name__.\nIt is a built-in variable that returns the name of the module.__main__: Like other programming languages, Python too has an execution entry point, i.e., main. '__main__' is the name of the scope in which top-level code executes. Basically you have two ways of using a Python module: Run it directly as a script, or import it. When a module is run as a script, its __name__ is set to __main__.Thus, the value of the __name__ attribute is set to __main__ when the module is run as the main program. Otherwise the value of __name__  is set to contain the name of the module.",
                "It is a special for when a Python file is called from the command line. This is typically used to call a \"main()\" function or execute other appropriate startup code, like commandline arguments handling for instance.It could be written in several ways. Another is:I am not saying you should use this in production code, but it serves to illustrate that there is nothing \"magical\" about if __name__ == '__main__'.It just a convention for invoking a main function in Python files.",
                "There are a number of variables that the system (Python interpreter) provides for source files (modules).  You can get their values anytime you want, so, let us focus on the __name__ variable/attribute:When Python loads a source code file, it executes all of the code found in it. (Note that it doesn't call all of the methods and functions defined in the file, but it does define them.)Before the interpreter executes the source code file though, it defines a few special variables for that file; __name__ is one of those special variables that Python automatically defines for each source code file.If Python is loading this source code file as the main program (i.e. the file you run), then it sets the special __name__ variable for this file to have a value \"__main__\".If this is being imported from another module, __name__ will be set to that module's name.So, in your example in part:means that the code block:will be executed only when you run the module directly; the code block will not execute if another module is calling/importing it because the value of __name__ will not equal to \"main\" in that particular instance.Hope this helps out.",
                "if __name__ == \"__main__\": is basically the top-level script environment, and it specifies the interpreter that ('I have the highest priority to be executed first').'__main__' is the name of the scope in which top-level code executes. A module\u2019s __name__ is set equal to '__main__' when read from standard input, a script, or from an interactive prompt.",
                "Consider:The output for the above is __main__.The above statement is true and prints \"direct method\". Suppose if they imported this class in another class it doesn't print \"direct method\" because, while importing, it will set __name__ equal to \"first model name\".",
                "In simple words:The code you see under if __name__ == \"__main__\": will only get called upon when your Python file is executed as python example1.pyHowever, if you wish to import your Python file example1.py as a module to work with another Python file, say example2.py, the code under if __name__ == \"__main__\": will not run or take any effect.",
                "You can make the file usable as a script as well as an importable module.fibo.py (a module named fibo)Reference: https://docs.python.org/3.5/tutorial/modules.html",
                "The reason foris primarily to avoid the import lock problems that would arise from having code directly imported. You want main() to run if your file was directly invoked (that's the __name__ == \"__main__\" case), but if your code was imported then the importer has to enter your code from the true main module to avoid import lock problems.A side-effect is that you automatically sign on to a methodology that supports multiple entry points. You can run your program using main() as the entry point, but you don't have to. While setup.py expects main(), other tools use alternate entry points. For example, to run your file as a gunicorn process, you define an app() function instead of a main(). Just as with setup.py, gunicorn imports your code so you don't want it do do anything while it's being imported (because of the import lock issue).",
                "If you are a beginner, probably the only answer you need right now is that this code is unnecessary for a simple script. It is only useful if you want to be able to import your script (or unpickle etc; see the other answers here for some other non-beginner scenarios).In slightly different words, the if __name__ guard is a mechanism for hiding code from other code. If you don't have a specific reason to hide something, don't: If you don't need to hide some code from import, don't put it behind this guard, and if you do, hide as little as possible.In slightly more detail, let's say you have a simple script fib.py (adapted from this answer):Now, if you simply run python fib.py it works fine. But __name__ will always be \"__main__\" in this scenario, so the condition is actually unnecessary. The script could be simplified to justNow, you can't import fib with the new version, but if you didn't plan to do that in the first place, this version is actually better, because it's simpler and clearer.If you do want to be able to import fib, the first version is useless, too, because the useful code is in a section which will not run when you import this file (in which case __name__ will not be \"__main__\"). The proper design in that case would be to refactor the code so that the useful parts are in a function you can run when you want to after you have imported it.Now, if you import fib, the call to main() will not be executed; but when you run python fib.py, it will.Actually, a better design still would be to isolate the reusable part (the actual calculation) from the user-visible input/output:Now, you can from fib import fibn and call the fibn() function from the code which performs this import.(I called the function fibn() just to make it clearer what is what in this example. In real life, you might call it fib() and do from fib import fib.)Similarly, you could import and call the main function if you wanted to reuse it.Returning to the code in the question, I would similarly move the code from the if into a function as well, so that callers can invoke that function if they want to.This changes the scope of the lock variable; if the surrounding code needs access to it, you will need to make it global (or, perhaps, better, refactor main to return lock, and have the caller capture the value in a local variable of its own).(Unlike in languages like C, the name main has no specific meaning to Python; but it's a common convention to use it as the name of the thing which will be run. You still have to actually explicitly call it, like main(), unlike in C.)",
                "Every module in Python has an attribute called __name__. The value of __name__  attribute is  __main__ when the module is run directly, like python my_module.py. Otherwise (like when you say import my_module) the value of __name__  is the name of the module.Small example to explain in short.We can execute this directly asOutputNow suppose we call the above script from another script:When you execute this,OutputSo, the above is self-explanatory that when you call test from another script, if loop __name__ in test.py will not execute.",
                "This answer is for Java programmers learning Python.\nEvery Java file typically contains one public class. You can use that class in two ways:Call the class from other files. You just have to import it in the calling program.Run the class stand alone, for testing purposes.For the latter case, the class should contain a public static void main() method. In Python this purpose is served by the globally defined label '__main__'.",
                "If this .py file are imported by other .py files, the code under the if statement will not be executed.If this .py are run by python this_py.py under shell, or double clicked in Windows. the code under the if statement will be executed.It is usually written for testing.",
                "We see if __name__ == '__main__': quite often.It checks if a module is being imported or not.In other words, the code within the if block will be executed only when the code runs directly. Here directly means not imported.Let's see what it does using a simple code that prints the name of the module:If we run the code directly via python test.py, the module name is __main__:",
                "If the Python interpreter is running a particular module then the __name__ global variable will have the value \"__main__\":When you run this script, it prints:If you import this file, say A to file B, and execute the file B then if __name__ == \"__main__\" in file A becomes False, so it prints:",
                "All the answers have pretty much explained the functionality. But I will provide one example of its usage which might help clearing out the concept further.Assume that you have two Python files, a.py and b.py. Now, a.py imports b.py. We run the a.py file, where the import b.py code is executed first. Before the rest of the a.py code runs, the code in the file b.py must run completely.In the b.py code, there is some code that is exclusive to that file b.py and we don't want any other file (other than the b.py file), that has imported the b.py file, to run it.So that is what this line of code checks. If it is the main file (i.e., b.py) running the code, which in this case it is not (a.py is the main file running), then only the code gets executed."
            ]
        },
        {
            "tag": "git",
            "question": [
                "How do I remove local (untracked) files from the current Git working tree?",
                "How do I delete untracked local files from the current working tree?"
            ],
            "url": "https://stackoverflow.com/questions/61212",
            "answer": [
                "Cleans the working tree by recursively removing files that are not under version control, starting from the current directory.Normally, only files unknown to Git are removed, but if the -x option is specified, ignored files are also removed. This can, for example, be useful to remove all build products.If any optional <path>... arguments are given, only those paths are affected.Step 1 is to show what will be deleted by using the -n option:Clean Step - beware: this will delete files:Note the case difference on the X for the two latter commands.If clean.requireForce is set to \"true\" (the default) in your configuration, one needs to specify -f otherwise nothing will actually happen.Again see the git-clean docs for more information.-f, --forceIf the Git configuration variable clean.requireForce is not set to\nfalse, git clean will refuse to run unless given -f, -n or -i.-xDon\u2019t use the standard ignore rules read from .gitignore (per\ndirectory) and $GIT_DIR/info/exclude, but do still use the ignore\nrules given with -e options. This allows removing all untracked files,\nincluding build products. This can be used (possibly in conjunction\nwith git reset) to create a pristine working directory to test a clean\nbuild.-XRemove only files ignored by Git. This may be useful to rebuild\neverything from scratch, but keep manually created files.-n, --dry-runDon\u2019t actually remove anything, just show what would be done.-dRemove untracked directories in addition to untracked files. If an\nuntracked directory is managed by a different Git repository, it is\nnot removed by default. Use -f option twice if you really want to\nremove such a directory.",
                "Use git clean -f -d to make sure that directories are also removed.Don\u2019t actually remove anything, just show what would be done.orRemove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository, it is not removed by default. Use the -f option twice if you really want to remove such a directory.You can then check if your files are really gone with git status.",
                "I am surprised nobody mentioned this before:That stands for interactive and you will get a quick overview of what is going to be deleted offering you the possibility to include/exclude the affected files. Overall, still faster than running the mandatory --dry-run before the real cleaning.You will have to toss in a -d if you also want to take care of empty folders. At the end, it makes  for a nice alias:That being said, the extra hand holding of interactive commands can be tiring for experienced users.  These days I just use the already mentioned git clean -fd",
                "git-clean - Remove untracked files from the working tree",
                "To remove all untracked files, The simple\nway is to add all of them first and reset the repo as below",
                "If untracked directory is a git repository of its own (e.g. submodule), you need to use -f twice:git clean -d -f -f",
                "This is what I always use:For a very large project you might want to run it a couple of times.",
                "I like git stash push -u because you can undo them all with git stash pop.EDIT: Also I found a way to show untracked file in a stash (e.g. git show stash@{0}^3) https://stackoverflow.com/a/12681856/338986EDIT2: git stash save is deprecated in favor of push. Thanks @script-wolf.",
                "Always use -n before running the clean command as it will show you what files would get removed.-d Normally, when no  is specified, git clean will not recurse into untracked directories to avoid removing too much. Specify -d to have it recurse into such directories as well. If any paths are specified, -d is irrelevant; all untracked files matching the specified paths (with exceptions for nested git directories mentioned under --force) will be removed.-f | --force\nIf the Git configuration variable clean.requireForce is not set to false, git clean will refuse to delete files or directories unless given -f or -i. Git will refuse to modify untracked nested git repositories (directories with a .git subdirectory) unless a second -f is given.Now run without -n if output was what you intend to remove.By default, git clean will only remove untracked files that are not ignored. Any file that matches a pattern in your .gitignore or other ignore files will not be removed. If you want to remove those files too, you can add a -x to the clean command.There is also interactive mode available -i with the clean commandBefore you use stash --all note:\nIf the --all option is used, then the ignored files are stashed and cleaned in addition to the untracked files.If the --keep-index option is used, all changes already added to the index are left intact. Your staged changes remain in your workspace, but at the same time, they are also saved into your stash.Calling git stash without any arguments is equivalent to git stash push.Stashing based on the used flags can clear your directory from unstaged / staged files by writing them to stash storage. I give\u2019s flexibility to retrieve the files at any point in time using stash with apply or pop. Then if you are fine with removing your stashed files you could run:To see full instruction on how to work with stash see this How to name and retrieve a stash by name in git?",
                "git-clean is what you are looking for. It is used to remove untracked files from the working tree.",
                "If needed to remove untracked files from particular subdirectory,And combined way to delete untracked dir/files and ignored files.after this you will have modified files only in git status.",
                "Remove all extra folders and files in this repo + submodulesThis gets you in same state as fresh clone.Remove all extra folders and files in this repo but not its submodulesRemove extra folders but not files (ex. build or logs folder)Remove extra folders + ignored files (but not newly added files)If file wasn't ignored and not yet checked-in then  it stays. Note the capital X.New interactive mode",
                "git clean -fd removes directorygit clean -fX removes ignored filesgit clean -fx removes ignored and un-ignored filescan be used all above options in combination asgit clean -fdXxcheck git manual for more help",
                "OK, deleting unwanted untracked files and folders are easy using git in command line, just do it like this:Double check before doing it as it will delete the files and folders without making any history...Also in this case, -f stands for force and -d stands for directory...So, if you want to delete files only, you can use -f only:If you want to delete(directories) and files, you can delete only untracked directories and files like this:Also, you can use -x flag for including the files which are ignored by git. This would be helpful if you want to delete everything.And adding -i flag, makes git asking you for permission for deleting files one by one on the go.If you not sure and want to check things first, add -n flag.Use -q if you don't want to see any report after successful deletion.I also create the image below to make it more memorable, especially I have seen many people confuse -f for cleaning folder sometimes or mix it up somehow!",
                "A better way is to use: git cleanThis removes untracked files, including directories (-d) and files ignored by git (-x).Also, replace the -f argument with -n to perform a dry-run or -i for interactive mode and it will tell you what will be removed.",
                "User interactive approach:-i for interactive\n-f for force\n-d for directory\n-x for ignored files(add if required)\nNote: Add -n or --dry-run to just check what it will do.",
                "To remove Untracked files :",
                "A lifehack for such situation I just invented and tried (that works perfectly):Beware! Be sure to commit any needed changes (even in non-untracked files) before performing this.",
                "For me only following worked:In all other cases, I was getting message \"Skipping Directory\" for some subdirectories.",
                "git clean -f -d -x $(git rev-parse --show-cdup) applies clean to the root directory, no matter where you call it within a repository directory tree. I use it all the time as it does not force you to leave the folder where you working now and allows to clean & commit right from the place where you are.Be sure that flags -f, -d, -x match your needs:There are other flags as well available, just check git clean --help.",
                "If you just want to delete the files listed as untracked by 'git status'I prefer this to 'git clean' because 'git clean' will delete files\nignored by git, so your next build will have to rebuild everything\nand you may lose your IDE settings too.",
                "To know what will be deleted before actually deleting:git clean -d -nIt will output something like:Would remove sample.txtTo delete everything listed in the output of the previous command:git clean -d -fIt will output something like:Removing sample.txt",
                "git add --all, git stash and git stash drop, try these three commands in this order inorder to remove all untracked files. By adding all those untracked files to git and stashing them will move all those untracked files to stash list and dropping out top one i.e., stash@{0} will remove the stashed changes from stash list.",
                "To remove the untracked files you should first use command to view the files that will be affected by cleaningThis will show you the list of files that will be deleted. Now to actually delete those files use this command:",
                "uggested Command for Removing Untracked Files from git docs is git cleangit clean - Remove untracked files from the working treeSuggested Method:  Interative Mode by using git clean -i\nso we can have control over it. let see remaining available options.Available Options:Explanation:1. -dRemove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository,\n   it is not removed by default. Use -f option twice if you really want to remove such a directory.2. -f, --forceIf the Git configuration variable clean.requireForce is not set to false, git clean will refuse to run unless given -f, -n or\n   -i.3. -i, --interactiveShow what would be done and clean files interactively. See \u201cInteractive mode\u201d for details.4. -n, --dry-runDon\u2019t actually remove anything, just show what would be done.5. -q, --quietBe quiet, only report errors, but not the files that are successfully removed.6. -e , --exclude=In addition to those found in .gitignore (per directory) and $GIT_DIR/info/exclude, also consider these patterns to be in the\n   set of the ignore rules in effect.7. -xDon\u2019t use the standard ignore rules read from .gitignore (per directory) and $GIT_DIR/info/exclude, but do still use the ignore\n   rules given with -e options. This allows removing all untracked files, including build products. This can be used (possibly in\n   conjunction with git reset) to create a pristine working directory to test a clean build.8. -XRemove only files ignored by Git. This may be useful to rebuild everything from scratch, but keep manually created files.",
                "git clean -f to remove untracked files from working directory.I have covered some basics here in my blog, git-intro-basic-commands",
                "Normal git clean command doesn't remove untracked files with my git version 2.9.0.windows.1.",
                "We can easily removed local untracked files from the current git working tree by using below git comments.Example:Links :",
                "The following command will clean out\n  the current git repository and all its submodules recursively:",
                "oh-my-zsh with zsh provides those great aliases via the git plugin. They can be used in bash as well.gclean='git clean -fd'\ngpristine='git reset --hard && git clean -dfx'"
            ]
        },
        {
            "tag": "javascript",
            "question": [
                "How do I redirect to another webpage?",
                "How can I redirect the user from one page to another using jQuery or pure JavaScript?"
            ],
            "url": "https://stackoverflow.com/questions/503093",
            "answer": [
                "jQuery is not necessary, and window.location.replace(...) will best simulate an HTTP redirect.window.location.replace(...) is better than using window.location.href, because replace() does not keep the originating page in the session history, meaning the user won't get stuck in a never-ending back-button fiasco.If you want to simulate someone clicking on a link, use\n location.hrefIf you want to simulate an HTTP redirect, use location.replaceFor example:",
                "WARNING: This answer has merely been provided as a possible solution; it is obviously not the best solution, as it requires jQuery. Instead, prefer the pure JavaScript solution.",
                "If you are here because you are losing HTTP_REFERER when redirecting, keep reading:(Otherwise ignore this last part)The following section is for those using HTTP_REFERER as one of many security measures (although it isn't a great protective measure). If you're using Internet\u00a0Explorer\u00a08 or lower, these variables get lost when using any form of JavaScript page redirection (location.href,  etc.).Below we are going to implement an alternative for IE8 & lower so that we don't lose HTTP_REFERER. Otherwise, you can almost always simply use window.location.href.Testing against HTTP_REFERER (URL pasting, session, etc.) can help tell whether a request is legitimate.\n(Note: there are also ways to work-around / spoof these referrers, as noted by droop's link in the comments)Simple cross-browser testing solution (fallback to window.location.href for Internet\u00a0Explorer\u00a09+ and all other browsers)Usage: redirect('anotherpage.aspx');",
                "There are lots of ways of doing this.",
                "This works for every browser:",
                "It would help if you were a little more descriptive in what you are trying to do.  If you are trying to generate paged data, there are some options in how you do this.  You can generate separate links for each page that you want to be able to get directly to.Note that the current page in the example is handled differently in the code and with CSS.If you want the paged data to be changed via AJAX, this is where jQuery would come in.  What you would do is add a click handler to each of the anchor tags corresponding to a different page.  This click handler would invoke some jQuery code that goes and fetches the next page via AJAX and updates the table with the new data.  The example below assumes that you have a web service that returns the new page data.",
                "I also think that location.replace(URL) is the best way, but if you want to notify the search engines about your redirection (they don't analyze JavaScript code to see the redirection) you should add the rel=\"canonical\" meta tag to your website.Adding a noscript section with a HTML refresh meta tag in it, is also a good solution. I suggest you to use this JavaScript redirection tool to create redirections. It also has Internet\u00a0Explorer support to pass the HTTP referrer.Sample code without delay looks like this:",
                "But if someone wants to redirect back to home page then he may use the following snippet.It would be helpful if you have three different environments as development, staging, and production.You can explore this window or window.location object by just putting these words in Chrome Console or Firebug's Console.",
                "JavaScript provides you many methods to retrieve and change the current URL which is displayed in browser's address bar. All these methods uses the Location object, which is  a property of the Window object. You can create a new Location object that has the current URL as follows..Basic Structure of a URLProtocol -- Specifies the protocol name be used to access the resource on the Internet. (HTTP (without SSL) or HTTPS (with SSL))hostname -- Host name specifies the host that owns the resource. For example, www.stackoverflow.com. A server provides services using the name of the host.port -- A port number used to recognize a specific process to which an Internet or other network message is to be forwarded when it arrives at a server.pathname -- The path gives info about the specific resource within the host that the Web client wants to access. For example, stackoverflow.com/index.html.query --  A query string follows the path component, and provides a string of information that the resource can utilize for some purpose (for example, as parameters for a search or as data to be processed).hash -- The anchor portion of a URL, includes the hash sign (#).With these Location object properties you can access all of these URL componentsNow If you want to change a page or redirect the user to some other page you can use the href property of the Location object like thisYou can use the href property of the Location object.Location Object also have these three methodsYou can use assign() and replace methods also to redirect to other pages like theseHow assign() and replace() differs -- The difference between replace() method and assign() method(), is that replace() removes the URL of the current document from the document history, means it is not possible to use the \"back\" button to navigate back to the original document. So Use the assign() method if you want to load a new document, andwant to give the option to navigate back to the original document.You can change the location object href property using jQuery also  like thisAnd hence you can redirect the user to some other url.",
                "Basically jQuery is just a JavaScript framework and for doing some of the things like redirection in this case, you can just use pure JavaScript, so in that case you have 3 options using vanilla JavaScript:1) Using location replace, this will replace the current history of the page, means that it is not possible to use the back button to go back to the original page.2) Using location assign, this will keep the history for you and with using back button, you can go back to the original page:3) I recommend using one of those previous ways, but this could be the third option using pure JavaScript:You can also write a function in jQuery to handle it, but not recommended as it's only one line pure JavaScript function, also you can use all of above functions without window if you are already in the window scope, for example window.location.replace(\"http://stackoverflow.com\"); could be location.replace(\"http://stackoverflow.com\");Also I show them all on the image below:",
                "Should just be able to set using window.location.Example:Here is a past post on the subject: How do I redirect to another webpage?",
                "Before I start, jQuery is a JavaScript library used for DOM manipulation. So you should not be using jQuery for a page redirect.A quote from Jquery.com:While jQuery might run without major issues in older browser versions,\nwe do not actively test jQuery in them and generally do not fix bugs\nthat may appear in them.It was found here:\nhttps://jquery.com/browser-support/So jQuery is not an end-all and be-all solution for backwards compatibility.The following solution using raw JavaScript works in all browsers and have been standard for a long time so you don't need any libraries for cross browser support.This page will redirect to Google after 3000 millisecondsDifferent options are as follows:When using replace, the back button will not go back to the redirect page, as if it was never in the history. If you want the user to be able to go back to the redirect page then use window.location.href or window.location.assign. If you do use an option that lets the user go back to the redirect page, remember that when you enter the redirect page it will redirect you back. So put that into consideration when picking an option for your redirect. Under conditions where the page is only redirecting when an action is done by the user then having the page in the back button history will be okay. But if the page auto redirects then you should use replace so that the user can use the back button without getting forced back to the page the redirect sends.You can also use meta data to run a page redirect as followed.META RefreshMETA LocationBASE HijackingMany more methods to redirect your unsuspecting client to a page they may not wish to go can be found on this page (not one of them is reliant on jQuery):https://code.google.com/p/html5security/wiki/RedirectionMethodsI would also like to point out, people don't like to be randomly redirected. Only redirect people when absolutely needed. If you start redirecting people randomly they will never go to your site again.The next paragraph is hypothetical:You also may get reported as a malicious site. If that happens then when people click on a link to your site the users browser may warn them that your site is malicious. What may also happen is search engines may start dropping your rating if people are reporting a bad experience on your site.Please review Google Webmaster Guidelines about redirects:\nhttps://support.google.com/webmasters/answer/2721217?hl=en&ref_topic=6001971Here is a fun little page that kicks you out of the page.If you combine the two page examples together you would have an infant loop of rerouting that will guarantee that your user will never want to use your site ever again.",
                "You can do that without jQuery as:And if you want only jQuery then you can do it like:",
                "This works with jQuery:",
                "# HTML Page Redirect Using jQuery/JavaScript MethodTry this example code:If you want to give a complete URL as window.location = \"www.google.co.in\";.",
                "Original question: \"How to redirect using jQuery?\", hence the answer implements jQuery >> Complimentary usage case.To just redirect to a page with JavaScript:Or if you need a delay:jQuery allows you to select elements from a web page with ease. You can find anything you want on a page and then use jQuery to add special effects, react to user actions, or show and hide content inside or outside the element you have selected. All these tasks start with knowing how to select an element or an event.Imagine someone wrote a script/plugin with 10000 lines of code. With jQuery you can connect to this code with just a line or two.",
                "So, the question is how to make a redirect page, and not how to redirect to a website?You only need to use JavaScript for this. Here is some tiny code that will create a dynamic redirect page.So say you just put this snippet into a redirect/index.html file on your website you can use it like so.http://www.mywebsite.com/redirect?url=http://stackoverflow.comAnd if you go to that link it will automatically redirect you to stackoverflow.com.Link to DocumentationAnd that's how you make a Simple redirect page with JavaScriptEdit:There is also one thing to note. I have added window.location.replace in my code because I think it suits a redirect page, but, you must know that when using window.location.replace and you get redirected, when you press the back button in your browser it will not got back to the redirect page, and it will go back to the page before it, take a look at this little demo thing.Example:The process: store home => redirect page to google => googleWhen at google: google => back button in browser => store homeSo, if this suits your needs then everything should be fine. If you want to include the redirect page in the browser history replace thiswith",
                "You need to put this line in your code:If you don't have jQuery, go with JavaScript:",
                "On your click function, just add:",
                "Try this:Code snippet of example.",
                "jQuery is not needed. You can do this:It is that easy!The best way to initiate an HTTP request is with document.loacation.href.replace('URL').",
                "First write properly. You want to navigate within an application for another link from your application for another link. Here is the code:And if you want to navigate pages within your application then I also have code, if you want.",
                "You can redirect in jQuery like this:",
                "JavaScript is very extensive. If you want to jump to another page you have three options.As you want to move to another page, you can use any from these if this is your requirement.\nHowever all three options are limited to different situations. Chose wisely according to your requirement.If you are interested in more knowledge about the concept, you can go through further.",
                "In JavaScript and jQuery we can use the following code to redirect the one page to another page:",
                "Please don't kill me, this is a joke. It's a joke. This is a joke.This did \"provide an answer to the question\", in the sense that it asked for a solution \"using jQuery\" which in this case entails forcing it into the equation somehow.Ferrybig apparently needs the joke explained (still joking, I'm sure there are limited options on the review form), so without further ado:Other answers are using jQuery's attr() on the location or window objects unnecessarily.This answer also abuses it, but in a more ridiculous way. Instead of using it to set the location, this uses attr() to retrieve a function that sets the location.The function is named jQueryCode even though there's nothing jQuery about it, and calling a function somethingCode is just horrible, especially when the something is not even a language.The \"85 bytes\" is a reference to Code Golf. Golfing is obviously not something you should do outside of code golf, and furthermore this answer is clearly not actually golfed.Basically, cringe.",
                "Javascript:Jquery:",
                "Here is a time-delay redirection. You can set the delay time to whatever you want:"
            ]
        },
        {
            "tag": "git",
            "question": [
                "How to modify existing, unpushed commit messages?",
                "I wrote the wrong thing in a commit message.\n\nHow can I change the message? The commit has not been pushed yet."
            ],
            "url": "https://stackoverflow.com/questions/179123",
            "answer": [
                "will open your editor, allowing you to change the commit message of the most recent commit. Additionally, you can set the commit message directly in the command line with:\u2026however, this can make multi-line commit messages or small corrections more cumbersome to enter.Make sure you don't have any working copy changes staged before doing this or they will get committed too. (Unstaged changes will not get committed.)If you've already pushed your commit up to your remote branch, then - after amending your commit locally (as described above) - you'll also need to force push the commit with:Warning: force-pushing will overwrite the remote branch with the state of your local one. If there are commits on the remote branch that you don't have in your local branch, you will lose those commits.Warning: be cautious about amending commits that you have already shared with other people. Amending commits essentially rewrites them to have different SHA IDs, which poses a problem if other people have copies of the old commit that you've rewritten. Anyone who has a copy of the old commit will need to synchronize their work with your newly re-written commit, which can sometimes be difficult, so make sure you coordinate with others when attempting to rewrite shared commit history, or just avoid rewriting shared commits altogether.Another option is to use interactive rebase.\nThis allows you to edit any message you want to update even if it's not the latest message.In order to do a Git squash, follow these steps:Once you squash your commits - choose the e/r for editing the message:When you use git rebase -i HEAD~n there can be more than n commits. Git will \"collect\" all the commits in the last n commits, and if there was a merge somewhere in between that range you will see all the commits as well, so the outcome will be n + .If you have to do it for more than a single branch and you might face conflicts when amending the content, set up git rerere and let Git resolve those conflicts automatically for you.git-commit(1) Manual Pagegit-rebase(1) Manual Pagegit-push(1) Manual Page",
                "If the commit you want to fix isn\u2019t the most recent one:git rebase --interactive $parent_of_flawed_commitIf you want to fix several flawed commits, pass the parent of the oldest one of them.An editor will come up, with a list of all commits since the one you gave.For each commit you want to reword, Git will drop you back into your editor. For each commit you want to edit, Git drops you into the shell. If you\u2019re in the shell:Most of this sequence will be explained to you by the output of the various commands as you go. It\u2019s very easy; you don\u2019t need to memorise it \u2013 just remember that git rebase --interactive lets you correct commits no matter how long ago they were.Note that you will not want to change commits that you have already pushed. Or maybe you do, but in that case you will have to take great care to communicate with everyone who may have pulled your commits and done work on top of them. How do I recover/resynchronise after someone pushes a rebase or a reset to a published branch?",
                "To amend the previous commit, make the changes you want and stage those changes, and then runThis will open a file in your text editor representing your new commit message. It starts out populated with the text from your old commit message. Change the commit message as you want, then save the file and quit your editor to finish.To amend the previous commit and keep the same log message, runTo fix the previous commit by removing it entirely, runIf you want to edit more than one commit message, run(Replace commit_count with number of commits that you want to edit.) This command launches your editor. Mark the first commit (the one that you want to change) as \u201cedit\u201d instead of \u201cpick\u201d, then save and exit your editor. Make the change you want to commit and then runNote: You can also \"Make the change you want\" from the editor opened by git commit --amend",
                "As already mentioned, git commit --amend is the way to overwrite the last commit. One note: if you would like to also overwrite the files, the command would be",
                "You also can use git filter-branch for that.It's not as easy as a trivial git commit --amend, but it's especially useful, if you already have some merges after your erroneous commit message.Note that this will try to rewrite every commit between HEAD and the flawed commit, so you should choose your msg-filter command very wisely ;-)",
                "I prefer this way:Otherwise, there will be a new commit with a new commit ID.",
                "If you are using the Git GUI tool, there is a button named Amend last commit. Click on that button and then it will display your last commit files and message. Just edit that message, and you can commit it with a new commit message.Or use this command from a console/terminal:",
                "You can use Git rebasing. For example, if you want to modify back to commit bbc643cd, runIn the default editor, modify 'pick' to 'edit' in the line whose commit you want to modify. Make your changes and then stage them withNow you can useto modify the commit, and after thatto return back to the previous head commit.",
                "If you only want to modify your last commit message, then do:That will drop you into your text editor and let you change the last commit message.If you want to change the last three commit messages, or any of the commit messages up to that point, supply HEAD~3 to the git rebase -i command:",
                "If you have to change an old commit message over multiple branches (i.e., the commit with the erroneous message is present in multiple branches) you might want to use:Git will create a temporary directory for rewriting and additionally backup old references in refs/original/.-f will enforce the execution of the operation. This is necessary if the temporary directory is already present or if there are already references stored under refs/original. If that is not the case, you can drop this flag.-- separates filter-branch options from revision options.--all will make sure that all branches and tags are rewritten.Due to the backup of your old references, you can easily go back to the state before executing the command.Say, you want to recover your master and access it in branch old_master:",
                "If it's your last commit, just amend the commit:(Using the -o (--only) flag to make sure you change only the commit message)If it's a buried commit, use the awesome interactive rebase:Find the commit you want, change pick to r (reword), and save and close the file. Done!Miniature Vim tutorial (or, how to rebase with only 8 keystrokes 3jcwrEscZZ):If you edit text a lot, then switch to the Dvorak keyboard layout, learn to touch-type, and learn Vim. Is it worth the effort? Yes.ProTip\u2122: Don't be afraid to experiment with \"dangerous\" commands that rewrite history* \u2014 Git doesn't delete your commits for 90 days by default; you can find them in the reflog:* Watch out for options like --hard and --force though \u2014 they can discard data.\n*  Also, don't rewrite history on any branches you're collaborating on.",
                "UseTo understand it in detail, an excellent post is 4. Rewriting Git History. It also talks about when not to use git commit --amend.",
                "You have a couple of options here. You can doas long as it's your last commit.Otherwise, if it's not your last commit, you can do an interactive rebase,Then inside the interactive rebase you simply add edit to that commit. When it comes up, do a git commit --amend and modify the commit message. If you want to roll back before that commit point, you could also use git reflog and just delete that commit. Then you just do a git commit again.",
                "If you are using the Git GUI, you can amend the last commit which hasn't been pushed with:",
                "I use the Git GUI as much as I can, and that gives you the option to amend the last commit:Also, git rebase -i origin/masteris a nice mantra that will always present you with the commits you have done on top of master, and give you the option to amend, delete, reorder or squash. No need to get hold of that hash first.",
                "For anyone looking for a Windows/Mac GUI to help with editing older messages (i.e. not just the latest message), I'd recommend Sourcetree. The steps to follow are below the image.For commits that haven't been pushed to a remote yet:...Or... for commits that have already been pushed:Follow the steps in this answer, which are similar to above, but require a further command to be run from the command line (git push origin <branch> -f) to force-push the branch. I'd recommend reading it all and applying the necessary caution!",
                "Wow, so there are a lot of ways to do this.Yet another way to do this is to delete the last commit, but keep its changes so that you won't lose your work. You can then do another commit with the corrected message. This would look something like this:I always do this if I forget to add a file or do a change.Remember to specify --soft instead of --hard, otherwise you lose that commit entirely.",
                "If you just want to edit the latest commit, use:orBut if you want to edit several commits in a row, you should use rebasing instead:In a file, like the one above, write edit/e or one of the other options, and hit save and exit.Now you'll be at the first wrong commit. Make changes in the files, and they'll be automatically staged for you. TypeSave and exit that and typeto move to next selection until finished with all your selections.Note that these things change all your SHA hashes after that particular commit.",
                "If you only want to change your last message you should use the --only flag or its shortcut -o with commit --amend:This ensures that you don't accidentally enhance your commit with staged stuff. Of course it's best to have a proper $EDITOR configuration. Then you can leave the -m option out, and Git will pre-fill the commit message with the old one. In this way it can be easily edited.",
                "Update your last wrong commit message with the new commit message in one line:Or, try Git reset like below:git reset can help you to break one commit into multiple commits too:Here you have successfully broken your last commit into two commits.",
                "On this question there are a lot of answers, but none of them explains in super detail how to change older commit messages using Vim. I was stuck trying to do this myself, so here I'll write down in detail how I did this especially for people who have no experience in Vim!I wanted to change my five latest commits that I already pushed to the server. This is quite 'dangerous' because if someone else already pulled from this, you can mess things up by changing the commit messages. However, when you\u2019re working on your own little branch and are sure no one pulled it you can change it like this:Let's say you want to change your five latest commits, and then you type this in the terminal:*Where 5 is the number of commit messages you want to change (so if you want to change the 10th to last commit, you type in 10).This command will get you into Vim there you can \u2018edit\u2019 your commit history. You\u2019ll see your last five commits at the top like this:Instead of pick you need to write reword. You can do this in Vim by typing in i. That makes you go in to insert mode. (You see that you\u2019re in insert mode by the word INSERT at the bottom.) For the commits you want to change, type in reword instead of pick.Then you need to save and quit this screen. You do that by first going in to \u2018command-mode\u2019 by pressing the Escbutton (you can check that you\u2019re in command-mode if the word INSERT at the bottom has disappeared). Then you can type in a command by typing :. The command to save and quit is wq. So if you type in :wq you\u2019re on the right track.Then Vim will go over every commit message you want to reword, and here you can actually change the commit messages. You\u2019ll do this by going into insert mode, changing the commit message, going into the command-mode, and save and quit. Do this five times and you\u2019re out of Vim!Then, if you already pushed your wrong commits, you need to git push --force to overwrite them. Remember that git push --force is quite a dangerous thing to do, so make sure that no one pulled from the server since you pushed your wrong commits!Now you have changed your commit messages!(As you see, I'm not that experienced in Vim, so if I used the wrong 'lingo' to explain what's happening, feel free to correct me!)",
                "You can use git-rebase-rewordIt is designed to edit any commit (not just last) same way as commit --amendIt is named after the action on rebase interactive to amend a commit: \"reword\". See this post and man -section interactive mode-Examples:",
                "I have added the aliases reci and recm for recommit (amend) it. Now I can do it with git recm or git recm -m:",
                "I realised that I had pushed a commit with a typo in it. In order to undo, I did the following:Warning: force pushing your changes will overwrite the remote branch with your local one. Make sure that you aren't going to be overwriting anything that you want to keep. Also be cautious about force pushing an amended (rewritten) commit if anyone else shares the branch with you, because they'll need to rewrite their own history if they have the old copy of the commit that you've just rewritten.",
                "I like to use the following:",
                "If you have not pushed the code to your remote branch (GitHub/Bitbucket) you can change the commit message on the command line as below.If you're working on a specific branch do this:If you've already pushed the code with the wrong message, and you need to be careful when changing the message. That is, after you change the commit message and try pushing it again, you end up with having issues. To make it smooth, follow these steps.Please read my entire answer before doing it.Important note: When you use the force push directly you might end up with code issues that other developers are working on the same branch. So to avoid those conflicts, you need to pull the code from your branch before making the force push:This is the best practice when changing the commit message, if it was already pushed."
            ]
        },
        {
            "tag": "javascript",
            "question": [
                "How do JavaScript closures work?",
                "How would you explain JavaScript closures to someone with a knowledge of the concepts they consist of (for example functions, variables and the like), but does not understand closures themselves?\n\nI ..."
            ],
            "url": "https://stackoverflow.com/questions/111102",
            "answer": [
                "A closure is a pairing of:A lexical environment is part of every execution context (stack frame) and is a map between identifiers (i.e. local variable names) and values.Every function in JavaScript maintains a reference to its outer lexical environment. This reference is used to configure the execution context created when a function is invoked. This reference enables code inside the function to \"see\" variables declared outside the function, regardless of when and where the function is called.If a function was called by a function, which in turn was called by another function, then a chain of references to outer lexical environments is created. This chain is called the scope chain.In the following code, inner forms a closure with the lexical environment of the execution context created when foo is invoked, closing over variable secret:function foo() {\n  const secret = Math.trunc(Math.random() * 100)\n  return function inner() {\n    console.log(`The secret number is ${secret}.`)\n  }\n}\nconst f = foo() // `secret` is not directly accessible from outside `foo`\nf() // The only way to retrieve `secret`, is to invoke `f`In other words: in JavaScript, functions carry a reference to a private \"box of state\", to which only they (and any other functions declared within the same lexical environment) have access. This box of the state is invisible to the caller of the function, delivering an excellent mechanism for data-hiding and encapsulation.And remember: functions in JavaScript can be passed around like variables (first-class functions), meaning these pairings of functionality and state can be passed around your program: similar to how you might pass an instance of a class around in C++.If JavaScript did not have closures, then more states would have to be passed between functions explicitly, making parameter lists longer and code noisier.So, if you want a function to always have access to a private piece of state, you can use a closure....and frequently we do want to associate the state with a function. For example, in Java or C++, when you add a private instance variable and a method to a class, you are associating the state with functionality.In C and most other common languages, after a function returns, all the local variables are no longer accessible because the stack-frame is destroyed. In JavaScript, if you declare a function within another function, then the local variables of the outer function can remain accessible after returning from it. In this way, in the code above, secret remains available to the function object inner, after it has been returned from foo.Closures are useful whenever you need a private state associated with a function. This is a very common scenario - and remember: JavaScript did not have a class syntax until 2015, and it still does not have a private field syntax. Closures meet this need.In the following code, the function toString closes over the details of the car.function Car(manufacturer, model, year, color) {\n  return {\n    toString() {\n      return `${manufacturer} ${model} (${year}, ${color})`\n    }\n  }\n}\n\nconst car = new Car('Aston Martin', 'V8 Vantage', '2012', 'Quantum Silver')\nconsole.log(car.toString())In the following code, the function inner closes over both fn and args.function curry(fn) {\n  const args = []\n  return function inner(arg) {\n    if(args.length === fn.length) return fn(...args)\n    args.push(arg)\n    return inner\n  }\n}\n\nfunction add(a, b) {\n  return a + b\n}\n\nconst curriedAdd = curry(add)\nconsole.log(curriedAdd(2)(3)()) // 5In the following code, function onClick closes over variable BACKGROUND_COLOR.const $ = document.querySelector.bind(document)\nconst BACKGROUND_COLOR = 'rgba(200, 200, 242, 1)'\n\nfunction onClick() {\n  $('body').style.background = BACKGROUND_COLOR\n}\n\n$('button').addEventListener('click', onClick)\n<button>Set background color</button>In the following example, all the implementation details are hidden inside an immediately executed function expression. The functions tick and toString close over the private state and functions they need to complete their work. Closures have enabled us to modularize and encapsulate our code.let namespace = {};\n\n(function foo(n) {\n  let numbers = []\n\n  function format(n) {\n    return Math.trunc(n)\n  }\n\n  function tick() {\n    numbers.push(Math.random() * 100)\n  }\n\n  function toString() {\n    return numbers.map(format)\n  }\n\n  n.counter = {\n    tick,\n    toString\n  }\n}(namespace))\n\nconst counter = namespace.counter\ncounter.tick()\ncounter.tick()\nconsole.log(counter.toString())This example shows that the local variables are not copied in the closure: the closure maintains a reference to the original variables themselves. It is as though the stack-frame stays alive in memory even after the outer function exits.function foo() {\n  let x = 42\n  let inner = () => console.log(x)\n  x = x + 1\n  return inner\n}\n\nfoo()() // logs 43In the following code, three methods log, increment, and update all close over the same lexical environment.And every time createObject is called, a new execution context (stack frame) is created and a completely new variable x, and a new set of functions (log etc.) are created, that close over this new variable.function createObject() {\n  let x = 42;\n  return {\n    log() { console.log(x) },\n    increment() { x++ },\n    update(value) { x = value }\n  }\n}\n\nconst o = createObject()\no.increment()\no.log() // 43\no.update(5)\no.log() // 5\nconst p = createObject()\np.log() // 42If you are using variables declared using var, be careful you understand which variable you are closing over. Variables declared using var are hoisted. This is much less of a problem in modern JavaScript due to the introduction of let and const.In the following code, each time around the loop, a new function inner is created, which closes over i. But because var i is hoisted outside the loop, all of these inner functions close over the same variable, meaning that the final value of i (3) is printed, three times.function foo() {\n  var result = []\n  for (var i = 0; i < 3; i++) {\n    result.push(function inner() { console.log(i) } )\n  }\n\n  return result\n}\n\nconst result = foo()\n// The following will print `3`, three times...\nfor (var i = 0; i < 3; i++) {\n  result[i]() \n}",
                "Every function in JavaScript maintains a link to its outer lexical environment. A lexical environment is a map of all the names (eg. variables, parameters) within a scope, with their values.So, whenever you see the function keyword, code inside that function has access to variables declared outside the function.function foo(x) {\r\n  var tmp = 3;\r\n\r\n  function bar(y) {\r\n    console.log(x + y + (++tmp)); // will log 16\r\n  }\r\n\r\n  bar(10);\r\n}\r\n\r\nfoo(2);This will log 16 because function bar closes over the parameter x and the variable tmp, both of which exist in the lexical environment of outer function foo.Function bar, together with its link with the lexical environment of function foo is a closure.A function doesn't have to return in order to create a closure. Simply by virtue of its declaration, every function closes over its enclosing lexical environment, forming a closure.function foo(x) {\r\n  var tmp = 3;\r\n\r\n  return function (y) {\r\n    console.log(x + y + (++tmp)); // will also log 16\r\n  }\r\n}\r\n\r\nvar bar = foo(2);\r\nbar(10); // 16\r\nbar(10); // 17The above function will also log 16, because the code inside bar can still refer to argument x and variable tmp, even though they are no longer directly in scope.However, since tmp is still hanging around inside bar's closure, it is available to be incremented. It will be incremented each time you call bar.The simplest example of a closure is this:var a = 10;\r\n\r\nfunction test() {\r\n  console.log(a); // will output 10\r\n  console.log(b); // will output 6\r\n}\r\nvar b = 6;\r\ntest();When a JavaScript function is invoked, a new execution context ec is created. Together with the function arguments and the target object, this execution context also receives a link to the lexical environment of the calling execution context, meaning the variables declared in the outer lexical environment (in the above example, both a and b) are available from ec.Every function creates a closure because every function has a link to its outer lexical environment.Note that variables themselves are visible from within a closure, not copies.",
                "FOREWORD: this answer was written when the question was:Like the old Albert said : \"If you can't explain it to a six-year old, you really don't understand it yourself.\u201d. Well I tried to explain JS closures to a 27 years old friend and completely failed.Can anybody consider that I am 6 and strangely interested in that subject ?I'm pretty sure I was one of the only people that attempted to take the initial question literally. Since then, the question has mutated several times, so my answer may now seem incredibly silly & out of place. Hopefully the general idea of the story remains fun for some.I'm a big fan of analogy and metaphor when explaining difficult concepts, so let me try my hand with a story.Once upon a time:There was a princess...She lived in a wonderful world full of adventures. She met her Prince Charming, rode around her world on a unicorn, battled dragons, encountered talking animals, and many other fantastical things.But she would always have to return back to her dull world of chores and grown-ups.And she would often tell them of her latest amazing adventure as a princess.But all they would see is a little girl......telling stories about magic and fantasy.And even though the grown-ups knew of real princesses, they would never believe in the unicorns or dragons because they could never see them. The grown-ups said that they only existed inside the little girl's imagination.But we know the real truth; that the little girl with the princess inside......is really a princess with a little girl inside.",
                "Taking the question seriously, we should find out what a typical 6-year-old is capable of cognitively, though admittedly, one who is interested in JavaScript is not so typical.On  Childhood Development: 5 to 7 Years  it says:Your child will be able to follow two-step directions. For example, if you say to your child, \"Go to the kitchen and get me a trash bag\" they will be able to remember that direction.We can use this example to explain closures, as follows:The kitchen is a closure that has a local variable, called trashBags.  There is a function inside the kitchen called getTrashBag that gets one trash bag and returns it.We can code this in JavaScript like this:function makeKitchen() {\r\n  var trashBags = ['A', 'B', 'C']; // only 3 at first\r\n\r\n  return {\r\n    getTrashBag: function() {\r\n      return trashBags.pop();\r\n    }\r\n  };\r\n}\r\n\r\nvar kitchen = makeKitchen();\r\n\r\nconsole.log(kitchen.getTrashBag()); // returns trash bag C\r\nconsole.log(kitchen.getTrashBag()); // returns trash bag B\r\nconsole.log(kitchen.getTrashBag()); // returns trash bag AFurther points that explain why closures are interesting:",
                "I need to know how many times a button has been clicked and do something on every third click...// Declare counter outside event handler's scope\nvar counter = 0;\nvar element = document.getElementById('button');\n\nelement.addEventListener(\"click\", function() {\n  // Increment outside counter\n  counter++;\n\n  if (counter === 3) {\n    // Do something every third time\n    console.log(\"Third time's the charm!\");\n\n    // Reset counter\n    counter = 0;\n  }\n});\n<button id=\"button\">Click Me!</button>Now this will work, but it does encroach into the outer scope by adding a variable, whose sole purpose is to keep track of the count. In some situations, this would be preferable as your outer application might need access to this information. But in this case, we are only changing every third click's behavior, so it is preferable to enclose this functionality inside the event handler.var element = document.getElementById('button');\n\nelement.addEventListener(\"click\", (function() {\n  // init the count to 0\n  var count = 0;\n\n  return function(e) { // <- This function becomes the click handler\n    count++; //    and will retain access to the above `count`\n\n    if (count === 3) {\n      // Do something every third time\n      console.log(\"Third time's the charm!\");\n\n      //Reset counter\n      count = 0;\n    }\n  };\n})());\n<button id=\"button\">Click Me!</button>Notice a few things here.In the above example, I am using the closure behavior of JavaScript. This behavior allows any function to have access to the scope in which it was created, indefinitely. To practically apply this, I immediately invoke a function that returns another function, and because the function I'm returning has access to the internal count variable (because of the closure behavior explained above) this results in a private scope for usage by the resulting function... Not so simple? Let's dilute it down...A simple one-line closureAll variables outside the returned function are available to the returned function, but they are not directly available to the returned function object...Get it? So in our primary example, the count variable is contained within the closure and always available to the event handler, so it retains its state from click to click.Also, this private variable state is fully accessible, for both readings and assigning to its private scoped variables.There you go; you're now fully encapsulating this behavior.Full Blog Post (including jQuery considerations)",
                "Closures are hard to explain because they are used to make some behaviour work that everybody intuitively expects to work anyway. I find the best way to explain them (and the way that I learned what they do) is to imagine the situation without them:const makePlus = function(x) {\n    return function(y) { return x + y; };\n}\n\nconst plus5 = makePlus(5);\nconsole.log(plus5(3));What would happen here if JavaScript didn't know closures? Just replace the call in the last line by its method body (which is basically what function calls do) and you get:Now, where's the definition of x? We didn't define it in the current scope. The only solution is to let plus5 carry its scope (or rather, its parent's scope) around. This way, x is well-defined and it is bound to the value 5.",
                "TLDRA closure is a link between a function and its outer lexical (ie. as-written) environment, such that the identifiers (variables, parameters, function declarations etc) defined within that environment are visible from within the function, regardless of when or from where the function is invoked.DetailsIn the terminology of the ECMAScript specification, a closure can be said to be implemented by the [[Environment]] reference of every function-object, which points to the lexical environment within which the function is defined.When a function is invoked via the internal [[Call]] method, the [[Environment]] reference on the function-object is copied into the outer environment reference of the environment record of the newly-created execution context (stack frame).In the following example, function f closes over the lexical environment of the global execution context:In the following example, function h closes over the lexical environment of function g, which, in turn, closes over the lexical environment of the global execution context.If an inner function is returned by an outer, then the outer lexical environment will persist after the outer function has returned. This is because the outer lexical environment needs to be available if the inner function is eventually invoked.In the following example, function j closes over the lexical environment of function i, meaning that variable x is visible from inside function j, long after function i has completed execution:function i() {\r\n    var x = 'mochacchino'\r\n    return function j() {\r\n        console.log('Printing the value of x, from within function j: ', x)\r\n    }\r\n} \r\n\r\nconst k = i()\r\nsetTimeout(k, 500) // invoke k (which is j) after 500msIn a closure, the variables in the outer lexical environment themselves are available, not copies.function l() {\r\n  var y = 'vanilla';\r\n\r\n  return {\r\n    setY: function(value) {\r\n      y = value;\r\n    },\r\n    logY: function(value) {\r\n      console.log('The value of y is: ', y);\r\n    }\r\n  }\r\n}\r\n\r\nconst o = l()\r\no.logY() // The value of y is: vanilla\r\no.setY('chocolate')\r\no.logY() // The value of y is: chocolateThe chain of lexical environments, linked between execution contexts via outer environment references, forms a scope chain and defines the identifiers visible from any given function.Please note that in an attempt to improve clarity and accuracy, this answer has been substantially changed from the original.",
                "OK, 6-year-old closures fan. Do you want to hear the simplest example of closure?Let's imagine the next situation: a driver is sitting in a car. That car is inside a plane. Plane is in the airport. The ability of driver to access things outside his car, but inside the plane, even if that plane leaves an airport, is a closure. That's it. When you turn 27, look at the more detailed explanation or at the example below.Here is how I can convert my plane story into the code.var plane = function(defaultAirport) {\r\n\r\n  var lastAirportLeft = defaultAirport;\r\n\r\n  var car = {\r\n    driver: {\r\n      startAccessPlaneInfo: function() {\r\n        setInterval(function() {\r\n          console.log(\"Last airport was \" + lastAirportLeft);\r\n        }, 2000);\r\n      }\r\n    }\r\n  };\r\n  car.driver.startAccessPlaneInfo();\r\n\r\n  return {\r\n    leaveTheAirport: function(airPortName) {\r\n      lastAirportLeft = airPortName;\r\n    }\r\n  }\r\n}(\"Boryspil International Airport\");\r\n\r\nplane.leaveTheAirport(\"John F. Kennedy\");",
                "This is an attempt to clear up several (possible) misunderstandings about closures that appear in some of the other answers.",
                "I wrote a blog post a while back explaining closures. Here's what I said about closures in terms of why you'd want one.Closures are a way to let a function\n  have persistent, private variables -\n  that is, variables that only one\n  function knows about, where it can\n  keep track of info from previous times\n  that it was run.In that sense, they let a function act a bit like an object with private attributes.Full post:So what are these closure thingys?",
                "The original question had a quote:If you can't explain it to a six-year old, you really don't understand it yourself.This is how I'd try to explain it to an actual six-year-old:You know how grown-ups can own a house, and they call it home? When a mom has a child, the child doesn't really own anything, right? But its parents own a house, so whenever someone asks \"Where's your home?\", the child can answer \"that house!\", and point to the house of its parents.A \"Closure\" is the ability of the child to always (even if abroad) be able to refer to its home, even though it's really the parent's who own the house.",
                "The following simple example covers all the main points of JavaScript closures.*Here is a factory that produces calculators that can add and multiply:The key point: Each call to make_calculator creates a new local variable n, which continues to be usable by that calculator's add and multiply functions long after make_calculator returns.If you are familiar with stack frames, these calculators seem strange: How can they keep accessing n after make_calculator returns?  The answer is to imagine that JavaScript doesn't use \"stack frames\", but instead uses \"heap frames\", which can persist after the function call that made them returns.Inner functions like add and multiply, which access variables declared in an outer function**, are called closures.That is pretty much all there is to closures.* For example, it covers all the points in the \"Closures for Dummies\" article given in another answer, except example 6, which simply shows that variables can be used before they are declared, a nice fact to know but completely unrelated to closures. It also covers all the points in the accepted answer, except for the points (1) that functions copy their arguments into local variables (the named function arguments), and (2) that copying numbers creates a new number, but copying an object reference gives you another reference to the same object. These are also good to know but again completely unrelated to closures. It is also very similar to the example in this answer but a bit shorter and less abstract. It does not cover the point of this answer or this comment, which is that JavaScript makes it difficult to plug the current value of a loop variable into your inner function: The \"plugging in\" step can only be done with a helper function that encloses your inner function and is invoked on each loop iteration. (Strictly speaking, the inner function accesses the helper function's copy of the variable, rather than having anything plugged in.) Again, very useful when creating closures, but not part of what a closure is or how it works. There is additional confusion due to closures working differently in functional languages like ML, where variables are bound to values rather than to storage space, providing a constant stream of people who understand closures in a way (namely the \"plugging in\" way) that is simply incorrect for JavaScript, where variables are always bound to storage space, and never to values.** Any outer function, if several are nested, or even in the global context, as this answer points out clearly.",
                "I still think Google's explanation works very well and is concise:*A C# question",
                "I tend to learn better by GOOD/BAD comparisons. I like to see working code followed by non-working code that someone is likely to encounter. I put together a jsFiddle that does a comparison and tries to boil down the differences to the simplest explanations I could come up with.In the above code createClosure(n) is invoked in every iteration of the loop. Note that I named the variable n to highlight that it is a new variable created in a new function scope and is not the same variable as index which is bound to the outer scope.This creates a new scope and n is bound to that scope; this means we have 10 separate scopes, one for each iteration.createClosure(n) returns a function that returns the n within that scope.Within each scope n is bound to whatever value it had when createClosure(n) was invoked so the nested function that gets returned will always return the value of n that it had when createClosure(n) was invoked.In the above code the loop was moved within the createClosureArray() function and the function now just returns the completed array, which at first glance seems more intuitive.What might not be obvious is that since createClosureArray() is only invoked once only one scope is created for this function instead of one for every iteration of the loop.Within this function a variable named index is defined. The loop runs and adds functions to the array that return index. Note that index is defined within the createClosureArray function which only ever gets invoked one time.Because there was only one scope within the createClosureArray() function, index is only bound to a value within that scope. In other words, each time the loop changes the value of index, it changes it for everything that references it within that scope.All of the functions added to the array return the SAME index variable from the parent scope where it was defined instead of 10 different ones from 10 different scopes like the first example. The end result is that all 10 functions return the same variable from the same scope.After the loop finished and index was done being modified the end value was 10, therefore every function added to the array returns the value of the single index variable which is now set to 10.CLOSURES DONE RIGHT\nn = 0\nn = 1\nn = 2\nn = 3\nn = 4\nn = 5\nn = 6\nn = 7\nn = 8\nn = 9CLOSURES DONE WRONG\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10",
                "Wikipedia on closures:In computer science, a closure is a function together with a referencing environment for the nonlocal names (free variables) of that function.Technically, in JavaScript, every function is a closure. It always has an access to variables defined in the surrounding scope.Since scope-defining construction in JavaScript is a function, not a code block like in many other languages, what we usually mean by closure in JavaScript is a function working with nonlocal variables defined in already executed surrounding function.Closures are often used for creating functions with some hidden private data (but it's not always the case).emsThe example above is using an anonymous function, which was executed once. But it does not have to be. It can be named (e.g. mkdb) and executed later, generating a database function each time it is invoked. Every generated function will have its own hidden database object. Another usage example of closures is when we don't return a function, but an object containing multiple functions for different purposes, each of those function having access to the same data.",
                "I put together an interactive JavaScript tutorial to explain how closures work.\nWhat's a Closure?Here's one of the examples:",
                "The children will never forget the secrets they have shared with their parents, even after their parents are\ngone. This is what closures are for functions.The secrets for JavaScript functions are the private variablesEvery time you call it, the local variable \"name\" is created and given the name \"Mary\". And every time the function exits the variable is lost and the name is forgotten.As you may guess, because the variables are re-created every time the function is called, and nobody else will know them, there must be a secret place where they are stored. It could be called Chamber of Secrets or stack or local scope but it doesn't matter. We know they are there, somewhere, hidden in the memory.But, in JavaScript, there is this very special thing that functions which are created inside other functions, can also know the local variables of their parents and keep them as long as they live.So, as long as we are in the parent -function, it can create one or more child functions which do share the secret variables from the secret place.But the sad thing is, if the child is also a private variable of its parent function, it would also die when the parent ends, and the secrets would die with them.So to live, the child has to leave before it's too lateAnd now, even though Mary is \"no longer running\", the memory of her is not lost and her child will always remember her name and other secrets they shared during their time together.So, if you call the child \"Alice\", she will respondThat's all there is to tell.",
                "I do not understand why the answers are so complex here.Here is a closure:Yes. You probably use that many times a day.There is no reason to believe closures are a complex design hack to address specific problems. No, closures are just about using a variable that comes from a higher scope from the perspective of where the function was declared (not run).Now what it allows you to do can be more spectacular, see other answers.",
                "A closure is where an inner function has access to variables in its outer function. That's probably the simplest one-line explanation you can get for closures.",
                "Example for the first point by dlaliberte:A closure is not only created when you return an inner function. In fact, the enclosing function does not need to return at all. You might instead assign your inner function to a variable in an outer scope, or pass it as an argument to another function where it could be used immediately. Therefore, the closure of the enclosing function probably already exists at the time that enclosing function was called since any inner function has access to it as soon as it is called.",
                "I know there are plenty of solutions already, but I guess that this small and simple script can be useful to demonstrate the concept:",
                "You're having a sleep over and you invite Dan.\nYou tell Dan to bring one XBox controller.Dan invites Paul.\nDan asks Paul to bring one controller. How many controllers were brought to the party?",
                "The author of Closures has explained closures pretty well, explaining the reason why we need them and also explaining LexicalEnvironment which is necessary to understanding closures. \nHere is the summary:What if a variable is accessed, but it isn\u2019t local? Like here:In this case, the interpreter finds the variable in the\nouter LexicalEnvironment object.The process consists of two steps:When a function is created, it gets a hidden property, named [[Scope]], which references the current LexicalEnvironment.If a variable is read, but can not be found anywhere, an error is generated.Nested functionsFunctions can be nested one inside another, forming a chain of LexicalEnvironments which can also be called a scope chain.So, function g has access to g, a and f.ClosuresA nested function may continue to live after the outer function has finished:Marking up LexicalEnvironments:As we see, this.say is a property in the user object, so it continues to live after User completed.And if you remember, when this.say is created, it (as every function) gets an internal reference this.say.[[Scope]] to the current LexicalEnvironment. So, the LexicalEnvironment of the current User execution stays in memory. All variables of User also are its properties, so they are also carefully kept, not junked as usually.The whole point is to ensure that if the inner function wants to access an outer variable in the future, it is able to do so.To summarize:This is called a closure.",
                "JavaScript functions can access their:If a function accesses its environment, then the function is a closure.Note that outer functions are not required, though they do offer benefits I don't discuss here. By accessing data in its environment, a closure keeps that data alive. In the subcase of outer/inner functions, an outer function can create local data and eventually exit, and yet, if any inner function(s) survive after the outer function exits, then the inner function(s) keep the outer function's local data alive.Example of a closure that uses the global environment:Imagine that the Stack Overflow Vote-Up and Vote-Down button events are implemented as closures, voteUp_click and voteDown_click, that have access to external variables isVotedUp and isVotedDown, which are defined globally. (For simplicity's sake, I am referring to StackOverflow's Question Vote buttons, not the array of Answer Vote buttons.)When the user clicks the VoteUp button, the voteUp_click function checks whether isVotedDown == true to determine whether to vote up or merely cancel a down vote. Function voteUp_click is a closure because it is accessing its environment.All four of these functions are closures as they all access their environment.",
                "As a father of a 6-year-old, currently teaching young children (and a relative novice to coding with no formal education so corrections will be required), I think the lesson would stick best through hands-on play. If the 6-year-old is ready to understand what a closure is, then they are old enough to have a go themselves. I'd suggest pasting the code into jsfiddle.net, explaining a bit, and leaving them alone to concoct a unique song. The explanatory text below is probably more appropriate for a 10 year old.INSTRUCTIONSDATA: Data is a collection of facts. It can be numbers, words, measurements, observations or even just descriptions of things. You can't touch it, smell it or taste it. You can write it down, speak it and hear it. You could use it to create touch smell and taste using a computer. It can be made useful by a computer using code.CODE: All the writing above is called code. It is written in JavaScript.JAVASCRIPT: JavaScript is a language. Like English or French or Chinese are languages. There are lots of languages that are understood by computers and other electronic processors. For JavaScript to be understood by a computer it needs an interpreter. Imagine if a teacher who only speaks Russian comes to teach your class at school. When the teacher says \"\u0432\u0441\u0435 \u0441\u0430\u0434\u044f\u0442\u0441\u044f\", the class would not understand. But luckily you have a Russian pupil in your class who tells everyone this means \"everybody sit down\" - so you all do. The class is like a computer and the Russian pupil is the interpreter. For JavaScript the most common interpreter is called a browser.BROWSER: When you connect to the Internet on a computer, tablet or phone to visit a website, you use a browser. Examples you may know are Internet Explorer, Chrome, Firefox and Safari. The browser can understand JavaScript and tell the computer what it needs to do. The JavaScript instructions are called functions.FUNCTION: A function in JavaScript is like a factory. It might be a little factory with only one machine inside. Or it might contain many other little factories, each with many machines doing different jobs. In a real life clothes factory you might have reams of cloth and bobbins of thread going in and T-shirts and jeans coming out. Our JavaScript factory only processes data, it can't sew, drill a hole or melt metal. In our JavaScript factory data goes in and data comes out.All this data stuff sounds a bit boring, but it is really very cool; we might have a function that tells a robot what to make for dinner. Let's say I invite you and your friend to my house. You like chicken legs best, I like sausages, your friend always wants what you want and my friend does not eat meat.I haven't got time to go shopping, so the function needs to know what we have in the fridge to make decisions. Each ingredient has a different cooking time and we want everything to be served hot by the robot at the same time. We need to provide the function with the data about what we like, the function could 'talk' to the fridge, and the function could control the robot.A function normally has a name, parentheses and braces. Like this:Note that /*...*/ and // stop code being read by the browser.NAME: You can call a function just about whatever word you want. The example \"cookMeal\" is typical in joining two words together and giving the second one a capital letter at the beginning - but this is not necessary. It can't have a space in it, and it can't be a number on its own.PARENTHESES: \"Parentheses\" or () are the letter box on the JavaScript function factory's door or a post box in the street for sending packets of information to the factory. Sometimes the postbox might be marked for example cookMeal(you, me, yourFriend, myFriend, fridge, dinnerTime), in which case you know what data you have to give it.BRACES: \"Braces\" which look like this {} are the tinted windows of our factory. From inside the factory you can see out, but from the outside you can't see in.THE LONG CODE EXAMPLE ABOVEOur code begins with the word function, so we know that it is one! Then the name of the function sing - that's my own description of what the function is about. Then parentheses (). The parentheses are always there for a function. Sometimes they are empty, and sometimes they have something in. This one has a word in: (person). After this there is a brace like this { . This marks the start of the function sing(). It has a partner which marks the end of sing() like this }So this function might have something to do with singing, and might need some data about a person. It has instructions inside to do something with that data.Now, after the function sing(), near the end of the code is the lineVARIABLE: The letters var stand for \"variable\". A variable is like an envelope. On the outside this envelope is marked \"person\". On the inside it contains a slip of paper with the information our function needs, some letters and spaces joined together like a piece of string (it's called a string) that make a phrase reading \"an old lady\". Our envelope could contain other kinds of things like numbers (called integers), instructions (called functions), lists (called arrays). Because this variable is written outside of all the braces {}, and because you can see out through the tinted windows when you are inside the braces, this variable can be seen from anywhere in the code. We call this a 'global variable'.GLOBAL VARIABLE: person is a global variable, meaning that if you change its value from \"an old lady\" to \"a young man\", the person will keep being a young man until you decide to change it again and that any other function in the code can see that it's a young man. Press the F12 button or look at the Options settings to open the developer console of a browser and type \"person\" to see what this value is. Type person=\"a young man\" to change it and then type \"person\" again to see that it has changed.After this we have the lineThis line is calling the function, as if it were calling a dog\"Come on sing, Come and get person!\"When the browser has loaded the JavaScript code an reached this line, it will start the function. I put the line at the end to make sure that the browser has all the information it needs to run it.Functions define actions  - the main function is about singing. It contains a variable called firstPart which applies to the singing about the person that applies to each of the verses of the song: \"There was \" + person + \" who swallowed\". If you type firstPart into the console, you won't get an answer because the variable is locked up in a function - the browser can't see inside the tinted windows of the braces.CLOSURES: The closures are the smaller functions that are inside the big sing() function. The little factories inside the big factory. They each have their own braces which mean that the variables inside them can't be seen from the outside. That's why the names of the variables (creature and result) can be repeated in the closures but with different values. If you type these variable names in the console window, you won't get its value because it's hidden by two layers of tinted windows.The closures all know what the sing() function's variable called firstPart is, because they can see out from their tinted windows.After the closures come the linesThe sing() function will call each of these functions in the order they are given. Then the sing() function's work will be done.",
                "Okay, talking with a 6-year old child, I would possibly use following associations.Imagine - you are playing with your little brothers and sisters in the entire house, and you are moving around with your toys and brought some of them into your older brother's room. After a while your brother returned from the school and went to his room, and he locked inside it, so now you could not access toys left there anymore in a direct way. But you could knock the door and ask your brother for that toys. This is called toy's closure; your brother made it up for you, and he is now into outer scope.Compare with a situation when a door was locked by draft and nobody inside (general function execution), and then some local fire occur and burn down the room (garbage collector:D), and then a new room was build and now you may leave another toys there (new function instance), but never get the same toys which were left in the first room instance.For an advanced child I would put something like the following. It is not perfect, but it makes you feel about what it is:As you can see, the toys left in the room are still accessible via the brother and no matter if the room is locked. Here is a jsbin to play around with it.",
                "A function in JavaScript is not just a reference to a set of instructions (as in C language), but it also includes a hidden data structure which is composed of references to all nonlocal variables it uses (captured variables). Such two-piece functions are called closures. Every function in JavaScript can be considered a closure.Closures are functions with a state. It is somewhat similar to \"this\" in the sense that \"this\" also provides state for a function but function and \"this\" are separate objects (\"this\" is just a fancy parameter, and the only way to bind it permanently to a function is to create a closure). While \"this\" and function always live separately, a function cannot be separated from its closure and the language provides no means to access captured variables.Because all these external variables referenced by a lexically nested function are actually local variables in the chain of its lexically enclosing functions (global variables can be assumed to be local variables of some root function), and every single execution of a function creates new instances of its local variables, it follows that every execution of a function returning (or otherwise transferring it out, such as registering it as a callback) a nested function creates a new closure (with its own potentially unique set of referenced nonlocal variables which represent its execution context).Also, it must be understood that local variables in JavaScript are created not on the stack frame, but on the heap and destroyed only when no one is referencing them. When a function returns, references to its local variables are decremented, but they can still be non-null if during the current execution they became part of a closure and are still referenced by its lexically nested functions (which can happen only if the references to these nested functions were returned or otherwise transferred to some external code).An example:",
                "An answer for a six-year-old (assuming he knows what a function is and what a variable is, and what data is):Functions can return data. One kind of data you can return from a function is another function. When that new function gets returned, all the variables and arguments used in the function that created it don't go away. Instead, that parent function \"closes.\" In other words, nothing can look inside of it and see the variables it used except for the function it returned. That new function has a special ability to look back inside the function that created it and see the data inside of it.Another really simple way to explain it is in terms of scope:Any time you create a smaller scope inside of a larger scope, the smaller scope will always be able to see what is in the larger scope.",
                "Perhaps a little beyond all but the most precocious of six-year-olds, but a few examples that helped make the concept of closure in JavaScript click for me.A closure is a function that has access to another function's scope (its variables and functions). The easiest way to create a closure is with a function within a function; the reason being that in JavaScript a function always has access to its containing function\u2019s scope.function outerFunction() {\r\n    var outerVar = \"monkey\";\r\n    \r\n    function innerFunction() {\r\n        alert(outerVar);\r\n    }\r\n    \r\n    innerFunction();\r\n}\r\n\r\nouterFunction();ALERT: monkeyIn the above example, outerFunction is called which in turn calls innerFunction. Note how outerVar is available to innerFunction, evidenced by its correctly alerting the value of outerVar.Now consider the following:function outerFunction() {\r\n    var outerVar = \"monkey\";\r\n    \r\n    function innerFunction() {\r\n        return outerVar;\r\n    }\r\n    \r\n    return innerFunction;\r\n}\r\n\r\nvar referenceToInnerFunction = outerFunction();\r\nalert(referenceToInnerFunction());ALERT: monkeyreferenceToInnerFunction is set to outerFunction(), which simply returns a reference to innerFunction. When referenceToInnerFunction is called, it returns outerVar. Again, as above, this demonstrates that innerFunction has access to outerVar, a variable of outerFunction. Furthermore, it is interesting to note that it retains this access even after outerFunction has finished executing.And here is where things get really interesting. If we were to get rid of outerFunction, say set it to null, you might think that referenceToInnerFunction would loose its access to the value of outerVar. But this is not the case.function outerFunction() {\r\n    var outerVar = \"monkey\";\r\n    \r\n    function innerFunction() {\r\n        return outerVar;\r\n    }\r\n    \r\n    return innerFunction;\r\n}\r\n\r\nvar referenceToInnerFunction = outerFunction();\r\nalert(referenceToInnerFunction());\r\n\r\nouterFunction = null;\r\nalert(referenceToInnerFunction());ALERT: monkey\nALERT: monkeyBut how is this so? How can referenceToInnerFunction still know the value of outerVar now that outerFunction has been set to null?The reason that referenceToInnerFunction can still access the value of outerVar is because when the closure was first created by placing innerFunction inside of outerFunction, innerFunction added a reference to outerFunction\u2019s scope (its variables and functions) to its scope chain. What this means is that innerFunction has a pointer or reference to all of outerFunction\u2019s variables, including outerVar. So even when outerFunction has finished executing, or even if it is deleted or set to null, the variables in its scope, like outerVar, stick around in memory because of the outstanding reference to them on the part of the innerFunction that has been returned to referenceToInnerFunction. To truly release outerVar and the rest of outerFunction\u2019s variables from memory you would have to get rid of this outstanding reference to them, say by setting referenceToInnerFunction to null as well.//////////Two other things about closures to note. First, the closure will always have access to the last values of its containing function.function outerFunction() {\r\n    var outerVar = \"monkey\";\r\n    \r\n    function innerFunction() {\r\n        alert(outerVar);\r\n    }\r\n    \r\n    outerVar = \"gorilla\";\r\n\r\n    innerFunction();\r\n}\r\n\r\nouterFunction();ALERT: gorillaSecond, when a closure is created, it retains a reference to all of its enclosing function\u2019s variables and functions; it doesn\u2019t get to pick and choose. And but so, closures should be used sparingly, or at least carefully, as they can be memory intensive; a lot of variables can be kept in memory long after a containing function has finished executing.",
                "I'd simply point them to the Mozilla Closures page. It's the best, most concise and simple explanation of closure basics and practical usage that I've found. It is highly recommended to anyone learning JavaScript.And yes, I'd even recommend it to a 6-year old -- if the 6-year old is learning about closures, then it's logical they're ready to comprehend the concise and simple explanation provided in the article."
            ]
        },
        {
            "tag": "git",
            "question": [
                "How do I revert a Git repository to a previous commit?",
                "How do I revert from my current state to a snapshot made on a certain commit?\n\nIf I do git log, then I get the following output:\n\n$ git log\ncommit a867b4af366350be2e7c21b8de9cc6504678a61b`\nAuthor: Me &..."
            ],
            "url": "https://stackoverflow.com/questions/4114095",
            "answer": [
                "This depends a lot on what you mean by \"revert\".If you want to temporarily go back to it, fool around, then come back to where you are, all you have to do is check out the desired commit:Or if you want to make commits while you're there, go ahead and make a new branch while you're at it:To go back to where you were, just check out the branch you were on again. (If you've made changes, as always when switching branches, you'll have to deal with them as appropriate. You could reset to throw them away; you could stash, checkout, stash pop to take them with you; you could commit them to a branch there if you want a branch there.)If, on the other hand, you want to really get rid of everything you've done since then, there are two possibilities. One, if you haven't published any of these commits, simply reset:If you mess up, you've already thrown away your local changes, but you can at least get back to where you were before by resetting again.On the other hand, if you've published the work, you probably don't want to reset the branch, since that's effectively rewriting history. In that case, you could indeed revert the commits. With Git, revert has a very specific meaning: create a commit with the reverse patch to cancel it out. This way you don't rewrite any history.The git-revert manpage actually covers a lot of this in its description. Another useful link is this git-scm.com section discussing git-revert.If you decide you didn't want to revert after all, you can revert the revert (as described here) or reset back to before the revert (see the previous section).You may also find this answer helpful in this case:\nHow can I move HEAD back to a previous location? (Detached head) & Undo commits",
                "Lots of complicated and dangerous answers here, but it's actually easy:This will revert everything from the HEAD back to the commit hash, meaning it will recreate that commit state in the working tree as if every commit after 0766c053 had been walked back. You can then commit the current tree, and it will create a brand new commit essentially equivalent to the commit you \"reverted\" to.(The --no-commit flag lets git revert all the commits at once- otherwise you'll be prompted for a message for each commit in the range, littering your history with unnecessary new commits.)This is a safe and easy way to rollback to a previous state. No history is destroyed, so it can be used for commits that have already been made public.",
                "Working on your own and just want it to work? Follow these instructions below, they\u2019ve worked reliably for me and many others for years.Working with others? Git is complicated. Read the comments below this answer, consider other answers, and discuss with your team before you do something rash.To revert to the previous commit, ignoring any changes:where HEAD is the last commit in your current branchTo revert to a commit that's older than the most recent commit:Credits go to a similar Stack Overflow question, Revert to a commit by a SHA hash in Git?.",
                "The best option for me and probably others is the Git reset option:This has been the best option for me! It is simple, fast and effective!** Note:** As mentioned in comments don't do this if you're sharing your branch with other people who have copies of the old commitsAlso from the comments, if you wanted a less 'ballzy' method you could use",
                "Before answering let's add some background, explaining what this HEAD is.HEAD is simply a reference to the current commit (latest) on the current branch. There can only be a single HEAD at any given time (excluding git worktree).The content of HEAD is stored inside .git/HEAD, and it contains the 40-bytes SHA-1 hash of the current commit.If you are not on the latest commit - meaning that HEAD is pointing to a prior commit in history it's called detached HEAD.On the command-line it will look like this - SHA-1 hash instead of the branch name since the HEAD is not pointing to the the tip of the current branch:This will checkout new branch pointing to the desired commit. This command will checkout to a given commit.At this point you can create a branch and start to work from this point on:You can always use the reflog as well. git reflog  will display any change which updated the HEAD and checking out the desired reflog entry will set the HEAD back to this commit.Every time the HEAD is modified there will be a new entry in the reflogThis will get you back to your desired commit.\"Move\" your HEAD back to the desired commit.This schema illustrates which command does what. As you can see there reset && checkout modify the HEAD.",
                "You can do this by the following two commands:It will remove your previous Git commit.If you want to keep your changes, you can also use:Then it will save your changes.",
                "If you want to \"uncommit\", erase the last commit message, and put the modified files back in staging, you would use the command:This is an extremely useful command in situations where you committed the wrong thing and you want to undo that last commit.Source: http://nakkaya.com/2009/09/24/git-delete-last-commit/",
                "The best way is:This will reset the branch to the specific commit and then will upload the remote server with the same commits as you have in local.Be careful with the --force flag as it removes all the subsequent commits after the selected commit without the option to recover them.",
                "I have tried a lot of ways to revert local changes in Git, and it seems that this works the best if you just want to revert to the latest commit state.Short description:I found a much more convenient and simple way to achieve the results above:where HEAD points to the latest commit at you current branch.It is the same code code as boulder_ruby suggested, but I have added git add . before  git reset --hard HEAD to erase all new files created since the last commit since this is what most people expect I believe when reverting to the latest commit.",
                "OK, going back to a previous commit in Git is quite easy...Revert back without keeping the changes:Revert back with keeping the changes:Explanation: using git reset, you can reset to a specific state. It's common using it with a commit hash as you see above.But as you see the difference is using the two flags --soft and --hard, by default git reset using --soft flag, but it's a good practice always using the flag, I explain each flag:The default flag as explained, not need to provide it, does not change the working tree, but it adds all changed files ready to commit, so you go back to the commit status which changes to files get unstaged.Be careful with this flag. It resets the working tree and all changes to tracked files and all will be gone!I also created the image below that may happen in a real life working with Git:",
                "Assuming you're talking about master and on that respective branch (that said, this could be any working branch you're concerned with):I found the answer from in a blog post (now no longer exists)Note that this is Resetting and Forcing the change to the remote, so that if others on your team have already git pulled, you will cause problems for them. You are destroying the change history, which is an important reason why people use git in the first place.Better to use revert (see other answers) than reset. \nIf you're a one man team then it probably doesn't matter.",
                "Jefromi's solutions are definitely the best ones, and you should definitely use them. However, for the sake of completeness, I also wanted to show these other alternative solutions that can also be used to revert a commit (in the sense that you create a new commit that undoes changes in previous commit, just like what git revert does).To be clear, these alternatives are not the best way to revert commits, Jefromi's solutions are, but I just want to point out that you can also use these other methods to achieve the same thing as git revert.This is a very slightly modified version of Charles Bailey's solution to Revert to a commit by a SHA hash in Git?:This basically works by using the fact that soft resets will leave the state of the previous commit staged in the index/staging-area, which you can then commit.This solution comes from svick's solution to Checkout old commit and make it a new commit:Similarly to alternative #1, this reproduces the state of <commit> in the current working copy. It is necessary to do git rm first because git checkout won't remove files that have been added since <commit>.",
                "Say you have the following commits in a text file named ~/commits-to-revert.txt (I used git log --pretty=oneline to get them)Create a Bash shell script to revert each of them:This reverts everything back to the previous state, including file and directory creations, and deletions, commit it to your branch and you retain the history, but you have it reverted back to the same file structure. Why Git doesn't have a git revert --to <hash> is beyond me.",
                "Here is a much simpler way to go back to a previous commit (and have it in an uncommited state, to do with it whatever you like):So, no need for commit ids and so on :)",
                "You can complete all these initial steps yourself and push back to the Git repository.Pull the latest version of your repository from Bitbucket using the git pull --all command.Run the Git log command with -n 4 from your terminal. The number after the -n determines the number of commits in the log starting from the most recent commit in your local history.Reset the head of your repository's history using the git reset --hard HEAD~N where N is the number of commits you want to take the head back. In the following example the head would be set back one commit, to the last commit in the repository history:Push the change to Git repository using git push --force to force push the change.If you want the Git repository to a previous commit:-",
                "Caution! This command can cause losing commit history, if user put the wrong commit mistakenly. Always have en extra backup of your git some\nwhere else just in case if you do mistakes, than you are a bit safer.\n:)I have had a similar issue and wanted to revert back to an earlier commit. In my case I was not interested to keep the newer commit, hence I used Hard.This is how I did it:This will revert on the local repository, and here after using git push -f will update the remote repository.For instance, if you want to completely ignore the commit with the name enforce non-group manage policies from the next imageyou'd runfollowed byAfter, you won't see that commit (enforce non-group manage policies) there",
                "After all the changes, when you push all these commands, you might have to use:And not only git push.",
                "Revert is the command to rollback the commits.Sample:It is capable of taking range from the HEAD like below. Here 1 says \"revert last commit.\"And then do:",
                "There is a command (not a part of core Git, but it is in the git-extras package) specifically for reverting and staging old commits:Per the man page, it can also be used as such:",
                "If the situation is an urgent one, and you just want to do what the questioner asked in a quick and dirty way, assuming your project is under a directory called, for example, \"my project\":QUICK AND DIRTY: depending on the circumstances, quick and dirty may in fact be very GOOD. What my solution here does is NOT replace irreversibly the files you have in your working directory with files hauled up/extracted from the depths of the git repository lurking beneath your .git/ directory using fiendishly clever and diabolically powerful git commands, of which there are many. YOU DO NOT HAVE TO DO SUCH DEEP-SEA DIVING TO RECOVER what may appear to be a disastrous situation, and attempting to do so without sufficient expertise may prove fatal.Copy the whole directory and call it something else, like \"my project - copy\". Assuming your git repository (\"repo\") files are under the \"my project\" directory (the default place for them, under a directory called \".git\"), you will now have copied both your work files and your repo files.Do this in the directory \"my project\":This will return the state of the repo under \"my project\" to what it was when you made that commit (a \"commit\" means a snapshot of your working files). All commits since the \"resetted\" commit will be lost forever under \"my project\", BUT... they will still be present in the repo under \"my project - copy\" since you copied all those files - including the ones in the repo, under .../.git/.You then have two versions on your system... you can examine or copy or modify files of interest, or whatever, from the previous commit. You can completely discard the files under \"my project - copy\", if you have decided the new work since the restored commit was going nowhere...The obvious thing if you want to carry on with the state of the project without actually discarding the work since this retrieved commit is to rename your directory again: Delete the project containing the retrieved commit (or give it a temporary name) and rename your \"my project - copy\" directory back to \"my project\". Then maybe try to understand some of the other answers here, and probably do another commit fairly soon.Git is a brilliant creation but absolutely no-one is able to just \"pick it up on the fly\": also people who try to explain it far too often assume prior knowledge of other VCS [Version Control Systems] and delve far too deep far too soon, and commit other terrible crimes, like using interchangeable terms for \"checking out\" - in ways which sometimes appear almost calculated to confuse a beginner.To save yourself much stress, learn from my scars. You have to pretty much have to read a book on Git - I'd recommend reading THE BOOK, Pro Git 2nd edition: available for free download etc. from git central. Published 2014 but, as at early 2022, still the best. Do it sooner rather than later: Git is destined to be part of your life from now on. If you do, bear in mind that much of the complexity of Git comes from branching and then remerging: the Pro Git book actually introduces this central aspect very gently, but you can skip those parts in any book on your first read. From your question there's no reason why people should be blinding you with science.Especially if, for example, this is a desperate situation and you're a newbie with Git!PS: (slight caution) One other thought: It is (now) actually quite simple to keep the Git repo in a directory other than the one with the working files. This would mean you would not copy the entire Git repository using the above quick & dirty solution. See the answer by Fryer using --separate-git-dir here. Bearing that in mind, be warned: If you have a \"separate-directory\" repository which you don't copy, and you do a hard reset, all versions subsequent to the reset commit really will be lost forever forever, unless you have, as you absolutely should, regularly backed up your repository, preferably to the Cloud (e.g. Google Drive) among other places.On this subject of \"backing up to the Cloud\", the next step is to open an account (free of course) with GitHub or (better in my view) GitLab. You can then regularly do a git push command to make your Cloud repo up-to-date \"properly\". But again, talking about this may be too much too soon: git push has to be configured, can fail to work for a totally baffling technical reason, involves learning about remote repos (\"origin\", etc). So a quick-and-dirty Cloud-based backup approach may be preferable until you become knowledgeable. Again, the Pro Git book introduces how remote repositories work, and relate to your local repo, very gently and rationally.",
                "Try resetting to the desired commit:To check COMMIT_ID use:This will reset all changed files to un-added state.Now you can checkout all un-added files byTo verify your changes use:UPDATEIf you have one and only commit in your repo, try",
                "Select your required commit, and check it bytill you get the required commit. To make the HEAD point to that, door git reset --hard HEAD~2 or whatever.",
                "Revert to most recent commit and ignoring all local changes:",
                "Idea: You basically want to replace the current working tree state with the one from a previous commit and then create a commit out of it. Ignored files should best be not changed. Here is how:Emtpy the working tree *.Bring the working tree in the state we want **.Create the revert commit.At first I thought that Yarins answer would be the best, but it doesn't work for merge commits. This solution does.Additionally it does not delete anything (pushed or upushed) from the history. It produces one clean commit which represents the state we want to revert back to.* by removing untracked but not ignored files (the ones specified in .gitignore) from working tree. The working tree is empty except for the ignored files which we wanted to keep (if not specifiy -x option for clean)** When a path is specified (here: .), checkout leaves HEAD alone.",
                "It directly clears all the changes that you have been making since the last commit.PS: It has a little problem; it also deletes all you recently stored stash changes. Which I guess in most cases should not matter.",
                "To completely clean a coder's directory up from some accidental changes, we used:Just git reset --hard HEAD will get rid of modifications, but it won't get rid of \"new\" files. In their case they'd accidentally dragged an important folder somewhere random, and all those files were being treated as new by Git, so a reset --hard didn't fix it. By running the git add -A . beforehand, it explicitly tracked them all with git, to be wiped out by the reset.",
                "I believe some people may come to this question wanting to know how to rollback committed changes they've made in their master - ie throw everything away and go back to origin/master, in which case, do this:https://superuser.com/questions/273172/how-to-reset-master-to-origin-master",
                "To keep the changes from the previous commit to HEAD and move to the previous commit, do:If changes are not required from the previous commit to HEAD and just discard all changes, do:",
                "As your commits are pushed remotely, you need to remove them. Let me assume your branch is develop and it is pushed over origin.You first need to remove develop from origin:Then you need to get develop to the status you want, let me assume the commit hash is EFGHIJK:Lastly, push develop again:",
                "If you want to correct some error in the last commit a good alternative would be using git commit --amend command. If the last commit is not pointed by any reference, this will do the trick, as it create a commit with the same parent as the last commit. If there is no reference to the last commit, it will simply be discarded and this commit will be the last commit. This is a good way of correcting commits without reverting commits. However it has its own limitations."
            ]
        },
        {
            "tag": "java",
            "question": [
                "Is Java \"pass-by-reference\" or \"pass-by-value\"?",
                "I always thought Java uses pass-by-reference.\nHowever, I've seen a blog post that claims that Java uses pass-by-value.\nI don't think I understand the distinction they're making.\nWhat is the ..."
            ],
            "url": "https://stackoverflow.com/questions/40480",
            "answer": [
                "The terms \"pass-by-value\" and \"pass-by-reference\" have special, precisely defined meanings in computer science. These meanings differ from the intuition many people have when first hearing the terms. Much of the confusion in this discussion seems to come from this fact.The terms \"pass-by-value\" and \"pass-by-reference\" are talking about variables. Pass-by-value means that the value of a variable is passed to a function/method. Pass-by-reference means that a reference to that variable is passed to the function. The latter gives the function a way to change the contents of the variable.By those definitions, Java is always pass-by-value.  Unfortunately, when we deal with variables holding objects we are really dealing with object-handles called references which are passed-by-value as well.  This terminology and semantics easily confuse many beginners.It goes like this:In the example above aDog.getName() will still return \"Max\". The value aDog within main is not changed in the function foo with the Dog \"Fifi\" as the object reference is passed by value. If it were passed by reference, then the aDog.getName() in main would return \"Fifi\" after the call to foo.Likewise:In the above example, Fifi is the dog's name after call to foo(aDog) because the object's name was set inside of foo(...). Any operations that foo performs on d are such that, for all practical purposes, they are performed on aDog, but it is not possible to change the value of the variable aDog itself.For more information on pass by reference and pass by value, consult the following answer: https://stackoverflow.com/a/430958/6005228. This explains more thoroughly the semantics and history behind the two and also explains why Java and many other modern languages appear to do both in certain cases.",
                "I just noticed you referenced my article.The Java Spec says that everything in Java is pass-by-value. There is no such thing as \"pass-by-reference\" in Java.The key to understanding this is that something likeis not a Dog; it's actually a pointer to a Dog. The use of the term \"reference\" in Java is very misleading and is what causes most of the confusion here. What they call \"references\" act/feel more like what we'd call \"pointers\" in most other languages.What that means, is when you haveyou're essentially passing the address of the created Dog object to the foo method.(I say essentially because Java pointers/references aren't direct addresses, but it's easiest to think of them that way.)Suppose the Dog object resides at memory address 42. This means we pass 42 to the method.if the Method were defined aslet's look at what's happening.Now let's think about what happens outside the method:Did myDog change?There's the key.Keeping in mind that myDog is a pointer, and not an actual Dog, the answer is NO. myDog still has the value 42; it's still pointing to the original Dog (but note that because of line \"AAA\", its name is now \"Max\" - still the same Dog; myDog's value has not changed.)It's perfectly valid to follow an address and change what's at the end of it; that does not change the variable, however.Java works exactly like C. You can assign a pointer, pass the pointer to a method, follow the pointer in the method and change the data that was pointed to. However, the caller will not see any changes you make to where that pointer points. (In a language with pass-by-reference semantics, the method function can change the pointer and the caller will see that change.)In C++, Ada, Pascal and other languages that support pass-by-reference, you can actually change the variable that was passed.If Java had pass-by-reference semantics, the foo method we defined above would have changed where myDog was pointing when it assigned someDog on line BBB.Think of reference parameters as being aliases for the variable passed in. When that alias is assigned, so is the variable that was passed in.A discussion in the comments warrants some clarification...In C, you can writeThis is not a special case in C. Both languages use pass-by-value semantics. Here the call site is creating additional data structure to assist the function to access and manipulate data.The function is being passed pointers to data, and follows those pointers to access and modify that data.A similar approach in Java, where the caller sets up assisting structure, might be:(or if you wanted both examples to demonstrate features the other language doesn't have, create a mutable IntWrapper class to use in place of the arrays)In these cases, both C and Java are simulating pass-by-reference. They're still both passing values (pointers to ints or arrays), and following those pointers inside the called function to manipulate the data.Pass-by-reference is all about the function declaration/definition, and how it handles its parameters. Reference semantics apply to every call to that function, and the call site only needs to pass variables, no additional data structure.These simulations require the call site and the function to cooperate. No doubt it's useful, but it's still pass-by-value.",
                "Java always passes arguments by value, NOT by reference.Let me explain this through an example:I will explain this in steps:Declaring a reference named f of type Foo and assign it a new object of type Foo with an attribute \"f\".From the method side, a reference of type Foo with a name a is declared and it's initially assigned null.As you call the method changeReference, the reference a will be assigned the object which is passed as an argument.Declaring a reference named b of type Foo and assign it a new object of type Foo with an attribute \"b\".a = b makes a new assignment to the reference a, not f, of the object whose attribute is \"b\".As you call modifyReference(Foo c) method, a reference c is created and assigned the object with attribute \"f\".c.setAttribute(\"c\"); will change the attribute of the object that reference c points to it, and it's the same object that reference f points to it.I hope you understand now how passing objects as arguments works in Java :)",
                "Java is always pass by value, with no exceptions, ever.So how is it that anyone can be at all confused by this, and believe that Java is pass by reference, or think they have an example of Java acting as pass by reference? The key point is that Java never provides direct access to the values of objects themselves, in any circumstances. The only access to objects is through a reference to that object. Because Java objects are always accessed through a reference, rather than directly, it is common to talk about fields and variables and method arguments as being objects, when pedantically they are only references to objects. The confusion stems from this (strictly speaking, incorrect) change in nomenclature.So, when calling a methodSo if you have doSomething(foo) and public void doSomething(Foo foo) { .. } the two Foos have copied references that point to the same objects.Naturally, passing by value a reference to an object looks very much like (and is indistinguishable in practice from) passing an object by reference.",
                "This will give you some insights of how Java really works to the point that in your next discussion about Java passing by reference or passing by value you'll just smile :-)Step one please erase from your mind that word that starts with 'p' \"_ _ _ _ _ _ _\", especially if you come from other programming languages. Java and 'p' cannot be written in the same book, forum, or even txt.Step two remember that when you pass an Object into a method you're passing the Object reference and not the Object itself.Now think of what an Object's reference/variable does/is:In the following (please don't try to compile/execute this...):What happens?A picture is worth a thousand words:Note that the anotherReferenceToTheSamePersonObject arrows is directed towards the Object and not towards the variable person!If you didn't get it then just trust me and remember that it's better to say that Java is pass by value. Well, pass by reference value. Oh well, even better is pass-by-copy-of-the-variable-value! ;)Now feel free to hate me but note that given this there is no difference between passing primitive data types and Objects when talking about method arguments.You always pass a copy of the bits of the value of the reference!Java is pass-by-value because inside a method you can modify the referenced Object as much as you want but no matter how hard you try you'll never be able to modify the passed variable that will keep referencing (not p _ _ _ _ _ _ _) the same Object no matter what!The changeName function above will never be able to modify the actual content (the bit values) of the passed reference. In other word changeName cannot make Person person refer to another Object.Of course you can cut it short and just say that  Java is pass-by-value!",
                "Java passes references by value.So you can't change the reference that gets passed in.",
                "I feel like arguing about \"pass-by-reference vs pass-by-value\" is not super-helpful.If you say, \"Java is pass-by-whatever (reference/value)\", in either case, you're not provide a complete answer. Here's some additional information that will hopefully aid in understanding what's happening in memory.Crash course on stack/heap before we get to the Java implementation:\nValues go on and off the stack in a nice orderly fashion, like a stack of plates at a cafeteria.\nMemory in the heap (also known as dynamic memory) is haphazard and disorganized. The JVM just finds space wherever it can, and frees it up as the variables that use it are no longer needed.Okay. First off, local primitives go on the stack. So this code:results in this:When you declare and instantiate an object. The actual object goes on the heap. What goes on the stack? The address of the object on the heap. C++ programmers would call this a pointer, but some Java developers are against the word \"pointer\". Whatever. Just know that the address of the object goes on the stack.Like so:An array is an object, so it goes on the heap as well. And what about the objects in the array? They get their own heap space, and the address of each object goes inside the array.So, what gets passed in when you call a method? If you pass in an object, what you're actually passing in is the address of the object. Some might say the \"value\" of the address, and some say it's just a reference to the object. This is the genesis of the holy war between \"reference\" and \"value\" proponents. What you call it isn't as important as that you understand that what's getting passed in is the address to the object.One String gets created and space for it is allocated in the heap, and the address to the string is stored on the stack and given the identifier hisName, since the address of the second String is the same as the first, no new String is created and no new heap space is allocated, but a new identifier is created on the stack. Then we call shout(): a new stack frame is created and a new identifier, name is created and assigned the address of the already-existing String.So, value, reference? You say \"potato\".",
                "Basically, reassigning Object parameters doesn't affect the argument, e.g.,will print out \"Hah!\" instead of null. The reason this works is because bar is a copy of the value of baz, which is just a reference to \"Hah!\". If it were the actual reference itself, then foo would have redefined baz to null.",
                "Just to show the contrast, compare the following C++ and Java snippets:In C++: Note: Bad code - memory leaks!  But it demonstrates the point.In Java,Java only has the two types of passing: by value for built-in types, and by value of the pointer for object types.",
                "Java passes references to objects by value.",
                "I can't believe that nobody mentioned Barbara Liskov yet. When she designed CLU in 1974, she ran into this same terminology problem, and she invented the term call by sharing (also known as call by object-sharing and call by object) for this specific case of \"call by value where the value is a reference\".",
                "The crux of the matter is that the word reference in the expression \"pass by reference\" means something completely different from the usual meaning of the word reference in Java.Usually in Java reference means a a reference to an object. But the technical terms pass by reference/value from programming language theory is talking about a reference to the memory cell holding the variable, which is something completely different.",
                "There are already great answers that cover this. I wanted to make a small contribution by sharing a very simple example (which will compile) contrasting the behaviors between Pass-by-reference in c++ and Pass-by-value in Java.A few points:C++ pass by reference example:Java pass \"a Java reference\" by value exampleEDITSeveral people have written comments which seem to indicate that either they are not looking at my examples or they don't get the c++ example. Not sure where the disconnect is, but guessing the c++ example is not clear. I'm posting the same example in pascal because I think pass-by-reference looks cleaner in pascal, but I could be wrong. I might just be confusing people more; I hope not.In pascal, parameters passed-by-reference are called \"var parameters\". In the procedure setToNil below, please note the keyword 'var' which precedes the parameter 'ptr'. When a pointer is passed to this procedure, it will be passed by reference. Note the behavior: when this procedure sets ptr to nil (that's pascal speak for NULL), it will set the argument to nil--you can't do that in Java.EDIT 2Some excerpts from \"THE Java Programming Language\" by Ken Arnold, James Gosling (the guy who invented Java), and David Holmes, chapter 2, section 2.6.5All parameters to methods are passed \"by value\". In other words,\nvalues of parameter variables in a method are copies of the invoker\nspecified as arguments.He goes on to make the same point regarding objects . . .You should note that when the parameter is an object reference, it is\nthe object reference-not the object itself-that is passed \"by value\".And towards the end of the same section he makes a broader statement about java being only pass by value and never pass by reference.The Java programming language does not pass objects by reference; it\npasses object references by value. Because two copies of the same\nreference refer to the same actual object, changes made through one\nreference variable are visible through the other. There is exactly one\nparameter passing mode-pass by value-and that helps keep things\nsimple.This section of the book has a great explanation of parameter passing in Java and of the distinction between pass-by-reference and pass-by-value and it's by the creator of Java. I would encourage anyone to read it, especially if you're still not convinced.I think the difference between the two models is very subtle and unless you've done programming where you actually used pass-by-reference, it's easy to miss where two models differ.I hope this settles the debate, but probably won't.EDIT 3I might be a little obsessed with this post. Probably because I feel that the makers of Java inadvertently spread misinformation. If instead of using the word \"reference\" for pointers they had used something else, say\ndingleberry, there would've been no problem. You could say, \"Java passes dingleberries by value and not by reference\", and nobody would be confused.That's the reason only Java developers have issue with this. They look at the word \"reference\" and think they know exactly what that means, so they don't even bother to consider the opposing argument.Anyway, I noticed a comment in an older post, which made a balloon analogy which I really liked. So much so that I decided to glue together some clip-art to make a set of cartoons to illustrate the point.Passing a reference by value--Changes to the reference are not reflected in the caller's scope, but the changes to the object are. This is because the reference is copied, but the both the original and the copy refer to the same object.Pass by reference--There is no copy of the reference. Single reference is shared by both the caller and the function being called. Any changes to the reference or the Object's data are reflected in the caller's scope.EDIT 4I have seen posts on this topic which describe the low level implementation of parameter passing in Java, which I think is great and very helpful because it makes an abstract idea concrete. However, to me the question is more about the behavior described in the language specification than about the technical implementation of the behavior. This is an exerpt from the Java Language Specification, section 8.4.1 :When the method or constructor is invoked (\u00a715.12), the values of the\nactual argument expressions initialize newly created parameter\nvariables, each of the declared type, before execution of the body of\nthe method or constructor. The Identifier that appears in the\nDeclaratorId may be used as a simple name in the body of the method or\nconstructor to refer to the formal parameter.Which means, java creates a copy of the passed parameters before executing a method. Like most people who studied compilers in college, I used \"The Dragon Book\" which is THE compilers book. It has a good description of \"Call-by-value\" and \"Call-by-Reference\" in Chapter 1. The Call-by-value description matches up with Java Specs exactly.Back when I studied compilers-in the 90's, I used the first edition of the book from 1986 which pre-dated Java by about 9 or 10 years. However, I just ran across a copy of the 2nd Eddition from 2007 which actually mentions Java! Section 1.6.6 labeled \"Parameter Passing Mechanisms\" describes parameter passing pretty nicely. Here is an excerpt under the heading \"Call-by-value\" which mentions Java:In call-by-value, the actual parameter is evaluated (if it is an\nexpression) or copied (if it is a variable). The value is placed in\nthe location belonging to the corresponding formal parameter of the\ncalled procedure. This method is used in C and Java, and is a common\noption in C++ , as well as in most other languages.",
                "In java everything is reference, so when you have something like:\n    Point pnt1 = new Point(0,0); Java does following:Java doesn't pass method arguments by reference; it passes them by value. I will use example from this site:Flow of the program:Creating two different Point object with two different reference associated.As expected output will be:On this line 'pass-by-value' goes into the play...References pnt1 and pnt2 are passed by value to the tricky method, which means that now yours references pnt1 and pnt2 have their copies named arg1 and arg2.So pnt1 and arg1 points to the same object. (Same for the pnt2 and arg2)In the tricky method:Next in the tricky methodHere, you first create new temp Point reference which will point on same place like arg1 reference. Then you move reference arg1 to point to the same place like arg2 reference.\nFinally arg2 will point to the same place like temp.From here scope of tricky method is gone and you don't have access any more to the references: arg1, arg2, temp. But important note is that everything you do with these references when they are 'in life' will permanently affect object on which they are point to.So after executing method tricky, when you return to main, you have this situation:So now, completely execution of program will be:",
                "Java is always pass by value, not pass by referenceFirst of all, we need to understand what pass by value and pass by reference are.Pass by value means that you are making a copy in memory of the actual parameter's value that is passed in. This is a copy of the contents of the actual parameter.Pass by reference (also called pass by address) means that a copy of the address of the actual parameter is stored.Sometimes Java can give the illusion of pass by reference. Let's see how it works by using the example below:The output of this program is:Let's understand step by step:As we all know it will create an object in the heap and return the reference value back to t. For example, suppose the value of t is 0x100234 (we don't know the actual JVM internal value, this is just an example) .When passing reference t to the function it will not directly pass the actual reference value of object test,  but it will create a copy of t and then pass it to the function. Since it is passing by value, it passes a copy of the variable rather than the actual reference of it. Since we said the value of t was 0x100234, both t and f will have the same value and hence they will point to the same object.If you change anything in the function using reference f it will modify the existing contents of the object. That is why we got the output changevalue,   which is updated in the function.To understand this more clearly, consider the following example:Will this throw a NullPointerException? No, because it only passes a copy of the reference.\nIn the case of passing by reference, it could have thrown a NullPointerException, as seen below:Hopefully this will help.",
                "Java is a pass by value(stack memory)How it worksLet's first understand that where java stores primitive data type and object data type.Primitive data types itself and object references are stored in the stack.\nObjects themselves are stored in the heap.It means, Stack memory stores primitive data types and also the\naddresses of objects.And you always pass a copy of the bits of the value of the reference.If it's a primitive data type then these copied bits contain the value of the primitive data type itself, That's why when we change the value of argument inside the method then it does not reflect the changes outside.If it's an object data type like Foo foo=new Foo() then in this case copy of the address of the object passes like file shortcut  , suppose we have a text file abc.txt at C:\\desktop and suppose we make shortcut of the same file and put this inside C:\\desktop\\abc-shortcut so when you access the file from C:\\desktop\\abc.txt and write 'Stack Overflow' and close the file and again you open the file from shortcut then you write ' is the largest online community for programmers to learn' then total file change will be 'Stack Overflow is the largest online community for programmers to learn' which means it doesn't matter from where you open the file , each time we were accessing the same file , here we can assume Foo as a file and suppose foo stored at 123hd7h(original address like C:\\desktop\\abc.txt ) address and 234jdid(copied address like C:\\desktop\\abc-shortcut which actually contains the original address of the file inside) ..\nSo for better understanding make shortcut file and feel.",
                "Getting an outside of the box view, let's look at Assembly or some low level memory management. At the CPU level a reference to anything immediately becomes a value if it gets written to memory or to one of the CPU registers. (That is why pointer is a good definition. It is a value, which has a purpose at the same time).Data in memory has a Location and at that location there is a value (byte,word, whatever). In Assembly we have a convenient solution to give a Name to certain Location (aka variable), but when compiling the code, the assembler simply replaces Name with the designated location just like your browser replaces domain names with IP addresses.Down to the core it is technically impossible to pass a reference to anything in any language without representing it (when it immediately becomes a value).Lets say we have a variable Foo, its Location is at the 47th byte in memory and its Value is 5. We have another variable Ref2Foo which is at 223rd byte in memory, and its value will be 47. This Ref2Foo might be a technical variable, not explicitly created by the program. If you just look at 5 and 47 without any other information, you will see just two Values.\nIf you use them as references then to reach to 5 we have to travel:This is how jump-tables work.If we want to call a method/function/procedure with Foo's value, there are a few possible way to pass the variable to the method, depending on the language and its several method invocation modes:In every cases above a value - a copy of an existing value - has been created, it is now upto the receiving method to handle it. When you write \"Foo\" inside the method, it is either read out from EAX, or automatically  dereferenced, or double dereferenced, the process depends on how the language works and/or what the type of Foo dictates. This is hidden from the developer until she circumvents the dereferencing process. So a reference is a value when represented, because a reference is a value that has to be processed (at language level).Now we have passed Foo to the method:Nitpicking on insignificant details, even languages that do pass-by-reference will pass values to functions, but those functions know that they have to use it for dereferencing purposes. This pass-the-reference-as-value is just hidden from the programmer because it is practically useless and the terminology is only pass-by-reference.Strict pass-by-value is also useless, it would mean that a 100 Mbyte array should have to be copied every time we call a method with the array as argument, therefore Java cannot be stricly pass-by-value. Every language would pass a reference to this huge array (as a value) and either employs copy-on-write mechanism if that array can be changed locally inside the method or allows the method (as Java does) to modify the array globally (from the caller's view) and a few languages allows to modify the Value of the reference itself.So in short and in Java's own terminology, Java is pass-by-value where value can be: either a real value or a value that is a representation of a reference.",
                "In Java, method arguments are all passed by value :Java arguments are all passed by value (the value  or reference is copied when used by the method) :In the case of primitive types, Java behaviour is simple:\nThe value is copied in another instance of the primitive type.In case of Objects, this is the same:\nObject variables are references (mem buckets holding only Object\u2019s address instead of a primitive value) that was created using the \"new\" keyword, and are copied like primitive types.The behaviour can appear different from primitive types: Because the copied object-variable contains the same address (to the same Object).\nObject's content/members might still be modified within a method and later access outside, giving the illusion that the (containing) Object itself was passed by reference.\"String\" Objects appear to be a good counter-example to the urban legend saying that \"Objects are passed by reference\":In effect, using a method, you will never be able, to update the value of a String passed as argument:A String Object, holds characters by an array declared final that can't be modified.\nOnly the address of the Object might be replaced by another using \"new\".\nUsing \"new\" to update the variable, will not let the Object be accessed from outside, since the variable was initially passed by value and copied.",
                "As far as I know, Java only knows call by value. This means for primitive datatypes you will work with an copy and for objects you will work with an copy of the reference to the objects. However I think there are some pitfalls; for example, this will not work:This will populate Hello World and not World Hello because in the swap function you use copys which have no impact on the references in the main. But if your objects are not immutable you can change it for example:This will populate Hello World on the command line. If you change StringBuffer into String it will produce just Hello because String is immutable. For example:However you could make a wrapper for String like this which would make it able to use it with Strings:edit: i believe this is also the reason to use StringBuffer when it comes to \"adding\" two Strings because you can modifie the original object which u can't with immutable objects like String is.",
                "No, it's not pass by reference.Java is pass by value according to the Java Language Specification:When the method or constructor is invoked (\u00a715.12), the values of the actual argument expressions initialize newly created parameter variables, each of the declared type, before execution of the body of the method or constructor. The Identifier that appears in the DeclaratorId may be used as a simple name in the body of the method or constructor to refer to the formal parameter.",
                "Let me try to explain my understanding with the help of four examples. Java is pass-by-value, and not pass-by-reference/**Pass By ValueIn Java, all parameters are passed by value, i.e. assigning a method argument is not visible to the caller.*/Example 1:ResultExample 2:/**\n * \n * Pass By Value\n *\n */ResultExample 3:/**\n  This 'Pass By Value has a feeling of 'Pass By Reference'Some people say primitive types and 'String' are 'pass by value'\n  and objects are 'pass by reference'.But from this example, we can understand that it is infact pass by value only,\n  keeping in mind that here we are passing the reference as the value.\n  ie: reference is passed by value.\n  That's why are able to change and still it holds true after the local scope.\n  But we cannot change the actual reference outside the original scope.\n  what that means is demonstrated by next example of PassByValueObjectCase2.*/ResultExample 4:/**In addition to what was mentioned in Example3 (PassByValueObjectCase1.java),  we cannot change the actual reference outside the original scope.\"Note: I am not pasting the code for private class Student. The class definition for Student is same as Example3.*/Result",
                "I thought I'd contribute this answer to add more details from the Specifications.First, What's the difference between passing by reference vs. passing by value?Passing by reference means the called functions' parameter will be the\nsame as the callers' passed argument (not the value, but the identityPass by value means the called functions' parameter will be a copy of\nthe callers' passed argument.Or from wikipedia, on the subject of pass-by-referenceIn call-by-reference evaluation (also referred to as\npass-by-reference), a function receives an implicit reference to a\nvariable used as argument, rather than a copy of its value. This\ntypically means that the function can modify (i.e. assign to) the\nvariable used as argument\u2014something that will be seen by its caller.And on the subject of pass-by-valueIn call-by-value, the argument expression is evaluated, and the\nresulting value is bound to the corresponding variable in the function [...].\nIf the function or procedure is able to assign values to its\nparameters, only its local copy is assigned [...].Second, we need to know what Java uses in its method invocations. The Java Language Specification statesWhen the method or constructor is invoked (\u00a715.12), the values of the\nactual argument expressions initialize newly created parameter\nvariables, each of the declared type, before execution of the body of\nthe method or constructor.So it assigns (or binds) the value of the argument to the corresponding parameter variable.What is the value of the argument?Let's consider reference types, the Java Virtual Machine Specification statesThere are three kinds of reference types: class types, array types,\nand interface types. Their values are references to dynamically\ncreated class instances, arrays, or class instances or arrays that\nimplement interfaces, respectively.The Java Language Specification also statesThe reference values (often just references) are pointers to these objects, and a special null reference, which refers to no object.The value of an argument (of some reference type) is a pointer to an object. Note that a variable, an invocation of a method with a reference type return type, and an instance creation expression (new ...) all resolve to a reference type value.Soall bind the value of a reference to a String instance to the method's newly created parameter, param. This is exactly what the definition of pass-by-value describes. As such, Java is pass-by-value.The fact that you can follow the reference to invoke a method or access a field of the referenced object is completely irrelevant to the conversation. The definition of pass-by-reference wasThis typically means that the function can modify (i.e. assign to) the\nvariable used as argument\u2014something that will be seen by its caller.In Java, modifying the variable means reassigning it. In Java, if you reassigned the variable within the method, it would go unnoticed to the caller. Modifying the object referenced by the variable is a different concept entirely.Primitive values are also defined in the Java Virtual Machine Specification, here. The value of the type is the corresponding integral or floating point value, encoded appropriately (8, 16, 32, 64, etc. bits).",
                "You can never pass by reference in Java, and one of the ways that is obvious is when you want to return more than one value from a method call. Consider the following bit of code in C++:Sometimes you want to use the same pattern in Java, but you can't; at least not directly. Instead you could do something like this:As was explained in previous answers, in Java you're passing a pointer to the array as a value into getValues. That is enough, because the method then modifies the array element, and by convention you're expecting element 0 to contain the return value. Obviously you can do this in other ways, such as structuring your code so this isn't necessary, or constructing a class that can contain the return value or allow it to be set. But the simple pattern available to you in C++ above is not available in Java.",
                "The distinction, or perhaps just the way I remember as I used to be under the same impression as the original poster is this: Java is always pass by value. All objects( in Java, anything except for primitives) in Java are references. These references are passed by value.",
                "As many people mentioned it before, Java is always pass-by-valueHere is another example that will help you understand the difference (the classic swap example):Prints:Before: a = 2, b = 3\n  After: a = 2, b = 3This happens because iA and iB are new local reference variables that have the same value of the passed references (they point to a and b respectively). So, trying to change the references of iA or iB will only change in the local scope and not outside of this method.",
                "I always think of it as \"pass by copy\". It is a copy of the value be it primitive or reference. If it is a primitive it is a copy of the bits that are the value and if it is an Object it is a copy of the reference.output of java PassByCopy:name= Maxx\n  name= FidoPrimitive wrapper classes and Strings are immutable so any example using those types will not work the same as other types/objects.",
                "Unlike some other languages, Java does not allow you to choose between pass-by-value and pass-by-reference\u2014all arguments are passed by value. A method call can pass two types of values to a method\u2014copies of primitive values (e.g., values of int and double) and copies of references to objects.When a method modifies a primitive-type parameter, changes to the parameter have no effect on the original argument value in the calling method.When it comes to objects, objects themselves cannot be passed to methods. So we pass the reference(address) of the object. We can manipulate the original object using this reference.How Java creates and stores objects: When we create an object we store the object\u2019s address in a reference variable. Let's analyze the following statement.\u201cAccount account1\u201d is the type and name of the reference variable, \u201c=\u201d is the assignment operator, \u201cnew\u201d asks for the required amount of space from the system. The constructor to the right of keyword new which creates the object is called implicitly by the keyword new. Address of the created object(result of right value, which is an expression called \"class instance creation expression\") is assigned to the left value (which is a reference variable with a name and a type specified) using the assign operator.Although an object\u2019s reference is passed by value, a method can still interact with the referenced object by calling its public methods using the copy of the object\u2019s reference. Since the reference stored in the parameter is a copy of the reference that was passed as an argument, the parameter in the called method and the argument in the calling method refer to the same object in memory.Passing references to arrays, instead of the array objects themselves, makes sense for performance reasons. Because everything in Java is passed by value, if array objects were passed,\na copy of each element would be passed. For large arrays, this would waste time and consume\nconsiderable storage for the copies of the elements.In the image below you can see we have two reference variables(These are called pointers in C/C++, and I think that term makes it easier to understand this feature.) in the main method. Primitive and reference variables are kept in stack memory(left side in images below). array1 and array2 reference variables \"point\" (as C/C++ programmers call it) or reference to a and b arrays respectively, which are objects (values these reference variables hold are addresses of objects) in heap memory (right side in images below).If we pass the value of array1 reference variable as an argument to the reverseArray method, a reference variable is created in the method and that reference variable starts pointing to the same array (a).So, if we sayin reverseArray method, it will make a change in array a.We have another reference variable in reverseArray method (array2) that points to an array c. If we were to sayin reverseArray method, then the reference variable array1 in method reverseArray would stop pointing to array a and start pointing to array c (Dotted line in second image).If we return value of reference variable array2 as the return value of method reverseArray and assign this value to reference variable array1 in main method, array1 in main will start pointing to array c.So let's write all the things we have done at once now.And now that reverseArray method is over, its reference variables(array1 and array2) are gone. Which means we now only have the two reference variables in main method array1 and array2 which point to c and b arrays respectively. No reference variable is pointing to object (array) a. So it is eligible for garbage collection.You could also assign value of array2 in main to array1. array1 would start pointing to b.",
                "Java has only pass by value. A very simple example to validate this.",
                "To make a long story short, Java objects have some very peculiar properties.In general, Java has primitive types (int, bool, char, double, etc) that are passed directly by value. Then Java has objects (everything that derives from java.lang.Object). Objects are actually always handled through a reference (a reference being a pointer that you can't touch). That means that in effect, objects are passed by reference, as the references are normally not interesting. It does however mean that you cannot change which object is pointed to as the reference itself is passed by value.Does this sound strange and confusing? Let's consider how C implements pass by reference and pass by value. In C, the default convention is pass by value. void foo(int x) passes an int by value. void foo(int *x) is a function that does not want an int a, but a pointer to an int: foo(&a). One would use this with the & operator to pass a variable address.Take this to C++, and we have references. References are basically (in this context) syntactic sugar that hide the pointer part of the equation: void foo(int &x) is called by foo(a), where the compiler itself knows that it is a reference and the address of the non-reference a should be passed. In Java, all variables referring to objects are actually of reference type, in effect forcing call by reference for most intends and purposes without the fine grained control (and complexity) afforded by, for example, C++.",
                "I have created a thread devoted to these kind of questions for any programming languages here.Java is also mentioned. Here is the short summary:"
            ]
        },
        {
            "tag": "git",
            "question": [
                "How do I make Git forget about a file that was tracked, but is now in .gitignore?",
                "I put a file that was previously being tracked by Git onto the .gitignore list. However, the file still shows up in git status after it is edited. How do I force Git to completely forget the file?"
            ],
            "url": "https://stackoverflow.com/questions/1274057",
            "answer": [
                ".gitignore will prevent untracked files from being added (without an add -f) to the set of files tracked by Git. However, Git will continue to track any files that are already being tracked.To stop tracking a file, we must remove it from the index:To remove a folder and all files in the folder recursively:The removal of the file from the head revision will happen on the next commit.WARNING: While this will not remove the physical file from your local machine, it will remove the files from other developers' machines on their next git pull.",
                "The series of commands below will remove all of the items from the Git index (not from the working directory or local repository), and then will update the Git index, while respecting Git ignores. PS. Index = CacheFirst:Then:Or as a one-liner:",
                "git update-index does the job for me:Note: This solution is actually independent of .gitignore as gitignore is only for untracked files.Since this answer was posted, a new option has been created and that should be preferred.  You should use --skip-worktree which is for modified tracked files that the user don't want to commit anymore and keep --assume-unchanged for performance to prevent git to check status of big tracked files. See https://stackoverflow.com/a/13631525/717372 for more details...To cancel",
                "This takes the list of the ignored files, removes them from the index, and commits the changes.",
                "Move it out, commit, and then move it back in.This has worked for me in the past, but there is probably a 'gittier' way to accomplish this.",
                "I always use this command to remove those untracked files.\nOne-line, Unix-style, clean output:It lists all your ignored files, replaces every output line with a quoted line instead to handle paths with spaces inside, and passes everything to git rm -r --cached to remove the paths/files/directories from the index.",
                "The copy/paste answer is:This command will NOT change the content of the .gitignore file. It will just ignore the files that have already been committed to a Git repository but now we have added them to .gitignore.The command git status; is just to review the changes and could be dropped.In the end, it will immediately commit the changes with the message \"Ignore unwanted files\".If you don't want to commit the changes, drop the last part of the command (git commit -m \"Ignore unwanted files\")",
                "Source: Untrack files already added to Git repository based on .gitignoreLet\u2019s say you have already added/committed some files to your Git repository and you then add them to your .gitignore file; these files will still be present in your repository index. This article we will see how to get rid of them.Before proceeding, make sure all your changes are committed, including your .gitignore file.To clear your repository, use:The rm command can be unforgiving. If you wish to try what it does beforehand, add the -n or --dry-run flag to test things out.Your repository is clean :)Push the changes to your remote to see the changes effective there as well.",
                "If you cannot git rm a tracked file because other people might need it (warning, even if you git rm --cached, when someone else gets this change, their files will be deleted in their filesystem).  These are often done due to config file overrides, authentication credentials, etc. Please look at https://gist.github.com/1423106 for ways people have worked around the problem.To summarize:",
                "I accomplished this by using git filter-branch. The exact command I used was taken from the man page:WARNING: this will delete the file from your entire historyThis command will recreate the entire commit history, executing git rm before each commit and so will get rid of the specified file. Don't forget to back it up before running the command as it will be lost.",
                "(Under Linux), I wanted to use the posts here suggesting the ls-files --ignored --exclude-standard | xargs git rm -r --cached approach.  However, (some of) the files to be removed had an embedded newline/LF/\\n in their names.  Neither of the solutions:cope with this situation (get errors about files not found).This uses the -z argument to ls-files, and the -0 argument to xargs to cater safely/correctly for \"nasty\" characters in filenames.In the manual page git-ls-files(1), it states:When -z option is not used, TAB, LF, and backslash characters in\npathnames are represented as \\t, \\n, and \\\\, respectively.so I think my solution is needed if filenames have any of these characters in them.",
                "Do the following steps for a file/folder:Remove a File:For example:I want to delete the test.txt file. I accidentally pushed to GitHub and want to remove it. Commands will be as follows:First, add \"test.txt\" in file .gitignoreRemove Folder:For example:I want to delete the .idea folder/directory. I accidentally pushed to GitHub and want to remove it. The commands will be as follows:First, add .idea in file .gitignore",
                "Update your .gitignore file \u2013 for instance, add a folder you don't want to track to .gitignore.git rm -r --cached . \u2013 Remove all tracked files, including wanted and unwanted. Your code will be safe as long as you have saved locally.git add . \u2013 All files will be added back in, except those in .gitignore.Hat tip to @AkiraYamamoto for pointing us in the right direction.",
                "Do the following steps serially, and you will be fine.Remove the mistakenly added files from the directory/storage. You can use the \"rm -r\" (for Linux) command or delete them by browsing the directories. Or move them to another location on your PC. (You maybe need to close the IDE if running for moving/removing.)Add the files / directories to the .gitignore file now and save it.Now remove them from the Git cache by using these commands (if there is more than one directory, remove them one by one by repeatedly issuing this command)Now do a commit and push by using the following commands. This will remove those files from Git remote and make Git stop tracking those files.",
                "I think, that maybe Git can't totally forget about a file because of its conception (section \"Snapshots, Not Differences\").This problem is absent, for example, when using CVS. CVS stores information as a list of file-based changes. Information for CVS is a set of files and the changes made to each file over time.But in Git every time you commit, or save the state of your project, it basically takes a picture of what all your files look like at that moment and stores a reference to that snapshot. So, if you added file once, it will always be present  in that snapshot.These two articles were helpful for me:git assume-unchanged vs skip-worktree and How to ignore changes in tracked files with GitBasing on it I do the following, if the file is already tracked:From this moment all local changes in this file will be ignored and will not go to remote. If the file is changed on remote, conflict will occur, when git pull. Stash won't work. To resolve it, copy the file content to the safe place and follow these steps:The file content will be replaced by the remote content. Paste your changes from the safe place to the file and perform again:If everyone, who works with the project, will perform git update-index --skip-worktree <file>, problems with pull should be absent. This solution is OK for configurations files, when every developer has their own project configuration.It is not very convenient to do this every time, when the file has been changed on remote, but it can protect it from overwriting by remote content.",
                "Move or copy the file to a safe location, so you don't lose it. Then 'git rm' the file and commit.The file will still show up if you revert to one of those earlier commits, or another branch where it has not been removed. However, in all future commits, you will not see the file again. If the file is in the Git ignore, then you can move it back into the folder, and Git won't see it.",
                "The answer from Matt Frear was the most effective IMHO. The following is just a PowerShell script for those on Windows to only remove files from their Git repository that matches their exclusion list.",
                "Using the git rm --cached command does not answer the original question:How do you force git to completely forget about [a file]?In fact, this solution will cause the file to be deleted in every other instance of the repository when executing a git pull!The correct way to force Git to forget about a file is documented by GitHub here.I recommend reading the documentation, but basically:Just replace full/path/to/file with the full path of the file. Make sure you've added the file to your .gitignore file.You'll also need to (temporarily) allow non-fast-forward pushes to your repository, since you're changing your Git history.",
                "git rm --cached -r <YOUR_files_or_folders>--cached  | only remove files from the index",
                "The accepted answer does not \"make Git \"forget\" about a file...\" (historically).  It only makes Git ignore the file in the present/future.This method makes Git completely forget ignored files (past/present/future), but it does not delete anything from the working directory (even when re-pulled from remote).This method requires usage of file /.git/info/exclude (preferred) or a pre-existing .gitignore in all the commits that have files to be ignored/forgotten. 1All methods of enforcing Git ignore behavior after-the-fact effectively rewrite history and thus have significant ramifications for any public/shared/collaborative repositories that might be pulled after this process. 2General advice: start with a clean repository - everything committed, nothing pending in working directory or index, and make a backup!Also, the comments/revision history of this answer (and revision history of this question) may be useful/enlightening.Finally, follow the rest of this GitHub guide (starting at step 6) which includes important warnings/information about the commands below.Other developers that pull from the now-modified remote repository should make a backup and then:1 Because /.git/info/exclude can be applied to all historical commits using the instructions above, perhaps details about getting a .gitignore file into the historical commit(s) that need it is beyond the scope of this answer.  I wanted a proper .gitignore file to be in the root commit, as if it was the first thing I did.  Others may not care since /.git/info/exclude can accomplish the same thing regardless where the .gitignore file exists in the commit history, and clearly rewriting history is a very touchy subject, even when aware of the ramifications.FWIW, potential methods may include git rebase or a git filter-branch that copies an external .gitignore into each commit, like the answers to this question.2 Enforcing Git ignore behavior after-the-fact by committing the results of a stand-alone git rm --cached command may result in newly-ignored file deletion in future pulls from the force-pushed remote. The --prune-empty flag in the following git filter-branch command avoids this problem by automatically removing the previous \"delete all ignored files\" index-only commit.  Rewriting Git history also changes commit hashes, which will wreak havoc on future pulls from public/shared/collaborative repositories.  Please understand the ramifications fully before doing this to such a repository. This GitHub guide specifies the following:Tell your collaborators to rebase, not merge, any branches they created off of your old (tainted) repository history. One merge commit could reintroduce some or all of the tainted history that you just went to the trouble of purging.Alternative solutions that do not affect the remote repository are git update-index --assume-unchanged </path/file> or git update-index --skip-worktree <file>, examples of which can be found here.",
                "In my case I needed to put \".envrc\" in the .gitignore file.And then I used:And the file was removed.Then I committed again, telling that the file was removed.But when I used the command git log -p, the content of the file (which was secret credentials of the Amazon S3) was showing the content which was removed and I don't want to show this content ever on the history of the Git repository.Then I used this command:And I don't see the content again.",
                "I liked JonBrave's answer, but I have messy enough working directories that commit -a scares me a bit, so here's what I've done:Breaking it down:",
                "The BFG is specifically designed for removing unwanted data like big files or passwords from Git repositories, so it has a simple flag that will remove any large historical (not-in-your-current-commit) files: '--strip-blobs-bigger-than'If you'd like to specify files by name, you can do that too:The BFG is 10-1000x faster than git filter-branch and is generally much easier to use - check the full usage instructions and examples for more details.Source: Reduce repository size",
                "If you don't want to use the CLI and are working on Windows, a very simple solution is to use TortoiseGit. It has the \"Delete (keep local)\" Action in the menu which works fine.",
                "This is no longer an issue in the latest Git (v2.17.1 at the time of writing).The .gitignore file finally ignores tracked-but-deleted files. You can test this for yourself by running the following script. The final git status statement should report \"nothing to commit\".",
                "This is how I solved my issue:git filter-branch --tree-filter 'rm -rf path/to/your/file' HEAD\n git pushIn this, we are basically trying to rewrite the history of that particular file in previous commits also.For more information, you can refer to the man page of filter-branch here.Source: Removing sensitive data from a repository - using filter-branchSource: Git: How to remove a big file wrongly committed",
                "In case of already committed DS_Store:Ignore them by:Finally, make a commit!",
                "Especially for the IDE-based files, I use this:For instance, for the slnx.sqlite file, I just got rid off it completely like the following:Just keep that in mind that some of those files store some local user settings and preferences for projects (like what files you had open). So every time you navigate or do some changes in your IDE, that file is changed and therefore it checks it out and show as uncommitted changes.",
                "If anyone is having a hard time on Windows and you want to ignore the entire folder, go to the desired 'folder' on file explorer, right click and do 'Git Bash Here' (Git for Windows should have been installed).Run this command:",
                "For me, the file was still available in the history and I first needed to squash the commits that added the removed files: https://gist.github.com/patik/b8a9dc5cd356f9f6f980"
            ]
        },
        {
            "tag": "python",
            "question": [
                "Does Python have a ternary conditional operator?",
                "Is there a ternary conditional operator in Python?"
            ],
            "url": "https://stackoverflow.com/questions/394809",
            "answer": [
                "Yes, it was added in version 2.5. The expression syntax is:First condition is evaluated, then exactly one of either a or b is evaluated and returned based on the Boolean value of condition. If condition evaluates to True, then a is evaluated and returned but b is ignored, or else when b is evaluated and returned but a is ignored.This allows short-circuiting because when condition is true only a is evaluated and b is not evaluated at all, but when condition is false only b is evaluated and a is not evaluated at all.For example:Note that conditionals are an expression, not a statement. This means you can't use statements such as pass, or assignments with = (or \"augmented\" assignments like +=), within a conditional expression:(In 3.8 and above, the := \"walrus\" operator allows simple assignment of values as an expression, which is then compatible with this syntax. But please don't write code like that; it will quickly become very difficult to understand.)Similarly, because it is an expression, the else part is mandatory:You can, however, use conditional expressions to assign a variable like so:Or for example to return a value:Think of the conditional expression as switching between two values. We can use it when we are in a 'one value or another' situation, where we will do the same thing with the result, regardless of whether the condition is met. We use the expression to compute the value, and then do something with it. If you need to do something different depending on the condition, then use a normal if statement instead.Keep in mind that it's frowned upon by some Pythonistas for several reasons:If you're having trouble remembering the order, then remember that when read aloud, you (almost) say what you mean. For example, x = 4 if b > 8 else 9 is read aloud as x will be 4 if b is greater than 8 otherwise 9.Official documentation:",
                "You can index into a tuple:test needs to return True or False.\nIt might be safer to always implement it as:or you can use the built-in bool() to assure a Boolean value:",
                "For versions prior to 2.5, there's the trick:It can give wrong results when on_true has a false Boolean value.1Although it does have the benefit of evaluating expressions left to right, which is clearer in my opinion.1. Is there an equivalent of C\u2019s \u201d?:\u201d ternary operator?",
                "<expression 1> if <condition> else <expression 2>",
                "From the documentation:Conditional expressions (sometimes called a \u201cternary operator\u201d) have the lowest priority of all Python operations.The expression x if C else y first evaluates the condition, C (not x); if C is true, x is evaluated and its value is returned; otherwise, y is evaluated and its value is returned.See PEP 308 for more details about conditional expressions.New since version 2.5.",
                "An operator for a conditional expression in Python was added in 2006 as part of Python Enhancement Proposal 308. Its form differ from common ?: operator and it's:which is equivalent to:Here is an example:Another syntax which can be used (compatible with versions before 2.5):where operands are lazily evaluated.Another way is by indexing a tuple (which isn't consistent with the conditional operator of most other languages):or explicitly constructed dictionary:Another (less reliable), but simpler method is to use and and or operators:however this won't work if x would be False.A possible workaround is to make x and y lists or tuples as in the following:or:If you're working with dictionaries, instead of using a ternary conditional, you can take advantage of get(key, default), for example:Source: ?: in Python at Wikipedia",
                "Unfortunately, thesolution doesn't have short-circuit behaviour; thus both falseValue and trueValue are evaluated regardless of the condition. This could be suboptimal or even buggy (i.e. both trueValue and falseValue could be methods and have side effects).One solution to this would be(execution delayed until the winner is known ;)), but it introduces inconsistency between callable and non-callable objects. In addition, it doesn't solve the case when using properties.And so the story goes - choosing between three mentioned solutions is a trade-off between having the short-circuit feature, using at least Python 2.5 (IMHO, not a problem anymore) and not being prone to \"trueValue-evaluates-to-false\" errors.",
                "Here I just try to show some important differences in the ternary operator between a couple of programming languages.",
                "For Python 2.5 and newer there is a specific syntax:In older Pythons a ternary operator is not implemented but it's possible to simulate it.Though, there is a potential problem, which if cond evaluates to True and on_true evaluates to False then on_false is returned instead of on_true. If you want this behavior the method is OK, otherwise use this:which can be wrapped by:and used this way:It is compatible with all Python versions.",
                "You might often findbut this leads to a problem when on_true == 0Where you would expect this result for a normal ternary operator:",
                "Yes. From the grammar file:The part of interest is:So, a ternary conditional operation is of the form:expression3 will be lazily evaluated (that is, evaluated only if expression2 is false in a boolean context). And because of the recursive definition, you can chain them indefinitely (though it may considered bad style.)Note that every if must be followed with an else. People learning list comprehensions and generator expressions may find this to be a difficult lesson to learn - the following will not work, as Python expects a third expression for an else:which raises a SyntaxError: invalid syntax.\nSo the above is either an incomplete piece of logic (perhaps the user expects a no-op in the false condition) or what may be intended is to use expression2 as a filter - notes that the following is legal Python:expression2 works as a filter for the list comprehension, and is not a ternary conditional operator.You may find it somewhat painful to write the following:expression1 will have to be evaluated twice with the above usage. It can limit redundancy if it is simply a local variable. However, a common and performant Pythonic idiom for this use-case is to use or's shortcutting behavior:which is equivalent in semantics. Note that some style-guides may limit this usage on the grounds of clarity - it does pack a lot of meaning into very little syntax.",
                "One of the alternatives to Python's conditional expressionis the following:which has the following nice extension:The shortest alternative remainswhich works because issubclass(bool, int).Careful, though: the alternative tois notbutThis works fine as long as no and yes are to be called with exactly the same parameters. If they are not, like inor inthen a similar alternative either does not exist (1) or is hardly viable (2). (In rare cases, depending on the context, something likecould make sense.)Thanks to Radek Roj\u00edk for his comment",
                "As already answered, yes, there is a ternary operator in Python:In many cases <expression 1> is also used as Boolean evaluated <condition>. Then you can use short-circuit evaluation.One big pro of short-circuit evaluation is the possibility of chaining more than two expressions:When working with functions it is more different in detail:PS: Of course, a short-circuit evaluation is not a ternary operator, but often the ternary is used in cases where the short circuit would be enough. It has a better readability and can be chained.",
                "Simulating the Python ternary operator.For exampleOutput:",
                "Just memorize this pyramid if you have trouble remembering:",
                "The ternary conditional operator simply allows testing a condition in a single line replacing the multiline if-else making the code compact.[on_true] if [expression] else [on_false]Above approach can be written as:",
                "Vinko Vrsalovic's answer is good enough. There is only one more thing:Note that conditionals are an expression, not a statement. This means you can't use assignment statements or pass or other statements within a conditional expressionAfter the walrus operator was introduced in Python 3.8, something changed.gives a = 3 and b is not defined,gives a is not defined and b = 5, andgives c = 5, a is not defined and b = 5.Even if this may be ugly, assignments can be done inside conditional expressions after Python 3.8. Anyway, it is still better to use normal if statement instead in this case.",
                "More a tip than an answer (I don't need to repeat the obvious for the hundredth time), but I sometimes use it as a one-liner shortcut in such constructs:, becomes:Some (many :) may frown upon it as unpythonic (even, Ruby-ish :), but I personally find it more natural - i.e., how you'd express it normally, plus a bit more visually appealing in large blocks of code.",
                "You can do this:Example:This would print \"odd\" if the number is odd or \"even\" if the number is even.The result: If condition is true, exp_1 is executed, else exp_2 is executed.Note: 0, None, False, emptylist, and emptyString evaluates as False.And any data other than 0 evaluates to True.If the condition [condition] becomes \"True\", then expression_1 will be evaluated, but not expression_2.If we \"and\" something with 0 (zero), the result will always to be false. So in the below statement,The expression exp won't be evaluated at all since \"and\" with 0 will always evaluate to zero and there is no need to evaluate the expression. This is how the compiler itself works, in all languages.Inthe expression exp won't be evaluated at all since \"or\" with 1 will always be 1. So it won't bother to evaluate the expression exp since the result will be 1 anyway (compiler optimization methods).But in case ofThe second expression exp2 won't be evaluated since True and exp1 would be True when exp1 isn't false.Similarly inThe expression exp1 won't be evaluated since False is equivalent to writing 0 and doing \"and\" with 0 would be 0 itself, but after exp1 since \"or\" is used, it will evaluate the expression exp2 after \"or\".Note:- This kind of branching using \"or\" and \"and\" can only be used when the expression_1 doesn't have a Truth value of False (or 0 or None or emptylist [ ] or emptystring ' '.) since if expression_1 becomes False, then the expression_2 will be evaluated because of the presence \"or\" between exp_1 and exp_2.In case you still want to make it work for all the cases regardless of what exp_1 and exp_2 truth values are, do this:",
                "Many programming languages derived from C usually have the following syntax of the ternary conditional operator:At first, the Python's benevolent dictator for life (I mean Guido van Rossum, of course) rejected it (as non-Pythonic style), since it's quite hard to understand for people not used to C language. Also, the colon sign : already has many uses in Python. After PEP 308 was approved, Python finally received its own shortcut conditional expression (what we use now):So, firstly it evaluates the condition. If it returns True, expression1 will be evaluated to give the result, otherwise expression2 will be evaluated. Due to lazy evaluation mechanics \u2013 only one expression will be executed.Here are some examples (conditions will be evaluated from left to right):Ternary operators can be chained in series:The following one is the same as previous one:",
                "Yes, Python have a ternary operator, here is the syntax and an example code to demonstrate the same :)",
                "Other answers correctly talk about the Python ternary operator. I would like to complement by mentioning a scenario for which the ternary operator is often used, but for which there is a better idiom. This is the scenario of using a default value.Suppose we want to use option_value with a default value if it is not set:or, if option_value is never set to a falsy value (0, \"\", etc.), simplyHowever, in this case an ever better solution is simply to write",
                "The syntax for the ternary operator in Python is:[on_true] if [expression] else [on_false]Using that syntax, here is how we would rewrite the code above using Python\u2019s ternary operator:It's still pretty clear, but much shorter. Note that the expression could be any type of expression, including a function call, that returns a value that evaluates to True or False.",
                "Python has a ternary form for assignments; however there may be even a shorter form that people should be aware of.It's very common to need to assign to a variable one value or another depending on a condition.^ This is the long form for doing such assignments.Below is the ternary form. But this isn't the most succinct way - see the last example.With Python, you can simply use or for alternative assignments.The above works since li1 is None and the interpreter treats that as False in logic expressions. The interpreter then moves on and evaluates the second expression, which is not None and it's not an empty list - so it gets assigned to a.This also works with empty lists. For instance, if you want to assign a whichever list has items.Knowing this, you can simply such assignments whenever you encounter them. This also works with strings and other iterables. You could assign a whichever string isn't empty.I always liked the C ternary syntax, but Python takes it a step further!I understand that some may say this isn't a good stylistic choice, because it relies on mechanics that aren't immediately apparent to all developers. I personally disagree with that viewpoint. Python is a syntax-rich language with lots of idiomatic tricks that aren't immediately apparent to the dabbler. But the more you learn and understand the mechanics of the underlying system, the more you appreciate it.",
                "Pythonic way of doing the things:But there always exists a different way of doing a ternary condition too:",
                "There are multiple ways. The simplest one is to use the condition inside the \"print\" method.You can useWhich is equivalent to:In this way, more than two statements are also possible to print. For example:can be written as:",
                "The if else-if version can be written as:",
                "Yes, it has, but it's different from C-syntax-like programming languages (which is condition ? value_if_true : value_if_falseIn Python, it goes like this: value_if_true if condition else value_if_falseExample: even_or_odd = \"even\" if x % 2 == 0 else \"odd\"",
                "A neat way to chain multiple operators:",
                "I find the default Python syntax val = a if cond else b cumbersome, so sometimes I do this:Of course, it has the downside of always evaluating both sides (a and b), but the syntax is way clearer to me."
            ]
        },
        {
            "tag": "javascript",
            "question": [
                "var functionName = function() {} vs function functionName() {}",
                "I've recently started maintaining someone else's JavaScript code. I'm fixing bugs, adding features and also trying to tidy up the code and make it more consistent.\nThe previous developer used two ways ..."
            ],
            "url": "https://stackoverflow.com/questions/336859",
            "answer": [
                "The difference is that functionOne is a function expression and so only defined when that line is reached, whereas functionTwo is a function declaration and is defined as soon as its surrounding function or script is executed (due to hoisting).For example, a function expression:// TypeError: functionOne is not a function\r\nfunctionOne();\r\n\r\nvar functionOne = function() {\r\n  console.log(\"Hello!\");\r\n};And, a function declaration:// Outputs: \"Hello!\"\r\nfunctionTwo();\r\n\r\nfunction functionTwo() {\r\n  console.log(\"Hello!\");\r\n}Historically, function declarations defined within blocks were handled inconsistently between browsers. Strict mode (introduced in ES5) resolved this by scoping function declarations to their enclosing block.'use strict';    \r\n{ // note this block!\r\n  function functionThree() {\r\n    console.log(\"Hello!\");\r\n  }\r\n}\r\nfunctionThree(); // ReferenceError",
                "First I want to correct Greg: function abc(){} is scoped too \u2014 the name abc is defined in the scope where this definition is encountered. Example:Secondly, it is possible to combine both styles:xyz is going to be defined as usual, abc is undefined in all browsers but Internet\u00a0Explorer \u2014 do not rely on it being defined. But it will be defined inside its body:If you want to alias functions on all browsers, use this kind of declaration:In this case, both xyz and abc are aliases of the same object:One compelling reason to use the combined style is the \"name\" attribute of function objects (not supported by Internet\u00a0Explorer). Basically when you define a function likeits name is automatically assigned. But when you define it likeits name is empty \u2014 we created an anonymous function and assigned it to some variable.Another good reason to use the combined style is to use a short internal name to refer to itself, while providing a long non-conflicting name for external users:In the example above we can do the same with an external name, but it'll be too unwieldy (and slower).(Another way to refer to itself is to use arguments.callee, which is still relatively long, and not supported in the strict mode.)Deep down, JavaScript treats both statements differently. This is a function declaration:abc here is defined everywhere in the current scope:Also, it hoisted through a return statement:This is a function expression:xyz here is defined from the point of assignment:Function declaration vs. function expression is the real reason why there is a difference demonstrated by Greg.Fun fact:Personally, I prefer the \"function expression\" declaration because this way I can control the visibility. When I define the function likeI know that I defined the function locally. When I define the function likeI know that I defined it globally providing that I didn't define abc anywhere in the chain of scopes. This style of definition is resilient even when used inside eval(). While the definitiondepends on the context and may leave you guessing where it is actually defined, especially in the case of eval() \u2014 the answer is: It depends on the browser.",
                "Here's the rundown on the standard forms that create functions: (Originally written for another question, but adapted after being moved into the canonical question.)Terms:The quick list:Function Declaration\"Anonymous\" function Expression (which despite the term, sometimes create functions with names)Named function ExpressionAccessor Function Initializer (ES5+)Arrow Function Expression (ES2015+) (which, like anonymous function expressions, don't involve an explicit name, and yet can create functions with names)Method Declaration in Object Initializer (ES2015+)Constructor and Method Declarations in class (ES2015+)The first form is a function declaration, which looks like this:A function declaration is a declaration; it's not a statement or expression. As such, you don't follow it with a ; (although doing so is harmless).A function declaration is processed when execution enters the context in which it appears, before any step-by-step code is executed. The function it creates is given a proper name (x in the example above), and that name is put in the scope in which the declaration appears.Because it's processed before any step-by-step code in the same context, you can do things like this:Until ES2015, the spec didn't cover what a JavaScript engine should do if you put a function declaration inside a control structure like try, if, switch, while, etc., like this:And since they're processed before step-by-step code is run, it's tricky to know what to do when they're in a control structure.Although doing this wasn't specified until ES2015, it was an allowable extension to support function declarations in blocks. Unfortunately (and inevitably), different engines did different things.As of ES2015, the specification says what to do. In fact, it gives three separate things to do:The rules for the loose modes are tricky, but in strict mode, function declarations in blocks are easy: They're local to the block (they have block scope, which is also new in ES2015), and they're hoisted to the top of the block. So:The second common form is called an anonymous function expression:Like all expressions, it's evaluated when it's reached in the step-by-step execution of the code.In ES5, the function this creates has no name (it's anonymous). In ES2015, the function is assigned a name if possible by inferring it from context. In the example above, the name would be y. Something similar is done when the function is the value of a property initializer. (For details on when this happens and the rules, search for SetFunctionName in the the specification\u00a0\u2014 it appears all over the place.)The third form is a named function expression (\"NFE\"):The function this creates has a proper name (w in this case). Like all expressions, this is evaluated when it's reached in the step-by-step execution of the code. The name of the function is not added to the scope in which the expression appears; the name is in scope within the function itself:Note that NFEs have frequently been a source of bugs for JavaScript implementations. IE8 and earlier, for instance, handle NFEs completely incorrectly, creating two different functions at two different times. Early versions of Safari had issues as well. The good news is that current versions of browsers (IE9 and up, current Safari) don't have those issues any more. (But as of this writing, sadly, IE8 remains in widespread use, and so using NFEs with code for the web in general is still problematic.)Sometimes functions can sneak in largely unnoticed; that's the case with accessor functions. Here's an example:Note that when I used the function, I didn't use ()! That's because it's an accessor function for a property. We get and set the property in the normal way, but behind the scenes, the function is called.You can also create accessor functions with Object.defineProperty, Object.defineProperties, and the lesser-known second argument to Object.create.ES2015 brings us the arrow function. Here's one example:See that n => n * 2 thing hiding in the map() call? That's a function.A couple of things about arrow functions:They don't have their own this. Instead, they close over the this of the context where they're defined. (They also close over arguments and, where relevant, super.) This means that the this within them is the same as the this where they're created, and cannot be changed.As you'll have noticed with the above, you don't use the keyword function; instead, you use =>.The n => n * 2 example above is one form of them. If you have multiple arguments to pass the function, you use parens:(Remember that Array#map passes the entry as the first argument, and the index as the second.)In both cases, the body of the function is just an expression; the function's return value will automatically be the result of that expression (you don't use an explicit return).If you're doing more than just a single expression, use {} and an explicit return (if you need to return a value), as normal:The version without { ... } is called an arrow function with an expression body or concise body. (Also: A concise arrow function.) The one with { ... } defining the body is an arrow function with a function body. (Also: A verbose arrow function.)ES2015 allows a shorter form of declaring a property that references a function called a method definition; it looks like this:the almost-equivalent in ES5 and earlier would be:the difference (other than verbosity) is that a method can use super, but a function cannot. So for instance, if you had an object that defined (say) valueOf using method syntax, it could use super.valueOf() to get the value Object.prototype.valueOf would have returned (before presumably doing something else with it), whereas the ES5 version would have to do Object.prototype.valueOf.call(this) instead.That also means that the method has a reference to the object it was defined on, so if that object is temporary (for instance, you're passing it into Object.assign as one of the source objects), method syntax could mean that the object is retained in memory when otherwise it could have been garbage collected (if the JavaScript engine doesn't detect that situation and handle it if none of the methods uses super).ES2015 brings us class syntax, including declared constructors and methods:There are two function declarations above: One for the constructor, which gets the name Person, and one for getFullName, which is a function assigned to Person.prototype.",
                "Speaking about the global context, both, the var statement and a FunctionDeclaration at the end will create a non-deleteable property on the global object, but the value of both can be overwritten.The subtle difference between the two ways is that when the Variable Instantiation process runs (before the actual code execution) all identifiers declared with var will be initialized with undefined, and the ones used by the FunctionDeclaration's will be available since that moment, for example:The assignment of the bar FunctionExpression takes place until runtime.A global property created by a FunctionDeclaration can be overwritten without any problems just like a variable value, e.g.:Another obvious difference between your two examples is that the first function doesn't have a name, but the second has it, which can be really useful when debugging (i.e. inspecting a call stack).About your edited first example (foo = function() { alert('hello!'); };), it is an undeclared assignment, I would highly encourage you to always use the var keyword.With an assignment, without the var statement, if the referenced identifier is not found in the scope chain, it will become a deleteable property of the global object.Also, undeclared assignments throw a ReferenceError on ECMAScript 5 under Strict Mode.A must read:Note: This answer has been merged from another question, in which the major doubt and misconception from the OP was that identifiers declared with a FunctionDeclaration, couldn't be overwritten which is not the case.",
                "The two code snippets you've posted there will, for almost all purposes, behave the same way.However, the difference in behaviour is that with the first variant (var functionOne = function() {}), that function can only be called after that point in the code.With the second variant (function functionTwo()), the function is available to code that runs above where the function is declared.This is because with the first variant, the function is assigned to the variable foo at run time. In the second, the function is assigned to that identifier, foo, at parse time.More technical informationJavaScript has three ways of defining functions.",
                "A better explanation to Greg's answerWhy no error? We were always taught that expressions are executed from top to bottom(??)Function declarations and variable declarations are always moved (hoisted) invisibly to the top of their containing scope by the JavaScript interpreter. Function parameters and language-defined names are, obviously, already there. ben cherryThis means that code like this:Notice that the assignment portion of the declarations were not hoisted. Only the name is hoisted.But in the case with function declarations, the entire function body will be hoisted as well:",
                "Other commenters have already covered the semantic difference of the two variants above. I wanted to note a stylistic difference: Only the \"assignment\" variation can set a property of another object.I often build JavaScript modules with a pattern like this:With this pattern, your public functions will all use assignment, while your private functions use declaration.(Note also that assignment should require a semicolon after the statement, while declaration prohibits it.)",
                "An illustration of when to prefer the first method to the second one is when you need to avoid overriding a function's previous definitions.With, this definition of myfunction will override any previous definition, since it will be done at parse-time.Whiledoes the correct job of defining myfunction only when condition is met.",
                "An important reason is to add one and only one variable as the \"Root\" of your namespace...orThere are many techniques for namespacing. It's become more important with the plethora of JavaScript modules available.Also see How do I declare a namespace in JavaScript?",
                "Hoisting is the JavaScript interpreter\u2019s action of moving all variable and function declarations to the top of the current scope.However, only the actual declarations are hoisted. by leaving assignments where they are.VariableJavascript is called loosely typed language. Which means Javascript variables can hold value of any Data-Type. Javascript automatically takes care of changing the variable-type based on the value/literal provided during runtime.FunctionDefault return value of function is 'undefined', Variable declaration default value also 'undefined'Function DeclarationFunction ExpressionFunction assigned to variable Example:javascript interpreted asYou can check function declaration, expression test over different browser's using jsperf Test RunnerES5 Constructor Function Classes: Function objects created using Function.prototype.bindJavaScript treats functions as first-class objects, so being an object, you can assign properties to a function.ES6 introduced Arrow function: An arrow function expression has a shorter syntax, they are best suited for non-method functions, and they cannot be used as constructors.ArrowFunction : ArrowParameters => ConciseBody.",
                "I'm adding my own answer just because everyone else has covered the hoisting part thoroughly.I've wondered about which way is better for a long while now, and thanks to http://jsperf.com now I know :)Function declarations are faster, and that's what really matters in web dev right? ;)",
                "The following works because function add() is scoped to the nearest block:try {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nfunction add(a, b){\n  return a + b;\n}The following does not work because the variable is called before a function value is assigned to the variable add.try {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nvar add=function(a, b){\n  return a + b;\n}The above code is identical in functionality to the code below. Note that explicitly assigning add = undefined is superfluous because simply doing var add; is the exact same as var add=undefined.var add = undefined;\n\ntry {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nadd = function(a, b){\n  return a + b;\n}The following does not work because var add= begins an expression and causes the following function add() to be an expression instead of a block. Named functions are only visible to themselves and their surrounding block. As function add() is an expression here, it has no surrounding block, so it is only visible to itself.try {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nvar add=function add(a, b){\n  return a + b;\n}The name of a function function thefuncname(){} is thefuncname when it is declared this way.function foobar(a, b){}\n\nconsole.log(foobar.name);var a = function foobar(){};\n\nconsole.log(a.name);Otherwise, if a function is declared as function(){}, the function.name is the first variable used to store the function.var a = function(){};\nvar b = (function(){ return function(){} });\n\nconsole.log(a.name);\nconsole.log(b.name);If there are no variables set to the function, then the functions name is the empty string (\"\").console.log((function(){}).name === \"\");Lastly, while the variable the function is assigned to initially sets the name, successive variables set to the function do not change the name.var a = function(){};\nvar b = a;\nvar c = b;\n\nconsole.log(a.name);\nconsole.log(b.name);\nconsole.log(c.name);In Google's V8 and Firefox's Spidermonkey there might be a few microsecond JIT compilation difference, but ultimately the result is the exact same. To prove this, let's examine the efficiency of JSPerf at micro-benchmarks by comparing the speed of two blank code snippets. The JSPerf tests are found here. And, the jsben.ch tests are  found here. As you can see, there is a noticeable difference when there should be none. If you are really a performance freak like me, then it might be more worth your while trying to reduce the number of variables and functions in the scope and especially eliminating polymorphism (such as using the same variable to store two different types).When you use the var keyword to declare a variable, you can then reassign a different value to the variable like so.(function(){\n    \"use strict\";\n    var foobar = function(){}; // initial value\n    try {\n        foobar = \"Hello World!\"; // new value\n        console.log(\"[no error]\");\n    } catch(error) {\n        console.log(\"ERROR: \" + error.message);\n    }\n    console.log(foobar, window.foobar);\n})();However, when we use the const-statement, the variable reference becomes immutable. This means that we cannot assign a new value to the variable. Please note, however, that this does not make the contents of the variable immutable: if you do const arr = [], then you can still do arr[10] = \"example\". Only doing something like arr = \"new value\" or arr = [] would throw an error as seen below.(function(){\n    \"use strict\";\n    const foobar = function(){}; // initial value\n    try {\n        foobar = \"Hello World!\"; // new value\n        console.log(\"[no error]\");\n    } catch(error) {\n        console.log(\"ERROR: \" + error.message);\n    }\n    console.log(foobar, window.foobar);\n})();Interestingly, if we declare the variable as function funcName(){}, then the immutability of the variable is the same as declaring it with var.(function(){\n    \"use strict\";\n    function foobar(){}; // initial value\n    try {\n        foobar = \"Hello World!\"; // new value\n        console.log(\"[no error]\");\n    } catch(error) {\n        console.log(\"ERROR: \" + error.message);\n    }\n    console.log(foobar, window.foobar);\n})();The \"nearest block\" is the nearest \"function,\" (including asynchronous functions, generator functions, and asynchronous generator functions). However, interestingly, a function functionName() {} behaves like a var functionName = function() {} when in a non-closure block to items outside said closure. Observe.try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}');\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\nvar add=function(a, b){return a + b}try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\nfunction add(a, b){\n  return a + b;\n}try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n(function () {\n    function add(a, b){\n      return a + b;\n    }\n})();try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n{\n    function add(a, b){\n      return a + b;\n    }\n}try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n(() => {\n    var add=function(a, b){\n      return a + b;\n    }\n})();try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n(() => {\n    function add(a, b){\n      return a + b;\n    }\n})();",
                "A function declaration and a function expression assigned to a variable behave the same once the binding is established.There is a difference however at how and when the function object is actually associated with its variable. This difference is due to the mechanism called variable hoisting in JavaScript.Basically, all function declarations and variable declarations are hoisted to the top of the function in which the declaration occurs (this is why we say that JavaScript has function scope).When a function declaration is hoisted, the function body \"follows\"\nso when the function body is evaluated, the variable will immediately\nbe bound to a function object.When a variable declaration is hoisted, the initialization does not\nfollow, but is \"left behind\". The variable is initialized to\nundefined at the start of the function body, and will be assigned\na value at its original location in the code. (Actually, it will be assigned a value at every location where a declaration of a variable with the same name occurs.)The order of hoisting is also important: function declarations take precedence over variable declarations with the same name, and the last function declaration takes precedence over previous function declarations with the same name.Some examples...Variable foo is hoisted to the top of the function, initialized to undefined, so that !foo is true, so foo is assigned 10. The foo outside of bar's scope plays no role and is untouched.Function declarations take precedence over variable declarations, and the last function declaration \"sticks\".In this example a is initialized with the function object resulting from evaluating the second function declaration, and then is assigned 4.Here the function declaration is hoisted first, declaring and initializing variable a. Next, this variable is assigned 10. In other words: the assignment does not assign to outer variable a.",
                "The first example is a function declaration:The second example is a function expression:The main difference is how they are hoisted (lifted and declared). In the first example, the whole function declaration is hoisted. In the second example only the var 'abc' is hoisted, its value (the function) will be undefined, and the function itself remains at the position that it is declared.To put it simply:To study more about this topic I strongly recommend you this\nlink",
                "In terms of code maintenance cost, named functions are more preferable:I suspect more PROS for named functions are follow. And what is listed as an advantage of named functions is a disadvantage for anonymous ones.Historically, anonymous functions appeared from the inability of JavaScript as a language to list members with named functions:",
                "In computer science terms, we talk about anonymous functions and named functions. I think the most important difference is that an anonymous function is not bound to a name, hence the name anonymous function. In JavaScript it is a first class object dynamically declared at runtime.For more information on anonymous functions and lambda calculus, Wikipedia is a good start: Anonymous Functions.",
                "I use the variable approach in my code for a very specific reason, the theory of which has been covered in an abstract way above, but an example might help some people like me, with limited JavaScript expertise.I have code that I need to run with 160 independently-designed brandings. Most of the code is in shared files, but branding-specific stuff is in a separate file, one for each branding.Some brandings require specific functions, and some do not. Sometimes I have to add new functions to do new branding-specific things. I am happy to change the shared coded, but I don't want to have to change all 160 sets of branding files.By using the variable syntax, I can declare the variable (a function pointer essentially) in the shared code and either assign a trivial stub function, or set to null.The one or two brandings that need a specific implementation of the function can then define their version of the function and assign this to the variable if they want, and the rest do nothing. I can test for a null function before I execute it in the shared code.From people's comments above, I gather it may be possible to redefine a static function too, but I think the variable solution is nice and clear.",
                "Greg's Answer is good enough, but I still would like to add something to it that I learned just now watching Douglas Crockford's videos.Function expression:Function statement:The function statement is just a shorthand for var statement with a function value.Soexpands toWhich expands further to:And they are both hoisted to the top of the code.",
                "@EugeneLazutkin gives an example where he names an assigned function to be able to use shortcut() as an internal reference to itself. John Resig gives another example - copying a recursive function assigned to another object in his Learning Advanced Javascript tutorial. While assigning functions to properties isn't strictly the question here, I recommend actively trying the tutorial out - run the code by clicking the button in the upper right corner, and double click the code to edit to your liking.Examples from the tutorial: recursive calls in yell():Tests fail when the original ninja object is removed. (page 13)function assert(predicate, message) { if(!predicate) { throw new Error(message); } }\n\nvar ninja = {\n  yell: function(n){\nreturn n > 0 ? ninja.yell(n-1) + \"a\" : \"hiy\";\n  }\n};\nassert( ninja.yell(4) == \"hiyaaaa\", \"A single object isn't too bad, either.\" ); \n\nvar samurai = { yell: ninja.yell };\nvar ninja = null;\n\ntry {\n  samurai.yell(4);\n} catch(e){\n  assert( false, \"Uh, this isn't good! Where'd ninja.yell go?\" );\n}If you name the function that will be called recursively, the tests will pass. (page 14)function assert(predicate, message) { if(!predicate) { throw new Error(message); } }\n\nvar ninja = {\n  yell: function yell(n){\nreturn n > 0 ? yell(n-1) + \"a\" : \"hiy\";\n  }\n};\nassert( ninja.yell(4) == \"hiyaaaa\", \"Works as we would expect it to!\" );\n \nvar samurai = { yell: ninja.yell };\nvar ninja = {};\nassert( samurai.yell(4) == \"hiyaaaa\", \"The method correctly calls itself.\" );\n\nconsole.log(samurai.yell(4));",
                "Another difference that is not mentioned in the other answers is that if you use the anonymous functionand use that as a constructor as inthen one.constructor.name will not be defined. Function.name is non-standard but is supported by Firefox, Chrome, other Webkit-derived browsers and IE 9+.Withit is possible to retrieve the name of the constructor as a string with two.constructor.name.",
                "The first one (function doSomething(x)) should be part of an object notation.The second one (var doSomething = function(x){ alert(x);}) is simply creating an anonymous function and assigning it to a variable, doSomething. So doSomething() will call the function.You may want to know what a function declaration and function expression is.A function declaration defines a named function variable without requiring variable assignment. Function declarations occur as standalone constructs and cannot be nested within non-function blocks.ECMA 5 (13.0) defines the syntax as \n  function Identifier ( FormalParameterListopt ) { FunctionBody }In above condition the function name is visible within its scope and the scope of its parent (otherwise it would be unreachable).And in a function expressionA function expression defines a function as a part of a larger expression syntax (typically a variable assignment ). Functions defined via functions expressions can be named or anonymous. Function expressions should not start with \u201cfunction\u201d.ECMA 5 (13.0) defines the syntax as \n  function Identifieropt ( FormalParameterListopt ) { FunctionBody }",
                "I'm listing out the differences below:A function declaration can be placed anywhere in the code. Even if it is invoked before the definition appears in code, it gets executed as function declaration is committed to memory or in a way it is hoisted up, before any other code in the page starts execution.Take a look at the function below:This is because, during execution, it looks like:-A function expression, if not defined before calling it, will result in an error. Also, here the function definition itself is not moved to the top or committed to memory like in the function declarations. But the variable to which we assign the function gets hoisted up and undefined gets assigned to it.Same function using function expressions:This is because during execution, it looks like:It is not safe to write function declarations in non-function blocks like if because they won't be accessible.Named function expression like the one below, may not work in Internet\u00a0Explorer browsers prior to version 9.",
                "About performance:New versions of V8 introduced several under-the-hood optimizations and so did SpiderMonkey.There is almost no difference now between expression and declaration. Function expression appears to be faster now.Chrome 62.0.3202FireFox 55Chrome Canary 63.0.3225Anonymous function expressions appear to have better performance\n  against Named function expression.Firefox\n\nChrome Canary\n\nChrome",
                "If you would use those functions to create objects, you would get:",
                "In JavaScript there are two ways to create functions:Function declaration:This is very basic, self-explanatory, used in many languages and standard across C family of languages. We declared a function defined it and executed it by calling it.What you should be knowing is that functions are actually objects in JavaScript; internally we have created an object for above function and given it a name called fn or the reference to the object is stored in fn. Functions are objects in JavaScript; an instance of function is actually an object instance.Function expression:JavaScript has first-class functions, that is, create a function and assign it to a variable just like you create a string or number and assign it to a variable. Here, the fn variable is assigned to a function. The reason for this concept is functions are objects in JavaScript; fn is pointing to the object instance of the above function. We have initialized a function and assigned it to a variable. It's not executing the function and assigning the result.Reference: JavaScript function declaration syntax: var fn = function() {} vs function fn() {}",
                "The first function syntax is Anonymous Function Expression:While, the second one is Function Declaration:The main difference between both is the function name since Anonymous Functions have no name to call.\nAnonymous functions are quick and easy to declare, and many libraries and tools tend to encourage this idiomatic style of code. However, anonymous functions have some drawbacks:Readability: anonymous functions omit a name which could cause less readable code.Debugging: anonymous functions have no name in stack traces, which can make debugging more difficult.Self-Reference: what if the function needs to refer to itself, for recursion for example.Providing a name for your function expression quite effectively addresses all these drawbacks, and has no tangible downsides. The best practice is to always name your function expressions:For functions assigned to a variable, naming the function, in this case, is not very common and may cause confusion, in this case, the arrow function may be a better choice.",
                "In light of the \"named functions show up in stack traces\" argument, modern JavaScript engines are actually quite capable of representing anonymous functions.As of this writing, V8, SpiderMonkey, Chakra and Nitro always refer to named functions by their names. They almost always refer to an anonymous function by its identifier if it has one.SpiderMonkey can figure out the name of an anonymous function returned from another function. The rest can't.If you really, really wanted your iterator and success callbacks to show up in the trace, you could name those too...But for the most part it's not worth stressing over.",
                "Both are different ways of defining a function. The difference is how the browser interprets and loads them into an execution context.The first case is of function expressions which loads only when the interpreter reaches that line of code. So if you do it like the following, you will get an error that the functionOne is not a function.The reason is that on the first line no value is assigned to functionOne, and hence it is undefined. We are trying to call it as a function, and hence we are getting an error.On the second line we are assigning the reference of an anonymous function to functionOne.The second case is of function declarations that loads before any code is executed. So if you do like the following you won't get any error as the declaration loads before code execution.",
                "They are pretty similar with some small differences, first one is a variable which assigned to an anonymous function (Function Declaration) and second one is the normal way to create a function in JavaScript(Anonymous function Declaration), both has usage, cons and pros:1. Function ExpressionA Function Expression defines a function as a part of a larger\n  expression syntax (typically a variable assignment ). Functions\n  defined via Functions Expressions can be named or anonymous. Function\n  Expressions must not start with \u201cfunction\u201d (hence the parentheses\n  around the self invoking example below).Assign a variable to a function, means no Hoisting, as we know functions in JavaScript can Hoist, means they can be called before they get declared, while variables need to be declared before getting access to them, so means in this case we can not access the function before where it's declared, also it could be a way that you write your functions, for the functions which return another function, this kind of declaration could make sense, also in ECMA6 & above you can assign this to an arrow function which can be used to call anonymous functions, also this way of declaring is a better way to create Constructor functions in JavaScript.2. Function DeclarationA Function Declaration defines a named function variable without\n  requiring variable assignment. Function Declarations occur as\n  standalone constructs and cannot be nested within non-function blocks.\n  It\u2019s helpful to think of them as siblings of Variable Declarations.\n  Just as Variable Declarations must start with \u201cvar\u201d, Function\n  Declarations must begin with \u201cfunction\u201d.This is the normal way of calling a function in JavaScript, this function can be called before you even declare it as in JavaScript all functions get Hoisted, but if you have 'use strict' this won't Hoist as expected, it's a good way to call all normal functions which are not big in lines and neither are a  constructor function.Also, if you need more info about how hoisting works in JavaScript, visit the link below:https://developer.mozilla.org/en-US/docs/Glossary/Hoisting",
                "This is just two possible ways of declaring functions, and in the second way, you can use the function before declaration."
            ]
        },
        {
            "tag": "java",
            "question": [
                "Why is subtracting these two times (in 1927) giving a strange result?",
                "If I run the following program, which parses two date strings referencing times 1 second apart and compares them:\npublic static void main(String[] args) throws ParseException {\n    SimpleDateFormat sf ..."
            ],
            "url": "https://stackoverflow.com/questions/6841333",
            "answer": [
                "It's a time zone change on December 31st in Shanghai.See this page for details of 1927 in Shanghai. Basically at midnight at the end of 1927, the clocks went back 5 minutes and 52 seconds. So \"1927-12-31 23:54:08\" actually happened twice, and it looks like Java is parsing it as the later possible instant for that local date/time - hence the difference.Just another episode in the often weird and wonderful world of time zones.EDIT: Stop press! History changes...The original question would no longer demonstrate quite the same behaviour, if rebuilt with version 2013a of TZDB. In 2013a, the result would be 358 seconds, with a transition time of 23:54:03 instead of 23:54:08.I only noticed this because I'm collecting questions like this in Noda Time, in the form of unit tests... The test has now been changed, but it just goes to show - not even historical data is safe.EDIT: History has changed again...In TZDB 2014f, the time of the change has moved to 1900-12-31, and it's now a mere 343 second change (so the time between t and t+1 is 344 seconds, if you see what I mean).EDIT: To answer a question around a transition at 1900... it looks like the Java timezone implementation treats all time zones as simply being in their standard time for any instant before the start of 1900 UTC:The code above produces no output on my Windows machine. So any time zone which has any offset other than its standard one at the start of 1900 will count that as a transition. TZDB itself has some data going back earlier than that, and doesn't rely on any idea of a \"fixed\" standard time (which is what getRawOffset assumes to be a valid concept) so other libraries needn't introduce this artificial transition.",
                "You've encountered a local time discontinuity:When local standard time was about to reach Sunday, 1. January 1928,\n  00:00:00 clocks were turned backward 0:05:52 hours to Saturday, 31.\n  December 1927, 23:54:08 local standard time insteadThis is not particularly strange and has happened pretty much everywhere at one time or another as timezones were switched or changed due to political or administrative actions.",
                "The moral of this strangeness is:",
                "When incrementing time you should convert back to UTC and then add or subtract. Use the local time only for display.This way you will be able to walk through any periods where hours or minutes happen twice.If you converted to UTC, add each second, and convert to local time for display. You would go through 11:54:08 p.m. LMT - 11:59:59 p.m. LMT and then 11:54:08 p.m. CST - 11:59:59 p.m. CST.",
                "Instead of converting each date, you can use the following code:And then see that the result is:",
                "I'm sorry to say, but the time discontinuity has moved a bit inJDK 6 two years ago, and in JDK 7 just recently in update 25.Lesson to learn: avoid non-UTC times at all costs, except maybe for display.",
                "As explained by others, there's a time discontinuity there. There are two possible timezone offsets for 1927-12-31 23:54:08 at Asia/Shanghai, but only one offset for 1927-12-31 23:54:07. So, depending on which offset is used, there's either a one second difference or a 5 minutes and 53 seconds difference.This slight shift of offsets, instead of the usual one-hour daylight savings (summer time) we are used to, obscures the problem a bit.Note that the 2013a update of the timezone database moved this discontinuity a few seconds earlier, but the effect would still be observable.The new java.time package on Java 8 let use see this more clearly, and provide tools to handle it. Given:Then durationAtEarlierOffset will be one second, while durationAtLaterOffset will be five minutes and 53 seconds.Also, these two offsets are the same:But these two are different:You can see the same problem comparing 1927-12-31 23:59:59 with 1928-01-01 00:00:00, though, in this case, it is the earlier offset that produces the longer divergence, and it is the earlier date that has two possible offsets.Another way to approach this is to check whether there's a transition going on. We can do this like this:You can check whether the transition is an overlap where there's more than one valid offset for that date/time or a gap where that date/time is not valid for that zone id - by using the isOverlap() and isGap() methods on zot4.I hope this helps people handle this sort of issue once Java 8 becomes widely available, or to those using Java 7 who adopt the JSR 310 backport.",
                "IMHO the pervasive, implicit localization in Java is its single largest design flaw. It may be intended for user interfaces, but frankly, who really uses Java for user interfaces today except for some IDEs where you can basically ignore localization because programmers aren't exactly the target audience for it. You can fix it (especially on Linux servers) by:To the Java Community Process members I recommend:I mean, come on, aren't global static variables an anti-OO pattern? Nothing else is those pervasive defaults given by some rudimentary environment variables.......",
                "As others said, it's a time change in 1927 in Shanghai.It was 23:54:07 in Shanghai, in the local standard time, but then after 5 minutes and 52 seconds, it turned to the next day at 00:00:00, and then local standard time changed back to 23:54:08. So, that's why the difference between the two times is 343 seconds, not 1 second, as you would have expected.The time can also mess up in other places like the US. The US has Daylight Saving Time. When the Daylight Saving Time starts the time goes forward 1 hour. But after a while, the Daylight Saving Time ends, and it goes backward 1 hour back to the standard time zone. So sometimes when comparing times in the US the difference is about 3600 seconds not 1 second.But there is something different about these two-time changes. The latter changes continuously and the former was just a change. It didn't change back or change again by the same amount.It's better to use UTC unless if needed to use non-UTC time like in display.",
                "It cannot ever be \"1\" as the result because getTime() returns long milliseconds not seconds (of which 353 milliseconds is a fair point but the epoch for Date is started at 1970 not the 1920's).\ncmmnt: The API section you are using is largely considered deprecated.\nhttp://windsolarhybridaustralia.x10.mx/httpoutputtools-tomcat-java.html"
            ]
        },
        {
            "tag": "javascript",
            "question": [
                "How to check whether a string contains a substring in JavaScript?",
                "Usually I would expect a String.contains() method, but there doesn't seem to be one. \n\nWhat is a reasonable way to check for this?"
            ],
            "url": "https://stackoverflow.com/questions/1789945",
            "answer": [
                "ECMAScript\u00a06  introduced String.prototype.includes:const string = \"foo\";\nconst substring = \"oo\";\n\nconsole.log(string.includes(substring)); // trueString.prototype.includes is case-sensitive and is not supported by Internet\u00a0Explorer without a polyfill.In ECMAScript\u00a05 or older environments, use String.prototype.indexOf, which returns -1 when a substring cannot be found:var string = \"foo\";\nvar substring = \"oo\";\n\nconsole.log(string.indexOf(substring) !== -1); // true",
                "There is a String.prototype.includes in ES6:Note that this does not work in Internet Explorer or some other old browsers with no or incomplete ES6 support. To make it work in old browsers, you may wish to use a transpiler like Babel, a shim library like es6-shim, or this polyfill from MDN:",
                "Another alternative is KMP (Knuth\u2013Morris\u2013Pratt).The KMP algorithm searches for a length-m substring in a length-n string in worst-case O(n+m) time, compared to a worst-case of O(n\u22c5m) for the naive algorithm, so using KMP may be reasonable if you care about worst-case time complexity.Here's a JavaScript implementation by Project Nayuki, taken from https://www.nayuki.io/res/knuth-morris-pratt-string-matching/kmp-string-matcher.js:function kmpSearch(pattern, text) {\n  if (pattern.length == 0)\n    return 0; // Immediate match\n\n  // Compute longest suffix-prefix table\n  var lsp = [0]; // Base case\n  for (var i = 1; i < pattern.length; i++) {\n    var j = lsp[i - 1]; // Start by assuming we're extending the previous LSP\n    while (j > 0 && pattern[i] !== pattern[j])\n      j = lsp[j - 1];\n    if (pattern[i] === pattern[j])\n      j++;\n    lsp.push(j);\n  }\n\n  // Walk through text string\n  var j = 0; // Number of chars matched in pattern\n  for (var i = 0; i < text.length; i++) {\n    while (j > 0 && text[i] != pattern[j])\n      j = lsp[j - 1]; // Fall back in the pattern\n    if (text[i]  == pattern[j]) {\n      j++; // Next char matched, increment position\n      if (j == pattern.length)\n        return i - (j - 1);\n    }\n  }\n  return -1; // Not found\n}\n\nconsole.log(kmpSearch('ays', 'haystack') != -1) // true\nconsole.log(kmpSearch('asdf', 'haystack') != -1) // false"
            ]
        },
        {
            "tag": "c#",
            "question": [
                "What is the difference between String and string in C#?",
                "What are the differences between these two and which one should I use?\nstring s = \"Hello world!\";\nString s = \"Hello world!\";"
            ],
            "url": "https://stackoverflow.com/questions/7074",
            "answer": [
                "string is an alias in C# for System.String.\nSo technically, there is no difference.  It's like int vs. System.Int32.As far as guidelines, it's generally recommended to use string any time you're referring to an object.e.g.Likewise, I think it's generally recommended to use String if you need to refer specifically to the class.e.g.It appears that the guidance in this area may have changed, as StyleCop now enforces the use of the C# specific aliases.",
                "Just for the sake of completeness, here's a brain dump of related information...As others have noted, string is an alias for System.String. Assuming your code using String compiles to System.String (i.e. you haven't got a using directive for some other namespace with a different String type), they compile to the same code, so at execution time there is no difference whatsoever. This is just one of the aliases in C#. The complete list is:Apart from string and object, the aliases are all to value types. decimal is a value type, but not a primitive type in the CLR. The only primitive type which doesn't have an alias is System.IntPtr.In the spec, the value type aliases are known as \"simple types\". Literals can be used for constant values of every simple type; no other value types have literal forms available. (Compare this with VB, which allows DateTime literals, and has an alias for it too.)There is one circumstance in which you have to use the aliases: when explicitly specifying an enum's underlying type. For instance:That's just a matter of the way the spec defines enum declarations - the part after the colon has to be the integral-type production, which is one token of sbyte, byte, short, ushort, int, uint, long, ulong, char... as opposed to a type production as used by variable declarations for example. It doesn't indicate any other difference.Finally, when it comes to which to use: personally I use the aliases everywhere for the implementation, but the CLR type for any APIs. It really doesn't matter too much which you use in terms of implementation - consistency among your team is nice, but no-one else is going to care. On the other hand, it's genuinely important that if you refer to a type in an API, you do so in a language-neutral way. A method called ReadInt32 is unambiguous, whereas a method called ReadInt requires interpretation. The caller could be using a language that defines an int alias for Int16, for example. The .NET framework designers have followed this pattern, good examples being in the BitConverter, BinaryReader and Convert classes.",
                "String stands for System.String and it is a .NET Framework type. string is an alias in the C# language for  System.String. Both of them are compiled to System.String in IL (Intermediate Language), so there is no difference. Choose what you like and use that. If you code in C#, I'd prefer string as it's a C# type alias and well-known by C# programmers.I can say the same about (int, System.Int32) etc..",
                "The best answer I have ever heard about using the provided type aliases in C# comes from Jeffrey Richter in his book CLR Via C#. Here are his 3 reasons:So there you have it. I think these are all really good points. I however, don't find myself using Jeffrey's advice in my own code. Maybe I am too stuck in my C# world but I end up trying to make my code look like the framework code.",
                "string is a reserved word, but String is just a class name. \nThis means that string cannot be used as a variable name by itself.If for some reason you wanted a variable called string, you'd see only the first of these compiles:If you really want a variable name called string you can use @ as a prefix:Another critical difference: Stack Overflow highlights them differently.",
                "There is one difference - you can't use String without using System; beforehand.",
                "It's been covered above; however, you can't use string in reflection; you must use String.",
                "System.String is the .NET string class - in C# string is an alias for System.String - so in use they are the same.As for guidelines I wouldn't get too bogged down and just use whichever you feel like - there are more important things in life and the code is going to be the same anyway.If you find yourselves building systems where it is necessary to specify the size of the integers you are using and so tend to use Int16, Int32, UInt16, UInt32 etc. then it might look more natural to use String - and when moving around between different .net languages it might make things more understandable - otherwise I would use string and int.",
                "I prefer the capitalized .NET types (rather than the aliases) for formatting reasons. The .NET types are colored the same as other object types (the value types are proper objects, after all).Conditional and control keywords (like if, switch, and return) are lowercase and colored dark blue (by default). And I would rather not have the disagreement in use and format.Consider:",
                "This YouTube video demonstrates practically how they differ.But now for a long textual answer.When we talk about .NET there are two different things one there is .NET framework and the other there are languages (C#, VB.NET etc) which use that framework.\"System.String\" a.k.a \"String\" (capital \"S\") is a .NET framework data type while \"string\" is a C# data type.In short \"String\" is an alias (the same thing called with different names) of \"string\". So technically both the below code statements will give the same output.orIn the same way, there are aliases for other C# data types as shown below:object: System.Object, string: System.String, bool: System.Boolean, byte: System.Byte, sbyte: System.SByte, short: System.Int16 and so on.Now the million-dollar question from programmer's point of view: So when to use \"String\" and \"string\"?The first thing to avoid confusion use one of them consistently. But from best practices perspective when you do variable declaration it's good to use \"string\" (small \"s\") and when you are using it as a class name then \"String\" (capital \"S\") is preferred.In the below code the left-hand side is a variable declaration and it is declared using \"string\". On the right-hand side, we are calling a method so \"String\" is more sensible.",
                "string and String are identical in all ways (except the uppercase \"S\").  There are no performance implications either way.Lowercase string is preferred in most projects due to the syntax highlighting",
                "C# is a language which is used together with the CLR.string is a type in C#.System.String is a type in the CLR.When you use C# together with the CLR string will be mapped to System.String.Theoretically, you could implement a C#-compiler that generated Java bytecode. A sensible implementation of this compiler would probably map string to java.lang.String in order to interoperate with the Java runtime library.",
                "Lower case string is an alias for System.String.\nThey are the same in C#.There's a debate over whether you should use the System types (System.Int32, System.String, etc.) types or the C# aliases (int, string, etc). I personally believe you should use the C# aliases, but that's just my personal preference.",
                "string is just an alias for System.String. The compiler will treat them identically.The only practical difference is the syntax highlighting as you mention, and that you have to write using System if you use String.",
                "Both are same. But from coding guidelines perspective it's better to use string instead of String. This is what generally developers use. e.g. instead of using Int32 we use int as int is alias to Int32FYI\n\u201cThe keyword string is simply an alias for the predefined class System.String.\u201d - C# Language Specification 4.2.3\nhttp://msdn2.microsoft.com/En-US/library/aa691153.aspx",
                "As the others are saying, they're the same.  StyleCop rules, by default, will enforce you to use string as a C# code style best practice, except when referencing System.String static functions, such as String.Format, String.Join, String.Concat, etc...",
                "New answer after 6 years and 5 months (procrastination).While string is a reserved C# keyword that always has a fixed meaning, String is just an ordinary identifier which could refer to anything. Depending on members of the current type, the current namespace and the applied using directives and their placement, String could be a value or a type distinct from global::System.String.I shall provide two examples where using directives will not help.First, when String is a value of the current type (or a local variable):The above will not compile because IEnumerable<> does not have a non-static member called Format, and no extension methods apply. In the above case, it may still be possible to use String in other contexts where a type is the only possibility syntactically. For example String local = \"Hi mum!\"; could be OK (depending on namespace and using directives).Worse: Saying String.Concat(someSequence) will likely (depending on usings) go to the Linq extension method Enumerable.Concat. It will not go to the static method string.Concat.Secondly, when String is another type, nested inside the current type:Neither statement in the Example method compiles. Here String is always a piano string, MyPiano.String. No member (static or not) Format exists on it (or is inherited from its base class). And the value \"Goodbye\" cannot be converted into it.",
                "Using System types makes it easier to port between C# and VB.Net, if you are into that sort of thing.",
                "Against what seems to be common practice among other programmers, I prefer String over string, just to highlight the fact that String is a reference type, as Jon Skeet mentioned.",
                "string is an alias (or shorthand) of System.String. That means, by typing string we meant System.String. You can read more in think link: 'string' is an alias/shorthand of System.String.",
                "I'd just like to add this to lfousts answer, from Ritchers book:The C# language specification states, \u201cAs a matter of style, use of the keyword is favored over\n  use of the complete system type name.\u201d I disagree with the language specification; I prefer\n  to use the FCL type names and completely avoid the primitive type names. In fact, I wish that\n  compilers didn\u2019t even offer the primitive type names and forced developers to use the FCL\n  type names instead. Here are my reasons:I\u2019ve seen a number of developers confused, not knowing whether to use string\n  or String in their code. Because in C# string (a keyword) maps exactly to\n  System.String (an FCL type), there is no difference and either can be used. Similarly,\n  I\u2019ve heard some developers say that int represents a 32-bit integer when the application\n  is running on a 32-bit OS and that it represents a 64-bit integer when the application\n  is running on a 64-bit OS. This statement is absolutely false: in C#, an int always maps\n  to System.Int32, and therefore it represents a 32-bit integer regardless of the OS the\n  code is running on. If programmers would use Int32 in their code, then this potential\n  confusion is also eliminated.In C#, long maps to System.Int64, but in a different programming language, long\n  could map to an Int16 or Int32. In fact, C++/CLI does treat long as an Int32.\n  Someone reading source code in one language could easily misinterpret the code\u2019s\n  intention if he or she were used to programming in a different programming language.\n  In fact, most languages won\u2019t even treat long as a keyword and won\u2019t compile code\n  that uses it.The FCL has many methods that have type names as part of their method names. For\n  example, the BinaryReader type offers methods such as ReadBoolean, ReadInt32,\n  ReadSingle, and so on, and the System.Convert type offers methods such as\n  ToBoolean, ToInt32, ToSingle, and so on. Although it\u2019s legal to write the following\n  code, the line with float feels very unnatural to me, and it\u2019s not obvious that the line is\n  correct:Many programmers that use C# exclusively tend to forget that other programming\n  languages can be used against the CLR, and because of this, C#-isms creep into the\n  class library code. For example, Microsoft\u2019s FCL is almost exclusively written in C# and\n  developers on the FCL team have now introduced methods into the library such as\n  Array\u2019s GetLongLength, which returns an Int64 value that is a long in C# but not\n  in other languages (like C++/CLI). Another example is System.Linq.Enumerable\u2019s\n  LongCount method.I didn't get his opinion before I read the complete paragraph.",
                "String (System.String) is a class in the base class library. string (lower case) is a reserved work in C# that is an alias for System.String. Int32 vs int is a similar situation as is Boolean vs. bool. These C# language specific keywords enable you to declare primitives in a style similar to C.",
                "It's a matter of convention, really.  string just looks more like C/C++ style.  The general convention is to use whatever shortcuts your chosen language has provided (int/Int for Int32).  This goes for \"object\" and decimal as well.Theoretically this could help to port code into some future 64-bit standard in which \"int\" might mean Int64, but that's not the point, and I would expect any upgrade wizard to change any int references to Int32 anyway just to be safe.",
                "@JaredPar (a developer on the C# compiler and prolific SO user!) wrote a great blog post on this issue. I think it is worth sharing here. It is a nice perspective on our subject.[...]The keyword string has concrete meaning in C#. It is the type System.String which exists in the core runtime assembly. The runtime intrinsically understands this type and provides the capabilities developers expect for strings in .NET. Its presence is so critical to C# that if that type doesn\u2019t exist the compiler will exit before attempting to even parse a line of code. Hence string has a precise, unambiguous meaning in C# code.The identifier String though has no concrete meaning in C#. It is an identifier that goes through all the name lookup rules as Widget, Student, etc \u2026 It could bind to string or it could bind to a type in another assembly entirely whose purposes may be entirely different than string. Worse it could be defined in a way such that code like String s = \"hello\"; continued to compile.The actual meaning of String will always depend on name resolution.\nThat means it depends on all the source files in the project and all\nthe types defined in all the referenced assemblies. In short it\nrequires quite a bit of context to know what it means.True that in the vast majority of cases String and string will bind to\nthe same type. But using String still means developers are leaving\ntheir program up to interpretation in places where there is only one\ncorrect answer. When String does bind to the wrong type it can leave\ndevelopers debugging for hours, filing bugs on the compiler team, and\ngenerally wasting time that could\u2019ve been saved by using string.Another way to visualize the difference is with this sample:Many will argue that while this is information technically accurate using String is still fine because it\u2019s exceedingly rare that a codebase would define a type of this name. Or that when String is defined it\u2019s a sign of a bad codebase.[...]You\u2019ll see that String is defined for a number of completely valid purposes: reflection helpers, serialization libraries, lexers, protocols, etc \u2026 For any of these libraries String vs. string has real consequences depending on where the code is used.So remember when you see the String vs. string debate this is about semantics, not style. Choosing string gives crisp meaning to your codebase. Choosing String isn\u2019t wrong but it\u2019s leaving the door open for surprises in the future.Note: I copy/pasted most of the blog posts for archive reasons. I ignore some parts, so I recommend skipping and reading the blog post if you can.",
                "String is not a keyword and it can be used as Identifier whereas string is a keyword and cannot be used as Identifier. And in function point of view both are same.",
                "Coming late to the party: I use the CLR types 100% of the time (well, except if forced to use the C# type, but I don't remember when the last time that was).I originally started doing this years ago, as per the CLR books by Ritchie. It made sense to me that all CLR languages ultimately have to be able to support the set of CLR types, so using the CLR types yourself provided clearer, and possibly more \"reusable\" code.Now that I've been doing it for years, it's a habit and I like the coloration that VS shows for the CLR types.The only real downer is that auto-complete uses the C# type, so I end up re-typing automatically generated types to specify the CLR type instead.Also, now, when I see \"int\" or \"string\", it just looks really wrong to me, like I'm looking at 1970's C code.",
                "There is no difference.The C# keyword string maps to the .NET type System.String - it is an alias that keeps to the naming conventions of the language.Similarly, int maps to System.Int32.",
                "There's a quote on this issue from Daniel Solis' book.All the predefined types  are mapped directly to\n  underlying .NET types. The C# type names (string) are simply aliases for the\n  .NET types (String or System.String), so using the .NET names works fine syntactically, although\n  this is discouraged. Within a C# program, you should use the C# names\n  rather than the .NET names.",
                "Yes, that's no difference between them, just like the bool and Boolean.",
                "string is a keyword, and you can't use string as an identifier.String is not a keyword, and you can use it as an identifier:ExampleThe keyword string  is an alias for\n System.String aside from the keyword issue, the two are exactly\n equivalent."
            ]
        },
        {
            "tag": "javascript",
            "question": [
                "How do I remove a property from a JavaScript object?",
                "Given an object:\nlet myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\nHow do I remove the property ..."
            ],
            "url": "https://stackoverflow.com/questions/208105",
            "answer": [
                "To remove a property from an object (mutating the object), you can do it like this:Demo\n\n\nvar myObject = {\n    \"ircEvent\": \"PRIVMSG\",\n    \"method\": \"newURI\",\n    \"regex\": \"^http://.*\"\n};\ndelete myObject.regex;\n\nconsole.log(myObject);For anyone interested in reading more about it, Stack Overflow user kangax has written an incredibly in-depth blog post about the delete statement on their blog, Understanding delete. It is highly recommended.If you'd like a new object with all the keys of the original except some, you could use destructuring.Demo\n\n\nlet myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\n// assign the key regex to the variable _ indicating it will be unused\nconst {regex: _, ...newObj} = myObject;\n\nconsole.log(newObj);   // has no 'regex' key\nconsole.log(myObject); // remains unchanged",
                "Objects in JavaScript can be thought of as maps between keys and values. The delete operator is used to remove these keys, more commonly known as object properties, one at a time.var obj = {\r\n  myProperty: 1    \r\n}\r\nconsole.log(obj.hasOwnProperty('myProperty')) // true\r\ndelete obj.myProperty\r\nconsole.log(obj.hasOwnProperty('myProperty')) // falseThe delete operator does not directly free memory, and it differs from simply assigning the value of null or undefined to a property, in that the property itself is removed from the object. Note that if the value of a deleted property was a reference type (an object), and another part of your program still holds a reference to that object, then that object will, of course, not be garbage collected until all references to it have disappeared.delete will only work on properties whose descriptor marks them as configurable.",
                "Old question, modern answer. Using object destructuring, an ECMAScript\u00a06 feature, it's as simple as:Or with the questions sample:You can see it in action in the Babel try-out editor.Edit:To reassign to the same variable, use a let:",
                "var myObject = {\"ircEvent\": \"PRIVMSG\", \"method\": \"newURI\", \"regex\": \"^http://.*\"};\r\n    \r\ndelete myObject.regex;\r\n\r\nconsole.log ( myObject.regex); // logs: undefinedThis works in Firefox and Internet\u00a0Explorer, and I think it works in all others.",
                "The delete operator is used to remove properties from objects.Note that, for arrays, this is not the same as removing an element. To remove an element from an array, use Array#splice or Array#pop. For example:Strictly speaking, it's impossible to truly delete anything in JavaScript. The delete operator neither deletes objects nor frees memory. Rather, it sets its operand to undefined and manipulates the parent object so that the member is gone.The object is not deleted. Only the reference is. Memory is only freed\nby the garbage collector when all references to an object are removed.Another important caveat is that the delete operator will not reorganize structures for you, which has results that can seem counterintuitive. Deleting an array index, for example, will leave a \"hole\" in it.This is because arrays are objects. So indices are the same as keys.Different built-in functions in JavaScript handle arrays with holes in them differently.for..in statements will skip the empty index completely.A naive for loop will yield undefined for the value at the index.Any method using Symbol.iterator will return undefined for the value at the index.forEach, map and reduce will simply skip the missing index, but will not remove itExample:So, the delete operator should not be used for the common use-case of removing elements from an array. Arrays have a dedicated methods for removing elements and reallocating memory: Array#splice() and Array#pop.Array#splice mutates the array, and returns any removed indices. deleteCount elements are removed from index start, and item1, item2... itemN are inserted into the array from index start. If deleteCount is omitted then elements from startIndex are removed to the end of the array.There is also a similarly named, but different, function on Array.prototype: Array#slice.Array#slice is non-destructive, and returns a new array containing the indicated indices from start to end. If end is left unspecified, it defaults to the end of the array. If end is positive, it specifies the zero-based non-inclusive index to stop at. If end is negative it, it specifies the index to stop at by counting back from the end of the array (eg. -1 will omit the final index). If end <= start, the result is an empty array.Array#pop removes the last element from an array, and returns that element. This operation changes the length of the array. The opposite operation is pushArray#shift is similar to pop, except it removes the first element. The opposite operation is unshift.",
                "To complete Koen's answer, in case you want to remove a dynamic variable using the spread syntax, you can do it like so:const key = 'a';\n\nconst { [key]: foo, ...rest } = { a: 1, b: 2, c: 3 };\n\nconsole.log(foo);  // 1\nconsole.log(rest); // { b: 2, c: 3 }* foo will be a new variable with the value of a (which is 1).There are a few common ways to remove a property from an object. Each one has its own pros and cons (check this performance comparison):Delete OperatorIt is readable and short, however, it might not be the best choice if you are operating on a large number of objects as its performance is not optimized.ReassignmentIt is more than two times faster than delete, however the property is not deleted and can be iterated.Spread OperatorThis ES6 operator allows us to return a brand new object, excluding any properties, without mutating the existing object. The downside is that it has the worse performance out of the above and is not suggested to be used when you need to remove many properties at a time.",
                "Another alternative is to use the Underscore.js library.Note that _.pick() and _.omit() both return a copy of the object and don't directly modify the original object. Assigning the result to the original object should do the trick (not shown).Reference: link _.pick(object, *keys)Return a copy of the object, filtered to only have values for the \nwhitelisted keys (or array of valid keys).Reference: link _.omit(object, *keys)Return a copy of the object, filtered to omit the \nblacklisted keys (or array of keys).For arrays, _.filter() and _.reject() can be used in a similar manner.",
                "To clone an object without a property:For example:And we need to delete a.With an explicit prop key:With a variable prop key:A cool arrow function \ud83d\ude0e:For multiple propertiesUsageOr",
                "The term you have used in your question title, Remove a property from a JavaScript object, can be interpreted in some different ways. The one is to remove it for whole the memory and the list of object keys or the other is just to remove it from your object. As it has been mentioned in some other answers, the delete keyword is the main part. Let's say you have your object like:If you do:the result would be:You can delete that specific key from your object keys like:Then your objects key using Object.keys(myJSONObject) would be:But the point is if you care about memory and you want to whole the object gets removed from the memory, it is recommended to set it to null before you delete the key:The other important point here is to be careful about your other references to the same object. For instance, if you create a variable like:Or add it as a new pointer to another object like:Then even if you remove it from your object myJSONObject, that specific object won't get deleted from the memory, since the regex variable and myOtherObject[\"regex\"] still have their values. Then how could we remove the object from the memory for sure?The answer would be to delete all the references you have in your code, pointed to that very object and also not use var statements to create new references to that object. This last point regarding var statements, is one of the most crucial issues that we are usually faced with, because using var statements would prevent the created object from getting removed.Which means in this case you won't be able to remove that object because you have created the regex variable via a var statement, and if you do:The result would be false, which means that your delete statement haven't been executed as you expected. But if you had not created that variable before, and you only had myOtherObject[\"regex\"] as your last existing reference, you could have done this just by removing it like:In other words, a JavaScript object is eligible to be killed as soon as there is no reference left in your code pointed to that object.Update:Thanks to @AgentME:Setting a property to null before deleting it doesn't accomplish\nanything (unless the object has been sealed by Object.seal and the\ndelete fails. That's not usually the case unless you specifically\ntry).To get more information on Object.seal: Object.seal()",
                "ECMAScript 2015 (or ES6) came with built-in Reflect object. It is possible to delete object property by calling Reflect.deleteProperty() function with target object and property key as parameters:which is equivalent to:But if the property of the object is not configurable it cannot be deleted neither with deleteProperty function nor delete operator:Object.freeze() makes all properties of object not configurable (besides other things). deleteProperty function (as well as delete operator) returns false when tries to delete any of it's properties. If property is configurable it returns true, even if property does not exist.The difference between delete and deleteProperty is when using strict mode:",
                "Suppose you have an object that looks like this:If you want to use the entire staff array, the proper way to do this, would be to do this:Alternatively, you could also do this:Similarly, removing the entire students array would be done by calling delete Hogwarts.students; or delete Hogwarts['students'];.Now, if you want to remove a single staff member or student, the procedure is a bit different, because both properties are arrays themselves.If you know the index of your staff member, you could simply do this:If you do not know the index, you'll also have to do an index search:While you technically can use delete for an array, using it would result in getting incorrect results when calling for example Hogwarts.staff.length later on. In other words, delete would remove the element, but it wouldn't update the value of length property. Using delete would also mess up your indexing.So, when deleting values from an object, always first consider whether you're dealing with object properties or whether you're dealing with array values, and choose the appropriate strategy based on that.If you want to experiment with this, you can use this Fiddle as a starting point.",
                "I personally use Underscore.js or Lodash for object and array manipulation:",
                "Using delete method is the best way to do that, as per MDN description, the delete operator removes a property from an object. So you can simply write:The delete operator removes a given property from an object. On\nsuccessful deletion, it will return true, else false will be returned.\nHowever, it is important to consider the following scenarios:The following snippet gives another simple example:var Employee = {\n  age: 28,\n  name: 'Alireza',\n  designation: 'developer'\n}\n\nconsole.log(delete Employee.name);   // returns true\nconsole.log(delete Employee.age);    // returns true\n\n// When trying to delete a property that does \n// not exist, true is returned \nconsole.log(delete Employee.salary); // returns trueFor more info about and seeing more examples visit the link below:https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/delete",
                "Another solution, using Array#reduce.var myObject = {\r\n  \"ircEvent\": \"PRIVMSG\",\r\n  \"method\": \"newURI\",\r\n  \"regex\": \"^http://.*\"\r\n};\r\n\r\nmyObject = Object.keys(myObject).reduce(function(obj, key) {\r\n  if (key != \"regex\") {           //key you want to remove\r\n    obj[key] = myObject[key];\r\n  }\r\n  return obj;\r\n}, {});\r\n\r\nconsole.log(myObject);However, it will mutate the original object. If you want to create a new object without the specified key, just assign the reduce function to a new variable, e.g.:(ES6)const myObject = {\r\n  ircEvent: 'PRIVMSG',\r\n  method: 'newURI',\r\n  regex: '^http://.*',\r\n};\r\n\r\nconst myNewObject = Object.keys(myObject).reduce((obj, key) => {\r\n  key !== 'regex' ? obj[key] = myObject[key] : null;\r\n  return obj;\r\n}, {});\r\n\r\nconsole.log(myNewObject);",
                "There are a lot of good answers here but I just want to chime in that when using delete to remove a property in JavaScript, it is often wise to first check if that property exists to prevent errors.E.gDue to the dynamic nature of JavaScript there are often cases where you simply don't know if the property exists or not. Checking if obj exists before the && also makes sure you don't throw an error due to calling the hasOwnProperty() function on an undefined object.Sorry if this didn't add to your specific use case but I believe this to be a good design to adapt when managing objects and their properties.",
                "This post is very old and I find it very helpful so I decided to share the unset function I wrote in case someone else see this post and think why it's not so simple as it in PHP unset function.The reason for writing this new unset function, is to keep the index of all other variables in this hash_map. Look at the following example, and see how the index of \"test2\" did not change after removing a value from the hash_map.function unset(unsetKey, unsetArr, resort) {\n  var tempArr = unsetArr;\n  var unsetArr = {};\n  delete tempArr[unsetKey];\n  if (resort) {\n    j = -1;\n  }\n  for (i in tempArr) {\n    if (typeof(tempArr[i]) !== 'undefined') {\n      if (resort) {\n        j++;\n      } else {\n        j = i;\n      }\n      unsetArr[j] = tempArr[i];\n    }\n  }\n  return unsetArr;\n}\n\nvar unsetArr = ['test', 'deletedString', 'test2'];\n\nconsole.log(unset('1', unsetArr, true)); // output Object {0: \"test\", 1: \"test2\"}\nconsole.log(unset('1', unsetArr, false)); // output Object {0: \"test\", 2: \"test2\"}",
                "Try the following method. Assign the Object property value to undefined. Then stringify the object and parse.var myObject = {\"ircEvent\": \"PRIVMSG\", \"method\": \"newURI\", \"regex\": \"^http://.*\"};\r\n\r\nmyObject.regex = undefined;\r\nmyObject = JSON.parse(JSON.stringify(myObject));\r\n\r\nconsole.log(myObject);",
                "Using ramda#dissoc you will get a new object without the attribute regex:You can also use other functions to achieve the same effect - omit, pick, ...",
                "There are a couple of ways to remove properties from an object:const myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\",\n};\n\ndelete myObject.regex;\nconsole.log(myObject);const myObject = {\n      \"ircEvent\": \"PRIVMSG\",\n      \"method\": \"newURI\",\n      \"regex\": \"^http://.*\",\n    };\n\ndelete myObject['regex'];\nconsole.log(myObject);\n// or\nconst name = 'ircEvent';\ndelete myObject[name];\nconsole.log(myObject);const myObject = {\n      \"ircEvent\": \"PRIVMSG\",\n      \"method\": \"newURI\",\n      \"regex\": \"^http://.*\",\n    };\n\nconst { regex, ...myObjectRest} = myObject;\nconsole.log(myObjectRest);",
                "If you want to delete a property deeply nested in the object then you can use the following recursive function with path to the property as the second argument:Example:",
                "const obj = {\r\n    \"Filters\":[\r\n        {\r\n            \"FilterType\":\"between\",\r\n            \"Field\":\"BasicInformationRow.A0\",\r\n            \"MaxValue\":\"2017-10-01\",\r\n            \"MinValue\":\"2017-09-01\",\r\n            \"Value\":\"Filters value\"\r\n        }\r\n    ]\r\n};\r\n\r\nlet new_obj1 = Object.assign({}, obj.Filters[0]);\r\nlet new_obj2 = Object.assign({}, obj.Filters[0]);\r\n\r\n/*\r\n\r\n// old version\r\n\r\nlet shaped_obj1 = Object.keys(new_obj1).map(\r\n    (key, index) => {\r\n        switch (key) {\r\n            case \"MaxValue\":\r\n                delete new_obj1[\"MaxValue\"];\r\n                break;\r\n            case \"MinValue\":\r\n                delete new_obj1[\"MinValue\"];\r\n                break;\r\n        }\r\n        return new_obj1;\r\n    }\r\n)[0];\r\n\r\n\r\nlet shaped_obj2 = Object.keys(new_obj2).map(\r\n    (key, index) => {\r\n        if(key === \"Value\"){\r\n            delete new_obj2[\"Value\"];\r\n        }\r\n        return new_obj2;\r\n    }\r\n)[0];\r\n\r\n\r\n*/\r\n\r\n\r\n// new version!\r\n\r\nlet shaped_obj1 = Object.keys(new_obj1).forEach(\r\n    (key, index) => {\r\n        switch (key) {\r\n            case \"MaxValue\":\r\n                delete new_obj1[\"MaxValue\"];\r\n                break;\r\n            case \"MinValue\":\r\n                delete new_obj1[\"MinValue\"];\r\n                break;\r\n            default:\r\n                break;\r\n        }\r\n    }\r\n);\r\n\r\nlet shaped_obj2 = Object.keys(new_obj2).forEach(\r\n    (key, index) => {\r\n        if(key === \"Value\"){\r\n            delete new_obj2[\"Value\"];\r\n        }\r\n    }\r\n);",
                "Here's an ES6 way to remove the entry easily:let myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\nconst removeItem = 'regex';\n\nconst { [removeItem]: remove, ...rest } = myObject;\n\nconsole.log(remove); // \"^http://.*\"\nconsole.log(rest); // Object { ircEvent: \"PRIVMSG\", method: \"newURI\" }",
                "Dan's assertion that 'delete' is very slow and the benchmark he posted were doubted. So I carried out the test myself in Chrome 59. It does seem that 'delete' is about 30 times slower:Note that I purposely carried out more than one 'delete' operations in one loop cycle to minimize the effect caused by the other operations.",
                "There are many different options presented on this page, not because most of the options are wrong\u2014or because the answers are duplicates\u2014but because the appropriate technique depends on the situation you're in and the goals of the tasks you and/or you team are trying to fulfill. To answer you question unequivocally, one needs to know:Once those four queries have been answered, there are essentially four categories of \"property removal\" in JavaScript to chose from in order to meet your goals. They are:This category is for operating on object literals or object instances when you want to retain/continue to use the original reference and aren't using stateless functional principles in your code. An example piece of syntax in this category:This category is the oldest, most straightforward & most widely supported category of property removal. It supports Symbol & array indexes in addition to strings and works in every version of JavaScript except for the very first release. However, it's mutative which violates some programming principles and has performance implications. It also can result in uncaught exceptions when used on non-configurable properties in strict mode.This category is for operating on plain object or array instances in newer ECMAScript flavors when a non-mutative approach is desired and you don't need to account for Symbol keys:This category is for operating on object literals or object instances when you want to retain/continue to use the original reference while guarding against exceptions being thrown on unconfigurable properties:In addition, while mutating objects in-place isn't stateless, you can use the functional nature of Reflect.deleteProperty to do partial application and other functional techniques that aren't possible with delete statements.This category is for operating on plain object or array instances in newer ECMAScript flavors when a non-mutative approach is desired and you don't need to account for Symbol keys:This category is generally allows for greater functional flexibility, including accounting for Symbols & omitting more than one property in one statement:",
                "You can use a filter like belowvar myObject = {\n    \"ircEvent\": \"PRIVMSG\",\n    \"method\": \"newURI\",\n    \"regex\": \"^http://.*\"\n};\n\n// Way 1\n\nlet filter1 = {}\n  Object.keys({...myObject}).filter(d => {\n  if(d !== 'regex'){\n    filter1[d] = myObject[d];\n  }\n})\n\nconsole.log(filter1)\n\n// Way 2\n\nlet filter2 = Object.fromEntries(Object.entries({...myObject}).filter(d =>\nd[0] !== 'regex'\n))\n\nconsole.log(filter2)",
                "@johnstock, we can also use JavaScript's prototyping concept to add method to objects to delete any passed key available in calling object.Above answers are appreciated.var myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\n// 1st and direct way \ndelete myObject.regex; // delete myObject[\"regex\"]\nconsole.log(myObject); // { ircEvent: 'PRIVMSG', method: 'newURI' }\n\n// 2 way -  by using the concept of JavaScript's prototyping concept\nObject.prototype.removeFromObjectByKey = function(key) {\n  // If key exists, remove it and return true\n  if (this[key] !== undefined) {\n    delete this[key]\n    return true;\n  }\n  // Else return false\n  return false;\n}\n\nvar isRemoved = myObject.removeFromObjectByKey('method')\nconsole.log(myObject) // { ircEvent: 'PRIVMSG' }\n\n// More examples\nvar obj = {\n  a: 45,\n  b: 56,\n  c: 67\n}\nconsole.log(obj) // { a: 45, b: 56, c: 67 }\n\n// Remove key 'a' from obj\nisRemoved = obj.removeFromObjectByKey('a')\nconsole.log(isRemoved); //true\nconsole.log(obj); // { b: 56, c: 67 }\n\n// Remove key 'd' from obj which doesn't exist\nvar isRemoved = obj.removeFromObjectByKey('d')\nconsole.log(isRemoved); // false\nconsole.log(obj); // { b: 56, c: 67 }",
                "I have used Lodash \"unset\" to make it happen for a nested object also... only this needs to write small logic to get the path of the property key which is expected by the omit method.var a = {\"bool\":{\"must\":[{\"range\":{\"price_index.final_price\":{\"gt\":\"450\", \"lt\":\"500\"}}}, {\"bool\":{\"should\":[{\"term\":{\"color_value.keyword\":\"Black\"}}]}}]}};\n\nfunction getPathOfKey(object,key,currentPath, t){\n    var currentPath = currentPath || [];\n\n    for(var i in object){\n        if(i == key){\n            t = currentPath;\n        }\n        else if(typeof object[i] == \"object\"){\n            currentPath.push(i)\n            return getPathOfKey(object[i], key,currentPath)\n        }\n    }\n    t.push(key);\n    return t;\n}\ndocument.getElementById(\"output\").innerHTML =JSON.stringify(getPathOfKey(a,\"price_index.final_price\"))\n<div id=\"output\">\n\n</div>var unset = require('lodash.unset');\nunset(a, getPathOfKey(a, \"price_index.final_price\"));",
                "let myObject = {\n    \"ircEvent\": \"PRIVMSG\",\n    \"method\": \"newURI\",\n    \"regex\": \"^http://.*\"\n};\n\n\nobj = Object.fromEntries(\n    Object.entries(myObject).filter(function (m){\n        return m[0] != \"regex\"/*or whatever key to delete*/\n    }\n))\n\nconsole.log(obj)You can also just treat the object like a2d array using Object.entries, and use splice to remove an element as you would in a normal array, or simply filter through the object, as one would an array, and assign the reconstructed object back to the original variable",
                "If you don't want to modify the original object.Remove a property without mutating the objectIf mutability is a concern, you can create a completely new object by copying all the properties from the old, except the one you want to remove.let myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\nlet prop = 'regex';\nconst updatedObject = Object.keys(myObject).reduce((object, key) => {\n  if (key !== prop) {\n    object[key] = myObject[key]\n  }\n  return object\n}, {})\n\nconsole.log(updatedObject);"
            ]
        },
        {
            "tag": "python",
            "question": [
                "What are metaclasses in Python?",
                "What are metaclasses? What are they used for?"
            ],
            "url": "https://stackoverflow.com/questions/100003",
            "answer": [
                "Before understanding metaclasses, you need to master classes in Python. And Python has a very peculiar idea of what classes are, borrowed from the Smalltalk language.In most languages, classes are just pieces of code that describe how to produce an object. That's kinda true in Python too:But classes are more than that in Python. Classes are objects too.Yes, objects.As soon as you use the keyword class, Python executes it and creates\nan object. The instructioncreates in memory an object with the name ObjectCreator.This object (the class) is itself capable of creating objects (the instances),\nand this is why it's a class.But still, it's an object, and therefore:e.g.:Since classes are objects, you can create them on the fly, like any object.First, you can create a class in a function using class:But it's not so dynamic, since you still have to write the whole class yourself.Since classes are objects, they must be generated by something.When you use the class keyword, Python creates this object automatically. But as\nwith most things in Python, it gives you a way to do it manually.Remember the function type? The good old function that lets you know what\ntype an object is:Well, type has also a completely different ability: it can create classes on the fly. type can take the description of a class as parameters,\nand return a class.(I  know, it's silly that the same function can have two completely different uses according to the parameters you pass to it. It's an issue due to backward\ncompatibility in Python)type works this way:Where:e.g.:can be created manually this way:You'll notice that we use MyShinyClass as the name of the class\nand as the variable to hold the class reference. They can be different,\nbut there is no reason to complicate things.type accepts a dictionary to define the attributes of the class. So:Can be translated to:And used as a normal class:And of course, you can inherit from it, so:would be:Eventually, you'll want to add methods to your class. Just define a function\nwith the proper signature and assign it as an attribute.And you can add even more methods after you dynamically create the class, just like adding methods to a normally created class object.You see where we are going: in Python, classes are objects, and you can create a class on the fly, dynamically.This is what Python does when you use the keyword class, and it does so by using a metaclass.Metaclasses are the 'stuff' that creates classes.You define classes in order to create objects, right?But we learned that Python classes are objects.Well, metaclasses are what create these objects. They are the classes' classes,\nyou can picture them this way:You've seen that type lets you do something like this:It's because the function type is in fact a metaclass. type is the\nmetaclass Python uses to create all classes behind the scenes.Now you wonder \"why the heck is it written in lowercase, and not Type?\"Well, I guess it's a matter of consistency with str, the class that creates\nstrings objects, and int the class that creates integer objects. type is\njust the class that creates class objects.You see that by checking the __class__ attribute.Everything, and I mean everything, is an object in Python. That includes integers,\nstrings, functions and classes. All of them are objects. And all of them have\nbeen created from a class:Now, what is the __class__ of any __class__ ?So, a metaclass is just the stuff that creates class objects.You can call it a 'class factory' if you wish.type is the built-in metaclass Python uses, but of course, you can create your\nown metaclass.In Python 2, you can add a __metaclass__ attribute when you write a class (see next section for the Python 3 syntax):If you do so, Python will use the metaclass to create the class Foo.Careful, it's tricky.You write class Foo(object) first, but the class object Foo is not created\nin memory yet.Python will look for __metaclass__ in the class definition. If it finds it,\nit will use it to create the object class Foo. If it doesn't, it will use\ntype to create the class.Read that several times.When you do:Python does the following:Is there a __metaclass__ attribute in Foo?If yes, create in-memory a class object (I said a class object, stay with me here), with the name Foo by using what is in __metaclass__.If Python can't find __metaclass__, it will look for a __metaclass__ at the MODULE level, and try to do the same (but only for classes that don't inherit anything, basically old-style classes).Then if it can't find any __metaclass__ at all, it will use the Bar's (the first parent) own metaclass (which might be the default type) to create the class object.Be careful here that the __metaclass__ attribute will not be inherited, the metaclass of the parent (Bar.__class__) will be. If Bar used a __metaclass__ attribute that created Bar with type() (and not type.__new__()), the subclasses will not inherit that behavior.Now the big question is, what can you put in __metaclass__?The answer is something that can create a class.And what can create a class? type, or anything that subclasses or uses it.The syntax to set the metaclass has been changed in Python 3:i.e. the __metaclass__ attribute is no longer used, in favor of a keyword argument in the list of base classes.The behavior of metaclasses however stays largely the same.One thing added to metaclasses in Python 3 is that you can also pass attributes as keyword-arguments into a metaclass, like so:Read the section below for how Python handles this.The main purpose of a metaclass is to change the class automatically,\nwhen it's created.You usually do this for APIs, where you want to create classes matching the\ncurrent context.Imagine a stupid example, where you decide that all classes in your module\nshould have their attributes written in uppercase. There are several ways to\ndo this, but one way is to set __metaclass__ at the module level.This way, all classes of this module will be created using this metaclass,\nand we just have to tell the metaclass to turn all attributes to uppercase.Luckily, __metaclass__ can actually be any callable, it doesn't need to be a\nformal class (I know, something with 'class' in its name doesn't need to be\na class, go figure... but it's helpful).So we will start with a simple example, by using a function.Let's check:Now, let's do exactly the same, but using a real class for a metaclass:Let's rewrite the above, but with shorter and more realistic variable names now that we know what they mean:You may have noticed the extra argument cls. There is\nnothing special about it: __new__ always receives the class it's defined in, as the first parameter. Just like you have self for ordinary methods which receive the instance as the first parameter, or the defining class for class methods.But this is not proper OOP. We are calling type directly and we aren't overriding or calling the parent's __new__. Let's do that instead:We can make it even cleaner by using super, which will ease inheritance (because yes, you can have metaclasses, inheriting from metaclasses, inheriting from type):Oh, and in Python 3 if you do this call with keyword arguments, like this:It translates to this in the metaclass to use it:That's it. There is really nothing more about metaclasses.The reason behind the complexity of the code using metaclasses is not because\nof metaclasses, it's because you usually use metaclasses to do twisted stuff\nrelying on introspection, manipulating inheritance, vars such as __dict__, etc.Indeed, metaclasses are especially useful to do black magic, and therefore\ncomplicated stuff. But by themselves, they are simple:Since __metaclass__ can accept any callable, why would you use a class\nsince it's obviously more complicated?There are several reasons to do so:Now the big question. Why would you use some obscure error-prone feature?Well, usually you don't:Metaclasses are deeper magic that\n99% of users should never worry about it.\nIf you wonder whether you need them,\nyou don't (the people who actually\nneed them know with certainty that\nthey need them, and don't need an\nexplanation about why).Python Guru Tim PetersThe main use case for a metaclass is creating an API. A typical example of this is the Django ORM. It allows you to define something like this:But if you do this:It won't return an IntegerField object. It will return an int, and can even take it directly from the database.This is possible because models.Model defines __metaclass__ and\nit uses some magic that will turn the Person you just defined with simple statements\ninto a complex hook to a database field.Django makes something complex look simple by exposing a simple API\nand using metaclasses, recreating code from this API to do the real job\nbehind the scenes.First, you know that classes are objects that can create instances.Well, in fact, classes are themselves instances. Of metaclasses.Everything is an object in Python, and they are all either instance of classes\nor instances of metaclasses.Except for type.type is actually its own metaclass. This is not something you could\nreproduce in pure Python, and is done by cheating a little bit at the implementation\nlevel.Secondly, metaclasses are complicated. You may not want to use them for\nvery simple class alterations. You can change classes by using two different techniques:99% of the time you need class alteration, you are better off using these.But 98% of the time, you don't need class alteration at all.",
                "A metaclass is the class of a class. A class defines how an instance of the class (i.e. an object) behaves while a metaclass defines how a class behaves. A class is an instance of a metaclass.While in Python you can use arbitrary callables for metaclasses (like Jerub shows), the better approach is to make it an actual class itself. type is the usual metaclass in Python. type is itself a class, and it is its own type. You won't be able to recreate something like type purely in Python, but Python cheats a little. To create your own metaclass in Python you really just want to subclass type.A metaclass is most commonly used as a class-factory. When you create an object by calling the class, Python creates a new class (when it executes the 'class' statement) by calling the metaclass. Combined with the normal __init__ and __new__ methods, metaclasses therefore allow you to do 'extra things' when creating a class, like registering the new class with some registry or replace the class with something else entirely.When the class statement is executed, Python first executes the body of the class statement as a normal block of code. The resulting namespace (a dict) holds the attributes of the class-to-be. The metaclass is determined by looking at the baseclasses of the class-to-be (metaclasses are inherited), at the __metaclass__ attribute of the class-to-be (if any) or the __metaclass__ global variable. The metaclass is then called with the name, bases and attributes of the class to instantiate it.However, metaclasses actually define the type of a class, not just a factory for it, so you can do much more with them. You can, for instance, define normal methods on the metaclass. These metaclass-methods are like classmethods in that they can be called on the class without an instance, but they are also not like classmethods in that they cannot be called on an instance of the class. type.__subclasses__() is an example of a method on the type metaclass. You can also define the normal 'magic' methods, like __add__, __iter__ and __getattr__, to implement or change how the class behaves.Here's an aggregated example of the bits and pieces:",
                "Note, this answer is for Python 2.x as it was written in 2008, metaclasses are slightly different in 3.x.Metaclasses are the secret sauce that make 'class' work. The default metaclass for a new style object is called 'type'.Metaclasses take 3 args. 'name', 'bases' and 'dict'Here is where the secret starts. Look for where name, bases and the dict come from in this example class definition.Lets define a metaclass that will demonstrate how 'class:' calls it.And now, an example that actually means something, this will automatically make the variables in the list \"attributes\" set on the class, and set to None.Note that the magic behaviour that Initialised gains by having the metaclass init_attributes is not passed onto a subclass of Initialised.Here is an even more concrete example, showing how you can subclass 'type' to make a metaclass that performs an action when the class is created. This is quite tricky:",
                "Others have explained how metaclasses work and how they fit into the Python type system. Here's an example of what they can be used for. In a testing framework I wrote, I wanted to keep track of the order in which classes were defined, so that I could later instantiate them in this order. I found it easiest to do this using a metaclass.Anything that's a subclass of MyType then gets a class attribute _order that records the order in which the classes were defined.",
                "One use for metaclasses is adding new properties and methods to an instance automatically.For example, if you look at Django models, their definition looks a bit confusing. It looks as if you are only defining class properties:However, at runtime the Person objects are filled with all sorts of useful methods. See the source for some amazing metaclassery.",
                "I think the ONLamp introduction to metaclass programming is well written and gives a really good introduction to the topic despite being several years old already.http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html (archived at https://web.archive.org/web/20080206005253/http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html)In short: A class is a blueprint for the creation of an instance, a metaclass is a blueprint for the creation of a class. It can be easily seen that in Python classes need to be first-class objects too to enable this behavior.I've never written one myself, but I think one of the nicest uses of metaclasses can be seen in the Django framework. The model classes use a metaclass approach to enable a declarative style of writing new models or form classes. While the metaclass is creating the class, all members get the possibility to customize the class itself.The thing that's left to say is: If you don't know what metaclasses are, the probability that you will not need them is 99%.",
                "TLDR: A metaclass instantiates and defines behavior for a class just like a class instantiates and defines behavior for an instance.Pseudocode:The above should look familiar. Well, where does Class come from? It's an instance of a metaclass (also pseudocode):In real code, we can pass the default metaclass, type, everything we need to instantiate a class and we get a class:A class is to an instance as a metaclass is to a class.When we instantiate an object, we get an instance:Likewise, when we define a class explicitly with the default metaclass, type, we instantiate it:Put another way, a class is an instance of a metaclass:Put a third way, a metaclass is a class's class.When you write a class definition and Python executes it, it uses a metaclass to instantiate the class object (which will, in turn, be used to instantiate instances of that class).Just as we can use class definitions to change how custom object instances behave, we can use a metaclass class definition to change the way a class object behaves.What can they be used for? From the docs:The potential uses for metaclasses are boundless. Some ideas that have been explored include logging, interface checking, automatic delegation, automatic property creation, proxies, frameworks, and automatic resource locking/synchronization.Nevertheless, it is usually encouraged for users to avoid using metaclasses unless absolutely necessary.When you write a class definition, for example, like this,You instantiate a class object.It is the same as functionally calling type with the appropriate arguments and assigning the result to a variable of that name:Note, some things automatically get added to the __dict__, i.e., the namespace:The metaclass of the object we created, in both cases, is type.(A side-note on the contents of the class __dict__: __module__ is there because classes must know where they are defined, and  __dict__ and __weakref__ are there because we don't define __slots__ - if we define __slots__ we'll save a bit of space in the instances, as we can disallow __dict__ and __weakref__ by excluding them. For example:... but I digress.)Here's the default __repr__ of classes:One of the most valuable things we can do by default in writing a Python object is to provide it with a good __repr__. When we call help(repr) we learn that there's a good test for a __repr__ that also requires a test for equality - obj == eval(repr(obj)). The following simple implementation of __repr__ and __eq__ for class instances of our type class provides us with a demonstration that may improve on the default __repr__ of classes:So now when we create an object with this metaclass, the __repr__ echoed on the command line provides a much less ugly sight than the default:With a nice __repr__ defined for the class instance, we have a stronger ability to debug our code. However, much further checking with eval(repr(Class)) is unlikely (as functions would be rather impossible to eval from their default __repr__'s).If, for example, we want to know in what order a class's methods are created in, we could provide an ordered dict as the namespace of the class. We would do this with __prepare__ which returns the namespace dict for the class if it is implemented in Python 3:And usage:And now we have a record of the order in which these methods (and other class attributes) were created:Note, this example was adapted from the documentation - the new enum in the standard library does this.So what we did was instantiate a metaclass by creating a class. We can also treat the metaclass as we would any other class. It has a method resolution order:And it has approximately the correct repr (which we can no longer eval unless we can find a way to represent our functions.):",
                "Python 3 updateThere are (at this point) two key methods in a metaclass:__prepare__ lets you supply a custom mapping (such as an OrderedDict) to be used as the namespace while the class is being created.  You must return an instance of whatever namespace you choose.  If you don't implement __prepare__ a normal dict is used.__new__ is responsible for the actual creation/modification of the final class.A bare-bones, do-nothing-extra metaclass would like:A simple example:Say you want some simple validation code to run on your attributes -- like it must always be an int or a str.  Without a metaclass, your class would look something like:As you can see, you have to repeat the name of the attribute twice.  This makes typos possible along with irritating bugs.A simple metaclass can address that problem:This is what the metaclass would look like (not using __prepare__ since it is not needed):A sample run of:produces:Note:  This example is simple enough it could have also been accomplished with a class decorator, but presumably an actual metaclass would be doing much more.The 'ValidateType' class for reference:",
                "If you've done Python programming for more than a few months you'll eventually stumble upon code that looks like this:The latter is possible when you implement the __call__() magic method on the class.The __call__() method is invoked when an instance of a class is used as a callable. But as we've seen from previous answers a class itself is an instance of a metaclass, so when we use the class as a callable (i.e. when we create an instance of it) we're actually calling its metaclass' __call__() method. At this point most Python programmers are a bit confused because they've been told that when creating an instance like this instance = SomeClass() you're calling its __init__() method. Some who've dug a bit deeper know that before __init__() there's __new__(). Well, today another layer of truth is being revealed, before __new__() there's the metaclass' __call__().Let's study the method call chain from specifically the perspective of creating an instance of a class.This is a metaclass that logs exactly the moment before an instance is created and the moment it's about to return it.This is a class that uses that metaclassAnd now let's create an instance of Class_1Observe that the code above doesn't actually do anything more than logging the tasks. Each method delegates the actual work to its parent's implementation, thus keeping the default behavior. Since type is Meta_1's parent class (type being the default parent metaclass) and considering the ordering sequence of the output above, we now have a clue as to what would be the pseudo implementation of type.__call__():We can see that the metaclass' __call__() method is the one that's called first. It then delegates creation of the instance to the class's __new__() method and initialization to the instance's __init__(). It's also the one that ultimately returns the instance.From the above it stems that the metaclass' __call__() is also given the opportunity to decide whether or not a call to Class_1.__new__() or Class_1.__init__() will eventually be made. Over the course of its execution it could actually return an object that hasn't been touched by either of these methods. Take for example this approach to the singleton pattern:Let's observe what happens when repeatedly trying to create an object of type Class_2",
                "A metaclass is a class that tells how (some) other class should be created.This is a case where I saw metaclass as a solution to my problem:\nI had a really complicated problem, that probably could have been solved differently, but I chose to solve it using a metaclass.  Because of the complexity, it is one of the few modules I have written where the comments in the module surpass the amount of code that has been written.  Here it is...",
                "The type(obj) function gets you the type of an object.The type() of a class is its metaclass.To use a metaclass:type is its own metaclass. The class of a class is a metaclass-- the body of a class is the arguments passed to the metaclass that is used to construct the class.Here you can read about how to use metaclasses to customize class construction.",
                "type is actually a metaclass -- a class that creates another classes.\nMost metaclass are the subclasses of type. The metaclass receives the new class as its first argument and provide access to class object with details as mentioned below:Note:Notice that the class was not instantiated at any time; the simple act of creating the class triggered execution of the metaclass.",
                "Python classes are themselves objects - as in instance - of their meta-class.The default metaclass, which is applied when when you determine classes as:meta class are used to apply some rule to an entire set of classes. For example, suppose you're building an ORM to access a database, and you want records from each table to be of a class mapped to that table (based on fields, business rules, etc..,), a possible use of metaclass is for instance, connection pool logic, which is share by all classes of record from all tables. Another use is logic to to support foreign keys, which involves multiple classes of records.when you define metaclass, you subclass type, and can overrided the following magic methods to insert your logic.anyhow, those two are the most commonly used hooks. metaclassing is powerful, and above is nowhere near and exhaustive list of uses for metaclassing.",
                "The type() function can return the type of an object or create a new type,for example, we can create a Hi class with the type() function and do not  need to use this way with class Hi(object):In addition to using type() to create classes dynamically, you can control creation behavior of class and use metaclass.According to the Python object model, the class is the object, so the class must be an instance of another certain class.\nBy default, a Python class is instance of the type class. That is, type is metaclass of most of the built-in classes and metaclass of user-defined classes.Magic will take effect when we passed keyword arguments in metaclass, it indicates the Python interpreter to create the CustomList through ListMetaclass. new (), at this point, we can modify the class definition, for example, and add a new method and then return the revised definition.",
                "In addition to the published answers I can say that a metaclass defines the behaviour for a class. So, you can explicitly set your metaclass. Whenever Python gets a keyword class then it starts searching for the metaclass. If it's not found \u2013 the default metaclass type is used to create the class's object. Using the __metaclass__ attribute, you can set metaclass of your class:It'll produce the output like this:And, of course, you can create your own metaclass to define the behaviour of any class that are created using your class.For doing that, your default metaclass type class must be inherited as this is the main metaclass:The output will be:",
                "Note that in python 3.6 a new dunder method __init_subclass__(cls, **kwargs) was introduced to replace a lot of common use cases for metaclasses. Is is called when a subclass of the defining class is created. See python docs.",
                "Here's another example of what it can be used for:The metaclass is powerful, there are many things (such as monkey magic) you can do with it, but be careful this may only be known to you.",
                "The top answer is correct.But readers may be coming here searching answers about similarly named inner classes. They are present in popular libraries, such as Django and WTForms.As DavidW points out in the comments beneath this answer, these are library-specific features and are not to be confused with the advanced, unrelated Python language feature with a similar name.Rather, these are namespaces within classes' dicts. They are constructed using inner classes for sake of readability.In this example special field, abstract is visibly separate from fields of Author model.Another example is from the documentation for WTForms:This syntax does not get special treatment in the python programming language. Meta is not a keyword here, and does not trigger metaclass behavior. Rather, third-party library code in packages like Django and WTForms reads this property in the constructors of certain classes, and elsewhere.The presence of these declarations modifies the behavior of the classes that have these declarations. For example, WTForms reads self.Meta.csrf to determine if the form needs a csrf field.",
                "In object-oriented programming, a metaclass is a class whose instances are classes. Just as an ordinary class defines the behavior of certain objects, a metaclass defines the behavior of certain class and their instances\nThe term metaclass simply means something used to create classes. In other words, it is the class of a class. The metaclass is used to create the class so like the object being an instance of a class, a class is an instance of a metaclass. In python classes are also considered objects.",
                "A class, in Python, is an object, and just like any other object, it is an instance of \"something\". This \"something\" is what is termed as a Metaclass. This metaclass is a special type of class that creates other class's objects. Hence, metaclass is responsible for making new classes. This allows the programmer to customize the way classes are generated.To create a metaclass, overriding of new() and init() methods is usually done. new() can be overridden to change the way objects are created, while init() can be overridden to change the way of initializing the object. Metaclass can be created by a number of ways. One of the ways is to use type() function. type() function, when called with 3 parameters, creates a metaclass. The parameters are :-Another way of creating a metaclass comprises of 'metaclass' keyword. Define the metaclass as a simple class. In the parameters of inherited class, pass metaclass=metaclass_nameMetaclass can be specifically used in the following situations :-",
                "I saw an interesting use case for metaclasses in a package called classutilities. It checks if all class variables are in upper case format (it is convenient to have unified logic for configuration classes), and checks if there are no instance level methods in class.\nAnother interesting example for metaclases was deactivation of unittests based on complex conditions (checking values of multiple environmental variables).",
                "In Python, a metaclass is a subclass of a subclass that determines how a subclass behaves. A class is an instance of another metaclass. In Python, a class specifies how the class's instance will behave.Since metaclasses are in charge of class generation, you can\u00a0write your own custom metaclasses to change how classes are created by performing additional actions or injecting code. Custom metaclasses aren't always important, but they can be.",
                "look this:In other words, when an object was not created (type of object), we looking MetaClass."
            ]
        },
        {
            "tag": "linux",
            "question": [
                "How to find all files containing specific text (string) on Linux?",
                "How do I find all files containing a specific string of text within their file contents?\nThe following doesn't work. It seems to display every single file in the system.\nfind / -type f -exec grep -H '..."
            ],
            "url": "https://stackoverflow.com/questions/16956810",
            "answer": [
                "Do the following:Along with these, --exclude, --include, --exclude-dir flags could be used for efficient searching:This will only search through those files which have .c or .h extensions:This will exclude searching all the files ending with .o extension:For directories it's possible to exclude one or more directories using the --exclude-dir parameter. For example, this will exclude the dirs dir1/, dir2/ and all of them matching *.dst/:This works very well for me, to achieve almost the same purpose like yours.For more options, see man grep.",
                "Use grep -ilR:",
                "You can use ack. It is like grep for source code. You can scan your entire file system with it.Just do:In your root directory.You can also use regular expressions, specify the filetype, etc.UPDATEI just discovered The Silver Searcher, which is like ack but 3-5x faster than it and even ignores patterns from a .gitignore file.",
                "You can use:The r stands for recursive and so will search in the path specified and also its sub-directories. This will tell you the file name as well as print out the line in the file where the string appears.Or a command similar to the one you are trying (example: ) for searching in all javascript files (*.js):This will print the lines in the files where the text appears, but it does not print the file name.In addition to this command, we can write this too:\ngrep -rn \"String to search\" /path/to/directory/or/file\n-r: recursive search\nn: line number will be shown for matches",
                "Recursive and case insensitive grep with line numbers:",
                "You can use grep tool to search recursively the current folder, like:Note: -r - Recursively search subdirectories.You can also use globbing syntax to search within specific files such as:Note: By using globbing option (**), it scans all the files recursively with specific extension or pattern. To enable this syntax, run: shopt -s globstar. You may also use **/*.* for all files (excluding hidden and without extension) or any other pattern.If you've the error that your argument is too long, consider narrowing down your search, or use find syntax instead such as:Alternatively, use ripgrep.If you're working on larger projects or big files, you should use ripgrep instead, like:Checkout the docs, installation steps or source code on the GitHub project page.It's much quicker than any other tool like GNU/BSD grep, ucg, ag, sift, ack, pt or similar, since it is built on top of Rust's regex engine which uses finite automata, SIMD and aggressive literal optimizations to make searching very fast.It supports ignore patterns specified in .gitignore files, so a single file path can be matched against multiple glob patterns simultaneously.You can use common parameters such as:",
                "First of all, I believe you have used -H instead of -l. Also you can try adding the text inside quotes followed by {} \\.Let's say you are searching for files containing specific text \"Apache License\" inside your directory. It will display results somewhat similar to below (output will be different based on your directory content).Even if you are not use about the case like \"text\" vs \"TEXT\", you can use the -i switch to ignore case. You can read further details here.Hope this helps you.",
                "This grep command will give you a precise result when you are searching for specific text on Linux -grep -inRsH \"Text to be searched\"  /path/to/dir (it can be '.')i stands for ignore case distinctionsR stands for recursive and it also include symlinks. It is better to use 'R' instead of 'r'n stands for \"it will print line number\".s stands for \"suppress error messages\"H stands for \"it will print the file name for each match\"",
                "If your grep doesn't support recursive search, you can combine find with xargs:I find this easier to remember than the format for find -exec.This will output the filename and the content of the matched line, e.g.Optional flags you may want to add to grep:",
                "There's a new utility called The SilversearcherIt works closely with Git and other VCS. So you won't get anything in a .git or another directory.You can simply useAnd it will do the task for you!",
                "How do I find all files containing specific text on Linux?\n  (...)I came across this solution twice:find / -type f -exec grep -H 'text-to-find-here' {} \\;If using find like in your example, better add -s (--no-messages) to grep, and 2>/dev/null at the end of the command to avoid lots of Permission denied messages issued by grep and find:find is the standard tool for searching files - combined with grep when looking for specific text - on Unix-like platforms. The find command is often combined with xargs, by the way.Faster and easier tools exist for the same purpose - see below. Better try them, provided they're available on your platform, of course:RipGrep - fastest search tool around:The Silver Searcher:ack:Note: You can add 2>/dev/null to these commands as well, to hide many error messages.Warning: unless you really can't avoid it, don't search from '/' (the root directory) to avoid a long and inefficient search!\n So in the examples above, you'd better replace '/' by a sub-directory name, e.g. \"/home\" depending where you actually want to search...",
                "Use pwd to search from any directory you are in, recursing downwardDepending on the version of grep you are using, you can omit pwd. In newer versions . seems to be the default case for grep if no directory is given.Thus:grep -rnw -e \"pattern\"orgrep -rnw \"pattern\"will do the same thing as above!",
                "Try:",
                "For example:",
                "grep can be used even if we're not looking for a string.Simply running,will print out the path to all text files, i.e. those containing only printable characters.",
                "Silver Searcher is a terrific tool, but ripgrep may be even better.It works on Linux, Mac and Windows, and was written up on Hacker News a couple of months ago (this has a link to Andrew Gallant's Blog which has a GitHub link):Ripgrep \u2013 A new command line search tool",
                "If you strictly want to use find then use find + grep:find /path/to/somewhere/ -type f -exec grep -nw 'textPattern' {} \\;Steps:This gives you the power of find to find files.find /path/to/somewhere/ -type f -name \\*.cpp -exec grep -nw 'textPattern' {} \\;You can use different options of find to improve your file search.",
                "Here are the several list of commands that can be used to search file.",
                "If you are in a Git repository, you can use:",
                "I am fascinated by how simple grep makes it with 'rl':Use '-r' without 'l' to see the file names followed by text in which the pattern is found!It works just perfect...",
                "Hope this is of assistance...Expanding the grep a bit to give more information in the output, for example, to get the line number in the file where the text is can be done as follows:And if you have an idea what the file type is you can narrow your search down by specifying file type extensions to search for, in this case .pas OR .dfm files:Short explanation of the options:",
                "orIf you want to search the current directory:",
                "There is the ack tool that would do exactly what you are looking for:You may ignore -i for case sensitive search.",
                "Explanation from commentsfind is a command that lets you find files and other objects like directories and links in subdirectories of a given path. If you don't specify a mask that filesnames should meet, it enumerates all directory objects.",
                "Try:which will search all file systems, because / is the root folder.For home folder use:For current folder use:",
                "A Simple find can work handy. alias it in your ~/.bashrc file:Start a new terminal and issue:",
                "grep is your good friend to achieve this.If you don't care about the case of the text to find, then use:",
                "To search for the string and output just that line with the search string:e.g.:To display filename containing the search string:e.g.:",
                "I wrote a Python script which does something similar. This is how one should use this script.The first argument, path, is the directory in which we will search recursively. The second argument, pattern_to_search, is a regular expression which we want to search in a file. We use the regular expression format defined in the Python re library. In this script, the . also matches newline.The third argument, file_pattern, is optional. This is another regular expression which works on a filename. Only those files which matches this regular expression will be considered.For example, if I want to search Python files with the extension py containing Pool( followed by word Adaptor, I do the following,And voila, it generates the path of matched files and line number at which the match was found. If more than one match was found, then each line number will be appended to the filename."
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I check whether a file exists without exceptions?",
                "How do I check whether a file exists or not, without using the try statement?"
            ],
            "url": "https://stackoverflow.com/questions/82831",
            "answer": [
                "If the reason you're checking is so you can do something like if file_exists: open_it(), it's safer to use a try around the attempt to open it. Checking and then opening risks the file being deleted or moved or something between when you check and when you try to open it.If you're not planning to open the file immediately, you can use os.path.isfileReturn True if path is an existing regular file. This follows symbolic links, so both islink() and isfile() can be true for the same path.if you need to be sure it's a file.Starting with Python 3.4, the pathlib module offers an object-oriented approach (backported to pathlib2 in Python 2.7):To check a directory, do:To check whether a Path object exists independently of whether is it a file or directory, use exists():You can also use resolve(strict=True) in a try block:",
                "Use os.path.exists to check both files and directories:Use os.path.isfile to check only files (note: follows symbolic links):",
                "Unlike isfile(), exists() will return True for directories. So depending on if you want only plain files or also directories, you'll use isfile() or exists(). Here is some simple REPL output:",
                "Use os.path.isfile() with os.access():",
                "Although almost every possible way has been listed in (at least one of) the existing answers (e.g. Python 3.4 specific stuff was added), I'll try to group everything together.Note: every piece of Python standard library code that I'm going to post, belongs to version 3.5.3.Problem statement:Check file (arguable: also folder (\"special\" file) ?) existenceDon't use try / except / else / finally blocksPossible solutions:Also check other function family members like os.path.isfile, os.path.isdir, os.path.lexists for slightly different behaviors:Return True if path refers to an existing path or an open file descriptor. Returns False for broken symbolic links. On some platforms, this function may return False if permission is not granted to execute os.stat() on the requested file, even if the path physically exists.All good, but if following the import tree:os.path - posixpath.py (ntpath.py)genericpath.py - line ~20+it's just a try / except block around [Python.Docs]: os.stat(path, *, dir_fd=None, follow_symlinks=True). So, your code is try / except free, but lower in the framestack there's (at least) one such block. This also applies to other functions (including os.path.isfile).It's a fancier (and more [Wiktionary]: Pythonic) way of handling paths, butUnder the hood, it does exactly the same thing (pathlib.py - line ~1330):Either:Create one:And its usage - I'll replicate the os.path.isfile behavior (note that this is just for demonstrating purposes, do not attempt to write such code for production):Use [Python.Docs]: contextlib.suppress(*exceptions) - which was specifically designed for selectively suppressing exceptionsBut, they seem to be wrappers over try / except / else / finally blocks, as [Python.Docs]: Compound statements - The with statement states:This allows common try...except...finally usage patterns to be encapsulated for convenient reuse.Search the results for matching item(s):[Python.Docs]: os.listdir(path='.') (or [Python.Docs]: os.scandir(path='.') on Python v3.5+, backport: [PyPI]: scandir)Under the hood, both use:Nix: [Man7]: OPENDIR(3) / [Man7]: READDIR(3) / [Man7]: CLOSEDIR(3)Win: [MS.Learn]: FindFirstFileW function (fileapi.h) / [MS.Learn]: FindNextFileW function (fileapi.h) / [MS.Learn]: FindClose function (fileapi.h)via [GitHub]: python/cpython - (main) cpython/Modules/posixmodule.cUsing scandir() instead of listdir() can significantly increase the performance of code that also needs file type or file attribute information, because os.DirEntry objects expose this information if the operating system provides it when scanning a directory. All os.DirEntry methods may perform a system call, but is_dir() and is_file() usually only require a system call for symbolic links; os.DirEntry.stat() always requires a system call on Unix, but only requires one for symbolic links on Windows.[Python.Docs]: os.walk(top, topdown=True, onerror=None, followlinks=False)[Python.Docs]: glob.iglob(pathname, *, root_dir=None, dir_fd=None, recursive=False, include_hidden=False) (or its predecessor: glob.glob)Since these iterate over folders, (in most of the cases) they are inefficient for our problem (there are exceptions, like non wildcarded globbing - as @ShadowRanger pointed out), so I'm not going to insist on them. Not to mention that in some cases, filename processing might be required.Its behavior is close to os.path.exists (actually it's wider, mainly because of the 2nd argument).User permissions might restrict the file \"visibility\" as the doc states:... test if the invoking user has the specified access to path. mode should be F_OK to test the existence of path...Security considerations:Using access() to check if a user is authorized to e.g. open a file before actually doing so using open() creates a security hole, because the user might exploit the short time interval between checking and opening the file to manipulate it.Since I also work in C, I use this method as well because under the hood, it calls native APIs (again, via \"${PYTHON_SRC_DIR}/Modules/posixmodule.c\"), but it also opens a gate for possible user errors, and it's not as Pythonic as other variants. So, don't use it unless you know what you're doing:Nix: [Man7]: ACCESS(2)Warning: Using these calls to check if a user is authorized to, for example, open a file before actually doing so using open(2) creates a security hole, because the user might exploit the short time interval between checking and opening the file to manipulate it. For this reason, the use of this system call should be avoided.Win: [MS.Learn]: GetFileAttributesW function (fileapi.h)As seen, this approach is highly discouraged (especially on Nix).Note: calling native APIs is also possible via [Python.Docs]: ctypes - A foreign function library for Python, but in most cases it's more complicated. Before working with CTypes, check [SO]: C function called from Python via ctypes returns incorrect value (@CristiFati's answer) out.(Win specific): since vcruntime###.dll (msvcr###.dll for older VStudio versions - I'm going to refer to it as UCRT) exports a [MS.Learn]: _access, _waccess function family as well, here's an example (note that the recommended [Python.Docs]: msvcrt - Useful routines from the MS VC++ runtime doesn't export them):Notes:Although it's not a good practice, I'm using os.F_OK in the call, but that's just for clarity (its value is 0)I'm using _waccess so that the same code works on Python 3 and Python 2 (in spite of [Wikipedia]: Unicode related differences between them - [SO]: Passing utf-16 string to a Windows function (@CristiFati's answer))Although this targets a very specific area, it was not mentioned in any of the previous answersThe Linux (Ubuntu ([Wikipedia]: Ubuntu version history) 16 x86_64 (pc064)) counterpart as well:Notes:Instead hardcoding libc.so (LibC)'s path (\"/lib/x86_64-linux-gnu/libc.so.6\") which may (and most likely, will) vary across systems, None (or the empty string) can be passed to CDLL constructor (ctypes.CDLL(None).access(b\"/tmp\", os.F_OK)). According to [Man7]: DLOPEN(3):If filename is NULL, then the returned handle is for the main\nprogram.  When given to dlsym(3), this handle causes a search for a\nsymbol in the main program, followed by all shared objects loaded at\nprogram startup, and then all shared objects loaded by dlopen() with\nthe flag RTLD_GLOBAL.Main (current) program (python) is linked against LibC, so its symbols (including access) will be loadedThis has to be handled with care, since functions like main, Py_Main and (all the) others are available; calling them could have disastrous effects (on the current program)This doesn't also apply to Windows (but that's not such a big deal, since UCRT is located in \"%SystemRoot%\\System32\" which is in %PATH% by default). I wanted to take things further and replicate this behavior on Windows (and submit a patch), but as it turns out, [MS.Learn]: GetProcAddress function (libloaderapi.h) only \"sees\" exported symbols, so unless someone declares the functions in the main executable as __declspec(dllexport) (why on Earth the common person would do that?), the main program is loadable, but it is pretty much unusableMost likely, will rely on one of the ways above (maybe with slight customizations). One example would be (again, Win specific) [GitHub]: mhammond/pywin32 - Python for Windows (pywin32) Extensions, which is a Python wrapper over WinAPIs.But, since this is more like a workaround, I'm stopping here.I consider this a (lame) workaround (gainarie): use Python as a wrapper to execute shell commands:Win:Nix ([Wikipedia]: Unix-like) - Ubuntu:Do use try / except / else / finally blocks, because they can prevent you running into a series of nasty problemsA possible counterexample that I can think of, is performance: such blocks are costly, so try not to place them in code that it's supposed to run hundreds of thousands times per second (but since (in most cases) it involves disk access, it won't be the case)",
                "Python 3.4+ has an object-oriented path module: pathlib.  Using this new module, you can check whether a file exists like this:You can (and usually should) still use a try/except block when opening files:The pathlib module has lots of cool stuff in it: convenient globbing, checking file's owner, easier path joining, etc.  It's worth checking out.  If you're on an older Python (version 2.6 or later), you can still install pathlib with pip:Then import it as follows:",
                "This is the simplest way to check if a file exists. Just because the file existed when you checked doesn't guarantee that it will be there when you need to open it.",
                "Now available since Python 3.4, import and instantiate a Path object with the file name, and check the is_file method (note that this returns True for symlinks pointing to regular files as well):If you're on Python 2, you can backport the pathlib module from pypi, pathlib2, or otherwise check isfile from the os.path module:Now the above is probably the best pragmatic direct answer here, but there's the possibility of a race condition (depending on what you're trying to accomplish), and the fact that the underlying implementation uses a try, but Python uses try everywhere in its implementation.Because Python uses try everywhere, there's really no reason to avoid an implementation that uses it.But the rest of this answer attempts to consider these caveats.Available since Python 3.4, use the new Path object in pathlib. Note that .exists is not quite right, because directories are not files (except in the unix sense that everything is a file).So we need to use is_file:Here's the help on is_file:So let's get a file that we know is a file:By default, NamedTemporaryFile deletes the file when closed (and will automatically close when no more references exist to it).If you dig into the implementation, though, you'll see that is_file uses try:We like try because it avoids race conditions. With try, you simply attempt to read your file, expecting it to be there, and if not, you catch the exception and perform whatever fallback behavior makes sense.If you want to check that a file exists before you attempt to read it, and you might be deleting it and then you might be using multiple threads or processes, or another program knows about that file and could delete it - you risk the chance of a race condition if you check it exists, because you are then racing to open it before its condition (its existence) changes.Race conditions are very hard to debug because there's a very small window in which they can cause your program to fail.But if this is your motivation, you can get the value of a try statement by using the suppress context manager.Python 3.4 gives us the suppress context manager (previously the ignore context manager), which does semantically exactly the same thing in fewer lines, while also (at least superficially) meeting the original ask to avoid a try statement:Usage:For earlier Pythons, you could roll your own suppress, but without a try will be more verbose than with. I do believe this actually is the only answer that doesn't use try at any level in the Python that can be applied to prior to Python 3.4 because it uses a context manager instead:Perhaps easier with a try:isfilefrom the docs:os.path.isfile(path)Return True if path is an existing regular file. This follows symbolic\n  links, so both islink() and isfile() can be true for the same path.But if you examine the source of this function, you'll see it actually does use a try statement:All it's doing is using the given path to see if it can get stats on it,  catching OSError and then checking if it's a file if it didn't raise the exception.If you intend to do something with the file, I would suggest directly attempting it with a try-except to avoid a race condition:os.accessAvailable for Unix and Windows is os.access, but to use you must pass flags, and it does not differentiate between files and directories. This is more used to test if the real invoking user has access in an elevated privilege environment:It also suffers from the same race condition problems as isfile. From the docs:Note:\n  Using access() to check if a user is authorized to e.g. open a file\n  before actually doing so using open() creates a security hole, because\n  the user might exploit the short time interval between checking and\n  opening the file to manipulate it. It\u2019s preferable to use EAFP\n  techniques. For example:is better written as:Avoid using os.access. It is a low level function that has more opportunities for user error than the higher level objects and functions discussed above.Another answer says this about os.access:Personally, I prefer this one because under the hood, it calls native APIs (via \"${PYTHON_SRC_DIR}/Modules/posixmodule.c\"), but it also opens a gate for possible user errors, and it's not as Pythonic as other variants:This answer says it prefers a non-Pythonic, error-prone method, with no justification. It seems to encourage users to use low-level APIs without understanding them.It also creates a context manager which, by unconditionally returning True, allows all Exceptions (including KeyboardInterrupt and SystemExit!) to pass silently, which is a good way to hide bugs.This seems to encourage users to adopt poor practices.",
                "Prefer the try statement. It's considered better style and avoids race conditions.Don't take my word for it. There's plenty of support for this theory. Here's a couple:",
                "Use:Importing os makes it easier to navigate and perform standard actions with your operating system.For reference, also see How do I check whether a file exists without exceptions?.If you need high-level operations, use shutil.",
                "Testing for files and folders with os.path.isfile(), os.path.isdir() and os.path.exists()Assuming that the \"path\" is a valid path, this table shows what is returned by each function for files and folders:You can also test if a file is a certain type of file using os.path.splitext() to get the extension (if you don't already know it)",
                "TL;DR \nThe answer is: use the pathlib modulePathlib is probably the most modern and convenient way for almost all of the file operations. For the existence of a file or a folder a single line of code is enough. If file is not exists, it will not throw any exception.The pathlib module was introduced in Python 3.4, so you need to have Python 3.4+. This library makes your life much easier while working with files and folders, and it is pretty to use. Here is more documentation about it: pathlib \u2014 Object-oriented filesystem paths.BTW, if you are going to reuse the path, then it is better to assign it to a variable.So it will become:",
                "In 2016 the best way is still using os.path.isfile:Or in Python 3 you can use pathlib:",
                "It doesn't seem like there's a meaningful functional difference between try/except and isfile(), so you should use which one makes sense.If you want to read a file, if it exists, doBut if you just wanted to rename a file if it exists, and therefore don't need to open it, doIf you want to write to a file, if it doesn't exist, doIf you need file locking, that's a different matter.",
                "You could try this (safer):The ouput would be:([Errno 2] No such file or directory:\n  'whatever.txt')Then, depending on the result, your program can just keep running from there or you can code to stop it if you want.",
                "Date: 2017-12-04Every possible solution has been listed in other answers.An intuitive and arguable way to check if a file exists is the following:I made an exhaustive cheat sheet for your reference:",
                "Although I always recommend using try and except statements, here are a few possibilities for you (my personal favourite is using os.access):Try opening the file:Opening the file will always verify the existence of the file. You can make a function just like so:If it's False, it will stop execution with an unhanded IOError\nor OSError in later versions of Python. To catch the exception,\nyou have to use a try except clause. Of course, you can always\nuse a try except` statement like so (thanks to hsandt\nfor making me think):Use os.path.exists(path):This will check the existence of what you specify. However, it checks for files and directories so beware about how you use it.Use os.access(path, mode):This will check whether you have access to the file. It will check for permissions. Based on the os.py documentation, typing in os.F_OK, it will check the existence of the path. However, using this will create a security hole, as someone can attack your file using the time between checking the permissions and opening the file. You should instead go directly to opening the file instead of checking its permissions. (EAFP vs LBYP). If you're not going to open the file afterwards, and only checking its existence, then you can use this.Anyway, here:I should also mention that there are two ways that you will not be able to verify the existence of a file. Either the issue will be permission denied or no such file or directory. If you catch an IOError, set the IOError as e (like my first option), and then type in print(e.args) so that you can hopefully determine your issue. I hope it helps! :)",
                "If the file is for opening you could use one of the following techniques:Note: This finds either a file or a directory with the given name.",
                "Additionally, os.access():Being R_OK, W_OK, and X_OK the flags to test for permissions (doc).",
                "Raising exceptions is considered to be an acceptable, and Pythonic,\napproach for flow control in your program. Consider handling missing\nfiles with IOErrors. In this situation, an IOError exception will be\nraised if the file exists but the user does not have read permissions.Source: Using Python: How To Check If A File Exists",
                "If you imported NumPy already for other purposes then there is no need to import other libraries like pathlib, os, paths, etc.This will return true or false based on its existence.",
                "You can follow these three ways:Note 1: The os.path.isfile used only for filesNote 2: The os.path.exists is used for both files and directories",
                "You can write Brian's suggestion without the try:.suppress is part of Python 3.4. In older releases you can quickly write your own suppress:",
                "Adding one more slight variation which isn't exactly reflected in the other answers.This will handle the case of the file_path being None or empty string.Adding a variant based on suggestion from ShahbazAdding a variant based on suggestion from Peter Wood",
                "I'm the author of a package that's been around for about 10 years, and it has a function that addresses this question directly. Basically, if you are on a non-Windows system, it uses Popen to access find.  However, if you are on Windows, it replicates find with an efficient filesystem walker.The code itself does not use a try block\u2026 except in determining the operating system and thus steering you to the \"Unix\"-style find or the hand-buillt find. Timing tests showed that the try was faster in determining the OS, so I did use one there (but nowhere else).And the doc\u2026The implementation, if you care to look, is here:\nhttps://github.com/uqfoundation/pox/blob/89f90fb308f285ca7a62eabe2c38acb87e89dad9/pox/shutils.py#L190",
                "Here's a one-line Python command for the Linux command line environment. I find this very handy since I'm not such a hot Bash guy.",
                "You can use the \"OS\" library of Python:",
                "How do I check whether a file exists, without using the try statement?In 2016, this is still arguably the easiest way to check if both a file exists and if it is a file:isfile is actually just a helper method that internally uses os.stat and stat.S_ISREG(mode) underneath. This os.stat is a lower-level method that will provide you with detailed information about files, directories, sockets, buffers, and more. More about os.stat hereNote: However, this approach will not lock the file in any way and therefore your code can become vulnerable to \"time of check to time of use\" (TOCTTOU) bugs.So raising exceptions is considered to be an acceptable, and Pythonic, approach for flow control in your program. And one should consider handling missing files with IOErrors, rather than if statements (just an advice)."
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I merge two dictionaries in a single expression?",
                "I want to merge two dictionaries into a new dictionary.\nx = {'a': 1, 'b': 2}\ny = {'b': 3, 'c': 4}\nz = merge(x, y)\n\n>>> z\n{'a': 1, 'b': 3, 'c': 4}\n\nWhenever a key k is present in both ..."
            ],
            "url": "https://stackoverflow.com/questions/38987",
            "answer": [
                "For dictionaries x and y, their shallowly-merged dictionary z takes values from y, replacing those from x.In Python 3.9.0 or greater (released 17 October 2020, PEP-584, discussed here):In Python 3.5 or greater:In Python 2, (or 3.4 or lower) write a function:and now:Say you have two dictionaries and you want to merge them into a new dictionary without altering the original dictionaries:The desired result is to get a new dictionary (z) with the values merged, and the second dictionary's values overwriting those from the first.A new syntax for this, proposed in PEP 448 and available as of Python 3.5, isAnd it is indeed a single expression.Note that we can merge in with literal notation as well:and now:It is now showing as implemented in the release schedule for 3.5, PEP 478, and it has now made its way into the What's New in Python 3.5 document.However, since many organizations are still on Python 2, you may wish to do this in a backward-compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process:In both approaches, y will come second and its values will replace x's values, thus b will point to 3 in our final result.If you are not yet on Python 3.5 or need to write backward-compatible code, and you want this in a single expression, the most performant while the correct approach is to put it in a function:and then you have a single expression:You can also make a function to merge an arbitrary number of dictionaries, from zero to a very large number:This function will work in Python 2 and 3 for all dictionaries. e.g. given dictionaries a to g:and key-value pairs in g will take precedence over dictionaries a to f, and so on.Don't use what you see in the formerly accepted answer:In Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict. In Python 3, this will fail because you're adding two dict_items objects together, not two lists -and you would have to explicitly create them as lists, e.g. z = dict(list(x.items()) + list(y.items())). This is a waste of resources and computation power.Similarly, taking the union of items() in Python 3 (viewitems() in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable, since sets are semantically unordered, the behavior is undefined in regards to precedence. So don't do this:This example demonstrates what happens when values are unhashable:Here's an example where y should have precedence, but instead the value from x is retained due to the arbitrary order of sets:Another hack you should not use:This uses the dict constructor and is very fast and memory-efficient (even slightly more so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic.Here's an example of the usage being remediated in django.Dictionaries are intended to take hashable keys (e.g. frozensets or tuples), but this method fails in Python 3 when keys are not strings.From the mailing list, Guido van Rossum, the creator of the language, wrote:I am fine with\ndeclaring dict({}, **{1:3}) illegal, since after all it is abuse of\nthe ** mechanism.andApparently dict(x, **y) is going around as \"cool hack\" for \"call\nx.update(y) and return x\". Personally, I find it more despicable than\ncool.It is my understanding (as well as the understanding of the creator of the language) that the intended usage for dict(**y) is for creating dictionaries for readability purposes, e.g.:instead ofDespite what Guido says, dict(x, **y) is in line with the dict specification, which btw. works for both Python 2 and 3. The fact that this only works for string keys is a direct consequence of how keyword parameters work and not a short-coming of dict. Nor is using the ** operator in this place an abuse of the mechanism, in fact, ** was designed precisely to pass dictionaries as keywords.Again, it doesn't work for 3 when keys are not strings. The implicit calling contract is that namespaces take ordinary dictionaries, while users must only pass keyword arguments that are strings. All other callables enforced it. dict broke this consistency in Python 2:This inconsistency was bad given other implementations of Python (PyPy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change.I submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints.More comments:dict(x.items() + y.items()) is still the most readable solution for Python 2. Readability counts.My response: merge_two_dicts(x, y) actually seems much clearer to me, if we're actually concerned about readability. And it is not forward compatible, as Python 2 is increasingly deprecated.{**x, **y} does not seem to handle nested dictionaries. the contents of nested keys are simply overwritten, not merged [...] I ended up being burnt by these answers that do not merge recursively and I was surprised no one mentioned it. In my interpretation of the word \"merging\" these answers describe \"updating one dict with another\", and not merging.Yes. I must refer you back to the question, which is asking for a shallow merge of two dictionaries, with the first's values being overwritten by the second's - in a single expression.Assuming two dictionaries of dictionaries, one might recursively merge them in a single function, but you should be careful not to modify the dictionaries from either source, and the surest way to avoid that is to make a copy when assigning values. As keys must be hashable and are usually therefore immutable, it is pointless to copy them:Usage:Coming up with contingencies for other value types is far beyond the scope of this question, so I will point you at my answer to the canonical question on a \"Dictionaries of dictionaries merge\".These approaches are less performant, but they will provide correct behavior.\nThey will be much less performant than copy and update or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they do respect the order of precedence (latter dictionaries have precedence)You can also chain the dictionaries manually inside a dict comprehension:or in Python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced):itertools.chain will chain the iterators over the key-value pairs in the correct order:I'm only going to do the performance analysis of the usages known to behave correctly. (Self-contained so you can copy and paste yourself.)In Python 3.8.1, NixOS:",
                "In your case, you can do:This will, as you want it, put the final dict in z, and make the value for key b be properly overridden by the second (y) dict's value:If you use Python 2, you can even remove the list() calls. To create z:If you use Python version 3.9.0a4 or greater, then you can directly use:",
                "An alternative:",
                "Another, more concise, option:Note: this has become a popular answer, but it is important to point out that if y has any non-string keys, the fact that this works at all is an abuse of a CPython implementation detail, and it does not work in Python 3, or in PyPy, IronPython, or Jython. Also, Guido is not a fan. So I can't recommend this technique for forward-compatible or cross-implementation portable code, which really means it should be avoided entirely.",
                "This probably won't be a popular answer, but you almost certainly do not want to do this.  If you want a copy that's a merge, then use copy (or deepcopy, depending on what you want) and then update.  The two lines of code are much more readable - more Pythonic - than the single line creation with .items() + .items().  Explicit is better than implicit.In addition, when you use .items() (pre Python 3.0), you're creating a new list that contains the items from the dict.  If your dictionaries are large, then that is quite a lot of overhead (two large lists that will be thrown away as soon as the merged dict is created).  update() can work more efficiently, because it can run through the second dict item-by-item.In terms of time:IMO the tiny slowdown between the first two is worth it for the readability.  In addition, keyword arguments for dictionary creation was only added in Python 2.3, whereas copy() and update() will work in older versions.",
                "In a follow-up answer, you asked about the relative performance of these two alternatives:On my machine, at least (a fairly ordinary x86_64 running Python 2.5.2), alternative z2 is not only shorter and simpler but also significantly faster.  You can verify this for yourself using the timeit module that comes with Python.Example 1: identical dictionaries mapping 20 consecutive integers to themselves:z2 wins by a factor of 3.5 or so.  Different dictionaries seem to yield quite different results, but z2 always seems to come out ahead.  (If you get inconsistent results for the same test, try passing in -r with a number larger than the default 3.)Example 2: non-overlapping dictionaries mapping 252 short strings to integers and vice versa:z2 wins by about a factor of 10.  That's a pretty big win in my book!After comparing those two, I wondered if z1's poor performance could be attributed to the overhead of constructing the two item lists, which in turn led me to wonder if this variation might work better:A few quick tests, e.g.lead me to conclude that z3 is somewhat faster than z1, but not nearly as fast as z2.  Definitely not worth all the extra typing.This discussion is still missing something important, which is a performance comparison of these alternatives with the \"obvious\" way of merging two lists: using the update method.  To try to keep things on an equal footing with the expressions, none of which modify x or y, I'm going to make a copy of x instead of modifying it in-place, as follows:A typical result:In other words, z0 and z2 seem to have essentially identical performance.  Do you think this might be a coincidence?  I don't....In fact, I'd go so far as to claim that it's impossible for pure Python code to do any better than this.  And if you can do significantly better in a C extension module, I imagine the Python folks might well be interested in incorporating your code (or a variation on your approach) into the Python core.  Python uses dict in lots of places; optimizing its operations is a big deal.You could also write this asas Tony does, but (not surprisingly) the difference in notation turns out not to have any measurable effect on performance.  Use whichever looks right to you.  Of course, he's absolutely correct to point out that the two-statement version is much easier to understand.",
                "In Python 3.0 and later, you can use collections.ChainMap which groups multiple dicts or other mappings together to create a single, updateable view:Update for Python 3.5 and later: You can use PEP 448 extended dictionary packing and unpacking.  This is fast and easy:Update for Python 3.9 and later:  You can use the PEP 584 union operator:",
                "I wanted something similar, but with the ability to specify how the values on duplicate keys were merged, so I hacked this out (but did not heavily test it).  Obviously this is not a single expression, but it is a single function call.",
                "Demonstration:Outputs:Thanks rednaw for edits.",
                "Python 3.5 (PEP 448) allows a nicer syntax option:Or evenIn Python 3.9 you also use | and |= with the below example from PEP 584",
                "For items with keys in both dictionaries ('b'), you can control which one ends up in the output by putting that one last.",
                "The best version I could think while not using copy would be:It's faster than dict(x.items() + y.items()) but not as fast as n = copy(a); n.update(b), at least on CPython. This version also works in Python 3 if you change iteritems() to items(), which is automatically done by the 2to3 tool.Personally I like this version best because it describes fairly good what I want in a single  functional syntax. The only minor problem is that it doesn't make completely obvious that values from y takes precedence over values from x, but I don't believe it's difficult to figure that out.",
                "While the question has already been answered several times,\nthis simple solution to the problem has not been listed yet.It is as fast as z0 and the evil z2 mentioned above, but easy to understand and change.",
                "Among such shady and dubious answers, this shining example is the one and only good way to merge dicts in Python, endorsed by dictator for life Guido van Rossum himself!  Someone else suggested half of this, but did not put it in a function.gives:",
                "I benchmarked the suggested with perfplot and found that the good oldis the fastest solution together with the good oldandCode to reproduce the plot:",
                "Be Pythonic. Use a comprehension:",
                "If you think lambdas are evil then read no further.\nAs requested, you can write the fast and memory-efficient solution with one expression:As suggested above, using two lines or writing a function is probably a better way to go.",
                "In python3, the items method no longer returns a list, but rather a view, which acts like a set. In this case you'll need to take the set union since concatenating with + won't work:For python3-like behavior in version 2.7, the viewitems method should work in place of items:I prefer this notation anyways since it seems more natural to think of it as a set union operation rather than concatenation (as the title shows).Edit:A couple more points for python 3. First, note that the dict(x, **y) trick won't work in python 3 unless the keys in y are strings.Also, Raymond Hettinger's Chainmap answer is pretty elegant, since it can take an arbitrary number of dicts as arguments, but from the docs it looks like it sequentially looks through a list of all the dicts for each lookup:Lookups search the underlying mappings successively until a key is found.This can slow you down if you have a lot of lookups in your application:So about an order of magnitude slower for lookups. I'm a fan of Chainmap, but looks less practical where there may be many lookups.",
                "Two dictionariesn dictionariessum has bad performance. See https://mathieularose.com/how-not-to-flatten-a-list-of-lists-in-python/",
                "Simple solution using itertools that preserves order (latter dicts have precedence)And it's usage:",
                "Abuse leading to a one-expression solution for Matthew's answer:You said you wanted one expression, so I abused lambda to bind a name, and tuples to override lambda's one-expression limit. Feel free to cringe.You could also do this of course if you don't care about copying it:",
                "If you don't mind mutating x,Simple, readable, performant. You know update() always returns None, which is a false value. So the above expression will always evaluate to x, after updating it.Most mutating methods in the standard library (like .update()) return None by convention, so this kind of pattern will work on those too. However, if you're using a dict subclass or some other method that doesn't follow this convention, then or may return its left operand, which may not be what you want. Instead, you can use a tuple display and index, which works regardless of what the first element evaluates to (although it's not quite as pretty):If you don't have x in a variable yet, you can use lambda to make a local without using an assignment statement. This amounts to using lambda as a let expression, which is a common technique in functional languages, but is maybe unpythonic.Although it's not that different from the following use of the new walrus operator (Python 3.8+ only),especially if you use a default argument:If you do want a copy, PEP 584 style x | y is the most Pythonic on 3.9+. If you must support older versions, PEP 448 style {**x, **y} is easiest for 3.5+. But if that's not available in your (even older) Python version, the let expression pattern works here too.(That is, of course, nearly equivalent to (z := x.copy()).update(y) or z, but if your Python version is new enough for that, then the PEP 448 style will be available.)",
                "Drawing on ideas here and elsewhere I've comprehended a function:Usage (tested in python 3):You could use a lambda instead.",
                "New in Python 3.9: Use the union operator (|) to merge dicts similar to sets:For matching keys, the right dict takes precedence.This also works for |= to modify a dict in-place:",
                "It's so silly that .update returns nothing.\nI just use a simple helper function to solve the problem:Examples:",
                "(For Python\u00a02.7* only; there are simpler solutions for Python\u00a03*.)If you're not averse to importing a standard library module, you can do(The or a bit in the lambda is necessary because dict.update always returns None on success.)",
                "The problem I have with solutions listed to date is that, in the merged dictionary, the value for key \"b\" is 10 but, to my way of thinking, it should be 12.\nIn that light, I present the following:",
                "There will be a new option when Python 3.8 releases (scheduled for 20 October, 2019), thanks to PEP 572: Assignment Expressions. The new assignment expression operator := allows you to assign the result of the copy and still use it to call update, leaving the combined code a single expression, rather than two statements, changing:to:while behaving identically in every way. If you must also return the resulting dict (you asked for an expression returning the dict; the above creates and assigns to newdict, but doesn't return it, so you couldn't use it to pass an argument to a function as is, a la myfunc((newdict := dict1.copy()).update(dict2))), then just add or newdict to the end (since update returns None, which is falsy, it will then evaluate and return newdict as the result of the expression):Important caveat: In general, I'd discourage this approach in favor of:The unpacking approach is clearer (to anyone who knows about generalized unpacking in the first place, which you should), doesn't require a name for the result at all (so it's much more concise when constructing a temporary that is immediately passed to a function or included in a list/tuple literal or the like), and is almost certainly faster as well, being (on CPython) roughly equivalent to:but done at the C layer, using the concrete dict API, so no dynamic method lookup/binding or function call dispatch overhead is involved (where (newdict := dict1.copy()).update(dict2) is unavoidably identical to the original two-liner in behavior, performing the work in discrete steps, with dynamic lookup/binding/invocation of methods.It's also more extensible, as merging three dicts is obvious:where using assignment expressions won't scale like that; the closest you could get would be:or without the temporary tuple of Nones, but with truthiness testing of each None result:either of which is obviously much uglier, and includes further inefficiencies (either a wasted temporary tuple of Nones for comma separation, or pointless truthiness testing of each update's None return for or separation).The only real advantage to the assignment expression approach occurs if:",
                "This should solve your problem.",
                "This can be done with a single dict comprehension:In my view the best answer for the 'single expression' part as no extra functions are needed, and it is short."
            ]
        },
        {
            "tag": "javascript",
            "question": [
                "How do I return the response from an asynchronous call?",
                "How do I return the response/result from a function foo that makes an asynchronous request?\nI am trying to return the value from the callback, as well as assigning the result to a local variable ..."
            ],
            "url": "https://stackoverflow.com/questions/14220321",
            "answer": [
                "\u2192 For a more general explanation of asynchronous behaviour with different examples, see Why is my variable unaltered after I modify it inside of a function? - Asynchronous code reference\u2192 If you already understand the problem, skip to the possible solutions below.The A in Ajax stands for asynchronous. That means sending the request (or rather receiving the response) is taken out of the normal execution flow. In your example, $.ajax returns immediately and the next statement, return result;, is executed before the function you passed as success callback was even called.Here is an analogy which hopefully makes the difference between synchronous and asynchronous flow clearer:Imagine you make a phone call to a friend and ask him to look something up for you. Although it might take a while, you wait on the phone and stare into space, until your friend gives you the answer that you needed.The same is happening when you make a function call containing \"normal\" code:Even though findItem might take a long time to execute, any code coming after var item = findItem(); has to wait until the function returns the result.You call your friend again for the same reason. But this time you tell him that you are in a hurry and he should call you back on your mobile phone. You hang up, leave the house, and do whatever you planned to do. Once your friend calls you back, you are dealing with the information he gave to you.That's exactly what's happening when you do an Ajax request.Instead of waiting for the response, the execution continues immediately and the statement after the Ajax call is executed. To get the response eventually, you provide a function to be called once the response was received, a callback (notice something? call back ?). Any statement coming after that call is executed before the callback is called.Embrace the asynchronous nature of JavaScript! While certain asynchronous operations provide synchronous counterparts (so does \"Ajax\"), it's generally discouraged to use them, especially in a browser context.Why is it bad do you ask?JavaScript runs in the UI thread of the browser and any long-running process will lock the UI, making it unresponsive. Additionally, there is an upper limit on the execution time for JavaScript and the browser will ask the user whether to continue the execution or not.All of this results in a really bad user experience. The user won't be able to tell whether everything is working fine or not. Furthermore, the effect will be worse for users with a slow connection.In the following we will look at three different solutions that are all building on top of each other:All three are available in current browsers, and node 7+.The ECMAScript version released in 2017 introduced syntax-level support for asynchronous functions. With the help of async and await, you can write asynchronous in a \"synchronous style\". The code is still asynchronous, but it's easier to read/understand.async/await builds on top of promises: an async function always returns a promise. await \"unwraps\" a promise and either result in the value the promise was resolved with or throws an error if the promise was rejected.Important: You can only use await inside an async function or in a JavaScript module. Top-level await is not supported outside of modules, so you might have to make an async IIFE (Immediately Invoked Function Expression) to start an async context if not using a module.You can read more about async and await on MDN.Here is an example that elaborates the delay function findItem() above:Current browser and node versions support async/await. You can also support older environments by transforming your code to ES5 with the help of regenerator (or tools that use regenerator, such as Babel).A callback is when function 1 is passed to function 2. Function 2 can call function 1 whenever it is ready. In the context of an asynchronous process, the callback will be called whenever the asynchronous process is done. Usually, the result is passed to the callback.In the example of the question, you can make foo accept a callback and use it as success callback. So thisbecomesHere we defined the function \"inline\" but you can pass any function reference:foo itself is defined as follows:callback will refer to the function we pass to foo when we call it and we pass it on to success. I.e. once the Ajax request is successful, $.ajax will call callback and pass the response to the callback (which can be referred to with result, since this is how we defined the callback).You can also process the response before passing it to the callback:It's easier to write code using callbacks than it may seem. After all, JavaScript in the browser is heavily event-driven (DOM events). Receiving the Ajax response is nothing else but an event.\nDifficulties could arise when you have to work with third-party code, but most problems can be solved by just thinking through the application flow.The Promise API is a new feature of ECMAScript 6 (ES2015), but it has good browser support already. There are also many libraries which implement the standard Promises API and provide additional methods to ease the use and composition of asynchronous functions (e.g., bluebird).Promises are containers for future values. When the promise receives the value (it is resolved) or when it is canceled (rejected), it notifies all of its \"listeners\" who want to access this value.The advantage over plain callbacks is that they allow you to decouple your code and they are easier to compose.Here is an example of using a promise:function delay() {\n  // `delay` returns a promise\n  return new Promise(function(resolve, reject) {\n    // Only `delay` is able to resolve or reject the promise\n    setTimeout(function() {\n      resolve(42); // After 3 seconds, resolve the promise with value 42\n    }, 3000);\n  });\n}\n\ndelay()\n  .then(function(v) { // `delay` returns a promise\n    console.log(v); // Log the value once it is resolved\n  })\n  .catch(function(v) {\n    // Or do something else if it is rejected\n    // (it would not happen in this example, since `reject` is not called).\n  });\n.as-console-wrapper { max-height: 100% !important; top: 0; }Applied to our Ajax call we could use promises like this:function ajax(url) {\n  return new Promise(function(resolve, reject) {\n    var xhr = new XMLHttpRequest();\n    xhr.onload = function() {\n      resolve(this.responseText);\n    };\n    xhr.onerror = reject;\n    xhr.open('GET', url);\n    xhr.send();\n  });\n}\n\najax(\"https://jsonplaceholder.typicode.com/todos/1\")\n  .then(function(result) {\n    console.log(result); // Code depending on result\n  })\n  .catch(function() {\n    // An error occurred\n  });\n.as-console-wrapper { max-height: 100% !important; top: 0; }Describing all the advantages that promise offer is beyond the scope of this answer, but if you write new code, you should seriously consider them. They provide a great abstraction and separation of your code.More information about promises: HTML5 rocks - JavaScript Promises.Deferred objects are jQuery's custom implementation of promises (before the Promise API was standardized). They behave almost like promises but expose a slightly different API.Every Ajax method of jQuery already returns a \"deferred object\" (actually a promise of a deferred object) which you can just return from your function:Keep in mind that promises and deferred objects are just containers for a future value, they are not the value itself. For example, suppose you had the following:This code misunderstands the above asynchronous issues. Specifically, $.ajax() doesn't freeze the code while it checks the '/password' page on your server - it sends a request to the server and while it waits, it immediately returns a jQuery Ajax Deferred object, not the response from the server. That means the if statement is going to always get this Deferred object, treat it as true, and proceed as though the user is logged in. Not good.But the fix is easy:As I mentioned, some(!) asynchronous operations have synchronous counterparts. I don't advocate their use, but for completeness' sake, here is how you would perform a synchronous call:If you directly use a XMLHttpRequest object, pass false as third argument to .open.If you use jQuery, you can set the async option to false. Note that this option is deprecated since jQuery 1.8.\nYou can then either still use a success callback or access the responseText property of the jqXHR object:If you use any other jQuery Ajax method, such as $.get, $.getJSON, etc., you have to change it to $.ajax (since you can only pass configuration parameters to $.ajax).Heads up! It is not possible to make a synchronous JSONP request. JSONP by its very nature is always asynchronous (one more reason to not even consider this option).",
                "Your code should be something along the lines of this:Felix Kling did a fine job writing an answer for people using jQuery for AJAX, but I've decided to provide an alternative for people who aren't.(Note, for those using the new fetch API, Angular or promises I've added another answer below)This is a short summary of \"Explanation of the problem\" from the other answer, if you're not sure after reading this, read that.The A in AJAX stands for asynchronous. That means sending the request (or rather receiving the response) is taken out of the normal execution flow. In your example, .send returns immediately and the next statement, return result;, is executed before the function you passed as success callback was even called.This means when you're returning, the listener you've defined did not execute yet, which means the value you're returning has not been defined.Here is a simple analogy:(Fiddle)The value of a returned is undefined since the a=5 part has not executed yet. AJAX acts like this, you're returning the value before the server got the chance to tell your browser what that value is.One possible solution to this problem is to code re-actively , telling your program what to do when the calculation completed.This is called CPS. Basically, we're passing getFive an action to perform when it completes, we're telling our code how to react when an event completes (like our AJAX call, or in this case the timeout).Usage would be:Which should alert \"5\" to the screen. (Fiddle).There are basically two ways how to solve this:As for synchronous AJAX, don't do it! Felix's answer raises some compelling arguments about why it's a bad idea. To sum it up, it'll freeze the user's browser until the server returns the response and create a very bad user experience. Here is another short summary taken from MDN on why:XMLHttpRequest supports both synchronous and asynchronous communications. In general, however, asynchronous requests should be preferred to synchronous requests for performance reasons.In short, synchronous requests block the execution of code... ...this can cause serious issues...If you have to do it, you can pass a flag. Here is how:Let your function accept a callback. In the example code foo can be made to accept a callback. We'll be telling our code how to react when foo completes.So:Becomes:Here we passed an anonymous function, but we could just as easily pass a reference to an existing function, making it look like:For more details on how this sort of callback design is done, check Felix's answer.Now, let's define foo itself to act accordingly(fiddle)We have now made our foo function accept an action to run when the AJAX completes successfully. We can extend this further by checking if the response status is not 200 and acting accordingly (create a fail handler and such). Effectively it is solving our issue.If you're still having a hard time understanding this, read the AJAX getting started guide at MDN.",
                "XMLHttpRequest 2 (first of all, read the answers from Benjamin Gruenbaum and Felix Kling)If you don't use jQuery and want a nice short XMLHttpRequest 2 which works in the modern browsers and also in the mobile browsers, I suggest to use it this way:As you can see:There are two ways to get the response of this Ajax call (three using the XMLHttpRequest var name):The simplest:Or if for some reason you bind() the callback to a class:Example:Or (the above one is better anonymous functions are always a problem):Nothing easier.Now some people will probably say that it's better to use onreadystatechange or the even the XMLHttpRequest variable name. That's wrong.Check out XMLHttpRequest advanced features.It supported all *modern browsers. And I can confirm as I have been using this approach since XMLHttpRequest 2 was created. I never had any type of problem in any browsers I used.onreadystatechange is only useful if you want to get the headers on state 2.Using the XMLHttpRequest variable name is another big error as you need to execute the callback inside the onload/oreadystatechange closures, or else you lost it.Now if you want something more complex using POST and FormData you can easily extend this function:Again ... it's a very short function, but it does GET and POST.Examples of usage:Or pass a full form element (document.getElementsByTagName('form')[0]):Or set some custom values:As you can see, I didn't implement sync... it's a bad thing.Having said that ... why don't we do it the easy way?As mentioned in the comment, the use of error && synchronous does completely break the point of the answer. Which is a nice short way to use Ajax in the proper way?Error handlerIn the above script, you have an error handler which is statically defined, so it does not compromise the function. The error handler can be used for other functions too.But to really get out an error, the only way is to write a wrong URL in which case every browser throws an error.Error handlers are maybe useful if you set custom headers, set the responseType to blob array buffer, or whatever...Even if you pass 'POSTAPAPAP' as the method it won't throw an error.Even if you pass 'fdggdgilfdghfldj' as formdata it won't throw an error.In the first case the error is inside the displayAjax() under this.statusText as Method not Allowed.In the second case, it simply works. You have to check at the server side if you passed the right post data.Cross-domain not allowed throws an error automatically.In the error response, there aren't any error codes.There is only the this.type which is set to error.Why add an error handler if you totally don't have any control over errors?\nMost of the errors are returned inside this in the callback function displayAjax().So: There isn't any need for error checks if you're able to copy and paste the URL properly. ;)PS: As the first test I wrote x('x', displayAjax)..., and it totally got a response...??? So I checked the folder where the HTML is located, and there was a file called 'x.xml'. So even if you forget the extension of your file XMLHttpRequest 2 WILL FIND IT. I LOL'dRead a file synchronousDon't do that.If you want to block the browser for a while load a nice big .txt file synchronous.Now you can doThere is no other way to do this in a non-asynchronous way. (Yeah, with setTimeout loop... but seriously?)Another point is... if you work with APIs or just your own list's files or whatever you always use different functions for each request...Only if you have a page where you load always the same XML/JSON or whatever you need only one function. In that case, modify a little the Ajax function and replace b with your special function.The functions above are for basic use.If you want to extend the function...Yes, you can.I'm using a lot of APIs and one of the first functions I integrate into every HTML page is the first Ajax function in this answer, with GET only...But you can do a lot of stuff with XMLHttpRequest 2:I made a download manager (using ranges on both sides with resume, filereader, and filesystem), various image resizers converters using canvas, populate web SQL databases with base64images and much more...But in these cases you should create a function only for that purpose... sometimes you need a blob, array buffers, you can set headers, override mimetype and there is a lot more...But the question here is how to return an Ajax response... (I added an easy way.)",
                "This means AngularJS, jQuery (with deferred), native XHR's replacement (fetch), Ember.js, Backbone.js's save or any Node.js library that returns promises.Your code should be something along the lines of this:Felix Kling did a fine job writing an answer for people using jQuery with callbacks for Ajax. I have an answer for native XHR. This answer is for generic usage of promises either on the frontend or backend.The JavaScript concurrency model in the browser and on the server with Node.js/io.js is asynchronous and reactive.Whenever you call a method that returns a promise, the then handlers are always executed asynchronously - that is, after the code below them that is not in a .then handler.This means when you're returning data the then handler you've defined did not execute yet. This in turn means that the value you're returning has not been set to the correct value in time.Here is a simple analogy for the issue:function getFive(){\n        var data;\n        setTimeout(function(){ // Set a timer for one second in the future\n           data = 5; // After a second, do this\n        }, 1000);\n        return data;\n    }\n    document.body.innerHTML = getFive(); // `undefined` here and not 5The value of data is undefined since the data = 5 part has not executed yet. It will likely execute in a second, but by that time it is irrelevant to the returned value.Since the operation did not happen yet (Ajax, server call, I/O, and timer) you're returning the value before the request got the chance to tell your code what that value is.One possible solution to this problem is to code re-actively, telling your program what to do when the calculation completed. Promises actively enable this by being temporal (time-sensitive) in nature.A Promise is a value over time. Promises have state. They start as pending with no value and can settle to:A promise can only change states once after which it will always stay at the same state forever. You can attach then handlers to promises to extract their value and handle errors. then handlers allow chaining of calls. Promises are created by using APIs that return them. For example, the more modern Ajax replacement fetch or jQuery's $.get return promises.When we call .then on a promise and return something from it - we get a promise for the processed value. If we return another promise we'll get amazing things, but let's hold our horses.Let's see how we can solve the above issue with promises. First, let's demonstrate our understanding of promise states from above by using the Promise constructor for creating a delay function:Now, after we converted setTimeout to use promises, we can use then to make it count:function delay(ms){ // Takes amount of milliseconds\n  // Returns a new promise\n  return new Promise(function(resolve, reject){\n    setTimeout(function(){ // When the time is up,\n      resolve(); // change the promise to the fulfilled state\n    }, ms);\n  });\n}\n\nfunction getFive(){\n  // We're RETURNING the promise. Remember, a promise is a wrapper over our value\n  return delay(100).then(function(){ // When the promise is ready,\n      return 5; // return the value 5. Promises are all about return values\n  })\n}\n// We _have_ to wrap it like this in the call site, and we can't access the plain value\ngetFive().then(function(five){\n   document.body.innerHTML = five;\n});Basically, instead of returning a value which we can't do because of the concurrency model - we're returning a wrapper for a value that we can unwrap with then. It's like a box you can open with then.This stands the same for your original API call, you can:So this works just as well. We've learned we can't return values from already asynchronous calls, but we can use promises and chain them to perform processing. We now know how to return the response from an asynchronous call.ES6 introduces generators which are functions that can return in the middle and then resume the point they were at. This is typically useful for sequences, for example:Is a function that returns an iterator over the sequence 1,2,3,3,3,3,.... which can be iterated. While this is interesting on its own and opens room for a lot of possibility, there is one particular interesting case.If the sequence we're producing is a sequence of actions rather than numbers - we can pause the function whenever an action is yielded and wait for it before we resume the function. So instead of a sequence of numbers, we need a sequence of future values - that is: promises.This somewhat a tricky, but very powerful trick let\u2019s us write asynchronous code in a synchronous manner. There are several \"runners\" that do this for you. Writing one is a short few lines of code, but it is beyond the scope of this answer. I'll be using Bluebird's Promise.coroutine here, but there are other wrappers like co or Q.async.This method returns a promise itself, which we can consume from other coroutines. For example:In ES7, this is further standardized. There are several proposals right now, but in all of them you can await promise. This is just \"sugar\" (nicer syntax) for the ES6 proposal above by adding the async and await keywords. Making the above example:It still returns a promise just the same :)",
                "You are using Ajax incorrectly. The idea is not to have it return anything, but instead hand off the data to something called a callback function, which handles the data.That is:Returning anything in the submit handler will not do anything. You must instead either hand off the data, or do what you want with it directly inside the success function.",
                "I will answer with a horrible-looking, hand-drawn comic. The second image is the reason why result is undefined in your code example.",
                "The simplest solution is to create a JavaScript function and call it for the Ajax success callback.",
                "People who are using AngularJS, can handle this situation using promises.Here it says,Promises can be used to unnest asynchronous functions and allows one to chain multiple functions together.You can find a nice explanation here also.An example found in documentation mentioned below.In Angular 2 with look at the following example, but its recommended to use observables with Angular 2.You can consume that in this way,See the original post here. But TypeScript does not support native ES6 Promises, if you want to use it, you might need plugin for that.Additionally, here is the promises specification.",
                "Most of the answers here give useful suggestions for when you have a single async operation, but sometimes, this comes up when you need to do an asynchronous operation for each entry in an array or other list-like structure. The temptation is to do this:Example:// WRONG\nvar theArray = [1, 2, 3];\nvar results = [];\ntheArray.forEach(function(entry) {\n    doSomethingAsync(entry, function(result) {\n        results.push(result);\n    });\n});\nconsole.log(\"Results:\", results); // E.g., using them, returning them, etc.\n\nfunction doSomethingAsync(value, callback) {\n    console.log(\"Starting async operation for \" + value);\n    setTimeout(function() {\n        console.log(\"Completing async operation for \" + value);\n        callback(value * 2);\n    }, Math.floor(Math.random() * 200));\n}\n.as-console-wrapper { max-height: 100% !important; }The reason that doesn't work is that the callbacks from doSomethingAsync haven't run yet by the time you're trying to use the results.So, if you have an array (or list of some kind) and want to do async operations for each entry, you have two options: Do the operations in parallel (overlapping), or in series (one after another in sequence).You can start all of them and keep track of how many callbacks you're expecting, and then use the results when you've gotten that many callbacks:Example:var theArray = [1, 2, 3];\nvar results = [];\nvar expecting = theArray.length;\ntheArray.forEach(function(entry, index) {\n    doSomethingAsync(entry, function(result) {\n        results[index] = result;\n        if (--expecting === 0) {\n            // Done!\n            console.log(\"Results:\", JSON.stringify(results)); // E.g., using the results\n        }\n    });\n});\n\nfunction doSomethingAsync(value, callback) {\n    console.log(\"Starting async operation for \" + value);\n    setTimeout(function() {\n        console.log(\"Completing async operation for \" + value);\n        callback(value * 2);\n    }, Math.floor(Math.random() * 200));\n}\n.as-console-wrapper { max-height: 100% !important; }(We could do away with expecting and just use results.length === theArray.length, but that leaves us open to the possibility that theArray is changed while the calls are outstanding...)Notice how we use the index from forEach to save the result in results in the same position as the entry it relates to, even if the results arrive out of order (since async calls don't necessarily complete in the order in which they were started).But what if you need to return those results from a function? As the other answers have pointed out, you can't; you have to have your function accept and call a callback (or return a Promise). Here's a callback version:Example:function doSomethingWith(theArray, callback) {\n    var results = [];\n    var expecting = theArray.length;\n    theArray.forEach(function(entry, index) {\n        doSomethingAsync(entry, function(result) {\n            results[index] = result;\n            if (--expecting === 0) {\n                // Done!\n                callback(results);\n            }\n        });\n    });\n}\ndoSomethingWith([1, 2, 3], function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value, callback) {\n    console.log(\"Starting async operation for \" + value);\n    setTimeout(function() {\n        console.log(\"Completing async operation for \" + value);\n        callback(value * 2);\n    }, Math.floor(Math.random() * 200));\n}\n.as-console-wrapper { max-height: 100% !important; }Or here's a version returning a Promise instead:Of course, if doSomethingAsync passed us errors, we'd use reject to reject the promise when we got an error.)Example:function doSomethingWith(theArray) {\n    return new Promise(function(resolve) {\n        var results = [];\n        var expecting = theArray.length;\n        theArray.forEach(function(entry, index) {\n            doSomethingAsync(entry, function(result) {\n                results[index] = result;\n                if (--expecting === 0) {\n                    // Done!\n                    resolve(results);\n                }\n            });\n        });\n    });\n}\ndoSomethingWith([1, 2, 3]).then(function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value, callback) {\n    console.log(\"Starting async operation for \" + value);\n    setTimeout(function() {\n        console.log(\"Completing async operation for \" + value);\n        callback(value * 2);\n    }, Math.floor(Math.random() * 200));\n}\n.as-console-wrapper { max-height: 100% !important; }(Or alternately, you could make a wrapper for doSomethingAsync that returns a promise, and then do the below...)If doSomethingAsync gives you a Promise, you can use Promise.all:If you know that doSomethingAsync will ignore a second and third argument, you can just pass it directly to map (map calls its callback with three arguments, but most people only use the first most of the time):Example:function doSomethingWith(theArray) {\n    return Promise.all(theArray.map(doSomethingAsync));\n}\ndoSomethingWith([1, 2, 3]).then(function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value) {\n    console.log(\"Starting async operation for \" + value);\n    return new Promise(function(resolve) {\n        setTimeout(function() {\n            console.log(\"Completing async operation for \" + value);\n            resolve(value * 2);\n        }, Math.floor(Math.random() * 200));\n    });\n}\n.as-console-wrapper { max-height: 100% !important; }Note that Promise.all resolves its promise with an array of the results of all of the promises you give it when they are all resolved, or rejects its promise when the first of the promises you give it rejects.Suppose you don't want the operations to be in parallel? If you want to run them one after another, you need to wait for each operation to complete before you start the next. Here's an example of a function that does that and calls a callback with the result:(Since we're doing the work in series, we can just use results.push(result) since we know we won't get results out of order. In the above we could have used results[index] = result;, but in some of the following examples we don't have an index to use.)Example:function doSomethingWith(theArray, callback) {\n    var results = [];\n    doOne(0);\n    function doOne(index) {\n        if (index < theArray.length) {\n            doSomethingAsync(theArray[index], function(result) {\n                results.push(result);\n                doOne(index + 1);\n            });\n        } else {\n            // Done!\n            callback(results);\n        }\n    }\n}\ndoSomethingWith([1, 2, 3], function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value, callback) {\n    console.log(\"Starting async operation for \" + value);\n    setTimeout(function() {\n        console.log(\"Completing async operation for \" + value);\n        callback(value * 2);\n    }, Math.floor(Math.random() * 200));\n}\n.as-console-wrapper { max-height: 100% !important; }(Or, again, build a wrapper for doSomethingAsync that gives you a promise and do the below...)If doSomethingAsync gives you a Promise, if you can use ES2017+ syntax (perhaps with a transpiler like Babel), you can use an async function with for-of and await:Example:async function doSomethingWith(theArray) {\n    const results = [];\n    for (const entry of theArray) {\n        results.push(await doSomethingAsync(entry));\n    }\n    return results;\n}\ndoSomethingWith([1, 2, 3]).then(function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value) {\n    console.log(\"Starting async operation for \" + value);\n    return new Promise(function(resolve) {\n        setTimeout(function() {\n            console.log(\"Completing async operation for \" + value);\n            resolve(value * 2);\n        }, Math.floor(Math.random() * 200));\n    });\n}\n.as-console-wrapper { max-height: 100% !important; }If you can't use ES2017+ syntax (yet), you can use a variation on the \"Promise reduce\" pattern (this is more complex than the usual Promise reduce because we're not passing the result from one into the next, but instead gathering up their results in an array):Example:function doSomethingWith(theArray) {\n    return theArray.reduce(function(p, entry) {\n        return p.then(function(results) {\n            return doSomethingAsync(entry).then(function(result) {\n                results.push(result);\n                return results;\n            });\n        });\n    }, Promise.resolve([]));\n}\ndoSomethingWith([1, 2, 3]).then(function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value) {\n    console.log(\"Starting async operation for \" + value);\n    return new Promise(function(resolve) {\n        setTimeout(function() {\n            console.log(\"Completing async operation for \" + value);\n            resolve(value * 2);\n        }, Math.floor(Math.random() * 200));\n    });\n}\n.as-console-wrapper { max-height: 100% !important; }...which is less cumbersome with ES2015+ arrow functions:Example:function doSomethingWith(theArray) {\n    return theArray.reduce((p, entry) => p.then(results => doSomethingAsync(entry).then(result => {\n        results.push(result);\n        return results;\n    })), Promise.resolve([]));\n}\ndoSomethingWith([1, 2, 3]).then(function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value) {\n    console.log(\"Starting async operation for \" + value);\n    return new Promise(function(resolve) {\n        setTimeout(function() {\n            console.log(\"Completing async operation for \" + value);\n            resolve(value * 2);\n        }, Math.floor(Math.random() * 200));\n    });\n}\n.as-console-wrapper { max-height: 100% !important; }",
                "Have a look at this example:As you can see getJoke is returning a resolved promise (it is resolved when returning res.data.value). So you wait until the $http.get request is completed and then console.log(res.joke) is executed (as a normal asynchronous flow).This is the plnkr:http://embed.plnkr.co/XlNR7HpCaIhJxskMJfSg/ES6 way (async - await)",
                "This is one of the places which two-way data binding or store concept that's used in many new JavaScript frameworks will work great for you...So if you are using Angular, React, or any other frameworks which do two-way data binding or store concept, this issue is simply fixed for you, so in easy words, your result is undefined at the first stage, so you have got result = undefined before you receive the data, then as soon as you get the result, it will be updated and get assigned to the new value which response of your Ajax call...But how you can do it in pure JavaScript or jQuery for example as you asked in this question?You can use a callback, promise and recently observable to handle it for you. For example, in promises we have some function like success() or then() which will be executed when your data is ready for you. The same with callback or the subscribe function on an observable.For example, in your case which you are using jQuery, you can do something like this:For more information, study promises and observables which are newer ways to do this async stuff.",
                "It's a very common issue we face while struggling with the 'mysteries' of JavaScript. Let me try demystifying this mystery today.Let's start with a simple JavaScript function:That's a simple synchronous function call (where each line of code is 'finished with its job' before the next one in sequence), and the result is same as expected.Now let's add a bit of twist, by introducing a little delay in our function, so that all lines of code are not 'finished' in sequence. Thus, it will emulate the asynchronous behavior of the function:So there you go; that delay just broke the functionality we expected! But what exactly happened? Well, it's actually pretty logical if you look at the code.The function foo(), upon execution, returns nothing (thus returned value is undefined), but it does start a timer, which executes a function after 1 second to return 'wohoo'. But as you can see, the value that's assigned to bar is the immediately returned stuff from foo(), which is nothing, i.e., just undefined.So, how do we tackle this issue?Let's ask our function for a promise.\nPromise is really about what it means: it means that the function guarantees you to provide with any output it gets in future. So let's see it in action for our little problem above:Thus, the summary is - to tackle the asynchronous functions like Ajax-based calls, etc., you can use a promise to resolve the value (which you intend to return). Thus, in short you resolve value instead of returning, in asynchronous functions.Apart from using then/catch to work with promises, there exists one more approach. The idea is to recognize an asynchronous function and then wait for the promises to resolve, before moving to the next line of code. It's still just the promises under the hood, but with a different syntactical approach. To make things clearer, you can find a comparison below:",
                "Another approach to return a value from an asynchronous function, is to pass in an object that will store the result from the asynchronous function.Here is an example of the same:I am using the result object to store the value during the asynchronous operation. This allows the result be available even after the asynchronous job.I use this approach a lot. I would be interested to know how well this approach works where wiring the result back through consecutive modules is involved.",
                "While promises and callbacks work fine in many situations, it is a pain in the rear to express something like:You'd end up going through async1; check if name is undefined or not and call the callback accordingly.While it is okay in small examples it gets annoying when you have a lot of similar cases and error handling involved.Fibers helps in solving the issue.You can checkout the project here.",
                "The following example I have written shows how toThis working example is self-contained. It will define a simple request object that uses the window XMLHttpRequest object to make calls. It will define a simple function to wait for a bunch of promises to be completed.Context. The example is querying the Spotify Web API endpoint in order to search for playlist objects for a given set of query strings:For each item, a new Promise will fire a block - ExecutionBlock, parse the result, schedule a new set of promises based on the result array, that is a list of Spotify user objects and execute the new HTTP call within the ExecutionProfileBlock asynchronously.You can then see a nested Promise structure, that lets you spawn multiple and completely asynchronous nested HTTP calls, and join the results from each subset of calls through Promise.all.NOTE\nRecent Spotify search APIs will require an access token to be specified in the request headers:So, you to run the following example you need to put your access token in the request headers:var spotifyAccessToken = \"YourSpotifyAccessToken\";\r\nvar console = {\r\n    log: function(s) {\r\n        document.getElementById(\"console\").innerHTML += s + \"<br/>\"\r\n    }\r\n}\r\n\r\n// Simple XMLHttpRequest\r\n// based on https://davidwalsh.name/xmlhttprequest\r\nSimpleRequest = {\r\n    call: function(what, response) {\r\n        var request;\r\n        if (window.XMLHttpRequest) { // Mozilla, Safari, ...\r\n            request = new XMLHttpRequest();\r\n        } else if (window.ActiveXObject) { // Internet Explorer\r\n            try {\r\n                request = new ActiveXObject('Msxml2.XMLHTTP');\r\n            }\r\n            catch (e) {\r\n                try {\r\n                  request = new ActiveXObject('Microsoft.XMLHTTP');\r\n                } catch (e) {}\r\n            }\r\n        }\r\n\r\n        // State changes\r\n        request.onreadystatechange = function() {\r\n            if (request.readyState === 4) { // Done\r\n                if (request.status === 200) { // Complete\r\n                    response(request.responseText)\r\n                }\r\n                else\r\n                    response();\r\n            }\r\n        }\r\n        request.open('GET', what, true);\r\n        request.setRequestHeader(\"Authorization\", \"Bearer \" + spotifyAccessToken);\r\n        request.send(null);\r\n    }\r\n}\r\n\r\n//PromiseAll\r\nvar promiseAll = function(items, block, done, fail) {\r\n    var self = this;\r\n    var promises = [],\r\n                   index = 0;\r\n    items.forEach(function(item) {\r\n        promises.push(function(item, i) {\r\n            return new Promise(function(resolve, reject) {\r\n                if (block) {\r\n                    block.apply(this, [item, index, resolve, reject]);\r\n                }\r\n            });\r\n        }(item, ++index))\r\n    });\r\n    Promise.all(promises).then(function AcceptHandler(results) {\r\n        if (done) done(results);\r\n    }, function ErrorHandler(error) {\r\n        if (fail) fail(error);\r\n    });\r\n}; //promiseAll\r\n\r\n// LP: deferred execution block\r\nvar ExecutionBlock = function(item, index, resolve, reject) {\r\n    var url = \"https://api.spotify.com/v1/\"\r\n    url += item;\r\n    console.log( url )\r\n    SimpleRequest.call(url, function(result) {\r\n        if (result) {\r\n\r\n            var profileUrls = JSON.parse(result).playlists.items.map(function(item, index) {\r\n                return item.owner.href;\r\n            })\r\n            resolve(profileUrls);\r\n        }\r\n        else {\r\n            reject(new Error(\"call error\"));\r\n        }\r\n    })\r\n}\r\n\r\narr = [\r\n    \"search?type=playlist&q=%22doom%20metal%22\",\r\n    \"search?type=playlist&q=Adele\"\r\n]\r\n\r\npromiseAll(arr, function(item, index, resolve, reject) {\r\n    console.log(\"Making request [\" + index + \"]\")\r\n    ExecutionBlock(item, index, resolve, reject);\r\n}, function(results) { // Aggregated results\r\n\r\n    console.log(\"All profiles received \" + results.length);\r\n    //console.log(JSON.stringify(results[0], null, 2));\r\n\r\n    ///// promiseall again\r\n\r\n    var ExecutionProfileBlock = function(item, index, resolve, reject) {\r\n        SimpleRequest.call(item, function(result) {\r\n            if (result) {\r\n                var obj = JSON.parse(result);\r\n                resolve({\r\n                    name: obj.display_name,\r\n                    followers: obj.followers.total,\r\n                    url: obj.href\r\n                });\r\n            } //result\r\n        })\r\n    } //ExecutionProfileBlock\r\n\r\n    promiseAll(results[0], function(item, index, resolve, reject) {\r\n        //console.log(\"Making request [\" + index + \"] \" + item)\r\n        ExecutionProfileBlock(item, index, resolve, reject);\r\n    }, function(results) { // aggregated results\r\n        console.log(\"All response received \" + results.length);\r\n        console.log(JSON.stringify(results, null, 2));\r\n    }\r\n\r\n    , function(error) { // Error\r\n        console.log(error);\r\n    })\r\n\r\n    /////\r\n\r\n  },\r\n  function(error) { // Error\r\n      console.log(error);\r\n  });\n<div id=\"console\" />I have extensively discussed this solution here.",
                "The short answer is, you have to implement a callback like this:",
                "JavaScript is single threaded.The browser can be divided into three parts:Event LoopWeb APIEvent QueueThe event loop runs for forever, i.e., kind of an infinite loop. The event queue is where all your functions are pushed on some event (example: click).This is one by one carried out of queue and put into the event loop which executes this function and prepares itself for the next one after the first one is executed. This means execution of one function doesn't start until the function before it in the queue is executed in the event loop.Now let us think we pushed two functions in a queue. One is for getting a data from the server and another utilises that data. We pushed the serverRequest() function in the queue first and then the utiliseData() function. The serverRequest function goes in the event loop and makes a call to server as we never know how much time it will take to get data from server, so this process is expected to take time and so we busy our event loop thus hanging our page.That's where Web API come into the role. It takes this function from the event loop and deals with the server making the event loop free, so that we can execute the next function from the queue.The next function in the queue is utiliseData() which goes in the loop, but because of no data available, it goes to waste and execution of the next function continues until the end of the queue. (This is called Async calling, i.e., we can do something else until we get data.)Let us suppose our serverRequest() function had a return statement in code. When we get back data from the server Web API, it will push it in the queue at the end of queue.As it gets pushed at the end of the queue, we cannot utilise its data as there isn't any function left in our queue to utilise this data. Thus it is not possible to return something from the async call.Thus the solution to this is callback or promise.We give our function (function utilising data returned from the server) to a function calling the server.In my code it is called as:JavaScript.info callback",
                "This is quite simple:Here's a working version of your code:await is supported in all current browsers and Node.js 8",
                "You can use this custom library (written using Promise) to make a remote call.Simple usage example:",
                "Another solution is to execute code via the sequential executor nsynjs.nsynjs will evaluate all promises sequentially, and put the promise result into the data property:function synchronousCode() {\n\n    var getURL = function(url) {\n        return window.fetch(url).data.text().data;\n    };\n    \n    var url = 'https://ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min.js';\n    console.log('received bytes:',getURL(url).length);\n    \n};\n\nnsynjs.run(synchronousCode,{},function(){\n    console.log('synchronousCode done');\n});\n<script src=\"https://rawgit.com/amaksr/nsynjs/master/nsynjs.js\"></script>Step 1. Wrap the function with a callback into the nsynjs-aware wrapper (if it has a promisified version, you can skip this step):Step 2. Put synchronous logic into function:Step 3. Run function in synchronous manner via nsynjs:Nsynjs will evaluate all operators and expressions step-by-step, pausing execution in case if the result of some slow function is not ready.More examples are here.",
                "ECMAScript 6 has 'generators' which allow you to easily program in an asynchronous style.To run the above code you do this:If you need to target browsers that don't support ES6 you can run the code through Babel or closure-compiler to generate ECMAScript 5.The callback ...args are wrapped in an array and destructured when you read them so that the pattern can cope with callbacks that have multiple arguments. For example with node fs:",
                "We find ourselves in a universe which appears to progress along a dimension we call \"time\". We don't really understand what time is, but we have developed abstractions and vocabulary that let us reason and talk about it: \"past\", \"present\", \"future\", \"before\", \"after\".The computer systems we build--more and more--have time as an important dimension. Certain things are set up to happen in the future. Then other things need to happen after those first things eventually occur. This is the basic notion called \"asynchronicity\". In our increasingly networked world, the most common case of asynchronicity is waiting for some remote system to respond to some request.Consider an example. You call the milkman and order some milk. When it comes, you want to put it in your coffee. You can't put the milk in your coffee right now, because it is not here yet. You have to wait for it to come before putting it in your coffee. In other words, the following won't work:Because JavaScript has no way to know that it needs to wait for order_milk to finish before it executes put_in_coffee. In other words, it does not know that order_milk is asynchronous--is something that is not going to result in milk until some future time. JavaScript, and other declarative languages execute one statement after another without waiting.The classic JavaScript approach to this problem, taking advantage of the fact that JavaScript supports functions as first-class objects which can be passed around, is to pass a function as a parameter to the asynchronous request, which it will then invoke when it has completed its task sometime in the future. That is the \"callback\" approach. It looks like this:order_milk kicks off, orders the milk, then, when and only when it arrives, it invokes put_in_coffee.The problem with this callback approach is that it pollutes the normal semantics of a function reporting its result with return; instead, functions must not reports their results by calling a callback given as a parameter. Also, this approach can rapidly become unwieldy when dealing with longer sequences of events. For example, let's say that I want to wait for the milk to be put in the coffee, and then and only then perform a third step, namely drinking the coffee. I end up needing to write something like this:where I am passing to put_in_coffee both the milk to put in it, and also the action (drink_coffee) to execute once the milk has been put in. Such code becomes hard to write, and read, and debug.In this case, we could rewrite the code in the question as:This was the motivation for the notion of a \"promise\", which is a particular type of value which represents a future or asynchronous outcome of some sort. It can represent something that already happened, or that is going to happen in the future, or might never happen at all. Promises have a single method, named then, to which you pass an action to be executed when the outcome the promise represents has been realized.In the case of our milk and coffee, we design order_milk to return a promise for the milk arriving, then specify put_in_coffee as a then action, as follows:One advantage of this is that we can string these together to create sequences of future occurrences (\"chaining\"):Let's apply promises to your particular problem. We will wrap our request logic inside a function, which returns a promise:Actually, all we've done is added a return to the call to $.ajax. This works because jQuery's $.ajax already returns a kind of promise-like thing. (In practice, without getting into details, we would prefer to wrap this call so as for return a real promise, or use some alternative to $.ajax that does so.) Now, if we want to load the file and wait for it to finish and then do something, we can simply sayfor instance,When using promises, we end up passing lots of functions into then, so it's often helpful to use the more compact ES6-style arrow functions:But there's still something vaguely dissatisfying about having to write code one way if synchronous and a quite different way if asynchronous. For synchronous, we writebut if a is asynchronous, with promises we have to writeAbove, we said, \"JavaScript has no way to know that it needs to wait for the first call to finish before it executes the second\". Wouldn't it be nice if there was some way to tell JavaScript that? It turns out that there is--the await keyword, used inside a special type of function called an \"async\" function. This feature is part of the upcoming version of ECMAScript (ES), but it is already available in transpilers such as Babel given the right presets. This allows us to simply writeIn your case, you would be able to write something like",
                "Short answer: Your foo() method returns immediately, while the $ajax() call executes asynchronously after the function returns. The problem is then how or where to store the results retrieved by the async call once it returns.Several solutions have been given in this thread. Perhaps the easiest way is to pass an object to the foo() method, and to store the results in a member of that object after the async call completes.Note that the call to foo() will still return nothing useful. However, the result of the async call will now be stored in result.response.",
                "var App = App || {};\n\nApp = {\n    getDataFromServer: function(){\n\n      var self = this,\n                 deferred = $.Deferred(),\n                 requests = [];\n\n      requests.push($.getJSON('request/ajax/url/1'));\n      requests.push($.getJSON('request/ajax/url/2'));\n\n      $.when.apply(jQuery, requests).done(function(xhrResponse) {\n        return deferred.resolve(xhrResponse.result);\n      });\n      return deferred;\n    },\n\n    init: function(){\n\n        this.getDataFromServer().done(_.bind(function(resp1, resp2) {\n\n           // Do the operations which you wanted to do when you\n           // get a response from Ajax, for example, log response.\n        }, this));\n    }\n};\nApp.init();",
                "As for many others, my encounter with asynchronous calls was puzzling at\nfirst.\nI don't remember the details, but I may have tried something like:let result;\n\n$.ajax({\n  url: 'https://jsonplaceholder.typicode.com/todos/1',\n  success: function (response) {\n    console.log('\\nInside $.ajax:');\n    console.log(response);\n    result = response;\n  }\n});\n\nconsole.log('Finally, the result: ' + result);\n.as-console-wrapper { max-height: 100% !important; top: 0; }\n<script src=\n\"https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js\"></script>Whoops! The output of the line\nconsole.log('Finally, the result: ' + result);\nwhich I thought would be printed last, is actually printed before the\nother output! \u2013 And it doesn't contain the result: it just prints undefined.\n1\nHow come?A helpful insightI distinctly remember my first aha! moment on how to understand asynchronous\ncalls.\nIt was this comment saying:\nyou actually don't want to get the data out of a callback;\nyou want to get your data-needing action into the callback!\n2\nThis is obvious in the example above.\nBut is it still possible to write code after the asynchronous call that\ndeals with the response once it has completed?The answer is yes! \u2013 It is possible.\nOne alternative is the use of a callback function in a continuation-passing\nstyle:\n3const url = 'https://jsonplaceholder.typicode.com/todos/2';\n\nfunction asynchronousCall (callback) {\n  const request = new XMLHttpRequest();\n  request.open('GET', url);\n  request.send();\n  request.onload = function () {\n    if (request.readyState === request.DONE) {\n      console.log('The request is done. Now calling back.');\n      callback(request.responseText);\n    }\n  };\n}\n\nasynchronousCall(function (result) {\n  console.log('This is the start of the callback function. Result:');\n  console.log(result);\n  console.log('The callback function finishes on this line. THE END!');\n});\n\nconsole.log('LAST in the code, but executed FIRST!');\n.as-console-wrapper { max-height: 100% !important; top: 0; }Note how the function asynchronousCall is void. It returns nothing.\nInstead, by calling asynchronousCall with an anonymous callback function\n(asynchronousCall(function (result) {...), this function executes the\ndesired actions on the result, but only after the request has completed \u2013\nwhen the responseText is available.Running the above snippet shows how I will probably not want to write any code\nafter the asyncronous call (such as the line\nLAST in the code, but executed FIRST!).\nWhy? \u2013 Because such code will\nhappen before the asyncronous call delivers any response data.\nDoing so is bound to cause confusion when comparing the code with the output.The .then() construct was introduced in the ECMA-262 6th Edition in June\n2015, and the async/await construct was introduced in the ECMA-262\n8th Edition in June 2017.\nThe code below is still plain JavaScript, replacing the old-school\nXMLHttpRequest with Fetch.\n4fetch('http://api.icndb.com/jokes/random')\n  .then(response => response.json())\n  .then(responseBody => {\n    console.log('.then() - the response body:');\n    console.log(JSON.stringify(responseBody) + '\\n\\n');\n  });\n\nasync function receiveAndAwaitPromise () {\n  const responseBody =\n    (await fetch('http://api.icndb.com/jokes/random')).json();\n  console.log('async/await:');\n  console.log(JSON.stringify(await responseBody) + '\\n\\n');\n}\n\nreceiveAndAwaitPromise();\n.as-console-wrapper { max-height: 100% !important; top: 0; }A word of warning is warranted if you decide to go with the async/await\nconstruct. Note in the above snippet how await is needed in two places.\nIf forgotten in the first place, there will be no output. If forgotten in the\nsecond place, the only output will be the empty object, {}\n(or [object Object] or [object Promise]).\nForgetting the async prefix of the function is maybe the worst of all \u2013 the\noutput will be \"SyntaxError: missing ) in parenthetical\" \u2013 no mentioning of\nthe missing async keyword.Suppose we need to request a whole bunch of URLs.\nI could send one request, wait till it responds, then send the next request,\nwait till it responds, and so on ...\nAargh! \u2013 That could take a loong time. Wouldn't it be better if I could send\nthem all at once, and then wait no longer than it takes for the slowest\nresponse to arrive?As a simplified example, I will use:The JSONs of the two URLs:The goal is to get an array of objects, where each object contains the title\nvalue from the corresponding URL.To make it a little more interesting, I will assume that there is already an\narray of names that I want the array of URL results (the titles) to be\nmerged with:The desired output is a mashup combining namesonly and urls into an\narray of objects:where I have changed the name of title to loremipsum.const namesonly = ['two','three'];\n\nconst urls = ['https://jsonplaceholder.typicode.com/todos/2',\n  'https://jsonplaceholder.typicode.com/todos/3'];\n\nPromise.all(urls.map(url => fetch(url)\n  .then(response => response.json())\n  .then(responseBody => responseBody.title)))\n  .then(titles => {\n    const names = namesonly.map(value => ({ name: value }));\n    console.log('names: ' + JSON.stringify(names));\n    const latins = titles.map(value => ({ loremipsum: value }));\n    console.log('latins:\\n' + JSON.stringify(latins));\n    const result =\n      names.map((item, i) => Object.assign({}, item, latins[i]));\n    console.log('result:\\n' + JSON.stringify(result));\n  });\n.as-console-wrapper { max-height: 100% !important; top: 0; }All the above examples are short and succinctly convey how asynchronous calls\nmay be used on toyish APIs.\nUsing small APIs works well to explain concepts and working code, but the\nexamples might be a bit of dry runs.The next section will show a more realistic example on how APIs may be\ncombined to create a more interesting output.The MusicBrainz API\nhas information about artists and music bands.\nAn example \u2013 a request for the British rock band Coldplay is:\nhttp://musicbrainz.org/ws/2/artist/cc197bad-dc9c-440d-a5b5-d52ba2e14234?&fmt=json&inc=url-rels+release-groups.\nThe JSON response contains \u2013 among other things \u2013 the 25 earliest album titles\nby the band.\nThis information is in the release-groups array.\nThe start of this array, including its first object is:This JSON snippet shows that the first album by Coldplay is Parachutes.\nIt also gives an id, in this case 1dc4c347-a1db-32aa-b14f-bc9cc507b843,\nwhich is a unique identifier of the album.This identifier can be used to make a lookup in the Cover Art Archive API:\nhttp://coverartarchive.org/release-group/1dc4c347-a1db-32aa-b14f-bc9cc507b843.\n7For each album, the JSON response contains some images, one of which is the\nfront cover of the album.\nThe first few lines of the response to the above request:Of interest here is the line\n\"small\": \"http://coverartarchive.org/release/435fc965-9121-461e-b8da-d9b505c9dc9b/4086974851-250.jpg\".\nThat URL is a direct link to the front cover of the Parachutes album.The code to create and visualize the mashupThe overall task is to use Postman to visualize all the album titles and front\ncovers of a music band.\nHow to write code to achieve this has already been described in quite some\ndetail in  an answer to the question\nHow can I visualize an API mashup in Postman? \u2013 Therefore I will avoid\nlengthy discussions here and just present the code and a screenshot of the\nresult:The result and documentationHow to download and run the Postman CollectionRunning the Postman Collection should be straightforward.\nAssuming you are using the desktop version of Postman, do as follows:Download and save\nhttp://henke.atwebpages.com/postman/mbid/MusicBands.pm_coll.json\nin a suitable place on your hard drive.In Postman, Ctrl + O > Upload Files >\nMusicBands.pm_coll.json > Import.\nYou should now see MusicBands among your collections in Postman.Collections > MusicBands > DummyRequest > Send.\n8In the Postman Response Body, click Visualize.You should now be able to scroll 15 albums as indicated by the\nscreenshot above.1 Expressed by the original poster as: they all return\nundefined.\n2 If you think asynchronous calls are confusing, consider having a\nlook at some questions and answers about asynchronous calls to see if that helps.\n3 The name XMLHttpRequest is as misleading as the X in\nAJAX \u2013 these days the data format of Web APIs is ubiquitously JSON, not XML.\n4 Fetch\nreturns a Promise.\nI was surprised to learn that neither XMLHttpRequest nor Fetch are part of\nthe ECMAScript standard.\nThe reason JavaScript can access them here is because the web browser provides\nthem.\nThe Fetch Standard and\nthe XMLHttpRequest Standard are both upheld by\nthe Web Hypertext Application Technology Working Group (WHATWG) that was formed in June 2004.\n5 This section borrows a lot from\nHow can I fetch an array of URLs with Promise.all?.\n6 This section relies heavily on\nHow can I visualize an API mashup in Postman?.\n7 This URL is automatically redirected to:\nhttps://ia800503.us.archive.org/29/items/mbid-435fc965-9121-461e-b8da-d9b505c9dc9b/index.json.\n8 If you get an error,\nSomething went wrong while running your scripts,\ntry hitting Send again.",
                "Use a callback() function inside the foo() success.\nTry it in this way. It is simple and easy to understand.",
                "The most perfect answer to this question is using Promise.There is a problem with using promises!I was using this solution for a while until I figured out there is an error in old browsers:Uncaught ReferenceError: Promise is not definedSo I decided to implement my own Promise class for ES3 to below JavaScript compilers if it's not defined. Just add this code before your main code and then safely use Promise!",
                "Of course there are many approaches like synchronous request, promise, but from my experience I think you should use the callback approach. It's natural to asynchronous behavior of JavaScript.So, your code snippet can be rewritten to be a little different:",
                "The question was:How do I return the response from an asynchronous call?which can be interpreted as:How to make asynchronous code look synchronous?The solution will be to avoid callbacks, and use a combination of Promises and async/await.I would like to give an example for an Ajax request.(Although it can be written in JavaScript, I prefer to write it in Python, and compile it to JavaScript using Transcrypt. It will be clear enough.)Let\u2019s first enable jQuery usage, to have $ available as S:Define a function which returns a Promise, in this case an Ajax call:Use the asynchronous code as if it were synchronous:",
                "Rather than throwing code at you, there are two concepts that are key to understanding how JavaScript handles callbacks and asynchronicity (is that even a word?)There are three things you need to be aware of; The queue; the event loop and the stackIn broad, simplistic terms, the event loop is like the project manager, it is constantly listening for any functions that want to run and communicates between the queue and the stack.Once it receives a message to run something it adds it to the queue. The queue is the list of things that are waiting to execute (like your AJAX request). imagine it like this:When one of these messages is going to execute it pops the message from the queue and creates a stack, the stack is everything JavaScript needs to execute to perform the instruction in the message. So in our example it's being told to call foobarFuncSo anything that foobarFunc needs to execute (in our case anotherFunction) will get pushed onto the stack. executed, and then forgotten about - the event loop will then move onto the next thing in the queue (or listen for messages)The key thing here is the order of execution. That isWhen you make a call using AJAX to an external party or run any asynchronous code (a setTimeout for example), JavaScript is dependant upon a response before it can proceed.The big question is when will it get the response? The answer is we don't know - so the event loop is waiting for that message to say \"hey run me\". If JavaScript just waited around for that message synchronously your app would freeze and it will suck. So JavaScript carries on executing the next item in the queue whilst waiting for the message to get added back to the queue.That's why with asynchronous functionality we use things called callbacks. - A function or handler that, when passed into another function, will be executed at a later date. A promise uses callbacks (functions passed to .then() for example) as a way to reason about this asynchronous behaviour in a more linear way. The promise is a way of saying \"I promise to return something at some point\" and the callback is how we handle that value that is eventually returned. jQuery uses specific callbacks called deffered.done deffered.fail and deffered.always (amongst others). You can see them all hereSo what you need to do is pass a function that is promised to execute at some point with data that is passed to it.Because a callback is not executed immediately but at a later time it's important to pass the reference to the function not it executed. soso most of the time (but not always) you'll pass foo not foo()Hopefully that will make some sense. When you encounter things like this that seem confusing - i highly recommend reading the documentation fully to at least get an understanding of it. It will make you a much better developer."
            ]
        },
        {
            "tag": "android",
            "question": [
                "What is the difference between px, dip, dp, and sp?",
                "What is the difference between the units of measure\npx, dip, dp, and sp?"
            ],
            "url": "https://stackoverflow.com/questions/2025282",
            "answer": [
                "From the Android Developer Documentation:px\nPixels - corresponds to actual pixels on the screen.in\nInches - based on the physical size of the screen.\n1 Inch OR 2.54 centimetersmm\n> Millimeters - based on the physical size of the screen.pt\n> Points - 1/72 of an inch based on the physical size of the screen.dp or dip\n> Density-independent Pixels - an abstract unit that is based on the physical density of the screen. These units are relative to a 160\ndpi screen, so one dp is one pixel on a 160 dpi screen. The ratio of dp-to-pixel will change with the screen density, but not necessarily in direct proportion. Note: The compiler accepts both \"dip\" and \"dp\", though \"dp\" is more consistent with \"sp\".sp\n> Scaleable Pixels OR scale-independent pixels - this is like the dp unit, but it is also scaled by the user's font size preference. It is recommended you\nuse this unit when specifying font sizes, so they will be adjusted\nfor both the screen density and the user's preference. Note, the Android documentation is inconsistent on what sp actually stands for, one doc says \"scale-independent pixels\", the other says \"scaleable pixels\".From Understanding Density Independence In Android:More info can be also be found in the Google Design Documentation.",
                "Pretty much everything about this and how to achieve the best support for multiple screens of different sizes and densities is very well documented here:Screen size\nActual physical size, measured as the screen's diagonal.\nFor simplicity, Android groups all actual screen sizes into four\ngeneralized sizes: small, normal, large, and extra-large.Screen density\nThe number of pixels within a physical area of the\nscreen; usually referred to as dpi (dots per inch). For example, a\n\"low\" density screen has fewer pixels within a given physical area,\ncompared to a \"normal\" or \"high\" density screen. For simplicity,\nAndroid groups all actual screen densities into six generalized\ndensities: low, medium, high, extra-high, extra-extra-high, and\nextra-extra-extra-high.OrientationThe orientation of the screen from the user's point of\nview. This is either landscape or portrait, meaning that the screen's\naspect ratio is either wide or tall, respectively. Be aware that not\nonly do different devices operate in different orientations by\ndefault, but the orientation can change at runtime when the user\nrotates the device.Resolution The total number of physical pixels on\na screen. When adding support for multiple screens, applications do\nnot work directly with resolution; applications should be concerned\nonly with screen size and density, as specified by the generalized\nsize and density groups.Density-independent pixel (dp) A virtual\npixel unit that you should use when defining UI layout, to express\nlayout dimensions or position in a density-independent way.\nThe density-independent pixel is equivalent to one physical pixel on a 160\ndpi screen, which is the baseline density assumed by the system for a\n\"medium\" density screen. At runtime, the system transparently handles\nany scaling of the dp units, as necessary, based on the actual density\nof the screen in use. The conversion of dp units to screen pixels is\nsimple:\npx = dp * (dpi / 160).\nFor example, on a 240 dpi screen, 1 dp\nequals 1.5 physical pixels. You should always use dp units when\ndefining your application's UI, to ensure proper display of your UI on\nscreens with different densities.If you are at all serious about developing an Android app for more than one type of device, you should have read the screens support development document at least once. In addition to that, it is always a good thing to know the actual number of active devices that have a particular screen configuration.",
                "I will elaborate more on how exactly does dp convert to px:The other way around: say, you want to add an image to your application and you need it to fill a 100 * 100 dp control. You'll need to create different size images for supported screen sizes:",
                "Moreover you should have a clear understanding of the following concepts:Screen size:Actual physical size, measured as the screen's diagonal. For simplicity, Android groups all actual screen sizes into\nfour generalized sizes: small, normal, large, and extra-large.Screen density:The number of pixels within a physical area of the screen; usually referred to as dpi (dots per inch). For example, a\n\"low\" density screen has fewer pixels within a given physical area,\ncompared to a \"normal\" or \"high\" density screen. For simplicity,\nAndroid groups all actual screen densities into four generalized\ndensities: low, medium, high, and extra high.Orientation:The orientation of the screen from the user's point of view. This is either landscape or portrait, meaning that the\nscreen's aspect ratio is either wide or tall, respectively. Be aware\nthat not only do different devices operate in different orientations\nby default, but the orientation can change at runtime when the user\nrotates the device.Resolution:The total number of physical pixels on a screen. When adding support for multiple screens, applications do not work directly\nwith resolution; applications should be concerned only with screen\nsize and density, as specified by the generalized size and density\ngroups.Density-independent pixel (dp):A virtual pixel unit that you should use when defining UI layout, to express layout dimensions or\nposition in a density-independent way. The density-independent pixel\nis equivalent to one physical pixel on a 160 dpi screen, which is the\nbaseline density assumed by the system for a \"medium\" density screen.\nAt runtime, the system transparently handles any scaling of the dp\nunits, as necessary, based on the actual density of the screen in use.\nThe conversion of dp units to screen pixels is simple: px = dp * (dpi\n/ 160). For example, on a 240 dpi screen, 1 dp equals 1.5 physical\npixels. You should always use dp units when defining your\napplication's UI, to ensure proper display of your UI on screens with\ndifferent densities.Reference: Android developers site",
                "dp is  dip. Use it for everything (margin, padding, etc.).Use sp for {text-size} only.See the difference between px, dp and sp on different screen sizes.Source: Android Programming: The Big Nerd Ranch Guide",
                "px or dot is a pixel on the physical screen.dpi are pixels per inch on the physical screen and represent the density of the display.Android gives alias names to several densitiesdip or dp are density-indenpendant pixels, i.e. they correspond to more or less pixels depending on the physical density.sp or sip is a scale-independant pixel. They are scaled when the Large Text option is turned on in Settings > AccessibilityUse sp for Text size.Use dp for everything else.",
                "I have calculated the formula below to make the conversions dpi to dp and sp",
                "Source 1Source 2Source 3: (data from source 3 is given below)These are dimension values defined in XML. A dimension is specified\nwith a number followed by a unit of measure. For example: 10px, 2in,\n5sp. The following units of measure are supported by Android:dpDensity-independent Pixels - An abstract unit that is based on the\nphysical density of the screen. These units are relative to a 160 dpi\n(dots per inch) screen, on which 1dp is roughly equal to 1px. When\nrunning on a higher density screen, the number of pixels used to draw\n1dp is scaled up by a factor appropriate for the screen's dpi.\nLikewise, when on a lower density screen, the number of pixels used\nfor 1dp is scaled down. The ratio of dp-to-pixel will change with the\nscreen density, but not necessarily in direct proportion. Using dp\nunits (instead of px units) is a simple solution to making the view\ndimensions in your layout resize properly for different screen\ndensities. In other words, it provides consistency for the real-world\nsizes of your UI elements across different devices.spScale-independent Pixels - This is like the dp unit, but it is also\nscaled by the user's font size preference. It is recommended that you use\nthis unit when specifying font sizes, so they will be adjusted for\nboth the screen density and the user's preference.ptPoints - 1/72 of an inch based on the physical size of the screen.pxPixels - Corresponds to actual pixels on the screen. This unit of\nmeasure is not recommended because the actual representation can vary\nacross devices; each device may have a different number of pixels per\ninch and may have more or fewer total pixels available on the screen.mmMillimeters - Based on the physical size of the screen.inInches - Based on the physical size of the screen.Note: A dimension is a simple resource that is referenced using the value provided in the name attribute (not the name of the XML file). As such, you can combine dimension resources with other simple resources in one XML file, under one  element.",
                "Basically the only time where px applies is one px, and that's if you want exactly one pixel on the screen like in the case of a divider:On >160 dpi, you may get 2-3 pixels,On >120 dpi, it rounds to 0.",
                "A virtual pixel unit that you should use when defining UI layout, to express layout dimensions or position in a density-independent way. As described above, the density-independent pixel is equivalent to one physical pixel on a 160 dpi screen, which is the baseline density assumed by the system for a \"medium\" density screen. At runtime, the system transparently handles any scaling of the dp units, as necessary, based on the actual density of the screen in use. The conversion of dp units to screen pixels is\nsimple:px = dp * (dpi / 160).For example, on a 240 dpi screen, 1 dp equals 1.5 physical pixels. You should always use dp units when defining your application's UI, to ensure\nproper display of your UI on screens with different densities.Understanding pixel to dp and vice versa is very essential (especially for giving exact dp values to creative team)It is explained above. Try to avoid in layout files. But there are some cases, where px is required. for example, ListView divider line. px is better here for giving a one-pixel line as a divider for all across screen resolutions.Use sp for font sizes. Then only the font inside the application will change while device fonts size changes (that is, Display -> Fonts on Device). If you want to keep a static sized font inside the app, you can give the font dimension in dp. In such a case, it will never change. Developers may get such a requirement for some specific screens, for that, developers can use dp instead of sp. In all other cases, sp is recommended.",
                "You can see the difference between px and dp from the below picture, and you can also find that the px and dp could not guarantee the same physical sizes on the different screens.",
                "Anything related with the size of text and appearance must use sp or pt. Whereas, anything related to the size of the controls, the layouts, etc. must be used with dp.You can use both dp and dip at its places.",
                "I would only use dp.There is a lot of talk about using \"sp\" for font sizes, and while I appreciate the point, I don't think that it is the right thing to do from a design point of view. You can end up breaking your design if the user has some wonky font size selection, and the user will end up blaming the app, and not their own life choices.Also, if you take an sp-font app on a 160\u00a0dpi tablet, you will find that everything scales up... but your font, which is going to look tiny in comparison. It isn't a good look.While the idea of \"sp\" fonts has a good heart, it is a poor idea. Stick with dp for everything.",
                "sp = scale independent pixeldp = dip = density independent pixelsdpi = dots per inchWe should avoid to use sp.We should use dp to support multiple screens.Android supports different screen resolutionsAn 120 dp ldpi device has 120 pixels in 1 inch size.The same for other densities...We as software engineers should use this conversion formula:pixel = dp * (density / 160)So 240 dpi device's 1 dp will have = 1 * (240/160) = 3/2 = 1.5 pixels.And 480 dpi device's 1 dp will have = 1 * (480/160) = 3 pixels.Using this 1.5 and 3 pixels knowledge, a software engineer can design layouts for different densities.To check screen parameters of any device:",
                "Difference between dp and sp units mentioned as \"user's font size preference\" by the answers copied from official documentation can be seen at run time by changing Settings->Accessibility->Large Text option.Large Text option forces text to become 1.3 times bigger.This might be well of course vendor dependent since it lies in packages/apps/Settings.",
                "dpi -px - pixelpt - pointsin - inch\n - with respect to physical screen size(1 inch = 2.54 cm).mm- milimeter\n - with respect to physical screen size.sp - scale-independent pixel.dip -In standard, dp and sp are used. sp for font size and dp for everything else.Formula for conversion of units:px = dp * ( dpi / 160 );",
                "Please read the answer from the community wiki.\nBelow mentioned is some information to be considered in addition to the above answers. Most Android developers miss this while developing apps, so I am adding these points.sp = scale independent pixeldp = density independent pixelsdpi = density pixelsI have gone through the above answers...not finding them exactly correct.\nsp for text size, dp for layout bounds - standard.\nBut sp for text size will break the layout if used carelessly in most of the devices.sp take the text size of the device, whereas dp take that of device density standard( never change in a device)\nSay 100sp text can occupy 80% of the screen or 100% of the screen depending on the font size set in the deviceYou can use sp for layout bounds also, it will work :)\nNo standard app use sp for whole textUse sp and dp for text size considering UX.Some people use huge FONT size in their phone for more readability, giving them small hardcoded sized text will be a UX issue. Put sp for text where necessary, but make sure it won't break the layout when the user changes his settings.Similarly, if you have a single app supporting all dimensions, adding xxxhdpi assets increases the app size a lot. But now xxxhdpi phones are common so we have to include xxxhdpi assets at least for icons in the sidebar, toolbar, and bottom bar. It's better to move to vector images to have a uniform and better quality images for all screen sizes.Also, note that people use custom fonts on their phones. So lack of a font can cause problems regarding spacing and all. Say text size 12sp for a custom font may take some pixels extra than the default font.Refer to google developer site for screen densities and base density details for android.\nhttps://developer.android.com/training/multiscreen/screendensities",
                "Screen Size in Android is grouped into categories small, medium, large, extra large, double-extra and triple-extra. Screen density is the number of pixels within an area (like an inch) of the screen. Generally, it is measured in dots-per-inch (dpi). Screen density is grouped as low, medium, high, and extra high. Resolution is the total number of pixels on the screen.Formula for Conversion between Unitsdp to px in deviceThe following example may help understand better. The scaling occurs based on bucket sizes of 120(ldpi), 160(mdpi), 240(hdpi), 320(xhdpi), 480(xxhdpi), and 640(xxxhdpi). The Google suggested ratio for designing is 3:4:6:8:12 for ldpi:mdpi:hdpi:xhdpi:xxhdpiA 150px X 150px image will occupy,You may use the following DPI calculator to fix your image sizes and other dimensions when you wish to have a uniform UI design on all Android devices.More Information refer to the following link.http://javapapers.com/android/difference-between-dp-dip-sp-px-in-mm-pt-in-android/",
                "Here's the formula used by Android:px = dp * (dpi / 160)Where dpi is one of the following screen densities. For a list of all possible densities go hereIt defines the \"DENSITY_*\" constants.Taken from here.This will sort out a lot of the confusion when translating between px and dp, if you know your screen dpi.So, let's say you want an image of 60 dp for an hdpi screen then the physical pixel size of 60 dp is:",
                "Normally sp is used for font sizes, while dip is used (also called dp) for others.",
                "I've come across a good article about designing Android apps UI for different screen resolutions, and I'd like to leave it here just for somebody searching in this area. Yes, I know that it's somehow described in Google docs (and mentioned in the posts above), I read that but it was not good for me (yeah, I may be too stupid)). It remained unclear to me how to design layouts capable to handle different screen sizes. I hate the DP concept and so on when I need to implement a \"flexible\" UI layout for different screens. (Hey iOS developers - yes, you're right it's a Storyboard concept).Android has not bad UI concept, but lacks iOS Storyboard features, unfortunately. Designing flexible UI in Android is not an easy thing (at the best).Here goes the article that helped me to understand what to do in Android to make layouts for different screen sizes:JMSTUDIO Blog:- Decide Android App Screen SizeHow to Design UI for Android Apps for Different Screen SizeTo design an app UI for different screen sizes, our initial design has to\nmeet a minimum required space for each screen size. Android defines a\nminimum size (in dp) for each generalized screen type. Here is an\nAndroid screen size guideline.\n\nWhen we get the screen size in dp, it is not enough for us to design\nthe Android app UI. For each screen size, we need to prepare graphics\nand bitmap images for each density. Here is an Android screen density\nguideline.For easy calculation, we can follow the 3:4:6:8 scaling ratio between\nthe four generalized densities. If we create a 36\u00d736 pixel picture for\nldpi device, the rest densities pictures size will be 48\u00d748 for mdpi,\n72\u00d772 for hdpi, and 96\u00d796 for xhdpi.How to Design Android Apps UI in PhotoshopMany designers have problems designing Android app UI in photoshop or another pixel\nbased graphic design tools because of the density-independent unit, dp.\nDesigners don\u2019t know how to map dp to pixel. Google also doesn\u2019t give\na clear Android UI design guide for them, though they give a basic\nformula for dp and pixel translation.As Android\u2019s definition, 1pd equal to 1px under 160 dpi device (mdpi).\nSo we want to design an Android app for xlarge Android devices with\nmdpi density, we can define our UI size in pixel as 960 pixels in width\nand 720px in height; Follow the same mapping rule, we can get\nfollowing Android App screen size UI design guideline:ADDED: If you are interested in \"flexible\" UI too, have a look at this library: An Android SDK that provides a new size unit - sdp (scalable dp). This size unit scales with the screen size (this also mentioned in an answer here, about SDP library)ADDED2 Google has finally understood the usefulness of the iOS Storeboard UI concept, and here goes ConstraintLayout for Android world: Build a Responsive UI with ConstraintLayout",
                "1) dp: (density independent pixels)The number of pixels represented in one unit of dp will increase as the screen resolution increases (when you have more dots/pixels per inch). Conversely on devices with lower resolution, the number of pixels represented in on unit of dp will decrease. Since this is a relative unit, it needs to have a baseline to be compared with. This baseline is a 160 dpi screen. This is the equation: px = dp * (dpi / 160).2) sp: (scale independent pixels)This unit scales according to the screen dpi (similar to dp) as well as the user\u2019s font size preference.3) px: (pixels)Actual pixels or dots on the screen.For more details you can visitAndroid Developer Guide > Dimension\nAndroid Developer Guide > Screens",
                "Screen size in Android is grouped into categories ldpi, mdpi, hdpi, xhdpi, xxhdpi and xxxhdpi. Screen density is the amount of pixels within an area (like inch) of the screen. Generally it is measured in dots-per-inch (dpi).PX(Pixels):DP/DIP(Density pixels / Density independent pixels):dip == dp. In earlier Android versions dip was used and later changed to dp. This is alternative of px.Generally we never use px because it is absolute value. If you use px to set width or height, and if that application is being downloaded into different screen sized devices, then that view will not stretch as per the screen original size.dp is highly recommended to use in place of px. Use dp if you want to mention width and height to grow & shrink dynamically  based on screen sizes.if we give dp/dip, android will automatically calculate the pixel size on the basis of 160 pixel sized screen.SP(Scale independent pixels):scaled based on user\u2019s font size preference. Fonts should use sp.when mentioning the font sizes to fit for various screen sizes, use sp. This is similar to dp.Use sp especially for font sizes to grow & shrink dynamically based on screen sizesAndroid Documentation says:when specifying dimensions, always use either dp or sp units. A dp is\n  a density-independent pixel that corresponds to the physical size of a\n  pixel at 160 dpi. An sp is the same base unit, but is scaled by the\n  user's preferred text size (it\u2019s a scale-independent pixel), so you\n  should use this measurement unit when defining text size",
                "Screen pixel density and resolution vary depending on the platform. Device-independent pixels and scalable pixels are units that provide a flexible way to accommodate a design across platforms.The number of pixels that fit into an inch is referred to as pixel density. High-density screens have more pixels per inch than low-density ones...The number of pixels that fit into an inch is referred to as pixel density. High-density screens have more pixels per inch than low-density ones. As a result, UI elements of the same pixel dimensions appear larger on low-density screens, and smaller on high-density screens.To calculate screen density, you can use this equation:Screen density = Screen width (or height) in pixels / Screen width (or height) in inchesScreen pixel density and resolution vary depending on the platform. Device-independent pixels and scalable pixels are units that provide a flexible way to accommodate a design across platforms.Calculating pixel density\nThe number of pixels that fit into an inch is referred to as pixel density. High-density screens have more pixels per inch than low-density ones...Density independence refers to the uniform display of UI elements on screens with different densities.Density-independent pixels, written as dp (pronounced \u201cdips\u201d), are flexible units that scale to have uniform dimensions on any screen. Material UIs use density-independent pixels to display elements consistently on screens with different densities.Read full text\nhttps://material.io/design/layout/pixel-density.html",
                "The screen of a mobile phone is made up of thousands of tiny dots known as pixels (px). A pixel is the smallest element which goes to make the picture. The more the number of pixels to make a picture or wording, the sharper it becomes and makes the smartphone screen more easily readable.Screen resolution is measured in terms of number of pixels on the screen. Screen resolution is a commonly-used specification when buying a device, but it's actually not that useful when designing for Android because thinking of screens in terms of pixels ignores the notion of physical size, which for a touch device is really really important.Density independent pixel (dp or dip) allow the designer to create assets that appear in a expected way, no matter the resolution or density of target device.A density independent pixel (dp or dip) is equal to one pixel at the baseline density or 160 dpi (dots per inch).1 px/1dp = 160 dpi/160 dpi2 px/1dp = 320 dpi(2x)/160 dpiwhere,dpi is dots per inchSo, at 320 dpi, 1 dp is equal to 2 px.Formulapx/dp = dpi/160dpiDots per inch (dpi) is a measure of the sharpness (that is, the density of illuminated points) on a display screen. The dots per inch for a given picture resolution will differ based on the overall screen size since the same number of pixels are being spread out over a different space.Working with density independent pixels help us to deal with a situation like where you have two devices with same pixel resolution, but differing amount of space. Suppose in a case, a tablet and phone has the same pixel resolution 1280 by 800 pixels (160 dpi) and 800 by 1280 pixels (320 dpi) respectively.Now because a tablet is at baseline density (160 dpi) its physical and density independent pixels sizes are the same, 1280 by 800. The phone on the other hand has a higher pixel density, so it has half as many density independent pixels as physical pixels. So a phone has 400 by 640 density independent pixels. So using a density-independent pixel makes it easier to mentally picture that tablet has much more space than the phone.Similarly, if you have two devices with similar screen size, but different pixel density, say one is 800 by 1280 pixels (320 dpi), and the other is 400 by 640 pixels (160 dpi), we don't need to define totally different layouts for these two devices as we can measure assets in terms of density independent pixel which is same for both devices.800 by 1280 pixels (320dpi)=400 by 640 density independent pixel (dp)400 by 640 pixels (160 dpi)=400 by 640 density independent pixel (dp)Scale independent pixels(sp) is the preferred unit for font size.\nFor accessibility purposes, Android allows users to customize their device's font size. Users that have trouble reading text can increase their device's font size. You can normally find this option in the display setting on your phone or tablet under font size. It's often also available through the accessibility settings.With scale independent pixels, 16 sp is exactly the same as 16 dp when the device's font size is normal or 100%. But when device's font size is large, for example 125%, 16 sp will translate to 20 dp or 1.25 times 16.If you use dp as the unit for font size, then that piece of text has a specific physical size no matter if the user has customize device's font size. Using sp units will make a better experience for people with impaired eyesight.Reference: Udacity, Google",
                "sp: scale independent pixelYou should use it with texts because it is automatically scaled according to the font size that is being used by the user in his device.px: pixel or picture element is the single point on the screen",
                "Pixels(px) \u2013 corresponds to actual pixels on the screen. This is used if you want to give in terms of absolute pixels for width or height.Density-independent Pixels (dp or dip) \u2013 an abstract unit that is based on the physical density of the screen. These units are relative to a 160 dpi screen, so one dp is one pixel on a 160 dpi screen. The ratio of dp-to-pixel will change with the screen density, but not necessarily in direct proportion. Note: The compiler accepts both \u201cdip\u201d and \u201cdp\u201d, though \u201cdp\u201d is more consistent with \u201csp\u201d.Scale-independent Pixels(sp) \u2013 this is like the dp unit, but it is also scaled by the user\u2019s font size preference. It is recommended you use this unit when specifying font sizes, so they will be adjusted for both the screen density and user\u2019s preference.Always use dp and sp only. sp for font sizes and dp for everything else. It will make UI compatible for Android devices with different densities.\nYou can learn more about pixel and dp from\nhttps://www.google.com/design/spec/layout/units-measurements.html#units-measurements-density-independent-pixels-dp-Source URL:- http://www.androidtutorialshub.com/what-is-the-difference-between-px-dp-dip-sp-on-android/",
                "I want to provide an easy way to understand dp. In fact, I think dp is the easiest one to understand. dp is just a physical length unit. It's of the same dimension as mm or inch. It's just convenient for us to write 50dp, 60dp rather than 50/160 inch or 60/160 inch, because one dp is just 1/160 inch whatever the screen size or resolution is.The only problem is that, the android dpi of some screens are not accurate. For example, a screen classified to 160dpi may have 170dpi indeed. So the computation result of dp is fuzzy. It should be approximately the same as 1/160 inch.",
                "SDP - a scalable size unit - basically it is not a unit, but dimension resources for different screen size.Try the sdp library from Intuit. It's very handy to solve unit problems, and you can quickly support multiple screens.Usageandroid:paddingBottom=\"@dimen/_15sdp\" for positive and android:layout_marginTop=\"@dimen/_minus10sdp\"  for negative sdp sdpIt has equivalent value in dp for each size in values-sw<N>dp folders (sw = smallestWidth).AttentionUse it carefully! In most cases you still need to design a different layout for tablets.ExampleYou can use db for text size, but I prefer ssp for text size.For more details, check the library GitHub page.",
                "The ratio of dp-to-pixel will change with the screen density, but not necessarily in direct proportion.Note: The compiler accepts both \"dip\" and \"dp\", though \"dp\" is more consistent with \"sp\".Scale-independent Pixels - this is like the dp unit, but it is also scaled by the user's font size preference."
            ]
        },
        {
            "tag": "git",
            "question": [
                "Move the most recent commit(s) to a new branch with Git",
                "How do I move my recent commits on master to a new branch, and reset master to before those commits were made? e.g. From this:\nmaster A - B - C - D - E\n\nTo this:\nnewbranch     C - D - E\n             /\n..."
            ],
            "url": "https://stackoverflow.com/questions/1628563",
            "answer": [
                "If you want to move your commits to an existing branch, it will look like this:You can store uncommitted edits to your stash before doing this, using git stash. Once complete, you can retrieve the stashed uncommitted edits with git stash popWARNING: This method works because you are creating a new branch with the first command: git branch newbranch. If you want to move commits to an existing branch you need to merge your changes into the existing branch before executing git reset --hard HEAD~3 (see Moving to an existing branch above). If you don't merge your changes first, they will be lost.Unless there are other circumstances involved, this can be easily done by branching and rolling back.But do make sure how many commits to go back. Alternatively, you can instead of HEAD~3, simply provide the hash of the commit (or the reference like origin/master) you want to \"revert back to\" on the master (/current) branch, e.g:*1 You will only be \"losing\" commits from the master branch, but don't worry, you'll have those commits in newbranch!Lastly, you may need to force push your latest changes to main repo:WARNING: With Git version 2.0 and later, if you later git rebase the new branch upon the original (master) branch, you may need an explicit --no-fork-point option during the rebase to avoid losing the carried-over commits.  Having branch.autosetuprebase always set makes this more likely.  See John Mellor's answer for details.",
                "For those wondering why it works (as I was at first):You want to go back to C, and move D and E to the new branch.  Here's what it looks like at first:After git branch newBranch:After git reset --hard HEAD~2:Since a branch is just a pointer, master pointed to the last commit.  When you made newBranch, you simply made a new pointer to the last commit.  Then using git reset you moved the master pointer back two commits.  But since you didn't move newBranch, it still points to the commit it originally did.",
                "The method exposed by sykora is the best option in this case. But sometimes is not the easiest and it's not a general method. For a general method use git cherry-pick:To achieve what OP wants, its a 2-step process:ExecuteNote the hashes of (say 3) commits you want on newbranch. Here I shall use:\nC commit: 9aa1233\nD commit: 453ac3d\nE commit: 612ecb3Note: You can use the first seven characters or\n  the whole commit hashgit cherry-pick applies those three commits to newbranch.",
                "Do NOT do this:As the next time you run git rebase (or git pull --rebase) those 3 commits would be silently discarded from newbranch! (see explanation below)Instead do this:Warning: the reflog is enabled by default, but if you've manually disabled it (e.g. by using a \"bare\" git repository), you won't be able to get the 3 commits back after running git reset --keep HEAD~3.An alternative that doesn't rely on the reflog is:(if you prefer you can write @{-1} - the previously checked out branch - instead of oldbranch).Why would git rebase discard the 3 commits after the first example? It's because git rebase with no arguments enables the --fork-point option by default, which uses the local reflog to try to be robust against the upstream branch being force-pushed.Suppose you branched off origin/master when it contained commits M1, M2, M3, then made three commits yourself:but then someone rewrites history by force-pushing origin/master to remove M2:Using your local reflog, git rebase can see that you forked from an earlier incarnation of the origin/master branch, and hence that the M2 and M3 commits are not really part of your topic branch. Hence it reasonably assumes that since M2 was removed from the upstream branch, you no longer want it in your topic branch either once the topic branch is rebased:This behavior makes sense, and is generally the right thing to do when rebasing.So the reason that the following commands fail:is because they leave the reflog in the wrong state. Git sees newbranch as having forked off the upstream branch at a revision that includes the 3 commits, then the reset --hard rewrites the upstream's history to remove the commits, and so next time you run git rebase it discards them like any other commit that has been removed from the upstream.But in this particular case we want those 3 commits to be considered as part of the topic branch. To achieve that, we need to fork off the upstream at the earlier revision that doesn't include the 3 commits. That's what my suggested solutions do, hence they both leave the reflog in the correct state.For more details, see the definition of --fork-point in the git rebase and git merge-base docs.",
                "Yet another way to do this, using just 2 commands. Also keeps your current working tree intact.Old version - before I learned about git branch -fBeing able to push to . is a nice trick to know.",
                "Here's a far simpler solution for commits to the wrong branch. Starting on branch master that has three mistaken commits:You can now use git add and git commit as you normally would. All new commits will be added to newbranch.The OP stated the goal was to \"take master back to before those commits were made\" without losing changes and this solution does that.I do this at least once a week when I accidentally make new commits to master instead of develop. Usually I have only one commit to rollback in which case using git reset HEAD^ on line 1 is a simpler way to rollback just one commit.Don't do this if you pushed master's changes upstreamSomeone else may have pulled those changes. If you are only rewriting your local master there's no impact when it's pushed upstream, but pushing a rewritten history to collaborators can cause headaches.",
                "This doesn't \"move\" them in the technical sense but it has the same effect:",
                "1. Rename master branch to your newbranch (assuming you are on master branch):2. Create master branch from the commit that you wish:e.g. git checkout -b master a34bc22NOTE:\nThe upstream for newbranch would be origin/master.",
                "To do this without rewriting history (i.e. if you've already pushed the commits):Both branches can then be pushed without force!",
                "Had just this situation:I performed:I expected that commit I would be the HEAD, but commit L is it now...To be sure to land on the right spot in the history its easier to work with the hash of the commit",
                "How can I go from thisto this?With two commandsgivingandgiving",
                "If you just need to move all your unpushed commits to a new branch,\nthen you just need to,create a new branch from the current one :git branch new-branch-namepush your new branch: git push origin new-branch-namerevert your old(current) branch to the last pushed/stable state: git reset --hard origin/old-branch-nameSome people also have other upstreams rather than origin, \nthey should use appropriate upstream",
                "TLDRFor meworks best to identify the commit hashes in question.",
                "You can do this is just 3  simple step that i used.1) make new branch where you want to commit you recent update.git branch <branch name>2)  Find  Recent Commit Id for commit on new branch.git log3)  Copy that commit id  note that Most Recent commit list take place on top. so you can find your commit. you also find this via message.git cherry-pick d34bcef232f6c...you can also provide some rang of commit id.git cherry-pick d34bcef...86d2aecNow your job done. If you picked correct id and correct branch then you will success. So before do this be careful. else another problem can occur.Now you can push your codegit push",
                "1) Create a new branch, which moves all your changes to new_branch.2) Then go back to old branch.3) Do git rebase4) Then the opened editor contains last 3 commit information.5) Change pick to drop in all those 3 commits. Then save and close the editor.6) Now last 3 commits are removed from current branch (master). Now push the branch forcefully, with + sign before branch name.",
                "Most of the solutions here count the amount of commits you'd like to go back. I think this is an error prone methodology. Counting would require recounting.You can simply pass the commit hash of the commit you want to be at HEAD or in other words, the commit you'd like to be the last commit via:(Notice see commit hash)To avoid this:",
                "I was surprised that nobody recommended this way:to explain:",
                "Using Emacs' git porcelain Magit, you can do this simply by hitting b s (magit-branch-spinoff). You'll be asked to enter a name for your new branch and once you hit enter, voila.From the Magit documentation:This command creates and checks out a new branch starting at and tracking the current branch. That branch in turn is reset to the last commit it shares with its upstream. If the current branch has no upstream or no unpushed commits, then the new branch is created anyway and the previously current branch is not touched.This is useful to create a feature branch after work has already began on the old branch (likely but not necessarily \"master\").",
                "I got to move 7 commits from one old-branch to a new-branch.After that, both branches were related to the 7 commits I have done. After git checkout new-branch, I was getting fine git log and git status, but, when accessing the old-branch (git checkout old-branch), I'd got the message \"git is behind by 7 commits and can be fast-forwarded\". What worked for me to erase this message was the followind:After that step, the last 7 commits was referenced only for the new-branch and the previous ones were referenced as old-branch and new-branch in the Bitbucket tree.",
                "If you are a UI person like me and you are using Visual Studio. Then you can do the following:\nIn my case, I want to take the latest commit to another branch.So all commit changes will appear in the Git Changes pane.Now, stash your changesFrom \"Git Changes\" double click on your latest Stash.\"Stash details\" pane will be opened. Click on \"Pop\", then resolve conflicts (if exists).",
                "Taking some ideas from other posts, avoiding anything to do with reset, and being ultra paranoid, my solution is:I'm not proud, but I kept my data ;)"
            ]
        },
        {
            "tag": "http",
            "question": [
                "What is the difference between POST and PUT in HTTP?",
                "According to RFC 2616, \u00a7 9.5, POST is used to create a resource:\n\nThe POST method is used to request that the origin server accept the entity enclosed in the request as a new subordinate of the ..."
            ],
            "url": "https://stackoverflow.com/questions/630453",
            "answer": [
                "Overall:Both PUT and POST can be used for creating.You have to ask, \"what are you performing the action upon?\", to distinguish what you should be using. Let's assume you're designing an API for asking questions.  If you want to use POST, then you would do that to a list of questions. If you want to use PUT, then you would do that to a particular question.Great, both can be used, so which one should I use in my RESTful design:You do not need to support both PUT and POST.Which you use is up to you.  But just remember to use the right one depending on what object you are referencing in the request.Some considerations:An example:I wrote the following as part of another answer on SO regarding this:POST:Used to modify and update a resourceNote that the following is an error:If the URL is not yet created, you\nshould not be using POST to create it\nwhile specifying the name.  This should\nresult in a 'resource not found' error\nbecause <new_question> does not exist\nyet.  You should PUT the <new_question>\nresource on the server first.You could though do something like\nthis to create a resources using POST:Note that in this case the resource\nname is not specified, the new objects\nURL path would be returned to you.PUT:Used to create a resource, or\noverwrite it.  While you specify the\nresources new URL.For a new resource:To overwrite an existing resource:Additionally, and a bit more concisely, RFC 7231 Section 4.3.4 PUT states (emphasis added),4.3.4.  PUTThe PUT method requests that the state of the target resource be\ncreated or replaced with the state defined by the representation\nenclosed in the request message payload.",
                "You can find assertions on the web that sayNeither is quite right.Better is to choose between PUT and POST based on idempotence of the action.PUT implies putting a resource - completely replacing whatever is available at the given URL with a different thing.  By definition, a PUT is idempotent.  Do it as many times as you like, and the result is the same. x=5 is idempotent.  You can PUT a resource whether it previously exists, or not (eg, to Create, or to Update)!POST updates a resource, adds a subsidiary resource, or causes a change.  A POST is not idempotent, in the way that x++ is not idempotent.By this argument, PUT is for creating when you know the URL of the thing you will create. POST can be used to create when you know the URL of the \"factory\" or manager for the category of things you want to create.so:or:",
                "The relevant specification for PUT and POST is RFC 2616 \u00a79.5ff.POST creates a child resource, so POST to /items creates a resources that lives under the /items resource.\nEg. /items/1. Sending the same post packet twice will create two resources.PUT is for creating or replacing a resource at a URL known by the client.Therefore: PUT is only a candidate for CREATE where the client already knows the url before the resource is created. Eg. /blogs/nigel/entry/when_to_use_post_vs_put as the title is used as the resource keyPUT replaces the resource at the known url if it already exists, so sending the same request twice has no effect. In other words, calls to PUT are idempotent.The RFC reads like this:The fundamental difference between the POST and PUT requests is reflected in the different meaning of the Request-URI. The URI in a POST request identifies the resource that will handle the enclosed entity. That resource might be a data-accepting process, a gateway to some other protocol, or a separate entity that accepts annotations. In contrast, the URI in a PUT request identifies the entity enclosed with the request -- the user agent knows what URI is intended and the server MUST NOT attempt to apply the request to some other resource. If the server desires that the request be applied to a different URI,Note: PUT has mostly been used to update resources (by replacing them in their entireties), but recently there is movement towards using PATCH for updating existing resources, as PUT specifies that it replaces the whole resource. RFC 5789.Update 2018: There is a case that can be made to avoid PUT. See \"REST without PUT\"With \u201cREST without PUT\u201d technique, the idea is that consumers are\nforced to post new 'nounified' request resources. As discussed\nearlier, changing a customer\u2019s mailing address is a POST to a new\n\u201cChangeOfAddress\u201d resource, not a PUT of a \u201cCustomer\u201d resource with a\ndifferent mailing address field value.taken from REST API Design - Resource Modeling by Prakash Subramaniam of ThoughtworksThis forces the API to avoid state transition problems with multiple clients updating a single resource, and matches more nicely with event sourcing and CQRS. When the work is done asynchronously, POSTing the transformation and waiting for it to be applied seems appropriate.",
                "POST means \"create new\" as in \"Here is the input for creating a user, create it for me\".PUT means \"insert, replace if already exists\" as in \"Here is the data for user 5\".You POST to example.com/users since you don't know the URL of the user yet, you want the server to create it.You PUT to example.com/users/id since you want to replace/create a specific user.POSTing twice with the same data means create two identical users with different ids. PUTing twice with the same data creates the user the first and updates him to the same state the second time (no changes). Since you end up with the same state after a PUT no matter how many times you perform it, it is said to be \"equally potent\" every time - idempotent. This is useful for automatically retrying requests. No more 'are you sure you want to resend' when you push the back button on the browser.A general advice is to use POST when you need the server to be in control of URL generation of your resources. Use PUT otherwise.  Prefer PUT  over POST.",
                "Can be performed with both PUT or POST in the following way:Creates THE new resource with newResourceId as the identifier, under the /resources URI, or collection.Creates A new resource under the /resources URI, or collection. Usually the identifier is returned by the server.Can only be performed with PUT in the following way:Updates the resource with existingResourceId as the identifier, under the /resources URI, or collection.When dealing with REST and URI as general, you have generic on the left and specific on the right. The generics are usually called collections and the more specific items can be called resource. Note that a resource can contain a collection.<-- generic -- specific -->When you use POST you are always refering to a collection, so whenever you say:you are posting a new user to the users collection.If you go on and try something like this:it will work, but semantically you are saying that you want to add a resource to the john collection under the users collection.Once you are using PUT you are refering to a resource or single item, possibly inside a collection. So when you say:you are telling to the server update, or create if it doesn't exist, the john resource under the users collection.Let me highlight some important parts of the spec:The POST method is used to request that the origin server accept the entity enclosed in the request as a new subordinate of the resource identified by the Request-URI in the Request-LineHence, creates a new resource on a collection.The PUT method requests that the enclosed entity be stored under the supplied Request-URI. If the Request-URI refers to an already existing resource, the enclosed entity SHOULD be considered as a modified version of the one residing on the origin server. If the Request-URI does not point to an existing resource, and that URI is capable of being defined as a new resource by the requesting user agent, the origin server can create the resource with that URI.\"Hence, create or update based on existence of the resource.",
                "I'd like to add my \"pragmatic\" advice. Use PUT when you know the \"id\" by which the object you are saving can be retrieved. Using PUT won't work too well if you need, say, a database generated id to be returned for you to do future lookups or updates.So: To save an existing user, or one where the client generates the id and it's been verified that the id is unique:Otherwise, use POST to initially create the object, and PUT to update the object:",
                "Both are used for data transmission between client to server, but there are subtle differences between them, which are:Analogy:Social Media/Network Analogy:",
                "Use POST to create, and PUT to update. That's how Ruby on Rails is doing it, anyway.",
                "REST is a very high-level concept. In fact, it doesn't even mention HTTP at all!If you have any doubts about how to implement REST in HTTP, you can always take a look at the Atom Publication Protocol (AtomPub) specification. AtomPub is a standard for writing RESTful webservices with HTTP that was developed by many HTTP and REST luminaries, with some input from Roy Fielding, the inventor of REST and (co-)inventor of HTTP himself.In fact, you might even be able to use AtomPub directly. While it came out of the blogging community, it is in no way restricted to blogging: it is a generic protocol for RESTfully interacting with arbitrary (nested) collections of arbitrary resources via HTTP. If you can represent your application as a nested collection of resources, then you can just use AtomPub and not worry about whether to use PUT or POST, what HTTP Status Codes to return and all those details.This is what AtomPub has to say about resource creation (section 9.2):To add members to a Collection, clients send POST requests to the URI of the Collection.",
                "The decision of whether to use PUT or POST to create a resource on a server with an HTTP + REST API is based on who owns the URL structure. Having the client know, or participate in defining, the URL struct is an unnecessary coupling akin to the undesirable couplings that arose from SOA. Escaping types of couplings is the reason REST is so popular. Therefore, the proper method to use is POST. There are exceptions to this rule and they occur when the client wishes to retain control over the location structure of the resources it deploys. This is rare and likely means something else is wrong.At this point some people will argue that if RESTful-URL's are used, the client does knows the URL of the resource and therefore a PUT is acceptable. After all, this is why canonical, normalized, Ruby on Rails, Django URLs are important, look at the Twitter API \u2026 blah blah blah. Those people need to understand there is no such thing as a Restful-URL and that Roy Fielding himself states that:A REST API must not define fixed resource names or hierarchies (an\nobvious coupling of client and server). Servers must have the freedom\nto control their own namespace. Instead, allow servers to instruct\nclients on how to construct appropriate URIs, such as is done in HTML\nforms and URI templates, by defining those instructions within media\ntypes and link relations. [Failure here implies that clients are\nassuming a resource structure due to out-of band information, such as\na domain-specific standard, which is the data-oriented equivalent to\nRPC's functional coupling].http://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-drivenThe idea of a RESTful-URL is actually a violation of REST as the server is in charge of the URL structure and should be free to decide how to use it to avoid coupling. If this confuses you read about the significance of self discovery on API design.Using POST to create resources comes with a design consideration because POST is not idempotent. This means that repeating a POST several times does not guarantee the same behavior each time. This scares people into using PUT to create resources when they should not. They know it's wrong (POST is for CREATE) but they do it anyway because they don't know how to solve this problem.  This concern is demonstrated in the following situation:Step 6 is where people commonly get confused about what to do. However, there is no reason to create a kludge to solve this issue. Instead, HTTP can be used as specified in RFC 2616 and the server replies:10.4.10 409 ConflictThe request could not be completed due to a conflict with the current\nstate of the resource. This code is only allowed in situations where\nit is expected that the user might be able to resolve the conflict and\nresubmit the request. The response body SHOULD include enoughinformation for the user to recognize the source of the conflict.\nIdeally, the response entity would include enough information for the\nuser or user agent to fix the problem; however, that might not be\npossible and is not required.Conflicts are most likely to occur in response to a PUT request. For\nexample, if versioning were being used and the entity being PUT\nincluded changes to a resource which conflict with those made by an\nearlier (third-party) request, the server might use the 409 response\nto indicate that it can\u2019t complete the request. In this case, the\nresponse entity would likely contain a list of the differences between\nthe two versions in a format defined by the response Content-Type.Replying with a status code of 409 Conflict is the correct recourse because:Update based on release of RFC 7231 to Replace 2616RFC 7231 is designed to replace 2616 and in Section 4.3.3 describes the follow possible response for a POSTIf the result of processing a POST would be equivalent to a\nrepresentation of an existing resource, an origin server MAY redirect\nthe user agent to that resource by sending a 303 (See Other) response\nwith the existing resource's identifier in the Location field.  This\nhas the benefits of providing the user agent a resource identifier\nand transferring the representation via a method more amenable to\nshared caching, though at the cost of an extra request if the user\nagent does not already have the representation cached.It now may be tempting to simply return a 303 in the event that a POST is repeated. However, the opposite is true. Returning a 303 would only make sense if multiple create requests (creating different resources) return the same content. An example would be a \"thank you for submitting your request message\" that the client need not re-download each time. RFC 7231 still maintains in section 4.2.2 that POST is not to be idempotent and continues to maintain that POST should be used for create.For more information about this, read this article.",
                "I like this advice, from RFC 2616's definition of PUT:The fundamental difference between the POST and PUT requests is reflected in the different meaning of the Request-URI. The URI in a POST request identifies the resource that will handle the enclosed entity. That resource might be a data-accepting process, a gateway to some other protocol, or a separate entity that accepts annotations. In contrast, the URI in a PUT request identifies the entity enclosed with the request -- the user agent knows what URI is intended and the server MUST NOT attempt to apply the request to some other resource.This jibes with the other advice here, that PUT is best applied to resources that already have a name, and POST is good for creating a new object under an existing resource (and letting the server name it).I interpret this, and the idempotency requirements on PUT, to mean that:",
                "In short:PUT is idempotent, where the resource state will be the same if the same operation is executed one time or multiple times.POST is non-idempotent, where the resource state may become different if the operation is executed multiple times as compared to executing a single time.PUT You can think of similar to \"UPDATE STUDENT SET address = \"abc\" where id=\"123\";POST You can think of something like \"INSERT INTO STUDENT(name, address) VALUES (\"abc\", \"xyzzz\");Student Id is auto generated.With PUT, if the same query is executed multiple times or one time, the STUDENT table state remains the same.In case of POST, if the same query is executed multiple times then multiple Student records get created in the database and the database state changes on each execution of an \"INSERT\" query.NOTE: PUT needs a resource location (already-resource) on which update needs to happen, whereas POST doesn't require that. Therefore intuitively POST is meant for creation of a new resource, whereas PUT is needed for updating the already existing resource.Some may come up with that updates can be performed with POST. There is no hard rule which one to use for updates or which one to use for create. Again these are conventions, and intuitively I'm inclined with the above mentioned reasoning and follow it.",
                "POST is like posting a letter to a mailbox or posting an email to an email queue.\nPUT is like when you put an object in a cubby hole or a place on a shelf (it has a known address).With POST, you're posting to the address of the QUEUE or COLLECTION. With PUT, you're putting to the address of the ITEM.PUT is idempotent. You can send the request 100 times and it will not matter. POST is not idempotent. If you send the request 100 times, you'll get 100 emails or 100 letters in your postal box.A general rule: if you know the id or name of the item, use PUT. If you want the id or name of the item to be assigned by the receiving party, use POST.",
                "Short Answer:Simple rule of thumb: Use POST to create, use PUT to update.Long Answer:POST:PUT:Longer Answer:To understand it we need to question why PUT was required, what were the problems PUT was trying to solve that POST couldn't.From a REST architecture's point of view there is none that matters. We could have lived without PUT as well. But from a client developer's point of view it made his/her life a lot simpler.Prior to PUT, clients couldn't directly know the URL that the server generated or if all it had generated any or whether the data to be sent to the server is already updated or not. PUT relieved the developer of all these headaches. PUT is idempotent, PUT handles race conditions, and PUT lets the client choose the URL.",
                "New answer (now that I understand REST better):PUT is merely a statement of what content the service should, from now on, use to render representations of the resource identified by the client; POST is a statement of what content the service should, from now on, contain (possibly duplicated) but it's up to the server how to identify that content.PUT x (if x identifies a resource): \"Replace the content of the resource identified by x with my content.\"PUT x (if x does not identify a resource): \"Create a new resource containing my content and use x to identify it.\"POST x: \"Store my content and give me an identifier that I can use to identify a resource (old or new) containing said content (possibly mixed with other content). Said resource should be identical or subordinate to that which x identifies.\" \"y's resource is subordinate to x's resource\" is typically but not necessarily implemented by making y a subpath of x (e.g. x = /foo and y = /foo/bar) and modifying the representation(s) of x's resource to reflect the existence of a new resource, e.g. with a hyperlink to y's resource and some metadata. Only the latter is really essential to good design, as URLs are opaque in REST -- you're supposed to use hypermedia instead of client-side URL construction to traverse the service anyways.In REST, there's no such thing as a resource containing \"content\". I refer as \"content\" to data that the service uses to render representations consistently. It typically consists of some related rows in a database or a file (e.g. an image file). It's up to the service to convert the user's content into something the service can use, e.g. converting a JSON payload into SQL statements.Original answer (might be easier to read):PUT /something (if /something already exists): \"Take whatever you have at /something and replace it with what I give you.\"PUT /something (if /something does not already exist): \"Take what I give you and put it at /something.\"POST /something: \"Take what I give you and put it anywhere you want under /something as long as you give me its URL when you're done.\"",
                "Ruby on Rails 4.0 will use the 'PATCH' method instead of PUT to do partial updates.RFC 5789 says about PATCH (since 1995):A new method is necessary to improve interoperability and prevent\n     errors.  The PUT method is already defined to overwrite a resource\n     with a complete new body, and cannot be reused to do partial changes.\n     Otherwise, proxies and caches, and even clients and servers, may get\n     confused as to the result of the operation.  POST is already used but\n     without broad interoperability (for one, there is no standard way to\n     discover patch format support).  PATCH was mentioned in earlier HTTP\n     specifications, but not completely defined.\"Edge Rails: PATCH is the new primary HTTP method for updates\" explains it.",
                "In addition to differences suggested by others, I want to add one more.In POST method you can send body params in form-dataIn PUT method you have to send body params in x-www-form-urlencodedHeader Content-Type:application/x-www-form-urlencodedAccording to this, you cannot send files or multipart data in the PUT methodEDITThe content type \"application/x-www-form-urlencoded\" is inefficient\n  for sending large quantities of binary data or text containing\n  non-ASCII characters. The content type \"multipart/form-data\" should be\n  used for submitting forms that contain files, non-ASCII data, and\n  binary data.Which means if you have to submitfiles, non-ASCII data, and binary datayou should use POST method",
                "At the risk of restating what has already been said, it seems important to remember that PUT implies that the client controls what the URL is going to end up being, when creating a resource. So part of the choice between PUT and POST is going to be about how much you can trust the client to provide correct, normalized URL that are coherent with whatever your URL scheme is.When you can't fully trust the client to do the right thing, it would be \nmore appropriate to use POST to create a new item and then send the URL back to the client in the response.",
                "In a very simple way I'm taking the example of the Facebook timeline.Case 1: When you post something on your timeline, it's a fresh new entry. So in this case they use the POST method because the POST method is non-idempotent.Case 2: If your friend comment on your post the first time, that also will create a new entry in the database so the POST method used.Case 3: If your friend edits his comment, in this case, they had a comment id, so they will update an existing comment instead of creating a new entry in the database. Therefore for this type of operation use the PUT method because it is idempotent.*In a single line, use POST to add a new entry in the database and PUT to update something in the database.",
                "The most important consideration is reliability. If a POST message gets lost the state of the system is undefined. Automatic recovery is impossible. For PUT messages, the state is undefined only until the first successful retry.For instance, it may not be a good idea to create credit card transactions with POST.If you happen to have auto generated  URI's on your resource you can still use PUT by passing a generated URI (pointing to an empty resource) to the client.Some other considerations:",
                "Readers new to this topic will be struck by the endless discussion about what you should do, and the relative absence of lessons from experience. The fact that REST is \"preferred\" over SOAP is, I suppose, a high-level learning from experience, but goodness we must have progressed from there? It's 2016. Roy's dissertation was in 2000. What have we developed? Was it fun? Was it easy to integrate with? To support? Will it handle the rise of smartphones and flaky mobile connections?According to ME, real-life networks are unreliable. Requests timeout. Connections are reset. Networks go down for hours or days at a time. Trains go into tunnels with mobile users aboard. For any given request (as occasionally acknowledged in all this discussion) the request can fall in the water on its way, or the response can fall in the water on its way back. In these conditions, issuing PUT, POST and DELETE requests directly against substantive resources has always struck me as a little brutal and naive.HTTP does nothing to ensure reliable completion of the request-response, and that's just fine because this is properly the job of network-aware applications. Developing such an application, you can jump through hoops to use PUT instead of POST, then more hoops to give a certain kind of error on the server if you detect duplicate requests. Back at the client, you then have to jump through hoops to interpret these errors, refetch, revalidate and repost.Or you can do this: consider your unsafe requests as ephemeral single-user resources (let's call them actions). Clients request a new \"action\" on a substantive resource with an empty POST to the resource. POST will be used only for this. Once safely in possession of the URI of the freshly minted action, the client PUTs the unsafe request to the action URI, not the target resource. Resolving the action and updating the \"real\" resource is properly the job of your API, and is here decoupled from the unreliable network.The server does the business, returns the response and stores it against the agreed action URI. If anything goes wrong, the client repeats the request (natural behaviour!), and if the server has already seen it, it repeats the stored response and does nothing else.You will quickly spot the similarity with promises: we create and return the placeholder for the result before doing anything. Also like a promise, an action can succeed or fail one time, but its result can be fetched repeatedly.Best of all, we give sending and receiving applications a chance to link the uniquely identified action to uniqueness in their respective environments. And we can start to demand, and enforce!, responsible behaviour from clients: repeat your requests as much as you like, but don't go generating a new action until you're in possession of a definitive result from the existing one.As such, numerous thorny problems go away. Repeated insert requests won't create duplicates, and we don't create the real resource until we're in possession of the data. (database columns can stay not-nullable). Repeated update requests won't hit incompatible states and won't overwrite subsequent changes. Clients can (re)fetch and seamlessy process the original confirmation for whatever reason (client crashed, response went missing, etc.).Successive delete requests can see and process the original confirmation, without hitting a 404 error. If things take longer than expected, we can respond provisionally, and we have a place where the client can check back for the definitive result. The nicest part of this pattern is its Kung-Fu (Panda) property. We take a weakness, the propensity for clients to repeat a request any time they don't understand the response, and turn it into a strength :-)Before telling me this is not RESTful, please consider the numerous ways in which REST principles are respected. Clients don't construct URLs. The API stays discoverable, albeit with a little change in semantics. HTTP verbs are used appropriately. If you think this is a huge change to implement, I can tell you from experience that it's not.If you think you'll have huge amounts of data to store, let's talk volumes: a typical update confirmation is a fraction of a kilobyte. HTTP currently gives you a minute or two to respond definitively. Even if you only store actions for a week, clients have ample chance to catch up. If you have very high volumes, you may want a dedicated acid-compliant key value store, or an in-memory solution.",
                "There seems to always be some confusion as to when to use the HTTP POST versus the HTTP PUT method for REST services. Most developers will try to associate CRUD operations directly to HTTP methods. I will argue that this is not correct and one can not simply associate the CRUD concepts to the HTTP methods. That is:It is true that the R(etrieve) and D(elete) of the CRUD operations can be mapped directly to the HTTP methods GET and DELETE respectively. However, the confusion lies in the C(reate) and U(update) operations. In some cases, one can use the PUT for a create while in other cases a POST will be required. The ambiguity lies in the definition of an HTTP PUT method versus an HTTP POST method.According to the HTTP 1.1 specifications the GET, HEAD, DELETE, and PUT methods must be idempotent, and the POST method is not idempotent. That is to say that an operation is idempotent if it can be performed on a resource once or many times and always return the same state of that resource. Whereas a non idempotent operation can return a modified state of the resource from one request to another. Hence, in a non idempotent operation, there is no guarantee that one will receive the same state of a resource.Based on the above idempotent definition, my take on using the HTTP PUT method versus using the HTTP POST method for REST services is:\nUse the HTTP PUT method when:In both cases, these operations can be performed multiple times with the same results. That is the resource will not be changed by requesting the operation more than once. Hence, a true idempotent operation.\nUse the HTTP POST method when:ConclusionDo not directly correlate and map CRUD operations to HTTP methods for REST services. The use of an HTTP PUT method versus an HTTP POST method should be based on the idempotent aspect of that operation. That is, if the operation is idempotent, then use the HTTP PUT method. If the operation is non idempotent, then use the HTTP POST method.",
                "the origin server can create the resource with that URISo you use POST and probably, but not necessary PUT for resource creation. You don't have to support both. For me POST is perfectly enough. So it is a design decision.As your quote mentioned, you use PUT for creation of there is no resource assigned to an IRI, and you want to create a resource anyway. For example, PUT /users/123/password usually replaces the old password with a new one, but you can use it to create a password if it does not exist already (for example, by freshly registered users or by restoring banned users).",
                "I'm going to land with the following:PUT refers to a resource, identified by the URI. In this case, you are updating it. It is the part of the three verbs referring to resources -- delete and get being the other two.POST is basically a free form message, with its meaning being defined 'out of band'. If the message can be interpreted as adding a resource to a directory, that would be OK, but basically you need to understand the message you are sending (posting) to know what will happen with the resource.Because PUT and GET and DELETE refer to a resource, they are also by definition idempotent.POST can perform the other three functions, but then the semantics of the request will be lost on the intermediaries such as caches and proxies. This also applies to providing security on the resource, since a post's URI doesn't necessarily indicate the resource it is applying to (it can though).A PUT doesn't need to be a create; the service could error if the resource isn't already created, but otherwise update it. Or vice versa -- it may create the resource, but not allow updates. The only thing required about PUT is that it points to a specific resource, and its payload is the representation of that resource. A successful PUT means (barring interference) that a GET would retrieve the same resource.Edit: One more thing -- a PUT can create, but if it does then the ID has to be a natural ID -- AKA an email address. That way when you PUT twice, the second put is an update of the first. This makes it idempotent.If the ID is generated (a new employee ID, for example), then the second PUT with the same URL would create a new record, which violates the idempotent rule. In this case the verb would be POST, and the message (not resource) would be to create a resource using the values defined in this message.",
                "Here's a simple rule:PUT to a URL should be used to update or create the resource that can be located at that URL.POST to a URL should be used to update or create a resource which is located at some other (\"subordinate\") URL, or is not locatable via HTTP.",
                "The semantics are supposed be different, in that \"PUT\", like \"GET\" is supposed to be idempotent -- meaning, you can the same exact PUT request multiple times and the result will be as if you executed it only once.I will describe the conventions which I think are most widely used and are most useful:When you PUT a resource at a particular URL what happens is that it should get saved at that URL, or something along those lines.When you POST to a resource at a particular URL, often you are posting a related piece of information to that URL. This implies that the resource at the URL already exists.For example, when you want to create a new stream, you can PUT it to some URL. But when you want to POST a message to an existing stream, you POST to its URL.As for modifying the properties of the stream, you can do that with either PUT or POST. Basically, only use \"PUT\" when the operation is idempotent - otherwise use POST.Note, however, that not all modern browsers support HTTP verbs other than GET or POST.",
                "Most of the time, you will use them like this:For example:In both cases, the request body contains the data for the resource to be created or updated. It should be obvious from the route names that POST is not idempotent (if you call it 3 times it will create 3 objects), but PUT is idempotent (if you call it 3 times the result is the same). PUT is often used for \"upsert\" operation (create or update), but you can always return a 404 error if you only want to use it to modify.Note that POST \"creates\" a new element in the collection, and PUT \"replaces\" an element at a given URL, but it is a very common practice to use PUT for partial modifications, that is, use it only to update existing resources and only modify the included fields in the body (ignoring the other fields). This is technically incorrect, if you want to be REST-purist, PUT should replace the whole resource and you should use PATCH for the partial update. I personally don't care much as far as the behavior is clear and consistent across all your API endpoints.Remember, REST is a set of conventions and guidelines to keep your API simple. If you end up with a complicated work-around just to check the \"RESTfull\" box then you are defeating the purpose ;)",
                "To me, the key of understanding the difference was to understand who defines the ID of the resource:Example (with some address service)There are many great answers with great details below, but that helped me to get to the point.",
                "If you are familiar with database operations,\nthere areI use PUT for Merge and update like operations and use POST for Insertions.",
                "While there is probably an agnostic way to describe these, it does seem to be conflicting with various statements from answers to websites.Let's be very clear and direct here. If you are a .NET developer working with Web API, the facts are (from the Microsoft API documentation),\nhttp://www.asp.net/web-api/overview/creating-web-apis/creating-a-web-api-that-supports-crud-operations:Sure you \"can\" use \"POST\" to update, but just follow the conventions laid out for you with your given framework. In my case it is .NET / Web API, so PUT is for UPDATE there is no debate.I hope this helps any Microsoft developers that read all comments with Amazon and Sun/Java website links."
            ]
        },
        {
            "tag": "javascript",
            "question": [
                "How do I include a JavaScript file in another JavaScript file?",
                "How do I include a JavaScript file inside another JavaScript file, similar to @import in CSS?"
            ],
            "url": "https://stackoverflow.com/questions/950087",
            "answer": [
                "The old versions of JavaScript had no import, include, or require, so many different approaches to this problem have been developed.But since 2015 (ES6), JavaScript has had the ES6 modules standard to import modules in Node.js, which is also supported by most modern browsers.For compatibility with older browsers, build tools like Webpack and Rollup and/or transpilation tools like Babel can be used.ECMAScript (ES6) modules have been supported in Node.js since v8.5, with the --experimental-modules flag, and since at least Node.js v13.8.0 without the flag. To enable \"ESM\" (vs. Node.js's previous CommonJS-style module system [\"CJS\"]) you either use \"type\": \"module\" in package.json or give the files the extension .mjs. (Similarly, modules written with Node.js's previous CJS module can be named .cjs if your default is ESM.)Using package.json:Then module.js:Then main.js:Using .mjs, you'd have module.mjs:Then main.mjs:Browsers have had support for loading ECMAScript modules directly (no tools like Webpack required) since Safari 10.1, Chrome 61, Firefox 60, and Edge 16. Check the current support at caniuse. There is no need to use Node.js' .mjs extension; browsers completely ignore file extensions on modules/scripts.Read more at https://jakearchibald.com/2017/es-modules-in-browsers/Dynamic imports let the script load other scripts as needed:Read more at https://developers.google.com/web/updates/2017/11/dynamic-importThe older CJS module style, still widely used in Node.js, is the module.exports/require system.There are other ways for JavaScript to include external JavaScript contents in browsers that do not require preprocessing.You could load an additional script with an AJAX call and then use eval to run it. This is the most straightforward way, but it is limited to your domain because of the JavaScript sandbox security model. Using eval also opens the door to bugs, hacks and security issues.Like Dynamic Imports you can load one or many scripts with a fetch call using promises to control order of execution for script dependencies using the Fetch Inject library:The jQuery library provides loading functionality in one line:You could add a script tag with the script URL into the HTML. To avoid the overhead of jQuery, this is an ideal solution.The script can even reside on a different server. Furthermore, the browser evaluates the code. The <script> tag can be injected into either the web page <head>, or inserted just before the closing </body> tag.Here is an example of how this could work:This function will add a new <script> tag to the end of the head section of the page, where the src attribute is set to the URL which is given to the function as the first parameter.Both of these solutions are discussed and illustrated in JavaScript Madness: Dynamic Script Loading.Now, there is a big issue you must know about. Doing that implies that you remotely load the code. Modern web browsers will load the file and keep executing your current script because they load everything asynchronously to improve performance. (This applies to both the jQuery method and the manual dynamic script loading method.)It means that if you use these tricks directly, you won't be able to use your newly loaded code the next line after you asked it to be loaded, because it will be still loading.For example: my_lovely_script.js contains MySuperObject:Then you reload the page hitting F5. And it works! Confusing...So what to do about it ?Well, you can use the hack the author suggests in the link I gave you. In summary, for people in a hurry, he uses an event to run a callback function when the script is loaded. So you can put all the code using the remote library in the callback function. For example:Then you write the code you want to use AFTER the script is loaded in a lambda function:Then you run all that:Note that the script may execute after the DOM has loaded, or before, depending on the browser and whether you included the line script.async = false;. There's a great article on Javascript loading in general which discusses this.As mentioned at the top of this answer, many developers use build/transpilation tool(s) like Parcel, Webpack, or Babel in their projects, allowing them to use upcoming JavaScript syntax, provide backward compatibility for older browsers, combine files, minify, perform code splitting etc.",
                "If anyone is looking for something more advanced, try out RequireJS. You'll get added benefits such as dependency management, better concurrency, and avoid duplication (that is, retrieving a script more than once).You can write your JavaScript files in \"modules\" and then reference them as dependencies in other scripts. Or you can use RequireJS as a simple \"go get this script\" solution.Example:Define dependencies as modules:some-dependency.jsimplementation.js is your \"main\" JavaScript file that depends on some-dependency.jsExcerpt from the GitHub README:RequireJS loads plain JavaScript files as well as more defined\n  modules. It is optimized for in-browser use, including in a Web\n  Worker, but it can be used in other JavaScript environments, like\n  Rhino and Node. It implements the Asynchronous Module API.RequireJS uses plain script tags to load modules/files, so it should\n  allow for easy debugging. It can be used simply to load existing\n  JavaScript files, so you can add it to your existing project without\n  having to re-write your JavaScript files....",
                "There actually is a way to load a JavaScript file not asynchronously, so you could use the functions included in your newly loaded file right after loading it, and I think it works in all browsers.You need to use jQuery.append() on the <head> element of your page, that is:However, this method also has a problem: if an error happens in the imported JavaScript file, Firebug (and also Firefox Error Console and Chrome Developer Tools as well) will report its place incorrectly, which is a big problem if you use Firebug to track JavaScript errors down a lot (I do). Firebug simply doesn't know about the newly loaded file for some reason, so if an error occurs in that file, it reports that it occurred in your main HTML file, and you will have trouble finding out the real reason for the error.But if that is not a problem for you, then this method should work.I have actually written a jQuery plugin called $.import_js() which uses this method:So all you would need to do to import JavaScript is:I also made a simple test for this at Example.It includes a main.js file in the main HTML and then the script in main.js uses $.import_js() to import an additional file called included.js, which defines this function:And right after including included.js, the hello() function is called, and you get the alert.(This answer is in response to e-satis' comment).",
                "Another way, that in my opinion is much cleaner, is to make a synchronous Ajax request instead of using a <script> tag. Which is also how Node.js handles includes.Here's an example using jQuery:You can then use it in your code as you'd usually use an include:And be able to call a function from the required script in the next line:",
                "It is possible to dynamically generate a JavaScript tag and append it to HTML document from inside other JavaScript code. This will load targeted JavaScript file.",
                "There is a good news for you. Very soon you will be able to load JavaScript code easily. It will become a standard way of importing modules of JavaScript code and will be part of core JavaScript itself.You simply have to write import cond from 'cond.js'; to load a macro named cond from a file cond.js.So you don't have to rely upon any JavaScript framework nor do you have to explicitly make Ajax calls.Refer to:Static module resolutionModule loaders",
                "Statement import is in ECMAScript 6.Syntax",
                "Maybe you can use this function that I found on this page How do I include a JavaScript file in a JavaScript file?:",
                "Here is a synchronous version without jQuery:Note that to get this working cross-domain, the server will need to set allow-origin header in its response.",
                "I just wrote this JavaScript code (using Prototype for DOM manipulation):Usage:Gist: http://gist.github.com/284442.",
                "If you want it in pure JavaScript, you can use document.write.If you use the jQuery library, you can use the $.getScript method.",
                "Here's the generalized version of how Facebook does it for their ubiquitous Like button:<script>\r\n  var firstScript = document.getElementsByTagName('script')[0],\r\n      js = document.createElement('script');\r\n  js.src = 'https://cdnjs.cloudflare.com/ajax/libs/Snowstorm/20131208/snowstorm-min.js';\r\n  js.onload = function () {\r\n    // do stuff with your dynamically loaded script\r\n    snowStorm.snowColor = '#99ccff';\r\n  };\r\n  firstScript.parentNode.insertBefore(js, firstScript);\r\n</script>If it works for Facebook, it will work for you.The reason why we look for the first script element instead of head or body is because some browsers don't create one if missing, but we're guaranteed to have a script element - this one. Read more at http://www.jspatterns.com/the-ridiculous-case-of-adding-a-script-element/.",
                "You can also assemble your scripts using PHP:File main.js.php:",
                "Most of solutions shown here imply dynamical loading. I was searching instead for a compiler which assemble all the depended files into a single output file. The same as Less/Sass preprocessors deal with the CSS @import at-rule. Since I didn't find anything decent of this sort, I wrote a simple tool solving the issue.So here is the compiler, https://github.com/dsheiko/jsic, which replaces $import(\"file-path\") with the requested file content securely. Here is the corresponding Grunt plugin: https://github.com/dsheiko/grunt-jsic.On the jQuery master branch, they simply concatenate atomic source files into a single one starting with intro.js and ending with outtro.js. That doesn't suits me as it provides no flexibility on the source code design. Check out how it works with jsic:src/main.jssrc/Form/Input/Tel.jsNow we can run the compiler:And get the combined filebuild/main.js",
                "If your intention to load the JavaScript file is using the functions from the imported/included file, you can also define a global object and set the functions as object items. For instance:You just need to be careful when you are including scripts in an HTML file. The order should be as in below:",
                "This should do:",
                "Or rather than including at run time, use a script to concatenate prior to upload.I use Sprockets (I don't know if there are others). You build your JavaScript code in separate files and include comments that are processed by the Sprockets engine as includes. For development you can include files sequentially, then for production to merge them...See also:",
                "I had a simple issue, but I was baffled by responses to this question.I had to use a variable (myVar1) defined in one JavaScript file (myvariables.js) in another JavaScript file (main.js).For this I did as below:Loaded the JavaScript code in the HTML file, in the correct order, myvariables.js first, then main.js:File: myvariables.jsFile: main.jsAs you saw, I had use a variable in one JavaScript file in another JavaScript file, but I didn't need to include one in another. I just needed to ensure that the first JavaScript file loaded before the second JavaScript file, and, the first JavaScript file's variables are accessible in the second JavaScript file, automatically.This saved my day. I hope this helps.",
                "In a modern language with the check if script has already been loaded, it would be:Usage (async/await):orUsage (Promise):",
                "The @import syntax for achieving CSS-like JavaScript importing is possible using a tool such as Mixture via their special .mix file type (see here). I assume the application does this via one of above-mentioned methods.From the Mixture documentation on .mix files:Mix files are simply .js or .css files with .mix. in the file name. A\nmix file simply     extends the functionality of a normal style or\nscript file and allows you to import and combine.Here's an example .mix file that combines multiple .js files into one:Mixture outputs this as scripts-global.js and also as a minified version (scripts-global.min.js).Note: I'm not in any way affiliated with Mixture, other than using it as a front-end development tool. I came across this question upon seeing a .mix JavaScript file in action (in one of the Mixture boilerplates) and being a bit confused by it (\"you can do this?\" I thought to myself). Then I realized that it was an application-specific file type (somewhat disappointing, agreed). Nevertheless, figured the knowledge might be helpful for others.Note: Mixture was discontinued on 2016/07/26 (after being open sourced on 2015/04/12).",
                "In case you are using Web Workers and want to include additional scripts in the scope of the worker, the other answers provided about adding scripts to the head tag, etc. will not work for you.Fortunately, Web Workers have their own importScripts function which is a global function in the scope of the Web Worker, native to the browser itself as it is part of the specification.Alternatively, as the second highest voted answer to your question highlights, RequireJS can also handle including scripts inside a Web Worker (likely calling importScripts itself, but with a few other useful features).",
                "Yes, use type=\"module\" in a script tag (support):And in a script.js file include another file like this:In 'module.js' you must export the function/class that you will import:A working example is here.",
                "Although these answers are great, there is a simple \"solution\" that has been around since script loading existed, and it will cover 99.999% of most people's use cases. Just include the script you need before the script that requires it. For most projects it does not take long to determine which scripts are needed and in what order.If script2 requires script1, this really is the absolute easiest way to do something like this. I'm very surprised no-one has brought this up, as it's the most obvious and simplest answer that will apply in nearly every single case.",
                "My usual method is:It works great and uses no page-reloads for me. I've tried the AJAX method (one of the other answers) but it doesn't seem to work as nicely for me.Here's an explanation of how the code works for those that are curious: essentially, it creates a new script tag (after the first one) of the URL. It sets it to asynchronous mode so it doesn't block the rest of the code, but calls a callback when the readyState (the state of the content to be loaded) changes to 'loaded'.",
                "I wrote a simple module that automates the job of importing/including module scripts in JavaScript. For detailed explanation of the code, refer to the blog post JavaScript require / import / include modules.",
                "This script will add a JavaScript file to the top of any other <script> tag:",
                "Keep it nice, short, simple, and maintainable! :]This code is simply a short functional example that could require additional feature functionality for full support on any (or given) platform.",
                "I came to this question because I was looking for a simple way to maintain a collection of useful JavaScript plugins. After seeing some of the solutions here, I came up with this:Set up a file called \"plugins.js\" (or extensions.js or whatever you want). Keep your plugin files together with that one master file.plugins.js will have an array called pluginNames[] that we will iterate over each(),\nthen append a <script> tag to the head for each pluginBUT:Even though all of the plugins get dropped into the head tag the way they ought to, they don't always get run by the browser when you click into the page or refresh.I've found it's more reliable to just write the script tags in a PHP include. You only have to write it once and that's just as much work as calling the plugin using JavaScript.",
                "There are several ways to implement modules in JavaScript. Here are the two most popular ones:Browsers do not support this moduling system yet, so in order for you to use this syntax you must use a bundler like Webpack. Using a bundler is better anyway because this can combine all of your different files into a single (or a couple of related) files. This will serve the files from the server to the client faster because each HTTP request has some associated overhead accompanied with it. Thus by reducing the overall HTTP request we improve the performance. Here is an example of ES6 modules:This moduling system is used in Node.js. You basically add your exports to an object which is called module.exports. You then can access this object via a require('modulePath'). Important here is to realize that these modules are being cached, so if you require() a certain module twice it will return the already created module."
            ]
        },
        {
            "tag": "javascript",
            "question": [
                "What is the difference between \"let\" and \"var\"?",
                "ECMAScript 6 introduced the let statement.\nI've heard that it's described as a local variable, but I'm still not quite sure how it behaves differently than the var keyword.\nWhat are the differences? ..."
            ],
            "url": "https://stackoverflow.com/questions/762011",
            "answer": [
                "The main difference is scoping rules. Variables declared by var keyword are scoped to the immediate function body (hence the function scope) while let variables are scoped to the immediate enclosing block denoted by { } (hence the block scope).function run() {\n  var foo = \"Foo\";\n  let bar = \"Bar\";\n\n  console.log(foo, bar); // Foo Bar\n\n  {\n    var moo = \"Mooo\"\n    let baz = \"Bazz\";\n    console.log(moo, baz); // Mooo Bazz\n  }\n\n  console.log(moo); // Mooo\n  console.log(baz); // ReferenceError\n}\n\nrun();The reason why let keyword was introduced to the language was function scope is confusing and was one of the main sources of bugs in JavaScript.Take a look at this example from another Stack Overflow question:var funcs = [];\n// let's create 3 functions\nfor (var i = 0; i < 3; i++) {\n  // and store them in funcs\n  funcs[i] = function() {\n    // each should log its value.\n    console.log(\"My value: \" + i);\n  };\n}\nfor (var j = 0; j < 3; j++) {\n  // and now let's run each one to see\n  funcs[j]();\n}My value: 3 was output to console each time funcs[j](); was invoked since anonymous functions were bound to the same variable.People had to create immediately invoked functions to capture correct values from the loops but that was also hairy.While variables declared with var keyword are hoisted (initialized with undefined before the code is run) which means they are accessible in their enclosing scope even before they are declared:function run() {\n  console.log(foo); // undefined\n  var foo = \"Foo\";\n  console.log(foo); // Foo\n}\n\nrun();let variables are not initialized until their definition is evaluated. Accessing them before the initialization results in a ReferenceError. The variable is said to be in \"temporal dead zone\" from the start of the block until the initialization is processed.function checkHoisting() {\n  console.log(foo); // ReferenceError\n  let foo = \"Foo\";\n  console.log(foo); // Foo\n}\n\ncheckHoisting();At the top level, let, unlike var, does not create a property on the global object:var foo = \"Foo\";  // globally scoped\nlet bar = \"Bar\"; // not allowed to be globally scoped\n\nconsole.log(window.foo); // Foo\nconsole.log(window.bar); // undefinedIn strict mode, var will let you re-declare the same variable in the same scope while let raises a SyntaxError.'use strict';\nvar foo = \"foo1\";\nvar foo = \"foo2\"; // No problem, 'foo1' is replaced with 'foo2'.\n\nlet bar = \"bar1\"; \nlet bar = \"bar2\"; // SyntaxError: Identifier 'bar' has already been declared",
                "let can also be used to avoid problems with closures. It binds fresh value rather than keeping an old reference as shown in examples below.for(var i=1; i<6; i++) {\r\n  $(\"#div\" + i).click(function () { console.log(i); });\r\n}\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\r\n<p>Clicking on each number will log to console:</p> \r\n<div id=\"div1\">1</div>\r\n<div id=\"div2\">2</div>\r\n<div id=\"div3\">3</div>\r\n<div id=\"div4\">4</div>\r\n<div id=\"div5\">5</div>Code above demonstrates a classic JavaScript closure problem. Reference to the i variable is being stored in the click handler closure, rather than the actual value of i.Every single click handler will refer to the same object because there\u2019s only one counter object which holds 6 so you get six on each click.A general workaround is to wrap this in an anonymous function and pass i as an argument. Such issues can also be avoided now by using let instead var as shown in the code below.(Tested in Chrome and Firefox 50)for(let i=1; i<6; i++) {\r\n  $(\"#div\" + i).click(function () { console.log(i); });\r\n}\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\r\n<p>Clicking on each number will log to console:</p> \r\n<div id=\"div1\">1</div>\r\n<div id=\"div2\">2</div>\r\n<div id=\"div3\">3</div>\r\n<div id=\"div4\">4</div>\r\n<div id=\"div5\">5</div>",
                "To understand the difference, consider the following code:Here, we can see that our variable j is only known in the first for loop, but not before and after. Yet, our variable i is known in the entire function.Also, consider that block scoped variables are not known before they are declared because they are not hoisted. You're also not allowed to redeclare the same block scoped variable within the same block. This makes block scoped variables less error prone than globally or functionally scoped variables, which are hoisted and which do not produce any errors in case of multiple declarations.Some people would argue that in the future we'll ONLY use let statements and that var statements will become obsolete. JavaScript guru Kyle Simpson wrote a very elaborate article on why he believes that won't be the case.Today, however, that is definitely not the case. In fact, we need actually to ask ourselves whether it's safe to use the let statement. The answer to that question depends on your environment:If you're writing server-side JavaScript code (Node.js), you can safely use the let statement.If you're writing client-side JavaScript code and use a browser based transpiler (like Traceur or babel-standalone), you can safely use the let statement, however your code is likely to be anything but optimal with respect to performance.If you're writing client-side JavaScript code and use a Node based transpiler (like the traceur shell script or Babel), you can safely use the let statement. And, because your browser will only know about the transpiled code, performance drawbacks should be limited.If you're writing client-side JavaScript code and don't use a transpiler, you need to consider browser support.There are still some browsers that don't support let at all :For an up-to-date overview of which browsers support the let statement at the time of your reading this answer, see this Can I Use page.(*) Globally and functionally scoped variables can be initialized and used before they are declared because JavaScript variables are hoisted. This means that declarations are always moved to the top of the scope.(**) Block scoped variables are not hoisted",
                "Here's an explanation of the let keyword with some examples.let works very much like var. The main difference is that the scope of a var variable is the entire enclosing functionThis table on Wikipedia shows which browsers support Javascript 1.7.Note that only Mozilla and Chrome browsers support it. IE, Safari, and potentially others don't.",
                "Variables declared using the let keyword are block-scoped, which means that they are available only in the block in which they were declared.At the top level, variables declared using let don't create properties on the global object.Inside a function (but outside of a block), let has the same scope as var.Variables declared using let inside a block can't be accessed outside that block.Variables declared with let in loops can be referenced only inside that loop.If you use let instead of var in a loop, with each iteration you get a new variable. That means that you can safely use a closure inside a loop.Because of the temporal dead zone, variables declared using let can't be accessed before they are declared. Attempting to do so throws an error.You can't declare the same variable multiple times using let. You also can't declare a variable using let with the same identifier as another variable which was declared using var.const is quite similar to let\u2014it's block-scoped and has TDZ. There are, however, two things which are different.Variable declared using const can't be re-assigned.Note that it doesn't mean that the value is immutable. Its properties still can be changed.If you want to have an immutable object, you should use Object.freeze().You always must specify a value when declaring a variable using const.",
                "The accepted answer is missing a point:",
                "\u26a1\ufe0f Sandbox to play around \u2193",
                "The main difference is the scope difference, while let can be only available inside the scope it's declared, like in for loop, var can be accessed outside the loop for example. From the documentation in MDN (examples also from MDN):let allows you to declare variables that are limited in scope to the block, statement, or expression on which it is used. This is unlike the var keyword, which defines a variable globally, or locally to an entire function regardless of block scope.Variables declared by let have as their scope the block in which they are defined, as well as in any contained sub-blocks. In this way, let works very much like var. The main difference is that the scope of a var variable is the entire enclosing function:At the top level of programs and functions, let, unlike var, does not create a property on the global object. For example:When used inside a block, let limits the variable's scope to that block. Note the difference between var whose scope is inside the function where it is declared.Also don't forget it's ECMA6 feature, so it's not fully supported yet, so it's better always transpiles it to ECMA5 using Babel etc... for more info about visit babel website",
                "Here is an example for the difference between the two (support just started for chrome):As you can see the var j variable is still having a value outside of the for loop scope (Block Scope), but the let i variable is undefined outside of the for loop scope.\"use strict\";\r\nconsole.log(\"var:\");\r\nfor (var j = 0; j < 2; j++) {\r\n  console.log(j);\r\n}\r\n\r\nconsole.log(j);\r\n\r\nconsole.log(\"let:\");\r\nfor (let i = 0; i < 2; i++) {\r\n  console.log(i);\r\n}\r\n\r\nconsole.log(i);",
                "There are some subtle differences \u2014 let scoping behaves more like variable scoping does in more or less any other languages.e.g. It scopes to the enclosing block, They don't exist before they're declared, etc.However it's worth noting that let is only a part of newer Javascript implementations and has varying degrees of browser support.",
                "Variable Not Hoistinglet will not hoist to the entire scope of the block they appear in. By contrast, var could hoist as below.Actually, Per @Bergi, Both var and let are hoisted.Garbage CollectionBlock scope of let is useful relates to closures and garbage collection to reclaim memory. Consider,The click handler callback does not need the hugeData variable at all. Theoretically, after process(..) runs, the huge data structure hugeData could be garbage collected. However, it's possible that some JS engine will still have to keep this huge structure, since the click function has a closure over the entire scope.However, the block scope can make this huge data structure to garbage collected.let loopslet in the loop can re-binds it to each iteration of the loop, making sure to re-assign it the value from the end of the previous loop iteration. Consider,However, replace var with letBecause let create a new lexical environment with those names for a) the initialiser expression b) each iteration (previosly to evaluating the increment expression), more details are here.",
                "The difference is in the scope of the variables declared with each.In practice, there are a number of useful consequences of the difference in scope:The restrictions imposed by let reduce the visibility of the variables and increase the likelihood that unexpected name collisions will be found early.  This makes it easier to track and reason about variables, including their reachability(helping with reclaiming unused memory).Consequently, let variables are less likely to cause problems when used in large programs or when independently-developed frameworks are combined in new and unexpected ways.var may still be useful if you are sure you want the single-binding effect when using a closure in a loop (#5) or for declaring externally-visible global variables in your code (#4).  Use of var for exports may be supplanted if export migrates out of transpiler space and into the core language.1. No use outside nearest enclosing block:\nThis block of code will throw a reference error because the second use of x occurs outside of the block where it is declared with let:In contrast, the same example with var works.2. No use before declaration:\nThis block of code will throw a ReferenceError before the code can be run because x is used before it is declared:In contrast, the same example with var parses and runs without throwing any exceptions.3. No redeclaration:\nThe following code demonstrates that a variable declared with let may not be redeclared later:4. Globals not attached to window:5. Easy use with closures:\nVariables declared with var do not work well with closures inside loops.  Here is a simple loop that outputs the sequence of values that the variable i has at different points in time:Specifically, this outputs:In JavaScript we often use variables at a significantly later time than when they are created.  When we demonstrate this by delaying the output with a closure passed to setTimeout:... the output remains unchanged as long as we stick with let.  In contrast, if we had used var i instead:... the loop unexpectedly outputs \"i is 5\" five times:",
                "Here's an example to add on to what others have already written. Suppose you want to make an array of functions, adderFunctions, where each function takes a single Number argument and returns the sum of the argument and the function's index in the array. Trying to generate adderFunctions with a loop using the var keyword won't work the way someone might na\u00efvely expect:The process above doesn't generate the desired array of functions because i's scope extends beyond the iteration of the for block in which each function was created. Instead, at the end of the loop, the i in each function's closure refers to i's value at the end of the loop (1000) for every anonymous function in adderFunctions. This isn't what we wanted at all: we now have an array of 1000 different functions in memory with exactly the same behavior. And if we subsequently update the value of i, the mutation will affect all the adderFunctions.However, we can try again using the let keyword:This time, i is rebound on each iteration of the for loop. Each function now keeps the value of i at the time of the function's creation, and adderFunctions behaves as expected.Now, image mixing the two behaviors and you'll probably see why it's not recommended to mix the newer let and const with the older var in the same script. Doing so can result is some spectacularly confusing code.Don't let this happen to you. Use a linter.NOTE: This is a teaching example intended to demonstrate the var/let behavior in loops and with function closures that would also be easy to understand. This would be a terrible way to add numbers. But the general technique of capturing data in anonymous function closures might be encountered in the real world in other contexts. YMMV.",
                "May the following two functions show the difference:",
                "ES6 introduced two new keyword(let and const) alternate to var.When you need a block level deceleration you can go with let and const instead of var.The below table summarize the difference between var, let and const",
                "The main difference between var and let is that variables declared with var are function scoped. Whereas functions declared with let are block scoped. For example:variables with var:When the first function testVar gets called the variable foo, declared with var, is still accessible outside the if statement. This variable foo would be available everywhere within the scope of the testVar function.variables with let:When the second function testLet gets called the variable bar, declared with let, is only accessible inside the if statement. Because variables declared with let are block scoped (where a block is the code between curly brackets e.g if{} , for{}, function{}).Another difference between var and let is variables with declared with let don't get hoisted. An example is the best way to illustrate this behavior:variables with let don't get hoisted:variables with var do get hoisted:A variable declared with let in the global scope (which is code that is not in a function) doesn't get added as a property on the global window object. For example (this code is in global scope):When should let be used over var?Use let over var whenever you can because it is simply scoped more specific. This reduces potential naming conflicts which can occur when dealing with a large number of variables. var can be used when you want a global variable explicitly to be on the window object (always consider carefully if this is really necessary).",
                "let is interesting, because it allows us to do something like this:Which results in counting [0, 7].WhereasOnly counts [0, 1].",
                "It also appears that, at least in Visual Studio 2015, TypeScript 1.5, \"var\" allows multiple declarations of the same variable name in a block, and \"let\" doesn't.This won't generate a compile error:This will:",
                "This explanation was taken from an article I wrote at Medium:Hoisting is a JavaScript mechanism where variables and function\ndeclarations are moved to the top of their scope by the parser which\nreads the source code into an intermediate representation before the\nactual code execution starts by the JavaScript interpreter. So, it actually\ndoesn\u2019t matter where variables or functions are declared, they will be\nmoved to the top of their scope regardless of whether their scope is\nglobal or local. This means thatis actually interpreted toSo, as we saw just now, var variables are being hoisted to the top\nof their scope and are being initialized with the value of undefined\nwhich means that we can actually assign their value before actually\ndeclaring them in the code like so:Regarding function declarations, we can invoke them before actually declaring them like so:Function expressions, on the other hand, are not hoisted, so we\u2019ll get the following error:ES6 introduced JavaScript developers the let and const keywords. While let and const are block-scoped and not function\nscoped as var it shouldn\u2019t make a difference while discussing their\nhoisting behavior. We\u2019ll start from the end, JavaScript hoists let\nand const.As we can see above, let doesn\u2019t allow us to use undeclared\nvariables, hence the interpreter explicitly output a reference error\nindicating that the hi variable cannot be accessed before\ninitialization. The same error will occur if we change the above let\nto constSo, bottom line, the JavaScript parser searches for variable\ndeclarations and functions and hoists them to the top of their scope\nbefore code execution and assign values to them in the memory so in\ncase the interpreter will encounter them while executing the code he\nwill recognize them and will be able to execute the code with their\nassigned values. Variables declared with let or const remain\nuninitialized at the beginning of execution while that variables\ndeclared with var are being initialized with a value of undefined.I added this visual illustration to help understanding of how are the hoisted\nvariables and function are being saved in the memory",
                "var is global scope (hoist-able) variable.let and const is block scope.test.js{\r\n    let l = 'let';\r\n    const c = 'const';\r\n    var v = 'var';\r\n    v2 = 'var 2';\r\n}\r\n\r\nconsole.log(v, this.v);\r\nconsole.log(v2, this.v2);\r\nconsole.log(l); // ReferenceError: l is not defined\r\nconsole.log(c); // ReferenceError: c is not defined",
                "varIn this code sample, variable i is declared using var. Therefore, it has a function scope. It means you can access i from only inside the function x. You can't read it from outside the function xfunction x(){\n  var i = 100;\n  console.log(i); // 100\n}\n \nconsole.log(i); // Error. You can't do this\n\nx();In this sample, you can see i is declared inside a if block. But it's declared using var. Therefore, it gets function scope. It means still you can access variable i inside function x. Because var always get scoped to functions. Even though variable i is declared inside if block, because of it's using var it get scoped to parent function x.function x(){\n  if(true){\n    var i = 100;\n  }\n  console.log(i); \n}\n\nx();Now variable i is declared inside the function y. Therefore, i scoped to function y. You can access i inside function y. But not from outside function y.function x(){\n  function y(){\n    var i = 100;\n    console.log(i);\n  }\n  \n  y();\n}\n\nx();function x(){\n  function y(){\n    var i = 100;\n  }\n  console.log(i); // ERROR\n}\n\nx();let, constlet and const has block scope.const and let behave same. But the difference is, when you assign value to const you can't re-assign. But you can re-assign values with let.In this example, variable i is declared inside an if block. So it can be only accessed from inside that if block. We can't access it from outside that if block. (here const work same as let)if(true){\n  let i = 100;\n  console.log(i); // Output: 100\n}\n\nconsole.log(i); // Errorfunction x(){\n  if(true){\n    let i = 100;\n    console.log(i); // Output: 100\n  }\n  console.log(i); // Error\n}\n\nx();Another difference with (let, const) vs var is you can access var defined variable before declaring it. It will give you undefined. But if you do that with let or const defined variable it will give you an error.console.log(x);\nvar x = 100;console.log(x); // ERROR\nlet x = 100;",
                "If I read the specs right then let thankfully can also be leveraged to avoid self invoking functions used to simulate private only members - a popular design pattern that decreases code readability, complicates debugging, that adds no real code protection or other benefit - except maybe satisfying someone's desire for semantics, so stop using it. /rantSee 'Emulating private interfaces'",
                "When Using letThe let keyword attaches the variable declaration to the scope of whatever block (commonly a { .. } pair) it's contained in. In other words,let implicitly hijacks any block's scope for its variable declaration.let variables cannot be accessed in the window object because they cannot be globally accessed.When Using varvar and variables in ES5 has scopes in functions meaning the variables are valid within the function and not outside the function itself.var variables can be accessed in the window object because they cannot be globally accessed.If you want to know more continue reading belowone of the most famous interview questions on scope also can suffice the exact use of let and var as below;When using letThis is because when using let, for every loop iteration the variable is scoped and has its own copy.When using varThis is because when using var, for every loop iteration the variable is scoped and has shared copy.",
                "Some hacks with let:1.2.3.",
                "let vs var. It's all about scope.var variables are global and can be accessed basically everywhere, while let variables are not global and only exist until a closing parenthesis kills them.See my example below, and note how the lion (let) variable acts differently in the two console.logs; it becomes out of scope in the 2nd console.log.",
                "I just came across one use case that I had to use var over let to introduce new variable. Here's a case:I want to create a new variable with dynamic variable names.The above code doesn't work because eval introduces a new block of code. The declaration using var will declare a variable outside of this block of code since var declares a variable in the function scope.let, on the other hand, declares a variable in a block scope. So, a variable will only be visible in eval block.",
                "The below shows how 'let' and 'var' are different in the scope:The gfoo, defined by let initially is in the global scope, and when we declare gfoo again inside the if clause its scope changed and when a new value is assigned to the variable inside that scope it does not affect the global scope.Whereas hfoo, defined by var is initially in the global scope, but again when we declare it inside the if clause, it considers the global scope hfoo, although var has been used again to declare it. And when we re-assign its value we see that the global scope hfoo is also affected. This is the primary difference.",
                "let is a part of es6. These functions will explain the difference in easy way.",
                "As mentioned above:The difference is scoping. var is scoped to the nearest function\n  block and let is scoped to the nearest enclosing block, which\n  can be smaller than a function block. Both are global if outside any\n  block.Lets see an example:Example1:In my both examples I have a function myfunc. myfunc contains a variable myvar equals to 10. \nIn my first example  I check   if myvar equals to 10 (myvar==10) . If yes, I agian declare  a variable  myvar (now I have two myvar variables)using var keyword and assign it a new value (20). In next line I  print its value on my console.  After the conditional block I again print the value of myvar on my console. If you look at the output of myfunc,   myvar has value equals to 20.Example2:\nIn my second example  instead of using var keyword in my conditional block I declare myvar using let keyword . Now when I call myfunc  I get two different outputs: myvar=20 and myvar=10.So the difference is very simple i.e its scope.",
                "As I am currently trying to get an in depth understanding of JavaScript I will share my brief research which contains some of the great pieces already discussed plus some other details in a different perspective.Understanding the difference between var and let can be easier if we understand the difference between function and block scope.Let's consider the following cases:when timer() gets called an ExecutionContext is created which will contain both the VariableEnvironment and all the LexicalEnvironments corresponding to each iteration.And a simpler exampleFunction ScopeBlock Scope"
            ]
        },
        {
            "tag": "css",
            "question": [
                "How to disable text selection highlighting",
                "For anchors that act like buttons (for example, the buttons on the sidebar of this Stack\u00a0Overflow page titled Questions, Tags, and Users) or tabs, is there a CSS standard way to disable the ..."
            ],
            "url": "https://stackoverflow.com/questions/826782",
            "answer": [
                "UPDATE January, 2017:According to Can I use, the user-select + -webkit-user-select for Safari is enough to achieve desired behavior in all major browsers.These are all of the available correct CSS variations:.noselect {\n  -webkit-touch-callout: none; /* iOS Safari */\n    -webkit-user-select: none; /* Safari */\n     -khtml-user-select: none; /* Konqueror HTML */\n       -moz-user-select: none; /* Old versions of Firefox */\n        -ms-user-select: none; /* Internet Explorer/Edge */\n            user-select: none; /* Non-prefixed version, currently\n                                  supported by Chrome, Edge, Opera and Firefox */\n}\n<p>\n  Selectable text.\n</p>\n<p class=\"noselect\">\n  Unselectable text.\n</p>Note that user-select is in standardization process (currently in a W3C working draft). It is not guaranteed to work everywhere and there might be differences in implementation among browsers. Also, browsers can drop support for it in the future.More information can be found in Mozilla Developer Network documentation.The values of this attribute are none, text, toggle, element, elements, all and inherit.",
                "In most browsers, this can be achieved using proprietary variations on the CSS user-select property, originally proposed and then abandoned in CSS\u00a03 and now proposed in CSS UI Level 4:For Internet Explorer < 10 and Opera < 15, you will need to use the unselectable attribute of the element you wish to be unselectable. You can set this using an attribute in HTML:Sadly this property isn't inherited, meaning you have to put an attribute in the start tag of every element inside the <div>. If this is a problem, you could instead use JavaScript to do this recursively for an element's descendants:Update 30 April 2014: This tree traversal needs to be rerun whenever a new element is added to the tree, but it seems from a comment by @Han that it is possible to avoid this by adding a mousedown event handler that sets unselectable on the target of the event. See http://jsbin.com/yagekiji/1 for details.This still doesn't cover all possibilities. While it is impossible to initiate selections in unselectable elements, in some browsers (Internet\u00a0Explorer and Firefox, for example) it's still impossible to prevent selections that start before and end after the unselectable element without making the whole document unselectable.",
                "Until CSS 3's user-select property becomes available, Gecko-based browsers support the -moz-user-select property you already found. WebKit and Blink-based browsers support the -webkit-user-select property.This of course is not supported in browsers that do not use the Gecko rendering engine.There is no \"standards\" compliant quick-and-easy way to do it; using JavaScript is an option.The real question is, why do you want users to not be able to highlight and presumably copy and paste certain elements? I have not come across a single time that I wanted to not let users highlight a certain portion of my website. Several of my friends, after spending many hours reading and writing code will use the highlight feature as a way to remember where on the page they were, or providing a marker so that their eyes know where to look next.The only place I could see this being useful is if you have buttons for forms that should not be copy and pasted if a user copy and pasted the website.",
                "A JavaScript solution for Internet\u00a0Explorer is:",
                "If you want to disable text selection on everything except on <p> elements, you can do this in CSS (watch out for the -moz-none which allows override in sub-elements, which is allowed in other browsers with none):",
                "In the solutions in previous answers selection is stopped, but the user still thinks you can select text because the cursor still changes. To keep it static, you'll have to set your CSS cursor:.noselect {\r\n    cursor: default;\r\n    -webkit-touch-callout: none;\r\n    -webkit-user-select: none;\r\n    -khtml-user-select: none;\r\n    -moz-user-select: none;\r\n    -ms-user-select: none;\r\n    user-select: none;\r\n}\n<p>\r\n  Selectable text.\r\n</p>\r\n<p class=\"noselect\">\r\n  Unselectable text.\r\n</p>This will make your text totally flat, like it would be in a desktop application.",
                "You can do so in Firefox and Safari (Chrome also?)",
                "Workaround for WebKit:I found it in a CardFlip example.",
                "I like the hybrid CSS + jQuery solution.To make all elements inside <div class=\"draggable\"></div> unselectable, use this CSS:And then, if you're using jQuery, add this inside a $(document).ready() block:I figure you still want any input elements to be interactable, hence the :not() pseudo-selector. You could use '*' instead if you don't care.Caveat: Internet\u00a0Explorer\u00a09 may not need this extra jQuery piece, so you may want to add a version check in there.",
                ".hidden:after {\r\n    content: attr(data-txt);\r\n}\n<p class=\"hidden\" data-txt=\"Some text you don't want to be selected\"></p>It's not the best way, though.",
                "You can use CSS or JavaScript for that.The JavaScript way is supported in older browsers, like old versions of Internet\u00a0Explorer as well, but if it's not your case, use the CSS way then:HTML/JavaScript:<html onselectstart='return false;'>\r\n  <body>\r\n    <h1>This is the Heading!</h1>\r\n    <p>And I'm the text, I won't be selected if you select me.</p>\r\n  </body>\r\n</html>HTML/CSS:.not-selectable {\r\n  -webkit-touch-callout: none;\r\n  -webkit-user-select: none;\r\n  -khtml-user-select: none;\r\n  -moz-user-select: none;\r\n  -ms-user-select: none;\r\n  user-select: none;\r\n}\n<body class=\"not-selectable\">\r\n  <h1>This is the Heading!</h1>\r\n  <p>And I'm the text, I won't be selected if you select me.</p>\r\n</body>",
                "For Internet Explorer in addition, you need to add pseudo class focus (.ClassName:focus) and outline-style: none.",
                "Try to insert these rows into the CSS and call the \"disHighlight\" at class property:",
                "A Quick Hack UpdateIf you use the value none for all the CSS user-select properties (including browser prefixes of it), there is a problem which can be still occurred by this.As CSS-Tricks says, the problem is:WebKit still allows the text to be copied, if you select elements around it.You can also use the below one to enforce that an entire element gets selected which means if you click on an element, all the text wrapped in that element will get selected. For this all you have to do is changing the value none to all.",
                "You can do this with a mixin:In an HTML tag:Try it in this CodePen.If you are using an autoprefixer you can remove other prefixes.Browser compatibility here.",
                "For those who have trouble achieving the same in the Android browser with the touch event, use:",
                "If you are using Less and Bootstrap you could write:",
                "Aside from the Mozilla-only property, no, there is no way to disable text selection with just standard CSS (as of now).If you notice, Stack Overflow doesn't disable text selection for their navigation buttons, and I would recommend against doing so in most cases, since it modifies normal selection behavior and makes it conflict with a user's expectations.",
                "This works in some browsers:Simply add your desired elements/ids in front of the selectors separated by commas without spaces, like so:The other answers are better; this should probably be seen as a last resort/catchall.",
                "Suppose there are two divs like this:.second {\r\n  cursor: default;\r\n  user-select: none;\r\n  -webkit-user-select: none;\r\n  /* Chrome/Safari/Opera */\r\n  -moz-user-select: none;\r\n  /* Firefox */\r\n  -ms-user-select: none;\r\n  /* Internet Explorer/Edge */\r\n  -webkit-touch-callout: none;\r\n  /* iOS Safari */\r\n}\n<div class=\"first\">\r\n  This is my first div\r\n</div>\r\n\r\n<div class=\"second\">\r\n  This is my second div\r\n</div>Set cursor to default so that it will give a unselectable feel to the user.Prefix need to be used to support it in all browsers. Without a prefix this may not work in all the answers.",
                "This will be useful if color selection is also not needed:...all other browser fixes. It will work in Internet\u00a0Explorer\u00a09 or later.",
                "Add this to the first div in which you want to disable the selection for text:",
                "NOTE:The correct answer is correct in that it prevents you from being able to select the text. However, it does not prevent you from being able to copy the text, as I'll show with the next couple of screenshots (as of 7th Nov 2014).As you can see, we were unable to select the numbers, but we were able to copy them.Tested on: Ubuntu, Google Chrome 38.0.2125.111.",
                "It is easily done with:Alternatively:Let's say you have a <h1 id=\"example\">Hello, World!</h1>. You will have to remove the innerHTML of that h1, in this case Hello, World. Then you will have to go to CSS and do this:Now it simply thinks it is a block-element, and not text.",
                "To get the result I needed, I found I had to use both ::selection and user-select",
                "This is not CSS, but it is worth a mention:jQuery UI Disable Selection:",
                "Check my solution without JavaScript:jsFiddleli:hover {\r\n    background-color: silver;\r\n}\r\n#id1:before {\r\n    content: \"File\";\r\n}\r\n#id2:before {\r\n    content: \"Edit\";\r\n}\r\n#id3:before {\r\n    content: \"View\";\r\n}\n<ul>\r\n    <li><a id=\"id1\" href=\"www.w1.com\"></a>\r\n    <li><a id=\"id2\" href=\"www.w2.com\"></a>\r\n    <li><a id=\"id3\" href=\"www.w3.com\"></a>\r\n</ul>Popup menu with my technique applied: http://jsfiddle.net/y4Lac/2/",
                "Though this pseudo-element was in drafts of CSS Selectors Level 3, it was removed during the Candidate Recommendation phase, as it appeared that its behavior was under-specified, especially with nested elements, and interoperability wasn't achieved.It's being discussed in How ::selection works on nested elements.Despite it is being implemented in browsers, you can make an illusion of text not being selected by using the same color and background color on selection as of the tab design (in your case).Disallowing users to select the text will raise usability issues.",
                "I have learned from the CSS-Tricks website.And this also:"
            ]
        },
        {
            "tag": "git",
            "question": [
                "How do I discard unstaged changes in Git?",
                "How do I discard changes in my working copy that are not in the index?"
            ],
            "url": "https://stackoverflow.com/questions/52704",
            "answer": [
                "For all unstaged files in current working directory use:For a specific file use:That together with git switch replaces the overloaded git checkout (see here), and thus removes the argument disambiguation.If a file has both staged and unstaged changes, only the unstaged changes shown in git diff are reverted. Changes shown in git diff --staged stay intact.Before Git 2.23For all unstaged files in current working directory:For a specific file:-- here to remove ambiguity (this is known as  argument disambiguation).",
                "Another quicker way is:You don't need to include --include-untracked if you don't want to be thorough about it.After that, you can drop that stash with a git stash drop command if you like.",
                "It seems like the complete solution is:WARNING: while it won't delete ignored files mentioned directly in .gitignore, git clean -df may delete ignored files residing in folders.git clean removes all untracked files and git checkout clears all unstaged changes.",
                "This checks out the current index for the current directory, throwing away all changes in files from the current directory downwards.or this which checks out all files from the index, overwriting working tree files.",
                "Cleans the working tree by recursively removing files that are not under version control, starting from the current directory.-d: Remove untracked directories in addition to untracked files-f: Force (might be not necessary depending on  clean.requireForce setting)Run git help clean to see the manual",
                "You can now discard unstaged changes in one tracked file with:and in all tracked files in the current directory (recursively) with:If you run the latter from the root of the repository, it will discard unstaged changes in all tracked files in the project.",
                "My favorite isThat lets you selectively revert chunks.See also:",
                "Since no answer suggests the exact option combination that I use, here it is:This is the online help text for the used git clean options:-dRemove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository, it is not removed by default. Use -f option twice if you really want to remove such a directory.-xDon\u2019t use the standard ignore rules read from .gitignore (per directory) and $GIT_DIR/info/exclude, but do still use the ignore rules given with -e options. This allows removing all untracked files, including build products. This can be used (possibly in conjunction with git reset) to create a pristine working directory to test a clean build.-nDon\u2019t actually remove anything, just show what would be done.-fIf the Git configuration variable clean.requireForce is not set to false, Git clean will refuse to delete files or directories unless given -f, -n, or -i. Git will refuse to delete directories within the .git subdirectory or file, unless a second -f is given.",
                "If you merely wish to remove changes to existing files, use checkout (documented here).If you want to remove files added since your last commit, use clean (documented here):If you wish to move changes to a holding space for later access, use stash (documented here):",
                "The easiest way to do this is by using this command:This command is used to discard changes in working directory -https://git-scm.com/docs/git-checkoutIn git command, stashing of untracked files is achieved by using:http://git-scm.com/docs/git-stash",
                "I really found this article helpful for explaining when to use what command: http://www.szakmeister.net/blog/2011/oct/12/reverting-changes-git/There are a couple different cases:If you haven't staged the file, then you use git checkout.  Checkout \"updates files in the working tree to match the version in the index\".  If the files have not been staged (aka added to the index)... this command will essentially revert the files to what your last commit was.git checkout -- foo.txtIf you have staged the file, then use git reset.  Reset changes the index to match a commit.git reset -- foo.txtI suspect that using git stash is a popular choice since it's a little less dangerous.  You can always go back to it if you accidently blow too much away when using git reset.  Reset is recursive by default.Take a look at the article above for further advice.",
                "If you aren't interested in keeping the unstaged changes (especially if the staged changes are new files), I found this handy:",
                "As you type git status, \n(use \"git checkout -- ...\" to discard changes in working directory)\nis shown.e.g. git checkout -- .",
                "You can use git stash - if something goes wrong, you can still revert from the stash.\nSimilar to some other answer here, but this one also removes all unstaged files and also all unstaged deletes:if you check that everything is OK, throw the stash away:The answer from Bilal Maqsood with git clean also worked for me, but with the stash I have more control - if I do sth accidentally, I can still get my changes backUPDATEI think there is 1 more change (don't know why this worked for me before):git add . -A instead of git add .without the -A the removed files will not be staged",
                "git checkout -fman git-checkout:-f, --forceWhen switching branches, proceed even if the index or the working tree differs from HEAD. This is used to throw away local changes.When checking out paths from the index, do not fail upon unmerged entries; instead, unmerged entries are ignored.",
                "Instead of discarding changes, I reset my remote to the origin. Note - this method is to completely restore your folder to that of the repo.So I do this to make sure they don't sit there when I git reset (later - excludes gitignores on the Origin/branchname)NOTE: If you want to keep files not yet tracked, but not in GITIGNORE you may wish to skip this step, as it will Wipe these untracked files not found on your remote repository (thanks @XtrmJosh).Then IThen I reset to originThat will put it back to square one. Just like RE-Cloning the branch, WHILE keeping all my gitignored files locally and in place.Updated per user comment below:\nVariation to reset the to whatever current branch the user is on.",
                "Tried all the solutions above but still couldn't get rid of new, unstaged files.Use git clean -f to remove those new files - with caution though! Note the force option.",
                "To do a permanent discard:\ngit reset --hardTo save changes for later:\ngit stash",
                "Just use:Done. Easy.If you really care about your stash stack then you can follow with git stash drop. But at that point you're better off using (from Mariusz Nowak):Nonetheless, I like git stash -u the best because it \"discards\" all tracked and untracked changes in just one command. Yet git checkout -- . only discards tracked changes,\nand git clean -df only discards untracked changes... and typing both commands is far too much work :)",
                "simply sayIt will remove all your local changes. You also can use later by sayingor \n    git stash pop",
                "you have a very simple git command git checkout .",
                "This works even in directories that are; outside of normal git permissions.Happened to me recently",
                "No matter what state your repo is in you can always reset to any previous commit:This will discard all changes which were made after that commit.",
                "In my opinion,should do the trick. As per Git documentation on git cleangit-clean - Remove untracked files from the working treeDescriptionCleans the working tree by recursively removing files that\n  are not under version control, starting from the current directory.Normally, only files unknown to Git are removed, but if the -x option\n  is specified, ignored files are also removed. This can, for example,\n  be useful to remove all build products.If any optional ... arguments are given, only those paths are\n  affected.Options-d Remove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository, it is\n  not removed by default. Use -f option twice if you really want to\n  remove such a directory.-f\n  --force If the Git configuration variable clean.requireForce is not set to false, git clean will refuse to run unless given -f, -n or -i.",
                "Another way to get rid of new files that is more specific than git clean -df (it will allow you to get rid of some files not necessarily all), is to add the new files to the index first, then stash, then drop the stash.This technique is useful when, for some reason, you can't easily delete all of the untracked files by some ordinary mechanism (like rm).",
                "What follows is really only a solution if you are working with a fork of a repository where you regularly synchronize (e.g. pull request) with another repo. Short answer: delete fork and refork, but read the warnings on github.I had a similar problem, perhaps not identical, and I'm sad to say my solution is not ideal, but it is ultimately effective.I would often have git status messages like this (involving at least 2/4 files):A keen eye will note that these files have dopplegangers that are a single letter in case off. Somehow, and I have no idea what led me down this path to start with (as I was not working with these files myself from the upstream repo), I had switched these files. Try the many solutions listed on this page (and other pages) did not seem to help.I was able to fix the problem by deleting my forked repository and all local repositories, and reforking. This alone was not enough; upstream had to rename the files in question to new filenames. As long as you don't have any uncommited work, no wikis, and no issues that diverge from the upstream repository, you should be just fine. Upstream may not be very happy with you, to say the least. As for my problem, it is undoubtedly a user error as I'm not that proficient with git, but the fact that it is far from easy to fix points to an issue with git as well.",
                "I had a weird situation where a file is always unstaged, this helps me to resolve.git rm .gitattributes\n  git add -A\n  git reset --hard",
                "When you want to transfer a stash to someone else:[edit] as commented, it \u00eds possible to name stashes. Well, use this if you want to share your stash ;)",
                "You could create your own alias which describes how to do it in a descriptive way.I use the next alias to discard changes.Then you can use it as next to discard all changes:Or just a file:Otherwise, if you want to discard all changes and also the untracked files, I use a mix of checkout and clean:So the use is simple as next:Now is available in the next Github repo which contains a lot of aliases:"
            ]
        },
        {
            "tag": "bash",
            "question": [
                "How do I get the directory where a Bash script is located from within the script itself?",
                "How do I get the path of the directory in which a Bash script is located, inside that script?\nI want to use a Bash script as a launcher for another application. I want to change the working directory ..."
            ],
            "url": "https://stackoverflow.com/questions/59895",
            "answer": [
                "is a useful one-liner which will give you the full directory name of the script no matter where it is being called from.It will work as long as the last component of the path used to find the script is not a symlink (directory links are OK).  If you also want to resolve any links to the script itself, you need a multi-line solution:This last one will work with any combination of aliases, source, bash -c, symlinks, etc.Beware: if you cd to a different directory before running this snippet, the result may be incorrect!Also, watch out for $CDPATH gotchas, and stderr output side effects if the user has smartly overridden cd to redirect output to stderr instead (including escape sequences, such as when calling update_terminal_cwd >&2 on Mac). Adding >/dev/null 2>&1 at the end of your cd command will take care of both possibilities.To understand how it works, try running this more verbose form:And it will print something like:",
                "Use dirname \"$0\":Using pwd alone will not work if you are not running the script from the directory it is contained in.",
                "The dirname command is the most basic, simply parsing the path up to the filename off of the $0 (script name) variable:But, as matt b pointed out, the path returned is different depending on how the script is called. pwd doesn't do the job because that only tells you what the current directory is, not what directory the script resides in. Additionally, if a symbolic link to a script is executed, you're going to get a (probably relative) path to where the link resides, not the actual script.Some others have mentioned the readlink command, but at its simplest, you can use:readlink will resolve the script path to an absolute path from the root of the filesystem. So, any paths containing single or double dots, tildes and/or symbolic links will be resolved to a full path.Here's a script demonstrating each of these, whatdir.sh:Running this script in my home dir, using a relative path:Again, but using the full path to the script:Now changing directories:And finally using a symbolic link to execute the script:There is however one case where this doesn't work, when the script is sourced (instead of executed) in bash:",
                "It works for all versions, includingAlternatively, if the Bash script itself is a relative symlink you want to follow it and return the full path of the linked-to script:SCRIPT_PATH is given in full path, no matter how it is called.Just make sure you locate this at start of the script.",
                "You can use $BASH_SOURCE:Note that you need to use #!/bin/bash and not #!/bin/sh since it's a Bash extension.",
                "Short answer:or (preferably):",
                "Here is an easy-to-remember script:",
                "This should do it:This works with symlinks and spaces in path.Please see the man pages for dirname and realpath.Please add a comment on how to support MacOS. I'm sorry I can verify it.",
                "pwd can be used to find the current working directory, and dirname to find the directory of a particular file (command that was run, is $0, so dirname $0 should give you the directory of the current script).However, dirname gives precisely the directory portion of the filename, which more likely than not is going to be relative to the current working directory. If your script needs to change directory for some reason, then the output from dirname becomes meaningless.I suggest the following:This way, you get an absolute, rather than a relative directory.Since the script will be run in a separate Bash instance, there isn't any need to restore the working directory afterwards, but if you do want to change back in your script for some reason, you can easily assign the value of pwd to a variable before you change directory, for future use.Although justsolves the specific scenario in the question, I find having the absolute path to more more useful generally.",
                "I don't think this is as easy as others have made it out to be.  pwd doesn't work, as the current directory is not necessarily the directory with the script.  $0 doesn't always have the information either.  Consider the following three ways to invoke a script:In the first and third ways $0 doesn't have the full path information.  In the second and third, pwd does not work.  The only way to get the directory in the third way would be to run through the path and find the file with the correct match.  Basically the code would have to redo what the OS does.One way to do what you are asking would be to just hardcode the data in the /usr/share directory, and reference it by its full path.  Data shoudn't be in the /usr/bin directory anyway, so this is probably the thing to do.",
                "This gets the current working directory on Mac\u00a0OS\u00a0X\u00a0v10.6.6 (Snow\u00a0Leopard):",
                "This is Linux specific, but you could use:",
                "Here is a POSIX compliant one-liner:",
                "The shortest and most elegant way to do this is:This would work on all platforms and is super clean.More details can be found in \"Which directory is that bash script in?\".",
                "...even when the called script is called from within another bash function or script, or when nested sourcing is being used!For many cases, all you need to acquire is the full path to the script you just called. This can be easily accomplished using realpath. Note that realpath is part of GNU coreutils. If you don't have it already installed (it comes default on Ubuntu), you can install it with sudo apt update && sudo apt install coreutils.get_script_path.sh (for the latest version of this script, see get_script_path.sh in my eRCaGuy_hello_world repo):IMPORTANT note on nested source calls: if \"${BASH_SOURCE[-1]}\" above doesn't give you quite what you want, try using \"${BASH_SOURCE[0]}\" instead. The first (0) index gives you the first entry in the array, and the last (-1) index gives you the last last entry in the array. Depending on what it is you're after, you may actually want the first entry. I discovered this to be the case when I sourced ~/.bashrc with . ~/.bashrc, which sourced ~/.bash_aliases with . ~/.bash_aliases, and I wanted the realpath (with expanded symlinks) to the ~/.bash_aliases file, NOT to the ~/.bashrc file. Since these are nested source calls, using \"${BASH_SOURCE[0]}\" gave me what I wanted: the expanded path to ~/.bash_aliases! Using \"${BASH_SOURCE[-1]}\", however, gave me what I did not want: the expanded path to ~/.bashrc.Example command and output:If you use \"$0\" in the script instead of \"${BASH_SOURCE[-1]}\", you'll get the same output as above when running the script, but this undesired output instead when sourcing the script:And, apparently if you use \"$BASH_SOURCE\" instead of \"${BASH_SOURCE[-1]}\", it will not work if the script is called from within another bash function. So, using \"${BASH_SOURCE[-1]}\" is therefore the best way to do it, as it solves both of these problems! See the references below.Difference between realpath and realpath -s:Note that realpath also successfully walks down symbolic links to determine and point to their targets rather than pointing to the symbolic link. If you do NOT want this behavior (sometimes I don't), then add -s to the realpath command above, making that line look like this instead:This way, symbolic links are NOT expanded. Rather, they are left as-is, as symbolic links in the full path.The code above is now part of my eRCaGuy_hello_world repo in this file here: bash/get_script_path.sh. Reference and run this file for full examples both with and withOUT symlinks in the paths. See the bottom of the file for example output in both cases.BASH_SOURCEAn array variable whose members are the source filenames where the corresponding shell function names in the FUNCNAME array variable are defined. The shell function ${FUNCNAME[$i]} is defined in the file ${BASH_SOURCE[$i]} and called from ${BASH_SOURCE[$i+1]}.",
                "Here is the simple, correct way:Explanation:${BASH_SOURCE[0]} - the full path to the script. The value of this will be correct even when the script is being sourced, e.g. source <(echo 'echo $0') prints bash, while replacing it with ${BASH_SOURCE[0]} will print the full path of the script. (Of course, this assumes you're OK taking a dependency on Bash.)readlink -f - Recursively resolves any symlinks in the specified path. This is a GNU extension, and not available on (for example) BSD systems. If you're running a Mac, you can use Homebrew to install GNU coreutils and supplant this with greadlink -f.And of course dirname gets the parent directory of the path.",
                "I tried all of these and none worked. One was very close, but it had a tiny bug that broke it badly; they forgot to wrap the path in quotation marks.Also a lot of people assume you're running the script from a shell, so they forget when you open a new script it defaults to your home.Try this directory on for size:This gets it right regardless how or where you run it:So to make it actually useful, here's how to change to the directory of the running script:",
                "This is a slight revision to the solution e-satis and 3bcdnlklvc04a pointed out in their answer:This should still work in all the cases they listed.This will prevent popd after a failed pushd. Thanks to konsolebox.",
                "I would use something like this:",
                "For systems having GNU coreutils readlink (for example, Linux):There's no need to use BASH_SOURCE when $0 contains the script filename.",
                "Try using:",
                "$_ is worth mentioning as an alternative to $0.  If you're running a script from Bash, the accepted answer can be shortened to:Note that this has to be the first statement in your script.",
                "These are short ways to get script information:Folders and files:Using these commands:And I got this output:Also see: https://pastebin.com/J8KjxrPF",
                "This works in Bash 3.2:If you have a ~/bin directory in your $PATH, you have  A inside this directory. It sources the script ~/bin/lib/B. You know where the included script is relative to the original one, in the lib subdirectory, but not where it is relative to the user's current directory.This is solved by the following (inside A):It doesn't matter where the user is or how he/she calls the script. This will always work.",
                "I've compared many of the answers given, and came up with some more compact solutions. These seem to handle all of the crazy edge cases that arise from your favorite combination of:If you're running from Linux, it seems that using the proc handle is the best solution to locate the fully resolved source of the currently running script (in an interactive session, the link points to the respective /dev/pts/X):This has a small bit of ugliness to it, but the fix is compact and easy to understand. We aren't using bash primitives only, but I'm okay with that because readlink simplifies the task considerably. The echo X adds an X to the end of the variable string so that any trailing whitespace in the filename doesn't get eaten, and the parameter substitution ${VAR%X} at the end of the line gets rid of the X. Because readlink adds a newline of its own (which would normally be eaten in the command substitution if not for our previous trickery), we have to get rid of that, too. This is most easily accomplished using the $'' quoting scheme, which lets us use escape sequences such as \\n to represent newlines (this is also how you can easily make deviously named directories and files).The above should cover your needs for locating the currently running script on Linux, but if you don't have the proc filesystem at your disposal, or if you're trying to locate the fully resolved path of some other file, then maybe you'll find the below code helpful. It's only a slight modification from the above one-liner. If you're playing around with strange directory/filenames, checking the output with both ls and readlink is informative, as ls will output \"simplified\" paths, substituting ? for things like newlines.",
                "I believe I've got this one. I'm late to the party, but I think some will appreciate it being here if they come across this thread. The comments should explain:",
                "Try the following cross-compatible solution:As the commands such as realpath or readlink could be not available (depending on the operating system).Note: In Bash, it's recommended to use ${BASH_SOURCE[0]} instead of $0, otherwise path can break when sourcing the file (source/.).Alternatively you can try the following function in Bash:This function takes one argument. If argument has already absolute path, print it as it is, otherwise print $PWD variable + filename argument (without ./ prefix).Related:"
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I execute a program or call a system command?",
                "How do I call an external command within Python as if I had typed it in a shell or command prompt?"
            ],
            "url": "https://stackoverflow.com/questions/89228",
            "answer": [
                "Use the subprocess module in the standard library:The advantage of subprocess.run over os.system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...).Even the documentation for os.system recommends using subprocess instead:The subprocess module provides more powerful facilities for spawning new processes and retrieving their results; using that module is preferable to using this function. See the Replacing Older Functions with the subprocess Module section in the subprocess documentation for some helpful recipes.On Python 3.4 and earlier, use subprocess.call instead of .run:",
                "Here is a summary of ways to call external programs, including their advantages and disadvantages:os.system passes the command and arguments to your system's shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example:However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, et cetera. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.os.popen will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don't need to worry about escaping anything. Example:subprocess.Popen. This is intended as a replacement for os.popen, but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you'd say:instead ofbut it is nice to have all of the options there in one unified class instead of 4 different popen functions. See the documentation.subprocess.call. This is basically just like the Popen class and takes all of the same arguments, but it simply waits until the command completes and gives you the return code. For example:subprocess.run. Python 3.5+ only. Similar to the above but even more flexible and returns a CompletedProcess object when the command finishes executing.os.fork, os.exec, os.spawn are similar to their C language counterparts, but I don't recommend using them directly.The subprocess module should probably be what you use.Finally, please be aware that for all methods where you pass the final command to be executed by the shell as a string and you are responsible for escaping it. There are serious security implications if any part of the string that you pass can not be fully trusted. For example, if a user is entering some/any part of the string. If you are unsure, only use these methods with constants. To give you a hint of the implications consider this code:and imagine that the user enters something \"my mama didnt love me && rm -rf /\" which could erase the whole filesystem.",
                "Typical implementation:You are free to do what you want with the stdout data in the pipe.  In fact, you can simply omit those parameters (stdout= and stderr=) and it'll behave like os.system().",
                "Some hints on detaching the child process from the calling one (starting the child process in background).Suppose you want to start a long task from a CGI script. That is, the child process should live longer than the CGI script execution process.The classical example from the subprocess module documentation is:The idea here is that you do not want to wait in the line 'call subprocess' until the longtask.py is finished. But it is not clear what happens after the line 'some more code here' from the example.My target platform was FreeBSD, but the development was on Windows, so I faced the problem on Windows first.On Windows (Windows\u00a0XP), the parent process will not finish until the longtask.py has finished its work. It is not what you want in a CGI script. The problem is not specific to Python; in the PHP community the problems are the same.The solution is to pass DETACHED_PROCESS Process Creation Flag to the underlying CreateProcess function in Windows API.\nIf you happen to have installed pywin32, you can import the flag from the win32process module, otherwise you should define it yourself:/* UPD 2015.10.27 @eryksun in a comment below notes, that the semantically correct flag is CREATE_NEW_CONSOLE (0x00000010) */On FreeBSD we have another problem: when the parent process is finished, it finishes the child processes as well. And that is not what you want in a CGI script either. Some experiments showed that the problem seemed to be in sharing sys.stdout. And the working solution was the following:I have not checked the code on other platforms and do not know the reasons of the behaviour on FreeBSD. If anyone knows, please share your ideas. Googling on starting background processes in Python does not shed any light yet.",
                "Note that this is dangerous, since the command isn't cleaned. I leave it up to you to google for the relevant documentation on the 'os' and 'sys' modules. There are a bunch of functions (exec* and spawn*) that will do similar things.",
                "I'd recommend using the subprocess module instead of os.system because it does shell escaping for you and is therefore much safer.",
                "If you want to return the results of the command, you can use os.popen. However, this is deprecated since version 2.6 in favor of the subprocess module, which other answers have covered well.",
                "There are lots of different libraries which allow you to call external commands with Python. For each library I've given a description and shown an example of calling an external command. The command I used as the example is ls -l (list all files). If you want to find out more about any of the libraries I've listed and linked the documentation for each of them.Hopefully this will help you make a decision on which library to use :)Subprocess allows you to call external commands and connect them to their input/output/error pipes (stdin, stdout, and stderr). Subprocess is the default choice for running commands, but sometimes other modules are better.os is used for \"operating system dependent functionality\". It can also be used to call external commands with os.system and os.popen (Note: There is also a subprocess.popen). os will always run the shell and is a simple alternative for people who don't need to, or don't know how to use subprocess.run.sh is a subprocess interface which lets you call programs as if they were functions. This is useful if you want to run a command multiple times.plumbum is a library for \"script-like\" Python programs. You can call programs like functions as in sh. Plumbum is useful if you want to run a pipeline without the shell.pexpect lets you spawn child applications, control them and find patterns in their output. This is a better alternative to subprocess for commands that expect a tty on Unix.fabric is a Python 2.5 and 2.7 library. It allows you to execute local and remote shell commands. Fabric is simple alternative for running commands in a secure shell (SSH)envoy is known as \"subprocess for humans\". It is used as a convenience wrapper around the subprocess module.commands contains wrapper functions for os.popen, but it has been removed from Python 3 since subprocess is a better alternative.",
                "Use the subprocess module (Python 3):It is the recommended standard way. However, more complicated tasks (pipes, output, input, etc.) can be tedious to construct and write.Note on Python version: If you are still using Python 2, subprocess.call works in a similar way.ProTip: shlex.split can help you to parse the command for run, call, and other subprocess functions in case you don't want (or you can't!) provide them in form of lists:If you do not mind external dependencies, use plumbum:It is the best subprocess wrapper. It's cross-platform, i.e. it works on both Windows and Unix-like systems. Install by pip install plumbum.Another popular library is sh:However, sh dropped Windows support, so it's not as awesome as it used to be. Install by pip install sh.",
                "I always use fabric for this things like:But this seem to be a good tool: sh (Python subprocess interface).Look at an example:",
                "Check the \"pexpect\" Python library, too.It allows for interactive controlling of external programs/commands, even ssh, ftp, telnet, etc. You can just type something like:",
                "If you need the output from the command you are calling,\nthen you can use subprocess.check_output (Python 2.7+).Also note the shell parameter.If shell is True, the specified command will be executed through the shell. This can be useful if you are using Python primarily for the enhanced control flow it offers over most system shells and still want convenient access to other shell features such as shell pipes, filename wildcards, environment variable expansion, and expansion of ~ to a user\u2019s home directory. However, note that Python itself offers implementations of many shell-like features (in particular, glob, fnmatch, os.walk(), os.path.expandvars(), os.path.expanduser(), and shutil).",
                "subprocess.run is the recommended approach as of Python 3.5 if your code does not need to maintain compatibility with earlier Python versions. It's more consistent and offers similar ease-of-use as Envoy. (Piping isn't as straightforward though. See this question for how.)Here's some examples from the documentation.Run a process:Raise on failed run:Capture output:I recommend trying Envoy. It's a wrapper for subprocess, which in turn aims to replace the older modules and functions. Envoy is subprocess for humans.Example usage from the README:Pipe stuff around too:",
                "This is how I run my commands. This code has everything you need pretty much",
                "Simple, use subprocess.run, which returns a CompletedProcess object:(run wants a list of lexically parsed shell arguments - this is what you'd type in a shell, separated by spaces, but not where the spaces are quoted, so use a specialized function, split, to split up what you would literally type into your shell)As of Python 3.5, the documentation recommends subprocess.run:The recommended approach to invoking subprocesses is to use the run() function for all use cases it can handle. For more advanced use cases, the underlying Popen interface can be used directly.Here's an example of the simplest possible usage - and it does exactly as asked:run waits for the command to successfully finish, then returns a CompletedProcess object. It may instead raise TimeoutExpired (if you give it a timeout= argument) or CalledProcessError (if it fails and you pass check=True).As you might infer from the above example, stdout and stderr both get piped to your own stdout and stderr by default.We can inspect the returned object and see the command that was given and the returncode:If you want to capture the output, you can pass subprocess.PIPE to the appropriate stderr or stdout:And those respective attributes return bytes.One might easily move from manually providing a command string (like the question suggests) to providing a string built programmatically. Don't build strings programmatically. This is a potential security issue. It's better to assume you don't trust the input.Note, only args should be passed positionally.Here's the actual signature in the source and as shown by help(run):The popenargs and kwargs are given to the Popen constructor. input can be a string of bytes (or unicode, if specify encoding or universal_newlines=True) that will be piped to the subprocess's stdin.The documentation describes timeout= and check=True better than I could:The timeout argument is passed to Popen.communicate(). If the timeout\nexpires, the child process will be killed and waited for. The\nTimeoutExpired exception will be re-raised after the child process has\nterminated.If check is true, and the process exits with a non-zero exit code, a\nCalledProcessError exception will be raised. Attributes of that\nexception hold the arguments, the exit code, and stdout and stderr if\nthey were captured.and this example for check=True is better than one I could come up with:Here's an expanded signature, as given in the documentation:Note that this indicates that only the args list should be passed positionally. So pass the remaining arguments as keyword arguments.When use Popen instead? I would struggle to find use-case based on the arguments alone. Direct usage of Popen would, however, give you access to its methods, including poll, 'send_signal', 'terminate', and 'wait'.Here's the Popen signature as given in the source. I think this is the most precise encapsulation of the information (as opposed to help(Popen)):But more informative is the Popen documentation:Execute a child program in a new process. On POSIX, the class uses\nos.execvp()-like behavior to execute the child program. On Windows,\nthe class uses the Windows CreateProcess() function. The arguments to\nPopen are as follows.Understanding the remaining documentation on Popen will be left as an exercise for the reader.",
                "Use subprocess....or for a very simple command:",
                "As of Python 3.7.0 released on June 27th 2018 (https://docs.python.org/3/whatsnew/3.7.html), you can achieve your desired result in the most powerful while equally simple way. This answer intends to show you the essential summary of various options in a short manner. For in-depth answers, please see the other ones.The big advantage of os.system(...) was its simplicity. subprocess is better and still easy to use, especially as of Python 3.5.Note: This is the exact answer to your question - running a commandlike in a shellIf possible, remove the shell overhead and run the command directly (requires a list).Pass program arguments in a list. Don't include \\\"-escaping for arguments containing spaces.The following code speaks for itself:result.stdout is all normal program output excluding errors. Read result.stderr to get them.capture_output=True - turns capturing on. Otherwise result.stderr and result.stdout would be None. Available from Python 3.7.text=True - a convenience argument added in Python 3.7 which converts the received binary data to Python strings you can easily work with.DoIf you just want to check if the program succeeded (returncode == 0) and otherwise throw an Exception, there is a more convenient function:But it's Python, so there's an even more convenient argument check which does the same thing automatically for you:You might want to have all program output inside stdout, even errors. To accomplish this, runresult.stderr will then be None and result.stdout will contain everything.shell=False expects a list of arguments. You might however, split an argument string on your own using shlex.That's it.Chances are high you just started using Python when you come across this question. Let's look at some common problems.FileNotFoundError: [Errno 2] No such file or directory: 'ls -a': 'ls -a'You're running a subprocess without shell=True . Either use a list ([\"ls\", \"-a\"]) or set shell=True.TypeError: [...] NoneType [...]Check that you've set capture_output=True.TypeError: a bytes-like object is required, not [...]You always receive byte results from your program. If you want to work with it like a normal string, set text=True.subprocess.CalledProcessError: Command '[...]' returned non-zero exit status 1.Your command didn't run successfully. You could disable returncode checking or check your actual program's validity.TypeError: init() got an unexpected keyword argument [...]You're likely using a version of Python older than 3.7.0; update it to the most recent one available. Otherwise there are other answers in this Stack Overflow post showing you older alternative solutions.",
                "os.system is OK, but kind of dated.  It's also not very secure.  Instead, try subprocess.  subprocess does not call sh directly and is therefore more secure than os.system.Get more information here.",
                "There is also Plumbum",
                "Use:os - This module provides a portable way of using operating system-dependent functionality.For the more os functions, here is the documentation.",
                "It can be this simple:",
                "There is another difference here which is not mentioned previously.subprocess.Popen executes the <command> as a subprocess. In my case, I need to execute file <a> which needs to communicate with another program, <b>.I tried subprocess, and execution was successful. However <b> could not communicate with <a>.\nEverything is normal when I run both from the terminal.One more: \n(NOTE: kwrite behaves different from other applications. If you try the below with Firefox, the results will not be the same.)If you try os.system(\"kwrite\"), program flow freezes until the user closes kwrite. To overcome that I tried instead os.system(konsole -e kwrite). This time program continued to flow, but kwrite became the subprocess of the console.Anyone runs the kwrite not being a subprocess (i.e. in the system monitor it must appear at the leftmost edge of the tree).",
                "os.system does not allow you to store results, so if you want to store results in some list or something, a subprocess.call works.",
                "subprocess.check_call is convenient if you don't want to test return values. It throws an exception on any error.",
                "I tend to use subprocess together with shlex (to handle escaping of quoted strings):",
                "I wrote a library for this, shell.py.It's basically a wrapper for popen and shlex for now. It also supports piping commands, so you can chain commands easier in Python. So you can do things like:",
                "In Windows you can just import the subprocess module and run external commands by calling subprocess.Popen(), subprocess.Popen().communicate() and subprocess.Popen().wait() as below:Output:",
                "Under Linux, in case you would like to call an external command that will execute independently (will keep running after the Python script terminates), you can use a simple queue as task spooler or the at command.An example with task spooler:Notes about task spooler (ts):You could set the number of concurrent processes to be run (\"slots\") with:ts -S <number-of-slots>Installing ts doesn't requires admin privileges. You can download and compile it from source with a simple make, add it to your path and you're done.",
                "Invoke is a Python (2.7 and 3.4+) task execution tool and library. It provides a clean, high-level API for running shell commands:",
                "You can use Popen, and then you can check the procedure's status:Check out subprocess.Popen."
            ]
        },
        {
            "tag": "git",
            "question": [
                "How do I change the URI (URL) for a remote Git repository?",
                "I have a repo (origin) on a USB key that I cloned on my hard drive (local). I moved \"origin\" to a NAS and successfully tested cloning it from here.\nI would like to know if I can change the ..."
            ],
            "url": "https://stackoverflow.com/questions/2432764",
            "answer": [
                "You canSee git help remote. You also can edit .git/config and change the URLs there.You're not in any danger of losing history unless you do something very silly (and if you're worried, just make a copy of your repo, since your repo is your history.)",
                "Changing a remote's URL",
                "git remote set-url {name} {url}",
                "Change Host for a Git Origin Serverfrom: http://pseudofish.com/blog/2010/06/28/change-host-for-a-git-origin-server/Hopefully this isn\u2019t something you need to do. The server that I\u2019ve been using to collaborate on a few git projects with had the domain name expire. This meant finding a way of migrating the local repositories to get back in sync.Update: Thanks to @mawolf for pointing out there is an easy way with recent git versions (post Feb, 2010):See the man page for details.If you\u2019re on an older version, then try this:As a caveat, this works only as it is the same server, just with different names.Assuming that the new hostname is newhost.com, and the old one was oldhost.com, the change is quite simple.Edit the .git/config file in your working directory. You should see something like:Change oldhost.com to newhost.com, save the file and you\u2019re done.From my limited testing (git pull origin; git push origin; gitx) everything seems in order. And yes, I know it is bad form to mess with git internals.",
                "This is very easy and simple; just follow these instructions.",
                "Open Terminal.Ist Step:- Change the current working directory to your local project.2nd Step:- List your existing remotes in order to get the name of the remote you want to change.git remote -vChange your remote's URL from HTTPS to SSH with the git remote set-url command.3rd Step:-  git remote set-url origin git@github.com:USERNAME/REPOSITORY.git4th Step:- Now Verify that the remote URL has changed.git remote -v\nVerify new remote URL",
                "(alternatively, open .git/config, look for [remote \"origin\"], and edit the url = line.You can check it worked by examining the remotes:Next time you push, you'll have to specify the new upstream branch, e.g.:See also: GitHub: Changing a remote's URL",
                "As seen here,",
                "First you need to type this command to view existing remotesgit remote -vThen second you need to type this command to Change the 'origin' remote's URLgit remote set-url origin <paste your GitHub URL>",
                "Write the below command from your repo terminal:Refer this link for more details about changing the url in the remote.",
                "To check git remote connection:Now, set the local repository to remote git:Now to make it upstream or push use following code:git push --set-upstream origin master -f",
                "Navigate to the project root of the local repository and check for existing remotes:If your repository is using SSH you will see something like:And if your repository is using HTTPS you will see something like:Changing the URL is done with git remote set-url. Depending on the output of git remote -v, you can change the URL in the following manner:In case of SSH, you can change the URL from REPOSITORY.git to NEW_REPOSITORY.git like:And in case of HTTPS, you can change the URL from REPOSITORY.git to NEW_REPOSITORY.git like:NOTE: If you've changed your GitHub username, you can follow the same process as above to update the change in the username associated with your repository. You would only have to update the USERNAME in the git remote set-url command.",
                "if you cloned your local will automatically consist,remote URL where it gets  cloned.you can check  it using git remote -vif you want to made change in it,here,origin - your branchif you want to overwrite existing branch you can still use it.. it will override your existing ... it will do,for you...",
                "Troubleshooting :You may encounter these errors when trying to changing a remote.\nNo such remote '[name]'This error means that the remote you tried to change doesn't exist:git remote set-url sofake https://github.com/octocat/Spoon-Knife\nfatal: No such remote 'sofake'Check that you've correctly typed the remote name.Reference : https://help.github.com/articles/changing-a-remote-s-url/",
                "I worked:",
                "In the Git Bash, enter the command:git remote set-url origin https://NewRepoLink.gitEnter the CredentialsDone",
                "You have a lot of ways to do that:ConsoleJust be sure that you've opened it in a place where a repository is.ConfigIt is placed in .git/config (same folder as repository)TortoiseGitThen just edit URL.SourceTreeClick on the \"Settings\" button on the toolbar to open the Repository Settings window.Click \"Add\" to add a remote repository path to the repository. A \"Remote details\" window will open.Enter a name for the remote path.Enter the URL/Path for the remote repositoryEnter the username for the hosting service for the remote repository.Click 'OK' to add the remote path.Back on the Repository Settings window, click 'OK'. The new remote path should be added on the repository now.If you need to edit an already added remote path, just click the 'Edit' button. You should be directed to the \"Remote details\" window where you can edit the details (URL/Path/Host Type) of the remote path.To remove a remote repository path, click the 'Remove' buttonref. Support",
                "For me, the accepted answer worked only in the case of fetch but not pull. I did the following to make it work for push as well.So to update the fetch URL:To update the pull URL:",
                "Change remote git URI to git@github.com rather than https://github.comExample:The benefit is that you may do git push automatically when you use ssh-agent :Put a script file $HOME/.ssh/agent to let it runs ssh-add using expect as below:",
                "To change the remote upstream:\ngit remote set-url origin <url>To add more upstreams:\ngit remote add newplace <url>So you can choose where to work\ngit push origin <branch> or git push newplace <branch>",
                "You can change the url by editing the config file.\nGo to your project root:Then edit the url field and set your new url. \nSave the changes. You can verify the changes by using the command.",
                "An alternative approach is to rename the 'old' origin (in the example below I name it simply old-origin) and adding a new one. This might be the desired approach if you still want to be able to push to the old origin every now and then:And in case you need to push your local state to the new origin:",
                "If you're using TortoiseGit then follow the below steps:Your branch and all your local commits will remain intact and you can keep working as you were before.",
                "Removing a remoteUse the git remote rm command to remove a remote URL from your repository.",
                "If you would like to set the username and password as well in the origin url, you can follow the below steps.Exporting the password in a variable would avoid issues with special characters.Steps:",
                "check your privilegein my case i need to check  my usernamei have two or three repository with seperate credentials.problem is my permission i have two private git server and repositoriesthis second account is admin of that new repo and first one is my default user account and i should grant permission to first",
                "For those who want to make this change from Visual Studio 2019Open Team Explorer (Ctrl+M)Home -> SettingsGit -> Repository SettingsRemotes -> Edit",
                "If your repository is private thenReference"
            ]
        },
        {
            "tag": "javascript",
            "question": [
                "Which equals operator (== vs ===) should be used in JavaScript comparisons?",
                "I'm using JSLint to go through JavaScript, and it's returning many suggestions to replace == (two equals signs) with === (three equals signs) when doing things like comparing idSele_UNVEHtype.value...."
            ],
            "url": "https://stackoverflow.com/questions/359494",
            "answer": [
                "The strict equality operator (===) behaves identically to the abstract equality operator (==) except no type conversion is done, and the types must be the same to be considered equal.Reference: Javascript Tutorial: Comparison OperatorsThe == operator will compare for equality after doing any necessary type conversions.  The === operator will not do the conversion, so if two values are not the same type === will simply return false. Both are equally quick.To quote Douglas Crockford's excellent JavaScript: The Good Parts,JavaScript has two sets of equality operators: === and !==, and their evil twins == and !=.  The good ones work the way you would expect.  If the two operands are of the same type and have the same value, then === produces true and !== produces false.  The evil twins do the right thing when the operands are of the same type, but if they are of different types, they attempt to coerce the values.  the rules by which they do that are complicated and unmemorable.  These are some of the interesting cases:The lack of transitivity is alarming.  My advice is to never use the evil twins.  Instead, always use === and !==.  All of the comparisons just shown produce false with the === operator.A good point was brought up by @Casebash in the comments and in @Phillipe Laybaert's answer concerning objects.  For objects, == and === act consistently with one another (except in a special case).The special case is when you compare a primitive with an object that evaluates to the same primitive, due to its toString or valueOf method. For example, consider the comparison of a string primitive with a string object created using the String constructor.Here the == operator is checking the values of the two objects and returning true, but the === is seeing that they're not the same type and returning false.  Which one is correct?  That really depends on what you're trying to compare.  My advice is to bypass the question entirely and just don't use the String constructor to create string objects from string literals.Reference\nhttp://www.ecma-international.org/ecma-262/5.1/#sec-11.9.3",
                "This is because the equality operator == does type coercion, meaning that the interpreter implicitly tries to convert the values before comparing.On the other hand, the identity operator === does not do type coercion, and thus does not convert the values when comparing.",
                "Here's an interesting visualisation of the equality comparison between == and ===.Source: https://github.com/dorey/JavaScript-Equality-Table (demo, unified demo)When using === for JavaScript equality testing, everything is as is.\nNothing gets converted before being evaluated.When using == for JavaScript equality testing, some funky conversions take place.Always use ===, unless you fully understand the funky conversions that take place with ==.",
                "In the answers here, I didn't read anything about what equal means. Some will say that === means equal and of the same type, but that's not really true. It actually means that both operands reference the same object, or in case of value types, have the same value.So, let's take the following code:The same here:Or even:This behavior is not always obvious. There's more to the story than being equal and being of the same type.The rule is:For value types (numbers):\na === b returns true if a and b have the same value and are of the same typeFor reference types:\na === b returns true if a and b reference the exact same objectFor strings:\na === b returns true if a and b are both strings and contain the exact same charactersStrings are not value types, but in Javascript they behave like value types, so they will be \"equal\" when the characters in the string are the same and when they are of the same length (as explained in the third rule)Now it becomes interesting:But how about this?:I thought strings behave like value types? Well, it depends who you ask... In this case a and b are not the same type. a is of type Object, while b is of type string. Just remember that creating a string object using the String constructor creates something of type Object that behaves as a string most of the time.",
                "Let me add this counsel:If in doubt, read the specification!ECMA-262 is the specification for a scripting language of which JavaScript is a dialect. Of course in practice it matters more how the most important browsers behave than an esoteric definition of how something is supposed to be handled. But it is helpful to understand why new String(\"a\") !== \"a\".Please let me explain how to read the specification to clarify this question. I see that in this very old topic nobody had an answer for the very strange effect. So, if you can read a specification, this will help you in your profession tremendously. It is an acquired skill. So, let's continue.Searching the PDF file for === brings me to page 56 of the specification: 11.9.4. The Strict Equals Operator ( === ), and after wading through the specificationalese I find:11.9.6 The Strict Equality Comparison Algorithm\nThe comparison x === y, where x and y are values, produces true or false. Such a comparison is performed as follows:\n\u00a0\u00a01. If Type(x) is different from Type(y), return false.\n\u00a0\u00a02. If Type(x) is Undefined, return true.\n\u00a0\u00a03. If Type(x) is Null, return true.\n\u00a0\u00a04. If Type(x) is not Number, go to step 11.\n\u00a0\u00a05. If x is NaN, return false.\n\u00a0\u00a06. If y is NaN, return false.\n\u00a0\u00a07. If x is the same number value as y, return true.\n\u00a0\u00a08. If x is +0 and y is \u22120, return true.\n\u00a0\u00a09. If x is \u22120 and y is +0, return true.\n\u00a0\u00a010. Return false.\n\u00a0\u00a011. If Type(x) is String, then return true if x and y are exactly the same sequence of characters (same length and same characters in corresponding positions); otherwise, return false.\n\u00a0\u00a012. If Type(x) is Boolean, return true if x and y are both true or both false; otherwise, return false.\n\u00a0\u00a013. Return true if x and y refer to the same object or if they refer to objects joined to each other (see 13.1.2). Otherwise, return false.Interesting is step 11. Yes, strings are treated as value types. But this does not explain why new String(\"a\") !== \"a\". Do we have a browser not conforming to ECMA-262?Not so fast!Let's check the types of the operands. Try it out for yourself by wrapping them in typeof(). I find that new String(\"a\") is an object, and step 1 is used: return false if the types are different.If you wonder why new String(\"a\") does not return a string, how about some exercise reading a specification? Have fun!Aidiakapi wrote this in a comment below:From the specification11.2.2 The new Operator:If Type(constructor) is not Object, throw a TypeError exception.With other words, if String wouldn't be of type Object it couldn't be used with the new operator.new always returns an Object, even for String constructors, too. And alas! The value semantics for strings (see step 11) is lost.And this finally means: new String(\"a\") !== \"a\".",
                "I tested this in Firefox with Firebug using code like this:console.time(\"testEquality\");\nvar n = 0;\nwhile (true) {\n  n++;\n  if (n == 100000)\n    break;\n}\nconsole.timeEnd(\"testEquality\");andconsole.time(\"testTypeEquality\");\nvar n = 0;\nwhile (true) {\n  n++;\n  if (n === 100000)\n    break;\n}\nconsole.timeEnd(\"testTypeEquality\");My results (tested five times each and averaged):So I'd say that the miniscule difference (this is over 100000 iterations, remember) is negligible. Performance isn't a reason to do ===. Type safety (well, as safe as you're going to get in JavaScript), and code quality is.",
                "In PHP and JavaScript, it is a strict equality operator. Which means, it will compare both type and values.",
                "In JavaScript it means of the same value and type.For example,but",
                "Why == is so unpredictable?What do you get when you compare an empty string \"\" with the number zero 0?trueYep, that's right according to == an empty string and the number zero are the same time.And it doesn't end there, here's another one:Things get really weird with arrays.Then weirder with stringsIt get's worse:When is equal not equal?Let me say that again:And this is just the crazy stuff you get with primitives.It's a whole new level of crazy when you use == with objects.At this point your probably wondering...Why does this happen?Well it's because unlike \"triple equals\" (===) which just checks if two values are the same.== does a whole bunch of other stuff.It has special handling for functions, special handling for nulls, undefined, strings, you name it.It get's pretty wacky.In fact, if you tried to write a function that does what == does it would look something like this:So what does this mean?It means == is complicated.Because it's complicated it's hard to know what's going to happen when you use it.Which means you could end up with bugs.So the moral of the story is...Make your life less complicated.Use === instead of ==.The End.",
                "The === operator is called a strict comparison operator, it does differ from the == operator.Lets take 2 vars a and b.For \"a == b\" to evaluate to true a and b need to be the same value.In the case of \"a === b\" a and b must be the same value and also the same type for it to evaluate to true.Take the following exampleIn summary; using the == operator might evaluate to true in situations where you do not want it to so using the === operator would be safer.In the 90% usage scenario it won't matter which one you use, but it is handy to know the difference when you get some unexpected behaviour one day.",
                "Many times an untyped check would be handy because you do not care if the value is either undefined, null, 0  or \"\"",
                "Javascript execution flow diagram for strict equality / Comparison '==='Javascript execution flow diagram for non strict equality / comparison '=='",
                "JavaScript === vs == .",
                "It means equality without type coercion\ntype coercion means JavaScript do not automatically convert any other data types to string data types",
                "In a typical script there will be no performance difference. More important may be the fact that thousand \"===\" is 1\u00a0KB heavier than thousand \"==\" :) JavaScript profilers can tell you if there is a performance difference in your case.But personally I would do what JSLint suggests. This recommendation is there not because of performance issues, but because type coercion means ('\\t\\r\\n' == 0) is true.",
                "The equal comparison operator == is confusing and should be avoided.If you HAVE TO live with it, then remember the following 3 things:EQUAL OPERATOR TRUTH TABLE IN JAVASCRIPT** STRANGE: note that any two values on the first column are not equal in that sense.**",
                "There is unlikely to be any performance difference between the two operations in your usage. There is no type-conversion to be done because both parameters are already the same type. Both operations will have a type comparison followed by a value comparison.",
                "Yes! It does matter.=== operator in javascript checks value as well as type where as == operator just checks the value (does type conversion if required).You can easily test it. Paste following code in an HTML file and open it in browserYou will get 'false' in alert. Now modify the onPageLoad() method to alert(x == 5); you will get true.",
                "Simply== means comparison between operands with type coercionand=== means comparison between operands without type coercion.Type coercion in JavaScript means automatically converting data types to other data types.For example:",
                "As a rule of thumb, I would generally use === instead of == (and !== instead of !=).Reasons are explained in in the answers above and also Douglas Crockford is pretty clear about it (JavaScript: The Good Parts).However there is one single exception:\n== null is an efficient way to check for 'is null or undefined':For example jQuery 1.9.1 uses this pattern 43 times, and  the JSHint syntax checker even provides the eqnull relaxing option for this reason.From the jQuery style guide:Strict equality checks (===) should be used in favor of ==. The only\nexception is when checking for undefined and null by way of null.EDIT 2021-03:Nowadays most browsers\nsupport the Nullish coalescing operator (??)\nand the Logical nullish assignment (??=), which allows a more concise way to\nassign a default value if a variable is null or undefined, for example:can be written as any of these forms",
                "It's a strict check test.It's a good thing especially if you're checking between 0 and false and null.For example, if you have:Then:All returns true and you may not want this. Let's suppose you have a function that can return the 0th index of an array or false on failure. If you check with \"==\" false, you can get a confusing result.So with the same thing as above, but a strict test:",
                "=== operator  checks the values as well as the types of the variables for equality.== operator just checks the value of the variables for equality.",
                "JSLint sometimes gives you unrealistic reasons to modify stuff. === has exactly the same performance as == if the types are already the same.It is faster only when the types are not the same, in which case it does not try to convert types but directly returns a false.So, IMHO, JSLint maybe used to write new code, but useless over-optimizing should be avoided at all costs.Meaning, there is no reason to change == to === in a check like if (a == 'test') when you know it for a fact that a can only be a String.Modifying a lot of code that way wastes developers' and reviewers' time and achieves nothing.",
                "A simple example is",
                "The top 2 answers both mentioned == means equality and === means identity. Unfortunately, this statement is incorrect.If both operands of == are objects, then they are compared to see if they are the same object. If both operands point to the same object, then the equal operator returns true. Otherwise,\nthe two are not equal.In the code above, both == and === get false because a and b are not the same objects.That's to say: if both operands of == are objects, == behaves same as ===, which also means identity. The essential difference of this two operators is about type conversion. == has conversion before it checks equality, but === does not.",
                "The problem is that you might easily get into trouble since JavaScript have a lot of implicit conversions meaning...Which pretty soon becomes a problem. The best sample of why implicit conversion is \"evil\" can be taken from this code in MFC / C++ which actually will compile due to an implicit conversion from CString to HANDLE which is a pointer typedef type...Which obviously during runtime does very undefined things...Google for implicit conversions in C++ and STL to get some of the arguments against it...",
                "From the core javascript reference=== Returns true if the operands are strictly equal (see above)\n  with no type conversion.",
                "Equality comparison:Operator ==Returns true, when both operands are equal. The operands are converted to the same type before being compared.Equality and type comparison:Operator ===Returns true if both operands are equal and of the same type. It's generally \nbetter and safer if you compare this way, because there's no behind-the-scenes type conversions.",
                "Here is a handy comparison table that shows the conversions that happen and the differences between == and ===.As the conclusion states:\"Use three equals unless you fully understand the conversions that take\n  place for two-equals.\"http://dorey.github.io/JavaScript-Equality-Table/",
                "null and undefined are nothingness, that is,Here a and b do not have values. Whereas, 0, false and '' are all values. One thing common beween all these are that they are all falsy values, which means they all satisfy falsy conditions.So, the 0, false and '' together form a sub-group. And on other hand, null & undefined form the second sub-group. Check the comparisons in the below image. null and undefined would equal. The other three would equal to each other. But, they all are treated as falsy conditions in JavaScript.This is same as any object (like {}, arrays, etc.), non-empty string & Boolean true are all truthy conditions. But, they are all not equal."
            ]
        },
        {
            "tag": "http",
            "question": [
                "What is the maximum length of a URL in different browsers?",
                "What is the maximum length of a URL for each browser?\nIs a maximum URL length part of the HTTP specification?"
            ],
            "url": "https://stackoverflow.com/questions/417142",
            "answer": [
                "If you keep URLs under 2000 characters, they'll work in virtually any combination of client and server software.If you are targeting particular browsers, see below for more details on specific limits.RFC 2616 (Hypertext Transfer Protocol HTTP/1.1) section 3.2.1 saysThe HTTP protocol does not place\nany a priori limit on the length of\na URI. Servers MUST be able to handle\nthe URI of any resource they    serve,\nand SHOULD be able to handle URIs of\nunbounded length if they    provide\nGET-based forms that could generate\nsuch URIs. A server    SHOULD return\n414 (Request-URI Too Long) status if a\nURI is longer    than the server can\nhandle (see section 10.4.15).That RFC has been obsoleted by RFC7230 which is a refresh of the HTTP/1.1 specification. It contains similar language, but also goes on to suggest this:Various ad hoc limitations on request-line length are found in\npractice. It is RECOMMENDED that all HTTP senders and recipients\nsupport, at a minimum, request-line lengths of 8000 octets.That's what the standards say. For the reality, there was an article on boutell.com (link goes to Internet Archive backup) that discussed what individual browser and server implementations will support. The executive summary is:Extremely long URLs are usually a\nmistake. URLs over 2,000 characters\nwill not work in the most popular web\nbrowsers. Don't use them if you intend\nyour site to work for the majority of\nInternet users.(Note: this is a quote from an article written in 2006, but in 2015 IE's declining usage means that longer URLs do work for the majority. However, IE still has the limitation...)IE8's maximum URL length is 2083 chars, and it seems IE9 has a similar limit.I've tested IE10 and the address bar will only accept 2083 chars. You can click a URL which is longer than this, but the address bar will still only show 2083 characters of this link.There's a nice writeup on the IE Internals blog which goes into some of the background to this.There are mixed reports IE11 supports longer URLs - see comments below. Given some people report issues, the general advice still stands.Be aware that the sitemaps protocol, which allows a site to inform search engines about available pages, has a limit of 2048 characters in a URL. If you intend to use sitemaps, a limit has been decided for you! (see Calin-Andrei Burloiu's answer below)There's also some research from 2010 into the maximum URL length that search engines will crawl and index. They found the limit was 2047 chars, which appears allied to the sitemap protocol spec. However, they also found the Google SERP tool wouldn't cope with URLs longer than 1855 chars.CDNs also impose limits on URI length, and will return a 414 Too long request when these limits are reached, for example:(credit to timrs2998 for providing that info in the comments)I tested the following against an Apache 2.4 server configured with a very large LimitRequestLine and LimitRequestFieldSize.See also this answer from Matas Vaitkevicius below.This is a popular question, and as the original research is ~14 years old I'll try to keep it up to date: As of Jan 2021, the advice still stands. Even though IE11 may possibly accept longer URLs, the ubiquity of older IE installations plus the search engine limitations mean staying under 2000 chars is the best general policy.",
                "The longest URLs I came across are data URLsExample image URL from Google image results (11747 characters)",
                "I wrote this test that keeps on adding 'a' to parameter until the browser failsC# part:View:PART 1On Chrome I got:It then blew up with:HTTP Error 404.15 - Not Found The request filtering module is\n  configured to deny a request where the query string is too long.Same on Internet\u00a0Explorer\u00a08 and FirefoxPART 2I went easy mode and added additional limits to IISExpress applicationhost.config and web.config setting maxQueryStringLength=\"32768\".after 7744 characters.PART 3Addedwhich didn't help at all. I finally decided to use fiddler to remove the referrer from header.Which did nicely.Chrome: got to 15613 characters. (I guess it's a 16K limit for IIS)And it failed again with:Firefox:Internet Explorer 8 failed with iexplore.exe crashing.After 2505Android EmulatorInternet Explorer 11Internet Explorer 10Internet Explorer 9",
                "WWW FAQs: What is the maximum length of a URL? has its own answer based on empirical testing and research. The short answer is that going over 2048 characters makes Internet\u00a0Explorer unhappy and thus this is the limit you should use. See the page for a long answer.",
                "On Apple platforms (iOS/macOS/tvOS/watchOS), the limit may be a 2 GB long URL scheme, as seen by this comment in the source code of Swift:On iOS, I've tested and confirmed that even a 300+ MB long URL is accepted. You can try such a long URL like this in Objective-C:And catch if it succeed with:",
                "There is really no universal maximum URL length. The max length is determined only by what the client browser chooses to support, which varies widely. The 2,083 limit is only present in Internet Explorer (all versions up to 7.0). The max length in Firefox and Safari seems to be unlimited, although instability occurs with URLs reaching around 65,000 characters.\nOpera seems to have no max URL length whatsoever, and doesn't suffer instability at extremely long lengths.",
                "The URI RFC (of which URLs are a subset) doesn't define a maximum length, however, it does recommend that the hostname part of the URI (if applicable) not exceed 255 characters in length:URI producers should use names that\nconform to the DNS syntax, even when\nuse of DNS is not immediately\napparent, and should limit these names\nto no more than 255 characters in\nlength.As noted in other posts though, some browsers have a practical limitation on the length of a URL.",
                "The HTTP 1.1 specification says:URIs in HTTP can be represented in\n  absolute form or relative to some\n  known base URI [11], depending upon\n  the context of their use. The two\n  forms are differentiated by the fact\n  that absolute URIs always begin\n  with a scheme name followed by a\n  colon. For definitive information on\n  URL syntax and semantics, see \"Uniform\n  Resource Identifiers (URI):    Generic\n  Syntax and Semantics,\" RFC 2396 [42]\n  (which replaces RFCs    1738 [4] and\n  RFC 1808 [11]). This specification\n  adopts the    definitions of\n  \"URI-reference\", \"absoluteURI\",\n  \"relativeURI\", \"port\",\n  \"host\",\"abs_path\", \"rel_path\", and\n  \"authority\" from that\n  specification.The HTTP protocol does not place\n  any a priori limit on the length of\n  a URI. Servers MUST be able to handle\n  the URI of any resource they    serve,\n  and SHOULD be able to handle URIs of\n  unbounded length if they    provide\n  GET-based forms that could generate\n  such URIs.* A server    SHOULD return\n  414 (Request-URI Too Long) status if a\n  URI is longer    than the server can\n  handle (see section 10.4.15).Note: Servers ought to be cautious about depending on URI\n  lengths\n        above 255 bytes, because some older client or proxy\n        implementations might not properly support these lengths.As mentioned by @Brian, the HTTP clients (e.g. browsers) may have their own limits, and HTTP servers will have different limits.",
                "Microsoft Support says \"Maximum URL length is 2,083 characters in Internet Explorer\".IE has problems with URLs longer than that. Firefox seems to work fine with >4k chars.",
                "In URL as UI Jakob Nielsen recommends:the social interface to the Web relies on email when users want to recommend Web pages to each other, and email is the second-most common way users get to new sites (search engines being the most common): make sure that all URLs on your site are less than 78 characters long so that they will not wrap across a line feed.This is not the maximum but I'd consider this a practical maximum if you want your URL to be shared.",
                "Sitemaps protocol, which is a way for webmasters to inform search engines about pages on their sites (also used by Google in Webmaster Tools), supports URLs with less than 2048 characters. So if you are planning to use this feature for Search Engine Optimization, take this into account.",
                "ASP.NET 2 and SQL Server reporting services 2005 have a limit of 2028. I found this out the hard way, where my dynamic URL generator would not pass over some parameters to a report beyond that point. This was under Internet\u00a0Explorer\u00a08.",
                "Why is the Internet\u00a0Explorer limit only 2K while IIS has a limit of 16K? I don't think it makes sense.So I want to start an experiment about Ajax request URL size limits.I have set my Tomcat HTTP connector's maxHttpHeaderSize=\"1048576\". And prepared a very long URL.Then I send a request with the long URL like the following:jQuery reports done. Tomcat reports the URL requested is 1048015 bytes. It was tested with Chrome 50 and Internet\u00a0Explorer\u00a011.So web browsers won't truncate or limit your URL intentionally when sending Ajax requests.",
                "Limit request line directive sets the maximum length of a URL. By default, it is set to 8190, which gives you a lot of room. However other servers and some browses, limit the length more.Because all parameters are passed on the URL line, items that were in password of hidden fields will also be displayed in the URL of course. Neither mobile should be used for real security measures and should be considered cosmetic security at best.",
                "It seems that Chrome at least has raised this limit. I pasted 20,000 characters into the bookmarklet and it took it.",
                "I have experience with SharePoint 2007, 2010 and there is a limit of the length URL you can create from the server side in this case SharePoint, so it depends mostly on, 1) the client (browser, version, and OS) and 2) the server technology, IIS, Apache, etc.",
                "According to the HTTP spec, there is no limit to a URL's length. Keep your URLs under 2048 characters; this will ensure the URLs work in all clients & server configurations. Also, search engines like URLs to remain under approximately 2000 characters."
            ]
        },
        {
            "tag": "javascript",
            "question": [
                "Loop over an array in JavaScript",
                "How can I loop through all the entries in an array using JavaScript?"
            ],
            "url": "https://stackoverflow.com/questions/9329446",
            "answer": [
                "TL;DRYour best bets are usuallySome quick \"don't\"s:But there's lots more to explore, read on...JavaScript has powerful semantics for looping through arrays and array-like objects. I've split the answer into two parts: Options for genuine arrays, and options for things that are just array-like, such as the arguments object, other iterable objects (ES2015+), DOM collections, and so on.Okay, let's look at our options:You have five options (two supported basically forever, another added by ECMAScript\u00a05 [\"ES5\"], and two more added in ECMAScript\u00a02015 (\"ES2015\", aka \"ES6\"):(You can see those old specs here: ES5, ES2015, but both have been superceded; the current editor's draft is always here.)Details:ES2015 added iterators and iterables to JavaScript. Arrays are iterable (so are strings, Maps, and Sets, as well as DOM collections and lists, as you'll see later). Iterable objects provide iterators for their values. The new for-of statement loops through the values returned by an iterator:const a = [\"a\", \"b\", \"c\"];\nfor (const element of a) { // You can use `let` instead of `const` if you like\n    console.log(element);\n}\n// a\n// b\n// cIt doesn't get simpler than that! Under the covers, that gets an iterator from the array and loops through the values the iterator returns. The iterator provided by arrays provides the values of the array elements, in order beginning to end.Notice how element is scoped to each loop iteration; trying to use element after the end of the loop would fail because it doesn't exist outside the loop body.In theory, a for-of loop involves several function calls (one to get the iterator, then one to get each value from it). Even when that's true, it's nothing to worry about, function calls are very cheap in modern JavaScript engines (it bothered me for forEach [below] until I looked into it; details). But additionally, JavaScript engines optimize those calls away (in performance-critical code) when dealing with native iterators for things like arrays.for-of is entirely async-friendly. If you need the work in a loop body to be done in series (not in parallel), an await in the loop body will wait for the promise to settle before continuing. Here's a silly example:function delay(ms) {\n    return new Promise(resolve => {\n        setTimeout(resolve, ms);\n    });\n}\n\nasync function showSlowly(messages) {\n    for (const message of messages) {\n        await delay(400);\n        console.log(message);\n    }\n}\n\nshowSlowly([\n    \"So\", \"long\", \"and\", \"thanks\", \"for\", \"all\", \"the\", \"fish!\"\n]);\n// `.catch` omitted because we know it never rejectsNote how the words appear with a delay before each one.It's a matter of coding style, but for-of is the first thing I reach for when looping through anything iterable.In any even vaguely-modern environment (so, not IE8) where you have access to the Array features added by ES5, you can use forEach (spec | MDN) if you're only dealing with synchronous code (or you don't need to wait for an asynchronous process to finish during the loop):const a = [\"a\", \"b\", \"c\"];\na.forEach((element) => {\n    console.log(element);\n});forEach accepts a callback function and, optionally, a value to use as this when calling that callback (not used above). The callback is called for each element in the array, in order, skipping non-existent elements in sparse arrays. Although I only used one parameter above, the callback is called with three arguments: The element for that iteration, the index of that element, and a reference to the array you're iterating over (in case your function doesn't already have it handy).Like for-of, forEach has the advantage that you don't have to declare indexing and value variables in the containing scope; in this case, they're supplied as arguments to the iteration function, and so nicely scoped to just that iteration.Unlike for-of, forEach has the disadvantage that it doesn't understand async functions and await. If you use an async function as the callback, forEach does not wait for that function's promise to settle before continuing. Here's the async example from for-of using forEach instead\u00a0\u2014 notice how there's an initial delay, but then all the text appears right away instead of waiting:function delay(ms) {\n    return new Promise(resolve => {\n        setTimeout(resolve, ms);\n    });\n}\n\nasync function showSlowly(messages) {\n    // INCORRECT, doesn't wait before continuing,\n    // doesn't handle promise rejections\n    messages.forEach(async message => {\n        await delay(400);\n        console.log(message);\n    });\n}\n\nshowSlowly([\n    \"So\", \"long\", \"and\", \"thanks\", \"for\", \"all\", \"the\", \"fish!\"\n]);\n// `.catch` omitted because we know it never rejectsforEach is the \"loop through them all\" function, but ES5 defined several other useful \"work your way through the array and do things\" functions, including:As with forEach, if you use an async function as your callback, none of those waits for the function's promise to settle. That means:Sometimes the old ways are the best:const a = [\"a\", \"b\", \"c\"];\nfor (let index = 0; index < a.length; ++index) {\n    const element = a[index];\n    console.log(element);\n}If the length of the array won't change during the loop, and it's in highly performance-sensitive code, a slightly more complicated version grabbing the length up front might be a tiny bit faster:const a = [\"a\", \"b\", \"c\"];\nfor (let index = 0, len = a.length; index < len; ++index) {\n    const element = a[index];\n    console.log(element);\n}And/or counting backward:const a = [\"a\", \"b\", \"c\"];\nfor (let index = a.length - 1; index >= 0; --index) {\n    const element = a[index];\n    console.log(element);\n}But with modern JavaScript engines, it's rare you need to eke out that last bit of juice.Before ES2015, the loop variable had to exist in the containing scope, because var only has function-level scope, not block-level scope. But as you saw in the examples above, you can use let within the for to scope the variables to just the loop. And when you do that, the index variable is recreated for each loop iteration, meaning closures created in the loop body keep a reference to the index for that specific iteration, which solves the old \"closures in loops\" problem:// (The `NodeList` from `querySelectorAll` is array-like)\nconst divs = document.querySelectorAll(\"div\");\nfor (let index = 0; index < divs.length; ++index) {\n    divs[index].addEventListener('click', e => {\n        console.log(\"Index is: \" + index);\n    });\n}\n<div>zero</div>\n<div>one</div>\n<div>two</div>\n<div>three</div>\n<div>four</div>In the above, you get \"Index is: 0\" if you click the first and \"Index is: 4\" if you click the last. This does not work if you use var instead of let (you'd always see \"Index is: 5\").Like for-of, for loops work well in async functions. Here's the earlier example using a for loop:function delay(ms) {\n    return new Promise(resolve => {\n        setTimeout(resolve, ms);\n    });\n}\n\nasync function showSlowly(messages) {\n    for (let i = 0; i < messages.length; ++i) {\n        const message = messages[i];\n        await delay(400);\n        console.log(message);\n    }\n}\n\nshowSlowly([\n    \"So\", \"long\", \"and\", \"thanks\", \"for\", \"all\", \"the\", \"fish!\"\n]);\n// `.catch` omitted because we know it never rejectsfor-in isn't for looping through arrays, it's for looping through the names of an object's properties. It does often seem to work for looping through arrays as a by-product of the fact that arrays are objects, but it doesn't just loop through the array indexes, it loops through all enumerable properties of the object (including inherited ones). (It also used to be that the order wasn't specified; it is now [details in this other answer], but even though the order is specified now, the rules are complex, there are exceptions, and relying on the order is not best practice.)The only real use cases for for-in on an array are:Looking only at that first example: You can use for-in to visit those sparse array elements if you use appropriate safeguards:// `a` is a sparse array\nconst a = [];\na[0] = \"a\";\na[10] = \"b\";\na[10000] = \"c\";\nfor (const name in a) {\n    if (Object.hasOwn(a, name) &&       // These checks are\n        /^0$|^[1-9]\\d*$/.test(name) &&  // explained\n        name <= 4294967294              // below\n       ) {\n        const element = a[name];\n        console.log(a[name]);\n    }\n}Note the three checks:That the object has its own property by that name (not one it inherits from its prototype; this check is also often written as a.hasOwnProperty(name) but ES2022 adds Object.hasOwn which can be more reliable), andThat the name is all decimal digits (e.g., normal string form, not scientific notation), andThat the name's value when coerced to a number is <= 2^32 - 2 (which is 4,294,967,294). Where does that number come from? It's part of the definition of an array index in the specification. Other numbers (non-integers, negative numbers, numbers greater than 2^32 - 2) are not array indexes. The reason it's 2^32 - 2 is that that makes the greatest index value one lower than 2^32 - 1, which is the maximum value an array's length can have. (E.g., an array's length fits in a 32-bit unsigned integer.)...although with that said, most code only does the hasOwnProperty check.You wouldn't do that in inline code, of course. You'd write a utility function. Perhaps:// Utility function for antiquated environments without `forEach`\nconst hasOwn = Object.prototype.hasOwnProperty.call.bind(Object.prototype.hasOwnProperty);\nconst rexNum = /^0$|^[1-9]\\d*$/;\nfunction sparseEach(array, callback, thisArg) {\n    for (const name in array) {\n        const index = +name;\n        if (hasOwn(a, name) &&\n            rexNum.test(name) &&\n            index <= 4294967294\n           ) {\n            callback.call(thisArg, array[name], index, array);\n        }\n    }\n}\n\nconst a = [];\na[5] = \"five\";\na[10] = \"ten\";\na[100000] = \"one hundred thousand\";\na.b = \"bee\";\n\nsparseEach(a, (value, index) => {\n    console.log(\"Value at \" + index + \" is \" + value);\n});Like for, for-in works well in asynchronous functions if the work within it needs to be done in series.function delay(ms) {\n    return new Promise(resolve => {\n        setTimeout(resolve, ms);\n    });\n}\n\nasync function showSlowly(messages) {\n    for (const name in messages) {\n        if (messages.hasOwnProperty(name)) { // Almost always this is the only check people do\n            const message = messages[name];\n            await delay(400);\n            console.log(message);\n        }\n    }\n}\n\nshowSlowly([\n    \"So\", \"long\", \"and\", \"thanks\", \"for\", \"all\", \"the\", \"fish!\"\n]);\n// `.catch` omitted because we know it never rejectsfor-of uses an iterator implicitly, doing all the scut work for you. Sometimes, you might want to use an iterator explicitly. It looks like this:const a = [\"a\", \"b\", \"c\"];\nconst it = a.values(); // Or `const it = a[Symbol.iterator]();` if you like\nlet entry;\nwhile (!(entry = it.next()).done) {\n    const element = entry.value;\n    console.log(element);\n}An iterator is an object matching the Iterator definition in the specification. Its next method returns a new result object each time you call it. The result object has a property, done, telling us whether it's done, and a property value with the value for that iteration. (done is optional if it would be false, value is optional if it would be undefined.)What you get for value varies depending on the iterator. On arrays, the default iterator provides the value of each array element (\"a\", \"b\", and \"c\" in the example earlier). Arrays also have three other methods that return iterators:Since iterator objects don't advance until you call next, they work well in async function loops. Here's the earlier for-of example using the iterator explicitly:function delay(ms) {\n    return new Promise(resolve => {\n        setTimeout(resolve, ms);\n    });\n}\n\nasync function showSlowly(messages) {\n    const it = messages.values()\n    while (!(entry = it.next()).done) {\n        await delay(400);\n        const element = entry.value;\n        console.log(element);\n    }\n}\n\nshowSlowly([\n    \"So\", \"long\", \"and\", \"thanks\", \"for\", \"all\", \"the\", \"fish!\"\n]);\n// `.catch` omitted because we know it never rejectsAside from true arrays, there are also array-like objects that have a length property and properties with all-digits names: NodeList instances, HTMLCollection instances, the arguments object, etc. How do we loop through their contents?At least some, and possibly most or even all, of the array approaches above apply equally well to array-like objects:Use for-of (use an iterator implicitly) (ES2015+)for-of uses the iterator provided by the object (if any). That includes host-provided objects (like DOM collections and lists). For instance, HTMLCollection instances from getElementsByXYZ methods and NodeLists instances from querySelectorAll both support iteration. (This is defined quite subtly by the HTML and DOM specifications. Basically, any object with length and indexed access is automatically iterable. It doesn't have to be marked iterable; that is used only for collections that, in addition to being iterable, support forEach, values, keys, and entries methods. NodeList does; HTMLCollection doesn't, but both are iterable.)Here's an example of looping through div elements:const divs = document.querySelectorAll(\"div\");\nfor (const div of divs) {\n    div.textContent = Math.random();\n}\n<div>zero</div>\n<div>one</div>\n<div>two</div>\n<div>three</div>\n<div>four</div>Use forEach and related (ES5+)The various functions on Array.prototype are \"intentionally generic\" and can be used on array-like objects via Function#call (spec | MDN) or Function#apply (spec | MDN). (If you have to deal with IE8 or earlier [ouch], see the \"Caveat for host-provided objects\" at the end of this answer, but it's not an issue with vaguely-modern browsers.)Suppose you wanted to use forEach on a Node's childNodes collection (which, being an HTMLCollection, doesn't have forEach natively). You'd do this:(Note, though, that you could just use for-of on node.childNodes.)If you're going to do that a lot, you might want to grab a copy of the function reference into a variable for reuse, e.g.:Use a simple for loopPerhaps obviously, a simple for loop works for array-like objects.Use an iterator explicitly (ES2015+)See #1.You may be able to get away with for-in (with safeguards), but with all of these more appropriate options, there's no reason to try.Other times, you may want to convert an array-like object into a true array. Doing that is surprisingly easy:Use Array.fromArray.from (spec) | (MDN) (ES2015+, but easily polyfilled) creates an array from an array-like object, optionally passing the entries through a mapping function first. So:...takes the NodeList from querySelectorAll and makes an array from it.The mapping function is handy if you were going to map the contents in some way. For instance, if you wanted to get an array of the tag names of the elements with a given class:Use spread syntax (...)It's also possible to use ES2015's spread syntax. Like for-of, this uses the iterator provided by the object (see #1 in the previous section):So for instance, if we want to convert a NodeList into a true array, with spread syntax this becomes quite succinct:Use the slice method of arraysWe can use the slice method of arrays, which like the other methods mentioned above is \"intentionally generic\" and so can be used with array-like objects, like this:So for instance, if we want to convert a NodeList into a true array, we could do this:(If you still have to handle IE8 [ouch], will fail; IE8 didn't let you use host-provided objects as this like that.)If you use Array.prototype functions with host-provided array-like objects (for example, DOM collections and such provided by the browser rather than the JavaScript engine), obsolete browsers like IE8 didn't necessarily handle that way, so if you have to support them, be sure to test in your target environments. But it's not an issue with vaguely-modern browsers. (For non-browser environments, naturally it'll depend on the environment.)",
                "Note: This answer is hopelessly out-of-date. For a more modern approach, look at the methods available on an array. Methods of interest might be:The standard way to iterate an array in JavaScript is a vanilla for-loop:Note, however, that this approach is only good if you have a dense array, and each index is occupied by an element. If the array is sparse, then you can run into performance problems with this approach, since you will iterate over a lot of indices that do not really exist in the array. In this case, a for .. in-loop might be a better idea. However, you must use the appropriate safeguards to ensure that only the desired properties of the array (that is, the array elements) are acted upon, since the for..in-loop will also be enumerated in legacy browsers, or if the additional properties are defined as enumerable.In ECMAScript 5 there will be a forEach method on the array prototype, but it is not supported in legacy browsers. So to be able to use it consistently you must either have an environment that supports it (for example, Node.js for server side JavaScript), or use a \"Polyfill\". The Polyfill for this functionality is, however, trivial and since it makes the code easier to read, it is a good polyfill to include.",
                "If you\u2019re using the jQuery library, you can use jQuery.each:EDIT :As per question, user want code in javascript instead of jquery so the edit is",
                "I think the reverse for loop deserves a mention here:Some developers use the reverse for loop by default, unless there is a good reason to loop forwards.Although the performance gains are usually insignificant, it sort of screams:\"Just do this to every item in the list, I don't care about the order!\"However in practice that is not actually a reliable indication of intent, since it is indistinguishable from those occasions when you do care about the order, and really do need to loop in reverse.  So in fact another construct would be needed to accurately express the \"don't care\" intent, something currently unavailable in most languages, including ECMAScript, but which could be called, for example, forEachUnordered().If order doesn't matter, and efficiency is a concern (in the innermost loop of a game or animation engine), then it may be acceptable to use the reverse for loop as your go-to pattern.  Just remember that seeing a reverse for loop in existing code does not necessarily mean that the order irrelevant!In general for higher level code where clarity and safety are greater concerns, I previously recommended using Array::forEach as your default pattern for looping (although these days I prefer to use for..of).  Reasons to prefer forEach over a reverse loop are:Then when you do see the reverse for loop in your code, that is a hint that it is reversed for a good reason (perhaps one of the reasons described above).  And seeing a traditional forward for loop may indicate that shifting can take place.(If the discussion of intent makes no sense to you, then you and your code may benefit from watching Crockford's lecture on Programming Style & Your Brain.)There is a debate about whether for..of or forEach() are preferable:For maximum browser support, for..of requires a polyfill for iterators, making your app slightly slower to execute and slightly larger to download.For that reason (and to encourage use of map and filter), some front-end style guides ban for..of completely!But the above concerns is not applicable to Node.js applications, where for..of is now well supported.And furthermore await does not work inside forEach().  Using for..of is the clearest pattern in this case.Personally, I tend to use whatever looks easiest to read, unless performance or minification has become a major concern.  So these days I prefer to use for..of instead of forEach(), but I will always use map or filter or find or some when applicable. \n (For the sake of my colleagues, I rarely use reduce.)You will notice that i-- is the middle clause (where we usually see a comparison) and the last clause is empty (where we usually see i++).  That means that i-- is also used as the condition for continuation.  Crucially, it is executed and checked before each iteration.How can it start at array.length without exploding?Because i-- runs before each iteration, on the first iteration we will actually be accessing the item at array.length - 1 which avoids any issues with Array-out-of-bounds undefined items.Why doesn't it stop iterating before index 0?The loop will stop iterating when the condition i-- evaluates to a falsey value (when it yields 0).The trick is that unlike --i, the trailing i-- operator decrements i but yields the value before the decrement.  Your console can demonstrate this:> var i = 5; [i, i--, i];[5, 5, 4]So on the final iteration, i was previously 1 and the i-- expression changes it to 0 but actually yields 1 (truthy), and so the condition passes.  On the next iteration i-- changes i to -1 but yields 0 (falsey), causing execution to immediately drop out of the bottom of the loop.In the traditional forwards for loop, i++ and ++i are interchangeable (as Douglas Crockford points out).  However in the reverse for loop, because our decrement is also our condition expression, we must stick with i-- if we want to process the item at index 0.Some people like to draw a little arrow in the reverse for loop, and end with a wink:Credits go to WYL for showing me the benefits and horrors of the reverse for loop.",
                "Some C-style languages use foreach to loop through enumerations. In JavaScript this is done with the for..in loop structure:There is a catch. for..in will loop through each of the object's enumerable members, and the members on its prototype. To avoid reading values that are inherited through the object's prototype, simply check if the property belongs to the object:Additionally, ECMAScript 5 has added a forEach method to Array.prototype which can be used to enumerate over an array using a calback (the polyfill is in the docs so you can still use it for older browsers):It's important to note that Array.prototype.forEach doesn't break when the callback returns false. jQuery and Underscore.js provide their own variations on each to provide loops that can be short-circuited.",
                "\ud83d\udc49\ud83c\udffd \u00a0 for...of\ud83d\udc49\ud83c\udffd \u00a0 forEach\ud83d\udc49\ud83c\udffd \u00a0 map*Different from the two above, map() creates a new array and expects you to return something after each iteration.\ud83d\uded1\u00a0 Important: As map() is meant to return a value at each iteration, it is an ideal method for transforming elements in arrays:On the other hand, for...of and forEach( ) don't need to return anything and that's why we typically use them to perform logic tasks that manipulate stuff outside.So to speak, you're going to find if () statements, side effects, and logging activities in these two.\ud83d\udc4c\ud83c\udffe\u00a0 TIP: you can also have the index (as well as the whole array) in each iteration in your .map() or .forEach() functions.Just pass additional arguments to them:",
                "If you want to loop over an array, use the standard three-part for loop.You can get some performance optimisations by caching myArray.length or iterating over it backwards.",
                "If you don't mind emptying the array:x will contain the last value of y and it will be removed from the array. You can also use shift() which will give and remove the first item from y.",
                "A forEach implementation (see in jsFiddle):",
                "I know this is an old post, and there are so many great answers already. For a little more completeness I figured I'd throw in another one using AngularJS. Of course, this only applies if you're using Angular, obviously, nonetheless I'd like to put it anyway.angular.forEach takes 2 arguments and an optional third argument. The first argument is the object (array) to iterate over, the second argument is the iterator function, and the optional third argument is the object context (basically referred to inside the loop as 'this'.There are different ways to use the forEach loop of angular. The simplest and probably most used isAnother way that is useful for copying items from one array to another isThough, you don't have to do that, you can simply do the following and it's equivalent to the previous example:Now there are pros and cons of using the angular.forEach function as opposed to the built in vanilla-flavored for loop.ProsConsider the following 2 nested loops, which do exactly the same thing. Let's say that we have 2 arrays of objects and each object contains an array of results, each of which has a Value property that's a string (or whatever). And let's say we need to iterate over each of the results and if they're equal then perform some action:Granted this is a very simple hypothetical example, but I've written triple embedded for loops using the second approach and it was very hard to read, and write for that matter.ConsI'm sure there's various other pros and cons as well, and please feel free to add any that you see fit. I feel that, bottom line, if you need efficiency, stick with just the native for loop for your looping needs. But, if your datasets are smaller and a some efficiency is okay to give up in exchange for readability and writability, then by all means throw an angular.forEach in that bad boy.",
                "As of ECMAScript\u00a06:list = [0, 1, 2, 3]\r\nfor (let obj of list) {\r\n    console.log(obj)\r\n}Where of avoids the oddities associated with in and makes it work like the for loop of any other language, and let binds i within the loop as opposed to within the function.The braces ({}) can be omitted when there is only one command (e.g. in the example above).",
                "Probably the for(i = 0; i < array.length; i++) loop is not the best choice. Why? If you have this:The method will call from array[0] to array[2]. First, this will first reference variables you don't even have, second you would not have the variables in the array, and third this will make the code bolder. Look here, it's what I use:And if you want it to be a function, you can do this:If you want to break, a little more logic:Example:It returns:",
                "There are three implementations of foreach in jQuery as follows.",
                "An easy solution now would be to use the underscore.js library. It's providing many useful tools, such as each and will automatically delegate the job to the native forEach if available.A CodePen example of how it works is:",
                "There isn't any for each loop in native JavaScript. You can either use libraries to get this functionality (I recommend Underscore.js), use a simple for in loop.However, note that there may be reasons to use an even simpler for loop (see Stack Overflow question Why is using \u201cfor\u2026in\u201d with array iteration such a bad idea?)",
                "ECMAScript\u00a05 (the version on JavaScript) to work with Arrays:forEach - Iterates through every item in the array and do whatever you need with each item.In case, more interested on operation on array using some inbuilt feature.map - It creates a new array with the result of the callback function. This method is good to be used when you need to format the elements of your array.reduce - As the name says, it reduces the array to a single value by calling the given function passing in the current element and the result of the previous execution.every - Returns true or false if all the elements in the array pass the test in the callback function.filter - Very similar to every except that filter returns an array with the elements that return true to the given function.",
                "There are a few ways to loop through an array in JavaScript, as below:for - it's the most common one. Full block of code for loopingvar languages = [\"Java\", \"JavaScript\", \"C#\", \"Python\"];\r\nvar i, len, text;\r\nfor (i = 0, len = languages.length, text = \"\"; i < len; i++) {\r\n    text += languages[i] + \"<br>\";\r\n}\r\ndocument.getElementById(\"example\").innerHTML = text;\n<p id=\"example\"></p>while - loop while a condition is through. It seems to be the fastest loopvar text = \"\";\r\nvar i = 0;\r\nwhile (i < 10) {\r\n    text +=  i + \") something<br>\";\r\n    i++;\r\n}\r\ndocument.getElementById(\"example\").innerHTML = text;\n<p id=\"example\"></p>do/while - also loop through a block of code while the condition is true, will run at least one timevar text = \"\"\r\nvar i = 0;\r\n\r\ndo {\r\n    text += i + \") something <br>\";\r\n    i++;\r\n}\r\nwhile (i < 10);\r\n\r\ndocument.getElementById(\"example\").innerHTML = text;\n<p id=\"example\"></p>Functional loops - forEach, map, filter, also reduce (they loop through the function, but they are used if you need to do something with your array, etc.// For example, in this case we loop through the number and double them up using the map function\r\nvar numbers = [65, 44, 12, 4];\r\ndocument.getElementById(\"example\").innerHTML = numbers.map(function(num){return num * 2});\n<p id=\"example\"></p>For more information and examples about functional programming on arrays, look at the blog post Functional programming in JavaScript: map, filter and reduce.",
                "This is an iterator for NON-sparse list where the index starts at 0, which is the typical scenario when dealing with document.getElementsByTagName or document.querySelectorAll)Examples of usage:Example #1Example #2Each p tag gets class=\"blue\"Example #3Every other p tag gets class=\"red\">Example #4And finally the first 20 blue p tags are changed to greenCaution when using string as function: the function is created out-of-context and ought to be used only where you are certain of variable scoping.  Otherwise, better to pass functions where scoping is more intuitive.",
                "There's no inbuilt ability to break in forEach. To interrupt execution use the Array#some like below:This works because some returns true as soon as any of the callbacks, executed in array order, returns true, short-circuiting the execution of the rest. \nOriginal Answer\nsee Array prototype for some",
                "I also would like to add this as a composition of a reverse loop and an answer above for someone that would like this syntax too.Pros:The benefit for this: You have the reference already in the first like that won't need to be declared later with another line. It is handy when looping trough the object array.Cons:This will break whenever the reference is false - falsey (undefined, etc.). It can be used as an advantage though. However, it would make it a little bit harder to read. And also depending on the browser it can be \"not\" optimized to work faster than the original one.",
                "jQuery way using $.map:",
                "Using loops with ECMAScript\u00a06  destructuring and the spread operatorDestructuring and using of the spread operator have proven quite useful for newcomers to ECMAScript\u00a06 as being more human-readable/aesthetic, although some JavaScript veterans might consider it messy. Juniors or some other people might find it useful.The following examples will use the for...of statement and the .forEach method.Examples 6, 7, and 8 can be used with any functional loops like .map, .filter, .reduce, .sort, .every, .some. For more information about these methods, check out the Array Object.Example 1: Normal for...of loop - no tricks here.let arrSimple = ['a', 'b', 'c'];\n\nfor (let letter of arrSimple) {\n  console.log(letter);\n}Example 2: Split words to characterslet arrFruits = ['apple', 'orange', 'banana'];\n\nfor (let [firstLetter, ...restOfTheWord] of arrFruits) {\n  // Create a shallow copy using the spread operator\n  let [lastLetter] = [...restOfTheWord].reverse();\n  console.log(firstLetter, lastLetter, restOfTheWord);\n}Example 3: Looping with a key and value// let arrSimple = ['a', 'b', 'c'];\n\n// Instead of keeping an index in `i` as per example `for(let i = 0 ; i<arrSimple.length;i++)`\n// this example will use a multi-dimensional array of the following format type:\n// `arrWithIndex: [number, string][]`\n\nlet arrWithIndex = [\n  [0, 'a'],\n  [1, 'b'],\n  [2, 'c'],\n];\n\n// Same thing can be achieved using `.map` method\n// let arrWithIndex = arrSimple.map((i, idx) => [idx, i]);\n\n// Same thing can be achieved using `Object.entries`\n// NOTE: `Object.entries` method doesn't work on Internet Explorer  unless it's polyfilled\n// let arrWithIndex = Object.entries(arrSimple);\n\nfor (let [key, value] of arrWithIndex) {\n  console.log(key, value);\n}Example 4: Get object properties inlinelet arrWithObjects = [{\n    name: 'Jon',\n    age: 32\n  },\n  {\n    name: 'Elise',\n    age: 33\n  }\n];\n\nfor (let { name, age: aliasForAge } of arrWithObjects) {\n  console.log(name, aliasForAge);\n}Example 5: Get deep object properties of what you needlet arrWithObjectsWithArr = [{\n    name: 'Jon',\n    age: 32,\n    tags: ['driver', 'chef', 'jogger']\n  },\n  {\n    name: 'Elise',\n    age: 33,\n    tags: ['best chef', 'singer', 'dancer']\n  }\n];\n\nfor (let { name, tags: [firstItemFromTags, ...restOfTags] } of arrWithObjectsWithArr) {\n  console.log(name, firstItemFromTags, restOfTags);\n}Example 6: Is Example 3 used with .forEachlet arrWithIndex = [\n  [0, 'a'],\n  [1, 'b'],\n  [2, 'c'],\n];\n\n// Not to be confused here, `forEachIndex` is the real index\n// `mappedIndex` was created by \"another user\", so you can't really trust it\n\narrWithIndex.forEach(([mappedIndex, item], forEachIndex) => {\n  console.log(forEachIndex, mappedIndex, item);\n});Example 7: Is Example 4 used with .forEachlet arrWithObjects = [{\n    name: 'Jon',\n    age: 32\n  },\n  {\n    name: 'Elise',\n    age: 33\n  }\n];\n// NOTE: Destructuring objects while using shorthand functions\n// are required to be surrounded by parentheses\narrWithObjects.forEach( ({ name, age: aliasForAge }) => {\n  console.log(name, aliasForAge)\n});Example 8: Is Example 5 used with .forEachlet arrWithObjectsWithArr = [{\n    name: 'Jon',\n    age: 32,\n    tags: ['driver', 'chef', 'jogger']\n  },\n  {\n    name: 'Elise',\n    age: 33,\n    tags: ['best chef', 'singer', 'dancer']\n  }\n];\n\narrWithObjectsWithArr.forEach(({\n  name,\n  tags: [firstItemFromTags, ...restOfTags]\n}) => {\n  console.log(name, firstItemFromTags, restOfTags);\n});",
                "When iterating over an array, we often want to accomplish one of the following goals:We want to iterate over the array and create a new array:Array.prototype.mapWe want to iterate over the array and don't create a new array:Array.prototype.forEach \nfor..of loopIn JavaScript, there are many ways of accomplishing both of these goals. However, some are more convenient than others. Below you can find some commonly used methods (the most convenient IMO) to accomplish array iteration in JavaScript.map() is a function located on Array.prototype which can transform every element of an array and then returns a new array. map() takes as an argument a callback function and works in the following manner:let arr = [1, 2, 3, 4, 5];\r\n\r\nlet newArr = arr.map((element, index, array) => {\r\n  return element * 2;\r\n})\r\n\r\nconsole.log(arr);\r\nconsole.log(newArr);The callback which we have passed into map() as an argument gets executed for every element. Then an array gets returned which has the same length as the original array. In this new array element is transformed by the callback function passed in as an argument to map().The distinct difference between map and another loop mechanism like forEach and a for..of loop is that map returns a new array and leaves the old array intact (except if you explicitly manipulate it with thinks like splice).Also, note that the map function's callback provides the index number of the current iteration as a second argument. Furthermore, does the third argument provide the array on which map was called? Sometimes these properties can be very useful.forEach is a function which is located on Array.prototype which takes a callback function as an argument. It then executes this callback function for every element in the array. In contrast to the map() function, the forEach function returns nothing (undefined). For example:let arr = [1, 2, 3, 4, 5];\r\n\r\narr.forEach((element, index, array) => {\r\n\r\n  console.log(element * 2);\r\n\r\n  if (index === 4) {\r\n    console.log(array)\r\n  }\r\n  // index, and oldArray are provided as 2nd and 3th argument by the callback\r\n\r\n})\r\n\r\nconsole.log(arr);Just like the map function, the forEach callback provides the index number of the current iteration as a second argument. Also, does the third argument provide the array on which forEach was called?The for..of loop loops through every element of an array (or any other iterable object). It works in the following manner:let arr = [1, 2, 3, 4, 5];\r\n\r\nfor(let element of arr) {\r\n  console.log(element * 2);\r\n}In the above example, element stands for an array element and arr is the array which we want to loop. Note that the name element is arbitrary, and we could have picked any other name like 'el' or something more declarative when this is applicable.Don't confuse the for..in loop with the for..of loop. for..in will loop through all enumerable properties of the array whereas the for..of loop will only loop through the array elements. For example:let arr = [1, 2, 3, 4, 5];\r\n\r\narr.foo = 'foo';\r\n\r\nfor(let element of arr) {\r\n  console.log(element);\r\n}\r\n\r\nfor(let element in arr) {\r\n  console.log(element);\r\n}",
                "Today (2019-12-18) I perform test on my macOS v10.13.6 (High Sierra), on Chrome v 79.0, Safari v13.0.4 and Firefox v71.0 (64 bit) - conclusions about optimisation (and micro-optimisation which usually is not worth to introduce it to code because the benefit is small, but code complexity grows).It looks like the traditional for i (Aa) is a good choice to write fast code on all browsers.The other solutions, like for-of (Ad), all in group C.... are usually 2 - 10 (and more) times slower than Aa, but for small arrays it is ok to use it - for the sake of increase code clarity.The loops with array length cached in n (Ab, Bb, Be) are sometimes faster, sometimes not. Probably compilers automatically detect this situation and introduce caching. The speed differences between the cached and no-cached versions (Aa, Ba, Bd) are about ~1%, so it looks like introduce n is a micro-optimisation.The i-- like solutions where the loop starts from the last array element (Ac, Bc) are usually ~30% slower than forward solutions - probably the reason is the way of CPU memory cache working - forward memory reading is more optimal for CPU caching). Is recommended to NOT USE such solutions.In tests we calculate the sum of array elements. I perform a test for small arrays (10 elements) and big arrays (1M elements) and divide them into three groups:let arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\r\n//let arr = Array.from(Array(1000000), (x, i) => i%10);\r\n\r\nfunction Aa(a, s=0) {\r\n  for(let i=0; i<a.length; i++) {\r\n    s += a[i];\r\n  }\r\n  console.log('Aa=', s);\r\n}\r\n\r\nfunction Ab(a, s=0) {\r\n  let n = a.length;\r\n  for(let i=0; i<n; i++) {\r\n    s += a[i];\r\n  }\r\n  console.log('Ab=', s);\r\n}\r\n\r\nfunction Ac(a, s=0) {\r\n  for(let i=a.length; i--;) {\r\n    s += a[i];\r\n  }\r\n  console.log('Ac=', s);\r\n}\r\n\r\nfunction Ad(a, s=0) {\r\n  for(let x of a) {\r\n    s += x;\r\n  }\r\n  console.log('Ad=', s);\r\n}\r\n\r\nfunction Ae(a, s=0) {\r\n  for(let i in a) if (a.hasOwnProperty(i)) {\r\n    s += a[i];\r\n  }\r\n  console.log('Ae=', s);\r\n}\r\n\r\nfunction Ba(a, s=0) {\r\n  let i = -1;\r\n  while(++i < a.length) {\r\n    s+= a[i];\r\n  }\r\n  console.log('Ba=', s);\r\n}\r\n\r\nfunction Bb(a, s=0) {\r\n  let i = -1;\r\n  let n = a.length;\r\n  while(++i < n) {\r\n    s+= a[i];\r\n  }\r\n  console.log('Bb=', s);\r\n}\r\n\r\nfunction Bc(a, s=0) {\r\n  let i = a.length;\r\n  while(i--) {\r\n    s += a[i];\r\n  }\r\n  console.log('Bc=', s);\r\n}\r\n\r\nfunction Bd(a, s=0) {\r\n  let i = 0;\r\n  do {\r\n    s+= a[i]\r\n  } while (++i < a.length);\r\n  console.log('Bd=', s);\r\n}\r\n\r\nfunction Be(a, s=0) {\r\n  let i = 0;\r\n  let n = a.length;\r\n  do {\r\n    s += a[i]\r\n  } while (++i < n);\r\n  console.log('Be=', s);\r\n}\r\n\r\nfunction Bf(a, s=0) {\r\n  const it = a.values(); \r\n  let e;\r\n  while (!(e = it.next()).done) { \r\n    s+= e.value; \r\n  }\r\n  console.log('Bf=', s);\r\n}\r\n\r\nfunction Ca(a, s=0) {\r\n  a.map(x => { s+=x });\r\n  console.log('Ca=', s);\r\n}\r\n\r\nfunction Cb(a, s=0) {\r\n  a.forEach(x => { s+=x });\r\n  console.log('Cb=', s);\r\n}\r\n\r\nfunction Cc(a, s=0) {\r\n  a.every(x => (s += x, 1));\r\n  console.log('Cc=', s);\r\n}\r\n\r\nfunction Cd(a, s=0) {\r\n  a.filter(x => { s+=x });\r\n  console.log('Cd=',s);\r\n}\r\n\r\nfunction Ce(a, s=0) {\r\n  a.reduce((z, c) => { s+=c }, 0);\r\n  console.log('Ce=', s);\r\n}\r\n\r\nfunction Cf(a, s=0) {\r\n  a.reduceRight((z, c) => { s += c }, 0);\r\n  console.log('Cf=', s);\r\n}\r\n\r\nfunction Cg(a, s=0) {\r\n  a.some(x => { s += x } );\r\n  console.log('Cg=', s);\r\n}\r\n\r\nfunction Ch(a, s=0) {\r\n  Array.from(a, x=> s += x);\r\n  console.log('Cc=', s);\r\n}\r\n\r\n\r\nAa(arr);\r\nAb(arr);\r\nAc(arr);\r\nAd(arr);\r\nAe(arr);\r\n\r\nBa(arr);\r\nBb(arr);\r\nBc(arr);\r\nBd(arr);\r\nBe(arr);\r\nBf(arr);\r\n\r\nCa(arr);\r\nCb(arr);\r\nCc(arr);\r\nCd(arr);\r\nCe(arr);\r\nCf(arr);\r\nCg(arr);\r\nCh(arr);\n<p style=\"color: red\">This snippets only PRESENTS code used for benchmark - it not perform test itself</p>Cross browser resultsResults for all tested browsersbrowsers**Array with 10 elementsResults for Chrome. You can perform the test on your machine here.Array with 1,000,000 elementsResults for Chrome. You can perform the test on your machine here",
                "A way closest to your idea would be to use Array.forEach() which accepts a closure function which will be executed for each element of the array.Another viable way would be to use Array.map() which works in the same way, but it also takes all values that you return and returns them in a new array (essentially mapping each element to a new one), like this:",
                "As per the new updated feature ECMAScript 6 (ES6) and ECMAScript 2015, you can use the following options with loops:for loopsfor...in loopsArray.forEach()for...of loopswhile loopsdo...while loops",
                "As one can see in the table above, for...of should be used wherever it fits. Since it supports async functions, skips non-numeric properties and prevents messing up the loop by accidentally modifying the loop index.See for...of reference for more examples, link to specification and difference between for...of and for...in. Or maybe check this tutorial for some explanation on how they differ.",
                "The lambda syntax doesn't usually work in Internet\u00a0Explorer\u00a010  or below.I usually use theIf you are a jQuery fan and already have a jQuery file running, you should reverse the positions of the index and value parameters",
                "You can call forEach like this:forEach will iterate over the array you provide and for each iteration it will have element which holds the value of that iteration. If you need index you can get the current index by passing the i as the second parameter in the callback function for forEach.Foreach is basically a High Order Function, Which takes another function as its parameter.Output:You can also iterate over an array like this:",
                "If you want to use forEach(), it will look like -If you want to use for(), it will look like -"
            ]
        },
        {
            "tag": "forms",
            "question": [
                "The definitive guide to form-based website authentication [closed]",
                "Moderator note:\nThis question is not a good fit for our question and answer format with the topicality rules which currently apply for Stack Overflow. We normally use a \"historical lock\" for ..."
            ],
            "url": "https://stackoverflow.com/questions/549",
            "answer": [
                "We'll assume you already know how to build a login+password HTML form which POSTs the values to a script on the server side for authentication. The sections below will deal with patterns for sound practical auth, and how to avoid the most common security pitfalls.To HTTPS or not to HTTPS?Unless the connection is already secure (that is, tunneled through HTTPS using SSL/TLS), your login form values will be sent in cleartext, which allows anyone eavesdropping on the line between browser and web server will be able to read logins as they pass through. This type of wiretapping is done routinely by governments, but in general, we won't address 'owned' wires other than to say this: Just use HTTPS.In essence, the only practical way to protect against wiretapping/packet sniffing during login is by using HTTPS or another certificate-based encryption scheme (for example, TLS) or a proven & tested challenge-response scheme (for example, the Diffie-Hellman-based SRP). Any other method can be easily circumvented by an eavesdropping attacker.Of course, if you are willing to get a little bit impractical, you could also employ some form of two-factor authentication scheme (e.g. the Google Authenticator app, a physical 'cold war style' codebook, or an RSA key generator dongle). If applied correctly, this could work even with an unsecured connection, but it's hard to imagine that a dev would be willing to implement two-factor auth but not SSL.(Do not) Roll-your-own JavaScript encryption/hashingGiven the perceived (though now avoidable) cost and technical difficulty of setting up an SSL certificate on your website, some developers are tempted to roll their own in-browser hashing or encryption schemes in order to avoid passing cleartext logins over an unsecured wire.While this is a noble thought, it is essentially useless (and can be a security flaw) unless it is combined with one of the above - that is, either securing the line with strong encryption or using a tried-and-tested challenge-response mechanism (if you don't know what that is, just know that it is one of the most difficult to prove, most difficult to design, and most difficult to implement concepts in digital security).While it is true that hashing the password can be effective against password disclosure, it is vulnerable to replay attacks, Man-In-The-Middle attacks / hijackings (if an attacker can inject a few bytes into your unsecured HTML page before it reaches your browser, they can simply comment out the hashing in the JavaScript), or brute-force attacks (since you are handing the attacker both username, salt and hashed password).CAPTCHAS against humanityCAPTCHA is meant to thwart one specific category of attack: automated dictionary/brute force trial-and-error with no human operator. There is no doubt that this is a real threat, however, there are ways of dealing with it seamlessly that don't require a CAPTCHA, specifically properly designed server-side login throttling schemes - we'll discuss those later.Know that CAPTCHA implementations are not created alike; they often aren't human-solvable, most of them are actually ineffective against bots, all of them are ineffective against cheap third-world labor (according to OWASP, the current sweatshop rate is $12 per 500 tests), and some implementations may be technically illegal in some countries (see OWASP Authentication Cheat Sheet). If you must use a CAPTCHA, use Google's reCAPTCHA, since it is OCR-hard by definition (since it uses already OCR-misclassified book scans) and tries very hard to be user-friendly.Personally, I tend to find CAPTCHAS annoying, and use them only as a last resort when a user has failed to log in a number of times and throttling delays are maxed out. This will happen rarely enough to be acceptable, and it strengthens the system as a whole.Storing Passwords / Verifying loginsThis may finally be common knowledge after all the highly-publicized hacks and user data leaks we've seen in recent years, but it has to be said: Do not store passwords in cleartext in your database. User databases are routinely hacked, leaked or gleaned through SQL injection, and if you are storing raw, plaintext passwords, that is instant game over for your login security.So if you can't store the password, how do you check that the login+password combination POSTed from the login form is correct? The answer is hashing using a key derivation function. Whenever a new user is created or a password is changed, you take the password and run it through a KDF, such as Argon2, bcrypt, scrypt or PBKDF2, turning the cleartext password (\"correcthorsebatterystaple\") into a long, random-looking string, which is a lot safer to store in your database. To verify a login, you run the same hash function on the entered password, this time passing in the salt and compare the resulting hash string to the value stored in your database. Argon2, bcrypt and scrypt store the salt with the hash already. Check out this article on sec.stackexchange for more detailed information.The reason a salt is used is that hashing in itself is not sufficient -- you'll want to add a so-called 'salt' to protect the hash against rainbow tables. A salt effectively prevents two passwords that exactly match from being stored as the same hash value, preventing the whole database being scanned in one run if an attacker is executing a password guessing attack.A cryptographic hash should not be used for password storage because user-selected passwords are not strong enough (i.e. do not usually contain enough entropy) and a password guessing attack could be completed in a relatively short time by an attacker with access to the hashes. This is why KDFs are used - these effectively \"stretch the key\", which means that every password guess an attacker makes causes multiple repetitions of the hash algorithm, for example 10,000 times, which causes the attacker to guess the password 10,000 times slower.Session data - \"You are logged in as Spiderman69\"Once the server has verified the login and password against your user database and found a match, the system needs a way to remember that the browser has been authenticated. This fact should only ever be stored server side in the session data.If you are unfamiliar with session data, here's how it works: A single randomly-generated string is stored in an expiring cookie and used to reference a collection of data - the session data - which is stored on the server. If you are using an MVC framework, this is undoubtedly handled already.If at all possible, make sure the session cookie has the secure and HTTP Only flags set when sent to the browser. The HttpOnly flag provides some protection against the cookie being read through XSS attack. The secure flag ensures that the cookie is only sent back via HTTPS, and therefore protects against network sniffing attacks. The value of the cookie should not be predictable. Where a cookie referencing a non-existent session is presented, its value should be replaced immediately to prevent session fixation.Session state can also be maintained on the client side. This is achieved by using techniques like JWT (JSON Web Token).Persistent Login Cookies (\"remember me\" functionality) are a danger zone; on the one hand, they are entirely as safe as conventional logins when users understand how to handle them; and on the other hand, they are an enormous security risk in the hands of careless users, who may use them on public computers and forget to log out, and who may not know what browser cookies are or how to delete them.Personally, I like persistent logins for the websites I visit on a regular basis, but I know how to handle them safely. If you are positive that your users know the same, you can use persistent logins with a clean conscience. If not - well, then you may subscribe to the philosophy that users who are careless with their login credentials brought it upon themselves if they get hacked. It's not like we go to our user's houses and tear off all those facepalm-inducing Post-It notes with passwords they have lined up on the edge of their monitors, either.Of course, some systems can't afford to have any accounts hacked; for such systems, there is no way you can justify having persistent logins.If you DO decide to implement persistent login cookies, this is how you do it:First, take some time to read Paragon Initiative's article on the subject. You'll need to get a bunch of elements right, and the article does a great job of explaining each.And just to reiterate one of the most common pitfalls, DO NOT STORE THE PERSISTENT LOGIN COOKIE (TOKEN) IN YOUR DATABASE, ONLY A HASH OF IT! The login token is Password Equivalent, so if an attacker got their hands on your database, they could use the tokens to log in to any account, just as if they were cleartext login-password combinations. Therefore, use hashing (according to https://security.stackexchange.com/a/63438/5002 a weak hash will do just fine for this purpose) when storing persistent login tokens.Don't implement 'secret questions'. The 'secret questions' feature is a security anti-pattern. Read the paper from link number 4 from the MUST-READ list. You can ask Sarah Palin about that one, after her Yahoo! email account got hacked during a previous presidential campaign because the answer to her security question was... \"Wasilla High School\"!Even with user-specified questions, it is highly likely that most users will choose either:A 'standard' secret question like mother's maiden name or favorite petA simple piece of trivia that anyone could lift from their blog, LinkedIn profile, or similarAny question that is easier to answer than guessing their password. Which, for any decent password, is every question you can imagineIn conclusion, security questions are inherently insecure in virtually all their forms and variations, and should not be employed in an authentication scheme for any reason.The true reason why security questions even exist in the wild is that they conveniently save the cost of a few support calls from users who can't access their email to get to a reactivation code. This at the expense of security and Sarah Palin's reputation. Worth it? Probably not.I already mentioned why you should never use security questions for handling forgotten/lost user passwords; it also goes without saying that you should never e-mail users their actual passwords. There are at least two more all-too-common pitfalls to avoid in this field:Don't reset a forgotten password to an autogenerated strong password - such passwords are notoriously hard to remember, which means the user must either change it or write it down - say, on a bright yellow Post-It on the edge of their monitor. Instead of setting a new password, just let users pick a new one right away - which is what they want to do anyway. (An exception to this might be if the users are universally using a password manager to store/manage passwords that would normally be impossible to remember without writing it down).Always hash the lost password code/token in the database. AGAIN, this code is another example of a Password Equivalent, so it MUST be hashed in case an attacker got their hands on your database. When a lost password code is requested, send the plaintext code to the user's email address, then hash it, save the hash in your database -- and throw away the original. Just like a password or a persistent login token.A final note: always make sure your interface for entering the 'lost password code' is at least as secure as your login form itself, or an attacker will simply use this to gain access instead. Making sure you generate very long 'lost password codes' (for example, 16 case-sensitive alphanumeric characters) is a good start, but consider adding the same throttling scheme that you do for the login form itself.First, you'll want to read this small article for a reality check: The 500 most common passwordsOkay, so maybe the list isn't the canonical list of most common passwords on any system anywhere ever, but it's a good indication of how poorly people will choose their passwords when there is no enforced policy in place. Plus, the list looks frighteningly close to home when you compare it to publicly available analyses of recently stolen passwords.So: With no minimum password strength requirements, 2% of users use one of the top 20 most common passwords. Meaning: if an attacker gets just 20 attempts, 1 in 50 accounts on your website will be crackable.Thwarting this requires calculating the entropy of a password and then applying a threshold.  The National Institute of Standards and Technology (NIST) Special Publication 800-63 has a set of very good suggestions.  That, when combined with a dictionary and keyboard layout analysis (for example, 'qwertyuiop' is a bad password), can reject 99% of all poorly selected passwords at a level of 18 bits of entropy.  Simply calculating password strength and showing a visual strength meter to a user is good, but insufficient.  Unless it is enforced, a lot of users will most likely ignore it.And for a refreshing take on user-friendliness of high-entropy passwords, Randall Munroe's Password Strength xkcd is highly recommended.Utilize Troy Hunt's Have I Been Pwned API to check users passwords against passwords compromised in public data breaches.First, have a look at the numbers: Password Recovery Speeds - How long will your password stand upIf you don't have the time to look through the tables in that link, here's the list of them:It takes virtually no time to crack a weak password, even if you're cracking it with an abacusIt takes virtually no time to crack an alphanumeric 9-character password if it is case insensitiveIt takes virtually no time to crack an intricate, symbols-and-letters-and-numbers, upper-and-lowercase password if it is less than 8 characters long (a desktop PC can search the entire keyspace up to 7 characters in a matter of days or even hours)It would, however, take an inordinate amount of time to crack even a 6-character password, if you were limited to one attempt per second!So what can we learn from these numbers? Well, lots, but we can focus on the most important part: the fact that preventing large numbers of rapid-fire successive login attempts (ie. the brute force attack) really isn't that difficult. But preventing it right isn't as easy as it seems.Generally speaking, you have three choices that are all effective against brute-force attacks (and dictionary attacks, but since you are already employing a strong passwords policy, they shouldn't be an issue):Present a CAPTCHA after N failed attempts (annoying as hell and often ineffective -- but I'm repeating myself here)Locking accounts and requiring email verification after N failed attempts (this is a DoS attack waiting to happen)And finally, login throttling: that is, setting a time delay between attempts after N failed attempts (yes, DoS attacks are still possible, but at least they are far less likely and a lot more complicated to pull off).Best practice #1: A short time delay that increases with the number of failed attempts, like:DoS attacking this scheme would be very impractical, since the resulting lockout time is slightly larger than the sum of the previous lockout times.To clarify: The delay is not a delay before returning the response to the browser. It is more like a timeout or refractory period during which login attempts to a specific account or from a specific IP address will not be accepted or evaluated at all. That is, correct credentials will not return in a successful login, and incorrect credentials will not trigger a delay increase.Best practice #2: A medium length time delay that goes into effect after N failed attempts, like:DoS attacking this scheme would be quite impractical, but certainly doable. Also, it might be relevant to note that such a long delay can be very annoying for a legitimate user. Forgetful users will dislike you.Best practice #3: Combining the two approaches - either a fixed, short time delay that goes into effect after N failed attempts, like:Or, an increasing delay with a fixed upper bound, like:This final scheme was taken from the OWASP best-practices suggestions (link 1 from the MUST-READ list) and should be considered best practice, even if it is admittedly on the restrictive side.As a rule of thumb, however, I would say: the stronger your password policy is, the less you have to bug users with delays. If you require strong (case-sensitive alphanumerics + required numbers and symbols) 9+ character passwords, you could give the users 2-4 non-delayed password attempts before activating the throttling.DoS attacking this final login throttling scheme would be very impractical. And as a final touch, always allow persistent (cookie) logins (and/or a CAPTCHA-verified login form) to pass through, so legitimate users won't even be delayed while the attack is in progress. That way, the very impractical DoS attack becomes an extremely impractical attack.Additionally, it makes sense to do more aggressive throttling on admin accounts, since those are the most attractive entry pointsJust as an aside, more advanced attackers will try to circumvent login throttling by 'spreading their activities':Distributing the attempts on a botnet to prevent IP address flaggingRather than picking one user and trying the 50.000 most common passwords (which they can't, because of our throttling), they will pick THE most common password and try it against 50.000 users instead. That way, not only do they get around maximum-attempts measures like CAPTCHAs and login throttling, their chance of success increases as well, since the number 1 most common password is far more likely than number 49.995Spacing the login requests for each user account, say, 30 seconds apart, to sneak under the radarHere, the best practice would be logging the number of failed logins, system-wide, and using a running average of your site's bad-login frequency as the basis for an upper limit that you then impose on all users.Too abstract? Let me rephrase:Say your site has had an average of 120 bad logins per day over the past 3 months. Using that (running average), your system might set the global limit to 3 times that -- ie. 360 failed attempts over a 24 hour period. Then, if the total number of failed attempts across all accounts exceeds that number within one day (or even better, monitor the rate of acceleration and trigger on a calculated threshold), it activates system-wide login throttling - meaning short delays for ALL users (still, with the exception of cookie logins and/or backup CAPTCHA logins).I also posted a question with more details and a really good discussion of how to avoid tricky pitfals in fending off distributed brute force attacksCredentials can be compromised, whether by exploits, passwords being written down and lost, laptops with keys being stolen, or users entering logins into phishing sites.  Logins can be further protected with two-factor authentication, which uses out-of-band factors such as single-use codes received from a phone call, SMS message, app, or dongle. Several providers offer two-factor authentication services.Authentication can be completely delegated to a single-sign-on service, where another provider handles collecting credentials. This pushes the problem to a trusted third party. Google and Twitter both provide standards-based SSO services, while Facebook provides a similar proprietary solution.",
                "The only practical way to send credentials 100% securely is by using SSL. Using JavaScript to hash the password is not safe. Common pitfalls for client-side password hashing:There's another secure method called SRP, but it's patented (although it is freely licensed) and there are few good implementations available.Don't ever store passwords as plaintext in the database. Not even if you don't care about the security of your own site. Assume that some of your users will reuse the password of their online bank account. So, store the hashed password, and throw away the original. And make sure the password doesn't show up in access logs or application logs. OWASP recommends the use of Argon2 as your first choice for new applications. If this is not available, PBKDF2 or scrypt should be used instead. And finally if none of the above are available, use bcrypt.Hashes by themselves are also insecure. For instance, identical passwords mean identical hashes--this makes hash lookup tables an effective way of cracking lots of passwords at once. Instead, store the salted hash. A salt is a string appended to the password prior to hashing - use a different (random) salt per user. The salt is a public value, so you can store them with the hash in the database. See here for more on this.This means that you can't send the user their forgotten passwords (because you only have the hash). Don't reset the user's password unless you have authenticated the user (users must prove that they are able to read emails sent to the stored (and validated) email address.)Security questions are insecure - avoid using them. Why? Anything a security question does, a password does better. Read PART III: Using Secret Questions in @Jens Roland answer here in this wiki.After the user logs in, the server sends the user a session cookie. The server can retrieve the username or id from the cookie, but nobody else can generate such a cookie (TODO explain mechanisms).Cookies can be hijacked: they are only as secure as the rest of the client's machine and other communications. They can be read from disk, sniffed in network traffic, lifted by a cross-site scripting attack, phished from a poisoned DNS so the client sends their cookies to the wrong servers. Don't send persistent cookies. Cookies should expire at the end of the client session (browser close or leaving your domain).If you want to autologin your users, you can set a persistent cookie, but it should be distinct from a full-session cookie. You can set an additional flag that the user has auto-logged in, and needs to log in for real for sensitive operations. This is popular with shopping sites that want to provide you with a seamless, personalized shopping experience but still protect your financial details. For example, when you return to visit Amazon, they show you a page that looks like you're logged in, but when you go to place an order (or change your shipping address, credit card etc.), they ask you to confirm your password.Financial websites such as banks and credit cards, on the other hand, only have sensitive data and should not allow auto-login or a low-security mode.",
                "First, a strong caveat that this answer is not the best fit for this exact question. It should definitely not be the top answer!I will go ahead and mention Mozilla\u2019s proposed BrowserID (or perhaps more precisely, the Verified Email Protocol) in the spirit of finding an upgrade path to better approaches to authentication in the future.I\u2019ll summarize it this way:This is not strictly \u201cform-based authentication for websites\u201d. But it is an effort to transition from the current norm of form-based authentication to something more secure: browser-supported authentication.",
                "I just thought I'd share this solution that I found to be working just fine.I call it the Dummy Field (though I haven't invented this so don't credit me). Others know this as a honey pot.In short: you just have to insert this into your <form> and check for it to be empty at when validating:The trick is to fool a bot into thinking it has to insert data into a required field, that's why I named the input \"email\". If you already have a field called email that you're using you should try naming the dummy field something else like \"company\", \"phone\" or \"emailaddress\". Just pick something you know you don't need and what sounds like something people would normally find logical to fill in into a web form. Now hide the input field using CSS or JavaScript/jQuery - whatever fits you best - just don't set the input type to hidden or else the bot won't fall for it.When you are validating the form (either client or server side) check if your dummy field has been filled to determine if it was sent by a human or a bot.Example:In case of a human:\nThe user will not see the dummy field (in my case named \"email\") and will not attempt to fill it. So the value of the dummy field should still be empty when the form has been sent.In case of a bot: The bot will see a field whose type is text and a name email (or whatever it is you called it) and will logically attempt to fill it with appropriate data. It doesn't care if you styled the input form with some fancy CSS, web-developers do it all the time. Whatever the value in the dummy field is, we don't care as long as it's larger than 0 characters.I used this method on a guestbook in combination with CAPTCHA, and I haven't seen a single spam post since. I had used a CAPTCHA-only solution before, but eventually, it resulted in about five spam posts every hour. Adding the dummy field in the form has stopped (at least until now) all the spam from appearing.I believe this can also be used just fine with a login/authentication form.Warning: Of course this method is not 100% foolproof. Bots can be programmed to ignore input fields with the style display:none applied to it. You also have to think about people who use some form of auto-completion (like most browsers have built-in!) to auto-fill all form fields for them. They might just as well pick up a dummy field.You can also vary this up a little by leaving the dummy field visible but outside the boundaries of the screen, but this is totally up to you.Be creative!",
                "I do not think the above answer is \"wrong\" but there are large areas of authentication that are not touched upon (or rather the emphasis is on \"how to implement cookie sessions\", not on \"what options are available and what are the trade-offs\".My suggested edits/answers areDo NOT try to implement your own login form or database storage of passwords, unless \nthe data being stored is valueless at account creation and self-generated (that is, web 2.0 style like Facebook, Flickr, etc.)This avoids any need to have \"sessions\" or cookies as the browser itself will re-encrypt the communication each time. It is the most \"lightweight\" development approach.However, I do not recommend this, except for public, low-value services. This is an issue with some of the other answers above - do not try an re-implement server-side authentication mechanisms - this problem has been solved and is supported by most major browsers. Do not use cookies. Do not store anything in your own hand-rolled database. Just ask, per request, if the request is authenticated. Everything else should be supported by configuration and third-party trusted software.So ...First, we are confusing the initial creation of an account (with a password) with the re-checking of the password subsequently. If I am Flickr and creating your site for the first time, the new user has access to zero value (blank web space). I truly do not care if the person creating the account is lying about their name. If I am creating an account of the hospital intranet/extranet, the value lies in all the medical records, and so I do care about the identity (*) of the account creator.This is the very very hard part. The only decent solution is a web of trust. For example, you join the hospital as a doctor. You create a web page hosted somewhere with your photo, your passport number, and a public key, and hash them all with the private key. You then visit the hospital and the system administrator looks at your passport, sees if the photo matches you, and then hashes the web page/photo hash with the hospital private key. From now on we can securely exchange keys and tokens. As can anyone who trusts the hospital (there is the secret sauce BTW). The system administrator can also give you an RSA dongle or other two-factor authentication.But this is a lot of a hassle, and not very web 2.0. However, it is the only secure way to create new accounts that have access to valuable information that is not self-created.Kerberos and SPNEGO - single sign-on mechanisms with a trusted third party - basically the user verifies against a trusted third party. (NB this is not in any way the not to be trusted OAuth)SRP - sort of clever password authentication without a trusted third party. But here we are getting into the realms of \"it's safer to use two-factor authentication, even if that's costlier\"SSL client side - give the clients a public key certificate (support in all major browsers - but raises questions over client machine security).In the end, it's a tradeoff - what is the cost of a security breach vs the cost of implementing more secure approaches. One day, we may see a proper PKI widely accepted and so no more own rolled authentication forms and databases. One day...",
                "When hashing, don't use fast hash algorithms such as MD5 (many hardware implementations exist).  Use something like SHA-512.  For passwords, slower hashes are better.The faster you can create hashes, the faster any brute force checker can work. Slower hashes will therefore slow down brute forcing. A slow hash algorithm will make brute forcing impractical for longer passwords (8 digits +)",
                "My favourite rule in regards to authentication systems: use passphrases, not passwords. Easy to remember, hard to crack.\nMore info: Coding Horror: Passwords vs. Pass Phrases",
                "I'd like to add one suggestion I've used, based on defense in depth. You don't need to have the same auth&auth system for admins as regular users. You can have a separate login form on a separate url executing separate code for requests that will grant high privileges. This one can make choices that would be a total pain to regular users. One such that I've used is to actually scramble the login URL for admin access and email the admin the new URL. Stops any brute force attack right away as your new URL can be arbitrarily difficult (very long random string) but your admin user's only inconvenience is following a link in their email. The attacker no longer knows where to even POST to.",
                "I dont't know whether it was best to answer this as an answer or as a comment. I opted for the first option.Regarding the poing PART IV: Forgotten Password Functionality in the first answer, I would make a point about Timing Attacks.In the Remember your password forms, an attacker could potentially check a full list of emails and detect which are registered to the system (see link below).Regarding the Forgotten Password Form, I would add that it is a good idea to equal times between successful and unsucessful queries with some delay function.https://crypto.stanford.edu/~dabo/papers/webtiming.pdf",
                "I would like to add one very important comment: -Many corporations deploy \"internal use only\" websites which are, effectively, \"corporate applications\" that happen to have been implemented through URLs. These URLs can (supposedly ...) only be resolved within \"the company's internal network.\" (Which network magically includes all VPN-connected 'road warriors.')When a user is dutifully-connected to the aforesaid network, their identity (\"authentication\") is [already ...] \"conclusively known,\" as is their permission (\"authorization\") to do certain things ... such as ... \"to access this website.\"This \"authentication + authorization\" service can be provided by several different technologies, such as LDAP (Microsoft OpenDirectory), or Kerberos.From your point-of-view, you simply know this: that anyone who legitimately winds-up at your website must be accompanied by [an environment-variable magically containing ...] a \"token.\" (i.e. The absence of such a token must be immediate grounds for 404 Not Found.)The token's value makes no sense to you, but, should the need arise, \"appropriate means exist\" by which your website can \"[authoritatively] ask someone who knows (LDAP... etc.)\" about any and every(!) question that you may have. In other words, you do not avail yourself of any \"home-grown logic.\" Instead, you inquire of The Authority and implicitly trust its verdict.Uh huh ... it's quite a mental-switch from the \"wild-and-wooly Internet.\"",
                "Use OpenID Connect or User-Managed Access.As nothing is more efficient than not doing it at all."
            ]
        },
        {
            "tag": "",
            "question": [
                "Why is processing a sorted array faster than processing an unsorted array?",
                "Here is a piece of C++ code that shows some very peculiar behavior.\nFor some reason, sorting the data (before the timed region) miraculously makes the primary loop almost six times faster:\n#include &..."
            ],
            "url": "https://stackoverflow.com/questions/11227809",
            "answer": [
                "You are a victim of branch prediction fail.Consider a railroad junction:Image by Mecanismo, via Wikimedia Commons. Used under the CC-By-SA 3.0 license.Now for the sake of argument, suppose this is back in the 1800s - before long-distance or radio communication.You are a blind operator of a junction and you hear a train coming. You have no idea which way it is supposed to go. You stop the train to ask the driver which direction they want. And then you set the switch appropriately.Trains are heavy and have a lot of inertia, so they take forever to start up and slow down.Is there a better way? You guess which direction the train will go!If you guess right every time, the train will never have to stop.\nIf you guess wrong too often, the train will spend a lot of time stopping, backing up, and restarting.Consider an if-statement: At the processor level, it is a branch instruction:You are a processor and you see a branch. You have no idea which way it will go. What do you do? You halt execution and wait until the previous instructions are complete. Then you continue down the correct path.Modern processors are complicated and have long pipelines. This means they take forever to \"warm up\" and \"slow down\".Is there a better way? You guess which direction the branch will go!If you guess right every time, the execution will never have to stop.\nIf you guess wrong too often, you spend a lot of time stalling, rolling back, and restarting.This is branch prediction. I admit it's not the best analogy since the train could just signal the direction with a flag. But in computers, the processor doesn't know which direction a branch will go until the last moment.How would you strategically guess to minimize the number of times that the train must back up and go down the other path? You look at the past history! If the train goes left 99% of the time, then you guess left. If it alternates, then you alternate your guesses. If it goes one way every three times, you guess the same...In other words, you try to identify a pattern and follow it. This is more or less how branch predictors work.Most applications have well-behaved branches. Therefore, modern branch predictors will typically achieve >90% hit rates. But when faced with unpredictable branches with no recognizable patterns, branch predictors are virtually useless.Further reading: \"Branch predictor\" article on Wikipedia.Notice that the data is evenly distributed between 0 and 255. When the data is sorted, roughly the first half of the iterations will not enter the if-statement. After that, they will all enter the if-statement.This is very friendly to the branch predictor since the branch consecutively goes the same direction many times. Even a simple saturating counter will correctly predict the branch except for the few iterations after it switches direction.Quick visualization:However, when the data is completely random, the branch predictor is rendered useless, because it can't predict random data. Thus there will probably be around 50% misprediction (no better than random guessing).What can be done?If the compiler isn't able to optimize the branch into a conditional move, you can try some hacks if you are willing to sacrifice readability for performance.Replace:with:This eliminates the branch and replaces it with some bitwise operations.(Note that this hack is not strictly equivalent to the original if-statement. But in this case, it's valid for all the input values of data[].)Benchmarks: Core i7 920 @ 3.5 GHzC++ - Visual Studio 2010 - x64 ReleaseJava - NetBeans 7.1.1 JDK 7 - x64Observations:A general rule of thumb is to avoid data-dependent branching in critical loops (such as in this example).Update:GCC 4.6.1 with -O3 or -ftree-vectorize on x64 is able to generate a conditional move, so there is no difference between the sorted and unsorted data - both are fast.(Or somewhat fast: for the already-sorted case, cmov can be slower especially if GCC puts it on the critical path instead of just add, especially on Intel before Broadwell where cmov has 2 cycle latency: gcc optimization flag -O3 makes code slower than -O2)VC++ 2010 is unable to generate conditional moves for this branch even under /Ox.Intel C++ Compiler (ICC) 11 does something miraculous. It interchanges the two loops, thereby hoisting the unpredictable branch to the outer loop. Not only is it immune to the mispredictions, it's also twice as fast as whatever VC++ and GCC can generate! In other words, ICC took advantage of the test-loop to defeat the benchmark...If you give the Intel compiler the branchless code, it just outright vectorizes it... and is just as fast as with the branch (with the loop interchange).This goes to show that even mature modern compilers can vary wildly in their ability to optimize code...",
                "Branch prediction.With a sorted array, the condition data[c] >= 128 is first false for a streak of values, then becomes true for all later values. That's easy to predict. With an unsorted array, you pay for the branching cost.",
                "The reason why performance improves drastically when the data is sorted is that the branch prediction penalty is removed, as explained beautifully in Mysticial's answer.Now, if we look at the codewe can find that the meaning of this particular if... else... branch is to add something when a condition is satisfied. This type of branch can be easily transformed into a conditional move statement, which would be compiled into a conditional move instruction: cmovl, in an x86 system. The branch and thus the potential branch prediction penalty is removed.In C, thus C++, the statement, which would compile directly (without any optimization) into the conditional move instruction in x86, is the ternary operator ... ? ... : .... So we rewrite the above statement into an equivalent one:While maintaining readability, we can check the speedup factor.On an Intel Core i7-2600K @ 3.4\u00a0GHz and Visual Studio 2010 Release Mode, the benchmark is:x86x64The result is robust in multiple tests. We get a great speedup when the branch result is unpredictable, but we suffer a little bit when it is predictable. In fact, when using a conditional move, the performance is the same regardless of the data pattern.Now let's look more closely by investigating the x86 assembly they generate. For simplicity, we use two functions max1 and max2.max1 uses the conditional branch if... else ...:max2 uses the ternary operator ... ? ... : ...:On an x86-64 machine, GCC -S generates the assembly below.max2 uses much less code due to the usage of instruction cmovge. But the real gain is that max2 does not involve branch jumps, jmp, which would have a significant performance penalty if the predicted result is not right.So why does a conditional move perform better?In a typical x86 processor, the execution of an instruction is divided into several stages. Roughly, we have different hardware to deal with different stages. So we do not have to wait for one instruction to finish to start a new one. This is called pipelining.In a branch case, the following instruction is determined by the preceding one, so we cannot do pipelining. We have to either wait or predict.In a conditional move case, the execution of conditional move instruction is divided into several stages, but the earlier stages like Fetch and Decode do not depend on the result of the previous instruction; only the latter stages need the result. Thus, we wait a fraction of one instruction's execution time. This is why the conditional move version is slower than the branch when the prediction is easy.The book Computer Systems: A Programmer's Perspective, second edition explains this in detail. You can check Section 3.6.6 for Conditional Move Instructions, entire Chapter 4 for Processor Architecture, and Section 5.11.2 for special treatment for Branch Prediction and Misprediction Penalties.Sometimes, some modern compilers can optimize our code to assembly with better performance, and sometimes some compilers can't (the code in question is using Visual Studio's native compiler). Knowing the performance difference between a branch and a conditional move when unpredictable can help us write code with better performance when the scenario gets so complex that the compiler can not optimize them automatically.",
                "If you are curious about even more optimizations that can be done to this code, consider this:Starting with the original loop:With loop interchange, we can safely change this loop to:Then, you can see that the if conditional is constant throughout the execution of the i loop, so you can hoist the if out:Then, you see that the inner loop can be collapsed into one single expression, assuming the floating point model allows it (/fp:fast is thrown, for example)That one is 100,000 times faster than before.",
                "No doubt some of us would be interested in ways of identifying code that is problematic for the CPU's branch-predictor. The Valgrind tool cachegrind has a branch-predictor simulator, enabled by using the --branch-sim=yes flag. Running it over the examples in this question, with the number of outer loops reduced to 10000 and compiled with g++, gives these results:Sorted:Unsorted:Drilling down into the line-by-line output produced by cg_annotate we see for the loop in question:Sorted:Unsorted:This lets you easily identify the problematic line - in the unsorted version the if (data[c] >= 128) line is causing 164,050,007 mispredicted conditional branches (Bcm) under cachegrind's branch-predictor model, whereas it's only causing 10,006 in the sorted version.Alternatively, on Linux you can use the performance counters subsystem to accomplish the same task, but with native performance using CPU counters.Sorted:Unsorted:It can also do source code annotation with dissassembly.See the performance tutorial for more details.",
                "I just read up on this question and its answers, and I feel an answer is missing.A common way to eliminate branch prediction that I've found to work particularly good in managed languages is a table lookup instead of using a branch (although I haven't tested it in this case).This approach works in general if:Background and whyFrom a processor perspective, your memory is slow. To compensate for the difference in speed, a couple of caches are built into your processor (L1/L2 cache). So imagine that you're doing your nice calculations and figure out that you need a piece of memory. The processor will get its 'load' operation and loads the piece of memory into cache -- and then uses the cache to do the rest of the calculations. Because memory is relatively slow, this 'load' will slow down your program.Like branch prediction, this was optimized in the Pentium processors: the processor predicts that it needs to load a piece of data and attempts to load that into the cache before the operation actually hits the cache. As we've already seen, branch prediction sometimes goes horribly wrong -- in the worst case scenario you need to go back and actually wait for a memory load, which will take forever (in other words: failing branch prediction is bad, a memory load after a branch prediction fail is just horrible!).Fortunately for us, if the memory access pattern is predictable, the processor will load it in its fast cache and all is well.The first thing we need to know is what is small? While smaller is generally better, a rule of thumb is to stick to lookup tables that are <= 4096 bytes in size. As an upper limit: if your lookup table is larger than 64K it's probably worth reconsidering.Constructing a tableSo we've figured out that we can create a small table. Next thing to do is get a lookup function in place. Lookup functions are usually small functions that use a couple of basic integer operations (and, or, xor, shift, add, remove and perhaps multiply). You want to have your input translated by the lookup function to some kind of 'unique key' in your table, which then simply gives you the answer of all the work you wanted it to do.In this case: >= 128 means we can keep the value, < 128 means we get rid of it. The easiest way to do that is by using an 'AND': if we keep it, we AND it with 7FFFFFFF; if we want to get rid of it, we AND it with 0. Notice also that 128 is a power of 2 -- so we can go ahead and make a table of 32768/128 integers and fill it with one zero and a lot of 7FFFFFFFF's.Managed languagesYou might wonder why this works well in managed languages. After all, managed languages check the boundaries of the arrays with a branch to ensure you don't mess up...Well, not exactly... :-)There has been quite some work on eliminating this branch for managed languages. For example:In this case, it's obvious to the compiler that the boundary condition will never be hit. At least the Microsoft JIT compiler (but I expect Java does similar things) will notice this and remove the check altogether. WOW, that means no branch. Similarly, it will deal with other obvious cases.If you run into trouble with lookups in managed languages -- the key is to add a & 0x[something]FFF to your lookup function to make the boundary check predictable -- and watch it going faster.The result of this case",
                "As data is distributed between 0 and 255 when the array is sorted, around the first half of the iterations will not enter the if-statement (the if statement is shared below).The question is: What makes the above statement not execute in certain cases as in case of sorted data? Here comes the \"branch predictor\". A branch predictor is a digital circuit that tries to guess which way a branch (e.g. an if-then-else structure) will go before this is known for sure. The purpose of the branch predictor is to improve the flow in the instruction pipeline. Branch predictors play a critical role in achieving high effective performance!Let's do some bench marking to understand it betterThe performance of an if-statement depends on whether its condition has a predictable pattern. If the condition is always true or always false, the branch prediction logic in the processor will pick up the pattern. On the other hand, if the pattern is unpredictable, the if-statement will be much more expensive.Let\u2019s measure the performance of this loop with different conditions:Here are the timings of the loop with different true-false patterns:A \u201cbad\u201d true-false pattern can make an if-statement up to six times slower than a \u201cgood\u201d pattern! Of course, which pattern is good and which is bad depends on the exact instructions generated by the compiler and on the specific processor.So there is no doubt about the impact of branch prediction on performance!",
                "One way to avoid branch prediction errors is to build a lookup table, and index it using the data.  Stefan de Bruijn discussed that in his answer.But in this case, we know values are in the range [0, 255] and we only care about values >= 128.  That means we can easily extract a single bit that will tell us whether we want a value or not: by shifting the data to the right 7 bits, we are left with a 0 bit or a 1 bit, and we only want to add the value when we have a 1 bit.  Let's call this bit the \"decision bit\".By using the 0/1 value of the decision bit as an index into an array, we can make code that will be equally fast whether the data is sorted or not sorted.  Our code will always add a value, but when the decision bit is 0, we will add the value somewhere we don't care about.  Here's the code:This code wastes half of the adds but never has a branch prediction failure.  It's tremendously faster on random data than the version with an actual if statement.But in my testing, an explicit lookup table was slightly faster than this, probably because indexing into a lookup table was slightly faster than bit shifting.  This shows how my code sets up and uses the lookup table (unimaginatively called lut for \"LookUp Table\" in the code).  Here's the C++ code:In this case, the lookup table was only 256 bytes, so it fits nicely in a cache and all was fast.  This technique wouldn't work well if the data was 24-bit values and we only wanted half of them... the lookup table would be far too big to be practical.  On the other hand, we can combine the two techniques shown above: first shift the bits over, then index a lookup table.  For a 24-bit value that we only want the top half value, we could potentially shift the data right by 12 bits, and be left with a 12-bit value for a table index.  A 12-bit table index implies a table of 4096 values, which might be practical.The technique of indexing into an array, instead of using an if statement, can be used for deciding which pointer to use.  I saw a library that implemented binary trees, and instead of having two named pointers (pLeft and pRight or whatever) had a length-2 array of pointers and used the \"decision bit\" technique to decide which one to follow.  For example, instead of:this library would do something like:Here's a link to this code: Red Black Trees, Eternally Confuzzled",
                "In the sorted case, you can do better than relying on successful branch prediction or any branchless comparison trick: completely remove the branch.Indeed, the array is partitioned in a contiguous zone with data < 128 and another with data >= 128. So you should find the partition point with a dichotomic search (using Lg(arraySize) = 15 comparisons), then do a straight accumulation from that point.Something like (unchecked)or, slightly more obfuscatedA yet faster approach, that gives an approximate solution for both sorted or unsorted is: sum= 3137536; (assuming a truly uniform distribution, 16384 samples with expected value 191.5) :-)",
                "The above behavior is happening because of Branch prediction.To understand branch prediction one must first understand an Instruction Pipeline.The the steps of running an instruction can be overlapped with the sequence of steps of running the previous and next instruction, so that different steps can be executed concurrently in parallel. This technique is known as instruction pipelining and is used to increase throughput in modern processors. To understand this better please see this example on Wikipedia.Generally, modern processors have quite long (and wide) pipelines, so many instruction can be in flight.  See Modern Microprocessors\nA 90-Minute Guide! which starts by introducing basic in-order pipelining and goes from there.But for ease let's consider a simple in-order pipeline with these 4 steps only.\n(Like a classic 5-stage RISC, but omitting a separate MEM stage.)4-stage pipeline in general for 2 instructions.Moving back to the above question let's consider the following instructions:Without branch prediction, the following would occur:To execute instruction B or instruction C the processor will have to wait (stall) till the instruction A leaves the EX stage in the pipeline, as the decision to go to instruction B or instruction C depends on the result of instruction A.  (i.e. where to fetch from next.) So the pipeline will look like this:Without prediction: when if condition is true:Without prediction: When if condition is false:As a result of waiting for the result of instruction A, the total CPU cycles spent in the above case (without branch prediction; for both true and false) is 7.So what is branch prediction?Branch predictor will try to guess which way a branch (an if-then-else structure) will go before this is known for sure. It will not wait for the instruction A to reach the EX stage of the pipeline, but it will guess the decision and go to that instruction (B or C in case of our example).In case of a correct guess, the pipeline looks something like this:If it is later detected that the guess was wrong then the partially executed instructions are discarded and the pipeline starts over with the correct branch, incurring a delay.\nThe time that is wasted in case of a branch misprediction is equal to the number of stages in the pipeline from the fetch stage to the execute stage. Modern microprocessors tend to have quite long pipelines so that the misprediction delay is between 10 and 20 clock cycles. The longer the pipeline the greater the need for a good branch predictor.In the OP's code, the first time when the conditional, the branch predictor does not have any information to base up prediction, so the first time it will randomly choose the next instruction. (Or fall back to static prediction, typically forward not-taken, backward taken).  Later in the for loop, it can base the prediction on the history.\nFor an array sorted in ascending order, there are three possibilities:Let us assume that the predictor will always assume the true branch on the first run.So in the first case, it will always take the true branch since historically all its predictions are correct.\nIn the 2nd case, initially it will predict wrong, but after a few iterations, it will predict correctly.\nIn the 3rd case, it will initially predict correctly till the elements are less than 128. After which it will fail for some time and the correct itself when it sees branch prediction failure in history.In all these cases the failure will be too less in number and as a result, only a few times it will need to discard the partially executed instructions and start over with the correct branch, resulting in fewer CPU cycles.But in case of a random unsorted array, the prediction will need to discard the partially executed instructions and start over with the correct branch most of the time and result in more CPU cycles compared to the sorted array.Further reading:",
                "An official answer would be fromYou can also see from this lovely diagram why the branch predictor gets confused.Each element in the original code is a random valueso the predictor will change sides as the std::rand() blow.On the other hand, once it's sorted, the predictor will first move into a state of strongly not taken and when the values change to the high value the predictor will in three runs through change all the way from strongly not taken to strongly taken.",
                "In the same line (I think this was not highlighted by any answer) it's good to mention that sometimes (specially in software where the performance matters\u2014like in the Linux kernel) you can find some if statements like the following:or similarly:Both likely() and unlikely() are in fact macros that are defined by using something like the GCC's __builtin_expect to help the compiler insert prediction code to favour the condition taking into account the information provided by the user. GCC supports other builtins that could change the behavior of the running program or emit low level instructions like clearing the cache, etc. See this documentation that goes through the available GCC's builtins.Normally this kind of optimizations are mainly found in hard-real time applications or embedded systems where execution time matters and it's critical. For example, if you are checking for some error condition that only happens 1/10000000 times, then why not inform the compiler about this? This way, by default, the branch prediction would assume that the condition is false.",
                "Frequently used Boolean operations in C++ produce many branches in the compiled program. If these branches are inside loops and are hard to predict they can slow down execution significantly. Boolean variables are stored as 8-bit integers with the value 0 for false and 1 for true.Boolean variables are overdetermined in the sense that all operators that have Boolean variables as input check if the inputs have any other value than 0 or 1, but operators that have Booleans as output can produce no other value than 0 or 1. This makes operations with Boolean variables as input less efficient than necessary.\nConsider example:This is typically implemented by the compiler in the following way:This code is far from optimal. The branches may take a long time in case of mispredictions. The Boolean operations can be made much more efficient if it is known with certainty that the operands have no other values than 0 and 1. The reason why the compiler does not make such an assumption is that the variables might have other values if they are uninitialized or come from unknown sources. The above code can be optimized if a and b has been initialized to valid values or if they come from operators that produce Boolean output. The optimized code looks like this:char is used instead of bool in order to make it possible to use the bitwise operators (& and |) instead of the Boolean operators (&& and ||). The bitwise operators are single instructions that take only one clock cycle. The OR operator (|) works even if a and b have other values than 0 or 1. The AND operator (&) and the EXCLUSIVE OR operator (^) may give inconsistent results if the operands have other values than 0 and 1.~ can not be used for NOT. Instead, you can make a Boolean NOT on a variable which is known to be 0 or 1 by XOR'ing it with 1:can be optimized to:a && b cannot be replaced with a & b if b is an expression that should not be evaluated if a is false ( && will not evaluate b, & will). Likewise, a || b can not be replaced with a | b if b is an expression that should not be evaluated if a is true.Using bitwise operators is more advantageous if the operands are variables than if the operands are comparisons:is optimal in most cases (unless you expect the && expression to generate many branch mispredictions).",
                "That's for sure!...Branch prediction makes the logic run slower, because of the switching which happens in your code! It's like you are going a straight street or a street with a lot of turnings, for sure the straight one is going to be done quicker!...If the array is sorted, your condition is false at the first step: data[c] >= 128, then becomes a true value for the whole way to the end of the street. That's how you get to the end of the logic faster. On the other hand, using an unsorted array, you need a lot of turning and processing which make your code run slower for sure...Look at the image I created for you below. Which street is going to be finished faster?So programmatically, branch prediction causes the process to be slower...Also at the end, it's good to know we have two kinds of branch predictions that each is going to affect your code differently:1. Static2. DynamicStatic branch prediction is used by the microprocessor the first time\na conditional branch is encountered, and dynamic branch prediction is\nused for succeeding executions of the conditional branch code.In order to effectively write your code to take advantage of these\nrules, when writing if-else or switch statements, check the most\ncommon cases first and work progressively down to the least common.\nLoops do not necessarily require any special ordering of code for\nstatic branch prediction, as only the condition of the loop iterator\nis normally used.",
                "This question has already been answered excellently many times over. Still I'd like to draw the group's attention to yet another interesting analysis.Recently this example (modified very slightly) was also used as a way to demonstrate how a piece of code can be profiled within the program itself on Windows. Along the way, the author also shows how to use the results to determine where the code is spending most of its time in both the sorted & unsorted case. Finally the piece also shows how to use a little known feature of the HAL (Hardware Abstraction Layer) to determine just how much branch misprediction is happening in the unsorted case.The link is here:\nA Demonstration of Self-Profiling",
                "As what has already been mentioned by others, what behind the mystery is Branch Predictor.I'm not trying to add something but explaining the concept in another way. \nThere is a concise introduction on the wiki which contains text and diagram.\nI do like the explanation below which uses a diagram to elaborate the Branch Predictor intuitively.In computer architecture, a branch predictor is a\n  digital circuit that tries to guess which way a branch (e.g. an\n  if-then-else structure) will go before this is known for sure. The\n  purpose of the branch predictor is to improve the flow in the\n  instruction pipeline. Branch predictors play a critical role in\n  achieving high effective performance in many modern pipelined\n  microprocessor architectures such as x86.Two-way branching is usually implemented with a conditional jump\n  instruction. A conditional jump can either be \"not taken\" and continue\n  execution with the first branch of code which follows immediately\n  after the conditional jump, or it can be \"taken\" and jump to a\n  different place in program memory where the second branch of code is\n  stored. It is not known for certain whether a conditional jump will be\n  taken or not taken until the condition has been calculated and the\n  conditional jump has passed the execution stage in the instruction\n  pipeline (see fig. 1).Based on the described scenario, I have written an animation demo to show how instructions are executed in a pipeline in different situations.Without branch prediction, the processor would have to wait until the\n  conditional jump instruction has passed the execute stage before the\n  next instruction can enter the fetch stage in the pipeline.The example contains three instructions and the first one is a conditional jump instruction. The latter two instructions can go into the pipeline until the conditional jump instruction is executed.It will take 9 clock cycles for 3 instructions to be completed.It will take 7 clock cycles for 3 instructions to be completed.It will take 9 clock cycles for 3 instructions to be completed.The time that is wasted in case of a branch misprediction is equal to\n  the number of stages in the pipeline from the fetch stage to the\n  execute stage. Modern microprocessors tend to have quite long\n  pipelines so that the misprediction delay is between 10 and 20 clock\n  cycles. As a result, making a pipeline longer increases the need for a\n  more advanced branch predictor.As you can see, it seems we don't have a reason not to use Branch Predictor.It's quite a simple demo that clarifies the very basic part of Branch Predictor. If those gifs are annoying, please feel free to remove them from the answer and visitors can also get the live demo source code from BranchPredictorDemo",
                "Branch-prediction gain!It is important to understand that branch misprediction doesn't slow down programs. The cost of a missed prediction is just as if branch prediction didn't exist and you waited for the evaluation of the expression to decide what code to run (further explanation in the next paragraph).Whenever there's an if-else \\ switch statement, the expression has to be evaluated to determine which block should be executed. In the assembly code generated by the compiler, conditional branch instructions are inserted.A branch instruction can cause a computer to begin executing a different instruction sequence and thus deviate from its default behavior of executing instructions in order (i.e. if the expression is false, the program skips the code of the if block) depending on some condition, which is the expression evaluation in our case.That being said, the compiler tries to predict the outcome prior to it being actually evaluated. It will fetch instructions from the if block, and if the expression turns out to be true, then wonderful! We gained the time it took to evaluate it and made progress in the code; if not then we are running the wrong code, the pipeline is flushed, and the correct block is run.Let's say you need to pick route 1 or route 2. Waiting for your partner to check the map, you have stopped at ## and waited, or you could just pick route1 and if you were lucky (route 1 is the correct route), then great you didn't have to wait for your partner to check the map (you saved the time it would have taken him to check the map), otherwise you will just turn back.While flushing pipelines is super fast, nowadays taking this gamble is worth it. Predicting sorted data or a data that changes slowly is always easier and better than predicting fast changes.",
                "On ARM, there is no branch needed, because every instruction has a 4-bit condition field, which tests (at zero cost) any of 16 different different conditions that may arise in the Processor Status Register, and if the condition on an instruction is false, the instruction is skipped. This eliminates the need for short branches, and there would be no branch prediction hit for this algorithm. Therefore, the sorted version of this algorithm would run slower than the unsorted version on ARM, because of the extra overhead of sorting.The inner loop for this algorithm would look something like the following in ARM assembly language:But this is actually part of a bigger picture:CMP opcodes always update the status bits in the Processor Status Register (PSR), because that is their purpose, but most other instructions do not touch the PSR unless you add an optional S suffix to the instruction, specifying that the PSR should be updated based on the result of the instruction. Just like the 4-bit condition suffix, being able to execute instructions without affecting the PSR is a mechanism that reduces the need for branches on ARM, and also facilitates out of order dispatch at the hardware level, because after performing some operation X that updates the status bits, subsequently (or in parallel) you can do a bunch of other work that explicitly should not affect (or be affected by) the status bits, then you can test the state of the status bits set earlier by X.The condition testing field and the optional \"set status bit\" field can be combined, for example:Most processor architectures do not have this ability to specify whether or not the status bits should be updated for a given operation, which can necessitate writing additional code to save and later restore status bits, or may require additional branches, or may limit the processor's out of order execution efficiency: one of the side effects of most CPU instruction set architectures forcibly updating status bits after most instructions is that it is much harder to tease apart which instructions can be run in parallel without interfering with each other. Updating status bits has side effects, therefore has a linearizing effect on code. ARM's ability to mix and match branch-free condition testing on any instruction with the option to either update or not update the status bits after any instruction is extremely powerful, for both assembly language programmers and compilers, and produces very efficient code.When you don't have to branch, you can avoid the time cost of flushing the pipeline for what would otherwise be short branches, and you can avoid the design complexity of many forms of speculative evalution. The performance impact of the initial naive imlementations of the mitigations for many recently discovered processor vulnerabilities (Spectre etc.) shows you just how much the performance of modern processors depends upon complex speculative evaluation logic. With a short pipeline and the dramatically reduced need for branching, ARM just doesn't need to rely on speculative evaluation as much as CISC processors. (Of course high-end ARM implementations do include speculative evaluation, but it's a smaller part of the performance story.)If you have ever wondered why ARM has been so phenomenally successful, the brilliant effectiveness and interplay of these two mechanisms (combined with another mechanism that lets you \"barrel shift\" left or right one of the two arguments of any arithmetic operator or offset memory access operator at zero additional cost) are a big part of the story, because they are some of the greatest sources of the ARM architecture's efficiency. The brilliance of the original designers of the ARM ISA back in 1983, Steve Furber and Roger (now Sophie) Wilson, cannot be overstated.",
                "It's about branch prediction. What is it?A branch predictor is one of the ancient performance-improving techniques which still finds relevance in modern architectures. While the simple prediction techniques provide fast lookup and power efficiency they suffer from a high misprediction rate.On the other hand, complex branch predictions \u2013either neural-based or variants of two-level branch prediction \u2013provide better prediction accuracy, but they consume more power and complexity increases exponentially.In addition to this, in complex prediction techniques, the time taken to predict the branches is itself very high \u2013ranging from 2 to 5 cycles \u2013which is comparable to the execution time of actual branches.Branch prediction is essentially an optimization (minimization) problem where the emphasis is on to achieve lowest possible miss rate, low power consumption, and low complexity with minimum resources.There really are three different kinds of branches:Forward conditional branches - based on a run-time condition, the PC (program counter) is changed to point to an address forward in the instruction stream.Backward conditional branches - the PC is changed to point backward in the instruction stream. The branch is based on some condition, such as branching backwards to the beginning of a program loop when a test at the end of the loop states the loop should be executed again.Unconditional branches - this includes jumps, procedure calls, and returns that have no specific condition. For example, an unconditional jump instruction might be coded in assembly language as simply \"jmp\", and the instruction stream must immediately be directed to the target location pointed to by the jump instruction, whereas a conditional jump that might be coded as \"jmpne\" would redirect the instruction stream only if the result of a comparison of two values in a previous \"compare\" instructions shows the values to not be equal. (The segmented addressing scheme used by the x86 architecture adds extra complexity since jumps can be either \"near\" (within a segment) or \"far\" (outside the segment). Each type has different effects on branch prediction algorithms.)Static/dynamic Branch Prediction: Static branch prediction is used by the microprocessor the first time a conditional branch is encountered, and dynamic branch prediction is used for succeeding executions of the conditional branch code.References:Branch predictorA Demonstration of Self-ProfilingBranch Prediction ReviewBranch Prediction (Using wayback machine)",
                "Besides the fact that the branch prediction may slow you down, a sorted array has another advantage:You can have a stop condition instead of just checking the value, this way you only loop over the relevant data, and ignore the rest.\nThe branch prediction will miss only once.",
                "Sorted arrays are processed faster than an unsorted array, due to a phenomena called branch prediction.The branch predictor is a digital circuit (in computer architecture) trying to predict which way a branch will go, improving the flow in the instruction pipeline. The circuit/computer predicts the next step and executes it.Making a wrong prediction leads to going back to the previous step, and executing with another prediction. Assuming the prediction is correct, the code will continue to the next step. A wrong prediction results in repeating the same step, until a correct prediction occurs.The answer to your question is very simple.In an unsorted array, the computer makes multiple predictions, leading to an increased chance of errors.\nWhereas, in a sorted array, the computer makes fewer predictions, reducing the chance of errors.\nMaking more predictions requires more time.Sorted Array: Straight RoadUnsorted Array: Curved RoadBranch prediction: Guessing/predicting which road is straight and following it without checkingAlthough both the roads reach the same destination, the straight road is shorter, and the other is longer. If then you choose the other by mistake, there is no turning back, and so you will waste some extra time if you choose the longer road. This is similar to what happens in the computer, and I hope this helped you understand better.Also I want to cite @Simon_Weaver from the comments:It doesn\u2019t make fewer predictions - it makes fewer incorrect predictions. It still has to predict for each time through the loop...",
                "I tried the same code with MATLAB 2011b with my MacBook Pro (Intel i7, 64 bit, 2.4 GHz) for the following MATLAB code:The results for the above MATLAB code are as follows:The results of the C code as in @GManNickG I get:Based on this, it looks MATLAB is almost 175 times slower than the C implementation without sorting and 350 times slower with sorting. In other words, the effect (of branch prediction) is 1.46x for MATLAB implementation and 2.7x for the C implementation.",
                "The assumption by other answers that one needs to sort the data is not correct.The following code does not sort the entire array, but only 200-element segments of it, and thereby runs the fastest.Sorting only k-element sections completes the pre-processing in linear time, O(n), rather than the O(n.log(n)) time needed to sort the entire array.This also \"proves\" that it has nothing to do with any algorithmic issue such as sort order, and it is indeed branch prediction.",
                "Bjarne Stroustrup's Answer to this question:That sounds like an interview question. Is it true? How would you know? It is a bad idea to answer questions about efficiency without first doing some measurements, so it is important to know how to measure.So, I tried with a vector of a million integers and got:I ran that a few times to be sure. Yes, the phenomenon is real. My key code was:At least the phenomenon is real with this compiler, standard library, and optimizer settings. Different implementations can and do give different answers. In fact, someone did do a more systematic study (a quick web search will find it) and most implementations show that effect.One reason is branch prediction: the key operation in the sort algorithm is \u201cif(v[i] < pivot]) \u2026\u201d or equivalent. For a sorted sequence that test is always true whereas, for a random sequence, the branch chosen varies randomly.Another reason is that when the vector is already sorted, we never need to move elements to their correct position. The effect of these little details is the factor of five or six that we saw.Quicksort (and sorting in general) is a complex study that has attracted some of the greatest minds of computer science. A good sort function is a result of both choosing a good algorithm and paying attention to hardware performance in its implementation.If you want to write efficient code, you need to know a bit about machine architecture.",
                "This question is rooted in branch prediction models on CPUs. I'd recommend reading this paper:Increasing the Instruction Fetch Rate via Multiple Branch Prediction and a Branch Address Cache  (But real CPUs these days still don't make multiple taken branch-predictions per clock cycle, except for Haswell and later effectively unrolling tiny loops in its loop buffer.  Modern CPUs can predict multiple branches not-taken to make use of their fetches in large contiguous blocks.)When you have sorted elements, branch prediction easily predicts correctly except right at the boundary, letting instructions flow through the CPU pipeline efficiently, without having to rewind and take the correct path on mispredictions.",
                "An answer for quick and simple understanding (read the others for more details)This concept is called branch predictionBranch prediction is an optimization technique that predicts the path the code will take before it is known with certainty. This is important because during the code execution, the machine prefetches several code statements and stores them in the pipeline.The problem arises in conditional branching, where there are two possible paths or parts of the code that can be executed.When the prediction was true, the optimization technique worked out.When the prediction was false, to explain it in a simple way, the code statement stored in the pipeline gets proved wrong and the actual code has to be completely reloaded, which takes up a lot of time.As common sense suggests, predictions of something sorted are way more accurate than predictions of something unsorted.branch prediction visualisation:sorted\n\nunsorted",
                "It is a branch prediction failure. You don't need to sort the array, but you just need to partition it with the value 128. Sorting is n*log(n), whereas partitioning is just linear. Basically it is just one run of the quick sort partitioning step with the pivot chosen to be 128. Unfortunately in C++ there is just nth_element function, which partition by position, not by value.The answer to this question is that it auto-vectorizes. As usual compilers don't pick perfect strategies. (Although GCC's might be optimal for SSE2 or SSE4.)"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I undo the most recent local commits in Git?",
                "I accidentally committed the wrong files to Git, but didn't push the commit to the server yet.\n\nHow do I undo those commits from the local repository?"
            ],
            "url": "https://stackoverflow.com/questions/927358",
            "answer": [
                "Alternatively, to edit the previous commit (or just its commit message), commit --amend will add changes within the current index to the previous commit.To remove (not revert) a commit that has been pushed to the server, rewriting history with git push origin main --force[-with-lease] is necessary. It's almost always a bad idea to use --force; prefer --force-with-lease instead, and as noted in the git manual:You should understand the implications of rewriting history if you [rewrite history] has already been published.You can use git reflog to determine the SHA-1 for the commit to which you wish to revert. Once you have this value, use the sequence of commands as explained above.HEAD~ is the same as HEAD~1. The article What is the HEAD in git? is helpful if you want to uncommit multiple commits.",
                "Undoing a commit is a little scary if you don't know how it works.  But it's actually amazingly easy if you do understand. I'll show you the 4 different ways you can undo a commit.Say you have this, where C is your HEAD and (F) is the state of your files.You want to destroy commit C and also throw away any uncommitted changes.  You do this:The result is:Now B is the HEAD.  Because you used --hard, your files are reset to their state at commit B.Maybe commit C wasn't a disaster, but just a bit off.  You want to undo the commit but keep your changes for a bit of editing before you do a better commit.  Starting again from here, with C as your HEAD:Do this, leaving off the --hard:In this case, the result is:In both cases, HEAD is just a pointer to the latest commit.  When you do a git reset HEAD~1, you tell Git to move the HEAD pointer back one commit.  But (unless you use --hard) you leave your files as they were.  So now git status shows the changes you had checked into C.  You haven't lost a thing!For the lightest touch, you can even undo your commit but leave your files and your index:This not only leaves your files alone, it even leaves your index alone.  When you do git status, you'll see that the same files are in the index as before.  In fact, right after this command, you could do git commit and you'd be redoing the same commit you just had.One more thing: Suppose you destroy a commit as in the first example, but then discover you needed it after all?  Tough luck, right?Nope, there's still a way to get it back.  Type thisand you'll see a list of (partial) commit shas (that is, hashes) that you've moved around in.  Find the commit you destroyed, and do this:You've now resurrected that commit.  Commits don't actually get destroyed in Git for some 90 days, so you can usually go back and rescue one you didn't mean to get rid of.",
                "There are two ways to \"undo\" your last commit, depending on whether or not you have already made your commit public (pushed to your remote repository):Let's say I committed locally, but now I want to remove that commit.To restore everything back to the way it was prior to the last commit, we need to reset to the commit before HEAD:Now git log will show that our last commit has been removed.If you have already made your commits public, you will want to create a new commit which will \"revert\" the changes you made in your previous commit (current HEAD).Your changes will now be reverted and ready for you to commit:For more information, check out Git Basics - Undoing Things.",
                "Add/remove files to get things the way you want:Then amend the commit:The previous, erroneous commit will be edited to reflect the new index state - in other words, it'll be like you never made the mistake in the first place.Note that you should only do this if you haven't pushed yet. If you have pushed, then you'll just have to commit a fix normally.",
                "This will add a new commit which deletes the added files.Or you can rewrite history to undo the last commit.Warning: this command will permanently remove the modifications to the .java files (and any other files) that you committed -- and delete all your changes from your working directory:The hard reset to HEAD-1 will set your working copy to the state of the commit before your wrong commit.",
                "Replace the files in the index:Then, if it's a private branch, amend the commit:Or, if it's a shared branch, make a new commit:(To change a previous commit, use the awesome interactive rebase.)ProTip\u2122: Add *.class to a gitignore to stop this happening again.Amending a commit is the ideal solution if you need to change the last commit, but a more general solution is reset.You can reset Git to any commit with:Where N is the number of commits before HEAD, and @~ resets to the previous commit.Instead of amending the commit, you could use:Check out git help reset, specifically the sections on --soft --mixed and --hard, for a better understanding of what this does.If you mess up, you can always use the reflog to find dropped commits:",
                "Use git revert <commit-id>.To get the commit ID, just use git log.",
                "If you are planning to undo a local commit entirely, whatever you change you did on the commit, and if you don't worry anything about that, just do the following command.(This command will ignore your entire commit and your changes will be lost completely from your local working tree). If you want to undo your commit, but you want your changes in the staging area (before commit just like after git add) then do the following command.Now your committed files come into the staging area. Suppose if you want to upstage the files, because you need to edit some wrong content, then do the following commandNow committed files to come from the staged area into the unstaged area. Now files are ready to edit, so whatever you change, you want to go edit and added it and make a fresh/new commit.More (link broken) (Archived version)",
                "If you have Git Extras installed, you can run git undo to undo the latest commit. git undo 3 will undo the last three commits.",
                "I wanted to undo the latest five commits in our shared repository. I looked up the revision id that I wanted to rollback to. Then I typed in the following.",
                "I prefer to use git rebase -i for this job, because a nice list pops up where I can choose the commits to get rid of. It might not be as direct as some other answers here, but it just feels right.Choose how many commits you want to list, then invoke like this (to enlist last three)Sample listThen Git will remove commits for any line that you remove.",
                "Use git-gui (or similar) to perform a git commit --amend. From the GUI you can add or remove individual files from the commit. You can also modify the commit message.Just reset your branch to the previous location (for example, using gitk or git rebase). Then reapply your changes from a saved copy. After garbage collection in your local repository, it will be like the unwanted commit never happened. To do all of that in a single command, use git reset HEAD~1.Word of warning: Careless use of git reset is a good way to get your working copy into a confusing state. I recommend that Git novices avoid this if they can.Perform a reverse cherry pick (git-revert) to undo the changes.If you haven't yet pulled other changes onto your branch, you can simply do...Then push your updated branch to the shared repository.The commit history will show both commits, separately.Also note: You don't want to do this if someone else may be working on the branch.Clean up your branch locally then repush...In the normal case, you probably needn't worry about your private-branch commit history being pristine.  Just push a followup commit (see 'How to undo a public commit' above), and later, do a squash-merge to hide the history.",
                "If you want to permanently undo it and you have cloned some repository.The commit id can be seen by:Then you can do like:",
                "If you have committed junk but not pushed,HEAD~1 is a shorthand for the commit before head. Alternatively you can refer to the SHA-1 of the hash if you want to reset to. --soft option will delete the commit but it will leave all your changed files \"Changes to be committed\", as git status would put it.If you want to get rid of any changes to tracked files in the working tree since the commit before head use \"--hard\" instead.ORIf you already pushed and someone pulled which is usually my case, you can't use git reset. You can however do a git revert,This will create a new commit that reverses everything introduced by the accidental commit.",
                "On SourceTree (GUI for GitHub), you may right-click the commit and do a 'Reverse Commit'. This should undo your changes.On the terminal:You may alternatively use:Or:",
                "A single command:It works great to undo the last local commit!",
                "Just reset it doing the command below using git:Explain: what git reset does, it's basically reset to any commit you'd like to go back to, then if you combine it with --soft key, it will go back, but keep the  changes in your file(s), so you get back to the stage which the file was just added, HEAD is the head of the branch and if you combine with ~1 (in this case you also use HEAD^), it will go back only one commit which what you want...I create the steps in the image below in more details for you, including all steps that may happens in real situations and committing the code:",
                "\"Reset the working tree to the last commit\"\"Clean unknown files from the working tree\"see - Git Quick ReferenceNOTE: This command will delete your previous commit, so use with caution! git reset --hard is safer.",
                "How to undo the last Git commit?To restore everything back to the way it was prior to the last commit, we need to reset to the commit before HEAD.If you don't want to keep your changes that you made:If you want to keep your changes:Now check your git log. It will show that our last commit has been removed.",
                "Use reflog to find a correct stateREFLOG BEFORE RESETSelect the correct reflog (f3cb6e2 in my case) and typeAfter that the repo HEAD will be reset to that HEADid\n\nLOG AFTER RESETFinally the reflog looks like the picture belowREFLOG FINAL",
                "First run:It will show you all the possible actions you have performed on your repository, for example, commit, merge, pull, etc.Then do:",
                "git reset --soft HEAD^ or git reset --soft HEAD~This will undo the last commit.Here --soft means reset into staging.HEAD~ or HEAD^ means to move to commit before HEAD.It will replace the last commit with the new commit.",
                "Another way:Checkout the branch you want to revert, then reset your local working copy back to the commit that you want to be the latest one on the remote server (everything after it will go bye-bye). To do this, in SourceTree I right-clicked on the and selected \"Reset BRANCHNAME to this commit\".Then navigate to your repository's local directory and run this command:This will erase all commits after the current one in your local repository but only for that one branch.",
                "Type git log and find the last commit hash code and then enter:",
                "In my case I accidentally committed some files I did not want to. So I did the following and it worked:Verify the results with gitk or git log --stat",
                "Simple, run this in your command line:",
                "I am just adding two cents for @Kyralessa's answer:If you are unsure what to use go for --soft (I used this convention to remember it --soft for safe).If you choose --hard by mistake you will LOSE your changes as it wasn't before.\nIf you choose --soft by mistake you can achieve the same results of --hard by applying additional commandsCredits goes to @Kyralessa.",
                "There are many ways to do it:Git command to undo the last commit/ previous commits:Warning: Do Not use --hard if you do not know what you are doing.\n--hard is too dangerous, and it might delete your files.Basic command to revert the commit in Git is:orCOMMIT-ID: ID for the commitn:  is the number of last commits you want to revertYou can get the commit id as shown below:where d81d3f1 and be20eb8 are commit id.Now, let's see some cases:Suppose you want to revert the last commit 'd81d3f1'.  Here are two options:orSuppose you want to revert the commit 'be20eb8':For more detailed information, you can refer to and try out some other commands too for resetting the head to a specified state:",
                "There are two main scenariosYou haven't pushed the commit yetIf the problem was extra files you commited (and you don't want those on repository), you can remove them using git rm and then commiting with --amendYou can also remove entire directories with -r, or even combine with other Bash commandsAfter removing the files, you can commit, with --amend optionThis will rewrite your recent local commit removing the extra files, so, these files will never be sent on push and also will be removed from your local .git repository by GC.You already pushed the commitYou can apply the same solution of the other scenario and then doing git push with the -f option, but it is not recommended since it overwrites the remote history with a divergent change (it can mess your repository).Instead, you have to do the commit without --amend (remember this about -amend`: That option rewrites the history on the last commit).",
                "or if you do not remember exactly in which commit it is, you might useThe proper way of removing files from the repository history is using git filter-branch. That is,But I recomnend you use this command with care. Read more at git-filter-branch(1) Manual Page."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I delete a Git branch locally and remotely?",
                "Failed Attempts to Delete a Remote Branch:\n$ git branch -d remotes/origin/bugfix\nerror: branch 'remotes/origin/bugfix' not found.\n\n$ git branch -d origin/bugfix\nerror: branch 'origin/bugfix' not found...."
            ],
            "url": "https://stackoverflow.com/questions/2003505",
            "answer": [
                "Note: In most cases, <remote_name> will be origin.To delete the local branch use one of the following:As of Git v1.7.0, you can delete a remote branch usingwhich might be easier to remember thanwhich was added in Git v1.5.0 \"to delete a remote branch or a tag.\"Starting with Git v2.8.0, you can also use git push with the -d option as an alias for --delete. Therefore, the version of Git you have installed will dictate whether you need to use the easier or harder syntax.From Chapter 3 of Pro Git by Scott Chacon:Suppose you\u2019re done with a remote branch \u2014 say, you and your collaborators are finished with a feature and have merged it into your remote\u2019s main branch (or whatever branch your stable code-line is in). You can delete a remote branch using the rather obtuse syntax git push [remotename] :[branch]. If you want to delete your server-fix branch from the server, you run the following:Boom. No more branches on your server. You may want to dog-ear this page, because you\u2019ll need that command, and you\u2019ll likely forget the syntax. A way to remember this command is by recalling the git push [remotename] [localbranch]:[remotebranch] syntax that we went over a bit earlier. If you leave off the [localbranch] portion, then you\u2019re basically saying, \u201cTake nothing on my side and make it be [remotebranch].\u201dI issued git push origin: bugfix and it worked beautifully. Scott Chacon was right\u2014I will want to dog ear that page (or virtually dog ear by answering this on Stack\u00a0Overflow).Then you should execute this on other machinesto propagate changes.",
                "Matthew\u2019s answer is great for removing remote branches and I also appreciate the explanation, but to make a simple distinction between the two commands:to remove a local branch from your machine: git branch -d {local_branch} (use -D instead to force deleting the branch without checking merged status);to remove a remote branch from the server: git push origin -d {remote_branch}.Reference: Git: Delete a branch (local or remote).",
                "If you want more detailed explanations of the following commands, then see the long answers in the next section.When you're dealing with deleting branches both locally and remotely, keep in mind that there are three different branches involved:The original poster used:Which only deleted his local remote-tracking branch origin/bugfix, and not the actual remote branch bugfix on origin.To delete that actual remote branch, you needThe following sections describe additional details to consider when deleting your remote and remote-tracking branches.Note that deleting the remote branch X from the command line using a git push will also remove the local remote-tracking branch origin/X, so it is not necessary to prune the obsolete remote-tracking branch with git fetch --prune or git fetch -p. However, it wouldn't hurt if you did it anyway.You can verify that the remote-tracking branch origin/X was also deleted by running the following:If you didn't delete your remote branch X from the command line (like above), then your local repository will still contain (a now obsolete) remote-tracking branch origin/X. This can happen if you deleted a remote branch directly through GitHub's web interface, for example.A typical way to remove these obsolete remote-tracking branches (since Git version 1.6.6) is to simply run git fetch with the --prune or shorter -p. Note that this removes all obsolete local remote-tracking branches for any remote branches that no longer exist on the remote:Here is the relevant quote from the 1.6.6 release notes (emphasis mine):\"git fetch\" learned --all and --multiple options, to run fetch from\nmany repositories, and --prune option to remove remote tracking\nbranches that went stale.  These make \"git remote update\" and \"git\nremote prune\" less necessary (there is no plan to remove \"remote\nupdate\" nor \"remote prune\", though).Alternatively, instead of pruning your obsolete local remote-tracking branches through git fetch -p, you can avoid making the extra network operation by just manually removing the branch(es) with the --remotes or -r flags:",
                "For deleting the remote branch:For deleting the local branch, you have three ways:Explain: OK, just explain what's going on here!Simply do git push origin --delete to delete your remote branch only, add the name of the branch at the end and this will delete and push it to remote at the same time...Also, git branch -D, which simply delete the local branch only!...-D stands for --delete --force which will delete the branch even it's not merged (force delete), but you can also use -d which stands for --delete which throw an error respective of the branch merge status...I also create the image below to show the steps:",
                "You can also use the following to delete the remote branchWhich does the same thing asbut it may be easier to remember.",
                "It's very simple:To delete the remote branchOr-- You can also delete tags with this syntaxTo forcefully delete local branchNote: do a git fetch --all --prune on other machines after deleting remote branch, to remove obsolete tracking branches.Exampleto remove local branchto remove remote branchWith the new version of git, its also possible to remove branch withTIP:\nif you want to see all available branches you can use git branch -a,and to see just remote branches, you can use git branch -r",
                "Tip: When you delete branches usingoronly the references are deleted. Even though the branch is actually removed on the remote, the references to it still exists in the local repositories of your team members. This means that for other team members the deleted branches are still visible when they do a git branch -a.To solve this, your team members can prune the deleted branches withThis is typically git remote prune origin.",
                "If you want to delete a branch, first checkout to the branch other than the branch to be deleted.Deleting the local branch:Deleting the remote branch:",
                "This is simple: Just run the following command:To delete a Git branch both locally and remotely, first delete the local branch using this command:(Here example is the branch name.)And after that, delete the remote branch using this command:",
                "Another approach is:WARNING: This will delete all remote branches that do not exist locally. Or more comprehensively,will effectively make the remote repository look like the local copy of the repository (local heads, remotes and tags are mirrored on remote).",
                "I use the following in my Bash settings:Then you can call:",
                "Delete locally:To delete a local branch, you can use:To delete a branch forcibly, use -D instead of -d.Delete remotely:There are two options:I would suggest you use the second way as it is more intuitive.",
                "If you want to complete both these steps with a single command, you can make an alias for it by adding the below to your ~/.gitconfig:Alternatively, you can add this to your global configuration from the command line usingNOTE: If using -d (lowercase d), the branch will only be deleted if it has been merged. To force the delete to happen, you will need to use -D (uppercase D).",
                "Since January 2013, GitHub included a Delete branch button next to each branch in your \"Branches\" page.Relevant blog post: Create and delete branches",
                "To delete your branch locally and remotelyCheckout to master branch -  git checkout masterDelete your remote branch - git push origin --delete <branch-name>Delete your local branch - git branch --delete <branch-name>",
                "You can also do this using git remote prune originIt prunes and deletes remote-tracking branches from a git branch -r listing.",
                "In addition to the other answers, I often use the git_remote_branch tool. It's an extra install, but it gets you a convenient way to interact with remote branches. In this case, to delete:I find that I also use the publish and track commands quite often.",
                "A one-liner command to delete both local, and remote:Or add the alias below to your ~/.gitconfig. Usage: git kill branch-name",
                "Deleting BranchesLet's assume our work on branch \"contact-form\" is done and we've already integrated it into \"master\". Since we don't need it anymore, we can delete it (locally):And for deleting the remote branch:",
                "Delete remote branchgit push origin :<branchname>Delete local branchgit branch -D <branchname>Delete local branch steps:",
                "Simply say:",
                "To delete locally - (normal)If your branch is in a rebasing/merging progress and that was not done properly, it means you will get an error, Rebase/Merge in progress, so in that case, you won't be able to delete your branch.So either you need to solve the rebasing/merging. Otherwise, you can do force delete by using,To delete in remote:You can do the same using:Graphical representation:",
                "Now you can do it with the GitHub Desktop application.After launching the applicationSwitch to the branch you would like to deleteFrom the \"Branch\" menu, select, \"Unpublish...\", to have the branch deleted from the GitHub servers.From the \"Branch\" menu, select, 'Delete \"branch_name\"...', to have the branch deleted off of your local machine (AKA the machine you are currently working on)",
                "is easier to remember than",
                "This won't work if you have a tag with the same name as the branch on the remote:In that case you need to specify that you want to delete the branch, not the tag:Similarly, to delete the tag instead of the branch you would use:",
                "Many of the other answers will lead to errors/warnings. This approach is relatively fool proof although you may still need git branch -D branch_to_delete if it's not fully merged into some_other_branch, for example.Remote pruning isn't needed if you deleted the remote branch. It's only used to get the most up-to-date remotes available on a repository you're tracking. I've observed git fetch will add remotes, not remove them. Here's an example of when git remote prune origin will actually do something:User A does the steps above. User B would run the following commands to see the most up-to-date remote branches:",
                "I got sick of googling for this answer, so I took a similar approach to the answer that crizCraig posted earlier.I added the following to my Bash profile:Then every time I'm done with a branch (merged into master, for example) I run the following in my terminal:...which then deletes my-branch-name from origin as as well as locally.",
                "According to the latest document using a terminal we can delete in the following way.Delete in local:Delete in remote location:",
                "Before executingmake sure you determine first what the exact name of the remote branch is by executing:This will tell you what to enter exactly for <branch> value. (branch is case sensitive!)"
            ]
        },
        {
            "tag": "",
            "question": [
                "What is the difference between 'git pull' and 'git fetch'?",
                "What are the differences between git pull and git fetch?"
            ],
            "url": "https://stackoverflow.com/questions/292357",
            "answer": [
                "In the simplest terms, git pull does a git fetch followed by a git merge.git fetch updates your remote-tracking branches under refs/remotes/<remote>/. This operation is safe to run at any time since it never changes any of your local branches under refs/heads.git pull brings a local branch up-to-date with its remote version, while also updating your other remote-tracking branches.From the Git documentation for git pull:git pull runs git fetch with the given parameters and then depending on configuration options or command line flags, will call either git rebase or git merge to reconcile diverging branches.It is helpful to keep in mind that when working on any Git respository on any particular machine, the repository contains a copy of all branches from all remotes as well as a copy of each local branch you have done some work on.You can see this using git branch -a, which should show your local branches, including master, and all branches from all remotes.Above, I have indicated the existance of a remote origin repo as well as another remote by another name another-remote-machine.Note you do not necessarily have to have a copy of each branch on all repositories. (Remotes and local.) It will depend on when you have synchronized things by running git pull, git push, git fetch, from the different machines/repositories involved.",
                "git pull tries to automatically merge after fetching commits. It is context sensitive, so all pulled commits will be merged into your currently active branch.  git pull automatically merges the commits without letting you review them first. If you don\u2019t carefully manage your branches, you may run into frequent conflicts.git fetch gathers any commits from the target branch that do not exist in the current branch and stores them in your local repository. However, it does not merge them with your current branch. This is particularly useful if you need to keep your repository up to date, but are working on something that might break if you update your files. To integrate the commits into your current branch, you must use git merge afterwards.",
                "It is important to contrast the design philosophy of git with the philosophy of a more traditional source control tool like SVN.Subversion was designed and built with a client/server model. There is a single repository that is the server, and several clients can fetch code from the server, work on it, then commit it back to the server. The assumption is that the client can always contact the server when it needs to perform an operation.Git was designed to support a more distributed model with no need for a central repository (though you can certainly use one if you like). Also git was designed so that the client and the \"server\" don't need to be online at the same time. Git was designed so that people on an unreliable link could exchange code via email, even. It is possible to work completely disconnected and burn a CD to exchange code via git.In order to support this model git maintains a local repository with your code and also an additional local repository that mirrors the state of the remote repository. By keeping a copy of the remote repository locally, git can figure out the changes needed even when the remote repository is not reachable.  Later when you need to send the changes to someone else, git can transfer them as a set of changes from a point in time known to the remote repository.git fetch is the command that says \"bring my local copy of the remote repository up to date.\"git pull says \"bring the changes in the remote repository to where I keep my own code.\"Normally git pull does this by doing a git fetch to bring the local copy of the remote repository up to date, and then merging the changes into your own code repository and possibly your working copy.The take away is to keep in mind that there are often at least three copies of a project on your workstation. One copy is your own repository with your own commit history. The second copy is your working copy where you are editing and building. The third copy is your local \"cached\" copy of a remote repository.",
                "Here is Oliver Steele's image of how all it all fits together:",
                "One use case of git fetch is that the following will tell you any changes in the remote branch since your last pull... so you can check before doing an actual pull, which could change files in your current branch and working copy.See git diff documentation regarding the double- .. and triple-dot ... syntax.",
                "It cost me a little bit to understand what was the difference, but this is a simple explanation. master in your localhost is a branch.When you clone a repository you fetch the entire repository to you local host. This means that at that time you have an origin/master pointer to HEAD and master pointing to the same HEAD.when you start working and do commits you advance the master pointer to HEAD + your commits. But the origin/master pointer is still pointing to what it was when you cloned.So the difference will be:",
                "Sometimes a visual representation helps.",
                "Even more brieflygit fetch fetches updates but does not merge them.git pull does a git fetch under the hood and then a merge.Brieflygit fetch is similar to pull but doesn't merge. i.e. it fetches remote updates (refs and objects) but your local stays the same (i.e. origin/master gets updated but master stays the same) .git pull pulls down from a remote and instantly merges.Moregit clone clones a repo.git rebase saves stuff from your current branch that isn't in the upstream branch to a temporary area. Your branch is now the same as before you started your changes. So, git pull -rebase will pull down the remote changes, rewind your local branch, replay your changes over the top of your current branch one by one until you're up-to-date.Also, git branch -a will show you exactly what\u2019s going on with all your branches - local and remote.This blog post was useful:The difference between git pull, git fetch and git clone (and git rebase) - Mike Pearceand covers git pull, git fetch, git clone and git rebase.I thought I'd update this to show how you'd actually use this in practice.Update your local repo from the remote (but don't merge):After downloading the updates, let's see the differences:If you're happy with those updates, then merge:Notes:On step 2: For more on diffs between local and remotes, see: How to compare a local Git branch with its remote branchOn step 3: It's probably more accurate (e.g. on a fast changing repo) to do a git rebase origin here. See @Justin Ohms comment in another answer.See also: http://longair.net/blog/2009/04/16/git-fetch-and-merge/Note also: I've mentioned a merge during a pull however you can configure a pull to use a rebase instead.",
                "You would pull if you want the histories merged, you'd fetch if you just 'want the codez' as some person has been tagging some articles around here.",
                "OK, here is some information about git pull and git fetch, so you can understand the actual differences... in few simple words, fetch gets the latest data, but not the code changes and not going to mess with your current  local branch code, but pull get the code changes and merge it your local branch, read on to get more details about each:It will download all refs and objects and any new branches to your local Repository...Fetch branches and/or tags (collectively, \"refs\") from one or more\nother repositories, along with the objects necessary to complete their\nhistories. Remote-tracking branches are updated (see the description\nof  below for ways to control this behavior).By default, any tag that points into the histories being fetched is\nalso fetched; the effect is to fetch tags that point at branches that\nyou are interested in. This default behavior can be changed by using\nthe --tags or --no-tags options or by configuring\nremote..tagOpt. By using a refspec that fetches tags explicitly,\nyou can fetch tags that do not point into branches you are interested\nin as well.git fetch can fetch from either a single named repository or URL or\nfrom several repositories at once if  is given and there is a\nremotes. entry in the configuration file. (See git-config1).When no remote is specified, by default the origin remote will be\nused, unless there\u2019s an upstream branch configured for the current\nbranch.The names of refs that are fetched, together with the object names\nthey point at, are written to .git/FETCH_HEAD. This information may be\nused by scripts or other git commands, such as git-pull.It will apply the changes from remote to the current branch in local...Incorporates changes from a remote repository into the current branch.\nIn its default mode, git pull is shorthand for git fetch followed by\ngit merge FETCH_HEAD.More precisely, git pull runs git fetch with the given parameters and\ncalls git merge to merge the retrieved branch heads into the current\nbranch. With --rebase, it runs git rebase instead of git merge.should be the name of a remote repository as passed to\ngit-fetch1.  can name an arbitrary remote ref (for example,\nthe name of a tag) or even a collection of refs with corresponding\nremote-tracking branches (e.g., refs/heads/:refs/remotes/origin/),\nbut usually it is the name of a branch in the remote repository.Default values for  and  are read from the\n\"remote\" and \"merge\" configuration for the current branch as set by\ngit-branch --track.I also create the visual below to show you how git fetch and git pull working together...",
                "The short and easy answer is that git pull is simply git fetch followed by git merge.It is very important to note that git pull will automatically merge whether you like it or not. This could, of course, result in merge conflicts. Let's say your remote is origin and your branch is master. If you git diff origin/master before pulling, you should have some idea of potential merge conflicts and could prepare your local branch accordingly.In addition to pulling and pushing, some workflows involve git rebase, such as this one, which I paraphrase from the linked article:If you find yourself in such a situation, you may be tempted to git pull --rebase. Unless you really, really know what you are doing, I would advise against that. This warning is from the man page for git-pull, version 2.3.5:This is a potentially dangerous mode of operation. It rewrites\n  history, which does not bode well when you published that history\n  already. Do not use this option unless you have read git-rebase(1)\n  carefully.",
                "You can fetch from a remote repository, see the differences and then pull or merge.This is an example for a remote repository called origin and a branch called master tracking the remote branch origin/master:",
                "This interactive graphical representation is very helpful in understanging git: http://ndpsoftware.com/git-cheatsheet.htmlgit fetch just \"downloads\" the changes from the remote to your local repository. git pull downloads the changes and merges them into your current branch. \"In its default mode, git pull is shorthand for git fetch followed by git merge FETCH_HEAD.\"",
                "In speaking of pull & fetch in the above answers, I would like to share an interesting trick,This above command is the most useful command in my git life which saved a lots of time.Before pushing your new commits to server, try this command and it will automatically sync latest server changes (with a fetch + merge) and will place your commit at the top in git log. No need to worry about manual pull/merge.Find details at: http://gitolite.com/git-pull--rebase",
                "I like to have some visual representation of the situation to grasp these things. Maybe other developers would like to see it too, so here's my addition. I'm not totally sure that it all is correct, so please comment if you find any mistakes.Some major advantages for having a fetched mirror of the remote are:",
                "The Difference between GIT Fetch and GIT Pull can be explained with the following scenario:\n(Keeping in mind that pictures speak louder than words!, I have provided pictorial representation)Let's take an example that you are working on a project with your team members. So there will be one main Branch of the project and all the contributors must fork it to their own local repository and then work on this local branch to modify/Add modules then push back to the main branch.So,\nInitial State of the two Branches when you forked the main project on your local repository will be like this- (A, B and C are Modules already completed of the project)Now, you have started working on the new module (suppose D)  and when you have completed the D module you want to push it to the main branch, But meanwhile what happens is that one of your teammates has developed new Module E, F and modified C.\nSo now what has happened is that your local repository is lacking behind the original progress of the project and thus pushing of your changes to the main branch can lead to conflict and may cause your Module D to malfunction.To avoid such issues and to work parallel with the original progress of the project there are Two ways:1. Git Fetch- This will Download all the changes that have been made to the origin/main branch project which are not present in your local branch. And will wait for the Git Merge command to apply the changes that have been fetched to your Repository or branch.So now You can carefully monitor the files before merging it to your repository. And you can also modify D if required because of Modified C.2. Git Pull- This will update your local branch with the origin/main branch i.e. actually what it does is a combination of Git Fetch and Git merge one after another.\nBut this may Cause Conflicts to occur, so it\u2019s recommended to use Git Pull with a clean copy.",
                "I have struggled with this as well.  In fact I got here with a google search of exactly the same question.  Reading all these answers finally painted a picture in my head and I decided to try to get this down looking at the state of the 2 repositories and 1 sandbox and actions performed over time while watching the version of them.  So here is what I came up with.  Please correct me if I messed up anywhere.The three repos with a fetch:The three repos with a pullThis helped me understand why a fetch is pretty important.",
                "In simple terms, if you were about to hop onto a plane without any Internet connection\u2026 before departing you could just do git fetch origin <branch>. It would fetch all the changes into your computer, but keep it separate from your local development/workspace.On the plane, you could make changes to your local workspace and then merge it with what you've previously fetched and then resolve potential merge conflicts all without a connection to the Internet. And unless someone had made new changes to the remote repository then once you arrive at the destination you would do git push origin <branch> and go get your coffee.From this awesome Atlassian tutorial:The git fetch command downloads commits, files, and refs from a\nremote repository into your local repository.Fetching is what you do when you want to see what everybody else has\nbeen working on. It\u2019s similar to SVN update in that it lets you see\nhow the central history has progressed, but it doesn\u2019t force you to\nactually merge the changes into your repository. Git isolates\nfetched content as a from existing local content, it has absolutely\nno effect on your local development work. Fetched content has to be explicitly checked out using the git checkout command. This makes\nfetching a safe way to review commits before integrating them with\nyour local repository.When downloading content from a remote repository, git pull and git fetch commands are available to accomplish the task. You can consider\ngit fetch the 'safe' version of the two commands. It will download\nthe remote content, but not update your local repository's working state,\nleaving your current work intact. git pull is the more aggressive\nalternative, it will download the remote content for the active local\nbranch and immediately execute git merge to create a merge commit\nfor the new remote content. If you have pending changes in progress\nthis will cause conflicts and kickoff the merge conflict resolution\nflow.With git pull:Hmmm...so if I'm not updating the working copy with git fetch, then where am I making changes? Where does Git fetch store the new commits?Great question. First and foremost, the heads or remotes don't store the new commits. They just have pointers to commits. So with git fetch you download the latest git objects (blob, tree, commits. To fully understand the objects watch this video on git internals), but only update your remotes pointer to point to the latest commit of that branch.  It's still isolated from your working copy, because your branch's pointer in the heads directory hasn't updated. It will only update upon a merge/pull. But again where? Let's find out.In your project directory (i.e., where you do your git commands) do:ls. This will show the files & directories. Nothing cool, I know.Now do ls -a. This will show dot files, i.e., files beginning with . You will then be able to see a directory named: .git.Do cd .git. This will obviously change your directory.Now comes the fun part; do ls. You will see a list of directories. We're looking for refs. Do cd refs.It's interesting to see what's inside all directories, but let's focus on two of them. heads and remotes. Use cd to check inside them too.Any git fetch that you do will update the pointer in the /.git/refs/remotes directory. It won't update anything in the /.git/refs/heads directory.Any git pull will first do the git fetch and update items in the /.git/refs/remotes directory.  It will then also merge with your local and then change the head inside the /.git/refs/heads directory.A very good related answer can also be found in Where does 'git fetch' place itself?.Also, look for \"Slash notation\" from the Git branch naming conventions post. It helps you better understand how Git places things in different directories.Just do:If the remote master was updated you'll get a message like this:If you didn't fetch and just did git checkout master then your local git wouldn't know that there are 2 commits added. And it would just say:But that's outdated and incorrect. It's because git will give you feedback solely based on what it knows. It's oblivious to new commits that it hasn't pulled down yet...Some IDEs (e.g. Xcode) are super smart and use the result of a git fetch and can annotate the lines of code that have been changed in remote branch of your current working branch. If that line has been changed by both local changes and remote branch, then that line gets annotated with red. This isn't a merge conflict. It's a potential merge conflict. It's a headsup that you can use to resolve the future merge conflict before doing git pull from the remote branch.If you fetched a remote branch e.g. did:Then this would go into your remotes directory. It's still not available to your local directory. However, it simplifies your checkout to that remote branch by DWIM (Do what I mean):you no longer need to do:For more on that read here",
                "We simply say:If you run git pull, you do not need to merge the data to local. If you run git fetch, it means you must run git merge for getting the latest code to your local machine. Otherwise, the local machine code would not be changed without merge.So in the Git Gui, when you do fetch, you have to merge the data. Fetch itself won't make the code changes at your local. You can check that when you update the code by fetching\nonce fetch and see; the code it won't change. Then you merge... You will see the changed code.",
                "git fetch pulls down the code from the remote server to your tracking branches in your local repository.  If your remote is named origin (the default) then these branches will be within origin/, for example origin/master, origin/mybranch-123, etc.  These are not your current branches, they are local copies of those branches from the server.git pull does a git fetch but then also merges the code from the tracking branch into your current local version of that branch.  If you're not ready for that changes yet, just git fetch first.",
                "git fetch will retrieve remote branches so that you can git diff or git merge them with the current branch. git pull will run fetch on the remote brach tracked by the current branch and then merge the result. You can use git fetch to see if there are any updates to the remote branch without necessary merging them with your local branch.",
                "Git FetchYou download changes to your local branch from origin through fetch. Fetch asks the remote repo for all commits that others have made but you don't have on your local repo. Fetch downloads these commits and adds them to the local repository.Git MergeYou can apply changes downloaded through fetch using the merge command. Merge will take the commits retrieved from fetch and try to add them to your local branch. The merge will keep the commit history of your local changes so that when you share your branch with push, Git will know how others can merge your changes.Git PullFetch and merge run together often enough that a command that combines the two, pull, was created. Pull does a fetch and then a merge to add the downloaded commits into your local branch.",
                "The only difference between git pull and git fetch is that :git pull pulls from a remote branch and merges it.git fetch only fetches from the remote branch but it does not mergei.e. git pull = git fetch + git merge ...",
                "Git allows chronologically older commits to be applied after newer commits.\nBecause of this, the act of transferring commits between repositories is split into two steps:Copying new commits from remote branch to copy of this remote branch inside local repo.(repo to repo operation) master@remote >> remote/origin/master@localIntegrating new commits to local branch(inside-repo operation) remote/origin/master@local >> master@localThere are two ways of doing step 2. You can:In git terminology, step 1 is git fetch, step 2 is git merge or git rebasegit pull is git fetch and git merge",
                "The git pull command is actually a shortcut for git fetch followed by the git merge or the git rebase command depending on your configuration. You can configure your Git repository so that git pull is a fetch followed by a rebase.",
                "Git obtains the branch of the latest version from the remote to the local using two commands:git fetch: Git is going to get the latest version from remote to local,  but it do not automatically merge.\n\u00a0\u00a0\u00a0\u00a0\ngit fetch origin master\ngit log -p master..origin/master\ngit merge origin/masterThe commands above mean that download latest version of the main branch from origin from the remote to origin master branch. And then compares the local master branch and origin master branch. Finally, merge.git pull: Git is going to get the latest version from the remote and merge into the local.git pull origin masterThe command above is the equivalent to git fetch and git merge. In practice, git fetch maybe more secure because before the merge we can see the changes and decide whether to merge.",
                "What is the difference between git pull and git fetch?To understand this, you first need to understand that your local git maintains not only your local repository, but it also maintains a local copy of the remote repository.git fetch brings your local copy of the remote repository up to date. For example, if your remote repository is GitHub - you may want to fetch any changes made in the remote repository to your local copy of it the remote repository. This will allow you to perform operations such as compare or merge.git pull on the other hand will bring down the changes in the remote repository to where you keep your own code. Typically, git pull will do a git fetch first to bring the local copy of the remote repository up to date, and then it will merge the changes into your own code repository and possibly your working copy.",
                "A simple Graphical Representation for Beginners,here,will fetch code from repository and rebase with your local... in git pull there is possibility of new commits getting created.but in ,git fetchwill fetch code from repository and we need to rebase it manually by using git rebaseeg: i am going to fetch from server master and rebase it in my local master.1) git pull ( rebase will done automatically):here origin is your remote repo master is your branch2) git fetch (need to rebase manually):it will fetch server changes from origin. and it will be in your local until you rebase it on your own. we need to fix conflicts manually by checking codes.this will rebase code into local. before that ensure you're in right branch.",
                "Actually Git maintains a copy of your own code and \nthe remote repository.The command git fetch makes your local copy up to date by getting data from remote repository. The reason we need this is because somebody else might have made some changes to the code and you want to keep yourself updated.The command git pull brings the changes in the remote repository to where you keep your own code. Normally, git pull does this by doing a \u2018git fetch\u2019 first to bring the local copy of the remote repository up to date, and then it merges the changes into your own code repository and possibly your working copy.",
                "git pull == ( git fetch + git merge)git fetch does not changes to local branches.If you already have a local repository with a remote set up for the desired project, you can grab all branches and tags for the existing remote using git fetch . ... Fetch does not make any changes to local branches, so you will need to merge a remote branch with a paired local branch to incorporate newly fetch changes. from github"
            ]
        },
        {
            "tag": "",
            "question": [
                "What does the \"yield\" keyword do?",
                "What is the use of the yield keyword in Python? What does it do?\nFor example, I'm trying to understand this code1:\ndef _get_child_candidates(self, distance, min_dist, max_dist):\n    if self._leftchild ..."
            ],
            "url": "https://stackoverflow.com/questions/231767",
            "answer": [
                "To understand what yield does, you must understand what generators are. And before you can understand generators, you must understand iterables.When you create a list, you can read its items one by one. Reading its items one by one is called iteration:mylist is an iterable. When you use a list comprehension, you create a list, and so an iterable:Everything you can use \"for... in...\" on is an iterable; lists, strings, files...These iterables are handy because you can read them as much as you wish, but you store all the values in memory and this is not always what you want when you have a lot of values.Generators are iterators, a kind of iterable you can only iterate over once. Generators do not store all the values in memory, they generate the values on the fly:It is just the same except you used () instead of []. BUT, you cannot perform for i in mygenerator a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end calculating 4, one by one.yield is a keyword that is used like return, except the function will return a generator.Here it's a useless example, but it's handy when you know your function will return a huge set of values that you will only need to read once.To master yield, you must understand that when you call the function, the code you have written in the function body does not run. The function only returns the generator object, this is a bit tricky.Then, your code will continue from where it left off each time for uses the generator.Now the hard part:The first time the for calls the generator object created from your function, it will run the code in your function from the beginning until it hits yield, then it'll return the first value of the loop. Then, each subsequent call will run another iteration of the loop you have written in the function and return the next value. This will continue until the generator is considered empty, which happens when the function runs without hitting yield. That can be because the loop has come to an end, or because you no longer satisfy an \"if/else\".Generator:Caller:This code contains several smart parts:The loop iterates on a list, but the list expands while the loop is being iterated. It's a concise way to go through all these nested data even if it's a bit dangerous since you can end up with an infinite loop. In this case, candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) exhausts all the values of the generator, but while keeps creating new generator objects which will produce different values from the previous ones since it's not applied on the same node.The extend() method is a list object method that expects an iterable and adds its values to the list.Usually, we pass a list to it:But in your code, it gets a generator, which is good because:And it works because Python does not care if the argument of a method is a list or not. Python expects iterables so it will work with strings, lists, tuples, and generators! This is called duck typing and is one of the reasons why Python is so cool. But this is another story, for another question...You can stop here, or read a little bit to see an advanced use of a generator:Note: For Python 3, useprint(corner_street_atm.__next__()) or print(next(corner_street_atm))It can be useful for various things like controlling access to a resource.The itertools module contains special functions to manipulate iterables. Ever wish to duplicate a generator?\nChain two generators? Group values in a nested list with a one-liner? Map / Zip without creating another list?Then just import itertools.An example? Let's see the possible orders of arrival for a four-horse race:Iteration is a process implying iterables (implementing the __iter__() method) and iterators (implementing the __next__() method).\nIterables are any objects you can get an iterator from. Iterators are objects that let you iterate on iterables.There is more about it in this article about how for loops work.",
                "When you see a function with yield statements, apply this easy trick to understand what will happen:This trick may give you an idea of the logic behind the function, but what actually happens with yield is significantly different than what happens in the list-based approach. In many cases, the yield approach will be a lot more memory efficient and faster too. In other cases, this trick will get you stuck in an infinite loop, even though the original function works just fine. Read on to learn more...First, the iterator protocol - when you writePython performs the following two steps:Gets an iterator for mylist:Call iter(mylist) -> this returns an object with a next() method (or __next__() in Python 3).[This is the step most people forget to tell you about]Uses the iterator to loop over items:Keep calling the next() method on the iterator returned from step 1. The return value from next() is assigned to x and the loop body is executed. If an exception StopIteration is raised from within next(), it means there are no more values in the iterator and the loop is exited.The truth is Python performs the above two steps anytime it wants to loop over the contents of an object - so it could be a for loop, but it could also be code like otherlist.extend(mylist) (where otherlist is a Python list).Here mylist is an iterable because it implements the iterator protocol. In a user-defined class, you can implement the __iter__() method to make instances of your class iterable. This method should return an iterator. An iterator is an object with a next() method. It is possible to implement both __iter__() and next() on the same class, and have __iter__() return self. This will work for simple cases, but not when you want two iterators looping over the same object at the same time.So that's the iterator protocol, many objects implement this protocol:Note that a for loop doesn't know what kind of object it's dealing with - it just follows the iterator protocol, and is happy to get item after item as it calls next(). Built-in lists return their items one by one, dictionaries return the keys one by one, files return the lines one by one, etc. And generators return... well that's where yield comes in:Instead of yield statements, if you had three return statements in f123() only the first would get executed, and the function would exit. But f123() is no ordinary function. When f123() is called, it does not return any of the values in the yield statements! It returns a generator object. Also, the function does not really exit - it goes into a suspended state. When the for loop tries to loop over the generator object, the function resumes from its suspended state at the very next line after the yield it previously returned from, executes the next line of code, in this case, a yield statement, and returns that as the next item. This happens until the function exits, at which point the generator raises StopIteration, and the loop exits.So the generator object is sort of like an adapter - at one end it exhibits the iterator protocol, by exposing __iter__() and next() methods to keep the for loop happy. At the other end, however, it runs the function just enough to get the next value out of it, and puts it back in suspended mode.Usually, you can write code that doesn't use generators but implements the same logic. One option is to use the temporary list 'trick' I mentioned before. That will not work in all cases, for e.g. if you have infinite loops, or it may make inefficient use of memory when you have a really long list. The other approach is to implement a new iterable class SomethingIter that keeps the state in instance members and performs the next logical step in its next() (or __next__() in Python 3) method. Depending on the logic, the code inside the next() method may end up looking very complex and prone to bugs. Here generators provide a clean and easy solution.",
                "Think of it this way:An iterator is just a fancy sounding term for an object that has a next() method.  So a yield-ed function ends up being something like this:Original version:This is basically what the Python interpreter does with the above code:For more insight as to what's happening behind the scenes, the for loop can be rewritten to this:Does that make more sense or just confuse you more?  :)I should note that this is an oversimplification for illustrative purposes. :)",
                "The yield keyword is reduced to two simple facts:In a nutshell: Most commonly, a generator is a lazy, incrementally-pending list, and yield statements allow you to use function notation to program the list values the generator should incrementally spit out. Furthermore, advanced usage lets you use generators as coroutines (see below).Basically, whenever the yield statement is encountered, the function pauses and saves its state, then emits \"the next return value in the 'list'\" according to the python iterator protocol (to some syntactic construct like a for-loop that repeatedly calls next() and catches a StopIteration exception, etc.). You might have encountered generators with generator expressions; generator functions are more powerful because you can pass arguments back into the paused generator function, using them to implement coroutines. More on that later.Let's define a function makeRange that's just like Python's range. Calling makeRange(n) RETURNS A GENERATOR:To force the generator to immediately return its pending values, you can pass it into list() (just like you could any iterable):The above example can be thought of as merely creating a list which you append to and return:There is one major difference, though; see the last section.An iterable is the last part of a list comprehension, and all generators are iterable, so they're often used like so:To get a better feel for generators, you can play around with the itertools module (be sure to use chain.from_iterable rather than chain when warranted). For example, you might even use generators to implement infinitely-long lazy lists like itertools.count(). You could implement your own def enumerate(iterable): zip(count(), iterable), or alternatively do so with the yield keyword in a while-loop.Please note: generators can actually be used for many more things, such as implementing coroutines or non-deterministic programming or other elegant things. However, the \"lazy lists\" viewpoint I present here is the most common use you will find.This is how the \"Python iteration protocol\" works. That is, what is going on when you do list(makeRange(5)). This is what I describe earlier as a \"lazy, incremental list\".The built-in function next() just calls the objects .__next__() function, which is a part of the \"iteration protocol\" and is found on all iterators. You can manually use the next() function (and other parts of the iteration protocol) to implement fancy things, usually at the expense of readability, so try to avoid doing that...Coroutine example:A coroutine (generators which generally accept input via the yield keyword e.g. nextInput = yield nextOutput, as a form of two-way communication) is basically a computation which is allowed to pause itself and request input (e.g. to what it should do next). When the coroutine pauses itself (when the running coroutine eventually hits a yield keyword), the computation is paused and control is inverted (yielded) back to the 'calling' function (the frame which requested the next value of the computation). The paused generator/coroutine remains paused until another invoking function (possibly a different function/context) requests the next value to unpause it (usually passing input data to direct the paused logic interior to the coroutine's code).You can think of python coroutines as lazy incrementally-pending lists, where the next element doesn't just depend on the previous computation, but also on input you may opt to inject during the generation process.Normally, most people would not care about the following distinctions and probably want to stop reading here.In Python-speak, an iterable is any object which \"understands the concept of a for-loop\" like a list [1,2,3], and an iterator is a specific instance of the requested for-loop like [1,2,3].__iter__(). A generator is exactly the same as any iterator, except for the way it was written (with function syntax).When you request an iterator from a list, it creates a new iterator. However, when you request an iterator from an iterator (which you would rarely do), it just gives you a copy of itself.Thus, in the unlikely event that you are failing to do something like this...... then remember that a generator is an iterator; that is, it is one-time-use. If you want to reuse it, you should call myRange(...) again. If you need to use the result twice, convert the result to a list and store it in a variable x = list(myRange(5)). Those who absolutely need to clone a generator (for example, who are doing terrifyingly hackish metaprogramming) can use itertools.tee (still works in Python 3) if absolutely necessary, since the copyable iterator Python PEP standards proposal has been deferred.",
                "What does the yield keyword do in Python?yield is only legal inside of a function definition, and the inclusion of yield in a function definition makes it return a generator.The idea for generators comes from other languages (see footnote 1) with varying implementations. In Python's Generators, the execution of the code is frozen at the point of the yield. When the generator is called (methods are discussed below) execution resumes and then freezes at the next yield.yield provides an\neasy way of implementing the iterator protocol, defined by the following two methods:\n__iter__ and __next__.  Both of those methods\nmake an object an iterator that you could type-check with the Iterator Abstract Base\nClass from the collections module.Let's do some introspection:The generator type is a sub-type of iterator:And if necessary, we can type-check like this:A feature of an Iterator is that once exhausted, you can't reuse or reset it:You'll have to make another if you want to use its functionality again (see footnote 2):One can yield data programmatically, for example:The above simple generator is also equivalent to the below - as of Python 3.3 you can use yield from:However, yield from also allows for delegation to subgenerators,\nwhich will be explained in the following section on cooperative delegation with sub-coroutines.yield forms an expression that allows data to be sent into the generator (see footnote 3)Here is an example, take note of the received variable, which will point to the data that is sent to the generator:First, we must queue up the generator with the builtin function, next. It will\ncall the appropriate next or __next__ method, depending on the version of\nPython you are using:And now we can send data into the generator. (Sending None is\nthe same as calling next.) :Now, recall that yield from is available in Python 3. This allows us to delegate coroutines to a subcoroutine:And now we can delegate functionality to a sub-generator and it can be used\nby a generator just as above:Now simulate adding another 1,000 to the account plus the return on the account (60.0):You can read more about the precise semantics of yield from in PEP 380.The close method raises GeneratorExit at the point the function\nexecution was frozen. This will also be called by __del__ so you\ncan put any cleanup code where you handle the GeneratorExit:You can also throw an exception which can be handled in the generator\nor propagated back to the user:Raises:I believe I have covered all aspects of the following question:What does the yield keyword do in Python?It turns out that yield does a lot. I'm sure I could add even more\nthorough examples to this. If you want more or have some constructive criticism, let me know by commenting\nbelow.The top/accepted answer is a very incomplete answer.The grammar currently allows any expression in a list comprehension.Since yield is an expression, it has been touted by some as interesting to use it in comprehensions or generator expression - in spite of citing no particularly good use-case.The CPython core developers are discussing deprecating its allowance.\nHere's a relevant post from the mailing list:On 30 January 2017 at 19:05, Brett Cannon  wrote:On Sun, 29 Jan 2017 at 16:39 Craig Rodrigues  wrote:I'm OK with either approach.  Leaving things the way they are in Python 3\nis no good, IMHO.My vote is it be a SyntaxError since you're not getting what you expect from\nthe syntax.I'd agree that's a sensible place for us to end up, as any code\nrelying on the current behaviour is really too clever to be\nmaintainable.In terms of getting there, we'll likely want:Cheers, Nick.--  Nick Coghlan   |   ncoghlan at gmail.com   |   Brisbane, AustraliaFurther, there is an outstanding issue (10544) which seems to be pointing in the direction of this never being a good idea (PyPy, a Python implementation written in Python, is already raising syntax warnings.)Bottom line, until the developers of CPython tell us otherwise: Don't put yield in a generator expression or comprehension.In Python 3:In a generator function, the return statement indicates that the generator is done and will cause StopIteration to be raised. The returned value (if any) is used as an argument to construct StopIteration and becomes the StopIteration.value attribute.Historical note, in Python 2:\n\"In a generator function, the return statement is not allowed to include an expression_list. In that context, a bare return indicates that the generator is done and will cause StopIteration to be raised.\"\nAn expression_list is basically any number of expressions separated by commas - essentially, in Python 2, you can stop the generator with return, but you can't return a value.The languages CLU, Sather, and Icon were referenced in the proposal\nto introduce the concept of generators to Python. The general idea is\nthat a function can maintain internal state and yield intermediate\ndata points on demand by the user. This promised to be superior in performance\nto other approaches, including Python threading, which isn't even available on some systems.This means, for example, that range objects aren't Iterators, even though they are iterable, because they can be reused. Like lists, their __iter__ methods return iterator objects.yield was originally introduced as a statement, meaning that it\ncould only appear at the beginning of a line in a code block.\nNow yield creates a yield expression.\nhttps://docs.python.org/2/reference/simple_stmts.html#grammar-token-yield_stmt\nThis change was proposed to allow a user to send data into the generator just as\none might receive it. To send data, one must be able to assign it to something, and\nfor that, a statement just won't work.",
                "yield is just like return - it returns whatever you tell it to (as a generator). The difference is that the next time you call the generator, execution starts from the last call to the yield statement. Unlike return, the stack frame is not cleaned up when a yield occurs, however control is transferred back to the caller, so its state will resume the next time the function is called.In the case of your code, the function get_child_candidates is acting like an iterator so that when you extend your list, it adds one element at a time to the new list.list.extend calls an iterator until it's exhausted. In the case of the code sample you posted, it would be much clearer to just return a tuple and append that to the list.",
                "There's one extra thing to mention: a function that yields doesn't actually have to terminate. I've written code like this:Then I can use it in other code like this:It really helps simplify some problems, and makes some things easier to work with.",
                "For those who prefer a minimal working example, meditate on this interactive Python session:",
                "TL;DRWhenever you find yourself building a list from scratch, yield each piece instead.This was my first \"aha\" moment with yield.yield is a sugary way to saybuild a series of stuffSame behavior:Different behavior:Yield is single-pass: you can only iterate through once. When a function has a yield in it we call it a generator function. And an iterator is what it returns. Those terms are revealing. We lose the convenience of a container, but gain the power of a series that's computed as needed, and arbitrarily long.Yield is lazy, it puts off computation. A function with a yield in it doesn't actually execute at all when you call it. It returns an iterator object that remembers where it left off. Each time you call next() on the iterator (this happens in a for-loop) execution inches forward to the next yield. return raises StopIteration and ends the series (this is the natural end of a for-loop).Yield is versatile. Data doesn't have to be stored all together, it can be made available one at a time. It can be infinite.If you need multiple passes and the series isn't too long, just call list() on it:Brilliant choice of the word yield because both meanings apply:yield \u2014 produce or provide (as in agriculture)...provide the next data in the series.yield \u2014 give way or relinquish (as in political power)...relinquish CPU execution until the iterator advances.",
                "Yield gives you a generator.As you can see, in the first case foo holds the entire list in memory at once. It's not a big deal for a list with 5 elements, but what if you want a list of 5 million? Not only is this a huge memory eater, it also costs a lot of time to build at the time that the function is called.In the second case, bar just gives you a generator. A generator is an iterable--which means you can use it in a for loop, etc, but each value can only be accessed once. All the values are also not stored in memory at the same time; the generator object \"remembers\" where it was in the looping the last time you called it--this way, if you're using an iterable to (say) count to 50 billion, you don't have to count to 50 billion all at once and store the 50 billion numbers to count through.Again, this is a pretty contrived example, you probably would use itertools if you really wanted to count to 50 billion. :)This is the most simple use case of generators. As you said, it can be used to write efficient permutations, using yield to push things up through the call stack instead of using some sort of stack variable. Generators can also be used for specialized tree traversal, and all manner of other things.",
                "It's returning a generator. I'm not particularly familiar with Python, but I believe it's the same kind of thing as C#'s iterator blocks if you're familiar with those.The key idea is that the compiler/interpreter/whatever does some trickery so that as far as the caller is concerned, they can keep calling next() and it will keep returning values - as if the generator method was paused. Now obviously you can't really \"pause\" a method, so the compiler builds a state machine for you to remember where you currently are and what the local variables etc look like. This is much easier than writing an iterator yourself.",
                "There is one type of answer that I don't feel has been given yet, among the many great answers that describe how to use generators. Here is the programming language theory answer:The yield statement in Python returns a generator. A generator in Python is a function that returns continuations (and specifically a type of coroutine, but continuations represent the more general mechanism to understand what is going on).Continuations in programming languages theory are a much more fundamental kind of computation, but they are not often used, because they are extremely hard to reason about and also very difficult to implement. But the idea of what a continuation is, is straightforward: it is the state of a computation that has not yet finished. In this state, the current values of variables, the operations that have yet to be performed, and so on, are saved. Then at some point later in the program the continuation can be invoked, such that the program's variables are reset to that state and the operations that were saved are carried out.Continuations, in this more general form, can be implemented in two ways. In the call/cc way, the program's stack is literally saved and then when the continuation is invoked, the stack is restored.In continuation passing style (CPS), continuations are just normal functions (only in languages where functions are first class) which the programmer explicitly manages and passes around to subroutines. In this style, program state is represented by closures (and the variables that happen to be encoded in them) rather than variables that reside somewhere on the stack. Functions that manage control flow accept continuation as arguments (in some variations of CPS, functions may accept multiple continuations) and manipulate control flow by invoking them by simply calling them and returning afterwards. A very simple example of continuation passing style is as follows:In this (very simplistic) example, the programmer saves the operation of actually writing the file into a continuation (which can potentially be a very complex operation with many details to write out), and then passes that continuation (i.e, as a first-class closure) to another operator which does some more processing, and then calls it if necessary. (I use this design pattern a lot in actual GUI programming, either because it saves me lines of code or, more importantly, to manage control flow after GUI events trigger.)The rest of this post will, without loss of generality, conceptualize continuations as CPS, because it is a hell of a lot easier to understand and read.Now let's talk about generators in Python. Generators are a specific subtype of continuation. Whereas continuations are able in general to save the state of a computation (i.e., the program's call stack), generators are only able to save the state of iteration over an iterator. Although, this definition is slightly misleading for certain use cases of generators. For instance:This is clearly a reasonable iterable whose behavior is well defined -- each time the generator iterates over it, it returns 4 (and does so forever). But it isn't probably the prototypical type of iterable that comes to mind when thinking of iterators (i.e., for x in collection: do_something(x)). This example illustrates the power of generators: if anything is an iterator, a generator can save the state of its iteration.To reiterate: Continuations can save the state of a program's stack and generators can save the state of iteration. This means that continuations are more a lot powerful than generators, but also that generators are a lot, lot easier. They are easier for the language designer to implement, and they are easier for the programmer to use (if you have some time to burn, try to read and understand this page about continuations and call/cc).But you could easily implement (and conceptualize) generators as a simple, specific case of continuation passing style:Whenever yield is called, it tells the function to return a continuation.  When the function is called again, it starts from wherever it left off. So, in pseudo-pseudocode (i.e., not pseudocode, but not code) the generator's next method is basically as follows:where the yield keyword is actually syntactic sugar for the real generator function, basically something like:Remember that this is just pseudocode and the actual implementation of generators in Python is more complex. But as an exercise to understand what is going on, try to use continuation passing style to implement generator objects without use of the yield keyword.",
                "Here is an example in plain language. I will provide a correspondence between high-level human concepts to low-level Python concepts.I want to operate on a sequence of numbers, but I don't want to bother my self with the creation of that sequence, I want only to focus on the operation I want to do. So, I do the following:This is what a generator does (a function that contains a yield); it starts executing on the first next(), pauses whenever it does a yield, and when asked for the next() value it continues from the point it was last. It fits perfectly by design with the iterator protocol of Python, which describes how to sequentially request values.The most famous user of the iterator protocol is the for command in Python. So, whenever you do a:it doesn't matter if sequence is a list, a string, a dictionary or a generator object like described above; the result is the same: you read items off a sequence one by one.Note that defining a function which contains a yield keyword is not the only way to create a generator; it's just the easiest way to create one.For more accurate information, read about iterator types, the yield statement and generators in the Python documentation.",
                "While a lot of answers show why you'd use a yield to create a generator, there are more uses for yield.  It's quite easy to make a coroutine, which enables the passing of information between two blocks of code.  I won't repeat any of the fine examples that have already been given about using yield to create a generator.To help understand what a yield does in the following code, you can use your finger to trace the cycle through any code that has a yield.  Every time your finger hits the yield, you have to wait for a next or a send to be entered.  When a next is called, you trace through the code until you hit the yield\u2026 the code on the right of the yield is evaluated and returned to the caller\u2026 then you wait.  When next is called again, you perform another loop through the code.  However, you'll note that in a coroutine, yield can also be used with a send\u2026 which will send a value from the caller into the yielding function. If a send is given, then yield receives the value sent, and spits it out the left hand side\u2026 then the trace through the code progresses until you hit the yield again (returning the value at the end, as if next was called).For example:",
                "There is another yield use and meaning (since Python 3.3):From PEP 380 -- Syntax for Delegating to a Subgenerator:A syntax is proposed for a generator to delegate part of its operations to another generator. This allows a section of code containing 'yield' to be factored out and placed in another generator. Additionally, the subgenerator is allowed to return with a value, and the value is made available to the delegating generator.The new syntax also opens up some opportunities for optimisation when one generator re-yields values produced by another.Moreover this will introduce (since Python 3.5):to avoid coroutines being confused with a regular generator (today yield is used in both).",
                "All great answers, however a bit difficult for newbies.I assume you have learned the return statement.As an analogy, return and yield are twins. return means 'return and stop' whereas 'yield` means 'return, but continue'Run it:See, you get only a single number rather than a list of them. return never allows you prevail happily, just implements once and quit.Replace return with yield:Now, you win to get all the numbers.Comparing to return which runs once and stops, yield runs times you planed.\nYou can interpret return as return one of them, and yield as return all of them. This is called iterable.It's the core about yield.The difference between a list return outputs and the object yield output is:You will always get [0, 1, 2] from a list object but only could retrieve them from 'the object yield output' once. So, it has a new name generator object as displayed in Out[11]: <generator object num_list at 0x10327c990>.In conclusion, as a metaphor to grok it:",
                "From a programming viewpoint, the iterators are implemented as thunks.To implement iterators, generators, and thread pools for concurrent execution, etc. as thunks, one uses messages sent to a closure object, which has a dispatcher, and the dispatcher answers to \"messages\".\"next\" is a message sent to a closure, created by the \"iter\" call.There are lots of ways to implement this computation. I used mutation, but it is possible to do this kind of computation without mutation, by returning the current value and the next yielder (making it referential transparent).  Racket uses a sequence of transformations of the initial program in some intermediary languages, one of such rewriting making the yield operator to be transformed in some language with simpler operators.Here is a demonstration of how yield could be rewritten, which uses the structure of R6RS, but the semantics is identical to Python's. It's the same model of computation, and only a change in syntax is required to rewrite it using yield of Python.",
                "Here are some Python examples of how to actually implement generators as if Python did not provide syntactic sugar for them:As a Python generator:Using lexical closures instead of generatorsUsing object closures instead of generators (because ClosuresAndObjectsAreEquivalent)",
                "I was going to post \"read page 19 of Beazley's 'Python: Essential Reference' for a quick description of generators\", but so many others have posted good descriptions already.Also, note that yield can be used in coroutines as the dual of their use in generator functions.  Although it isn't the same use as your code snippet, (yield) can be used as an expression in a function.  When a caller sends a value to the method using the send() method, then the coroutine will execute until the next (yield) statement is encountered.Generators and coroutines are a cool way to set up data-flow type applications.  I thought it would be worthwhile knowing about the other use of the yield statement in functions.",
                "Here is a simple example:Output:I am not a Python developer, but it looks to me yield holds the position of program flow and the next loop start from \"yield\" position. It seems like it is waiting at that position, and just before that, returning a value outside, and next time continues to work.It seems to be an interesting and nice ability :D",
                "Here is a mental image of what yield does.I like to think of a thread as having a stack (even when it's not implemented that way).When a normal function is called, it puts its local variables on the stack, does some computation, then clears the stack and returns. The values of its local variables are never seen again.With a yield function, when its code begins to run (i.e. after the function is called, returning a generator object, whose next() method is then invoked), it similarly puts its local variables onto the stack and computes for a while. But then, when it hits the yield statement, before clearing its part of the stack and returning, it takes a snapshot of its local variables and stores them in the generator object. It also writes down the place where it's currently up to in its code (i.e. the particular yield statement).So it's a kind of a frozen function that the generator is hanging onto.When next() is called subsequently, it retrieves the function's belongings onto the stack and re-animates it. The function continues to compute from where it left off, oblivious to the fact that it had just spent an eternity in cold storage.Compare the following examples:When we call the second function, it behaves very differently to the first. The yield statement might be unreachable, but if it's present anywhere, it changes the nature of what we're dealing with.Calling yielderFunction() doesn't run its code, but makes a generator out of the code. (Maybe it's a good idea to name such things with the yielder prefix for readability.)The gi_code and gi_frame fields are where the frozen state is stored. Exploring them with dir(..), we can confirm that our mental model above is credible.",
                "Imagine that you have created a remarkable machine that is capable of generating thousands and thousands of lightbulbs per day. The machine generates these lightbulbs in boxes with a unique serial number. You don't have enough space to store all of these lightbulbs at the same time, so you would like to adjust it to generate lightbulbs on-demand.Python generators don't differ much from this concept. Imagine that you have a function called barcode_generator that generates unique serial numbers for the boxes. Obviously, you can have a huge number of such barcodes returned by the function, subject to the hardware (RAM) limitations. A wiser, and space efficient, option is to generate those serial numbers on-demand.Machine's code:Note the next(barcode) bit.As you can see, we have a self-contained \u201cfunction\u201d to generate the next unique serial number each time. This function returns a generator! As you can see, we are not calling the function each time we need a new serial number, but instead we are using next() given the generator to obtain the next serial number.To be more precise, this generator is a lazy iterator! An iterator is an object that helps us traverse a sequence of objects. It's called lazy because it does not load all the items of the sequence in memory until they are needed. The use of next in the previous example is the explicit way to obtain the next item from the iterator. The implicit way is using for loops:This will print barcodes infinitely, yet you will not run out of memory.In other words, a generator looks like a function but behaves like an iterator.Finally, real-world applications? They are usually useful when you work with big sequences. Imagine reading a huge file from disk with billions of records. Reading the entire file in memory, before you can work with its content, will probably be infeasible (i.e., you will run out of memory).",
                "An easy example to understand what it is: yieldThe output is:",
                "Like every answer suggests, yield is used for creating a sequence generator. It's used for generating some sequence dynamically. For example, while reading a file line by line on a network, you can use the yield function as follows:You can use it in your code as follows:Execution Control Transfer gotchaThe execution control will be transferred from getNextLines() to the for loop when yield is executed. Thus, every time getNextLines() is invoked, execution begins from the point where it was paused last time.Thus in short, a function with the following codewill print",
                "(My below answer only speaks from the perspective of using Python generator, not the underlying implementation of generator mechanism, which involves some tricks of stack and heap manipulation.)When yield is used instead of a return in a python function, that function is turned into something special called generator function. That function will return an object of generator type. The yield keyword is a flag to notify the python compiler to treat such function specially. Normal functions will terminate once some value is returned from it. But with the help of the compiler, the generator function can be thought of as resumable. That is, the execution context will be restored and the execution will continue from last run. Until you explicitly call return, which will raise a StopIteration exception (which is also part of the iterator protocol), or reach the end of the function. I found a lot of references about generator but this one from the functional programming perspective is the most digestable.(Now I want to talk about the rationale behind generator, and the iterator based on my own understanding. I hope this can help you grasp the essential motivation of iterator and generator. Such concept shows up in other languages as well such as C#.)As I understand, when we want to process a bunch of data, we usually first store the data somewhere and then process it one by one. But this naive approach is problematic. If the data volume is huge, it's expensive to store them as a whole beforehand. So instead of storing the data itself directly, why not store some kind of metadata indirectly, i.e. the logic how the data is computed.There are 2 approaches to wrap such metadata.Either way, an iterator is created, i.e. some object that can give you the data you want. The OO approach may be a bit complex. Anyway, which one to use is up to you.",
                "In summary, the yield statement transforms your function into a factory that produces a special object called a generator which wraps around the body of your original function. When the generator is iterated, it executes your function  until it reaches the next yield then suspends execution and evaluates to the value passed to yield. It repeats this process on each iteration until the path of execution exits the function. For instance,simply outputsThe power comes from using the generator with a loop that calculates a sequence, the generator executes the loop stopping each time to 'yield' the next result of the calculation, in this way it calculates a list on the fly, the benefit being the memory saved for especially large calculationsSay you wanted to create a your own range function that produces an iterable range of numbers, you could do it like so,and use it like this;But this is inefficient becauseLuckily Guido and his team were generous enough to develop generators so we could just do this;Now upon each iteration a function on the generator called next() executes the function until it either reaches a 'yield' statement in which it stops and  'yields' the value or reaches the end of the function. In this case on the first call, next() executes up to the yield statement and yield 'n', on the next call it will execute the  increment statement, jump back to the 'while', evaluate it, and if true, it will stop and yield 'n' again, it will continue that way until the while condition returns false and the generator jumps to the end of the function.",
                "Yield is an objectA return in a function will return a single value.If you want a function to return a huge set of values, use yield.More importantly, yield is a barrier.like barrier in the CUDA language, it will not transfer control until it gets\n  completed.That is, it will run the code in your function from the beginning until it hits yield. Then, it\u2019ll return the first value of the loop.Then, every other call will run the loop you have written in the function one more time, returning the next value until there isn't any value to return.",
                "Many people use return rather than yield, but in some cases yield can be more efficient and easier to work with.Here is an example which yield is definitely best for:return (in function)yield (in function)Calling functionsBoth functions do the same thing, but yield uses three lines instead of five and has one less variable to worry about.This is the result from the code:As you can see both functions do the same thing. The only difference is return_dates() gives a list and yield_dates() gives a generator.A real life example would be something like reading a file line by line or if you just want to make a generator.",
                "The yield keyword simply collects returning results. Think of yield like return +=",
                "yield is like a return element for a function. The difference is, that the yield element turns a function into a generator. A generator behaves just like a function until something is 'yielded'. The generator stops until it is next called, and continues from exactly the same point as it started. You can get a sequence of all the 'yielded' values in one, by calling list(generator())."
            ]
        },
        {
            "tag": "",
            "question": [
                "Which JSON content type do I use?",
                "There are many \"standards\" for the JSON content type:\napplication/json\napplication/x-javascript\ntext/javascript\ntext/x-javascript\ntext/x-json\n\nWhich one do I use, and where? I assume ..."
            ],
            "url": "https://stackoverflow.com/questions/477816",
            "answer": [
                "For JSON text:The MIME media type for JSON text is application/json. The default encoding is UTF-8. (Source: RFC 4627)For JSONP (runnable JavaScript) with callback:Here are some blog posts that were mentioned in the relevant comments:",
                "IANA has registered the official MIME Type for JSON as application/json.When asked about why not text/json, Crockford seems to have said JSON is not really JavaScript nor text and also IANA was more likely to hand out application/* than text/*.More resources:",
                "For JSON:For JSON-P:",
                "Of course, the correct MIME media type for JSON is application/json, but it's necessary to realize what type of data is expected in your application.For example, I use Ext GWT and the server response must go as text/html but contains JSON data.Client side, Ext GWT form listenerIn case of using application/json response type, the browser suggests me to save the file.Server side source code snippet using Spring MVC",
                "Response is dynamically generated data, according to the query parameters passed in the URL.Example:Content-Type: application/jsonJSON with padding.\nResponse is JSON data, with a function call wrapped around it.Example:Content-Type: application/javascript",
                "If you are using Ubuntu or Debian and you serve .json files through Apache, you might want to serve the files with the correct content type. I am doing this primarily because I want to use the Firefox extension JSONViewThe Apache module mod_mime will help to do this easily. However, with Ubuntu you need to edit the file /etc/mime.types and add the lineThen restart Apache:",
                "If you're calling ASP.NET Web Services from the client-side you have to use application/json for it to work. I believe this is the same for the jQuery and Ext frameworks.",
                "The right content type for JSON is application/json UNLESS you're using JSONP, also known as JSON with Padding, which is actually JavaScript and so the right content type would be application/javascript.",
                "There is no doubt that application/json is the best MIME type for a JSON response.But I had some experience where I had to use application/x-javascript because of some compression issues. My hosting environment is shared hosting with GoDaddy. They do not allow me to change server configurations. I had added the following code to my web.config file for compressing responses.By using this, the .aspx pages was compressed with g-zip but JSON responses were not. I addedin the static and dynamic types sections. But this does not compress JSON responses at all.After that I removed this newly added type and addedin both the static and dynamic types sections, and changed the response type in.ashx (asynchronous handler) toAnd now I found that my JSON responses were compressed with g-zip. So I personally recommend to useonly if you want to compress your JSON responses on a shared hosting environment. Because in shared hosting, they do not allow you to change IIS configurations.",
                "Only when using application/json as the MIME type I have the following (as of November 2011 with the most recent versions of Chrome, Firefox with Firebug):",
                "Not everything works for content type application/json.If you are using Ext\u00a0JS form submit to upload file, be aware that the server response is parsed by the browser to create the document for the <iframe>.If the server is using JSON to send the return object, then the Content-Type header must be set to text/html in order to tell the browser to insert the text unchanged into the document body.See the Ext JS 3.4.0 API documentation.",
                "JSON is a domain-specific language (DSL) and a data format independent of JavaScript, and as such has its own MIME type, application/json. Respect for MIME types is of course client driven, so text/plain may do for transfer of bytes, but then you would be pushing up interpretation to the vendor application domain unnecessarily - application/json. Would you transfer XML via text/plain?But honestly, your choice of MIME type is advice to the client as to how to interpret the data- text/plain or text/HTML (when it's not HTML) is like type erasure- it's as uninformative as making all your objects of type Object in a typed language.No browser runtime I know of will take a JSON document and automatically make it available to the runtime as a JavaScript accessible object without intervention, but if you are working with a crippled client, that's an entirely different matter. But that's not the whole story- RESTful JSON services often don't have JavaScript runtimes, but it doesn't stop them using JSON as a viable data interchange format. If clients are that crippled... then I would consider perhaps HTML injection via an Ajax templating service instead.Application/JSON!",
                "If you're in a client-side environment, investigating about the cross-browser support is mandatory for a well supported web application.The right HTTP Content-Type would be application/json, as others already highlighted too, but some clients do not handle it very well, that's why jQuery recommends the default text/html.",
                "The correct answer is:",
                "As many others have mentioned, application/json is the correct answer.But what haven't been explained yet is what the other options you proposed mean.application/x-javascript: Experimental MIME type for JavaScript before application/javascript was made standard.text/javascript: Now obsolete. You should use application/javascript when using javascript.text/x-javascript: Experimental MIME type for the above situation.text/x-json: Experimental MIME type for JSON before application/json got officially registered.All in all, whenever you have any doubts about content types, you should check this link",
                "In JSP, you can use this in page directive:The correct MIME media type for JSON is application/json.  JSP will use it for sending a response to the client.",
                "\u201capplication/json\u201d is the correct JSON content type.",
                "The IANA registration for application/json saysApplications that use this media type:  JSON has been used to\n     exchange data between applications written in all of these\n     programming languages: ActionScript, C, C#, Clojure, ColdFusion,\n     Common Lisp, E, Erlang, Go, Java, JavaScript, Lua, Objective CAML,\n     Perl, PHP, Python, Rebol, Ruby, Scala, and Scheme.You'll notice that IANA.org doesn't list any of these other media types, in fact even application/javascript is now obsolete. So application/json is really the only possible correct answer.Browser support is another thing.The most widely supported non-standard media types are text/json or text/javascript. But some big names even use text/plain.Even more strange is the Content-Type header sent by Flickr, who returns JSON as text/xml. Google uses text/javascript for some of it's ajax apis.Examples:Output: Content-Type: text/javascriptOutput: Content-Type: text/xml",
                "The right MIME type is application/jsonBUTI experienced many situations where the browser type or the framework user needed:",
                "I use the below",
                "The Content-Type header should be set to 'application/json' when posting. Server listening for the request should include \"Accept=application/json\".\nIn Spring MVC you can do it like this:Add headers to the response:",
                "The application/json works great in PHP to store an array or object\n  data.I use this code to put data in JSON on Google Cloud Storage (GCS) which is set publically viewable:To get back the data is straight forward:",
                "In Spring you have a defined type: MediaType.APPLICATION_JSON_VALUE which is equivalent to application/json.",
                "For JSON, I am using:This is described in the IETF's JSON Data Interchange Format 7158 proposal, Section 1.2: Specifications of JSON.",
                "If the JSON is with padding then it will be application/jsonp. If the JSON is without padding then it will be application/json.To deal with both, it is a good practice to use: 'application/javascript' without bothering whether it is with padding or without padding.",
                "Extending the accepted responses, when you are using JSON in a REST context...There is a strong argument about using application/x-resource+json and application/x-collection+json when you are representing REST resources and collections.And if you decide to follow the jsonapi specification, you should use of application/vnd.api+json, as it is documented.Altough there is not an universal standard, it is clear that the added semantic to the resources being transfered justify a more explicit Content-Type than just application/json.Following this reasoning, other contexts could justify a more specific Content-Type.",
                "If you get data from REST API in JSON, you have to use Content-Type:",
                "PHP developers use this:",
                "JSON (JavaScript Object Notation) and JSONP (\"JSON with padding\") formats seems to be very similar and therefore it might be very confusing which MIME type they should be using. Even though the formats are similar, there are some subtle differences between them.So whenever in any doubts, I have a very simple approach (which works perfectly fine in most cases), namely, go and check corresponding RFC document.JSON\nRFC 4627 (The application/json Media Type for JavaScript Object Notation (JSON)) is a specifications of JSON format. It says in section 6, that the MIME media type for JSON text isJSONP\nJSONP (\"JSON with padding\") is handled different way than JSON, in a browser. JSONP is treated as a regular JavaScript script and therefore it should use application/javascript, the current official MIME type for JavaScript. In many cases, however, text/javascript MIME type will work fine too.Note that text/javascript has been marked as obsolete by RFC 4329 (Scripting Media Types) document and it is recommended to use application/javascript type instead. However, due to legacy reasons, text/javascript is still widely used and it has cross-browser support (which is not always a case with application/javascript MIME type, especially with older browsers)."
            ]
        },
        {
            "tag": "",
            "question": [
                "How can I remove a specific item from an array?",
                "How do I remove a specific value from an array? Something like:\narray.remove(value);\n\nI have to use core JavaScript. Frameworks are not allowed."
            ],
            "url": "https://stackoverflow.com/questions/5767325",
            "answer": [
                "Find the index of the array element you want to remove using indexOf, and then remove that index with splice.The splice() method changes the contents of an array by removing\nexisting elements and/or adding new elements.const array = [2, 5, 9];\n\nconsole.log(array);\n\nconst index = array.indexOf(5);\nif (index > -1) { // only splice array when item is found\n  array.splice(index, 1); // 2nd parameter means remove one item only\n}\n\n// array = [2, 9]\nconsole.log(array);The second parameter of splice is the number of elements to remove. Note that splice modifies the array in place and returns a new array containing the elements that have been removed.For the reason of completeness, here are functions. The first function removes only a single occurrence (i.e. removing the first match of 5 from [2,5,9,1,5,8,5]), while the second function removes all occurrences:function removeItemOnce(arr, value) {\n  var index = arr.indexOf(value);\n  if (index > -1) {\n    arr.splice(index, 1);\n  }\n  return arr;\n}\n\nfunction removeItemAll(arr, value) {\n  var i = 0;\n  while (i < arr.length) {\n    if (arr[i] === value) {\n      arr.splice(i, 1);\n    } else {\n      ++i;\n    }\n  }\n  return arr;\n}\n// Usage\nconsole.log(removeItemOnce([2,5,9,1,5,8,5], 5))\nconsole.log(removeItemAll([2,5,9,1,5,8,5], 5))In TypeScript, these functions can stay type-safe with a type parameter:",
                "Edited on 2016 OctoberIn this code example I use array.filter(...) function to remove unwanted items from an array. This function doesn't change the original array and creates a new one. If your browser doesn't support this function (e.g. Internet Explorer before version 9, or Firefox before version 1.5), consider polyfilling with core-js.IMPORTANT ECMAScript 6 () => {} arrow function syntax is not supported in Internet Explorer at all, Chrome before version 45, Firefox before version 22, and Safari before version 10. To use ECMAScript 6 syntax in old browsers you can use BabelJS.An additional advantage of this method is that you can remove multiple itemsIMPORTANT array.includes(...) function is not supported in Internet Explorer at all, Chrome before version 47, Firefox before version 43, Safari before version 9, and Edge before version 14 but you can polyfill with core-js.If the \"This-Binding Syntax\" proposal is ever accepted, you'll be able to do this:Try it yourself in BabelJS :)Reference",
                "I don't know how you are expecting array.remove(int) to behave. There are three possibilities I can think of that you might want.To remove an element of an array at an index i:If you want to remove every element with value number from the array:If you just want to make the element at index i no longer exist, but you don't want the indexes of the other elements to change:",
                "It depends on whether you want to keep an empty spot or not.If you do want an empty slot:If you don't want an empty slot:And if you need the value of that item, you can just store the returned array's element:If you want to remove at either end of the array, you can use array.pop() for the last one or array.shift() for the first one (both return the value of the item as well).If you don't know the index of the item, you can use array.indexOf(item) to get it (in a if() to get one item or in a while() to get all of them). array.indexOf(item) returns either the index or -1 if not found.",
                "A friend was having issues in Internet\u00a0Explorer\u00a08 and showed me what he did. I told him it was wrong, and he told me he got the answer here. The current top answer will not work in all browsers (Internet\u00a0Explorer\u00a08 for example), and it will only remove the first occurrence of the item.It loops through the array backwards (since indices and length will change as items are removed) and removes the item if it's found. It works in all browsers.",
                "There are two major approachessplice(): anArray.splice(index, 1);delete: delete anArray[index];Be careful when you use the delete for an array. It is good for deleting attributes of objects, but not so good for arrays. It is better to use splice for arrays.Keep in mind that when you use delete for an array you could get wrong results for anArray.length. In other words, delete would remove the element, but it wouldn't update the value of the length property.You can also expect to have holes in index numbers after using delete, e.g. you could end up with having indexes 1, 3, 4, 8, 9, and 11 and length as it was before using delete. In that case, all indexed for loops would crash, since indexes are no longer sequential.If you are forced to use delete for some reason, then you should use for each loops when you need to loop through arrays. As the matter of fact, always avoid using indexed for loops, if possible. That way the code would be more robust and less prone to problems with indexes.",
                "Array.prototype.removeByValue = function (val) {\n  for (var i = 0; i < this.length; i++) {\n    if (this[i] === val) {\n      this.splice(i, 1);\n      i--;\n    }\n  }\n  return this;\n}\n\nvar fruits = ['apple', 'banana', 'carrot', 'orange'];\nfruits.removeByValue('banana');\n\nconsole.log(fruits);\n// -> ['apple', 'carrot', 'orange']",
                "There isn't any need to use indexOf or splice. However, it performs better if you only want to remove one occurrence of an element.Find and move (move):Use indexOf and splice (indexof):Use only splice (splice):Run-times on Node.js for an array with 1000 elements (averaged over 10,000 runs):indexof is approximately 10 times slower than move. Even if improved by removing the call to indexOf in splice, it performs much worse than move.",
                "This provides a predicate instead of a value.NOTE: it will update the given array, and return the affected rows.",
                "You can do it easily with the filter method:function remove(arrOriginal, elementToRemove){\n    return arrOriginal.filter(function(el){return el !== elementToRemove});\n}\nconsole.log(remove([1, 2, 1, 0, 3, 1, 4], 1));This removes all elements from the array and also works faster than a combination of slice and indexOf.",
                "John Resig posted a good implementation:If you don\u2019t want to extend a global object, you can do something like the following, instead:But the main reason I am posting this is to warn users against the alternative implementation suggested in the comments on that page (Dec 14, 2007):It seems to work well at first, but through a painful process I discovered it fails when trying to remove the second to last element in an array. For example, if you have a 10-element array and you try to remove the 9th element with this:You end up with an 8-element array. I don't know why, but I confirmed John's original implementation doesn't have this problem.",
                "You can use ES6. For example to delete the value '3' in this case:Output :",
                "Underscore.js can be used to solve issues with multiple browsers. It uses in-build browser methods if present. If they are absent like in the case of older Internet\u00a0Explorer versions it uses its own custom methods.A simple example to remove elements from array (from the website):",
                "Using filter is an elegant way to achieve this requirement.\nfilter will not mutate the original array.const num = 3;\nlet arr = [1, 2, 3, 4];\nconst arr2 = arr.filter(x => x !== num);\nconsole.log(arr); // [1, 2, 3, 4]\nconsole.log(arr2); // [1, 2, 4]You can use filter and then assign the result to the original array if you want to achieve a mutation removal behaviour.const num = 3;\nlet arr = [1, 2, 3, 4];\narr = arr.filter(x => x !== num);\nconsole.log(arr); // [1, 2, 4]By the way, filter will remove all of the occurrences matched in the condition (not just the first occurrence) like you can see in the following exampleconst num = 3;\nlet arr = [1, 2, 3, 3, 3, 4];\narr = arr.filter(x => x !== num);\nconsole.log(arr); // [1, 2, 4]In case, you just want to remove the first occurrence, you can use the splice methodconst num = 3;\nlet arr = [1, 2, 3, 3, 3, 4];\narr.splice(arr.indexOf(num), 1);\nconsole.log(arr); // [1, 2, 3, 3, 4]",
                "Here are a few ways to remove an item from an array using JavaScript.All the method described do not mutate the original array, and instead create a new one.Suppose you have an array, and you want to remove an item in position i.One method is to use slice():const items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst i = 3\nconst filteredItems = items.slice(0, i).concat(items.slice(i+1, items.length))\n\nconsole.log(filteredItems)slice() creates a new array with the indexes it receives. We simply create a new array, from start to the index we want to remove, and concatenate another array from the first position following the one we removed to the end of the array.In this case, one good option is to use filter(), which offers a more declarative approach:const items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst valueToRemove = 'c'\nconst filteredItems = items.filter(item => item !== valueToRemove)\n\nconsole.log(filteredItems)This uses the ES6 arrow functions. You can use the traditional functions to support older browsers:const items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst valueToRemove = 'c'\nconst filteredItems = items.filter(function(item) {\n  return item !== valueToRemove\n})\n\nconsole.log(filteredItems)or you can use Babel and transpile the ES6 code back to ES5 to make it more digestible to old browsers, yet write modern JavaScript in your code.What if instead of a single item, you want to remove many items?Let's find the simplest solution.You can just create a function and remove items in series:const items = ['a', 'b', 'c', 'd', 'e', 'f']\n\nconst removeItem = (items, i) =>\n  items.slice(0, i-1).concat(items.slice(i, items.length))\n\nlet filteredItems = removeItem(items, 3)\nfilteredItems = removeItem(filteredItems, 5)\n//[\"a\", \"b\", \"c\", \"d\"]\n\nconsole.log(filteredItems)You can search for inclusion inside the callback function:const items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst valuesToRemove = ['c', 'd']\nconst filteredItems = items.filter(item => !valuesToRemove.includes(item))\n//\u00a0[\"a\", \"b\", \"e\", \"f\"]\n\nconsole.log(filteredItems)splice() (not to be confused with slice()) mutates the original array, and should be avoided.(originally posted on my site https://flaviocopes.com/how-to-remove-item-from-array/)",
                "If you want a new array with the deleted positions removed, you can always delete the specific element and filter out the array. It might need an extension of the array object for browsers that don't implement the filter method, but in the long term it's easier since all you do is this:It should display [1, 2, 3, 4, 6].",
                "Check out this code. It works in every major browser.remove_item = function(arr, value) {\n var b = '';\n for (b in arr) {\n  if (arr[b] === value) {\n   arr.splice(b, 1);\n   break;\n  }\n }\n return arr;\n};\n\nvar array = [1,3,5,6,5,9,5,3,55]\nvar res = remove_item(array,5);\nconsole.log(res)",
                "Removing a particular element/string from an array can be done in a one-liner:where:theArray: the array you want to remove something particular fromstringToRemoveFromArray: the string you want to be removed and 1 is the number of elements you want to remove.NOTE: If \"stringToRemoveFromArray\" is not located in the array, this will remove the last element of the array.It's always good practice to check if the element exists in your array first, before removing it.Depending if you have newer or older version of Ecmascript running on your client's computers:ORWhere '3' is the value you want to be removed from the array.\nThe array would then become : ['1','2','4','5','6']",
                "This post summarizes common approaches to element removal from an array as of ECMAScript 2019 (ES10).| In-place: Yes | \n| Removes duplicates: Yes(loop), No(indexOf) | \n| By value / index: By index |If you know the value you want to remove from an array you can use the splice method. First, you must identify the index of the target item. You then use the index as the start element and remove just one element.| In-place: No | \n| Removes duplicates: Yes | \n| By value / index: By value |The specific element can be filtered out from the array, by providing a filtering function. Such function is then called for every element in the array.| In-place: Yes/No (Depends on implementation) | \n| Removes duplicates: Yes/No (Depends on implementation) | \n| By value / index: By index / By value (Depends on implementation) |The prototype of Array can be extended with additional methods. Such methods will be then available to use on created arrays.Note: Extending prototypes of objects from the standard library of JavaScript (like Array) is considered by some as an antipattern.| In-place: Yes | \n| Removes duplicates: No | \n| By value / index: By index |Using the delete operator does not affect the length property. Nor does it affect the indexes of subsequent elements. The array becomes sparse, which is a fancy way of saying the deleted item is not removed but becomes undefined.The delete operator is designed to remove properties from JavaScript objects, which arrays are objects.| In-place: No | \n| Removes duplicates: Yes | \n| By value / index: By value |ES10 introduced Object.fromEntries, which can be used to create the desired Array from any Array-like object and filter unwanted elements during the process.| In-place: Yes | \n| Removes duplicates: No | \n| By value / index: N/A |JavaScript Array elements can be removed from the end of an array by setting the length property to a value less than the current value. Any element whose index is greater than or equal to the new length will be removed.| In-place: Yes | \n| Removes duplicates: No | \n| By value / index: N/A |The pop method removes the last element of the array, returns that element, and updates the length property. The pop method modifies the array on which it is invoked, This means unlike using delete the last element is removed completely and the array length reduced.| In-place: Yes | \n| Removes duplicates: No | \n| By value / index: N/A |The .shift() method works much like the pop method except it removes the first element of a JavaScript array instead of the last. When the element is removed the remaining elements are shifted down.| In-place: Yes | \n| Removes duplicates: N/A | \n| By value / index: N/A |The fastest technique is to set an array variable to an empty array.Alternatively technique from 2.1.1 can be used by setting length to 0.",
                "You can use lodash _.pull (mutate array), _.pullAt (mutate array) or _.without (does't mutate array),",
                "ES6 & without mutation:  (October 2016)const removeByIndex = (list, index) =>\r\n      [\r\n        ...list.slice(0, index),\r\n        ...list.slice(index + 1)\r\n      ];\r\n         \r\noutput = removeByIndex([33,22,11,44],1) //=> [33,11,44]\r\n      \r\nconsole.log(output)",
                "Today (2019-12-09) I conduct performance tests on macOS v10.13.6 (High Sierra) for chosen solutions. I show delete (A), but I do not use it in comparison with other methods, because it left empty space in the array.The conclusionsIn tests, I remove the middle element from the array in different ways. The A, C solutions are in-place. The B, D, E, F, G, H solutions are immutable.Results for an array with 10 elementsIn Chrome the array.splice (C) is the fastest in-place solution. The array.filter (D) is the fastest immutable solution. The slowest is array.slice (F). You can perform the test on your machine here.Results for an array with 1.000.000 elementsIn Chrome the array.splice (C) is the fastest in-place solution (the delete (C) is similar fast - but it left an empty slot in the array (so it does not perform a 'full remove')). The array.slice-splice (H) is the fastest immutable solution. The slowest is array.filter (D and E). You can perform the test on your machine here.var a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];\nvar log = (letter,array) => console.log(letter, array.join `,`);\n\nfunction A(array) {\n  var index = array.indexOf(5);\n  delete array[index];\n  log('A', array);\n}\n\nfunction B(array) {\n  var index = array.indexOf(5);\n  var arr = Array.from(array);\n  arr.splice(index, 1)\n  log('B', arr);\n}\n\nfunction C(array) {\n  var index = array.indexOf(5);\n  array.splice(index, 1);\n  log('C', array);\n}\n\nfunction D(array) {\n  var arr = array.filter(item => item !== 5)\n  log('D', arr);\n}\n\nfunction E(array) {\n  var index = array.indexOf(5);\n  var arr = array.filter((item, i) => i !== index)\n  log('E', arr);\n}\n\nfunction F(array) {\n  var index = array.indexOf(5);\n  var arr = array.slice(0, index).concat(array.slice(index + 1))\n  log('F', arr);\n}\n\nfunction G(array) {\n  var index = array.indexOf(5);\n  var arr = [...array.slice(0, index), ...array.slice(index + 1)]\n  log('G', arr);\n}\n\nfunction H(array) {\n  var index = array.indexOf(5);\n  var arr = array.slice(0);\n  arr.splice(index, 1);\n  log('H', arr);\n}\n\nA([...a]);\nB([...a]);\nC([...a]);\nD([...a]);\nE([...a]);\nF([...a]);\nG([...a]);\nH([...a]);\nThis snippet only presents code used in performance tests - it does not perform tests itself.Comparison for browsers: Chrome v78.0.0, Safari v13.0.4, and Firefox v71.0.0",
                "OK, for example you have the array below:And we want to delete number 4. You can simply use the below code:If you are reusing this function, you write a reusable function which will be attached to the native array function like below:But how about if you have the below array instead with a few [5]s in the array?We need a loop to check them all, but an easier and more efficient way is using built-in JavaScript functions, so we write a function which use a filter like below instead:Also there are third-party libraries which do help you to do this, like Lodash or Underscore. For more information, look at lodash _.pull, _.pullAt or _.without.",
                "I'm pretty new to JavaScript and needed this functionality. I merely wrote this:Then when I want to use it:Output - As expected.\n[\"item1\", \"item1\"]You may have different needs than I, so you can easily modify it to suit them. I hope this helps someone.",
                "I want to answer based on ECMAScript\u00a06. Assume you have an array like below:If you want to delete at a special index like 2, write the below code:But if you want to delete a special item like 3 and you don't know its index, do like below:Hint: please use an arrow function for filter callback unless you will get an empty array.",
                "If you have complex objects in the array you can use filters? \nIn situations where $.inArray or array.splice is not as easy to use. Especially if the objects are perhaps shallow in the array.E.g. if you have an object with an Id field and you want the object removed from an array:",
                "Update: This method is recommended only if you cannot use ECMAScript 2015 (formerly known as ES6). If you can use it, other answers here provide much neater implementations.This gist here will solve your problem, and also deletes all occurrences of the argument instead of just 1 (or a specified value).Usage:",
                "You should never mutate your array as this is against the functional programming pattern. You can create a new array without referencing the one you want to change data of using the ECMAScript\u00a06 method filter;Suppose you want to remove 5 from the array, you can simply do it like this:This will give you a new array without the value you wanted to remove. So the result will be:For further understanding you can read the MDN documentation on Array.filter.",
                "A more modern, ECMAScript 2015 (formerly known as Harmony or ES 6) approach. Given:Then:Yielding:You can use Babel and a polyfill service to ensure this is well supported across browsers.",
                "You can do a backward loop to make sure not to screw up the indexes, if there are multiple instances of the element.var myElement = \"chocolate\";\nvar myArray = ['chocolate', 'poptart', 'poptart', 'poptart', 'chocolate', 'poptart', 'poptart', 'chocolate'];\n\n/* Important code */\nfor (var i = myArray.length - 1; i >= 0; i--) {\n  if (myArray[i] == myElement) myArray.splice(i, 1);\n}\nconsole.log(myArray);"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I rename a local Git branch?",
                "How do I rename a local branch which has not yet been pushed to a remote repository?\nRelated:\n\nRename master branch for both local and remote Git repositories\nHow do I rename both a Git local and ..."
            ],
            "url": "https://stackoverflow.com/questions/6591213",
            "answer": [
                "To rename the current branch:To rename a branch while pointed to any branch:-m is short for --move.To push the  local branch and reset the upstream branch:To delete the  remote branch:To create a git rename alias:On Windows or another case-insensitive filesystem, use -M if there are only capitalization changes in the name. Otherwise, Git will throw a \"branch already exists\" error.",
                "The above command will change your branch name, but you have to be very careful using the renamed branch, because it will still refer to the old upstream branch associated with it, if any.If you want to push some changes into master after your local branch is renamed into new_branch_name (example name):git push origin new_branch_name:master (now changes will go to master branch but your local branch name is new_branch_name)For more details, see \"How to rename your local branch name in Git.\"",
                "To rename your current branch:",
                "Here are the steps to rename the branch:EDIT (12/01/2017): Make sure you run command git status and check that the newly created branch is pointing to its own ref and not the older one. If you find the reference to the older branch, you need to unset the upstream using:",
                "Rename the branch will be useful once your branch is finished. Then new stuff is coming, and you want to develop in the same branch instead of deleting it and create the new one.From my experience, to rename a local and remote branch in Git you should do the following steps.Quoting from Multiple States - Rename a local and remote branch in\n  gitIf you are on the branch you want to rename:If you are on a different branch:",
                "The answers so far have been correct, but here is some additional information:One can safely rename a branch with '-m' (move), but one has to be careful with '-M', because it forces the rename, even if there is an existing branch with the same name already. Here is the excerpt from the 'git-branch' man page:With a -m or -M option, <oldbranch> will be renamed to <newbranch>. If <oldbranch> had a corresponding reflog, it is renamed to match <newbranch>, and a reflog entry is created to remember the branch renaming. If <newbranch> exists, -M must be used to force the rename to happen.",
                "If it is your current branch, just doIf it is another branch you want to rename- If your branch was pushed, then after renaming you need to delete it from the remote Git repository and ask your new local to track a new remote branch:",
                "I foolishly named a branch starting with a hyphen, and then checked out master.  I didn't want to delete my branch, I had work in it.Neither of these worked:git checkout -dumb-namegit checkout -- -dumb-name\"s, 's and \\s didn't help either.  git branch -m doesn't work.Here's how I finally fixed it. Go into your working copy's .git/refs/heads, find the filename \"-dumb-name\", get the hash of the branch.  Then this will check it out, make a new branch with a sane name, and delete the old one.",
                "Just three steps to replicate change in name on remote as well as on GitHub:Step 1 git branch -m old_branchname new_branchnameStep 2 git push origin :old_branchname new_branchnameStep 3 git push --set-upstream origin new_branchname",
                "To rename a branch locally:Now you'll have to propagate these changes on your remote server as well.To push changes of the deleted old branch:To push changes of creation of new branch:",
                "Trying to answer specifically the question (at least the title).You can also rename the local branch, but keep tracking the old name on the remote.Now, when you run git push, the remote old_branch ref is updated with your local new_branch.You have to know and remember this configuration. But it can be useful if you don't have the choice for the remote branch name, but you don't like it (oh, I mean, you've got a very good reason not to like it !) and prefer a clearer name for your local branch.Playing with the fetch configuration, you can even rename the local remote-reference. i.e, having a refs/remote/origin/new_branch ref pointer to the branch, that is in fact the old_branch on origin. However, I highly discourage this, for the safety of your mind.",
                "Update 2022Before we begin, make sure you\u2019ve selected the branch you want to rename:If you want to see all of your local branches, use the following command:When you\u2019re all clear, follow these steps:Using the Git rename branch command will require you to add an -m option to your command:You can also rename a local branch from another branch by using the following two commands:Lastly, this command will list all \u2014 both local and remote \u2014 branches to verify that it has been renamed:Although it isn\u2019t possible to rename a remote branch directly, the process of renaming one involves these two easy steps:To start, you will need to rename a local branch by following the previous steps.\n2.Then delete the old branch and push the new one. You can do this easily with the following command:Reset the upstream branch for your new local branch, and you will be all set:",
                "Rename the branch using this command:-m: It renames/moves the branch. If there is already a branch, you will get an error.If there is already a branch and you want to rename with that branch, use:For more information about help, use this command in the terminal:or",
                "Advanced Git users can rename manually using:",
                "If you are on the branch you want to rename:If you are on a different branch:git push origin :old-name new-namegit push origin -u new-nameOr for a fast way to do that, you can use these 3 steps:# Rename branch locally# Delete the old remote branch# Push the new branch, set local branch to track the new remoteReferance: https://www.w3docs.com/snippets/git/how-to-rename-git-local-and-remote-branches.html",
                "Here are three steps: A command that you can call inside your terminal and change branch name.If you need more: step-by-step, How To Change Git Branch Name is a good article about that.",
                "Probably as mentioned by others, this will be a case mismatch in branch naming.If you have such a situation, I can guess that you're on Windows which will also lead you to:Then you have to do an intermediate step:Nothing more.",
                "Changing the branch locally is quite easy...If you are on the branch you want to change the name for, simply do this:Otherwise, if you are on master or any other branch other than the one you'd like to change the name, simply do:Also, I create the image below to show this in action on a command line. In this case, you are on master branch, for example:",
                "To rename the current branch (except for detached HEAD state) you can also use this alias:",
                "Since you do not want to push the branch to a remote server, this example will be useful:Let's say you have an existing branch called \"my-hot-feature,\" and you want to rename it to \"feature-15.\"First, you want to change your local branch. This couldn't be easier:For more information, you can visit Locally and Remotely Renaming a Branch in Git.",
                "If you are willing to use SourceTree (which I strongly recommend), you can right click your branch and chose 'Rename'.",
                "This will set the new name for the current branch you are working with.Here you have to provide the old branch name and the new branch name.",
                "Another option is not to use the command line at all. Git GUI clients such as SourceTree take away much of the syntactical learning curve / pain that causes questions such as this one to be amongst the most viewed on Stack Overflow.In SourceTree, right click on any local branch in the \"Branches\" pane on the left and select \"Rename ...\".",
                "A simple way to do it:For more, see this.",
                "Git version 2.9.2If you want to change the name of the local branch you are on:If you want to change the name of a different branch:If you want to change the name of a different branch to a name that already exists:Note: The last command is destructive and will rename your branch, but you will lose the old branch with that name and those commits because branch names must be unique.",
                "If you want to change the name of the current branch, run:If you want to delete the old remote branch, run:If you want to delete the old remote branch and create a new remote branch, run:",
                "Actually you have three steps because the local branch has a duplicate on the server so we have one step for local on two steps on the server:",
                "Git branch rename can be done by using:git branch -m oldBranch newBranchgit branch -M oldBranch ExistingBranchThe difference between -m and -M:-m: if you're trying to rename your branch with an existing branch name using -m.\nIt will raise an error saying that the branch already exists. You need to give unique name.But,-M: this will help you to force rename with a given name, even it is exists. So an existing branch will overwrite entirely with it...Here is a Git terminal example,",
                "All of the previous answers are talking about git branch -m. Of course, it's easy to operate, but for me, it may be a little hard to remember another Git command. So I tried to get the work done by the command I was familiar with. Yeah, you may guessed it.I use git branch -b <new_branch_name>. And if you don't want to save the old branch now you can execute git branch -D <old_branch_name> to remove it.I know it may be a little tedious, but it's easier to understand and remember. I hope it\u2018s helpful for you.",
                "For Git GUI users it couldn't be much simpler.\nIn Git GUI, choose the branch name from the drop down list in the \"Rename Branch\" dialog box created from the menu item Branch:Rename, type a New Name, and click \"Rename\". I have highlighted where to find the drop down list."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I undo 'git add' before commit?",
                "I mistakenly added files to Git using the command:\ngit add myfile.txt\n\nI have not yet run git commit. How do I undo this so that these changes will not be included in the commit?"
            ],
            "url": "https://stackoverflow.com/questions/348170",
            "answer": [
                "Undo git add for uncommitted changes with:That will remove the file from the current index (the \"about to be committed\" list) without changing anything else.To unstage all changes for all files:In old versions of Git, the above commands are equivalent to git reset HEAD <file> and git reset HEAD respectively, and will fail if HEAD is undefined (because you haven't yet made any commits in your repository) or ambiguous (because you created a branch called HEAD, which is a stupid thing that you shouldn't do). This was changed in Git 1.8.2, though, so in modern versions of Git you can use the commands above even prior to making your first commit:\"git reset\" (without options or parameters) used to error out when\nyou do not have any commits in your history, but it now gives you\nan empty index (to match non-existent commit you are not even on).Documentation: git reset",
                "You want:Reasoning:When I was new to this, I first tried(to undo my entire initial add), only to get this (not so) helpful message:It turns out that this is because the HEAD ref (branch?) doesn't exist until after the first commit. That is, you'll run into the same beginner's problem as me if your workflow, like mine, was something like:git status... lots of crap scrolls by ...=> Damn, I didn't want to add all of that.google \"undo git add\"=> find Stack Overflow - yaygit reset .=>    fatal: Failed to resolve 'HEAD' as a valid ref.It further turns out that there's a bug logged against the unhelpfulness of this in the mailing list.And that the correct solution was right there in the Git status output (which, yes, I glossed over as 'crap)And the solution indeed is to use git rm --cached FILE.Note the warnings elsewhere here - git rm deletes your local working copy of the file, but not if you use --cached.  Here's the result of git help rm:--cached\n      Use this option to unstage and remove paths only from the index.\n      Working tree files, whether modified or not, will be left.I proceed to useto remove everything and start again. Didn't work though, because while add . is recursive, turns out rm needs -r to recurse. Sigh.Okay, now I'm back to where I started. Next time I'm going to use -n to do a dry run and see what will be added:I zipped up everything to a safe place before trusting git help rm about the --cached not destroying anything (and what if I misspelled it).",
                "If you type:Git will tell you what is staged, etc., including instructions on how to unstage:I find Git does a pretty good job of nudging me to do the right thing in situations like this.Note: Recent Git versions (1.8.4.x) have changed this message:",
                "To clarify: git add moves changes from the current working directory to the staging area (index).This process is called staging. So the most natural command to stage the changes (changed files) is the obvious one:git add is just an easier-to-type alias for git stagePity there is no git unstage nor git unadd commands. The relevant one is harder to guess or remember, but it is pretty obvious:We can easily create an alias for this:And finally, we have new commands:Personally I use even shorter aliases:",
                "An addition to the accepted answer, if your mistakenly-added file was huge, you'll probably notice that, even after removing it from the index with 'git reset', it still seems to occupy space in the .git directory.This is nothing to be worried about; the file is indeed still in the repository, but only as a \"loose object\". It will not be copied to other repositories (via clone, push), and the space will be eventually reclaimed - though perhaps not very soon. If you are anxious, you can run:Update (what follows is my attempt to clear some confusion that can arise from the most upvoted answers):So, which is the real undo of git add?git reset HEAD <file> ?orgit rm --cached <file>?Strictly speaking, and if I'm not mistaken: none.git add cannot be undone - safely, in general.Let's recall first what git add <file> actually does:If <file> was not previously tracked, git add adds it to the cache, with its current content.If <file> was already tracked, git add saves the current content (snapshot, version) to the cache. In Git, this action is still called add, (not mere update it), because two different versions (snapshots) of a file are regarded as two different items: hence, we are indeed adding a new item to the cache, to be eventually committed later.In light of this, the question is slightly ambiguous:I mistakenly added files using the command...The OP's scenario seems to be the first one (untracked file),  we want the \"undo\" to remove the file (not just the current contents) from the tracked items. If this is the case, then it's ok to run  git rm --cached <file>.And we could also run git reset HEAD <file>. This is in general preferable, because it works in both scenarios: it also does the undo when we wrongly added a version of an already tracked item.But there are two caveats.First: There is (as pointed out in the answer) only one scenario in which git reset HEAD doesn't work, but git rm --cached does: a new repository (no commits). But, really, this a practically irrelevant case.Second: Be aware that git reset HEAD  can't magically recover the previously cached file contents, it just resynchronises it from the HEAD. If our misguided git add overwrote a previous staged uncommitted version, we can't recover it. That's why, strictly speaking, we cannot undo [*].Example:Of course, this is not very critical if we just follow the usual lazy workflow of doing 'git add' only for adding new files (case 1), and we update new contents via the commit, git commit -a command.* (Edit: the above is practically correct, but still there can be some slightly hackish/convoluted ways for recovering changes that were staged, but not committed and then overwritten - see the comments by Johannes Matokic and iolsmit)",
                "Undo a file which has already been added is quite easy using Git. For resetting myfile.txt, which have already been added, use:Explanation:After you staged unwanted file(s), to undo, you can do git reset. Head is head of your file in the local and the last parameter is the name of your file.I have created the steps in the image below in more details for you, including all steps which may happen in these cases:",
                "will \"un-add\" everything you've added from your current directory recursively",
                "Git has commands for every action imaginable, but it needs extensive knowledge to get things right and because of that it is counter-intuitive at best...What you did before:What you want:Remove the file from the index, but keep it versioned and left with uncommitted changes in working copy:Reset the file to the last state from HEAD, undoing changes and removing them from the index:This is needed since git reset --hard HEAD won't work with single files.Remove <file> from index and versioning, keeping the un-versioned file with changes in working copy:Remove <file> from working copy and versioning completely:",
                "Runand remove all the files manually or by selecting all of them and clicking on the unstage from commit button.",
                "The question is not clearly posed. The reason is that git add has two meanings:If in doubt, useBecause it does the expected thing in both cases.Warning: if you do git rm --cached file on a file that was modified (a file that existed before in the repository), then the file will be removed on git commit! It will still exist in your file system, but if anybody else pulls your commit, the file will be deleted from their work tree.git status will tell you if the file was a new file or modified:",
                "As per many of the other answers, you can use git resetBUT:I found this great little post that actually adds the Git command (well, an alias) for git unadd: see git unadd for details or..Simply,Now you canAlternatively / directly:",
                "will remove a file named filename.txt from the current index (also called the \u201cstaging area\u201d, which is where changes \u201cabout to be committed\u201d are saved), without changing anything else (the working directory is not overwritten).",
                "If you're on your initial commit and you can't use git reset, just declare \"Git bankruptcy\" and delete the .git folder and start over",
                "As pointed out by others in related questions (see here, here, here, here, here, here, and here), you can now unstage a single file with:and unstage all files (from the root of the repo) with:git restore was introduced in July 2019 and released in version 2.23.\nWith the --staged flag, it restores the content of the index (what is asked here).When running git status with staged uncommitted file(s), this is now what Git suggests to use to unstage file(s) (instead of git reset HEAD <file> as it used to prior to v2.23).",
                "Use git add -i to remove just-added files from your upcoming commit.  Example:Adding the file you didn't want:Going into interactive add to undo your add (the commands typed at git here are \"r\" (revert), \"1\" (first entry in the list revert shows), 'return' to drop out of revert mode, and \"q\" (quit):That's it!  Here's your proof, showing that \"foo\" is back on the untracked list:",
                "Here's a way to avoid this vexing problem when you start a new project:Git makes it really hard to do git reset if you don't have any commits.  If you create a tiny initial commit just for the sake of having one, after that you can git add -A and git reset as many times as you want in order to get everything right.Another advantage of this method is that if you run into line-ending troubles later and need to refresh all your files, it's easy:",
                "Note that if you fail to specify a revision then you have to include a separator. Example from my console:(Git version 1.7.5.4)",
                "Maybe Git has evolved since you posted your question.Now, you can try:This should be what you are looking for.",
                "To remove new files from the staging area (and only in case of a new file), as suggested above:Use rm --cached only for new files accidentally added.",
                "To reset every file in a particular folder (and its subfolders), you can use the following command:",
                "Use the * command to handle multiple files at a time:etc.",
                "Just type git reset it will revert back and it is like you never typed git add . since your last commit. Make sure you have committed before.",
                "Suppose I create a new file, newFile.txt:Suppose I add the file accidentally, git add newFile.txt:Now I want to undo this add, before commit, git reset newFile.txt:",
                "You can unstage or undo using the git command or GUI Git.Single fileMultiple filesSuppose you have added Home.js, ListItem.js, Update.js by mistake,and want to undo/reset =>The same example using Git GUIOpens a window. Uncheck your files from Staged changes (will commit)",
                "For a specific file:For all added files:Note: checkout changes the code in the files and moves to the last updated (committed) state. reset doesn't change the codes; it just resets the header.",
                "To undo git add, use:",
                "There is also interactive mode:Choose option 3 to un add files. In my case I often want to add more than one file, and with interactive mode you can use numbers like this to add files. This will take all but 4: 1, 2, 3, and 5To choose a sequence, just type 1-5 to take all from 1 to 5.Git staging files",
                "This command will unstash your changes:You can also useto add parts of files.",
                "Will remove a file named filename.txt from the current index, the \"about to be committed\" area, without changing anything else.",
                "git add myfile.txt # This will add your file into the to-be-committed listQuite opposite to this command is,so, you will be in the previous state. Specified will be again in untracked list (previous state).It will reset your head with that specified file. so, if your head doesn't have it means, it will simply reset it."
            ]
        },
        {
            "tag": "",
            "question": [
                "What is the \"-->\" operator in C++?",
                "After reading Hidden Features and Dark Corners of C++/STL on comp.lang.c++.moderated, I was completely surprised that the following snippet compiled and worked in both Visual Studio 2008 and G++ 4.4.\n..."
            ],
            "url": "https://stackoverflow.com/questions/1642028",
            "answer": [
                "--> is not an operator. It is in fact two separate operators, -- and >.The conditional's code decrements x, while returning x's original (not decremented) value, and then compares the original value with 0 using the > operator.To better understand, the statement could be written as follows:",
                "Or for something completely different... x slides to 0.Not so mathematical, but... every picture paints a thousand words...",
                "That's a very complicated operator, so even ISO/IEC JTC1 (Joint Technical Committee 1) placed its description in two different parts of the C++ Standard.Joking aside, they are two different operators: -- and > described respectively in \u00a75.2.6/2 and \u00a75.9 of the C++03 Standard.",
                "x can go to zero even faster in the opposite direction in C++:8 6 4 2You can control speed with an arrow!90 80 70 60 50 40 30 20 10;)",
                "It's equivalent tox-- (post decrement) is equivalent to x = x-1 (but returning the original value of x), so the code transforms to:",
                "It'sJust the space makes the things look funny, -- decrements and > compares.",
                "The usage of --> has historical relevance. Decrementing was (and still is in some cases), faster than incrementing on the x86 architecture. Using --> suggests that x is going to 0, and appeals to those with mathematical backgrounds.",
                "Utterly geek, but I will be using this:",
                "is how that's parsed.",
                "One book I read (I don't remember correctly which book) stated: Compilers try to parse expressions to the biggest token by using the left right rule.In this case, the expression:Parses to biggest tokens:The same rule applies to this expression:After parse:",
                "This is exactly the same as",
                "Anyway, we have a \"goes to\" operator now. \"-->\" is easy to be remembered as a direction, and \"while x goes to zero\" is meaning-straight.Furthermore, it is a little more efficient than \"for (x = 10; x > 0; x --)\" on some platforms.",
                "This code first compares x and 0 and then decrements x. (Also said in the first answer: You're post-decrementing x and then comparing x and 0 with the > operator.) See the output of this code:We now first compare and then decrement by seeing 0 in the output.If we want to first decrement and then compare, use this code:That output is:",
                "My compiler will print out 9876543210 when I run this code.As expected. The while( x-- > 0 ) actually means while( x > 0). The x-- post decrements x.is a different way of writing the same thing.It is nice that the original looks like \"while x goes to 0\" though.",
                "There is a space missing between -- and >. x is post decremented, that is, decremented after checking the condition x>0 ?.",
                "-- is the decrement operator and > is the greater-than operator.The two operators are applied as a single one like -->.",
                "It's a combination of two operators. First -- is for decrementing the value, and > is for checking whether the value is greater than the right-hand operand.The output will be:",
                "C and C++ obey the \"maximal munch\" rule. The same way a---b is translated to (a--) - b, in your case  x-->0 translates to (x--)>0.What the rule says essentially is that going left to right, expressions are formed by taking the maximum of characters which will form a valid token.",
                "Actually, x is post-decrementing and with that condition is being checked. It's not -->, it's (x--) > 0Note: value of x is changed after the condition is checked, because it post-decrementing. Some similar cases can also occur, for example:",
                "Instead of regular arrow operator (-->) you can use armor-piercing arrow operator: --x> (note those sharp barbs on the arrow tip). It adds +1 to armor piercing, so it finishes the loop 1 iteration faster than regular arrow operator. Try it yourself:",
                "For larger numbers, C++20 introduces some more advanced looping features.\nFirst to catch i we can build an inverse loop-de-loop and deflect it onto the std::ostream. However, the speed of i is implementation-defined, so we can use the new C++20 speed operator <<i<< to speed it up. We must also catch it by building wall, if we don't, i leaves the scope and de referencing it causes undefined behavior. To specify the separator, we can use:and there we have a for loop from 67 to 1.",
                "Why all the complication?The simple answer to the original question is just:It does the same thing. I am not saying you should do it like this, but it does the same thing and would have answered the question in one post.The x-- is just shorthand for the above, and > is just a normal greater-than operator. No big mystery!There are too many people making simple things complicated nowadays  ;)",
                "Conventional way we define condition in while loop parenthesis\"()\" and terminating condition inside the braces\"{}\", but this -- & > is a way one defines all at once.\nFor example:It says, decrement a and run the loop till the time a is greater than 0Other way it should have been like:Both ways, we do the same thing and achieve the same goals.",
                "(x --> 0) means (x-- > 0).Output:  9 8 7 6 5 4 3 2 1Output: 9 8 7 6 5 4 3 2 1 0Output: 9 8 7 6 5 4 3 2 1 0Output: 9 8 7 6 5 4 3 2 1 0Likewise, you can try lot of methods to execute this command successfully.",
                "This --> is not an operator at all. We have an operator like ->, but not like -->. It is just a wrong interpretation of while(x-- >0) which simply means x has the post decrement operator and this loop will run till it is greater than zero.Another simple way of writing this code would be while(x--). The  while loop will stop whenever it gets a false condition and here there is only one case, i.e., 0. So it will stop when the x value is decremented to zero.",
                "Here -- is the unary post decrement operator.",
                "--> is not an operator, it is the juxtaposition of -- (post-decrement) and > (greater than comparison).The loop will look more familiar as:This loop is a classic idiom to enumerate values between 10 (the excluded upper bound) and 0 the included lower bound, useful to iterate over the elements of an array from the last to the first.The initial value 10 is the total number of iterations (for example the length of the array), and one plus the first value used inside the loop. The 0 is the last value of x inside the loop, hence the comment x goes to 0.Note that the value of x after the loop completes is -1.Note also that this loop will operate the same way if x has an unsigned type such as size_t, which is a strong advantage over the naive alternative for (i = length-1; i >= 0; i--).For this reason, I am actually a fan of this surprising syntax: while (x --> 0). I find this idiom eye-catching and elegant, just like for (;;) vs: while (1) (which looks confusingly similar to while (l)). It also works in other languages whose syntax is inspired by C: C++, Objective-C, java, javascript, C# to name a few.",
                "That's what you mean.We heard in childhood,Stop don't, Let Go (\u0631\u0648\u06a9\u0648 \u0645\u062a\u060c \u062c\u0627\u0646\u06d2 \u062f\u0648)Where a Comma makes confusionStop, don't let go. (\u0631\u0648\u06a9\u0648\u060c \u0645\u062a \u062c\u0627\u0646\u06d2 \u062f\u0648)Same Happens in Programming now, a SPACE makes confusion. :D",
                "The operator you use is called \"decrement-and-then-test\". It is defined in the C99 standard, which is the latest version of the C programming language standard. The C99 standard added a number of new operators, including the \"decrement-and-then-test\" operator, to the C language. Many C++ compilers have adopted these new operators as extensions to the C++ language.Here is how the code without using the \"decrement-and-then-test\" operator:In this version of the code, the while loop uses the > operator to test whether x is greater than 0. The x-- statement is used to decrement x by 1 at the end of each iteration of the loop."
            ]
        },
        {
            "tag": "",
            "question": [
                "Can comments be used in JSON?",
                "Can I use comments inside a JSON file? If so, how?"
            ],
            "url": "https://stackoverflow.com/questions/244777",
            "answer": [
                "No.JSON is data-only. If you include a comment, then it must be data too.You could have a designated data element called \"_comment\" (or something) that should be ignored by apps that use the JSON data.You would probably be better having the comment in the processes that generates/receives the JSON, as they are supposed to know what the JSON data will be in advance, or at least the structure of it.But if you decided to:",
                "No, comments of the form //\u2026 or /*\u2026*/ are not allowed in JSON. This answer is based on:",
                "Include comments if you choose; strip them out with a minifier before parsing or transmitting.I just released JSON.minify() which strips out comments and whitespace from a block of JSON and makes it valid JSON that can be parsed. So, you might use it like:When I released it, I got a huge backlash of people disagreeing with even the idea of it, so I decided that I'd write a comprehensive blog post on why comments make sense in JSON. It includes this notable comment from the creator of JSON:Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser. - Douglas Crockford, 2012Hopefully that's helpful to those who disagree with why JSON.minify() could be useful.",
                "Comments were removed from JSON by design.I removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability. I know that the lack of comments makes some people sad, but it shouldn't.Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser.Source: Public statement by Douglas Crockford on G+",
                "JSON does not support comments. It was also never intended to be used for configuration files where comments would be needed.Hjson is a configuration file format for humans. Relaxed syntax, fewer mistakes, more comments.See hjson.github.io for JavaScript, Java, Python, PHP, Rust, Go, Ruby, C++ and C# libraries.",
                "DISCLAIMER: YOUR WARRANTY IS VOIDAs has been pointed out, this hack takes advantage of the implementation of the spec. Not all JSON parsers will understand this sort of JSON. Streaming parsers in particular will choke.It's an interesting curiosity, but you should really not be using it for anything at all. Below is the original answer.I've found a little hack that allows you to place comments in a JSON file that will not affect the parsing, or alter the data being represented in any way.It appears that when declaring an object literal you can specify two values with the same key, and the last one takes precedence. Believe it or not, it turns out that JSON parsers work the same way. So we can use this to create comments in the source JSON that will not be present in a parsed object representation.If we apply this technique, your commented JSON file might look like this:The above code is valid JSON. If you parse it, you'll get an object like this:Which means there is no trace of the comments, and they won't have weird side-effects.Happy hacking!",
                "Consider using YAML. It's nearly a superset of JSON (virtually all valid JSON is valid YAML) and it allows comments.",
                "You can't. At least that's my experience from a quick glance at json.org.JSON has its syntax visualized on that page. There isn't any note about comments.",
                "Comments are not an official standard, although some parsers support C++-style comments. One that I use is JsonCpp. In the examples there is this one:jsonlint does not validate this. So comments are a parser specific extension and not standard.Another parser is JSON5.An alternative to JSON TOML.A further alternative is jsonc.The latest version of nlohmann/json has optional support for ignoring comments on parsing.",
                "Here is what I found in the Google Firebase documentation that allows you to put comments in JSON:",
                "You should write a JSON schema instead. JSON schema is currently a proposed Internet draft specification. Besides documentation, the schema can also be used for validating your JSON data.Example:You can provide documentation by using the description schema attribute.",
                "If you are using Jackson as your JSON parser then this is how you enable it to allow comments:Then you can have comments like this:And you can also have comments starting with # by setting:But in general (as answered before) the specification does not allow comments.",
                "NO. JSON used to support comments but they were abused and removed from the standard.From the creator of JSON:I removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability.  I know that the lack of comments makes some people sad, but it shouldn't.  - Douglas Crockford, 2012The official JSON site is at JSON.org. JSON is defined as a standard by ECMA International. There is always a petition process to have standards revised. It is unlikely that annotations will be added to the JSON standard for several reasons.JSON by design is an easily reverse-engineered (human parsed) alternative to XML. It is simplified even to the point that annotations are unnecessary. It is not even a markup language. The goal is stability and  interoperablilty.Anyone who understands the \"has-a\" relationship of object orientation can understand any JSON structure - that is the whole point. It is just a  directed acyclic graph (DAG) with node tags (key/value pairs), which is a near universal data structure.This only annotation required might be \"//These are DAG tags\". The key names can be as informative as required, allowing arbitrary semantic arity.Any platform can parse JSON with just a few lines of code. XML requires complex OO libraries that are not viable on many platforms.Annotations would just make JSON less interoperable. There is simply nothing else to add unless what you really need is a markup language (XML), and don't care if your persisted data is easily parsed.BUT as the creator of JSON also observed, there has always been JS pipeline support for comments:Go ahead and insert all the comments you like.\nThen pipe it through JSMin before handing it to your JSON parser. - Douglas Crockford, 2012",
                "If you are using the Newtonsoft.Json library with ASP.NET to read/deserialize you can use comments in the JSON content://\"name\": \"string\"//\"id\": intor/* This is acomment example */PS: Single-line comments are only supported with 6+ versions of Newtonsoft Json.Additional note for people who can't think out of the box: I use the JSON format for basic settings in an ASP.NET web application I made. I read the file, convert it into the settings object with the Newtonsoft library and use it when necessary.I prefer writing comments about each individual setting in the JSON file itself, and I really don't care about the integrity of the JSON format as long as the library I use is OK with it.I think this is an 'easier to use/understand' way than creating a separate 'settings.README' file and explaining the settings in it.If you have a problem with this kind of usage; sorry, the genie is out of the lamp. People would find other usages for JSON format, and there is nothing you can do about it.",
                "If your text file, which is a JSON string, is going to be read by some program, how difficult would it be to strip out either C or C++ style comments before using it?Answer: It would be a one liner. If you do that then JSON files could be used as configuration files.",
                "The idea behind JSON is to provide simple data exchange between applications. These are typically web based and the language is JavaScript.It doesn't really allow for comments as such, however, passing a comment as one of the name/value pairs in the data would certainly work, although that data would obviously need to be ignored or handled specifically by the parsing code.All that said, it's not the intention that the JSON file should contain comments in the traditional sense. It should just be the data.Have a look at the JSON website for more detail.",
                "JSON does not support comments natively, but you can make your own decoder or at least preprocessor to strip out comments, that's perfectly fine (as long as you just ignore comments and don't use them to guide how your application should process the JSON data).JSON does not have comments. A JSON encoder MUST NOT output comments.\nA JSON decoder MAY accept and ignore comments.Comments should never be used to transmit anything meaningful. That is\nwhat JSON is for.Cf: Douglas Crockford, author of JSON spec.",
                "I just encountering this for configuration files. I don't want to use XML (verbose, graphically, ugly, hard to read), or \"ini\" format (no hierarchy, no real standard, etc.) or Java \"Properties\" format (like .ini).JSON can do all they can do, but it is way less verbose and more human readable - and parsers are easy and ubiquitous in many languages. It's just a tree of data. But out-of-band comments are a necessity often to document \"default\" configurations and the like. Configurations are never to be \"full documents\", but trees of saved data that can be human readable when needed.I guess one could use \"#\": \"comment\", for \"valid\" JSON.",
                "It depends on your JSON library. Json.NET supports JavaScript-style comments, /* commment */.See another Stack\u00a0Overflow question.",
                "Yes, the new standard, JSON5 allows the C++ style comments, among many other extensions:The JSON5 Data Interchange Format (JSON5) is a superset of JSON that aims to alleviate some of the limitations of JSON. It is fully backwards compatible, and using it is probably better than writing the custom non standard parser, turning non standard features on for the existing one or using various hacks like string fields for commenting. Or, if the parser in use supports, simply agree we are using JSON 5 subset that is JSON and C++ style comments. It is much better than we tweak JSON standard the way we see fit.There is already npm package, Python package, Java package and C library available. It is backwards compatible. I see no reason to stay with the \"official\" JSON restrictions.I think that removing comments from JSON has been driven by the same reasons as removing the operator overloading in Java: can be used the wrong way yet some clearly legitimate use cases were overlooked. For operator overloading, it is matrix algebra and complex numbers. For JSON comments, its is configuration files and other documents that may be written, edited or read by humans and not just by parser.",
                "JSON makes a lot of sense for config files and other local usage because it's ubiquitous and because it's much simpler than XML.If people have strong reasons against having comments in JSON when communicating data (whether valid or not), then possibly JSON could be split into two:JSON-DOC will allow comments, and other minor differences might exist such as handling whitespace. Parsers can easily convert from one spec to the other.With regards to the remark made by Douglas Crockford on this issues (referenced by @Artur Czajka)Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser.We're talking about a generic config file issue (cross language/platform), and he's answering with a JS specific utility!Sure a JSON specific minify can be implemented in any language,\nbut standardize this so it becomes ubiquitous across parsers in all languages and platforms so people stop wasting their time lacking the feature because they have good use-cases for it, looking the issue up in online forums, and getting people telling them it's a bad idea or suggesting it's easy to implement stripping comments out of text files.The other issue is interoperability. Suppose you have a library or API or any kind of subsystem which has some config or data files associated with it. And this subsystem is\nto be accessed from different languages.  Then do you go about telling people: by the way\ndon't forget to strip out the comments from the JSON files before passing them to the parser!",
                "If you use JSON5 you can include comments.JSON5 is a proposed extension to JSON that aims to make it easier for humans to write and maintain by hand. It does this by adding some minimal syntax features directly from ECMAScript\u00a05.",
                "The Dojo Toolkit JavaScript toolkit (at least as of version 1.4), allows you to include comments in your JSON. The comments can be of /* */ format. Dojo Toolkit consumes the JSON via the dojo.xhrGet() call.Other JavaScript toolkits may work similarly.This can be helpful when experimenting with alternate data structures (or even data lists) before choosing a final option.",
                "JSON is not a framed protocol. It is a language free format. So a comment's format is not defined for JSON.As many people have suggested, there are some tricks, for example, duplicate keys or a specific key _comment that you can use. It's up to you.",
                "Disclaimer: This is sillyThere is actually a way to add comments, and stay within the specification (no additional parser needed). It will not result into human-readable comments without any sort of parsing though.You could abuse the following:Insignificant whitespace is allowed before or after any token.\nWhitespace is any sequence of one or more of the following code\npoints: character tabulation (U+0009), line feed (U+000A), carriage\nreturn (U+000D), and space (U+0020).In a hacky way, you can abuse this to add a comment. For instance: start and end your comment with a tab. Encode the comment in base3 and use the other whitespace characters to represent them. For instance.(hello base three in ASCII) But instead of 0 use space, for 1 use line feed and for 2 use carriage return.This will just leave you with a lot of unreadable whitespace (unless you make an IDE plugin to encode/decode it on the fly).I never even tried this, for obvious reasons and neither should you.",
                "You can have comments in JSONP, but not in pure JSON. I've just spent an hour trying to make my program work with this example from Highcharts.If you follow the link, you will seeSince I had a similar file in my local folder, there were no issues with the Same-origin policy, so I decided to use pure JSON\u2026 and, of course, $.getJSON was failing silently because of the comments.Eventually I just sent a manual HTTP request to the address above and realized that the content-type was text/javascript since, well, JSONP returns pure JavaScript. In this case comments are allowed. But my application returned content-type application/json, so I had to remove the comments.",
                "JSON doesn't allow comments, per se. The reasoning is utterly foolish, because you can use JSON itself to create comments, which obviates the reasoning entirely, and loads the parser data space for no good reason at all for exactly the same result and potential issues, such as they are: a JSON file with comments.If you try to put comments in (using // or /* */ or # for instance), then some parsers will fail because this is strictly not\nwithin the JSON specification. So you should never do that.Here, for instance, where my image manipulation system has saved image notations and some basic formatted (comment) information relating to them (at the bottom):",
                "This is a \"can you\" question. And here is a \"yes\" answer.No, you shouldn't use duplicative object members to stuff side channel data into a JSON encoding. (See \"The names within an object SHOULD be unique\" in the RFC).And yes, you could insert comments around the JSON, which you could parse out.But if you want a way of inserting and extracting arbitrary side-channel data to a valid JSON, here is an answer. We take advantage of the non-unique representation of data in a JSON encoding. This is allowed* in section two of the RFC under \"whitespace is allowed before or after any of the six structural characters\".*The RFC only states \"whitespace is allowed before or after any of the six structural characters\", not explicitly mentioning strings, numbers, \"false\", \"true\", and \"null\". This omission is ignored in ALL implementations.First, canonicalize your JSON by minifying it:Then encode your comment in binary:Then steg your binary:Here is your output:",
                "In my case, I need to use comments for debug purposes just before the output of the JSON. So I put the debug information in the HTTP header, to avoid breaking the client:",
                "We are using strip-json-comments for our project. It supports something like:Simply npm install --save strip-json-comments to install and use it like:"
            ]
        },
        {
            "tag": "",
            "question": [
                "What and where are the stack and heap?",
                "What are the stack and heap?\nWhere are they located physically in a computer's memory?\nTo what extent are they controlled by the OS or language run-time?\nWhat is their scope?\nWhat determines their ..."
            ],
            "url": "https://stackoverflow.com/questions/79923",
            "answer": [
                "The stack is the memory set aside as scratch space for a thread of execution.  When a function is called, a block is reserved on the top of the stack for local variables and some bookkeeping data.  When that function returns, the block becomes unused and can be used the next time a function is called.  The stack is always reserved in a LIFO (last in first out) order; the most recently reserved block is always the next block to be freed.  This makes it really simple to keep track of the stack; freeing a block from the stack is nothing more than adjusting one pointer.The heap is memory set aside for dynamic allocation.  Unlike the stack, there's no enforced pattern to the allocation and deallocation of blocks from the heap; you can allocate a block at any time and free it at any time.  This makes it much more complex to keep track of which parts of the heap are allocated or free at any given time; there are many custom heap allocators available to tune heap performance for different usage patterns.Each thread gets a stack, while there's typically only one heap for the application (although it isn't uncommon to have multiple heaps for different types of allocation).To answer your questions directly:To what extent are they controlled by the OS or language runtime?The OS allocates the stack for each system-level thread when the thread is created.  Typically the OS is called by the language runtime to allocate the heap for the application.What is their scope?The stack is attached to a thread, so when the thread exits the stack is reclaimed.  The heap is typically allocated at application startup by the runtime, and is reclaimed when the application (technically process) exits.What determines the size of each of them?The size of the stack is set when a thread is created.  The size of the heap is set on application startup, but can grow as space is needed (the allocator requests more memory from the operating system).What makes one faster?The stack is faster because the access pattern makes it trivial to allocate and deallocate memory from it (a pointer/integer is simply incremented or decremented), while the heap has much more complex bookkeeping involved in an allocation or deallocation.  Also, each byte in the stack tends to be reused very frequently which means it tends to be mapped to the processor's cache, making it very fast. Another performance hit for the heap is that the heap, being mostly a global resource, typically has to be multi-threading safe, i.e. each allocation and deallocation needs to be - typically - synchronized with \"all\" other heap accesses in the program.A clear demonstration:\n\nImage source: vikashazrati.wordpress.com",
                "Stack:Heap:Example:",
                "The most important point is that heap and stack are generic terms for ways in which memory can be allocated.  They can be implemented in many different ways, and the terms apply to the basic concepts.In a stack of items, items sit one on top of the other in the order they were placed there, and you can only remove the top one (without toppling the whole thing over).The simplicity of a stack is that you do not need to maintain a table containing a record of each section of allocated memory; the only state information you need is a single pointer to the end of the stack.  To allocate and de-allocate, you just increment and decrement that single pointer.  Note: a stack can sometimes be implemented to start at the top of a section of memory and extend downwards rather than growing upwards.In a heap, there is no particular order to the way items are placed.  You can reach in and remove items in any order because there is no clear 'top' item.Heap allocation requires maintaining a full record of what memory is allocated and what isn't, as well as some overhead maintenance to reduce fragmentation, find contiguous memory segments big enough to fit the requested size, and so on.  Memory can be deallocated at any time leaving free space.  Sometimes a memory allocator will perform maintenance tasks such as defragmenting memory by moving allocated memory around, or garbage collecting - identifying at runtime when memory is no longer in scope and deallocating it.These images should do a fairly good job of describing the two ways of allocating and freeing memory in a stack and a heap.  Yum!To what extent are they controlled by the OS or language runtime?As mentioned, heap and stack are general terms, and can be implemented in many ways.  Computer programs typically have a stack called a call stack which stores information relevant to the current function such as a pointer to whichever function it was called from, and any local variables.  Because functions call other functions and then return, the stack grows and shrinks to hold information from the functions further down the call stack.  A program doesn't really have runtime control over it; it's determined by the programming language, OS and even the system architecture.A heap is a general term used for any memory that is allocated dynamically and randomly; i.e. out of order.  The memory is typically allocated by the OS, with the application calling API functions to do this allocation.  There is a fair bit of overhead required in managing dynamically allocated memory, which is usually handled by the runtime code of the programming language or environment used.What is their scope?The call stack is such a low level concept that it doesn't relate to 'scope' in the sense of programming.  If you disassemble some code you'll see relative pointer style references to portions of the stack, but as far as a higher level language is concerned, the language imposes its own rules of scope.  One important aspect of a stack, however, is that once a function returns, anything local to that function is immediately freed from the stack.  That works the way you'd expect it to work given how your programming languages work.  In a heap, it's also difficult to define.  The scope is whatever is exposed by the OS, but your programming language probably adds its rules about what a \"scope\" is in your application.  The processor architecture and the OS use virtual addressing, which the processor translates to physical addresses and there are page faults, etc.  They keep track of what pages belong to which applications.  You never really need to worry about this, though, because you just use whatever method your programming language uses to allocate and free memory, and check for errors (if the allocation/freeing fails for any reason).What determines the size of each of them?Again, it depends on the language, compiler, operating system and architecture.  A stack is usually pre-allocated, because by definition it must be contiguous memory.  The language compiler or the OS determine its size.  You don't store huge chunks of data on the stack, so it'll be big enough that it should never be fully used, except in cases of unwanted endless recursion (hence, \"stack overflow\") or other unusual programming decisions.A heap is a general term for anything that can be dynamically allocated.  Depending on which way you look at it, it is constantly changing size.  In modern processors and operating systems the exact way it works is very abstracted anyway, so you don't normally need to worry much about how it works deep down, except that (in languages where it lets you) you mustn't use memory that you haven't allocated yet or memory that you have freed.What makes one faster?The stack is faster because all free memory is always contiguous.  No list needs to be maintained of all the segments of free memory, just a single pointer to the current top of the stack.  Compilers usually store this pointer in a special, fast register for this purpose.  What's more, subsequent operations on a stack are usually concentrated within very nearby areas of memory, which at a very low level is good for optimization by the processor on-die caches.",
                "(I have moved this answer from another question that was more or less a dupe of this one.)The answer to your question is implementation specific and may vary across compilers and processor architectures. However, here is a simplified explanation.Can a function be allocated on the heap instead of a stack?No, activation records for functions (i.e. local or automatic variables) are allocated on the stack that is used not only to store these variables, but also to keep track of nested function calls.How the heap is managed is really up to the runtime environment. C uses malloc and C++ uses new, but many other languages have garbage collection.However, the stack is a more low-level feature closely tied to the processor architecture. Growing the heap when there is not enough space isn't too hard since it can be implemented in the library call that handles the heap. However, growing the stack is often impossible as the stack overflow only is discovered when it is too late; and shutting down the thread of execution is the only viable option.",
                "In the following C# codeHere's how the memory is managedLocal Variables that only need to last as long as the function invocation go in the stack. The heap is used for variables whose lifetime we don't really know up front but we expect them to last a while. In most languages it's critical that we know at compile time how large a variable is if we want to store it on the stack.Objects (which vary in size as we update them) go on the heap because we don't know at creation time how long they are going to last. In many languages the heap is garbage collected to find objects (such as the cls1 object) that no longer have any references.In Java, most objects go directly into the heap. In languages like C / C++, structs and classes can often remain on the stack when you're not dealing with pointers.More information can be found here:The difference between stack and heap memory allocation \u00ab  timmurphy.organd here:Creating Objects on the Stack and HeapThis article is the source of picture above: Six important .NET concepts: Stack, heap, value types, reference types, boxing, and unboxing - CodeProjectbut be aware it may contain some inaccuracies.",
                "The Stack\nWhen you call a function the arguments to that function plus some other overhead is put on the stack. Some info (such as where to go on return) is also stored there.\nWhen you declare a variable inside your function, that variable is also allocated on the stack.Deallocating the stack is pretty simple because you always deallocate in the reverse order in which you allocate. Stack stuff is added as you enter functions, the corresponding data is removed as you exit them. This means that you tend to stay within a small region of the stack unless you call lots of functions that call lots of other functions (or create a recursive solution).The Heap\nThe heap is a generic name for where you put the data that you create on the fly. If you don't know how many spaceships your program is going to create, you are likely to use the new (or malloc or equivalent) operator to create each spaceship. This allocation is going to stick around for a while, so it is likely we will free things in a different order than we created them.Thus, the heap is far more complex, because there end up being regions of memory that are unused interleaved with chunks that are - memory gets fragmented. Finding free memory of the size you need is a difficult problem. This is why the heap should be avoided (though it is still often used).Implementation\nImplementation of both the stack and heap is usually down to the runtime / OS. Often games and other applications that are performance critical create their own memory solutions that grab a large chunk of memory from the heap and then dish it out internally to avoid relying on the OS for memory.This is only practical if your memory usage is quite different from the norm - i.e for games where you load a level in one huge operation and can chuck the whole lot away in another huge operation.Physical location in memory\nThis is less relevant than you think because of a technology called Virtual Memory which makes your program think that you have access to a certain address where the physical data is somewhere else (even on the hard disc!). The addresses you get for the stack are in increasing order as your call tree gets deeper. The addresses for the heap are un-predictable (i.e implimentation specific) and frankly not important.",
                "Other answers just avoid explaining what static allocation means. So I will explain the three main forms of allocation and how they usually relate to the heap, stack, and data segment below. I also will show some examples in both C/C++ and Python to help people understand.\"Static\" (AKA statically allocated) variables are not allocated on the stack. Do not assume so - many people do only because \"static\" sounds a lot like \"stack\". They actually exist in neither the stack nor the heap. They are part of what's called the data segment.However, it is generally better to consider \"scope\" and \"lifetime\" rather than \"stack\" and \"heap\".Scope refers to what parts of the code can access a variable. Generally we think of local scope (can only be accessed by the current function) versus global scope (can be accessed anywhere) although scope can get much more complex.Lifetime refers to when a variable is allocated and deallocated during program execution. Usually we think of static allocation (variable will persist through the entire duration of the program, making it useful for storing the same information across several function calls) versus automatic allocation (variable only persists during a single call to a function, making it useful for storing information that is only used during your function and can be discarded once you are done) versus dynamic allocation (variables whose duration is defined at runtime, instead of compile time like static or automatic).Although most compilers and interpreters implement this behavior similarly in terms of using stacks, heaps, etc, a compiler may sometimes break these conventions if it wants as long as behavior is correct. For instance, due to optimization a local variable may only exist in a register or be removed entirely, even though most local variables exist in the stack. As has been pointed out in a few comments, you are free to implement a compiler that doesn't even use a stack or a heap, but instead some other storage mechanisms (rarely done, since stacks and heaps are great for this).I will provide some simple annotated C code to illustrate all of this. The best way to learn is to run a program under a debugger and watch the behavior. If you prefer to read python, skip to the end of the answer :)A particularly poignant example of why it's important to distinguish between lifetime and scope is that a variable can have local scope but static lifetime - for instance, \"someLocalStaticVariable\" in the code sample above. Such variables can make our common but informal naming habits very confusing. For instance when we say \"local\" we usually mean \"locally scoped automatically allocated variable\" and when we say global we usually mean \"globally scoped statically allocated variable\". Unfortunately when it comes to things like \"file scoped statically allocated variables\" many people just say... \"huh???\".Some of the syntax choices in C/C++ exacerbate this problem - for instance many people think global variables are not \"static\" because of the syntax shown below.Note that putting the keyword \"static\" in the declaration above prevents var2 from having global scope. Nevertheless, the global var1 has static allocation. This is not intuitive! For this reason, I try to never use the word \"static\" when describing scope, and instead say something like \"file\" or \"file limited\" scope. However many people use the phrase \"static\" or \"static scope\" to describe a variable that can only be accessed from one code file. In the context of lifetime, \"static\" always means the variable is allocated at program start and deallocated when program exits.Some people think of these concepts as C/C++ specific. They are not. For instance, the Python sample below illustrates all three types of allocation (there are some subtle differences possible in interpreted languages that I won't get into here).",
                "Others have answered the broad strokes pretty well, so I'll throw in a few details.Stack and heap need not be singular. A common situation in which you have more than one stack is if you have more than one thread in a process.  In this case each thread has its own stack. You can also have more than one heap, for example some DLL configurations can result in different DLLs allocating from different heaps, which is why it's generally a bad idea to release memory allocated by a different library.In C you can get the benefit of variable length allocation through the use of alloca, which allocates on the stack, as opposed to alloc, which allocates on the heap. This memory won't survive your return statement, but it's useful for a scratch buffer.Making a huge temporary buffer on Windows that you don't use much of is not free. This is because the compiler will generate a stack probe loop that is called every time your function is entered to make sure the stack exists (because Windows uses a single guard page at the end of your stack to detect when it needs to grow the stack. If you access memory more than one page off the end of the stack you will crash). Example:",
                "Others have directly answered your question, but when trying to understand the stack and the heap, I think it is helpful to consider the memory layout of a traditional UNIX process (without threads and mmap()-based allocators). The Memory Management Glossary web page has a diagram of this memory layout.The stack and heap are traditionally located at opposite ends of the process's virtual address space. The stack grows automatically when accessed, up to a size set by the kernel (which can be adjusted with setrlimit(RLIMIT_STACK, ...)). The heap grows when the memory allocator invokes the brk() or sbrk() system call, mapping more pages of physical memory into the process's virtual address space.In systems without virtual memory, such as some embedded systems, the same basic layout often applies, except the stack and heap are fixed in size. However, in other embedded systems (such as those based on Microchip PIC microcontrollers), the program stack is a separate block of memory that is not addressable by data movement instructions, and can only be modified or read indirectly through program flow instructions (call, return, etc.). Other architectures, such as Intel Itanium processors, have multiple stacks. In this sense, the stack is an element of the CPU architecture.",
                "What is a stack?A stack is a pile of objects, typically one that is neatly arranged.Stacks in computing architectures are regions of memory where data is added or removed in a last-in-first-out manner. \nIn a multi-threaded application, each thread will have its own stack.What is a heap?A heap is an untidy collection of things piled up haphazardly.In computing architectures the heap is an area of dynamically-allocated memory that is managed automatically by the operating system or the memory manager library. \nMemory on the heap is allocated, deallocated, and resized regularly during program execution, and this can lead to a problem called fragmentation. \nFragmentation occurs when memory objects are allocated with small spaces in between that are too small to hold additional memory objects. \nThe net result is a percentage of the heap space that is not usable for further memory allocations.Both togetherIn a multi-threaded application, each thread will have its own stack. But, all the different threads will share the heap. \nBecause the different threads share the heap in a multi-threaded application, this also means that there has to be some coordination between the threads so that they don\u2019t try to access and manipulate the same piece(s) of memory in the heap at the same time.Which is faster \u2013 the stack or the heap? And why?The stack is much faster than the heap. \nThis is because of the way that memory is allocated on the stack. \nAllocating memory on the stack is as simple as moving the stack pointer up.For people new to programming, it\u2019s probably a good idea to use the stack since it\u2019s easier. \nBecause the stack is small, you would want to use it when you know exactly how much memory you will need for your data, or if you know the size of your data is very small. \nIt\u2019s better to use the heap when you know that you will need a lot of memory for your data, or you just are not sure how much memory you will need (like with a dynamic array).The stack is the area of memory where local variables (including method parameters) are stored. When it comes to object variables, these are merely references (pointers) to the actual objects on the heap.\nEvery time an object is instantiated, a chunk of heap memory is set aside to hold the data (state) of that object. Since objects can contain other objects, some of this data can in fact hold references to those nested objects.",
                "The stack is a portion of memory that can be manipulated via several key assembly language instructions, such as 'pop' (remove and return a value from the stack) and 'push' (push a value to the stack), but also call (call a subroutine - this pushes the address to return to the stack) and return (return from a subroutine - this pops the address off of the stack and jumps to it).  It's the region of memory below the stack pointer register, which can be set as needed.  The stack is also used for passing arguments to subroutines, and also for preserving the values in registers before calling subroutines.The heap is a portion of memory that is given to an application by the operating system, typically through a syscall like malloc.  On modern OSes this memory is a set of pages that only the calling process has access to.The size of the stack is determined at runtime, and generally does not grow after the program launches.  In a C program, the stack needs to be large enough to hold every variable declared within each function.  The heap will grow dynamically as needed, but the OS is ultimately making the call (it will often grow the heap by more than the value requested by malloc, so that at least some future mallocs won't need to go back to the kernel to get more memory.  This behavior is often customizable)Because you've allocated the stack before launching the program, you never need to malloc before you can use the stack, so that's a slight advantage there.  In practice, it's very hard to predict what will be fast and what will be slow in modern operating systems that have virtual memory subsystems, because how the pages are implemented and where they are stored is an implementation detail.",
                "I think many other people have given you mostly correct answers on this matter.One detail that has been missed, however, is that the \"heap\" should in fact probably be called the \"free store\".  The reason for this distinction is that the original free store was implemented with a data structure known as a \"binomial heap.\"  For that reason, allocating from early implementations of malloc()/free() was allocation from a heap.  However, in this modern day, most free stores are implemented with very elaborate data structures that are not binomial heaps.",
                "You can do some interesting things with the stack.  For instance, you have functions like alloca (assuming you can get past the copious warnings concerning its use), which is a form of malloc that specifically uses the stack, not the heap, for memory.That said, stack-based memory errors are some of the worst I've experienced.  If you use heap memory, and you overstep the bounds of your allocated block, you have a decent chance of triggering a segment fault.  (Not 100%: your block may be incidentally contiguous with another that you have previously allocated.)  But since variables created on the stack are always contiguous with each other, writing out of bounds can change the value of another variable.  I have learned that whenever I feel that my program has stopped obeying the laws of logic, it is probably buffer overflow.",
                "Simply, the stack is where local variables get created. Also, every time you call a subroutine the program counter (pointer to the next machine instruction) and any important registers, and sometimes the parameters get pushed on the stack. Then any local variables inside the subroutine are pushed onto the stack (and used from there). When the subroutine finishes, that stuff all gets popped back off the stack. The PC and register data gets and put back where it was as it is popped, so your program can go on its merry way.The heap is the area of memory dynamic memory allocations are made out of (explicit \"new\" or \"allocate\" calls). It is a special data structure that can keep track of blocks of memory of varying sizes and their allocation status.In \"classic\" systems RAM was laid out such that the stack pointer started out at the bottom of memory, the heap pointer started out at the top, and they grew towards each other. If they overlap, you are out of RAM. That doesn't work with modern multi-threaded OSes though. Every thread has to have its own stack, and those can get created dynamicly.",
                "From WikiAnwser.When a function or a method calls another function which in turns calls another function, etc., the execution of all those functions remains suspended until the very last function returns its value.This chain of suspended function calls is the stack, because elements in the stack (function calls) depend on each other.The stack is important to consider in exception handling and thread executions.The heap is simply the memory used by programs to store variables.\nElement of the heap (variables) have no dependencies with each other and can always be accessed randomly at any time.",
                "StackHeap",
                "A stack is used for static memory allocation and a heap for dynamic memory allocation, both stored in the computer's RAM.The StackThe stack is a \"LIFO\" (last in, first out) data structure, that is managed and optimized by the CPU quite closely. Every time a function declares a new variable, it is \"pushed\" onto the stack. Then every time a function exits, all of the variables pushed onto the stack by that function, are freed (that is to say, they are deleted). Once a stack variable is freed, that region of memory becomes available for other stack variables.The advantage of using the stack to store variables, is that memory is managed for you. You don't have to allocate memory by hand, or free it once you don't need it any more. What's more, because the CPU organizes stack memory so efficiently, reading from and writing to stack variables is very fast.More can be found here.The HeapThe heap is a region of your computer's memory that is not managed automatically for you, and is not as tightly managed by the CPU. It is a more free-floating region of memory (and is larger). To allocate memory on the heap, you must use malloc() or calloc(), which are built-in C functions. Once you have allocated memory on the heap, you are responsible for using free() to deallocate that memory once you don't need it any more.If you fail to do this, your program will have what is known as a memory leak. That is, memory on the heap will still be set aside (and won't be available to other processes). As we will see in the debugging section, there is a tool called Valgrind that can help you detect memory leaks.Unlike the stack, the heap does not have size restrictions on variable size (apart from the obvious physical limitations of your computer). Heap memory is slightly slower to be read from and written to, because one has to use pointers to access memory on the heap. We will talk about pointers shortly.Unlike the stack, variables created on the heap are accessible by any function, anywhere in your program. Heap variables are essentially global in scope.More can be found here.Variables allocated on the stack are stored directly to the memory and access to this memory is very fast, and its allocation is dealt with when the program is compiled. When a function or a method calls another function which in turns calls another function, etc., the execution of all those functions remains suspended until the very last function returns its value. The stack is always reserved in a LIFO order, the most recently reserved block is always the next block to be freed. This makes it really simple to keep track of the stack, freeing a block from the stack is nothing more than adjusting one pointer.Variables allocated on the heap have their memory allocated at run time and accessing this memory is a bit slower, but the heap size is only limited by the size of virtual memory. Elements of the heap have no dependencies with each other and can always be accessed randomly at any time. You can allocate a block at any time and free it at any time. This makes it much more complex to keep track of which parts of the heap are allocated or free at any given time.You can use the stack if you know exactly how much data you need to allocate before compile time, and it is not too big. You can use the heap if you don't know exactly how much data you will need at runtime or if you need to allocate a lot of data.In a multi-threaded situation each thread will have its own completely independent stack, but they will share the heap. The stack is thread specific and the heap is application specific. The stack is important to consider in exception handling and thread executions.Each thread gets a stack, while there's typically only one heap for the application (although it isn't uncommon to have multiple heaps for different types of allocation).At run-time, if the application needs more heap, it can allocate memory from free memory and if the stack needs memory, it can allocate memory from free memory allocated memory for the application.Even, more detail is given here and here.Now come to your question's answers.To what extent are they controlled by the OS or language runtime?The OS allocates the stack for each system-level thread when the thread is created. Typically the OS is called by the language runtime to allocate the heap for the application.More can be found here.What is their scope?Already given in top.\"You can use the stack if you know exactly how much data you need to allocate before compile time, and it is not too big. You can use the heap if you don't know exactly how much data you will need at runtime or if you need to allocate a lot of data.\"More can be found in here.What determines the size of each of them?The size of the stack is set by OS when a thread is created. The size of the heap is set on application startup, but it can grow as space is needed (the allocator requests more memory from the operating system).What makes one faster?Stack allocation is much faster since all it really does is move the stack pointer. Using memory pools, you can get comparable performance out of heap allocation, but that comes with a slight added complexity and its own headaches.Also, stack vs. heap is not only a performance consideration; it also tells you a lot about the expected lifetime of objects.Details can be found from here.",
                "OK, simply and in short words, they mean ordered and not ordered...!Stack: In stack items, things get on the top of each-other, means gonna be faster and more efficient to be processed!...So there is always an index to point the specific item, also processing gonna be faster, there is relationship between the items as well!...Heap: No order, processing gonna be slower and values are messed up together with no specific order or index... there are random and there is no relationship between them... so execution and usage time could be vary...I also create the image below to show how they may look like:",
                "stack, heap and data of each process in virtual memory:",
                "In the 1980s, UNIX propagated like bunnies with big companies rolling their own.\nExxon had one as did dozens of brand names lost to history.\nHow memory was laid out was at the discretion of the many implementors.A typical C program was laid out flat in memory with\nan opportunity to increase by changing the brk() value.\nTypically, the HEAP was just below this brk value\nand increasing brk increased the amount of available heap.The single STACK was typically an area below HEAP which was a tract of memory\ncontaining nothing of value until the top of the next fixed block of memory.\nThis next block was often CODE which could be overwritten by stack data\nin one of the famous hacks of its era.One typical memory block was BSS (a block of zero values)\nwhich was accidentally not zeroed in one manufacturer's offering.\nAnother was DATA containing initialized values, including strings and numbers.\nA third was CODE containing CRT (C runtime), main, functions, and libraries.The advent of virtual memory in UNIX changes many of the constraints.\nThere is no objective reason why these blocks need be contiguous,\nor fixed in size, or ordered a particular way now.\nOf course, before UNIX was Multics which didn't suffer from these constraints.\nHere is a schematic showing one of the memory layouts of that era.",
                "A couple of cents: I think, it will be good to draw memory graphical and more simple:Arrows - show where grow stack and heap, process stack size have limit, defined in OS, thread stack size limits by parameters in thread create API usually. Heap usually limiting by process maximum virtual memory size, for 32 bit 2-4\u00a0GB for example.So simple way: process heap is general for process and all threads inside, using for memory allocation in common case with something like malloc().Stack is quick memory for store in common case function return pointers and variables, processed as parameters in function call, local function variables.",
                "Since some answers went nitpicking, I'm going to contribute my mite.Surprisingly, no one has mentioned that multiple (i.e. not related to the number of running OS-level threads) call stacks are to be found not only in exotic languages (PostScript) or platforms (Intel Itanium), but also in fibers, green threads and some implementations of coroutines.Fibers, green threads and coroutines are in many ways similar, which leads to much confusion.  The difference between fibers and green threads is that the former use cooperative multitasking, while the latter may feature either cooperative or preemptive one (or even both). For the distinction between fibers and coroutines, see here.In any case, the purpose of both fibers, green threads and coroutines is having multiple functions executing concurrently, but not in parallel (see this SO question for the distinction) within a single OS-level thread, transferring control back and forth from one another in an organized fashion.When using fibers, green threads or coroutines, you usually have a separate stack per function. (Technically, not just a stack but a whole context of execution is per function. Most importantly, CPU registers.) For every thread there're as many stacks as there're concurrently running functions, and the thread is switching between executing each function according to the logic of your program. When a function runs to its end, its stack is destroyed. So, the number and lifetimes of stacks are dynamic and are not determined by the number of OS-level threads!Note that I said \"usually have a separate stack per function\". There're both stackful and stackless implementations of couroutines. Most notable stackful C++ implementations are Boost.Coroutine and Microsoft PPL's async/await. (However, C++'s resumable functions (a.k.a. \"async and await\"), which were proposed to C++17, are likely to use stackless coroutines.)Fibers proposal to the C++ standard library is forthcoming. Also, there're some third-party libraries. Green threads are extremely popular in languages like Python and Ruby.",
                "I have something to share, although the major points are already covered.StackHeapInteresting note:",
                "Wow! So many answers and I don't think one of them got it right...1) Where and what are they (physically in a real computer's memory)?The stack is memory that begins as the highest memory address allocated to your program image, and it then decrease in value from there. It is reserved for called function parameters and for all temporary variables used in functions.There are two heaps: public and private.The private heap begins on a 16-byte boundary (for 64-bit programs) or a 8-byte boundary (for 32-bit programs) after the last byte of code in your program, and then increases in value from there. It is also called the default heap.If the private heap gets too large it will overlap the stack area, as will the stack overlap the heap if it gets too big. Because the stack starts at a higher address and works its way down to lower address, with proper hacking you can get make the stack so large that it will overrun the private heap area and overlap the code area. The trick then is to overlap enough of the code area that you can hook into the code. It's a little tricky to do and you risk a program crash, but it's easy and very effective.The public heap resides in it's own memory space outside of your program image space. It is this memory that will be siphoned off onto the hard disk if memory resources get scarce.2) To what extent are they controlled by the OS or language runtime?The stack is controlled by the programmer, the private heap is managed by the OS, and the public heap is not controlled by anyone because it is an OS service -- you make requests and either they are granted or denied.2b) What is their scope?They are all global to the program, but their contents can be private, public, or global.2c) What determines the size of each of them?The size of the stack and the private heap are determined by your compiler runtime options. The public heap is initialized at runtime using a size parameter.2d) What makes one faster?They are not designed to be fast, they are designed to be useful. How the programmer utilizes them determines whether they are \"fast\" or \"slow\"REF:https://norasandler.com/2019/02/18/Write-a-Compiler-10.htmlhttps://learn.microsoft.com/en-us/windows/desktop/api/heapapi/nf-heapapi-getprocessheaphttps://learn.microsoft.com/en-us/windows/desktop/api/heapapi/nf-heapapi-heapcreate",
                "A lot of answers are correct as concepts, but we must note that a stack is needed by the hardware (i.e. microprocessor) to allow calling subroutines (CALL in assembly language..). (OOP guys will call it methods)On the stack you save return addresses and call \u2192 push / ret \u2192 pop is managed directly in hardware.You can use the stack to pass parameters.. even if it is slower than using registers (would a microprocessor guru say or a good 1980s BIOS book...)Stack usage is faster as:",
                "Where and what are they (physically in a real computer's memory)?ANSWER: Both are in RAM.ASIDE:RAM is like a desk and HDDs/SSDs (permanent storage) are like bookshelves. To read anything, you must have a book open on your desk, and you can only have as many books open as fit on your desk. To get a book, you pull it from your bookshelf and open it on your desk. To return a book, you close the book on your desk and return it to its bookshelf.Stack and heap are names we give to two ways compilers store different kinds of data in the same place (i.e. in RAM).What is their scope?\nWhat determines the size of each of them?\nWhat makes one faster?ANSWER:The stack is for static (fixed size) dataa. At compile time, the compiler reads the variable types used in your code.i. It allocates a fixed amount of memory for these variables.\nii. This size of this memory cannot grow.b. The memory is contiguous (a single block), so access is sometimes faster than the heapc. An object placed on the stack that grows in memory during runtime beyond the size of the stack causes a stack overflow errorThe heap is for dynamic (changing size) dataa. The amount of memory is limited only by the amount of empty space available in RAM\ni. The amount used can grow or shrink as needed at runtimeb. Since items are allocated on the heap by finding empty space wherever it exists in RAM, data is not always in a contiguous section, which sometimes makes access slower than the stackc. Programmers manually put items on the heap with the new keyword and MUST manually deallocate this memory when they are finished using it.\ni. Code that repeatedly allocates new memory without deallocating it when it is no longer needed leads to a memory leak.ASIDE:The stack and heap were not primarily introduced to improve speed; they were introduced to handle memory overflow. The first concern regarding use of the stack vs. the heap should be whether memory overflow will occur. If an object is intended to grow in size to an unknown amount (like a linked list or an object whose members can hold an arbitrary amount of data), place it on the heap. As far as possible, use the C++ standard library (STL) containers vector, map, and list as they are memory and speed efficient and added to make your life easier (you don't need to worry about memory allocation/deallocation).After getting your code to run, if you find it is running unacceptably slow, then go back and refactor your code and see if it can be programmed more efficiently. It may turn out the problem has nothing to do with the stack or heap directly at all (e.g. use an iterative algorithm instead of a recursive one, look at I/O vs. CPU-bound tasks, perhaps add multithreading or multiprocessing).I say sometimes slower/faster above because the speed of the program might not have anything to do with items being allocated on the stack or heap.To what extent are they controlled by the OS or language run-time?ANSWER:The stack size is determined at compile time by the compiler.The heap size varies during runtime. (The heap works with the OS during runtime to allocate memory.)ASIDE:Below is a little more about control and compile-time vs. runtime operations.Each computer has a unique instruction set architecture (ISA), which are its hardware commands (e.g. \"MOVE\", \"JUMP\", \"ADD\", etc.).An OS is nothing more than a resource manager (controls how/when/ and where to use memory, processors, devices, and information).The ISA of the OS is called the bare machine and the remaining commands are called the extended machine. The kernel is the first layer of the extended machine. It controls things likeWhen we say \"compiler\", we generally mean the compiler, assembler, and linker togetherThe machine code gets passed to the kernel when executed, which determines when it should run and take control, but the machine code itself contains ISA commands for requesting files, requesting memory, etc. So the code issues ISA commands, but everything has to pass by the kernel.",
                "The stack is essentially an easy-to-access memory that simply manages its items \n  as a - well - stack. Only items for which the size is known in advance can go onto the stack. This is the case for numbers, strings, booleans.The heap is a memory for items of which you can\u2019t predetermine the\n  exact size and structure. Since objects and arrays can be mutated and\n  change at runtime, they have to go into the heap.Source: Academind",
                "CPU stack and heap are physically related to how CPU and registers works with memory, how machine-assembly language works, not high-level languages themselves, even if these languages can decide little things.All modern CPUs work with the \"same\" microprocessor theory: they are all based on what's called \"registers\" and some are for \"stack\" to gain performance. All CPUs have stack registers since the beginning and they had been always here, way of talking, as I know. Assembly languages are the same since the beginning, despite variations... up to Microsoft and its Intermediate Language (IL) that changed the paradigm to have a OO virtual machine assembly language. So we'll be able to have some CLI/CIL CPU in the future (one project of MS).CPUs have stack registers to speed up memories access, but they are limited compared to the use of others registers to get full access to all the available memory for the processus. It why we talked about stack and heap allocations.In summary, and in general, the heap is hudge and slow and is for \"global\" instances and objects content, as the stack is little and fast and for \"local\" variables and references (hidden pointers to forget to manage them).So when we use the new keyword in a method, the reference (an int) is created in the stack, but the object and all its content (value-types as well as objects) is created in the heap, if I remember. But local elementary value-types and arrays are created in the stack.The difference in memory access is at the cells referencing level: addressing the heap, the overall memory of the process, requires more complexity in terms of handling CPU registers, than the stack which is \"more\" locally in terms of addressing because the CPU stack register is used as base address, if I remember.It is why when we have very long or infinite recurse calls or loops, we got stack overflow quickly, without freezing the system on modern computers...C# Heap(ing) Vs Stack(ing) In .NETStack vs Heap: Know the DifferenceStatic class memory allocation where it is stored C#What and where are the stack and heap?https://en.wikipedia.org/wiki/Memory_managementhttps://en.wikipedia.org/wiki/Stack_registerAssembly language resources:Assembly Programming TutorialIntel\u00ae 64 and IA-32 Architectures Software Developer Manuals",
                "Thank you for a really good discussion but as a real noob I wonder where instructions are kept? In the BEGINNING scientists were deciding between two architectures (von NEUMANN where everything is considered DATA and HARVARD where an area of memory was reserved for instructions and another for data). Ultimately, we went with the von Neumann design and now everything is considered 'the same'. This made it hard for me when I was learning assembly \nhttps://www.cs.virginia.edu/~evans/cs216/guides/x86.html\nbecause they talk about registers and stack pointers.Everything above talks about DATA. My guess is that since an instruction is a defined thing with a specific memory footprint, it would go on the stack and so all 'those' registers discussed in assembly are on the stack. Of course then came object oriented programming with instructions and data comingled into a structure that was dynamic so now instructions would be kept on the heap as well?",
                "When a process is created then after loading code and data OS setup heap start just after data ends and stack to top of address space based on architectureWhen more heap is required OS will allocate dynamically and heap chunk is always virtually contiguousPlease see brk(), sbrk() and alloca() system call in linux"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I force \"git pull\" to overwrite local files?",
                "How do I force an overwrite of local files on a git pull? My local repository contains a file of the same filename as on the server.\n\nerror: Untracked working tree file 'example.txt' would be ..."
            ],
            "url": "https://stackoverflow.com/questions/1125968",
            "answer": [
                "Any uncommitted local changes to tracked files will be lost.Any local files that are not tracked by Git will not be affected.First, update all origin/<branch> refs to latest:Backup your current branch (e.g. master):Jump to the latest commit on origin/master and checkout those files:git fetch downloads the latest from remote without trying to merge or rebase anything.git reset resets the master branch to what you just fetched. The --hard option changes all the files in your working tree to match the files in origin/master.[*]: It's worth noting that it is possible to maintain current local commits by creating a branch from master before resetting:After this, all of the old commits will be kept in new-branch-to-save-current-commits.Uncommitted changes, however (even staged), will be lost. Make sure to stash and commit anything you need. For that you can run the following:And then to reapply these uncommitted changes:",
                "This will remove all uncommitted changes and then pull:",
                "WARNING: git clean deletes all your untracked files/directories and can't be undone.Sometimes just clean -f does not help. In case you have untracked DIRECTORIES, -d option also needed:WARNING: git clean deletes all your untracked files/directories and can't be undone.Consider using -n (--dry-run) flag first. This will show you what will be deleted without actually deleting anything:Example output:",
                "Like Hedgehog I think the answers are terrible. But though Hedgehog's answer might be better, I don't think it is as elegant as it could be.  The way I found to do this is by using fetch and merge with a defined strategy. Which should make it so that your local changes are preserved as long as they are not one of the files that you are trying to force an overwrite with.-X is an option name, and theirs is the value for that option. You're choosing to use their changes (the other option is ours changes) if there is a conflict.",
                "Instead of doing:I'd advise doing the following:No need to fetch all remotes and branches if you're going to reset to the origin/master branch right?",
                "It looks like the best way is to first do:To delete all untracked files and then continue with the usual git pull...",
                "Warning, doing this will permanently delete your files if you have any directory/* entries in your gitignore file.Some answers seem to be terrible. Terrible in the sense of what happened to @Lauri by following David Avsajanishvili suggestion.Rather (git > v1.7.6):Later you can clean the stash history.Manually, one-by-one:Brutally, all-at-once:Of course if you want to go back to what you stashed:",
                "You might find this command helpful to throw away local changes:And then do a cleanup (removes untracked files from the working tree):If you want to remove untracked directories in addition to untracked files:",
                "Instead of merging with git pull, try this:git fetch --allfollowed by:git reset --hard origin/master.",
                "The only thing that worked for me was:This will take you back five commits and then withI found that by looking up how to undo a Git merge.",
                "The problem with all these solutions is that they are all either too complex or, an even bigger problem, is that they remove all untracked files from the webserver, which we don't want since there are always needed configuration files which are on the server and not in the Git repository.Here is the cleanest solution which we are using:The first command fetches the newest data.The second command checks if there are any files that are being added to the repository and deletes those untracked files from the local repository which would cause conflicts.The third command checks-out all the files which were locally modified.Finally, we do a pull to update to the newest version, but this time without any conflicts, since untracked files which are in the repo don't exist anymore and all the locally modified files are already the same as in the repository.",
                "First of all, try the standard way:Warning: Above commands can results in data/files loss only if you don't have them committed! If you're not sure, make the backup first of your whole repository folder.Then pull it again.If above won't help and you don't care about your untracked files/directories (make the backup first just in case), try the following simple steps:This will REMOVE all git files (excempt .git/ dir, where you have all commits) and pull it again.Why git reset HEAD --hard could fail in some cases?Custom rules in .gitattributes fileHaving eol=lf rule in .gitattributes could cause git to modify some file changes by converting CRLF line-endings into LF in some text files.If that's the case, you've to commit these CRLF/LF changes (by reviewing them in git status), or try: git config core.autcrlf false to temporary ignore them.File system incompabilityWhen you're using file-system which doesn't support permission attributes.\nIn example you have two repositories, one on Linux/Mac (ext3/hfs+) and another one on FAT32/NTFS based file-system.As you notice, there are two different kind of file systems, so the one which doesn't support Unix permissions basically can't reset file permissions on system which doesn't support that kind of permissions, so no matter how --hard you try, git always detect some \"changes\".",
                "I had the same problem. No one gave me this solution, but it worked for me.I solved it by:Now it works.",
                "In speaking of pull/fetch/merge in the previous answers, I would like to share an interesting and productive trick,This above command is the most useful command in my Git life which saved a lot of time.Before pushing your newly commit to server, try this command and it will automatically synchronise the latest server changes (with a fetch + merge) and will place your commit at the top in the Git log. There isn't any need to worry about manual pull/merge.Find details in What does \"git pull --rebase\" do?.",
                "Here is a generic solution if you do not always want to paste the branch name or you want to automate this within a scriptIf you want to reset your local changes too:You also could add a bash alias using this command:",
                "I had a similar problem.  I had to do this:",
                "I summarized other answers. You can execute git pull without errors:Warning: This script is very powerful, so you could lose your changes.",
                "Based on my own similar experiences, the solution offered by Strahinja Kustudic above is by far the best.  As others have pointed out, simply doing hard reset will remove all the untracked files which could include lots of things that you don't want removed, such as config files.  What is safer, is to remove only the files that are about to be added, and for that matter, you'd likely also want to checkout any locally-modified files that are about to be updated.That in mind, I updated Kustudic's script to do just that.  I also fixed a typo (a missing ' in the original).",
                "I had the same problem and for some reason, even a git clean -f -d would not do it. Here is why: For some reason, if your file is ignored by Git (via a .gitignore entry, I assume), it still bothers about overwriting this with a later pull, but a clean will not remove it, unless you add -x.",
                "I believe there are two possible causes of conflict, which must be solved separately, and as far as I can tell none of the above answers deals with both:Local files that are untracked need to be deleted, either manually (safer) or as suggested in other answers, by git clean -f -dLocal commits that are not on the remote branch need to be deleted as well. IMO the easiest way to achieve this is with: git reset --hard origin/master (replace 'master' by whatever branch you are working on, and run a git fetch origin first)",
                "It seems like most answers here are focused on the master branch; however, there are times when I'm working on the same feature branch in two different places and I want a rebase in one to be reflected in the other without a lot of jumping through hoops.Based on a combination of RNA's answer and torek's answer to a similar question, I've come up with this which works splendidly:Run this from a branch and it'll only reset your local branch to the upstream version.This can be nicely put into a git alias (git forcepull) as well:git config alias.forcepull \"!git fetch ; git reset --hard @{u}\"Or, in your .gitconfig file:Enjoy!",
                "An easier way would be to:This will override your local file with the file on git",
                "I just solved this myself by:where the last command gives a list of what your local changes were. Keep modifying the \"tmp\" branch until it is acceptable and then merge back onto master with:For next time, you can probably handle this in a cleaner way by looking up \"git stash branch\" though stash is likely to cause you trouble on the first few tries, so do first experiment on a non-critical project...",
                "I have a strange situation that neither git clean or git reset works. I have to remove the conflicting file from git index by using the following script on every untracked file:Then I am able to pull just fine.",
                "I know of a much easier and less painful method:That's it!",
                "I am not sure why anyone did not talk about FETCH_HEAD yet.If you want to put it in an alias, the command would be:",
                "Requirements:Solution:Fetch with a clean of files and directories ignoring .gitignore and hard reset to origin.",
                "Just doSo you avoid all unwanted side effects, like deleting files or directories you wanted to keep, etc.",
                "Despite the original question, the top answers can cause problems for people who have a similar problem, but don't want to lose their local files. For example, see Al-Punk and crizCraig's comments.The following version commits your local changes to a temporary branch (tmp), checks out the original branch (which I'm assuming is master) and merges the updates. You could do this with stash, but I've found it's usually easier to simply use the branch / merge approach.where we assume the other repository is origin master.",
                "Reset the index and the head to origin/master, but do not reset the working tree:"
            ]
        },
        {
            "tag": "",
            "question": [
                "Why does HTML think \u201cchucknorris\u201d is a color?",
                "Why do certain random strings produce colors when entered as background colors in HTML?\nFor example, bgcolor=\"chucknorris\" produces a red background:\n\r\n\r\n<body bgcolor=\"chucknorris\"> ..."
            ],
            "url": "https://stackoverflow.com/questions/8318911",
            "answer": [
                "It\u2019s a holdover from the Netscape days:Missing digits are treated as 0[...]. An incorrect digit is simply interpreted as 0. For example the values #F0F0F0, F0F0F0, F0F0F, #FxFxFx and FxFxFx are all the same.It is from the blog post A little rant about Microsoft Internet Explorer's color parsing which covers it in great detail, including varying lengths of color values, etc.If we apply the rules in turn from the blog post, we get the following:Replace all nonvalid hexadecimal characters with 0\u2019s:Pad out to the next total number of characters divisible by\u00a03 (11\u00a0\u2192 12):Split into three equal groups, with each component representing the corresponding colour component of an RGB colour:Truncate each of the arguments from the right down to two characters.Which, finally, gives the following result:Here\u2019s an example demonstrating the bgcolor attribute in action, to produce this \u201camazing\u201d colour swatch:<table>\n  <tr>\n    <td bgcolor=\"chucknorris\" cellpadding=\"8\" width=\"100\" align=\"center\">chuck norris</td>\n    <td bgcolor=\"mrt\"         cellpadding=\"8\" width=\"100\" align=\"center\" style=\"color:#ffffff\">Mr T</td>\n    <td bgcolor=\"ninjaturtle\" cellpadding=\"8\" width=\"100\" align=\"center\" style=\"color:#ffffff\">ninjaturtle</td>\n  </tr>\n  <tr>\n    <td bgcolor=\"sick\"  cellpadding=\"8\" width=\"100\" align=\"center\">sick</td>\n    <td bgcolor=\"crap\"  cellpadding=\"8\" width=\"100\" align=\"center\">crap</td>\n    <td bgcolor=\"grass\" cellpadding=\"8\" width=\"100\" align=\"center\">grass</td>\n  </tr>\n</table>This also answers the other part of the question: Why does bgcolor=\"chucknorr\" produce a yellow colour? Well, if we apply the rules, the string is:Which gives a light yellow gold colour. As the string starts off as 9\u00a0characters, we keep the second\u00a0\u2018C\u2019 this time around, hence it ends up in the final colour value.I originally encountered this when someone pointed out that you could do color=\"crap\" and, well, it comes out brown.",
                "I'm sorry to disagree, but according to the rules for parsing a legacy color value posted by Yuhong Bao, chucknorris does not equate to #CC0000, but rather to #C00000, a very similar but slightly different hue of red. I used the Firefox ColorZilla add-on to verify this.The rules state:I was able to use these rules to correctly interpret the following strings:The original answerers who said the color was #CC0000 have since edited their answers to include the correction.",
                "The reason is the browser can not understand it and try to somehow translate it to what it can understand and in this case into a hexadecimal value!...chucknorris starts with c which is recognised character in hexadecimal, also it's converting all unrecognised characters into 0!So chucknorris in hexadecimal format becomes: c00c00000000, all other characters become 0 and c remains where they are...Now they get divided by 3 for RGB(red, green, blue)... R: c00c, G: 0000, B:0000...But we know valid hexadecimal for RGB is just 2 characters, means R: c0, G: 00, B:00So the real result is:I also added the steps in the image as a quick reference for you:",
                "Most browsers will simply ignore any non-hexadecimal values in your color string, substituting non-hexadecimal digits with zeros.ChuCknorris translates to c00c0000000.  At this point, the browser will divide the string into three equal sections, indicating Red, Green and Blue values: c00c 0000 0000.  Extra bits in each section will be ignored, which makes the final result #c00000 which is a reddish color.Note, this does not apply to CSS color parsing, which follow the CSS standard.<p><font color='chucknorris'>Redish</font></p>\n<p><font color='#c00000'>Same as above</font></p>\n<p><span style=\"color: chucknorris\">Black</span></p>",
                "The browser is trying to convert chucknorris into hexadecimal colour code, because it\u2019s not a valid value.This seems to be an issue primarily with Internet\u00a0Explorer and Opera\u00a0(12) as both Chrome\u00a0(31) and Firefox\u00a0(26) just ignore this.P.S. The numbers in brackets are the browser versions I tested on.Similarly, Rajnikanth (Indian Chuck Noris) converse to a shade of black:0a00 00a0 0000 => #0a0000On a lighter noteChuck Norris doesn\u2019t conform to web standards. Web standards conform\nto him. #BADA55",
                "The WHATWG HTML specification has the exact algorithm for parsing a legacy color value.The code Netscape Classic used for parsing color strings is open source: netscape/lib/layout/layimage.c.For example, notice that each character is parsed as a hex digit and then is shifted into a 32-bit integer without checking for overflow. Only eight hex digits fit into a 32-bit integer, which is why only the last 8 characters are considered. After parsing the hex digits into 32-bit integers, they are then truncated into 8-bit integers by dividing them by 16 until they fit into 8-bit, which is why leading zeros are ignored.This code does not exactly match what is defined in the spec, but the only difference there is a few lines of code. I think it is these lines that were added (in Netscape 4):",
                "chucknorris starts with c, and the browser reads it into a hexadecimal value.Because A, B, C, D, E, and F are characters in hexadecimal.The browser converts chucknorris to a hexadecimal value, C00C00000000.Then the C00C00000000 hexadecimal value is converted to RGB format (divided by 3):C00C00000000\u00a0\u21d2 R:C00C, G:0000, B:0000The browser needs only two digits to indicate the colour:R:C00C, G:0000, B:0000\u00a0\u21d2 R:C0, G:00, B:00\u00a0\u21d2 C00000Finally, show bgcolor = C00000 in the web browser.Here's an example demonstrating it:<table>\n  <tr>\n    <td bgcolor=\"chucknorris\" cellpadding=\"10\" width=\"150\" align=\"center\">chucknorris</td>\n    <td bgcolor=\"c00c00000000\" cellpadding=\"10\" width=\"150\" align=\"center\">c00c00000000</td>\n    <td bgcolor=\"c00000\" cellpadding=\"10\" width=\"150\" align=\"center\">c00000</td>\n  </tr>\n</table>",
                "The rules for parsing colors on legacy attributes involves additional steps than those mentioned in existing answers. The truncate component to 2 digits part is described as:Some examples:Below is a partial implementation of the algorithm. It does not handle errors or cases where the user enters a valid color.function parseColor(input) {\r\n  // todo: return error if input is \"\"\r\n  input = input.trim();\r\n  // todo: return error if input is \"transparent\"\r\n  // todo: return corresponding #rrggbb if input is a named color\r\n  // todo: return #rrggbb if input matches #rgb\r\n  // todo: replace unicode code points greater than U+FFFF with 00\r\n  if (input.length > 128) {\r\n    input = input.slice(0, 128);\r\n  }\r\n  if (input.charAt(0) === \"#\") {\r\n    input = input.slice(1);\r\n  }\r\n  input = input.replace(/[^0-9A-Fa-f]/g, \"0\");\r\n  while (input.length === 0 || input.length % 3 > 0) {\r\n    input += \"0\";\r\n  }\r\n  var r = input.slice(0, input.length / 3);\r\n  var g = input.slice(input.length / 3, input.length * 2 / 3);\r\n  var b = input.slice(input.length * 2 / 3);\r\n  if (r.length > 8) {\r\n    r = r.slice(-8);\r\n    g = g.slice(-8);\r\n    b = b.slice(-8);\r\n  }\r\n  while (r.length > 2 && r.charAt(0) === \"0\" && g.charAt(0) === \"0\" && b.charAt(0) === \"0\") {\r\n    r = r.slice(1);\r\n    g = g.slice(1);\r\n    b = b.slice(1);\r\n  }\r\n  if (r.length > 2) {\r\n    r = r.slice(0, 2);\r\n    g = g.slice(0, 2);\r\n    b = b.slice(0, 2);\r\n  }\r\n  return \"#\" + r.padStart(2, \"0\") + g.padStart(2, \"0\") + b.padStart(2, \"0\");\r\n}\r\n\r\n$(function() {\r\n  $(\"#input\").on(\"change\", function() {\r\n    var input = $(this).val();\r\n    var color = parseColor(input);\r\n    var $cells = $(\"#result tbody td\");\r\n    $cells.eq(0).attr(\"bgcolor\", input);\r\n    $cells.eq(1).attr(\"bgcolor\", color);\r\n\r\n    var color1 = $cells.eq(0).css(\"background-color\");\r\n    var color2 = $cells.eq(1).css(\"background-color\");\r\n    $cells.eq(2).empty().append(\"bgcolor: \" + input, \"<br>\", \"getComputedStyle: \" + color1);\r\n    $cells.eq(3).empty().append(\"bgcolor: \" + color, \"<br>\", \"getComputedStyle: \" + color2);\r\n  });\r\n});\nbody { font: medium monospace; }\r\ninput { width: 20em; }\r\ntable { table-layout: fixed; width: 100%; }\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js\"></script>\r\n\r\n<p><input id=\"input\" placeholder=\"Enter color e.g. chucknorris\"></p>\r\n<table id=\"result\">\r\n  <thead>\r\n    <tr>\r\n      <th>Left Color</th>\r\n      <th>Right Color</th>\r\n    </tr>\r\n  </thead>\r\n  <tbody>\r\n    <tr>\r\n      <td>&nbsp;</td>\r\n      <td>&nbsp;</td>\r\n    </tr>\r\n    <tr>\r\n      <td>&nbsp;</td>\r\n      <td>&nbsp;</td>\r\n    </tr>\r\n  </tbody>\r\n</table>"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I check if an element is hidden in jQuery?",
                "How do I toggle the visibility of an element using  .hide(), .show(), or .toggle()?\nHow do I test if an element is visible or hidden?"
            ],
            "url": "https://stackoverflow.com/questions/178325",
            "answer": [
                "Since the question refers to a single element, this code might be more suitable:It is the same as twernt's suggestion, but applied to a single element; and it matches the algorithm recommended in the jQuery FAQ.We use jQuery's is() to check the selected element with another element, selector or any jQuery object. This method traverses along the DOM elements to find a match, which satisfies the passed parameter. It will return true if there is a match, otherwise return false.",
                "You can use the hidden selector:And the visible selector:",
                "The above method does not consider the visibility of the parent. To consider the parent as well, you should use .is(\":hidden\") or .is(\":visible\").For example,The above method will consider div2 visible while :visible not. But the above might be useful in many cases, especially when you need to find if there is any error divs visible in the hidden parent because in such conditions :visible will not work.",
                "None of these answers address what I understand to be the question, which is what I was searching for, \"How do I handle items that have visibility: hidden?\". Neither :visible nor :hidden will handle this, as they are both looking for display per the documentation.  As far as I could determine, there is no selector to handle CSS visibility.  Here is how I resolved it (standard jQuery selectors, there may be a more condensed syntax):",
                "From How do I determine the state of a toggled element?You can determine whether an element is collapsed or not by using the :visible and :hidden selectors.If you're simply acting on an element based on its visibility, you can just include :visible or :hidden in the selector expression. For example:",
                "Often when checking if something is visible or not, you are going to go right ahead immediately and do something else with it. jQuery chaining makes this easy.So if you have a selector and you want to perform some action on it only if is visible or hidden, you can use filter(\":visible\") or filter(\":hidden\") followed by chaining it with the action you want to take.So instead of an if statement, like this:Or more efficient, but even uglier:You can do it all in one line:",
                "The :visible selector according to the jQuery documentation:Elements with visibility: hidden or opacity: 0 are considered to be visible, since they still consume space in the layout.This is useful in some cases and useless in others, because if you want to check if the element is visible (display != none), ignoring the parents visibility, you will find that doing .css(\"display\") == 'none' is not only faster, but will also return the visibility check correctly.If you want to check visibility instead of display, you should use: .css(\"visibility\") == \"hidden\".Also take into consideration the additional jQuery notes:Because :visible is a jQuery extension and not part of the CSS specification, queries using :visible cannot take advantage of the performance boost provided by the native DOM querySelectorAll() method. To achieve the best performance when using :visible to select elements, first select the elements using a pure CSS selector, then use .filter(\":visible\").Also, if you are concerned about performance, you should check Now you see me\u2026 show/hide performance (2010-05-04). And use other methods to show and hide elements.",
                "How element visibility and jQuery works;An element could be hidden with display:none, visibility:hidden or opacity:0. The difference between those methods:opacity:0 hides the element as \"visibility:hidden\", and it still takes up space in the layout; the only difference is that opacity lets one to make an element partly transparent;Useful jQuery toggle methods:",
                "This works for me, and I am using show() and hide() to make my div hidden/visible:",
                "You can also do this using plain JavaScript:Notes:Works everywhereWorks for nested elementsWorks for CSS and inline stylesDoesn't require a framework",
                "I would use CSS class .hide { display: none!important; }.For hiding/showing, I call .addClass(\"hide\")/.removeClass(\"hide\"). For checking visibility, I use .hasClass(\"hide\").It's a simple and clear way to check/hide/show elements, if you don't plan to use .toggle() or .animate() methods.",
                "Demo Link$('#clickme').click(function() {\n  $('#book').toggle('slow', function() {\n    // Animation complete.\n    alert($('#book').is(\":visible\")); //<--- TRUE if Visible False if Hidden\n  });\n});\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<div id=\"clickme\">\n  Click here\n</div>\n<img id=\"book\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/87/Google_Chrome_icon_%282011%29.png\" alt=\"\" width=\"300\"/>Source (from my blog):Blogger Plug n Play - jQuery Tools and Widgets: How to See if Element is hidden or Visible Using jQuery",
                "ebdiv should be set to style=\"display:none;\". It works for both show and hide:",
                "One can simply use the hidden or visible attribute, like:Or you can simplify the same with is as follows.",
                "Another answer you should put into consideration is if you are hiding an element, you should use jQuery, but instead of actually hiding it, you remove the whole element, but you copy its HTML content and the tag itself into a jQuery variable, and then all you need to do is test if there is such a tag on the screen, using the normal if (!$('#thetagname').length).",
                "When testing an element against :hidden selector in jQuery it should be considered that an absolute positioned element may be recognized as hidden although their child elements are visible.This seems somewhat counter-intuitive in the first place \u2013 though having a closer look at the jQuery documentation gives the relevant information:Elements can be considered hidden for several reasons: [...] Their width and height are explicitly set to 0. [...]So this actually makes sense in regards to the box-model and the computed style for the element. Even if width and height are not set explicitly to 0 they may be set implicitly.Have a look at the following example:console.log($('.foo').is(':hidden')); // true\r\nconsole.log($('.bar').is(':hidden')); // false\n.foo {\r\n  position: absolute;\r\n  left: 10px;\r\n  top: 10px;\r\n  background: #ff0000;\r\n}\r\n\r\n.bar {\r\n  position: absolute;\r\n  left: 10px;\r\n  top: 10px;\r\n  width: 20px;\r\n  height: 20px;\r\n  background: #0000ff;\r\n}\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\r\n<div class=\"foo\">\r\n  <div class=\"bar\"></div>\r\n</div>Update for jQuery 3.x:With jQuery 3 the described behavior will change! Elements will be considered visible if they have any layout boxes, including those of zero width and/or height.JSFiddle with jQuery 3.0.0-alpha1:http://jsfiddle.net/pM2q3/7/The same JavaScript code will then have this output:",
                "$(document).ready(function() {\n  if ($(\"#checkme:hidden\").length) {\n    console.log('Hidden');\n  }\n});\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<div id=\"checkme\" class=\"product\" style=\"display:none\">\n  <span class=\"itemlist\"><!-- Shows Results for Fish --></span> Category:Fish\n  <br>Product: Salmon Atlantic\n  <br>Specie: Salmo salar\n  <br>Form: Steaks\n</div>",
                "To check if it is not visible I use !:Or the following is also the sam, saving the jQuery selector in a variable to have better performance when you need it multiple times:",
                "Using classes designated for \"hiding\" elements is easy and also one of the most efficient methods. Toggling a class 'hidden' with a Display style of 'none' will perform faster than editing that style directly. I explained some of this pretty thoroughly in Stack Overflow question Turning two elements visible/hidden in the same div.Here is a truly enlightening video of a Google Tech Talk by Google front-end engineer Nicholas Zakas:",
                "After all, none of examples suits me, so I wrote my own.Tests (no support of Internet\u00a0Explorer filter:alpha):a) Check if the document is not hiddenb) Check if an element has zero width / height / opacity or display:none / visibility:hidden in inline stylesc) Check if the center (also because it is faster than testing every pixel / corner) of element is not hidden by other element (and all ancestors, example: overflow:hidden / scroll / one element over another) or screen edgesd) Check if an element has zero width / height / opacity or display:none / visibility:hidden in computed styles (among all ancestors)Tested onAndroid 4.4 (Native browser/Chrome/Firefox), Firefox (Windows/Mac), Chrome (Windows/Mac), Opera (Windows Presto/Mac WebKit), Internet\u00a0Explorer (Internet\u00a0Explorer 5-11 document modes + Internet\u00a0Explorer 8 on a virtual machine), and Safari (Windows/Mac/iOS).How to use:",
                "Example of using the visible check for adblocker is activated:$(document).ready(function(){\r\n  if(!$(\"#ablockercheck\").is(\":visible\"))\r\n    $(\"#ablockermsg\").text(\"Please disable adblocker.\").show();\r\n});\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\r\n<div class=\"ad-placement\" id=\"ablockercheck\"></div>\r\n<div id=\"ablockermsg\" style=\"display: none\"></div>\"ablockercheck\" is a ID which adblocker blocks. So checking it if it is visible you are able to detect if adblocker is turned On.",
                "You need to check both... Display as well as visibility:If we check for $(this).is(\":visible\"), jQuery checks for both the things automatically.",
                "$(document).ready(function() {\n   var visible = $('#tElement').is(':visible');\n\n   if(visible) {\n      alert(\"visible\");\n                    // Code\n   }\n   else\n   {\n      alert(\"hidden\");\n   }\n});\n<script src=\"https://code.jquery.com/jquery-1.10.2.js\"></script>\n\n<input type=\"text\" id=\"tElement\" style=\"display:block;\">Firstname</input>",
                "Simply check visibility by checking for a boolean value, like:I used this code for each function. Otherwise you can use is(':visible') for checking the visibility of an element.",
                "Because Elements with visibility: hidden or opacity: 0 are considered visible, since they still consume space in the layout (as described for jQuery :visible Selector) - we can check if element is really visible in this way:",
                "But what if the element's CSS is like the following?So this answer to Stack Overflow question How to check if an element is off-screen should also be considered.",
                "A function can be created in order to check for visibility/display attributes in order to gauge whether the element is shown in the UI or not.Working Fiddle",
                "Also here's a ternary conditional expression to check the state of the element and then to toggle it:"
            ]
        },
        {
            "tag": "",
            "question": [
                "What does \"use strict\" do in JavaScript, and what is the reasoning behind it?",
                "Recently, I ran some of my JavaScript code through Crockford's JSLint, and it gave the following error:\n\nProblem at line 1 character 1: Missing \"use strict\" statement.\n\nDoing some searching, ..."
            ],
            "url": "https://stackoverflow.com/questions/1335851",
            "answer": [
                "Inside native ECMAScript modules (with import and export statements) and ES6 classes, strict mode is always enabled and cannot be disabled.This article about Javascript Strict Mode might interest you: John Resig - ECMAScript 5 Strict Mode, JSON, and MoreTo quote some interesting parts:Strict Mode is a new feature in ECMAScript 5 that allows you to place a program, or a function, in a \"strict\" operating context. This strict context prevents certain actions from being taken and throws more exceptions.And:Strict mode helps out in a couple ways:Also note you can apply \"strict mode\" to the whole file... Or you can use it only for a specific function (still quoting from John Resig's article):Which might be helpful if you have to mix old and new code ;-)So, I suppose it's a bit like the \"use strict\" you can use in Perl (hence the name?): it helps you make fewer errors, by detecting more things that could lead to breakages.Strict mode is now supported by all major browsers.",
                "It's a new feature of ECMAScript 5. John Resig wrote up a nice summary of it.It's just a string you put in your JavaScript files (either at the top of your file or inside of a function) that looks like this:Putting it in your code now shouldn't cause any problems with current browsers as it's just a string. It may cause problems with your code in the future if your code violates the pragma.  For instance, if you currently have foo = \"bar\" without defining foo first, your code will start failing...which is a good thing in my opinion.",
                "The statement \"use strict\";  instructs the browser to use the Strict mode, which is a reduced and safer feature set of JavaScript.Disallows global variables. (Catches missing var declarations and typos in variable names)Silent failing assignments will throw error in strict mode (assigning NaN = 5;)Attempts to delete undeletable properties will throw (delete Object.prototype)Requires all property names in an object literal to be unique (var x = {x1: \"1\", x1: \"2\"})Function parameter names must be unique (function sum (x, x) {...})Forbids octal syntax (var x = 023; some devs assume wrongly that a preceding zero does nothing to change the number.)Forbids the with keywordeval in strict mode does not introduce new variablesForbids deleting plain names (delete x;)Forbids binding or assignment of the names eval and arguments in any formStrict mode does not alias properties of the arguments object with the formal parameters. (e.g. in function sum (a,b) { return arguments[0] + b;} This works because arguments[0] is bound to a and so on. ) (See examples section below to understand the difference)arguments.callee is not supported[Ref: Strict mode, Mozilla Developer Network]Examples:",
                "If people are worried about using use strict it might be worth checking out this article:ECMAScript 5 'Strict mode' support in browsers. What does this mean?\nNovoGeek.com - Krishna's weblogIt talks about browser support, but more importantly how to deal with it safely:",
                "A word of caution, all you hard-charging programmers:  applying \"use strict\" to existing code can be hazardous!  This thing is not some feel-good, happy-face sticker that you can slap on the code to make it 'better'.  With the \"use strict\" pragma, the browser will suddenly THROW exceptions in random places that it never threw before just because at that spot you are doing something that default/loose JavaScript happily allows but strict JavaScript abhors!  You may have strictness violations hiding in seldom used calls in your code that will only throw an exception when they do eventually get run - say, in the production environment that your paying customers use!If you are going to take the plunge, it is a good idea to apply \"use strict\" alongside comprehensive unit tests and a strictly configured JSHint build task that will give you some confidence that there is no dark corner of your module that will blow up horribly just because you've turned on Strict Mode.  Or, hey, here's another option:  just don't add \"use strict\" to any of your legacy code, it's probably safer that way, honestly.  DEFINITELY DO NOT add \"use strict\" to any modules you do not own or maintain, like third party modules.I think even though it is a deadly caged animal, \"use strict\" can be good stuff, but you have to do it right.  The best time to go strict is when your project is greenfield and you are starting from scratch. Configure JSHint/JSLint with all the warnings and options cranked up as tight as your team can stomach, get a good build/test/assert system du jour rigged like Grunt+Karma+Chai, and only THEN start marking all your new modules as \"use strict\".  Be prepared to cure lots of niggly errors and warnings.  Make sure everyone understands the gravity by configuring the build to FAIL if JSHint/JSLint produces any violations.My project was not a greenfield project when I adopted \"use strict\".  As a result, my IDE is full of red marks because I don't have \"use strict\" on half my modules, and JSHint complains about that.  It's a reminder to me about what refactoring I should do in the future.  My goal is to be red mark free due to all of my missing \"use strict\" statements, but that is years away now.",
                "The JavaScript strict mode is a feature in ECMAScript 5. You can enable the strict mode by declaring this in the top of your script/function.When a JavaScript engine sees this directive, it will start to interpret the code in a special mode. In this mode, errors are thrown up when certain coding practices that could end up being potential bugs are detected (which is the reasoning behind the strict mode).Consider this example:In their obsession to line up the numeric literals, the developer has inadvertently initialized variable b with an octal literal. Non-strict mode will interpret this as a numeric literal with value 24 (in base 10). However, strict mode will throw an error.For a non-exhaustive list of specialties in strict mode, see this answer.In my new JavaScript application: Absolutely! Strict mode can be used as a whistleblower when you are doing something stupid with your code.In my existing JavaScript code: Probably not! If your existing JavaScript code has statements that are prohibited in strict-mode, the application will simply break. If you want strict mode, you should be prepared to debug and correct your existing code. This is why using 'use strict'; does not suddenly make your code better.Insert a 'use strict'; statement on top of your script:Note that everything in the file myscript.js will be interpreted in strict mode.Or, insert a 'use strict'; statement on top of your function body:Everything in the lexical scope of function doSomething will be interpreted in strict mode. The word lexical scope is important here. For example, if your strict code calls a function of a library that is not strict, only your code is executed in strict mode, and not the called function. See this answer for a better explanation.I found a nice article describing several things that are prohibited in strict mode (note that this is not an exhaustive list):Historically, JavaScript has been confused about how functions\nare scoped. Sometimes they seem to be statically scoped, but some\nfeatures make them behave like they are dynamically scoped. This is\nconfusing, making programs difficult to read and understand.\nMisunderstanding causes bugs. It also is a problem for performance.\nStatic scoping would permit variable binding to happen at compile\ntime, but the requirement for dynamic scope means the binding must be\ndeferred to runtime, which comes with a significant performance\npenalty.Strict mode requires that all variable binding be done statically.\nThat means that the features that previously required dynamic binding\nmust be eliminated or modified. Specifically, the with statement is\neliminated, and the eval function\u2019s ability to tamper with the\nenvironment of its caller is severely restricted.One of the benefits of strict code is that tools like YUI Compressor\ncan do a better job when processing it.JavaScript has implied global variables. If\nyou do not explicitly declare a variable, a global variable is\nimplicitly declared for you. This makes programming easier for\nbeginners because they can neglect some of their basic housekeeping\nchores. But it makes the management of larger programs much more\ndifficult and it significantly degrades reliability. So in strict\nmode, implied global variables are no longer created. You should\nexplicitly declare all of your variables.There are a number of situations that could cause this\nto be bound to the global object. For example, if you forget to\nprovide the new prefix when calling a constructor function, the\nconstructor's this will be bound unexpectedly to the global object, so\ninstead of initializing a new object, it will instead be silently\ntampering with global variables. In these situations, strict mode will\ninstead bind this to undefined, which will cause the constructor to\nthrow an exception instead, allowing the error to be detected much\nsooner.JavaScript has always had read-only properties, but you\ncould not create them yourself until ES5\u2019s Object.createProperty\nfunction exposed that capability. If you attempted to assign a value\nto a read-only property, it would fail silently. The assignment would\nnot change the property\u2019s value, but your program would proceed as\nthough it had. This is an integrity hazard that can cause programs to\ngo into an inconsistent state. In strict mode, attempting to change a\nread-only property will throw an exception.The octal (or base 8) representation of numbers was extremely\nuseful when doing machine-level programming on machines whose word\nsizes were a multiple of 3. You needed octal when working with the CDC\n6600 mainframe, which had a word size of 60 bits. If you could read\noctal, you could look at a word as 20 digits. Two digits represented\nthe op code, and one digit identified one of 8 registers. During the\nslow transition from machine codes to high level languages, it was\nthought to be useful to provide octal forms in programming languages.In C, an extremely unfortunate representation of octalness was\nselected: Leading zero. So in C, 0100 means 64, not 100, and 08 is an\nerror, not 8. Even more unfortunately, this anachronism has been\ncopied into nearly all modern languages, including JavaScript, where\nit is only used to create errors. It has no other purpose. So in\nstrict mode, octal forms are no longer allowed.The arguments pseudo array becomes a little bit more\narray-like in ES5. In strict mode, it loses its callee and caller\nproperties. This makes it possible to pass your arguments to untrusted\ncode without giving up a lot of confidential context. Also, the\narguments property of functions is eliminated.In strict mode, duplicate keys in a function literal will produce a\nsyntax error. A function can\u2019t have two parameters with the same name.\nA function can\u2019t have a variable with the same name as one of its\nparameters. A function can\u2019t delete its own variables. An attempt to\ndelete a non-configurable property now throws an exception. Primitive\nvalues are not implicitly wrapped.ECMAScript 5 adds a list of reserved words. If you use them as variables or arguments, strict mode will throw an error. The reserved words are:implements, interface, let, package, private, protected, public, static, and yield",
                "I strongly recommend every developer to start using strict mode now. There are enough browsers supporting it that strict mode will legitimately help save us from errors we didn\u2019t even know were in your code.Apparently, at the initial stage there will be errors we have never encountered before. To get the full benefit, we need to do proper testing after switching to strict mode to make sure we have caught everything. Definitely we don\u2019t just throw use strict in our code and assume there are no errors. So the churn is that it\u2019s time to start using this incredibly useful language feature to write better code.For example,JSLint is a debugger written by Douglas Crockford. Simply paste in your script, and it\u2019ll quickly scan for any noticeable issues and errors in your code.",
                "I would like to offer a somewhat more founded answer complementing the other answers. I was hoping to edit the most popular answer, but failed. I tried to make it as comprehensive and complete as I could.You can refer to the MDN documentation for more information.\"use strict\" a directive introduced in ECMAScript 5.Directives are similar to statements, yet different.The use strict directive indicates that the following code (in a script or a function) is strict code.\nThe code in the highest level of a script (code that is not in a function) is considered strict code when the script contains a use strict directive.\nThe content of a function is considered strict code when the function itself is defined in a strict code or when the function contains a use strict directive.\nCode that is passed to an eval() method is considered strict code when eval() was called from a strict code or contains the use strict directive itself.The strict mode of ECMAScript 5 is a restricted subset of the JavaScript language, which eliminates relevant deficits of the language and features more stringent error checking and higher security. The following lists the differences between strict mode and normal mode (of which the first three are particularly important):Also when a function is invoked with call() or apply in strict mode, then this is exactly the value of the first argument of the call()or apply() invocation. (In normal mode null and undefined are replaced by the global Object and values, which are not objects, are cast into objects.)In strict mode you will get a TypeError, when you try to assign to readonly properties or to define new properties for a non extensible object. (In normal mode both simply fail without error message.)In strict mode, when passing code to eval(), you cannot declare or define variables or functions in the scope of the caller (as you can do it in normal mode). Instead, a new scope is created for eval() and the variables and functions are within that scope. That scope is destroyed after eval() finishes execution.In strict mode the arguments-object of a function contains a static copy of the values, which are passed to that function. In normal mode the arguments-object has a somewhat \"magical\" behaviour: The elements of the array and the named function parameters reference both the same value.In strict mode you will get a SyntaxError when the delete operator is followed by a non qualified identifier (a variable, function or function parameter). In normal mode the delete expression would do nothing and is evaluated to false.In strict mode you will get a TypeError when you try to delete a non configurable property. (In normal mode the attempt simply fails and the delete expression is evaluated to false).In strict mode it is considered a syntactical error when you try to define several properties with the same name for an object literal. (In normal mode there is no error.)In strict mode it is considered a syntactical error when a function declaration has multiple parameters with the same name. (In normal mode there is no error.)In strict mode octal literals are not allowed (these are literals that start with 0. (In normal mode some implementations do allow octal literals.)In strict mode the identifiers eval and arguments are treated like keywords. You cannot change their value, cannot assign a value to them, and you cannot use them as names for variables, functions, function parameters or identifiers of a catch block.In strict mode are more restrictions on the possibilities to examine the call stack. arguments.caller and arguments.callee cause a TypeError in a function in strict mode. Furthermore, some caller- and arguments properties of functions in strict mode cause a TypeError when you try to read them.",
                "My two cents:One of the goals of strict mode is to allow for faster debugging of issues. It helps the developers by throwing exception when certain wrong things occur that can cause silent & strange behaviour of your webpage. The moment we use  use strict, the code will throw out errors which helps developer to fix it in advance.Few important things which I have learned after using  use strict :Prevents Global Variable Declaration:\"use strict\";\nvar tree1Data = { name: 'Banana Tree',age: 100,leafCount: 100000};\n\nfunction Tree(typeOfTree) {\n    var age;\n    var leafCount;\n\n    age = typeOfTree.age;\n    leafCount = typeOfTree.leafCount;\n    nameoftree = typeOfTree.name;\n};\n\nvar tree1 = new Tree(tree1Data);\nconsole.log(window);Now,this code creates nameoftree in global scope which could be accessed using window.nameoftree. When we implement use strict the code would throw error.Uncaught ReferenceError: nameoftree is not definedEliminates with statement :with statements can't be minified using tools like uglify-js. They're also deprecated and removed from future JavaScript versions.Sample:\"use strict\";\nvar tree1Data = {\n    name: 'Banana Tree',\n    age: 100,\n    leafCount: 100000\n};\n\nfunction Tree(typeOfTree) {\n    var age;\n    var leafCount;\n\n    age = typeOfTree.age;\n    leafCount = typeOfTree.leafCount;\n   // nameoftree = typeOfTree.name;\n\n    for (var i = 0; i < 2; ++i) {\n       // let(leafCount = i) { /*do something*/ }\n    }\n    for (var i = 0; i < 2; ++i) {\n        with(leafCount = i) { /*do something*/ }\n    }\n};\n\nvar tree1 = new Tree(tree1Data);\nconsole.log(window);Prevents Duplicates :When we have duplicate property, it throws an exceptionUncaught SyntaxError: Duplicate data property in object literal not\nallowed in strict mode\"use strict\";\nvar tree1Data = {\n    name: 'Banana Tree',\n    age: 100,\n    leafCount: 100000,\n    name:'Banana Tree'\n};There are few more but I need to gain more knowledge on that.",
                "If you use a browser released in the last year or so then it most likely supports JavaScript Strict mode. Only older browsers around before ECMAScript 5 became the current standard don't support it.The quotes around the command make sure that the code will still work in older browsers as well (although the things that generate a syntax error in strict mode will generally just cause the script to malfunction in some hard to detect way in those older browsers).",
                "When adding \"use strict\";, the following cases will throw a SyntaxError before the script is executing:Paving the way for future ECMAScript versions, using one of the newly reserved keywords (in prevision for ECMAScript 6): implements, interface, let, package, private, protected, public, static, and yield.Declaring function in blocksOctal syntaxthis point to the global object.Declaring twice the same name for a property name in an object literalThis is no longer the case in ECMAScript 6 (bug 1041128).Declaring two function arguments with the same name functionSetting a value to an undeclared variableUsing delete on a variable name delete myVariable;Using eval or arguments as variable or function argument nameSources:Transitioning to strict mode on MDNStrict mode on MDNJavaScript\u2019s Strict Mode and Why You Should Use It on Colin J. Ihrig's blog (archived version)",
                "Strict mode makes several changes to normal JavaScript semantics:eliminates some JavaScript silent errors by changing them\nto throw errors.fixes mistakes that make it difficult for JavaScript\nengines to perform optimizations.prohibits some syntax likely to be defined in future\nversions of ECMAScript.for more information vistit Strict Mode- Javascript",
                "\"Use Strict\"; is an insurance that programmer will not use the loose or the bad properties of JavaScript. It is a guide, just like a ruler will help you make straight lines. \"Use Strict\" will help you do \"Straight coding\".Those that prefer not to use rulers to do their lines straight usually end up in those pages asking for others to debug their code.Believe me. The overhead is negligible compared to poorly designed code. Doug Crockford, who has been a senior JavaScript developer for several years, has a very interesting post here. Personally, I like to return to his site all the time to make sure I don't forget my good practice.Modern JavaScript practice should always evoke the \"Use Strict\"; pragma. The only reason that the ECMA Group has made the \"Strict\" mode optional is to permit less experienced coders access to JavaScript and give then time to adapt to the new and safer coding practices.",
                "Including use strict in the beginning of your all sensitive JavaScript files from this point is a small way to be a better JavaScript programmer and avoid random variables becoming global and things change silently.",
                "Quoting from w3schools:The \"use strict\" directive is new in JavaScript 1.8.5 (ECMAScript\n  version 5).It is not a statement, but a literal expression, ignored by earlier\n  versions of JavaScript.The purpose of \"use strict\" is to indicate that the code should be\n  executed in \"strict mode\".With strict mode, you can not, for example, use undeclared variables.Strict mode makes it easier to write \"secure\" JavaScript.Strict mode changes previously accepted \"bad syntax\" into real errors.As an example, in normal JavaScript, mistyping a variable name creates\n  a new global variable. In strict mode, this will throw an error,\n  making it impossible to accidentally create a global variable.In normal JavaScript, a developer will not receive any error feedback\n  assigning values to non-writable properties.In strict mode, any assignment to a non-writable property, a\n  getter-only property, a non-existing property, a non-existing\n  variable, or a non-existing object, will throw an error.Please refer to http://www.w3schools.com/js/js_strict.asp to know more",
                "\"use strict\" makes JavaScript code to run in strict mode, which basically means everything needs to be defined before use. The main reason for using strict mode is to avoid accidental global uses of undefined methods.Also in strict mode, things run faster, some warnings or silent warnings throw fatal errors, it's better to always use it to make a neater code.\"use strict\" is widely needed to be used in ECMA5, in ECMA6 it's part of JavaScript by default, so it doesn't need to be added if you're using ES6.Look at these statements and examples from MDN:The \"use strict\" Directive The \"use strict\" directive is new in\n  JavaScript 1.8.5 (ECMAScript version 5). It is not a statement, but a\n  literal expression, ignored by earlier versions of JavaScript. The\n  purpose of \"use strict\" is to indicate that the code should be\n  executed in \"strict mode\". With strict mode, you can not, for example,\n  use undeclared variables.Examples of using \"use strict\":\n  Strict mode for functions: Likewise, to invoke strict mode for a\n  function, put the exact statement \"use strict\"; (or 'use strict';) in\n  the function's body before any other statements.1) strict mode in functions2) whole-script strict mode3) Assignment to a non-writable globalYou can read more on MDN.",
                "There's a good talk by some people who were on the ECMAScript committee: Changes to JavaScript, Part 1: ECMAScript 5\" about how incremental use of the \"use strict\" switch allows JavaScript implementers to clean up a lot of the dangerous features of JavaScript without suddenly breaking every website in the world.Of course it also talks about just what a lot of those misfeatures are (were) and how ECMAScript 5 fixes them.",
                "Small examples to compare:Non-strict mode:for (i of [1,2,3]) console.log(i)\r\n    \r\n// output:\r\n// 1\r\n// 2\r\n// 3Strict mode:'use strict';\r\nfor (i of [1,2,3]) console.log(i)\r\n\r\n// output:\r\n// Uncaught ReferenceError: i is not definedNon-strict mode:String.prototype.test = function () {\r\n  console.log(typeof this === 'string');\r\n};\r\n\r\n'a'.test();\r\n\r\n// output\r\n// falseString.prototype.test = function () {\r\n  'use strict';\r\n  \r\n  console.log(typeof this === 'string');\r\n};\r\n\r\n'a'.test();\r\n\r\n// output\r\n// true",
                "Note that use strict was introduced in EcmaScript 5 and was kept since then.Below are the conditions to trigger strict mode in ES6 and ES7:",
                "The main reasons why developers should use \"use strict\" are:Prevents accidental declaration of global variables.Using \"use strict()\" will make sure that variables are declared with var before use. \nEg:The string \"arguments\" cannot be used as a variable:Will restrict uses of keywords as variables. Trying to use them will throw errors.In short will make your code less error prone and in turn will make you write good code.To read more about it you can refer here.",
                "use strict is a way to make your code safer, because you can't use dangerous features that can work not as you expect. And, as was written before, it makes code more strict.",
                "JavaScript \u201cstrict\u201d mode was introduced in ECMAScript 5.Writing \"use strict\"; at the very top of your JS file turns on strict\nsyntax checking. It does the following tasks for us:shows an error if you try to assign to an undeclared variablestops you from overwriting key JS system librariesforbids some unsafe or error-prone language featuresuse strict also works inside of individual functions. It is always a better practice to include use strict in your code.Browser compatibility issue: \nThe \"use\" directives are meant to be backwards-compatible. Browsers that do not support them will just see a string literal that isn't referenced further. So, they will pass over it and move on.",
                "\"use strict\"; is the ECMA effort to make JavaScript a little bit more robust. It brings in JS an attempt to make it at least a little \"strict\" (other languages implement strict rules since the 90s). It actually \"forces\" JavaScript developers to follow some sort of coding best practices.\nStill, JavaScript is very fragile. There is no such thing as typed variables, typed methods, etc.\nI strongly recommend JavaScript developers to learn a more robust language such as Java or ActionScript3, and implement the same best practices in your JavaScript code, it will work better and be easier to debug.",
                "Normally, JavaScript does not follow strict rules, hence increasing chances of errors. After using \"use strict\", the JavaScript code should follow strict set of rules as in other programming languages such as use of terminators, declaration before initialization, etc.If \"use strict\" is used, the code should be written by following a strict set of rules, hence decreasing the chances of errors and ambiguities.",
                "Use Strict is used to show common and repeated errors so that it is handled differently , and changes the way java script runs , such changes are :Prevents accidental globalsNo duplicatesEliminates withEliminates this coercionSafer eval()Errors for immutablesyou can also read this article for the details",
                "\"use strict\"; Defines that JavaScript code should be executed in\n   \"strict mode\".All modern browsers support \"use strict\" except Internet Explorer 9 and lower.DisadvantageIf a developer used a library that was in strict mode, but the developer was used to working in normal mode, they might call some actions on the library that wouldn\u2019t work as expected.Worse, since the developer is in normal mode, they don\u2019t have the advantages of extra errors being thrown, so the error might fail silently.Also, as listed above, strict mode stops you from doing certain things.People generally think that you shouldn\u2019t use those things in the first place, but some developers don\u2019t like the constraint and want to use all the features of the language.For basic example and for reference go through :https://www.tutorialsteacher.com/javascript/javascript-strict",
                "JavaScript was designed and implemented hastily because of the browser wars and bad management. As a result many poor design decisions, un-intuitive syntax and confusing semantics found their way into the language. Strict mode aims to amend some of these mistakes.But fixing these mistakes without creating alternative interpretation breaks backward compatibility. So, \"use strict\" directive creates that alternative interpretation of the code while communicating it to the programmer.For example, this keywords refers to the object in a method definition, like this or self in other languages.this has no purpose outside the method context but all JavaScript functions have this keyword whether they are methods or not:Here this resolves to the global object which does not make sense and serves no purpose because global object is already available in the scope.In strict mode this in a global function resolves to undefined, which is what we expect.Some mistakes can not be fixed even in strict mode because syntax should be valid for older browsers since they ignore \"strict mode\" directive. This is by design.",
                "Strict mode can prevent memory leaks.Please check the function below written in non-strict mode:In this function, we are using a variable called name inside the function. Internally, the compiler will first check if there is any variable declared with that particular name in that particular function scope. Since the compiler understood that there is no such variable, it will check in the outer scope. In our case, it is the global scope. Again, the compiler understood that there is also no variable declared in the global space with that name, so it creates such a variable for us in the global space. Conceptually, this variable will be created in the global scope and will be available in the entire application.Another scenario is that, say, the variable is declared in a child function. In that case, the compiler checks the validity of that variable in the outer scope, i.e., the parent function. Only then it will check in the global space and create a variable for us there.\nThat means additional checks need to be done. This will affect the performance of the application.Now let's write the same function in strict mode.We will get the following error.Here, the compiler throws the reference error. In strict mode, the compiler does not allow us to use the variable without declaring it. So memory leaks can be prevented. In addition, we can write more optimized code.",
                "Strict mode eliminates errors that would be ignored in non-strict mode, thus making javascript \u201cmore secured\u201d.Is it considered among best practices?Yes, It's considered part of the best practices while working with javascript to include Strict mode. This is done by adding the below line of code in your JS file.'use strict';in your code.What does it mean to user agents?Indicating that code should be interpreted in strict mode specifies to user agents like browsers that they should treat code literally as written, and throw an error if the code doesn't make sense.For example: Consider in your .js file you have the following code:Scenario 1: [NO STRICT MODE]Scenario 2: [NO STRICT MODE]So why does the variable name is being printed in both cases?Without strict mode turned on, user agents often go through a series of modifications to problematic code in an attempt to get it to make sense. On the surface, this can seem like a fine thing, and indeed, working outside of strict mode makes it possible for people to get their feet wet with JavaScript code without having all the details quite nailed down. However, as a developer, I don't want to leave a bug in my code, because I know it could come back and bite me later on, and I also just want to write good code. And that's where strict mode helps out.Scenario 3: [STRICT MODE]Additional tip: To maintain code quality using strict mode, you don't need to write this over and again especially if you have multiple .js file. You can enforce this rule globally in eslint rules as follows:Filename: .eslintrc.jsOkay, so what is prevented in strict mode?Using a variable without declaring it will throw an error in strict mode. This is to prevent unintentionally creating global variables throughout your application. The example with printing Chicago covers this in particular.Deleting a variable or a function or an argument is a no-no in strict mode.Duplicating a parameter name is not allowed in strict mode.Reserved words in the Javascript language are not allowed in strict mode. The words are implements interface, let, packages, private, protected, public. static, and yieldFor a more comprehensive list check out the MDN documentation here: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Strict_mode",
                "strict mode enables strict features in the v8 engine. Short example of some features:You can enable it globally by writing:Per function you just include in function:es6 features are enabled (this is browser dependent), for node v4+ this is important.Performance, in some cases, is better.There are more features as well, check here for more!"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I check out a remote Git branch?",
                "Somebody pushed a branch called test with git push origin test to a shared repository. I can see the branch with git branch -r. How do I check out the remote test branch? I've tried:\n\ngit checkout ..."
            ],
            "url": "https://stackoverflow.com/questions/1783405",
            "answer": [
                "The answer has been split depending on whether there is one remote repository configured or multiple. The reason for this is that for the single remote case, some of the commands can be simplified as there is less ambiguity.Updated for Git 2.23: For older versions, see the section at the end.In both cases, start by fetching from the remote repository to make sure you have all the latest changes downloaded.This will fetch all of the remote branches for you. You can see the branches available for checkout with:The branches that start with remotes/* can be thought of as read only copies of the remote branches. To work on a branch you need to create a local branch from it. This is done with the Git command switch (since Git 2.23) by giving it the name of the remote branch (minus the remote name):In this case Git is guessing (can be disabled with --no-guess) that you are trying to checkout and track the remote branch with the same name.In the case where multiple remote repositories exist, the remote repository needs to be explicitly named.As before, start by fetching the latest remote changes:This will fetch all of the remote branches for you. You can see the branches available for checkout with:With the remote branches in hand, you now need to check out the branch you are interested in with -c to create a new local branch:For more information about using git switch:I also created the image below for you to share the differences, look at how to fetch works, and also how it's different to pull:git switch was added in Git 2.23, prior to this git checkout was used to switch branches.To checkout out with only a single remote repository:if there there are multiple remote repositories configured it becomes a bit longer",
                "Sidenote: With modern Git (>= 1.6.6), you are able to use just(note that it is 'test' not 'origin/test') to perform magical DWIM-mery and create local branch 'test' for you, for which upstream would be remote-tracking branch 'origin/test'.The * (no branch) in git branch output means that you are on unnamed branch, in so called \"detached HEAD\" state (HEAD points directly to commit, and is not symbolic reference to some local branch).  If you made some commits on this unnamed branch, you can always create local branch off current commit:A more modern approach as suggested in the comments:@Dennis: git checkout <non-branch>, for example git checkout origin/test results in detached HEAD / unnamed branch, while git checkout test or git checkout -b test origin/test results in local\nbranch test (with remote-tracking branch origin/test as upstream) \u2013\nJakub Nar\u0119bski Jan 9 '14 at 8:17emphasis on git checkout origin/test",
                "In this case, you probably want to create a local test branch which is tracking the remote test branch:In earlier versions of git, you needed an explicit --track option, but that is the default now when you are branching off a remote branch.To create the local branch and switch to it, use:",
                "While the first and selected answer is technically correct, there's the possibility you have not yet retrieved all objects and refs from the remote repository. If that is the case, you'll receive the following error:fatal: git checkout: updating paths is incompatible with switching branches.\n  Did you intend to checkout 'origin/remote_branch' which can not be resolved as commit?If you receive this message, you must first do a git fetch origin where origin is the name of the remote repository prior to running git checkout remote_branch. Here's a full example with responses:As you can see, running git fetch origin retrieved any remote branches we were not yet setup to track on our local machine. From there, since we now have a ref to the remote branch, we can simply run git checkout remote_branch and we'll gain the benefits of remote tracking.",
                "I tried the above solution, but it didn't work. Try this, it works:This will fetch the remote branch and create a new local branch (if not exists already) with name local_branch_name and track the remote one in it.",
                "This will DWIM for a remote not named origin (documentation):To add a new remote, you will need to do the following first:The first tells Git the remote exists, the second gets the commits.",
                "Use:Other answers do not work with modern Git in my benign case. You might need to pull first if the remote branch is new, but I haven't checked that case.",
                "You basically see the branch, but you don't have a local copy yet!...You need to fetch the branch...You can simply fetch and then checkout to the branch, use the one line command below to do that:I also created the image below for you to share the differences, look at how fetch works and also how it's different to pull:",
                "To clone a Git repository, do:The above command checks out all of the branches, but only the master branch will be initialized. If you want to checkout the other branches, do:This command checks out the remote branch, and your local branch name will be same as the remote branch.If you want to override your local branch name on checkout:Now your local branch name is enhancement, but your remote branch name is future_branch.",
                "You can tryor",
                "I was stuck in a situation seeing error: pathspec 'desired-branch' did not match any file(s) known to git. for all of the suggestions above. I'm on Git version 1.8.3.1.So this worked for me:The explanation behind is that I've noticed that when fetching the remote branch, it was fetched to FETCH_HEAD:",
                "I always do:git fetch origin && git checkout --track origin/branch_name",
                "First, you need to do:git fetch # If you don't know about branch nameSecond, you can check out remote branch into your local by:-b will create new branch in specified name from your selected remote branch.",
                "I use the following command:",
                "Commandsare equal toand thenBoth will create a latest fixes_for_dev from development",
                "Simply run git checkout with the name of the remote branch. Git will automatically create a local branch that tracks the remote one:However, if that branch name is found in more than one remote, this won't work as Git doesn't know which to use. In that case you can use either:orIn 2.19, Git learned the checkout.defaultRemote configuration, which specifies a remote to default to when resolving such an ambiguity.",
                "The git remote show <origin name> command will list all branches (including un-tracked branches). Then you can find the remote branch name that you need to fetch.Example:Use these steps to fetch remote branches:Example:",
                "If the branch is on something other than the origin remote I like to do the following:This will checkout the next branch on the upstream remote in to a local branch called second/next. Which means if you already have a local branch named next it will not conflict.",
                "None of these answers worked for me. This worked:",
                "git fetch && git checkout your-branch-name",
                "git branch -r says the object name is invalid, because that branch name isn't in Git's local branch list. Update your local branch list from origin with:And then try checking out your remote branch again.This worked for me.I believe git fetch pulls in all remote branches, which is not what the original poster wanted.",
                "Fetch from the remote and checkout the branch.E.g.:git fetch origin && git checkout feature/XYZ-1234-Add-alerts",
                "Other guys and gals give the solutions, but maybe I can tell you why.git checkout test which does nothingDoes nothing doesn't equal doesn't work, so I guess when you type 'git checkout test' in your terminal and press enter key, no message appears and no error occurs. Am I right?If the answer is 'yes', I can tell you the cause.The cause is that there is a file (or folder) named 'test' in your work tree.When git checkout xxx parsed,",
                "To get newly created branchesTo switch into another branch",
                "git checkout -b \"Branch_name\" [ B means Create local branch]git branch --allgit checkout -b \"Your Branch name\"git branchgit pull origin \"Your Branch name\"successfully checkout from the master branch to dev branch",
                "There are many alternatives, for example:Alternative 1:It's the simplest way.Alternative 2:It's the same, but in two steps.",
                "TL;DRUsing git switch rather than git checkout. More details are on this page.I think the answer is obsolete. Git split some functions of checkout to switch and restore now.The following is my summary:If you want to update something for a remote branch, you should create a local branch to \"track\" the remote branch. You can update anything you want in local and finally push to remote. If you check out to the remote branch directly after cloning your repository, you may see the \"detached HEAD\" status and the following message from Git:So how can we create a local branch to track a remote branch?To create a local branch to track a remote branch, you can use git checkout <remote branch name> or git switch <remote branch name>. If you have a file or folder has same name as your remote branch name, git checkout would output some error message, but git switch can work normally!Example:See all branches, and we want to create a local branch to track the remote branch remotes/origin/asd, and we also have the file name asd:The filename is same as remote branch, and Git should output some error messages if we are using the git checkout command to create a local branch to track a remote branchIt works if we are using git switch!",
                "I used that one:",
                "To get all remote branches, use this:Then check out to the branch:",
                "For us, it seems the remote.origin.fetch configuration gave a problem. Therefore, we could not see any other remote branches than master, so git fetch [--all] did not help. Neither git checkout mybranch nor git checkout -b mybranch --track origin/mybranch did work, although it certainly was at remote.The previous configuration only allowed master to be fetched:Fix it by using * and fetch the new information from origin:Now we could git checkout the remote branch locally.I don't have any idea how this configuration ended up in our local repository."
            ]
        },
        {
            "tag": "",
            "question": [
                "What does if __name__ == \"__main__\": do?",
                "What does this do, and why should one include the if statement?\nif __name__ == \"__main__\":\n    print(\"Hello, World!\")\r\nIf you are trying to close a question where someone should be ..."
            ],
            "url": "https://stackoverflow.com/questions/419163",
            "answer": [
                "It's boilerplate code that protects users from accidentally invoking the script when they didn't intend to. Here are some common problems when the guard is omitted from a script:If you import the guardless script in another script (e.g. import my_script_without_a_name_eq_main_guard), then the latter script will trigger the former to run at import time and using the second script's command line arguments. This is almost always a mistake.If you have a custom class in the guardless script and save it to a pickle file, then unpickling it in another script will trigger an import of the guardless script, with the same problems outlined in the previous bullet.To better understand why and how this matters, we need to take a step back to understand how Python initializes scripts and how this interacts with its module import mechanism.Whenever the Python interpreter reads a source file, it does two things:it sets a few special variables like __name__, and thenit executes all of the code found in the file.Let's see how this works and how it relates to your question about the __name__ checks we always see in Python scripts.Let's use a slightly different code sample to explore how imports and scripts work.  Suppose the following is in a file called foo.py.When the Python interpreter reads a source file, it first defines a few special variables. In this case, we care about the __name__ variable.When Your Module Is the Main ProgramIf you are running your module (the source file) as the main program, e.g.the interpreter will assign the hard-coded string \"__main__\" to the __name__ variable, i.e.When Your Module Is Imported By AnotherOn the other hand, suppose some other module is the main program and it imports your module. This means there's a statement like this in the main program, or in some other module the main program imports:The interpreter will search for your foo.py file (along with searching for a few other variants), and prior to executing that module, it will assign the name \"foo\" from the import statement to the __name__ variable, i.e.After the special variables are set up, the interpreter executes all the code in the module, one statement at a time. You may want to open another window on the side with the code sample so you can follow along with this explanation.AlwaysIt prints the string \"before import\" (without quotes).It loads the math module and assigns it to a variable called math. This is equivalent to replacing import math with the following (note that __import__ is a low-level function in Python that takes a string and triggers the actual import):It prints the string \"before function_a\".It executes the def block, creating a function object, then assigning that function object to a variable called function_a.It prints the string \"before function_b\".It executes the second def block, creating another function object, then assigning it to a variable called function_b.It prints the string \"before __name__ guard\".Only When Your Module Is the Main ProgramOnly When Your Module Is Imported by AnotherAlwaysSummaryIn summary, here's what'd be printed in the two cases:You might naturally wonder why anybody would want this.  Well, sometimes you want to write a .py file that can be both used by other programs and/or modules as a module, and can also be run as the main program itself.  Examples:Your module is a library, but you want to have a script mode where it runs some unit tests or a demo.Your module is only used as a main program, but it has some unit tests, and the testing framework works by importing .py files like your script and running special test functions. You don't want it to try running the script just because it's importing the module.Your module is mostly used as a main program, but it also provides a programmer-friendly API for advanced users.Beyond those examples, it's elegant that running a script in Python is just setting up a few magic variables and importing the script. \"Running\" the script is a side effect of importing the script's module.Question: Can I have multiple __name__ checking blocks?  Answer: it's strange to do so, but the language won't stop you.Suppose the following is in foo2.py.  What happens if you say python foo2.py on the command-line? Why?",
                "When your script is run by passing it as a command to the Python interpreter,all of the code that is at indentation level 0 gets executed.  Functions and classes that are defined are, well, defined, but none of their code gets run.  Unlike other languages, there's no main() function that gets run automatically - the main() function is implicitly all the code at the top level.In this case, the top-level code is an if block.  __name__ is a built-in variable which evaluates to the name of the current module.  However, if a module is being run directly (as in myscript.py above), then __name__ instead is set to the string \"__main__\".  Thus, you can test whether your script is being run directly or being imported by something else by testingIf your script is being imported into another module, its various function and class definitions will be imported and its top-level code will be executed, but the code in the then-body of the if clause above won't get run as the condition is not met. As a basic example, consider the following two scripts:Now, if you invoke the interpreter asThe output will beIf you run two.py instead:You getThus, when module one gets loaded, its __name__ equals \"one\" instead of \"__main__\".",
                "Create the following two files:Now run each file individually.Running python a.py:When a.py is executed, it imports the module b. This causes all the code inside b to run. Python sets globals()['__name__'] in the b module to the module's name, b.Running python b.py:When only the file b.py is executed, Python sets globals()['__name__'] in this file to \"__main__\". Therefore, the if statement evaluates to True this time.",
                "To outline the basics:The global variable, __name__, in the module that is the entry point to your program, is '__main__'. Otherwise, it's the name you import the module by.So, code under the if block will only run if the module is the entry point to your program.It allows the code in the module to be importable by other modules, without executing the code block beneath on import.Why do we need this?Say you're writing a Python script designed to be used as a module:You could test the module by adding this call of the function to the bottom:and running it (on a command prompt) with something like:However, if you want to import the module to another script:On import, the do_important function would be called, so you'd probably comment out your function call, do_important(), at the bottom.And then you'll have to remember whether or not you've commented out your test function call. And this extra complexity would mean you're likely to forget, making your development process more troublesome.The __name__ variable points to the namespace wherever the Python interpreter happens to be at the moment.Inside an imported module, it's the name of that module.But inside the primary module (or an interactive Python session, i.e. the interpreter's Read, Eval, Print Loop, or REPL) you are running everything from its \"__main__\".So if you check before executing:With the above, your code will only execute when you're running it as the primary module (or intentionally call it from another script).There's a Pythonic way to improve on this, though.What if we want to run this business process from outside the module?If we put the code we want to exercise as we develop and test in a function like this and then do our check for '__main__' immediately after:We now have a final function for the end of our module that will run if we run the module as the primary module.It will allow the module and its functions and classes to be imported into other scripts without running the main function, and will also allow the module (and its functions and classes) to be called when running from a different '__main__' module, i.e.This idiom can also be found in the Python documentation in an explanation of the __main__ module. That text states:This module represents the (otherwise anonymous) scope in which the\n  interpreter\u2019s main program executes \u2014 commands read either from\n  standard input, from a script file, or from an interactive prompt. It\n  is this environment in which the idiomatic \u201cconditional script\u201d stanza\n  causes a script to run:",
                "if __name__ == \"__main__\" is the part that runs when the script is run from (say) the command line using a command like python myscript.py.",
                "__name__ is a global variable (in Python, global actually means on the module level) that exists in all namespaces. It is typically the module's name (as a str type).As the only special case, however, in whatever Python process you run, as in mycode.py:the otherwise anonymous global namespace is assigned the value of '__main__' to its __name__.Thus, including the final lineswill cause your script's uniquely defined main function to run.Another benefit of using this construct: you can also import your code as a module in another script and then run the main function if and when your program decides:",
                "There are lots of different takes here on the mechanics of the code in question, the \"How\", but for me none of it made sense until I understood the \"Why\". This should be especially helpful for new programmers.Take file \"ab.py\":And a second file \"xy.py\":What is this code actually doing?When you execute xy.py, you import ab. The import statement runs the module immediately on import, so ab's operations get executed before the remainder of xy's. Once finished with ab, it continues with xy.The interpreter keeps track of which scripts are running with __name__. When you run a script - no matter what you've named it - the interpreter calls it \"__main__\", making it the master or 'home' script that gets returned to after running an external script.Any other script that's called from this \"__main__\" script is assigned its filename as its __name__ (e.g., __name__ == \"ab.py\"). Hence, the line if __name__ == \"__main__\": is the interpreter's test to determine if it's interpreting/parsing the 'home' script that was initially executed, or if it's temporarily peeking into another (external) script. This gives the programmer flexibility to have the script behave differently if it's executed directly vs. called externally.Let's step through the above code to understand what's happening, focusing first on the unindented lines and the order they appear in the scripts. Remember that function - or def - blocks don't do anything by themselves until they're called. What the interpreter might say if mumbled to itself:The bottom two lines mean: \"If this is the \"__main__\" or 'home' script, execute the function called main()\". That's why you'll see a def main(): block up top, which contains the main flow of the script's functionality.Why implement this?Remember what I said earlier about import statements? When you import a module it doesn't just 'recognize' it and wait for further instructions - it actually runs all the executable operations contained within the script. So, putting the meat of your script into the main() function effectively quarantines it, putting it in isolation so that it won't immediately run when imported by another script.Again, there will be exceptions, but common practice is that main() doesn't usually get called externally. So you may be wondering one more thing: if we're not calling main(), why are we calling the script at all? It's because many people structure their scripts with standalone functions that are built to be run independent of the rest of the code in the file. They're then later called somewhere else in the body of the script. Which brings me to this:But the code works without itYes, that's right. These separate functions can be called from an in-line script that's not contained inside a main() function. If you're accustomed (as I am, in my early learning stages of programming) to building in-line scripts that do exactly what you need, and you'll try to figure it out again if you ever need that operation again ... well, you're not used to this kind of internal structure to your code, because it's more complicated to build and it's not as intuitive to read.But that's a script that probably can't have its functions called externally, because if it did it would immediately start calculating and assigning variables. And chances are if you're trying to re-use a function, your new script is related closely enough to the old one that there will be conflicting variables.In splitting out independent functions, you gain the ability to re-use your previous work by calling them into another script. For example, \"example.py\" might import \"xy.py\" and call x(), making use of the 'x' function from \"xy.py\". (Maybe it's capitalizing the third word of a given text string; creating a NumPy array from a list of numbers and squaring them; or detrending a 3D surface. The possibilities are limitless.)(As an aside, this question contains an answer by @kindall that finally helped me to understand - the why, not the how. Unfortunately it's been marked as a duplicate of this one, which I think is a mistake.)",
                "The code under if __name__ == '__main__': will only be executed if the module is invoked as a script.As an example, consider the following module my_test_module.py:First possibility: Import my_test_module.py in another moduleNow if you invoke main.py:Note that only the top-level print() statement in my_test_module is executed.Second possibility: Invoke my_test_module.py as a scriptNow if you run my_test_module.py as a Python script, both print() statements will be executed:For a more comprehensive explanation, you can read What does if __name__ == '__main__' do in Python.",
                "When there are certain statements in our module (M.py) we want to be executed when it'll be running as main (not imported), we can place those statements (test-cases, print statements) under this if block.As by default (when module running as main, not imported) the __name__ variable is set to \"__main__\", and when it'll be imported the __name__ variable will get a different value, most probably the name of the module ('M').\nThis is helpful in running different variants of a modules together, and separating their specific input & output statements and also if there are any test-cases.In short, use this 'if __name__ == \"main\" ' block to prevent (certain) code from being run when the module is imported.",
                "Put simply, __name__ is a variable defined for each script that defines whether the script is being run as the main module or it is being run as an imported module.So if we have two scripts;andThe output from executing script1 isAnd the output from executing script2 is:As you can see, __name__ tells us which code is the 'main' module.\nThis is great, because you can just write code and not have to worry about structural issues like in C/C++, where, if a file does not implement a 'main' function then it cannot be compiled as an executable and if it does, it cannot then be used as a library.Say you write a Python script that does something great and you implement a boatload of functions that are useful for other purposes. If I want to use them I can just import your script and use them without executing your program (given that your code only executes within the  if __name__ == \"__main__\": context). Whereas in C/C++ you would have to portion out those pieces into a separate module that then includes the file. Picture the situation below;The arrows are import links. For three modules each trying to include the previous modules code there are six files (nine, counting the implementation files) and five links. This makes it difficult to include other code into a C project unless it is compiled specifically as a library. Now picture it for Python:You write a module, and if someone wants to use your code they just import it and the __name__ variable can help to separate the executable portion of the program from the library part.",
                "To be short, you need to know several points:import a action actually runs all that can be run in a.py, meaning each line in a.pyBecause of point 1, you may not want everything to be run in a.py when importing itTo solve the problem in point 2, Python allows you to use a condition check__name__ is an implicit variable in all .py modules:The important thing that Python is special at is point 4! The rest is just basic logic.I've been reading so much throughout the answers on this page. I would say, if you know the thing, for sure you will understand those answers, otherwise, you are still confused.",
                "Let's look at the answer in a more abstract way:Suppose we have this code in x.py:Blocks A and B are run when we are running x.py.But just block A (and not B) is run when we are running another module, y.py for example, in which x.py is imported and the code is run from there (like when a function in x.py is called from y.py).",
                "When you run Python interactively the local __name__ variable is assigned a value of __main__. Likewise, when you execute a Python module from the command line, rather than importing it into another module, its __name__ attribute is assigned a value of __main__, rather than the actual name of the module. In this way, modules can look at their own __name__ value to determine for themselves how they are being used, whether as support for another program or as the main application executed from the command line. Thus, the following idiom is quite common in Python modules:",
                "Consider:It checks if the __name__ attribute of the Python script is \"__main__\". In other words, if the program itself is executed, the attribute will be __main__, so the program will be executed (in this case the main() function).However, if your Python script is used by a module, any code outside of the if statement will be executed, so if __name__ == \"__main__\" is used just to check if the program is used as a module or not, and therefore decides whether to run the code.",
                "Before explaining anything about if __name__ == '__main__' it is important to understand what __name__ is and what it does.__name__ is a DunderAlias - can be thought of as a global variable (accessible from modules) and works in a similar way to global.It is a string (global as mentioned above) as indicated by type(__name__) (yielding <class 'str'>), and is an inbuilt standard for both Python 3 and Python 2 versions.It can not only be used in scripts but can also be found in both the interpreter and modules/packages.test_file.py:Resulting in __main__somefile.py:test_file.py:Resulting in somefileNotice that when used in a package or module, __name__ takes the name of the file.  The path of the actual module or package path is not given, but has its own DunderAlias __file__, that allows for this.You should see that, where __name__, where it is the main file (or program) will always return __main__, and if it is a module/package, or anything that is running off some other Python script, will return the name of the file where it has originated from.Being a variable means that it's value can be overwritten (\"can\" does not mean \"should\"), overwriting the value of __name__ will result in a lack of readability.  So do not do it, for any reason.  If you need a variable define a new variable.It is always assumed that the value of __name__ to be __main__ or the name of the file.  Once again changing this default value will cause more confusion that it will do good, causing problems further down the line.It is considered good practice in general to include the if __name__ == '__main__' in scripts.Now we know the behaviour of __name__ things become clearer:An if is a flow control statement that contains the block of code will execute if the value given is true. We have seen that __name__ can take either\n__main__ or the file name it has been imported from.This means that if __name__ is equal to __main__ then the file must be the main file and must actually be running (or it is the interpreter), not a module or package imported into the script.If indeed __name__ does take the value of __main__ then whatever is in that block of code will execute.This tells us that if the file running is the main file (or you are running from the interpreter directly) then that condition must execute.  If it is a package then it should not, and the value will not be __main__.__name__ can also be used in modules to define the name of a moduleIt is also possible to do other, less common but useful things with __name__, some I will show here:You can also use it to provide runnable help functions/utilities on packages and modules without the elaborate use of libraries.It also allows modules to be run from the command line as main scripts, which can be also very useful.",
                "I think it's best to break the answer in depth and in simple words:__name__: Every module in Python has a special attribute called __name__.\nIt is a built-in variable that returns the name of the module.__main__: Like other programming languages, Python too has an execution entry point, i.e., main. '__main__' is the name of the scope in which top-level code executes. Basically you have two ways of using a Python module: Run it directly as a script, or import it. When a module is run as a script, its __name__ is set to __main__.Thus, the value of the __name__ attribute is set to __main__ when the module is run as the main program. Otherwise the value of __name__  is set to contain the name of the module.",
                "It is a special for when a Python file is called from the command line. This is typically used to call a \"main()\" function or execute other appropriate startup code, like commandline arguments handling for instance.It could be written in several ways. Another is:I am not saying you should use this in production code, but it serves to illustrate that there is nothing \"magical\" about if __name__ == '__main__'.It just a convention for invoking a main function in Python files.",
                "There are a number of variables that the system (Python interpreter) provides for source files (modules).  You can get their values anytime you want, so, let us focus on the __name__ variable/attribute:When Python loads a source code file, it executes all of the code found in it. (Note that it doesn't call all of the methods and functions defined in the file, but it does define them.)Before the interpreter executes the source code file though, it defines a few special variables for that file; __name__ is one of those special variables that Python automatically defines for each source code file.If Python is loading this source code file as the main program (i.e. the file you run), then it sets the special __name__ variable for this file to have a value \"__main__\".If this is being imported from another module, __name__ will be set to that module's name.So, in your example in part:means that the code block:will be executed only when you run the module directly; the code block will not execute if another module is calling/importing it because the value of __name__ will not equal to \"main\" in that particular instance.Hope this helps out.",
                "if __name__ == \"__main__\": is basically the top-level script environment, and it specifies the interpreter that ('I have the highest priority to be executed first').'__main__' is the name of the scope in which top-level code executes. A module\u2019s __name__ is set equal to '__main__' when read from standard input, a script, or from an interactive prompt.",
                "Consider:The output for the above is __main__.The above statement is true and prints \"direct method\". Suppose if they imported this class in another class it doesn't print \"direct method\" because, while importing, it will set __name__ equal to \"first model name\".",
                "In simple words:The code you see under if __name__ == \"__main__\": will only get called upon when your Python file is executed as python example1.pyHowever, if you wish to import your Python file example1.py as a module to work with another Python file, say example2.py, the code under if __name__ == \"__main__\": will not run or take any effect.",
                "You can make the file usable as a script as well as an importable module.fibo.py (a module named fibo)Reference: https://docs.python.org/3.5/tutorial/modules.html",
                "The reason foris primarily to avoid the import lock problems that would arise from having code directly imported. You want main() to run if your file was directly invoked (that's the __name__ == \"__main__\" case), but if your code was imported then the importer has to enter your code from the true main module to avoid import lock problems.A side-effect is that you automatically sign on to a methodology that supports multiple entry points. You can run your program using main() as the entry point, but you don't have to. While setup.py expects main(), other tools use alternate entry points. For example, to run your file as a gunicorn process, you define an app() function instead of a main(). Just as with setup.py, gunicorn imports your code so you don't want it do do anything while it's being imported (because of the import lock issue).",
                "If you are a beginner, probably the only answer you need right now is that this code is unnecessary for a simple script. It is only useful if you want to be able to import your script (or unpickle etc; see the other answers here for some other non-beginner scenarios).In slightly different words, the if __name__ guard is a mechanism for hiding code from other code. If you don't have a specific reason to hide something, don't: If you don't need to hide some code from import, don't put it behind this guard, and if you do, hide as little as possible.In slightly more detail, let's say you have a simple script fib.py (adapted from this answer):Now, if you simply run python fib.py it works fine. But __name__ will always be \"__main__\" in this scenario, so the condition is actually unnecessary. The script could be simplified to justNow, you can't import fib with the new version, but if you didn't plan to do that in the first place, this version is actually better, because it's simpler and clearer.If you do want to be able to import fib, the first version is useless, too, because the useful code is in a section which will not run when you import this file (in which case __name__ will not be \"__main__\"). The proper design in that case would be to refactor the code so that the useful parts are in a function you can run when you want to after you have imported it.Now, if you import fib, the call to main() will not be executed; but when you run python fib.py, it will.Actually, a better design still would be to isolate the reusable part (the actual calculation) from the user-visible input/output:Now, you can from fib import fibn and call the fibn() function from the code which performs this import.(I called the function fibn() just to make it clearer what is what in this example. In real life, you might call it fib() and do from fib import fib.)Similarly, you could import and call the main function if you wanted to reuse it.Returning to the code in the question, I would similarly move the code from the if into a function as well, so that callers can invoke that function if they want to.This changes the scope of the lock variable; if the surrounding code needs access to it, you will need to make it global (or, perhaps, better, refactor main to return lock, and have the caller capture the value in a local variable of its own).(Unlike in languages like C, the name main has no specific meaning to Python; but it's a common convention to use it as the name of the thing which will be run. You still have to actually explicitly call it, like main(), unlike in C.)",
                "Every module in Python has an attribute called __name__. The value of __name__  attribute is  __main__ when the module is run directly, like python my_module.py. Otherwise (like when you say import my_module) the value of __name__  is the name of the module.Small example to explain in short.We can execute this directly asOutputNow suppose we call the above script from another script:When you execute this,OutputSo, the above is self-explanatory that when you call test from another script, if loop __name__ in test.py will not execute.",
                "This answer is for Java programmers learning Python.\nEvery Java file typically contains one public class. You can use that class in two ways:Call the class from other files. You just have to import it in the calling program.Run the class stand alone, for testing purposes.For the latter case, the class should contain a public static void main() method. In Python this purpose is served by the globally defined label '__main__'.",
                "If this .py file are imported by other .py files, the code under the if statement will not be executed.If this .py are run by python this_py.py under shell, or double clicked in Windows. the code under the if statement will be executed.It is usually written for testing.",
                "We see if __name__ == '__main__': quite often.It checks if a module is being imported or not.In other words, the code within the if block will be executed only when the code runs directly. Here directly means not imported.Let's see what it does using a simple code that prints the name of the module:If we run the code directly via python test.py, the module name is __main__:",
                "If the Python interpreter is running a particular module then the __name__ global variable will have the value \"__main__\":When you run this script, it prints:If you import this file, say A to file B, and execute the file B then if __name__ == \"__main__\" in file A becomes False, so it prints:",
                "All the answers have pretty much explained the functionality. But I will provide one example of its usage which might help clearing out the concept further.Assume that you have two Python files, a.py and b.py. Now, a.py imports b.py. We run the a.py file, where the import b.py code is executed first. Before the rest of the a.py code runs, the code in the file b.py must run completely.In the b.py code, there is some code that is exclusive to that file b.py and we don't want any other file (other than the b.py file), that has imported the b.py file, to run it.So that is what this line of code checks. If it is the main file (i.e., b.py) running the code, which in this case it is not (a.py is the main file running), then only the code gets executed."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I remove local (untracked) files from the current Git working tree?",
                "How do I delete untracked local files from the current working tree?"
            ],
            "url": "https://stackoverflow.com/questions/61212",
            "answer": [
                "Cleans the working tree by recursively removing files that are not under version control, starting from the current directory.Normally, only files unknown to Git are removed, but if the -x option is specified, ignored files are also removed. This can, for example, be useful to remove all build products.If any optional <path>... arguments are given, only those paths are affected.Step 1 is to show what will be deleted by using the -n option:Clean Step - beware: this will delete files:Note the case difference on the X for the two latter commands.If clean.requireForce is set to \"true\" (the default) in your configuration, one needs to specify -f otherwise nothing will actually happen.Again see the git-clean docs for more information.-f, --forceIf the Git configuration variable clean.requireForce is not set to\nfalse, git clean will refuse to run unless given -f, -n or -i.-xDon\u2019t use the standard ignore rules read from .gitignore (per\ndirectory) and $GIT_DIR/info/exclude, but do still use the ignore\nrules given with -e options. This allows removing all untracked files,\nincluding build products. This can be used (possibly in conjunction\nwith git reset) to create a pristine working directory to test a clean\nbuild.-XRemove only files ignored by Git. This may be useful to rebuild\neverything from scratch, but keep manually created files.-n, --dry-runDon\u2019t actually remove anything, just show what would be done.-dRemove untracked directories in addition to untracked files. If an\nuntracked directory is managed by a different Git repository, it is\nnot removed by default. Use -f option twice if you really want to\nremove such a directory.",
                "Use git clean -f -d to make sure that directories are also removed.Don\u2019t actually remove anything, just show what would be done.orRemove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository, it is not removed by default. Use the -f option twice if you really want to remove such a directory.You can then check if your files are really gone with git status.",
                "I am surprised nobody mentioned this before:That stands for interactive and you will get a quick overview of what is going to be deleted offering you the possibility to include/exclude the affected files. Overall, still faster than running the mandatory --dry-run before the real cleaning.You will have to toss in a -d if you also want to take care of empty folders. At the end, it makes  for a nice alias:That being said, the extra hand holding of interactive commands can be tiring for experienced users.  These days I just use the already mentioned git clean -fd",
                "git-clean - Remove untracked files from the working tree",
                "To remove all untracked files, The simple\nway is to add all of them first and reset the repo as below",
                "If untracked directory is a git repository of its own (e.g. submodule), you need to use -f twice:git clean -d -f -f",
                "This is what I always use:For a very large project you might want to run it a couple of times.",
                "I like git stash push -u because you can undo them all with git stash pop.EDIT: Also I found a way to show untracked file in a stash (e.g. git show stash@{0}^3) https://stackoverflow.com/a/12681856/338986EDIT2: git stash save is deprecated in favor of push. Thanks @script-wolf.",
                "Always use -n before running the clean command as it will show you what files would get removed.-d Normally, when no  is specified, git clean will not recurse into untracked directories to avoid removing too much. Specify -d to have it recurse into such directories as well. If any paths are specified, -d is irrelevant; all untracked files matching the specified paths (with exceptions for nested git directories mentioned under --force) will be removed.-f | --force\nIf the Git configuration variable clean.requireForce is not set to false, git clean will refuse to delete files or directories unless given -f or -i. Git will refuse to modify untracked nested git repositories (directories with a .git subdirectory) unless a second -f is given.Now run without -n if output was what you intend to remove.By default, git clean will only remove untracked files that are not ignored. Any file that matches a pattern in your .gitignore or other ignore files will not be removed. If you want to remove those files too, you can add a -x to the clean command.There is also interactive mode available -i with the clean commandBefore you use stash --all note:\nIf the --all option is used, then the ignored files are stashed and cleaned in addition to the untracked files.If the --keep-index option is used, all changes already added to the index are left intact. Your staged changes remain in your workspace, but at the same time, they are also saved into your stash.Calling git stash without any arguments is equivalent to git stash push.Stashing based on the used flags can clear your directory from unstaged / staged files by writing them to stash storage. I give\u2019s flexibility to retrieve the files at any point in time using stash with apply or pop. Then if you are fine with removing your stashed files you could run:To see full instruction on how to work with stash see this How to name and retrieve a stash by name in git?",
                "git-clean is what you are looking for. It is used to remove untracked files from the working tree.",
                "If needed to remove untracked files from particular subdirectory,And combined way to delete untracked dir/files and ignored files.after this you will have modified files only in git status.",
                "Remove all extra folders and files in this repo + submodulesThis gets you in same state as fresh clone.Remove all extra folders and files in this repo but not its submodulesRemove extra folders but not files (ex. build or logs folder)Remove extra folders + ignored files (but not newly added files)If file wasn't ignored and not yet checked-in then  it stays. Note the capital X.New interactive mode",
                "git clean -fd removes directorygit clean -fX removes ignored filesgit clean -fx removes ignored and un-ignored filescan be used all above options in combination asgit clean -fdXxcheck git manual for more help",
                "OK, deleting unwanted untracked files and folders are easy using git in command line, just do it like this:Double check before doing it as it will delete the files and folders without making any history...Also in this case, -f stands for force and -d stands for directory...So, if you want to delete files only, you can use -f only:If you want to delete(directories) and files, you can delete only untracked directories and files like this:Also, you can use -x flag for including the files which are ignored by git. This would be helpful if you want to delete everything.And adding -i flag, makes git asking you for permission for deleting files one by one on the go.If you not sure and want to check things first, add -n flag.Use -q if you don't want to see any report after successful deletion.I also create the image below to make it more memorable, especially I have seen many people confuse -f for cleaning folder sometimes or mix it up somehow!",
                "A better way is to use: git cleanThis removes untracked files, including directories (-d) and files ignored by git (-x).Also, replace the -f argument with -n to perform a dry-run or -i for interactive mode and it will tell you what will be removed.",
                "User interactive approach:-i for interactive\n-f for force\n-d for directory\n-x for ignored files(add if required)\nNote: Add -n or --dry-run to just check what it will do.",
                "To remove Untracked files :",
                "A lifehack for such situation I just invented and tried (that works perfectly):Beware! Be sure to commit any needed changes (even in non-untracked files) before performing this.",
                "For me only following worked:In all other cases, I was getting message \"Skipping Directory\" for some subdirectories.",
                "git clean -f -d -x $(git rev-parse --show-cdup) applies clean to the root directory, no matter where you call it within a repository directory tree. I use it all the time as it does not force you to leave the folder where you working now and allows to clean & commit right from the place where you are.Be sure that flags -f, -d, -x match your needs:There are other flags as well available, just check git clean --help.",
                "If you just want to delete the files listed as untracked by 'git status'I prefer this to 'git clean' because 'git clean' will delete files\nignored by git, so your next build will have to rebuild everything\nand you may lose your IDE settings too.",
                "To know what will be deleted before actually deleting:git clean -d -nIt will output something like:Would remove sample.txtTo delete everything listed in the output of the previous command:git clean -d -fIt will output something like:Removing sample.txt",
                "git add --all, git stash and git stash drop, try these three commands in this order inorder to remove all untracked files. By adding all those untracked files to git and stashing them will move all those untracked files to stash list and dropping out top one i.e., stash@{0} will remove the stashed changes from stash list.",
                "To remove the untracked files you should first use command to view the files that will be affected by cleaningThis will show you the list of files that will be deleted. Now to actually delete those files use this command:",
                "uggested Command for Removing Untracked Files from git docs is git cleangit clean - Remove untracked files from the working treeSuggested Method:  Interative Mode by using git clean -i\nso we can have control over it. let see remaining available options.Available Options:Explanation:1. -dRemove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository,\n   it is not removed by default. Use -f option twice if you really want to remove such a directory.2. -f, --forceIf the Git configuration variable clean.requireForce is not set to false, git clean will refuse to run unless given -f, -n or\n   -i.3. -i, --interactiveShow what would be done and clean files interactively. See \u201cInteractive mode\u201d for details.4. -n, --dry-runDon\u2019t actually remove anything, just show what would be done.5. -q, --quietBe quiet, only report errors, but not the files that are successfully removed.6. -e , --exclude=In addition to those found in .gitignore (per directory) and $GIT_DIR/info/exclude, also consider these patterns to be in the\n   set of the ignore rules in effect.7. -xDon\u2019t use the standard ignore rules read from .gitignore (per directory) and $GIT_DIR/info/exclude, but do still use the ignore\n   rules given with -e options. This allows removing all untracked files, including build products. This can be used (possibly in\n   conjunction with git reset) to create a pristine working directory to test a clean build.8. -XRemove only files ignored by Git. This may be useful to rebuild everything from scratch, but keep manually created files.",
                "git clean -f to remove untracked files from working directory.I have covered some basics here in my blog, git-intro-basic-commands",
                "Normal git clean command doesn't remove untracked files with my git version 2.9.0.windows.1.",
                "We can easily removed local untracked files from the current git working tree by using below git comments.Example:Links :",
                "The following command will clean out\n  the current git repository and all its submodules recursively:",
                "oh-my-zsh with zsh provides those great aliases via the git plugin. They can be used in bash as well.gclean='git clean -fd'\ngpristine='git reset --hard && git clean -dfx'"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I redirect to another webpage?",
                "How can I redirect the user from one page to another using jQuery or pure JavaScript?"
            ],
            "url": "https://stackoverflow.com/questions/503093",
            "answer": [
                "jQuery is not necessary, and window.location.replace(...) will best simulate an HTTP redirect.window.location.replace(...) is better than using window.location.href, because replace() does not keep the originating page in the session history, meaning the user won't get stuck in a never-ending back-button fiasco.If you want to simulate someone clicking on a link, use\n location.hrefIf you want to simulate an HTTP redirect, use location.replaceFor example:",
                "WARNING: This answer has merely been provided as a possible solution; it is obviously not the best solution, as it requires jQuery. Instead, prefer the pure JavaScript solution.",
                "If you are here because you are losing HTTP_REFERER when redirecting, keep reading:(Otherwise ignore this last part)The following section is for those using HTTP_REFERER as one of many security measures (although it isn't a great protective measure). If you're using Internet\u00a0Explorer\u00a08 or lower, these variables get lost when using any form of JavaScript page redirection (location.href,  etc.).Below we are going to implement an alternative for IE8 & lower so that we don't lose HTTP_REFERER. Otherwise, you can almost always simply use window.location.href.Testing against HTTP_REFERER (URL pasting, session, etc.) can help tell whether a request is legitimate.\n(Note: there are also ways to work-around / spoof these referrers, as noted by droop's link in the comments)Simple cross-browser testing solution (fallback to window.location.href for Internet\u00a0Explorer\u00a09+ and all other browsers)Usage: redirect('anotherpage.aspx');",
                "There are lots of ways of doing this.",
                "This works for every browser:",
                "It would help if you were a little more descriptive in what you are trying to do.  If you are trying to generate paged data, there are some options in how you do this.  You can generate separate links for each page that you want to be able to get directly to.Note that the current page in the example is handled differently in the code and with CSS.If you want the paged data to be changed via AJAX, this is where jQuery would come in.  What you would do is add a click handler to each of the anchor tags corresponding to a different page.  This click handler would invoke some jQuery code that goes and fetches the next page via AJAX and updates the table with the new data.  The example below assumes that you have a web service that returns the new page data.",
                "I also think that location.replace(URL) is the best way, but if you want to notify the search engines about your redirection (they don't analyze JavaScript code to see the redirection) you should add the rel=\"canonical\" meta tag to your website.Adding a noscript section with a HTML refresh meta tag in it, is also a good solution. I suggest you to use this JavaScript redirection tool to create redirections. It also has Internet\u00a0Explorer support to pass the HTTP referrer.Sample code without delay looks like this:",
                "But if someone wants to redirect back to home page then he may use the following snippet.It would be helpful if you have three different environments as development, staging, and production.You can explore this window or window.location object by just putting these words in Chrome Console or Firebug's Console.",
                "JavaScript provides you many methods to retrieve and change the current URL which is displayed in browser's address bar. All these methods uses the Location object, which is  a property of the Window object. You can create a new Location object that has the current URL as follows..Basic Structure of a URLProtocol -- Specifies the protocol name be used to access the resource on the Internet. (HTTP (without SSL) or HTTPS (with SSL))hostname -- Host name specifies the host that owns the resource. For example, www.stackoverflow.com. A server provides services using the name of the host.port -- A port number used to recognize a specific process to which an Internet or other network message is to be forwarded when it arrives at a server.pathname -- The path gives info about the specific resource within the host that the Web client wants to access. For example, stackoverflow.com/index.html.query --  A query string follows the path component, and provides a string of information that the resource can utilize for some purpose (for example, as parameters for a search or as data to be processed).hash -- The anchor portion of a URL, includes the hash sign (#).With these Location object properties you can access all of these URL componentsNow If you want to change a page or redirect the user to some other page you can use the href property of the Location object like thisYou can use the href property of the Location object.Location Object also have these three methodsYou can use assign() and replace methods also to redirect to other pages like theseHow assign() and replace() differs -- The difference between replace() method and assign() method(), is that replace() removes the URL of the current document from the document history, means it is not possible to use the \"back\" button to navigate back to the original document. So Use the assign() method if you want to load a new document, andwant to give the option to navigate back to the original document.You can change the location object href property using jQuery also  like thisAnd hence you can redirect the user to some other url.",
                "Basically jQuery is just a JavaScript framework and for doing some of the things like redirection in this case, you can just use pure JavaScript, so in that case you have 3 options using vanilla JavaScript:1) Using location replace, this will replace the current history of the page, means that it is not possible to use the back button to go back to the original page.2) Using location assign, this will keep the history for you and with using back button, you can go back to the original page:3) I recommend using one of those previous ways, but this could be the third option using pure JavaScript:You can also write a function in jQuery to handle it, but not recommended as it's only one line pure JavaScript function, also you can use all of above functions without window if you are already in the window scope, for example window.location.replace(\"http://stackoverflow.com\"); could be location.replace(\"http://stackoverflow.com\");Also I show them all on the image below:",
                "Should just be able to set using window.location.Example:Here is a past post on the subject: How do I redirect to another webpage?",
                "Before I start, jQuery is a JavaScript library used for DOM manipulation. So you should not be using jQuery for a page redirect.A quote from Jquery.com:While jQuery might run without major issues in older browser versions,\nwe do not actively test jQuery in them and generally do not fix bugs\nthat may appear in them.It was found here:\nhttps://jquery.com/browser-support/So jQuery is not an end-all and be-all solution for backwards compatibility.The following solution using raw JavaScript works in all browsers and have been standard for a long time so you don't need any libraries for cross browser support.This page will redirect to Google after 3000 millisecondsDifferent options are as follows:When using replace, the back button will not go back to the redirect page, as if it was never in the history. If you want the user to be able to go back to the redirect page then use window.location.href or window.location.assign. If you do use an option that lets the user go back to the redirect page, remember that when you enter the redirect page it will redirect you back. So put that into consideration when picking an option for your redirect. Under conditions where the page is only redirecting when an action is done by the user then having the page in the back button history will be okay. But if the page auto redirects then you should use replace so that the user can use the back button without getting forced back to the page the redirect sends.You can also use meta data to run a page redirect as followed.META RefreshMETA LocationBASE HijackingMany more methods to redirect your unsuspecting client to a page they may not wish to go can be found on this page (not one of them is reliant on jQuery):https://code.google.com/p/html5security/wiki/RedirectionMethodsI would also like to point out, people don't like to be randomly redirected. Only redirect people when absolutely needed. If you start redirecting people randomly they will never go to your site again.The next paragraph is hypothetical:You also may get reported as a malicious site. If that happens then when people click on a link to your site the users browser may warn them that your site is malicious. What may also happen is search engines may start dropping your rating if people are reporting a bad experience on your site.Please review Google Webmaster Guidelines about redirects:\nhttps://support.google.com/webmasters/answer/2721217?hl=en&ref_topic=6001971Here is a fun little page that kicks you out of the page.If you combine the two page examples together you would have an infant loop of rerouting that will guarantee that your user will never want to use your site ever again.",
                "You can do that without jQuery as:And if you want only jQuery then you can do it like:",
                "This works with jQuery:",
                "# HTML Page Redirect Using jQuery/JavaScript MethodTry this example code:If you want to give a complete URL as window.location = \"www.google.co.in\";.",
                "Original question: \"How to redirect using jQuery?\", hence the answer implements jQuery >> Complimentary usage case.To just redirect to a page with JavaScript:Or if you need a delay:jQuery allows you to select elements from a web page with ease. You can find anything you want on a page and then use jQuery to add special effects, react to user actions, or show and hide content inside or outside the element you have selected. All these tasks start with knowing how to select an element or an event.Imagine someone wrote a script/plugin with 10000 lines of code. With jQuery you can connect to this code with just a line or two.",
                "So, the question is how to make a redirect page, and not how to redirect to a website?You only need to use JavaScript for this. Here is some tiny code that will create a dynamic redirect page.So say you just put this snippet into a redirect/index.html file on your website you can use it like so.http://www.mywebsite.com/redirect?url=http://stackoverflow.comAnd if you go to that link it will automatically redirect you to stackoverflow.com.Link to DocumentationAnd that's how you make a Simple redirect page with JavaScriptEdit:There is also one thing to note. I have added window.location.replace in my code because I think it suits a redirect page, but, you must know that when using window.location.replace and you get redirected, when you press the back button in your browser it will not got back to the redirect page, and it will go back to the page before it, take a look at this little demo thing.Example:The process: store home => redirect page to google => googleWhen at google: google => back button in browser => store homeSo, if this suits your needs then everything should be fine. If you want to include the redirect page in the browser history replace thiswith",
                "You need to put this line in your code:If you don't have jQuery, go with JavaScript:",
                "On your click function, just add:",
                "Try this:Code snippet of example.",
                "jQuery is not needed. You can do this:It is that easy!The best way to initiate an HTTP request is with document.loacation.href.replace('URL').",
                "First write properly. You want to navigate within an application for another link from your application for another link. Here is the code:And if you want to navigate pages within your application then I also have code, if you want.",
                "You can redirect in jQuery like this:",
                "JavaScript is very extensive. If you want to jump to another page you have three options.As you want to move to another page, you can use any from these if this is your requirement.\nHowever all three options are limited to different situations. Chose wisely according to your requirement.If you are interested in more knowledge about the concept, you can go through further.",
                "In JavaScript and jQuery we can use the following code to redirect the one page to another page:",
                "Please don't kill me, this is a joke. It's a joke. This is a joke.This did \"provide an answer to the question\", in the sense that it asked for a solution \"using jQuery\" which in this case entails forcing it into the equation somehow.Ferrybig apparently needs the joke explained (still joking, I'm sure there are limited options on the review form), so without further ado:Other answers are using jQuery's attr() on the location or window objects unnecessarily.This answer also abuses it, but in a more ridiculous way. Instead of using it to set the location, this uses attr() to retrieve a function that sets the location.The function is named jQueryCode even though there's nothing jQuery about it, and calling a function somethingCode is just horrible, especially when the something is not even a language.The \"85 bytes\" is a reference to Code Golf. Golfing is obviously not something you should do outside of code golf, and furthermore this answer is clearly not actually golfed.Basically, cringe.",
                "Javascript:Jquery:",
                "Here is a time-delay redirection. You can set the delay time to whatever you want:"
            ]
        },
        {
            "tag": "",
            "question": [
                "How to modify existing, unpushed commit messages?",
                "I wrote the wrong thing in a commit message.\n\nHow can I change the message? The commit has not been pushed yet."
            ],
            "url": "https://stackoverflow.com/questions/179123",
            "answer": [
                "will open your editor, allowing you to change the commit message of the most recent commit. Additionally, you can set the commit message directly in the command line with:\u2026however, this can make multi-line commit messages or small corrections more cumbersome to enter.Make sure you don't have any working copy changes staged before doing this or they will get committed too. (Unstaged changes will not get committed.)If you've already pushed your commit up to your remote branch, then - after amending your commit locally (as described above) - you'll also need to force push the commit with:Warning: force-pushing will overwrite the remote branch with the state of your local one. If there are commits on the remote branch that you don't have in your local branch, you will lose those commits.Warning: be cautious about amending commits that you have already shared with other people. Amending commits essentially rewrites them to have different SHA IDs, which poses a problem if other people have copies of the old commit that you've rewritten. Anyone who has a copy of the old commit will need to synchronize their work with your newly re-written commit, which can sometimes be difficult, so make sure you coordinate with others when attempting to rewrite shared commit history, or just avoid rewriting shared commits altogether.Another option is to use interactive rebase.\nThis allows you to edit any message you want to update even if it's not the latest message.In order to do a Git squash, follow these steps:Once you squash your commits - choose the e/r for editing the message:When you use git rebase -i HEAD~n there can be more than n commits. Git will \"collect\" all the commits in the last n commits, and if there was a merge somewhere in between that range you will see all the commits as well, so the outcome will be n + .If you have to do it for more than a single branch and you might face conflicts when amending the content, set up git rerere and let Git resolve those conflicts automatically for you.git-commit(1) Manual Pagegit-rebase(1) Manual Pagegit-push(1) Manual Page",
                "If the commit you want to fix isn\u2019t the most recent one:git rebase --interactive $parent_of_flawed_commitIf you want to fix several flawed commits, pass the parent of the oldest one of them.An editor will come up, with a list of all commits since the one you gave.For each commit you want to reword, Git will drop you back into your editor. For each commit you want to edit, Git drops you into the shell. If you\u2019re in the shell:Most of this sequence will be explained to you by the output of the various commands as you go. It\u2019s very easy; you don\u2019t need to memorise it \u2013 just remember that git rebase --interactive lets you correct commits no matter how long ago they were.Note that you will not want to change commits that you have already pushed. Or maybe you do, but in that case you will have to take great care to communicate with everyone who may have pulled your commits and done work on top of them. How do I recover/resynchronise after someone pushes a rebase or a reset to a published branch?",
                "To amend the previous commit, make the changes you want and stage those changes, and then runThis will open a file in your text editor representing your new commit message. It starts out populated with the text from your old commit message. Change the commit message as you want, then save the file and quit your editor to finish.To amend the previous commit and keep the same log message, runTo fix the previous commit by removing it entirely, runIf you want to edit more than one commit message, run(Replace commit_count with number of commits that you want to edit.) This command launches your editor. Mark the first commit (the one that you want to change) as \u201cedit\u201d instead of \u201cpick\u201d, then save and exit your editor. Make the change you want to commit and then runNote: You can also \"Make the change you want\" from the editor opened by git commit --amend",
                "As already mentioned, git commit --amend is the way to overwrite the last commit. One note: if you would like to also overwrite the files, the command would be",
                "You also can use git filter-branch for that.It's not as easy as a trivial git commit --amend, but it's especially useful, if you already have some merges after your erroneous commit message.Note that this will try to rewrite every commit between HEAD and the flawed commit, so you should choose your msg-filter command very wisely ;-)",
                "I prefer this way:Otherwise, there will be a new commit with a new commit ID.",
                "If you are using the Git GUI tool, there is a button named Amend last commit. Click on that button and then it will display your last commit files and message. Just edit that message, and you can commit it with a new commit message.Or use this command from a console/terminal:",
                "You can use Git rebasing. For example, if you want to modify back to commit bbc643cd, runIn the default editor, modify 'pick' to 'edit' in the line whose commit you want to modify. Make your changes and then stage them withNow you can useto modify the commit, and after thatto return back to the previous head commit.",
                "If you only want to modify your last commit message, then do:That will drop you into your text editor and let you change the last commit message.If you want to change the last three commit messages, or any of the commit messages up to that point, supply HEAD~3 to the git rebase -i command:",
                "If you have to change an old commit message over multiple branches (i.e., the commit with the erroneous message is present in multiple branches) you might want to use:Git will create a temporary directory for rewriting and additionally backup old references in refs/original/.-f will enforce the execution of the operation. This is necessary if the temporary directory is already present or if there are already references stored under refs/original. If that is not the case, you can drop this flag.-- separates filter-branch options from revision options.--all will make sure that all branches and tags are rewritten.Due to the backup of your old references, you can easily go back to the state before executing the command.Say, you want to recover your master and access it in branch old_master:",
                "If it's your last commit, just amend the commit:(Using the -o (--only) flag to make sure you change only the commit message)If it's a buried commit, use the awesome interactive rebase:Find the commit you want, change pick to r (reword), and save and close the file. Done!Miniature Vim tutorial (or, how to rebase with only 8 keystrokes 3jcwrEscZZ):If you edit text a lot, then switch to the Dvorak keyboard layout, learn to touch-type, and learn Vim. Is it worth the effort? Yes.ProTip\u2122: Don't be afraid to experiment with \"dangerous\" commands that rewrite history* \u2014 Git doesn't delete your commits for 90 days by default; you can find them in the reflog:* Watch out for options like --hard and --force though \u2014 they can discard data.\n*  Also, don't rewrite history on any branches you're collaborating on.",
                "UseTo understand it in detail, an excellent post is 4. Rewriting Git History. It also talks about when not to use git commit --amend.",
                "You have a couple of options here. You can doas long as it's your last commit.Otherwise, if it's not your last commit, you can do an interactive rebase,Then inside the interactive rebase you simply add edit to that commit. When it comes up, do a git commit --amend and modify the commit message. If you want to roll back before that commit point, you could also use git reflog and just delete that commit. Then you just do a git commit again.",
                "If you are using the Git GUI, you can amend the last commit which hasn't been pushed with:",
                "I use the Git GUI as much as I can, and that gives you the option to amend the last commit:Also, git rebase -i origin/masteris a nice mantra that will always present you with the commits you have done on top of master, and give you the option to amend, delete, reorder or squash. No need to get hold of that hash first.",
                "For anyone looking for a Windows/Mac GUI to help with editing older messages (i.e. not just the latest message), I'd recommend Sourcetree. The steps to follow are below the image.For commits that haven't been pushed to a remote yet:...Or... for commits that have already been pushed:Follow the steps in this answer, which are similar to above, but require a further command to be run from the command line (git push origin <branch> -f) to force-push the branch. I'd recommend reading it all and applying the necessary caution!",
                "Wow, so there are a lot of ways to do this.Yet another way to do this is to delete the last commit, but keep its changes so that you won't lose your work. You can then do another commit with the corrected message. This would look something like this:I always do this if I forget to add a file or do a change.Remember to specify --soft instead of --hard, otherwise you lose that commit entirely.",
                "If you just want to edit the latest commit, use:orBut if you want to edit several commits in a row, you should use rebasing instead:In a file, like the one above, write edit/e or one of the other options, and hit save and exit.Now you'll be at the first wrong commit. Make changes in the files, and they'll be automatically staged for you. TypeSave and exit that and typeto move to next selection until finished with all your selections.Note that these things change all your SHA hashes after that particular commit.",
                "If you only want to change your last message you should use the --only flag or its shortcut -o with commit --amend:This ensures that you don't accidentally enhance your commit with staged stuff. Of course it's best to have a proper $EDITOR configuration. Then you can leave the -m option out, and Git will pre-fill the commit message with the old one. In this way it can be easily edited.",
                "Update your last wrong commit message with the new commit message in one line:Or, try Git reset like below:git reset can help you to break one commit into multiple commits too:Here you have successfully broken your last commit into two commits.",
                "On this question there are a lot of answers, but none of them explains in super detail how to change older commit messages using Vim. I was stuck trying to do this myself, so here I'll write down in detail how I did this especially for people who have no experience in Vim!I wanted to change my five latest commits that I already pushed to the server. This is quite 'dangerous' because if someone else already pulled from this, you can mess things up by changing the commit messages. However, when you\u2019re working on your own little branch and are sure no one pulled it you can change it like this:Let's say you want to change your five latest commits, and then you type this in the terminal:*Where 5 is the number of commit messages you want to change (so if you want to change the 10th to last commit, you type in 10).This command will get you into Vim there you can \u2018edit\u2019 your commit history. You\u2019ll see your last five commits at the top like this:Instead of pick you need to write reword. You can do this in Vim by typing in i. That makes you go in to insert mode. (You see that you\u2019re in insert mode by the word INSERT at the bottom.) For the commits you want to change, type in reword instead of pick.Then you need to save and quit this screen. You do that by first going in to \u2018command-mode\u2019 by pressing the Escbutton (you can check that you\u2019re in command-mode if the word INSERT at the bottom has disappeared). Then you can type in a command by typing :. The command to save and quit is wq. So if you type in :wq you\u2019re on the right track.Then Vim will go over every commit message you want to reword, and here you can actually change the commit messages. You\u2019ll do this by going into insert mode, changing the commit message, going into the command-mode, and save and quit. Do this five times and you\u2019re out of Vim!Then, if you already pushed your wrong commits, you need to git push --force to overwrite them. Remember that git push --force is quite a dangerous thing to do, so make sure that no one pulled from the server since you pushed your wrong commits!Now you have changed your commit messages!(As you see, I'm not that experienced in Vim, so if I used the wrong 'lingo' to explain what's happening, feel free to correct me!)",
                "You can use git-rebase-rewordIt is designed to edit any commit (not just last) same way as commit --amendIt is named after the action on rebase interactive to amend a commit: \"reword\". See this post and man -section interactive mode-Examples:",
                "I have added the aliases reci and recm for recommit (amend) it. Now I can do it with git recm or git recm -m:",
                "I realised that I had pushed a commit with a typo in it. In order to undo, I did the following:Warning: force pushing your changes will overwrite the remote branch with your local one. Make sure that you aren't going to be overwriting anything that you want to keep. Also be cautious about force pushing an amended (rewritten) commit if anyone else shares the branch with you, because they'll need to rewrite their own history if they have the old copy of the commit that you've just rewritten.",
                "I like to use the following:",
                "If you have not pushed the code to your remote branch (GitHub/Bitbucket) you can change the commit message on the command line as below.If you're working on a specific branch do this:If you've already pushed the code with the wrong message, and you need to be careful when changing the message. That is, after you change the commit message and try pushing it again, you end up with having issues. To make it smooth, follow these steps.Please read my entire answer before doing it.Important note: When you use the force push directly you might end up with code issues that other developers are working on the same branch. So to avoid those conflicts, you need to pull the code from your branch before making the force push:This is the best practice when changing the commit message, if it was already pushed."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do JavaScript closures work?",
                "How would you explain JavaScript closures to someone with a knowledge of the concepts they consist of (for example functions, variables and the like), but does not understand closures themselves?\n\nI ..."
            ],
            "url": "https://stackoverflow.com/questions/111102",
            "answer": [
                "A closure is a pairing of:A lexical environment is part of every execution context (stack frame) and is a map between identifiers (i.e. local variable names) and values.Every function in JavaScript maintains a reference to its outer lexical environment. This reference is used to configure the execution context created when a function is invoked. This reference enables code inside the function to \"see\" variables declared outside the function, regardless of when and where the function is called.If a function was called by a function, which in turn was called by another function, then a chain of references to outer lexical environments is created. This chain is called the scope chain.In the following code, inner forms a closure with the lexical environment of the execution context created when foo is invoked, closing over variable secret:function foo() {\n  const secret = Math.trunc(Math.random() * 100)\n  return function inner() {\n    console.log(`The secret number is ${secret}.`)\n  }\n}\nconst f = foo() // `secret` is not directly accessible from outside `foo`\nf() // The only way to retrieve `secret`, is to invoke `f`In other words: in JavaScript, functions carry a reference to a private \"box of state\", to which only they (and any other functions declared within the same lexical environment) have access. This box of the state is invisible to the caller of the function, delivering an excellent mechanism for data-hiding and encapsulation.And remember: functions in JavaScript can be passed around like variables (first-class functions), meaning these pairings of functionality and state can be passed around your program: similar to how you might pass an instance of a class around in C++.If JavaScript did not have closures, then more states would have to be passed between functions explicitly, making parameter lists longer and code noisier.So, if you want a function to always have access to a private piece of state, you can use a closure....and frequently we do want to associate the state with a function. For example, in Java or C++, when you add a private instance variable and a method to a class, you are associating the state with functionality.In C and most other common languages, after a function returns, all the local variables are no longer accessible because the stack-frame is destroyed. In JavaScript, if you declare a function within another function, then the local variables of the outer function can remain accessible after returning from it. In this way, in the code above, secret remains available to the function object inner, after it has been returned from foo.Closures are useful whenever you need a private state associated with a function. This is a very common scenario - and remember: JavaScript did not have a class syntax until 2015, and it still does not have a private field syntax. Closures meet this need.In the following code, the function toString closes over the details of the car.function Car(manufacturer, model, year, color) {\n  return {\n    toString() {\n      return `${manufacturer} ${model} (${year}, ${color})`\n    }\n  }\n}\n\nconst car = new Car('Aston Martin', 'V8 Vantage', '2012', 'Quantum Silver')\nconsole.log(car.toString())In the following code, the function inner closes over both fn and args.function curry(fn) {\n  const args = []\n  return function inner(arg) {\n    if(args.length === fn.length) return fn(...args)\n    args.push(arg)\n    return inner\n  }\n}\n\nfunction add(a, b) {\n  return a + b\n}\n\nconst curriedAdd = curry(add)\nconsole.log(curriedAdd(2)(3)()) // 5In the following code, function onClick closes over variable BACKGROUND_COLOR.const $ = document.querySelector.bind(document)\nconst BACKGROUND_COLOR = 'rgba(200, 200, 242, 1)'\n\nfunction onClick() {\n  $('body').style.background = BACKGROUND_COLOR\n}\n\n$('button').addEventListener('click', onClick)\n<button>Set background color</button>In the following example, all the implementation details are hidden inside an immediately executed function expression. The functions tick and toString close over the private state and functions they need to complete their work. Closures have enabled us to modularize and encapsulate our code.let namespace = {};\n\n(function foo(n) {\n  let numbers = []\n\n  function format(n) {\n    return Math.trunc(n)\n  }\n\n  function tick() {\n    numbers.push(Math.random() * 100)\n  }\n\n  function toString() {\n    return numbers.map(format)\n  }\n\n  n.counter = {\n    tick,\n    toString\n  }\n}(namespace))\n\nconst counter = namespace.counter\ncounter.tick()\ncounter.tick()\nconsole.log(counter.toString())This example shows that the local variables are not copied in the closure: the closure maintains a reference to the original variables themselves. It is as though the stack-frame stays alive in memory even after the outer function exits.function foo() {\n  let x = 42\n  let inner = () => console.log(x)\n  x = x + 1\n  return inner\n}\n\nfoo()() // logs 43In the following code, three methods log, increment, and update all close over the same lexical environment.And every time createObject is called, a new execution context (stack frame) is created and a completely new variable x, and a new set of functions (log etc.) are created, that close over this new variable.function createObject() {\n  let x = 42;\n  return {\n    log() { console.log(x) },\n    increment() { x++ },\n    update(value) { x = value }\n  }\n}\n\nconst o = createObject()\no.increment()\no.log() // 43\no.update(5)\no.log() // 5\nconst p = createObject()\np.log() // 42If you are using variables declared using var, be careful you understand which variable you are closing over. Variables declared using var are hoisted. This is much less of a problem in modern JavaScript due to the introduction of let and const.In the following code, each time around the loop, a new function inner is created, which closes over i. But because var i is hoisted outside the loop, all of these inner functions close over the same variable, meaning that the final value of i (3) is printed, three times.function foo() {\n  var result = []\n  for (var i = 0; i < 3; i++) {\n    result.push(function inner() { console.log(i) } )\n  }\n\n  return result\n}\n\nconst result = foo()\n// The following will print `3`, three times...\nfor (var i = 0; i < 3; i++) {\n  result[i]() \n}",
                "Every function in JavaScript maintains a link to its outer lexical environment. A lexical environment is a map of all the names (eg. variables, parameters) within a scope, with their values.So, whenever you see the function keyword, code inside that function has access to variables declared outside the function.function foo(x) {\r\n  var tmp = 3;\r\n\r\n  function bar(y) {\r\n    console.log(x + y + (++tmp)); // will log 16\r\n  }\r\n\r\n  bar(10);\r\n}\r\n\r\nfoo(2);This will log 16 because function bar closes over the parameter x and the variable tmp, both of which exist in the lexical environment of outer function foo.Function bar, together with its link with the lexical environment of function foo is a closure.A function doesn't have to return in order to create a closure. Simply by virtue of its declaration, every function closes over its enclosing lexical environment, forming a closure.function foo(x) {\r\n  var tmp = 3;\r\n\r\n  return function (y) {\r\n    console.log(x + y + (++tmp)); // will also log 16\r\n  }\r\n}\r\n\r\nvar bar = foo(2);\r\nbar(10); // 16\r\nbar(10); // 17The above function will also log 16, because the code inside bar can still refer to argument x and variable tmp, even though they are no longer directly in scope.However, since tmp is still hanging around inside bar's closure, it is available to be incremented. It will be incremented each time you call bar.The simplest example of a closure is this:var a = 10;\r\n\r\nfunction test() {\r\n  console.log(a); // will output 10\r\n  console.log(b); // will output 6\r\n}\r\nvar b = 6;\r\ntest();When a JavaScript function is invoked, a new execution context ec is created. Together with the function arguments and the target object, this execution context also receives a link to the lexical environment of the calling execution context, meaning the variables declared in the outer lexical environment (in the above example, both a and b) are available from ec.Every function creates a closure because every function has a link to its outer lexical environment.Note that variables themselves are visible from within a closure, not copies.",
                "FOREWORD: this answer was written when the question was:Like the old Albert said : \"If you can't explain it to a six-year old, you really don't understand it yourself.\u201d. Well I tried to explain JS closures to a 27 years old friend and completely failed.Can anybody consider that I am 6 and strangely interested in that subject ?I'm pretty sure I was one of the only people that attempted to take the initial question literally. Since then, the question has mutated several times, so my answer may now seem incredibly silly & out of place. Hopefully the general idea of the story remains fun for some.I'm a big fan of analogy and metaphor when explaining difficult concepts, so let me try my hand with a story.Once upon a time:There was a princess...She lived in a wonderful world full of adventures. She met her Prince Charming, rode around her world on a unicorn, battled dragons, encountered talking animals, and many other fantastical things.But she would always have to return back to her dull world of chores and grown-ups.And she would often tell them of her latest amazing adventure as a princess.But all they would see is a little girl......telling stories about magic and fantasy.And even though the grown-ups knew of real princesses, they would never believe in the unicorns or dragons because they could never see them. The grown-ups said that they only existed inside the little girl's imagination.But we know the real truth; that the little girl with the princess inside......is really a princess with a little girl inside.",
                "Taking the question seriously, we should find out what a typical 6-year-old is capable of cognitively, though admittedly, one who is interested in JavaScript is not so typical.On  Childhood Development: 5 to 7 Years  it says:Your child will be able to follow two-step directions. For example, if you say to your child, \"Go to the kitchen and get me a trash bag\" they will be able to remember that direction.We can use this example to explain closures, as follows:The kitchen is a closure that has a local variable, called trashBags.  There is a function inside the kitchen called getTrashBag that gets one trash bag and returns it.We can code this in JavaScript like this:function makeKitchen() {\r\n  var trashBags = ['A', 'B', 'C']; // only 3 at first\r\n\r\n  return {\r\n    getTrashBag: function() {\r\n      return trashBags.pop();\r\n    }\r\n  };\r\n}\r\n\r\nvar kitchen = makeKitchen();\r\n\r\nconsole.log(kitchen.getTrashBag()); // returns trash bag C\r\nconsole.log(kitchen.getTrashBag()); // returns trash bag B\r\nconsole.log(kitchen.getTrashBag()); // returns trash bag AFurther points that explain why closures are interesting:",
                "I need to know how many times a button has been clicked and do something on every third click...// Declare counter outside event handler's scope\nvar counter = 0;\nvar element = document.getElementById('button');\n\nelement.addEventListener(\"click\", function() {\n  // Increment outside counter\n  counter++;\n\n  if (counter === 3) {\n    // Do something every third time\n    console.log(\"Third time's the charm!\");\n\n    // Reset counter\n    counter = 0;\n  }\n});\n<button id=\"button\">Click Me!</button>Now this will work, but it does encroach into the outer scope by adding a variable, whose sole purpose is to keep track of the count. In some situations, this would be preferable as your outer application might need access to this information. But in this case, we are only changing every third click's behavior, so it is preferable to enclose this functionality inside the event handler.var element = document.getElementById('button');\n\nelement.addEventListener(\"click\", (function() {\n  // init the count to 0\n  var count = 0;\n\n  return function(e) { // <- This function becomes the click handler\n    count++; //    and will retain access to the above `count`\n\n    if (count === 3) {\n      // Do something every third time\n      console.log(\"Third time's the charm!\");\n\n      //Reset counter\n      count = 0;\n    }\n  };\n})());\n<button id=\"button\">Click Me!</button>Notice a few things here.In the above example, I am using the closure behavior of JavaScript. This behavior allows any function to have access to the scope in which it was created, indefinitely. To practically apply this, I immediately invoke a function that returns another function, and because the function I'm returning has access to the internal count variable (because of the closure behavior explained above) this results in a private scope for usage by the resulting function... Not so simple? Let's dilute it down...A simple one-line closureAll variables outside the returned function are available to the returned function, but they are not directly available to the returned function object...Get it? So in our primary example, the count variable is contained within the closure and always available to the event handler, so it retains its state from click to click.Also, this private variable state is fully accessible, for both readings and assigning to its private scoped variables.There you go; you're now fully encapsulating this behavior.Full Blog Post (including jQuery considerations)",
                "Closures are hard to explain because they are used to make some behaviour work that everybody intuitively expects to work anyway. I find the best way to explain them (and the way that I learned what they do) is to imagine the situation without them:const makePlus = function(x) {\n    return function(y) { return x + y; };\n}\n\nconst plus5 = makePlus(5);\nconsole.log(plus5(3));What would happen here if JavaScript didn't know closures? Just replace the call in the last line by its method body (which is basically what function calls do) and you get:Now, where's the definition of x? We didn't define it in the current scope. The only solution is to let plus5 carry its scope (or rather, its parent's scope) around. This way, x is well-defined and it is bound to the value 5.",
                "TLDRA closure is a link between a function and its outer lexical (ie. as-written) environment, such that the identifiers (variables, parameters, function declarations etc) defined within that environment are visible from within the function, regardless of when or from where the function is invoked.DetailsIn the terminology of the ECMAScript specification, a closure can be said to be implemented by the [[Environment]] reference of every function-object, which points to the lexical environment within which the function is defined.When a function is invoked via the internal [[Call]] method, the [[Environment]] reference on the function-object is copied into the outer environment reference of the environment record of the newly-created execution context (stack frame).In the following example, function f closes over the lexical environment of the global execution context:In the following example, function h closes over the lexical environment of function g, which, in turn, closes over the lexical environment of the global execution context.If an inner function is returned by an outer, then the outer lexical environment will persist after the outer function has returned. This is because the outer lexical environment needs to be available if the inner function is eventually invoked.In the following example, function j closes over the lexical environment of function i, meaning that variable x is visible from inside function j, long after function i has completed execution:function i() {\r\n    var x = 'mochacchino'\r\n    return function j() {\r\n        console.log('Printing the value of x, from within function j: ', x)\r\n    }\r\n} \r\n\r\nconst k = i()\r\nsetTimeout(k, 500) // invoke k (which is j) after 500msIn a closure, the variables in the outer lexical environment themselves are available, not copies.function l() {\r\n  var y = 'vanilla';\r\n\r\n  return {\r\n    setY: function(value) {\r\n      y = value;\r\n    },\r\n    logY: function(value) {\r\n      console.log('The value of y is: ', y);\r\n    }\r\n  }\r\n}\r\n\r\nconst o = l()\r\no.logY() // The value of y is: vanilla\r\no.setY('chocolate')\r\no.logY() // The value of y is: chocolateThe chain of lexical environments, linked between execution contexts via outer environment references, forms a scope chain and defines the identifiers visible from any given function.Please note that in an attempt to improve clarity and accuracy, this answer has been substantially changed from the original.",
                "OK, 6-year-old closures fan. Do you want to hear the simplest example of closure?Let's imagine the next situation: a driver is sitting in a car. That car is inside a plane. Plane is in the airport. The ability of driver to access things outside his car, but inside the plane, even if that plane leaves an airport, is a closure. That's it. When you turn 27, look at the more detailed explanation or at the example below.Here is how I can convert my plane story into the code.var plane = function(defaultAirport) {\r\n\r\n  var lastAirportLeft = defaultAirport;\r\n\r\n  var car = {\r\n    driver: {\r\n      startAccessPlaneInfo: function() {\r\n        setInterval(function() {\r\n          console.log(\"Last airport was \" + lastAirportLeft);\r\n        }, 2000);\r\n      }\r\n    }\r\n  };\r\n  car.driver.startAccessPlaneInfo();\r\n\r\n  return {\r\n    leaveTheAirport: function(airPortName) {\r\n      lastAirportLeft = airPortName;\r\n    }\r\n  }\r\n}(\"Boryspil International Airport\");\r\n\r\nplane.leaveTheAirport(\"John F. Kennedy\");",
                "This is an attempt to clear up several (possible) misunderstandings about closures that appear in some of the other answers.",
                "I wrote a blog post a while back explaining closures. Here's what I said about closures in terms of why you'd want one.Closures are a way to let a function\n  have persistent, private variables -\n  that is, variables that only one\n  function knows about, where it can\n  keep track of info from previous times\n  that it was run.In that sense, they let a function act a bit like an object with private attributes.Full post:So what are these closure thingys?",
                "The original question had a quote:If you can't explain it to a six-year old, you really don't understand it yourself.This is how I'd try to explain it to an actual six-year-old:You know how grown-ups can own a house, and they call it home? When a mom has a child, the child doesn't really own anything, right? But its parents own a house, so whenever someone asks \"Where's your home?\", the child can answer \"that house!\", and point to the house of its parents.A \"Closure\" is the ability of the child to always (even if abroad) be able to refer to its home, even though it's really the parent's who own the house.",
                "The following simple example covers all the main points of JavaScript closures.*Here is a factory that produces calculators that can add and multiply:The key point: Each call to make_calculator creates a new local variable n, which continues to be usable by that calculator's add and multiply functions long after make_calculator returns.If you are familiar with stack frames, these calculators seem strange: How can they keep accessing n after make_calculator returns?  The answer is to imagine that JavaScript doesn't use \"stack frames\", but instead uses \"heap frames\", which can persist after the function call that made them returns.Inner functions like add and multiply, which access variables declared in an outer function**, are called closures.That is pretty much all there is to closures.* For example, it covers all the points in the \"Closures for Dummies\" article given in another answer, except example 6, which simply shows that variables can be used before they are declared, a nice fact to know but completely unrelated to closures. It also covers all the points in the accepted answer, except for the points (1) that functions copy their arguments into local variables (the named function arguments), and (2) that copying numbers creates a new number, but copying an object reference gives you another reference to the same object. These are also good to know but again completely unrelated to closures. It is also very similar to the example in this answer but a bit shorter and less abstract. It does not cover the point of this answer or this comment, which is that JavaScript makes it difficult to plug the current value of a loop variable into your inner function: The \"plugging in\" step can only be done with a helper function that encloses your inner function and is invoked on each loop iteration. (Strictly speaking, the inner function accesses the helper function's copy of the variable, rather than having anything plugged in.) Again, very useful when creating closures, but not part of what a closure is or how it works. There is additional confusion due to closures working differently in functional languages like ML, where variables are bound to values rather than to storage space, providing a constant stream of people who understand closures in a way (namely the \"plugging in\" way) that is simply incorrect for JavaScript, where variables are always bound to storage space, and never to values.** Any outer function, if several are nested, or even in the global context, as this answer points out clearly.",
                "I still think Google's explanation works very well and is concise:*A C# question",
                "I tend to learn better by GOOD/BAD comparisons. I like to see working code followed by non-working code that someone is likely to encounter. I put together a jsFiddle that does a comparison and tries to boil down the differences to the simplest explanations I could come up with.In the above code createClosure(n) is invoked in every iteration of the loop. Note that I named the variable n to highlight that it is a new variable created in a new function scope and is not the same variable as index which is bound to the outer scope.This creates a new scope and n is bound to that scope; this means we have 10 separate scopes, one for each iteration.createClosure(n) returns a function that returns the n within that scope.Within each scope n is bound to whatever value it had when createClosure(n) was invoked so the nested function that gets returned will always return the value of n that it had when createClosure(n) was invoked.In the above code the loop was moved within the createClosureArray() function and the function now just returns the completed array, which at first glance seems more intuitive.What might not be obvious is that since createClosureArray() is only invoked once only one scope is created for this function instead of one for every iteration of the loop.Within this function a variable named index is defined. The loop runs and adds functions to the array that return index. Note that index is defined within the createClosureArray function which only ever gets invoked one time.Because there was only one scope within the createClosureArray() function, index is only bound to a value within that scope. In other words, each time the loop changes the value of index, it changes it for everything that references it within that scope.All of the functions added to the array return the SAME index variable from the parent scope where it was defined instead of 10 different ones from 10 different scopes like the first example. The end result is that all 10 functions return the same variable from the same scope.After the loop finished and index was done being modified the end value was 10, therefore every function added to the array returns the value of the single index variable which is now set to 10.CLOSURES DONE RIGHT\nn = 0\nn = 1\nn = 2\nn = 3\nn = 4\nn = 5\nn = 6\nn = 7\nn = 8\nn = 9CLOSURES DONE WRONG\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10",
                "Wikipedia on closures:In computer science, a closure is a function together with a referencing environment for the nonlocal names (free variables) of that function.Technically, in JavaScript, every function is a closure. It always has an access to variables defined in the surrounding scope.Since scope-defining construction in JavaScript is a function, not a code block like in many other languages, what we usually mean by closure in JavaScript is a function working with nonlocal variables defined in already executed surrounding function.Closures are often used for creating functions with some hidden private data (but it's not always the case).emsThe example above is using an anonymous function, which was executed once. But it does not have to be. It can be named (e.g. mkdb) and executed later, generating a database function each time it is invoked. Every generated function will have its own hidden database object. Another usage example of closures is when we don't return a function, but an object containing multiple functions for different purposes, each of those function having access to the same data.",
                "I put together an interactive JavaScript tutorial to explain how closures work.\nWhat's a Closure?Here's one of the examples:",
                "The children will never forget the secrets they have shared with their parents, even after their parents are\ngone. This is what closures are for functions.The secrets for JavaScript functions are the private variablesEvery time you call it, the local variable \"name\" is created and given the name \"Mary\". And every time the function exits the variable is lost and the name is forgotten.As you may guess, because the variables are re-created every time the function is called, and nobody else will know them, there must be a secret place where they are stored. It could be called Chamber of Secrets or stack or local scope but it doesn't matter. We know they are there, somewhere, hidden in the memory.But, in JavaScript, there is this very special thing that functions which are created inside other functions, can also know the local variables of their parents and keep them as long as they live.So, as long as we are in the parent -function, it can create one or more child functions which do share the secret variables from the secret place.But the sad thing is, if the child is also a private variable of its parent function, it would also die when the parent ends, and the secrets would die with them.So to live, the child has to leave before it's too lateAnd now, even though Mary is \"no longer running\", the memory of her is not lost and her child will always remember her name and other secrets they shared during their time together.So, if you call the child \"Alice\", she will respondThat's all there is to tell.",
                "I do not understand why the answers are so complex here.Here is a closure:Yes. You probably use that many times a day.There is no reason to believe closures are a complex design hack to address specific problems. No, closures are just about using a variable that comes from a higher scope from the perspective of where the function was declared (not run).Now what it allows you to do can be more spectacular, see other answers.",
                "A closure is where an inner function has access to variables in its outer function. That's probably the simplest one-line explanation you can get for closures.",
                "Example for the first point by dlaliberte:A closure is not only created when you return an inner function. In fact, the enclosing function does not need to return at all. You might instead assign your inner function to a variable in an outer scope, or pass it as an argument to another function where it could be used immediately. Therefore, the closure of the enclosing function probably already exists at the time that enclosing function was called since any inner function has access to it as soon as it is called.",
                "I know there are plenty of solutions already, but I guess that this small and simple script can be useful to demonstrate the concept:",
                "You're having a sleep over and you invite Dan.\nYou tell Dan to bring one XBox controller.Dan invites Paul.\nDan asks Paul to bring one controller. How many controllers were brought to the party?",
                "The author of Closures has explained closures pretty well, explaining the reason why we need them and also explaining LexicalEnvironment which is necessary to understanding closures. \nHere is the summary:What if a variable is accessed, but it isn\u2019t local? Like here:In this case, the interpreter finds the variable in the\nouter LexicalEnvironment object.The process consists of two steps:When a function is created, it gets a hidden property, named [[Scope]], which references the current LexicalEnvironment.If a variable is read, but can not be found anywhere, an error is generated.Nested functionsFunctions can be nested one inside another, forming a chain of LexicalEnvironments which can also be called a scope chain.So, function g has access to g, a and f.ClosuresA nested function may continue to live after the outer function has finished:Marking up LexicalEnvironments:As we see, this.say is a property in the user object, so it continues to live after User completed.And if you remember, when this.say is created, it (as every function) gets an internal reference this.say.[[Scope]] to the current LexicalEnvironment. So, the LexicalEnvironment of the current User execution stays in memory. All variables of User also are its properties, so they are also carefully kept, not junked as usually.The whole point is to ensure that if the inner function wants to access an outer variable in the future, it is able to do so.To summarize:This is called a closure.",
                "JavaScript functions can access their:If a function accesses its environment, then the function is a closure.Note that outer functions are not required, though they do offer benefits I don't discuss here. By accessing data in its environment, a closure keeps that data alive. In the subcase of outer/inner functions, an outer function can create local data and eventually exit, and yet, if any inner function(s) survive after the outer function exits, then the inner function(s) keep the outer function's local data alive.Example of a closure that uses the global environment:Imagine that the Stack Overflow Vote-Up and Vote-Down button events are implemented as closures, voteUp_click and voteDown_click, that have access to external variables isVotedUp and isVotedDown, which are defined globally. (For simplicity's sake, I am referring to StackOverflow's Question Vote buttons, not the array of Answer Vote buttons.)When the user clicks the VoteUp button, the voteUp_click function checks whether isVotedDown == true to determine whether to vote up or merely cancel a down vote. Function voteUp_click is a closure because it is accessing its environment.All four of these functions are closures as they all access their environment.",
                "As a father of a 6-year-old, currently teaching young children (and a relative novice to coding with no formal education so corrections will be required), I think the lesson would stick best through hands-on play. If the 6-year-old is ready to understand what a closure is, then they are old enough to have a go themselves. I'd suggest pasting the code into jsfiddle.net, explaining a bit, and leaving them alone to concoct a unique song. The explanatory text below is probably more appropriate for a 10 year old.INSTRUCTIONSDATA: Data is a collection of facts. It can be numbers, words, measurements, observations or even just descriptions of things. You can't touch it, smell it or taste it. You can write it down, speak it and hear it. You could use it to create touch smell and taste using a computer. It can be made useful by a computer using code.CODE: All the writing above is called code. It is written in JavaScript.JAVASCRIPT: JavaScript is a language. Like English or French or Chinese are languages. There are lots of languages that are understood by computers and other electronic processors. For JavaScript to be understood by a computer it needs an interpreter. Imagine if a teacher who only speaks Russian comes to teach your class at school. When the teacher says \"\u0432\u0441\u0435 \u0441\u0430\u0434\u044f\u0442\u0441\u044f\", the class would not understand. But luckily you have a Russian pupil in your class who tells everyone this means \"everybody sit down\" - so you all do. The class is like a computer and the Russian pupil is the interpreter. For JavaScript the most common interpreter is called a browser.BROWSER: When you connect to the Internet on a computer, tablet or phone to visit a website, you use a browser. Examples you may know are Internet Explorer, Chrome, Firefox and Safari. The browser can understand JavaScript and tell the computer what it needs to do. The JavaScript instructions are called functions.FUNCTION: A function in JavaScript is like a factory. It might be a little factory with only one machine inside. Or it might contain many other little factories, each with many machines doing different jobs. In a real life clothes factory you might have reams of cloth and bobbins of thread going in and T-shirts and jeans coming out. Our JavaScript factory only processes data, it can't sew, drill a hole or melt metal. In our JavaScript factory data goes in and data comes out.All this data stuff sounds a bit boring, but it is really very cool; we might have a function that tells a robot what to make for dinner. Let's say I invite you and your friend to my house. You like chicken legs best, I like sausages, your friend always wants what you want and my friend does not eat meat.I haven't got time to go shopping, so the function needs to know what we have in the fridge to make decisions. Each ingredient has a different cooking time and we want everything to be served hot by the robot at the same time. We need to provide the function with the data about what we like, the function could 'talk' to the fridge, and the function could control the robot.A function normally has a name, parentheses and braces. Like this:Note that /*...*/ and // stop code being read by the browser.NAME: You can call a function just about whatever word you want. The example \"cookMeal\" is typical in joining two words together and giving the second one a capital letter at the beginning - but this is not necessary. It can't have a space in it, and it can't be a number on its own.PARENTHESES: \"Parentheses\" or () are the letter box on the JavaScript function factory's door or a post box in the street for sending packets of information to the factory. Sometimes the postbox might be marked for example cookMeal(you, me, yourFriend, myFriend, fridge, dinnerTime), in which case you know what data you have to give it.BRACES: \"Braces\" which look like this {} are the tinted windows of our factory. From inside the factory you can see out, but from the outside you can't see in.THE LONG CODE EXAMPLE ABOVEOur code begins with the word function, so we know that it is one! Then the name of the function sing - that's my own description of what the function is about. Then parentheses (). The parentheses are always there for a function. Sometimes they are empty, and sometimes they have something in. This one has a word in: (person). After this there is a brace like this { . This marks the start of the function sing(). It has a partner which marks the end of sing() like this }So this function might have something to do with singing, and might need some data about a person. It has instructions inside to do something with that data.Now, after the function sing(), near the end of the code is the lineVARIABLE: The letters var stand for \"variable\". A variable is like an envelope. On the outside this envelope is marked \"person\". On the inside it contains a slip of paper with the information our function needs, some letters and spaces joined together like a piece of string (it's called a string) that make a phrase reading \"an old lady\". Our envelope could contain other kinds of things like numbers (called integers), instructions (called functions), lists (called arrays). Because this variable is written outside of all the braces {}, and because you can see out through the tinted windows when you are inside the braces, this variable can be seen from anywhere in the code. We call this a 'global variable'.GLOBAL VARIABLE: person is a global variable, meaning that if you change its value from \"an old lady\" to \"a young man\", the person will keep being a young man until you decide to change it again and that any other function in the code can see that it's a young man. Press the F12 button or look at the Options settings to open the developer console of a browser and type \"person\" to see what this value is. Type person=\"a young man\" to change it and then type \"person\" again to see that it has changed.After this we have the lineThis line is calling the function, as if it were calling a dog\"Come on sing, Come and get person!\"When the browser has loaded the JavaScript code an reached this line, it will start the function. I put the line at the end to make sure that the browser has all the information it needs to run it.Functions define actions  - the main function is about singing. It contains a variable called firstPart which applies to the singing about the person that applies to each of the verses of the song: \"There was \" + person + \" who swallowed\". If you type firstPart into the console, you won't get an answer because the variable is locked up in a function - the browser can't see inside the tinted windows of the braces.CLOSURES: The closures are the smaller functions that are inside the big sing() function. The little factories inside the big factory. They each have their own braces which mean that the variables inside them can't be seen from the outside. That's why the names of the variables (creature and result) can be repeated in the closures but with different values. If you type these variable names in the console window, you won't get its value because it's hidden by two layers of tinted windows.The closures all know what the sing() function's variable called firstPart is, because they can see out from their tinted windows.After the closures come the linesThe sing() function will call each of these functions in the order they are given. Then the sing() function's work will be done.",
                "Okay, talking with a 6-year old child, I would possibly use following associations.Imagine - you are playing with your little brothers and sisters in the entire house, and you are moving around with your toys and brought some of them into your older brother's room. After a while your brother returned from the school and went to his room, and he locked inside it, so now you could not access toys left there anymore in a direct way. But you could knock the door and ask your brother for that toys. This is called toy's closure; your brother made it up for you, and he is now into outer scope.Compare with a situation when a door was locked by draft and nobody inside (general function execution), and then some local fire occur and burn down the room (garbage collector:D), and then a new room was build and now you may leave another toys there (new function instance), but never get the same toys which were left in the first room instance.For an advanced child I would put something like the following. It is not perfect, but it makes you feel about what it is:As you can see, the toys left in the room are still accessible via the brother and no matter if the room is locked. Here is a jsbin to play around with it.",
                "A function in JavaScript is not just a reference to a set of instructions (as in C language), but it also includes a hidden data structure which is composed of references to all nonlocal variables it uses (captured variables). Such two-piece functions are called closures. Every function in JavaScript can be considered a closure.Closures are functions with a state. It is somewhat similar to \"this\" in the sense that \"this\" also provides state for a function but function and \"this\" are separate objects (\"this\" is just a fancy parameter, and the only way to bind it permanently to a function is to create a closure). While \"this\" and function always live separately, a function cannot be separated from its closure and the language provides no means to access captured variables.Because all these external variables referenced by a lexically nested function are actually local variables in the chain of its lexically enclosing functions (global variables can be assumed to be local variables of some root function), and every single execution of a function creates new instances of its local variables, it follows that every execution of a function returning (or otherwise transferring it out, such as registering it as a callback) a nested function creates a new closure (with its own potentially unique set of referenced nonlocal variables which represent its execution context).Also, it must be understood that local variables in JavaScript are created not on the stack frame, but on the heap and destroyed only when no one is referencing them. When a function returns, references to its local variables are decremented, but they can still be non-null if during the current execution they became part of a closure and are still referenced by its lexically nested functions (which can happen only if the references to these nested functions were returned or otherwise transferred to some external code).An example:",
                "An answer for a six-year-old (assuming he knows what a function is and what a variable is, and what data is):Functions can return data. One kind of data you can return from a function is another function. When that new function gets returned, all the variables and arguments used in the function that created it don't go away. Instead, that parent function \"closes.\" In other words, nothing can look inside of it and see the variables it used except for the function it returned. That new function has a special ability to look back inside the function that created it and see the data inside of it.Another really simple way to explain it is in terms of scope:Any time you create a smaller scope inside of a larger scope, the smaller scope will always be able to see what is in the larger scope.",
                "Perhaps a little beyond all but the most precocious of six-year-olds, but a few examples that helped make the concept of closure in JavaScript click for me.A closure is a function that has access to another function's scope (its variables and functions). The easiest way to create a closure is with a function within a function; the reason being that in JavaScript a function always has access to its containing function\u2019s scope.function outerFunction() {\r\n    var outerVar = \"monkey\";\r\n    \r\n    function innerFunction() {\r\n        alert(outerVar);\r\n    }\r\n    \r\n    innerFunction();\r\n}\r\n\r\nouterFunction();ALERT: monkeyIn the above example, outerFunction is called which in turn calls innerFunction. Note how outerVar is available to innerFunction, evidenced by its correctly alerting the value of outerVar.Now consider the following:function outerFunction() {\r\n    var outerVar = \"monkey\";\r\n    \r\n    function innerFunction() {\r\n        return outerVar;\r\n    }\r\n    \r\n    return innerFunction;\r\n}\r\n\r\nvar referenceToInnerFunction = outerFunction();\r\nalert(referenceToInnerFunction());ALERT: monkeyreferenceToInnerFunction is set to outerFunction(), which simply returns a reference to innerFunction. When referenceToInnerFunction is called, it returns outerVar. Again, as above, this demonstrates that innerFunction has access to outerVar, a variable of outerFunction. Furthermore, it is interesting to note that it retains this access even after outerFunction has finished executing.And here is where things get really interesting. If we were to get rid of outerFunction, say set it to null, you might think that referenceToInnerFunction would loose its access to the value of outerVar. But this is not the case.function outerFunction() {\r\n    var outerVar = \"monkey\";\r\n    \r\n    function innerFunction() {\r\n        return outerVar;\r\n    }\r\n    \r\n    return innerFunction;\r\n}\r\n\r\nvar referenceToInnerFunction = outerFunction();\r\nalert(referenceToInnerFunction());\r\n\r\nouterFunction = null;\r\nalert(referenceToInnerFunction());ALERT: monkey\nALERT: monkeyBut how is this so? How can referenceToInnerFunction still know the value of outerVar now that outerFunction has been set to null?The reason that referenceToInnerFunction can still access the value of outerVar is because when the closure was first created by placing innerFunction inside of outerFunction, innerFunction added a reference to outerFunction\u2019s scope (its variables and functions) to its scope chain. What this means is that innerFunction has a pointer or reference to all of outerFunction\u2019s variables, including outerVar. So even when outerFunction has finished executing, or even if it is deleted or set to null, the variables in its scope, like outerVar, stick around in memory because of the outstanding reference to them on the part of the innerFunction that has been returned to referenceToInnerFunction. To truly release outerVar and the rest of outerFunction\u2019s variables from memory you would have to get rid of this outstanding reference to them, say by setting referenceToInnerFunction to null as well.//////////Two other things about closures to note. First, the closure will always have access to the last values of its containing function.function outerFunction() {\r\n    var outerVar = \"monkey\";\r\n    \r\n    function innerFunction() {\r\n        alert(outerVar);\r\n    }\r\n    \r\n    outerVar = \"gorilla\";\r\n\r\n    innerFunction();\r\n}\r\n\r\nouterFunction();ALERT: gorillaSecond, when a closure is created, it retains a reference to all of its enclosing function\u2019s variables and functions; it doesn\u2019t get to pick and choose. And but so, closures should be used sparingly, or at least carefully, as they can be memory intensive; a lot of variables can be kept in memory long after a containing function has finished executing.",
                "I'd simply point them to the Mozilla Closures page. It's the best, most concise and simple explanation of closure basics and practical usage that I've found. It is highly recommended to anyone learning JavaScript.And yes, I'd even recommend it to a 6-year old -- if the 6-year old is learning about closures, then it's logical they're ready to comprehend the concise and simple explanation provided in the article."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I revert a Git repository to a previous commit?",
                "How do I revert from my current state to a snapshot made on a certain commit?\n\nIf I do git log, then I get the following output:\n\n$ git log\ncommit a867b4af366350be2e7c21b8de9cc6504678a61b`\nAuthor: Me &..."
            ],
            "url": "https://stackoverflow.com/questions/4114095",
            "answer": [
                "This depends a lot on what you mean by \"revert\".If you want to temporarily go back to it, fool around, then come back to where you are, all you have to do is check out the desired commit:Or if you want to make commits while you're there, go ahead and make a new branch while you're at it:To go back to where you were, just check out the branch you were on again. (If you've made changes, as always when switching branches, you'll have to deal with them as appropriate. You could reset to throw them away; you could stash, checkout, stash pop to take them with you; you could commit them to a branch there if you want a branch there.)If, on the other hand, you want to really get rid of everything you've done since then, there are two possibilities. One, if you haven't published any of these commits, simply reset:If you mess up, you've already thrown away your local changes, but you can at least get back to where you were before by resetting again.On the other hand, if you've published the work, you probably don't want to reset the branch, since that's effectively rewriting history. In that case, you could indeed revert the commits. With Git, revert has a very specific meaning: create a commit with the reverse patch to cancel it out. This way you don't rewrite any history.The git-revert manpage actually covers a lot of this in its description. Another useful link is this git-scm.com section discussing git-revert.If you decide you didn't want to revert after all, you can revert the revert (as described here) or reset back to before the revert (see the previous section).You may also find this answer helpful in this case:\nHow can I move HEAD back to a previous location? (Detached head) & Undo commits",
                "Lots of complicated and dangerous answers here, but it's actually easy:This will revert everything from the HEAD back to the commit hash, meaning it will recreate that commit state in the working tree as if every commit after 0766c053 had been walked back. You can then commit the current tree, and it will create a brand new commit essentially equivalent to the commit you \"reverted\" to.(The --no-commit flag lets git revert all the commits at once- otherwise you'll be prompted for a message for each commit in the range, littering your history with unnecessary new commits.)This is a safe and easy way to rollback to a previous state. No history is destroyed, so it can be used for commits that have already been made public.",
                "Working on your own and just want it to work? Follow these instructions below, they\u2019ve worked reliably for me and many others for years.Working with others? Git is complicated. Read the comments below this answer, consider other answers, and discuss with your team before you do something rash.To revert to the previous commit, ignoring any changes:where HEAD is the last commit in your current branchTo revert to a commit that's older than the most recent commit:Credits go to a similar Stack Overflow question, Revert to a commit by a SHA hash in Git?.",
                "The best option for me and probably others is the Git reset option:This has been the best option for me! It is simple, fast and effective!** Note:** As mentioned in comments don't do this if you're sharing your branch with other people who have copies of the old commitsAlso from the comments, if you wanted a less 'ballzy' method you could use",
                "Before answering let's add some background, explaining what this HEAD is.HEAD is simply a reference to the current commit (latest) on the current branch. There can only be a single HEAD at any given time (excluding git worktree).The content of HEAD is stored inside .git/HEAD, and it contains the 40-bytes SHA-1 hash of the current commit.If you are not on the latest commit - meaning that HEAD is pointing to a prior commit in history it's called detached HEAD.On the command-line it will look like this - SHA-1 hash instead of the branch name since the HEAD is not pointing to the the tip of the current branch:This will checkout new branch pointing to the desired commit. This command will checkout to a given commit.At this point you can create a branch and start to work from this point on:You can always use the reflog as well. git reflog  will display any change which updated the HEAD and checking out the desired reflog entry will set the HEAD back to this commit.Every time the HEAD is modified there will be a new entry in the reflogThis will get you back to your desired commit.\"Move\" your HEAD back to the desired commit.This schema illustrates which command does what. As you can see there reset && checkout modify the HEAD.",
                "You can do this by the following two commands:It will remove your previous Git commit.If you want to keep your changes, you can also use:Then it will save your changes.",
                "If you want to \"uncommit\", erase the last commit message, and put the modified files back in staging, you would use the command:This is an extremely useful command in situations where you committed the wrong thing and you want to undo that last commit.Source: http://nakkaya.com/2009/09/24/git-delete-last-commit/",
                "The best way is:This will reset the branch to the specific commit and then will upload the remote server with the same commits as you have in local.Be careful with the --force flag as it removes all the subsequent commits after the selected commit without the option to recover them.",
                "I have tried a lot of ways to revert local changes in Git, and it seems that this works the best if you just want to revert to the latest commit state.Short description:I found a much more convenient and simple way to achieve the results above:where HEAD points to the latest commit at you current branch.It is the same code code as boulder_ruby suggested, but I have added git add . before  git reset --hard HEAD to erase all new files created since the last commit since this is what most people expect I believe when reverting to the latest commit.",
                "OK, going back to a previous commit in Git is quite easy...Revert back without keeping the changes:Revert back with keeping the changes:Explanation: using git reset, you can reset to a specific state. It's common using it with a commit hash as you see above.But as you see the difference is using the two flags --soft and --hard, by default git reset using --soft flag, but it's a good practice always using the flag, I explain each flag:The default flag as explained, not need to provide it, does not change the working tree, but it adds all changed files ready to commit, so you go back to the commit status which changes to files get unstaged.Be careful with this flag. It resets the working tree and all changes to tracked files and all will be gone!I also created the image below that may happen in a real life working with Git:",
                "Assuming you're talking about master and on that respective branch (that said, this could be any working branch you're concerned with):I found the answer from in a blog post (now no longer exists)Note that this is Resetting and Forcing the change to the remote, so that if others on your team have already git pulled, you will cause problems for them. You are destroying the change history, which is an important reason why people use git in the first place.Better to use revert (see other answers) than reset. \nIf you're a one man team then it probably doesn't matter.",
                "Jefromi's solutions are definitely the best ones, and you should definitely use them. However, for the sake of completeness, I also wanted to show these other alternative solutions that can also be used to revert a commit (in the sense that you create a new commit that undoes changes in previous commit, just like what git revert does).To be clear, these alternatives are not the best way to revert commits, Jefromi's solutions are, but I just want to point out that you can also use these other methods to achieve the same thing as git revert.This is a very slightly modified version of Charles Bailey's solution to Revert to a commit by a SHA hash in Git?:This basically works by using the fact that soft resets will leave the state of the previous commit staged in the index/staging-area, which you can then commit.This solution comes from svick's solution to Checkout old commit and make it a new commit:Similarly to alternative #1, this reproduces the state of <commit> in the current working copy. It is necessary to do git rm first because git checkout won't remove files that have been added since <commit>.",
                "Say you have the following commits in a text file named ~/commits-to-revert.txt (I used git log --pretty=oneline to get them)Create a Bash shell script to revert each of them:This reverts everything back to the previous state, including file and directory creations, and deletions, commit it to your branch and you retain the history, but you have it reverted back to the same file structure. Why Git doesn't have a git revert --to <hash> is beyond me.",
                "Here is a much simpler way to go back to a previous commit (and have it in an uncommited state, to do with it whatever you like):So, no need for commit ids and so on :)",
                "You can complete all these initial steps yourself and push back to the Git repository.Pull the latest version of your repository from Bitbucket using the git pull --all command.Run the Git log command with -n 4 from your terminal. The number after the -n determines the number of commits in the log starting from the most recent commit in your local history.Reset the head of your repository's history using the git reset --hard HEAD~N where N is the number of commits you want to take the head back. In the following example the head would be set back one commit, to the last commit in the repository history:Push the change to Git repository using git push --force to force push the change.If you want the Git repository to a previous commit:-",
                "Caution! This command can cause losing commit history, if user put the wrong commit mistakenly. Always have en extra backup of your git some\nwhere else just in case if you do mistakes, than you are a bit safer.\n:)I have had a similar issue and wanted to revert back to an earlier commit. In my case I was not interested to keep the newer commit, hence I used Hard.This is how I did it:This will revert on the local repository, and here after using git push -f will update the remote repository.For instance, if you want to completely ignore the commit with the name enforce non-group manage policies from the next imageyou'd runfollowed byAfter, you won't see that commit (enforce non-group manage policies) there",
                "After all the changes, when you push all these commands, you might have to use:And not only git push.",
                "Revert is the command to rollback the commits.Sample:It is capable of taking range from the HEAD like below. Here 1 says \"revert last commit.\"And then do:",
                "There is a command (not a part of core Git, but it is in the git-extras package) specifically for reverting and staging old commits:Per the man page, it can also be used as such:",
                "If the situation is an urgent one, and you just want to do what the questioner asked in a quick and dirty way, assuming your project is under a directory called, for example, \"my project\":QUICK AND DIRTY: depending on the circumstances, quick and dirty may in fact be very GOOD. What my solution here does is NOT replace irreversibly the files you have in your working directory with files hauled up/extracted from the depths of the git repository lurking beneath your .git/ directory using fiendishly clever and diabolically powerful git commands, of which there are many. YOU DO NOT HAVE TO DO SUCH DEEP-SEA DIVING TO RECOVER what may appear to be a disastrous situation, and attempting to do so without sufficient expertise may prove fatal.Copy the whole directory and call it something else, like \"my project - copy\". Assuming your git repository (\"repo\") files are under the \"my project\" directory (the default place for them, under a directory called \".git\"), you will now have copied both your work files and your repo files.Do this in the directory \"my project\":This will return the state of the repo under \"my project\" to what it was when you made that commit (a \"commit\" means a snapshot of your working files). All commits since the \"resetted\" commit will be lost forever under \"my project\", BUT... they will still be present in the repo under \"my project - copy\" since you copied all those files - including the ones in the repo, under .../.git/.You then have two versions on your system... you can examine or copy or modify files of interest, or whatever, from the previous commit. You can completely discard the files under \"my project - copy\", if you have decided the new work since the restored commit was going nowhere...The obvious thing if you want to carry on with the state of the project without actually discarding the work since this retrieved commit is to rename your directory again: Delete the project containing the retrieved commit (or give it a temporary name) and rename your \"my project - copy\" directory back to \"my project\". Then maybe try to understand some of the other answers here, and probably do another commit fairly soon.Git is a brilliant creation but absolutely no-one is able to just \"pick it up on the fly\": also people who try to explain it far too often assume prior knowledge of other VCS [Version Control Systems] and delve far too deep far too soon, and commit other terrible crimes, like using interchangeable terms for \"checking out\" - in ways which sometimes appear almost calculated to confuse a beginner.To save yourself much stress, learn from my scars. You have to pretty much have to read a book on Git - I'd recommend reading THE BOOK, Pro Git 2nd edition: available for free download etc. from git central. Published 2014 but, as at early 2022, still the best. Do it sooner rather than later: Git is destined to be part of your life from now on. If you do, bear in mind that much of the complexity of Git comes from branching and then remerging: the Pro Git book actually introduces this central aspect very gently, but you can skip those parts in any book on your first read. From your question there's no reason why people should be blinding you with science.Especially if, for example, this is a desperate situation and you're a newbie with Git!PS: (slight caution) One other thought: It is (now) actually quite simple to keep the Git repo in a directory other than the one with the working files. This would mean you would not copy the entire Git repository using the above quick & dirty solution. See the answer by Fryer using --separate-git-dir here. Bearing that in mind, be warned: If you have a \"separate-directory\" repository which you don't copy, and you do a hard reset, all versions subsequent to the reset commit really will be lost forever forever, unless you have, as you absolutely should, regularly backed up your repository, preferably to the Cloud (e.g. Google Drive) among other places.On this subject of \"backing up to the Cloud\", the next step is to open an account (free of course) with GitHub or (better in my view) GitLab. You can then regularly do a git push command to make your Cloud repo up-to-date \"properly\". But again, talking about this may be too much too soon: git push has to be configured, can fail to work for a totally baffling technical reason, involves learning about remote repos (\"origin\", etc). So a quick-and-dirty Cloud-based backup approach may be preferable until you become knowledgeable. Again, the Pro Git book introduces how remote repositories work, and relate to your local repo, very gently and rationally.",
                "Try resetting to the desired commit:To check COMMIT_ID use:This will reset all changed files to un-added state.Now you can checkout all un-added files byTo verify your changes use:UPDATEIf you have one and only commit in your repo, try",
                "Select your required commit, and check it bytill you get the required commit. To make the HEAD point to that, door git reset --hard HEAD~2 or whatever.",
                "Revert to most recent commit and ignoring all local changes:",
                "Idea: You basically want to replace the current working tree state with the one from a previous commit and then create a commit out of it. Ignored files should best be not changed. Here is how:Emtpy the working tree *.Bring the working tree in the state we want **.Create the revert commit.At first I thought that Yarins answer would be the best, but it doesn't work for merge commits. This solution does.Additionally it does not delete anything (pushed or upushed) from the history. It produces one clean commit which represents the state we want to revert back to.* by removing untracked but not ignored files (the ones specified in .gitignore) from working tree. The working tree is empty except for the ignored files which we wanted to keep (if not specifiy -x option for clean)** When a path is specified (here: .), checkout leaves HEAD alone.",
                "It directly clears all the changes that you have been making since the last commit.PS: It has a little problem; it also deletes all you recently stored stash changes. Which I guess in most cases should not matter.",
                "To completely clean a coder's directory up from some accidental changes, we used:Just git reset --hard HEAD will get rid of modifications, but it won't get rid of \"new\" files. In their case they'd accidentally dragged an important folder somewhere random, and all those files were being treated as new by Git, so a reset --hard didn't fix it. By running the git add -A . beforehand, it explicitly tracked them all with git, to be wiped out by the reset.",
                "I believe some people may come to this question wanting to know how to rollback committed changes they've made in their master - ie throw everything away and go back to origin/master, in which case, do this:https://superuser.com/questions/273172/how-to-reset-master-to-origin-master",
                "To keep the changes from the previous commit to HEAD and move to the previous commit, do:If changes are not required from the previous commit to HEAD and just discard all changes, do:",
                "As your commits are pushed remotely, you need to remove them. Let me assume your branch is develop and it is pushed over origin.You first need to remove develop from origin:Then you need to get develop to the status you want, let me assume the commit hash is EFGHIJK:Lastly, push develop again:",
                "If you want to correct some error in the last commit a good alternative would be using git commit --amend command. If the last commit is not pointed by any reference, this will do the trick, as it create a commit with the same parent as the last commit. If there is no reference to the last commit, it will simply be discarded and this commit will be the last commit. This is a good way of correcting commits without reverting commits. However it has its own limitations."
            ]
        },
        {
            "tag": "",
            "question": [
                "Is Java \"pass-by-reference\" or \"pass-by-value\"?",
                "I always thought Java uses pass-by-reference.\nHowever, I've seen a blog post that claims that Java uses pass-by-value.\nI don't think I understand the distinction they're making.\nWhat is the ..."
            ],
            "url": "https://stackoverflow.com/questions/40480",
            "answer": [
                "The terms \"pass-by-value\" and \"pass-by-reference\" have special, precisely defined meanings in computer science. These meanings differ from the intuition many people have when first hearing the terms. Much of the confusion in this discussion seems to come from this fact.The terms \"pass-by-value\" and \"pass-by-reference\" are talking about variables. Pass-by-value means that the value of a variable is passed to a function/method. Pass-by-reference means that a reference to that variable is passed to the function. The latter gives the function a way to change the contents of the variable.By those definitions, Java is always pass-by-value.  Unfortunately, when we deal with variables holding objects we are really dealing with object-handles called references which are passed-by-value as well.  This terminology and semantics easily confuse many beginners.It goes like this:In the example above aDog.getName() will still return \"Max\". The value aDog within main is not changed in the function foo with the Dog \"Fifi\" as the object reference is passed by value. If it were passed by reference, then the aDog.getName() in main would return \"Fifi\" after the call to foo.Likewise:In the above example, Fifi is the dog's name after call to foo(aDog) because the object's name was set inside of foo(...). Any operations that foo performs on d are such that, for all practical purposes, they are performed on aDog, but it is not possible to change the value of the variable aDog itself.For more information on pass by reference and pass by value, consult the following answer: https://stackoverflow.com/a/430958/6005228. This explains more thoroughly the semantics and history behind the two and also explains why Java and many other modern languages appear to do both in certain cases.",
                "I just noticed you referenced my article.The Java Spec says that everything in Java is pass-by-value. There is no such thing as \"pass-by-reference\" in Java.The key to understanding this is that something likeis not a Dog; it's actually a pointer to a Dog. The use of the term \"reference\" in Java is very misleading and is what causes most of the confusion here. What they call \"references\" act/feel more like what we'd call \"pointers\" in most other languages.What that means, is when you haveyou're essentially passing the address of the created Dog object to the foo method.(I say essentially because Java pointers/references aren't direct addresses, but it's easiest to think of them that way.)Suppose the Dog object resides at memory address 42. This means we pass 42 to the method.if the Method were defined aslet's look at what's happening.Now let's think about what happens outside the method:Did myDog change?There's the key.Keeping in mind that myDog is a pointer, and not an actual Dog, the answer is NO. myDog still has the value 42; it's still pointing to the original Dog (but note that because of line \"AAA\", its name is now \"Max\" - still the same Dog; myDog's value has not changed.)It's perfectly valid to follow an address and change what's at the end of it; that does not change the variable, however.Java works exactly like C. You can assign a pointer, pass the pointer to a method, follow the pointer in the method and change the data that was pointed to. However, the caller will not see any changes you make to where that pointer points. (In a language with pass-by-reference semantics, the method function can change the pointer and the caller will see that change.)In C++, Ada, Pascal and other languages that support pass-by-reference, you can actually change the variable that was passed.If Java had pass-by-reference semantics, the foo method we defined above would have changed where myDog was pointing when it assigned someDog on line BBB.Think of reference parameters as being aliases for the variable passed in. When that alias is assigned, so is the variable that was passed in.A discussion in the comments warrants some clarification...In C, you can writeThis is not a special case in C. Both languages use pass-by-value semantics. Here the call site is creating additional data structure to assist the function to access and manipulate data.The function is being passed pointers to data, and follows those pointers to access and modify that data.A similar approach in Java, where the caller sets up assisting structure, might be:(or if you wanted both examples to demonstrate features the other language doesn't have, create a mutable IntWrapper class to use in place of the arrays)In these cases, both C and Java are simulating pass-by-reference. They're still both passing values (pointers to ints or arrays), and following those pointers inside the called function to manipulate the data.Pass-by-reference is all about the function declaration/definition, and how it handles its parameters. Reference semantics apply to every call to that function, and the call site only needs to pass variables, no additional data structure.These simulations require the call site and the function to cooperate. No doubt it's useful, but it's still pass-by-value.",
                "Java always passes arguments by value, NOT by reference.Let me explain this through an example:I will explain this in steps:Declaring a reference named f of type Foo and assign it a new object of type Foo with an attribute \"f\".From the method side, a reference of type Foo with a name a is declared and it's initially assigned null.As you call the method changeReference, the reference a will be assigned the object which is passed as an argument.Declaring a reference named b of type Foo and assign it a new object of type Foo with an attribute \"b\".a = b makes a new assignment to the reference a, not f, of the object whose attribute is \"b\".As you call modifyReference(Foo c) method, a reference c is created and assigned the object with attribute \"f\".c.setAttribute(\"c\"); will change the attribute of the object that reference c points to it, and it's the same object that reference f points to it.I hope you understand now how passing objects as arguments works in Java :)",
                "Java is always pass by value, with no exceptions, ever.So how is it that anyone can be at all confused by this, and believe that Java is pass by reference, or think they have an example of Java acting as pass by reference? The key point is that Java never provides direct access to the values of objects themselves, in any circumstances. The only access to objects is through a reference to that object. Because Java objects are always accessed through a reference, rather than directly, it is common to talk about fields and variables and method arguments as being objects, when pedantically they are only references to objects. The confusion stems from this (strictly speaking, incorrect) change in nomenclature.So, when calling a methodSo if you have doSomething(foo) and public void doSomething(Foo foo) { .. } the two Foos have copied references that point to the same objects.Naturally, passing by value a reference to an object looks very much like (and is indistinguishable in practice from) passing an object by reference.",
                "This will give you some insights of how Java really works to the point that in your next discussion about Java passing by reference or passing by value you'll just smile :-)Step one please erase from your mind that word that starts with 'p' \"_ _ _ _ _ _ _\", especially if you come from other programming languages. Java and 'p' cannot be written in the same book, forum, or even txt.Step two remember that when you pass an Object into a method you're passing the Object reference and not the Object itself.Now think of what an Object's reference/variable does/is:In the following (please don't try to compile/execute this...):What happens?A picture is worth a thousand words:Note that the anotherReferenceToTheSamePersonObject arrows is directed towards the Object and not towards the variable person!If you didn't get it then just trust me and remember that it's better to say that Java is pass by value. Well, pass by reference value. Oh well, even better is pass-by-copy-of-the-variable-value! ;)Now feel free to hate me but note that given this there is no difference between passing primitive data types and Objects when talking about method arguments.You always pass a copy of the bits of the value of the reference!Java is pass-by-value because inside a method you can modify the referenced Object as much as you want but no matter how hard you try you'll never be able to modify the passed variable that will keep referencing (not p _ _ _ _ _ _ _) the same Object no matter what!The changeName function above will never be able to modify the actual content (the bit values) of the passed reference. In other word changeName cannot make Person person refer to another Object.Of course you can cut it short and just say that  Java is pass-by-value!",
                "Java passes references by value.So you can't change the reference that gets passed in.",
                "I feel like arguing about \"pass-by-reference vs pass-by-value\" is not super-helpful.If you say, \"Java is pass-by-whatever (reference/value)\", in either case, you're not provide a complete answer. Here's some additional information that will hopefully aid in understanding what's happening in memory.Crash course on stack/heap before we get to the Java implementation:\nValues go on and off the stack in a nice orderly fashion, like a stack of plates at a cafeteria.\nMemory in the heap (also known as dynamic memory) is haphazard and disorganized. The JVM just finds space wherever it can, and frees it up as the variables that use it are no longer needed.Okay. First off, local primitives go on the stack. So this code:results in this:When you declare and instantiate an object. The actual object goes on the heap. What goes on the stack? The address of the object on the heap. C++ programmers would call this a pointer, but some Java developers are against the word \"pointer\". Whatever. Just know that the address of the object goes on the stack.Like so:An array is an object, so it goes on the heap as well. And what about the objects in the array? They get their own heap space, and the address of each object goes inside the array.So, what gets passed in when you call a method? If you pass in an object, what you're actually passing in is the address of the object. Some might say the \"value\" of the address, and some say it's just a reference to the object. This is the genesis of the holy war between \"reference\" and \"value\" proponents. What you call it isn't as important as that you understand that what's getting passed in is the address to the object.One String gets created and space for it is allocated in the heap, and the address to the string is stored on the stack and given the identifier hisName, since the address of the second String is the same as the first, no new String is created and no new heap space is allocated, but a new identifier is created on the stack. Then we call shout(): a new stack frame is created and a new identifier, name is created and assigned the address of the already-existing String.So, value, reference? You say \"potato\".",
                "Basically, reassigning Object parameters doesn't affect the argument, e.g.,will print out \"Hah!\" instead of null. The reason this works is because bar is a copy of the value of baz, which is just a reference to \"Hah!\". If it were the actual reference itself, then foo would have redefined baz to null.",
                "Just to show the contrast, compare the following C++ and Java snippets:In C++: Note: Bad code - memory leaks!  But it demonstrates the point.In Java,Java only has the two types of passing: by value for built-in types, and by value of the pointer for object types.",
                "Java passes references to objects by value.",
                "I can't believe that nobody mentioned Barbara Liskov yet. When she designed CLU in 1974, she ran into this same terminology problem, and she invented the term call by sharing (also known as call by object-sharing and call by object) for this specific case of \"call by value where the value is a reference\".",
                "The crux of the matter is that the word reference in the expression \"pass by reference\" means something completely different from the usual meaning of the word reference in Java.Usually in Java reference means a a reference to an object. But the technical terms pass by reference/value from programming language theory is talking about a reference to the memory cell holding the variable, which is something completely different.",
                "There are already great answers that cover this. I wanted to make a small contribution by sharing a very simple example (which will compile) contrasting the behaviors between Pass-by-reference in c++ and Pass-by-value in Java.A few points:C++ pass by reference example:Java pass \"a Java reference\" by value exampleEDITSeveral people have written comments which seem to indicate that either they are not looking at my examples or they don't get the c++ example. Not sure where the disconnect is, but guessing the c++ example is not clear. I'm posting the same example in pascal because I think pass-by-reference looks cleaner in pascal, but I could be wrong. I might just be confusing people more; I hope not.In pascal, parameters passed-by-reference are called \"var parameters\". In the procedure setToNil below, please note the keyword 'var' which precedes the parameter 'ptr'. When a pointer is passed to this procedure, it will be passed by reference. Note the behavior: when this procedure sets ptr to nil (that's pascal speak for NULL), it will set the argument to nil--you can't do that in Java.EDIT 2Some excerpts from \"THE Java Programming Language\" by Ken Arnold, James Gosling (the guy who invented Java), and David Holmes, chapter 2, section 2.6.5All parameters to methods are passed \"by value\". In other words,\nvalues of parameter variables in a method are copies of the invoker\nspecified as arguments.He goes on to make the same point regarding objects . . .You should note that when the parameter is an object reference, it is\nthe object reference-not the object itself-that is passed \"by value\".And towards the end of the same section he makes a broader statement about java being only pass by value and never pass by reference.The Java programming language does not pass objects by reference; it\npasses object references by value. Because two copies of the same\nreference refer to the same actual object, changes made through one\nreference variable are visible through the other. There is exactly one\nparameter passing mode-pass by value-and that helps keep things\nsimple.This section of the book has a great explanation of parameter passing in Java and of the distinction between pass-by-reference and pass-by-value and it's by the creator of Java. I would encourage anyone to read it, especially if you're still not convinced.I think the difference between the two models is very subtle and unless you've done programming where you actually used pass-by-reference, it's easy to miss where two models differ.I hope this settles the debate, but probably won't.EDIT 3I might be a little obsessed with this post. Probably because I feel that the makers of Java inadvertently spread misinformation. If instead of using the word \"reference\" for pointers they had used something else, say\ndingleberry, there would've been no problem. You could say, \"Java passes dingleberries by value and not by reference\", and nobody would be confused.That's the reason only Java developers have issue with this. They look at the word \"reference\" and think they know exactly what that means, so they don't even bother to consider the opposing argument.Anyway, I noticed a comment in an older post, which made a balloon analogy which I really liked. So much so that I decided to glue together some clip-art to make a set of cartoons to illustrate the point.Passing a reference by value--Changes to the reference are not reflected in the caller's scope, but the changes to the object are. This is because the reference is copied, but the both the original and the copy refer to the same object.Pass by reference--There is no copy of the reference. Single reference is shared by both the caller and the function being called. Any changes to the reference or the Object's data are reflected in the caller's scope.EDIT 4I have seen posts on this topic which describe the low level implementation of parameter passing in Java, which I think is great and very helpful because it makes an abstract idea concrete. However, to me the question is more about the behavior described in the language specification than about the technical implementation of the behavior. This is an exerpt from the Java Language Specification, section 8.4.1 :When the method or constructor is invoked (\u00a715.12), the values of the\nactual argument expressions initialize newly created parameter\nvariables, each of the declared type, before execution of the body of\nthe method or constructor. The Identifier that appears in the\nDeclaratorId may be used as a simple name in the body of the method or\nconstructor to refer to the formal parameter.Which means, java creates a copy of the passed parameters before executing a method. Like most people who studied compilers in college, I used \"The Dragon Book\" which is THE compilers book. It has a good description of \"Call-by-value\" and \"Call-by-Reference\" in Chapter 1. The Call-by-value description matches up with Java Specs exactly.Back when I studied compilers-in the 90's, I used the first edition of the book from 1986 which pre-dated Java by about 9 or 10 years. However, I just ran across a copy of the 2nd Eddition from 2007 which actually mentions Java! Section 1.6.6 labeled \"Parameter Passing Mechanisms\" describes parameter passing pretty nicely. Here is an excerpt under the heading \"Call-by-value\" which mentions Java:In call-by-value, the actual parameter is evaluated (if it is an\nexpression) or copied (if it is a variable). The value is placed in\nthe location belonging to the corresponding formal parameter of the\ncalled procedure. This method is used in C and Java, and is a common\noption in C++ , as well as in most other languages.",
                "In java everything is reference, so when you have something like:\n    Point pnt1 = new Point(0,0); Java does following:Java doesn't pass method arguments by reference; it passes them by value. I will use example from this site:Flow of the program:Creating two different Point object with two different reference associated.As expected output will be:On this line 'pass-by-value' goes into the play...References pnt1 and pnt2 are passed by value to the tricky method, which means that now yours references pnt1 and pnt2 have their copies named arg1 and arg2.So pnt1 and arg1 points to the same object. (Same for the pnt2 and arg2)In the tricky method:Next in the tricky methodHere, you first create new temp Point reference which will point on same place like arg1 reference. Then you move reference arg1 to point to the same place like arg2 reference.\nFinally arg2 will point to the same place like temp.From here scope of tricky method is gone and you don't have access any more to the references: arg1, arg2, temp. But important note is that everything you do with these references when they are 'in life' will permanently affect object on which they are point to.So after executing method tricky, when you return to main, you have this situation:So now, completely execution of program will be:",
                "Java is always pass by value, not pass by referenceFirst of all, we need to understand what pass by value and pass by reference are.Pass by value means that you are making a copy in memory of the actual parameter's value that is passed in. This is a copy of the contents of the actual parameter.Pass by reference (also called pass by address) means that a copy of the address of the actual parameter is stored.Sometimes Java can give the illusion of pass by reference. Let's see how it works by using the example below:The output of this program is:Let's understand step by step:As we all know it will create an object in the heap and return the reference value back to t. For example, suppose the value of t is 0x100234 (we don't know the actual JVM internal value, this is just an example) .When passing reference t to the function it will not directly pass the actual reference value of object test,  but it will create a copy of t and then pass it to the function. Since it is passing by value, it passes a copy of the variable rather than the actual reference of it. Since we said the value of t was 0x100234, both t and f will have the same value and hence they will point to the same object.If you change anything in the function using reference f it will modify the existing contents of the object. That is why we got the output changevalue,   which is updated in the function.To understand this more clearly, consider the following example:Will this throw a NullPointerException? No, because it only passes a copy of the reference.\nIn the case of passing by reference, it could have thrown a NullPointerException, as seen below:Hopefully this will help.",
                "Java is a pass by value(stack memory)How it worksLet's first understand that where java stores primitive data type and object data type.Primitive data types itself and object references are stored in the stack.\nObjects themselves are stored in the heap.It means, Stack memory stores primitive data types and also the\naddresses of objects.And you always pass a copy of the bits of the value of the reference.If it's a primitive data type then these copied bits contain the value of the primitive data type itself, That's why when we change the value of argument inside the method then it does not reflect the changes outside.If it's an object data type like Foo foo=new Foo() then in this case copy of the address of the object passes like file shortcut  , suppose we have a text file abc.txt at C:\\desktop and suppose we make shortcut of the same file and put this inside C:\\desktop\\abc-shortcut so when you access the file from C:\\desktop\\abc.txt and write 'Stack Overflow' and close the file and again you open the file from shortcut then you write ' is the largest online community for programmers to learn' then total file change will be 'Stack Overflow is the largest online community for programmers to learn' which means it doesn't matter from where you open the file , each time we were accessing the same file , here we can assume Foo as a file and suppose foo stored at 123hd7h(original address like C:\\desktop\\abc.txt ) address and 234jdid(copied address like C:\\desktop\\abc-shortcut which actually contains the original address of the file inside) ..\nSo for better understanding make shortcut file and feel.",
                "Getting an outside of the box view, let's look at Assembly or some low level memory management. At the CPU level a reference to anything immediately becomes a value if it gets written to memory or to one of the CPU registers. (That is why pointer is a good definition. It is a value, which has a purpose at the same time).Data in memory has a Location and at that location there is a value (byte,word, whatever). In Assembly we have a convenient solution to give a Name to certain Location (aka variable), but when compiling the code, the assembler simply replaces Name with the designated location just like your browser replaces domain names with IP addresses.Down to the core it is technically impossible to pass a reference to anything in any language without representing it (when it immediately becomes a value).Lets say we have a variable Foo, its Location is at the 47th byte in memory and its Value is 5. We have another variable Ref2Foo which is at 223rd byte in memory, and its value will be 47. This Ref2Foo might be a technical variable, not explicitly created by the program. If you just look at 5 and 47 without any other information, you will see just two Values.\nIf you use them as references then to reach to 5 we have to travel:This is how jump-tables work.If we want to call a method/function/procedure with Foo's value, there are a few possible way to pass the variable to the method, depending on the language and its several method invocation modes:In every cases above a value - a copy of an existing value - has been created, it is now upto the receiving method to handle it. When you write \"Foo\" inside the method, it is either read out from EAX, or automatically  dereferenced, or double dereferenced, the process depends on how the language works and/or what the type of Foo dictates. This is hidden from the developer until she circumvents the dereferencing process. So a reference is a value when represented, because a reference is a value that has to be processed (at language level).Now we have passed Foo to the method:Nitpicking on insignificant details, even languages that do pass-by-reference will pass values to functions, but those functions know that they have to use it for dereferencing purposes. This pass-the-reference-as-value is just hidden from the programmer because it is practically useless and the terminology is only pass-by-reference.Strict pass-by-value is also useless, it would mean that a 100 Mbyte array should have to be copied every time we call a method with the array as argument, therefore Java cannot be stricly pass-by-value. Every language would pass a reference to this huge array (as a value) and either employs copy-on-write mechanism if that array can be changed locally inside the method or allows the method (as Java does) to modify the array globally (from the caller's view) and a few languages allows to modify the Value of the reference itself.So in short and in Java's own terminology, Java is pass-by-value where value can be: either a real value or a value that is a representation of a reference.",
                "In Java, method arguments are all passed by value :Java arguments are all passed by value (the value  or reference is copied when used by the method) :In the case of primitive types, Java behaviour is simple:\nThe value is copied in another instance of the primitive type.In case of Objects, this is the same:\nObject variables are references (mem buckets holding only Object\u2019s address instead of a primitive value) that was created using the \"new\" keyword, and are copied like primitive types.The behaviour can appear different from primitive types: Because the copied object-variable contains the same address (to the same Object).\nObject's content/members might still be modified within a method and later access outside, giving the illusion that the (containing) Object itself was passed by reference.\"String\" Objects appear to be a good counter-example to the urban legend saying that \"Objects are passed by reference\":In effect, using a method, you will never be able, to update the value of a String passed as argument:A String Object, holds characters by an array declared final that can't be modified.\nOnly the address of the Object might be replaced by another using \"new\".\nUsing \"new\" to update the variable, will not let the Object be accessed from outside, since the variable was initially passed by value and copied.",
                "As far as I know, Java only knows call by value. This means for primitive datatypes you will work with an copy and for objects you will work with an copy of the reference to the objects. However I think there are some pitfalls; for example, this will not work:This will populate Hello World and not World Hello because in the swap function you use copys which have no impact on the references in the main. But if your objects are not immutable you can change it for example:This will populate Hello World on the command line. If you change StringBuffer into String it will produce just Hello because String is immutable. For example:However you could make a wrapper for String like this which would make it able to use it with Strings:edit: i believe this is also the reason to use StringBuffer when it comes to \"adding\" two Strings because you can modifie the original object which u can't with immutable objects like String is.",
                "No, it's not pass by reference.Java is pass by value according to the Java Language Specification:When the method or constructor is invoked (\u00a715.12), the values of the actual argument expressions initialize newly created parameter variables, each of the declared type, before execution of the body of the method or constructor. The Identifier that appears in the DeclaratorId may be used as a simple name in the body of the method or constructor to refer to the formal parameter.",
                "Let me try to explain my understanding with the help of four examples. Java is pass-by-value, and not pass-by-reference/**Pass By ValueIn Java, all parameters are passed by value, i.e. assigning a method argument is not visible to the caller.*/Example 1:ResultExample 2:/**\n * \n * Pass By Value\n *\n */ResultExample 3:/**\n  This 'Pass By Value has a feeling of 'Pass By Reference'Some people say primitive types and 'String' are 'pass by value'\n  and objects are 'pass by reference'.But from this example, we can understand that it is infact pass by value only,\n  keeping in mind that here we are passing the reference as the value.\n  ie: reference is passed by value.\n  That's why are able to change and still it holds true after the local scope.\n  But we cannot change the actual reference outside the original scope.\n  what that means is demonstrated by next example of PassByValueObjectCase2.*/ResultExample 4:/**In addition to what was mentioned in Example3 (PassByValueObjectCase1.java),  we cannot change the actual reference outside the original scope.\"Note: I am not pasting the code for private class Student. The class definition for Student is same as Example3.*/Result",
                "I thought I'd contribute this answer to add more details from the Specifications.First, What's the difference between passing by reference vs. passing by value?Passing by reference means the called functions' parameter will be the\nsame as the callers' passed argument (not the value, but the identityPass by value means the called functions' parameter will be a copy of\nthe callers' passed argument.Or from wikipedia, on the subject of pass-by-referenceIn call-by-reference evaluation (also referred to as\npass-by-reference), a function receives an implicit reference to a\nvariable used as argument, rather than a copy of its value. This\ntypically means that the function can modify (i.e. assign to) the\nvariable used as argument\u2014something that will be seen by its caller.And on the subject of pass-by-valueIn call-by-value, the argument expression is evaluated, and the\nresulting value is bound to the corresponding variable in the function [...].\nIf the function or procedure is able to assign values to its\nparameters, only its local copy is assigned [...].Second, we need to know what Java uses in its method invocations. The Java Language Specification statesWhen the method or constructor is invoked (\u00a715.12), the values of the\nactual argument expressions initialize newly created parameter\nvariables, each of the declared type, before execution of the body of\nthe method or constructor.So it assigns (or binds) the value of the argument to the corresponding parameter variable.What is the value of the argument?Let's consider reference types, the Java Virtual Machine Specification statesThere are three kinds of reference types: class types, array types,\nand interface types. Their values are references to dynamically\ncreated class instances, arrays, or class instances or arrays that\nimplement interfaces, respectively.The Java Language Specification also statesThe reference values (often just references) are pointers to these objects, and a special null reference, which refers to no object.The value of an argument (of some reference type) is a pointer to an object. Note that a variable, an invocation of a method with a reference type return type, and an instance creation expression (new ...) all resolve to a reference type value.Soall bind the value of a reference to a String instance to the method's newly created parameter, param. This is exactly what the definition of pass-by-value describes. As such, Java is pass-by-value.The fact that you can follow the reference to invoke a method or access a field of the referenced object is completely irrelevant to the conversation. The definition of pass-by-reference wasThis typically means that the function can modify (i.e. assign to) the\nvariable used as argument\u2014something that will be seen by its caller.In Java, modifying the variable means reassigning it. In Java, if you reassigned the variable within the method, it would go unnoticed to the caller. Modifying the object referenced by the variable is a different concept entirely.Primitive values are also defined in the Java Virtual Machine Specification, here. The value of the type is the corresponding integral or floating point value, encoded appropriately (8, 16, 32, 64, etc. bits).",
                "You can never pass by reference in Java, and one of the ways that is obvious is when you want to return more than one value from a method call. Consider the following bit of code in C++:Sometimes you want to use the same pattern in Java, but you can't; at least not directly. Instead you could do something like this:As was explained in previous answers, in Java you're passing a pointer to the array as a value into getValues. That is enough, because the method then modifies the array element, and by convention you're expecting element 0 to contain the return value. Obviously you can do this in other ways, such as structuring your code so this isn't necessary, or constructing a class that can contain the return value or allow it to be set. But the simple pattern available to you in C++ above is not available in Java.",
                "The distinction, or perhaps just the way I remember as I used to be under the same impression as the original poster is this: Java is always pass by value. All objects( in Java, anything except for primitives) in Java are references. These references are passed by value.",
                "As many people mentioned it before, Java is always pass-by-valueHere is another example that will help you understand the difference (the classic swap example):Prints:Before: a = 2, b = 3\n  After: a = 2, b = 3This happens because iA and iB are new local reference variables that have the same value of the passed references (they point to a and b respectively). So, trying to change the references of iA or iB will only change in the local scope and not outside of this method.",
                "I always think of it as \"pass by copy\". It is a copy of the value be it primitive or reference. If it is a primitive it is a copy of the bits that are the value and if it is an Object it is a copy of the reference.output of java PassByCopy:name= Maxx\n  name= FidoPrimitive wrapper classes and Strings are immutable so any example using those types will not work the same as other types/objects.",
                "Unlike some other languages, Java does not allow you to choose between pass-by-value and pass-by-reference\u2014all arguments are passed by value. A method call can pass two types of values to a method\u2014copies of primitive values (e.g., values of int and double) and copies of references to objects.When a method modifies a primitive-type parameter, changes to the parameter have no effect on the original argument value in the calling method.When it comes to objects, objects themselves cannot be passed to methods. So we pass the reference(address) of the object. We can manipulate the original object using this reference.How Java creates and stores objects: When we create an object we store the object\u2019s address in a reference variable. Let's analyze the following statement.\u201cAccount account1\u201d is the type and name of the reference variable, \u201c=\u201d is the assignment operator, \u201cnew\u201d asks for the required amount of space from the system. The constructor to the right of keyword new which creates the object is called implicitly by the keyword new. Address of the created object(result of right value, which is an expression called \"class instance creation expression\") is assigned to the left value (which is a reference variable with a name and a type specified) using the assign operator.Although an object\u2019s reference is passed by value, a method can still interact with the referenced object by calling its public methods using the copy of the object\u2019s reference. Since the reference stored in the parameter is a copy of the reference that was passed as an argument, the parameter in the called method and the argument in the calling method refer to the same object in memory.Passing references to arrays, instead of the array objects themselves, makes sense for performance reasons. Because everything in Java is passed by value, if array objects were passed,\na copy of each element would be passed. For large arrays, this would waste time and consume\nconsiderable storage for the copies of the elements.In the image below you can see we have two reference variables(These are called pointers in C/C++, and I think that term makes it easier to understand this feature.) in the main method. Primitive and reference variables are kept in stack memory(left side in images below). array1 and array2 reference variables \"point\" (as C/C++ programmers call it) or reference to a and b arrays respectively, which are objects (values these reference variables hold are addresses of objects) in heap memory (right side in images below).If we pass the value of array1 reference variable as an argument to the reverseArray method, a reference variable is created in the method and that reference variable starts pointing to the same array (a).So, if we sayin reverseArray method, it will make a change in array a.We have another reference variable in reverseArray method (array2) that points to an array c. If we were to sayin reverseArray method, then the reference variable array1 in method reverseArray would stop pointing to array a and start pointing to array c (Dotted line in second image).If we return value of reference variable array2 as the return value of method reverseArray and assign this value to reference variable array1 in main method, array1 in main will start pointing to array c.So let's write all the things we have done at once now.And now that reverseArray method is over, its reference variables(array1 and array2) are gone. Which means we now only have the two reference variables in main method array1 and array2 which point to c and b arrays respectively. No reference variable is pointing to object (array) a. So it is eligible for garbage collection.You could also assign value of array2 in main to array1. array1 would start pointing to b.",
                "Java has only pass by value. A very simple example to validate this.",
                "To make a long story short, Java objects have some very peculiar properties.In general, Java has primitive types (int, bool, char, double, etc) that are passed directly by value. Then Java has objects (everything that derives from java.lang.Object). Objects are actually always handled through a reference (a reference being a pointer that you can't touch). That means that in effect, objects are passed by reference, as the references are normally not interesting. It does however mean that you cannot change which object is pointed to as the reference itself is passed by value.Does this sound strange and confusing? Let's consider how C implements pass by reference and pass by value. In C, the default convention is pass by value. void foo(int x) passes an int by value. void foo(int *x) is a function that does not want an int a, but a pointer to an int: foo(&a). One would use this with the & operator to pass a variable address.Take this to C++, and we have references. References are basically (in this context) syntactic sugar that hide the pointer part of the equation: void foo(int &x) is called by foo(a), where the compiler itself knows that it is a reference and the address of the non-reference a should be passed. In Java, all variables referring to objects are actually of reference type, in effect forcing call by reference for most intends and purposes without the fine grained control (and complexity) afforded by, for example, C++.",
                "I have created a thread devoted to these kind of questions for any programming languages here.Java is also mentioned. Here is the short summary:"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I make Git forget about a file that was tracked, but is now in .gitignore?",
                "I put a file that was previously being tracked by Git onto the .gitignore list. However, the file still shows up in git status after it is edited. How do I force Git to completely forget the file?"
            ],
            "url": "https://stackoverflow.com/questions/1274057",
            "answer": [
                ".gitignore will prevent untracked files from being added (without an add -f) to the set of files tracked by Git. However, Git will continue to track any files that are already being tracked.To stop tracking a file, we must remove it from the index:To remove a folder and all files in the folder recursively:The removal of the file from the head revision will happen on the next commit.WARNING: While this will not remove the physical file from your local machine, it will remove the files from other developers' machines on their next git pull.",
                "The series of commands below will remove all of the items from the Git index (not from the working directory or local repository), and then will update the Git index, while respecting Git ignores. PS. Index = CacheFirst:Then:Or as a one-liner:",
                "git update-index does the job for me:Note: This solution is actually independent of .gitignore as gitignore is only for untracked files.Since this answer was posted, a new option has been created and that should be preferred.  You should use --skip-worktree which is for modified tracked files that the user don't want to commit anymore and keep --assume-unchanged for performance to prevent git to check status of big tracked files. See https://stackoverflow.com/a/13631525/717372 for more details...To cancel",
                "This takes the list of the ignored files, removes them from the index, and commits the changes.",
                "Move it out, commit, and then move it back in.This has worked for me in the past, but there is probably a 'gittier' way to accomplish this.",
                "I always use this command to remove those untracked files.\nOne-line, Unix-style, clean output:It lists all your ignored files, replaces every output line with a quoted line instead to handle paths with spaces inside, and passes everything to git rm -r --cached to remove the paths/files/directories from the index.",
                "The copy/paste answer is:This command will NOT change the content of the .gitignore file. It will just ignore the files that have already been committed to a Git repository but now we have added them to .gitignore.The command git status; is just to review the changes and could be dropped.In the end, it will immediately commit the changes with the message \"Ignore unwanted files\".If you don't want to commit the changes, drop the last part of the command (git commit -m \"Ignore unwanted files\")",
                "Source: Untrack files already added to Git repository based on .gitignoreLet\u2019s say you have already added/committed some files to your Git repository and you then add them to your .gitignore file; these files will still be present in your repository index. This article we will see how to get rid of them.Before proceeding, make sure all your changes are committed, including your .gitignore file.To clear your repository, use:The rm command can be unforgiving. If you wish to try what it does beforehand, add the -n or --dry-run flag to test things out.Your repository is clean :)Push the changes to your remote to see the changes effective there as well.",
                "If you cannot git rm a tracked file because other people might need it (warning, even if you git rm --cached, when someone else gets this change, their files will be deleted in their filesystem).  These are often done due to config file overrides, authentication credentials, etc. Please look at https://gist.github.com/1423106 for ways people have worked around the problem.To summarize:",
                "I accomplished this by using git filter-branch. The exact command I used was taken from the man page:WARNING: this will delete the file from your entire historyThis command will recreate the entire commit history, executing git rm before each commit and so will get rid of the specified file. Don't forget to back it up before running the command as it will be lost.",
                "(Under Linux), I wanted to use the posts here suggesting the ls-files --ignored --exclude-standard | xargs git rm -r --cached approach.  However, (some of) the files to be removed had an embedded newline/LF/\\n in their names.  Neither of the solutions:cope with this situation (get errors about files not found).This uses the -z argument to ls-files, and the -0 argument to xargs to cater safely/correctly for \"nasty\" characters in filenames.In the manual page git-ls-files(1), it states:When -z option is not used, TAB, LF, and backslash characters in\npathnames are represented as \\t, \\n, and \\\\, respectively.so I think my solution is needed if filenames have any of these characters in them.",
                "Do the following steps for a file/folder:Remove a File:For example:I want to delete the test.txt file. I accidentally pushed to GitHub and want to remove it. Commands will be as follows:First, add \"test.txt\" in file .gitignoreRemove Folder:For example:I want to delete the .idea folder/directory. I accidentally pushed to GitHub and want to remove it. The commands will be as follows:First, add .idea in file .gitignore",
                "Update your .gitignore file \u2013 for instance, add a folder you don't want to track to .gitignore.git rm -r --cached . \u2013 Remove all tracked files, including wanted and unwanted. Your code will be safe as long as you have saved locally.git add . \u2013 All files will be added back in, except those in .gitignore.Hat tip to @AkiraYamamoto for pointing us in the right direction.",
                "Do the following steps serially, and you will be fine.Remove the mistakenly added files from the directory/storage. You can use the \"rm -r\" (for Linux) command or delete them by browsing the directories. Or move them to another location on your PC. (You maybe need to close the IDE if running for moving/removing.)Add the files / directories to the .gitignore file now and save it.Now remove them from the Git cache by using these commands (if there is more than one directory, remove them one by one by repeatedly issuing this command)Now do a commit and push by using the following commands. This will remove those files from Git remote and make Git stop tracking those files.",
                "I think, that maybe Git can't totally forget about a file because of its conception (section \"Snapshots, Not Differences\").This problem is absent, for example, when using CVS. CVS stores information as a list of file-based changes. Information for CVS is a set of files and the changes made to each file over time.But in Git every time you commit, or save the state of your project, it basically takes a picture of what all your files look like at that moment and stores a reference to that snapshot. So, if you added file once, it will always be present  in that snapshot.These two articles were helpful for me:git assume-unchanged vs skip-worktree and How to ignore changes in tracked files with GitBasing on it I do the following, if the file is already tracked:From this moment all local changes in this file will be ignored and will not go to remote. If the file is changed on remote, conflict will occur, when git pull. Stash won't work. To resolve it, copy the file content to the safe place and follow these steps:The file content will be replaced by the remote content. Paste your changes from the safe place to the file and perform again:If everyone, who works with the project, will perform git update-index --skip-worktree <file>, problems with pull should be absent. This solution is OK for configurations files, when every developer has their own project configuration.It is not very convenient to do this every time, when the file has been changed on remote, but it can protect it from overwriting by remote content.",
                "Move or copy the file to a safe location, so you don't lose it. Then 'git rm' the file and commit.The file will still show up if you revert to one of those earlier commits, or another branch where it has not been removed. However, in all future commits, you will not see the file again. If the file is in the Git ignore, then you can move it back into the folder, and Git won't see it.",
                "The answer from Matt Frear was the most effective IMHO. The following is just a PowerShell script for those on Windows to only remove files from their Git repository that matches their exclusion list.",
                "Using the git rm --cached command does not answer the original question:How do you force git to completely forget about [a file]?In fact, this solution will cause the file to be deleted in every other instance of the repository when executing a git pull!The correct way to force Git to forget about a file is documented by GitHub here.I recommend reading the documentation, but basically:Just replace full/path/to/file with the full path of the file. Make sure you've added the file to your .gitignore file.You'll also need to (temporarily) allow non-fast-forward pushes to your repository, since you're changing your Git history.",
                "git rm --cached -r <YOUR_files_or_folders>--cached  | only remove files from the index",
                "The accepted answer does not \"make Git \"forget\" about a file...\" (historically).  It only makes Git ignore the file in the present/future.This method makes Git completely forget ignored files (past/present/future), but it does not delete anything from the working directory (even when re-pulled from remote).This method requires usage of file /.git/info/exclude (preferred) or a pre-existing .gitignore in all the commits that have files to be ignored/forgotten. 1All methods of enforcing Git ignore behavior after-the-fact effectively rewrite history and thus have significant ramifications for any public/shared/collaborative repositories that might be pulled after this process. 2General advice: start with a clean repository - everything committed, nothing pending in working directory or index, and make a backup!Also, the comments/revision history of this answer (and revision history of this question) may be useful/enlightening.Finally, follow the rest of this GitHub guide (starting at step 6) which includes important warnings/information about the commands below.Other developers that pull from the now-modified remote repository should make a backup and then:1 Because /.git/info/exclude can be applied to all historical commits using the instructions above, perhaps details about getting a .gitignore file into the historical commit(s) that need it is beyond the scope of this answer.  I wanted a proper .gitignore file to be in the root commit, as if it was the first thing I did.  Others may not care since /.git/info/exclude can accomplish the same thing regardless where the .gitignore file exists in the commit history, and clearly rewriting history is a very touchy subject, even when aware of the ramifications.FWIW, potential methods may include git rebase or a git filter-branch that copies an external .gitignore into each commit, like the answers to this question.2 Enforcing Git ignore behavior after-the-fact by committing the results of a stand-alone git rm --cached command may result in newly-ignored file deletion in future pulls from the force-pushed remote. The --prune-empty flag in the following git filter-branch command avoids this problem by automatically removing the previous \"delete all ignored files\" index-only commit.  Rewriting Git history also changes commit hashes, which will wreak havoc on future pulls from public/shared/collaborative repositories.  Please understand the ramifications fully before doing this to such a repository. This GitHub guide specifies the following:Tell your collaborators to rebase, not merge, any branches they created off of your old (tainted) repository history. One merge commit could reintroduce some or all of the tainted history that you just went to the trouble of purging.Alternative solutions that do not affect the remote repository are git update-index --assume-unchanged </path/file> or git update-index --skip-worktree <file>, examples of which can be found here.",
                "In my case I needed to put \".envrc\" in the .gitignore file.And then I used:And the file was removed.Then I committed again, telling that the file was removed.But when I used the command git log -p, the content of the file (which was secret credentials of the Amazon S3) was showing the content which was removed and I don't want to show this content ever on the history of the Git repository.Then I used this command:And I don't see the content again.",
                "I liked JonBrave's answer, but I have messy enough working directories that commit -a scares me a bit, so here's what I've done:Breaking it down:",
                "The BFG is specifically designed for removing unwanted data like big files or passwords from Git repositories, so it has a simple flag that will remove any large historical (not-in-your-current-commit) files: '--strip-blobs-bigger-than'If you'd like to specify files by name, you can do that too:The BFG is 10-1000x faster than git filter-branch and is generally much easier to use - check the full usage instructions and examples for more details.Source: Reduce repository size",
                "If you don't want to use the CLI and are working on Windows, a very simple solution is to use TortoiseGit. It has the \"Delete (keep local)\" Action in the menu which works fine.",
                "This is no longer an issue in the latest Git (v2.17.1 at the time of writing).The .gitignore file finally ignores tracked-but-deleted files. You can test this for yourself by running the following script. The final git status statement should report \"nothing to commit\".",
                "This is how I solved my issue:git filter-branch --tree-filter 'rm -rf path/to/your/file' HEAD\n git pushIn this, we are basically trying to rewrite the history of that particular file in previous commits also.For more information, you can refer to the man page of filter-branch here.Source: Removing sensitive data from a repository - using filter-branchSource: Git: How to remove a big file wrongly committed",
                "In case of already committed DS_Store:Ignore them by:Finally, make a commit!",
                "Especially for the IDE-based files, I use this:For instance, for the slnx.sqlite file, I just got rid off it completely like the following:Just keep that in mind that some of those files store some local user settings and preferences for projects (like what files you had open). So every time you navigate or do some changes in your IDE, that file is changed and therefore it checks it out and show as uncommitted changes.",
                "If anyone is having a hard time on Windows and you want to ignore the entire folder, go to the desired 'folder' on file explorer, right click and do 'Git Bash Here' (Git for Windows should have been installed).Run this command:",
                "For me, the file was still available in the history and I first needed to squash the commits that added the removed files: https://gist.github.com/patik/b8a9dc5cd356f9f6f980"
            ]
        },
        {
            "tag": "",
            "question": [
                "Does Python have a ternary conditional operator?",
                "Is there a ternary conditional operator in Python?"
            ],
            "url": "https://stackoverflow.com/questions/394809",
            "answer": [
                "Yes, it was added in version 2.5. The expression syntax is:First condition is evaluated, then exactly one of either a or b is evaluated and returned based on the Boolean value of condition. If condition evaluates to True, then a is evaluated and returned but b is ignored, or else when b is evaluated and returned but a is ignored.This allows short-circuiting because when condition is true only a is evaluated and b is not evaluated at all, but when condition is false only b is evaluated and a is not evaluated at all.For example:Note that conditionals are an expression, not a statement. This means you can't use statements such as pass, or assignments with = (or \"augmented\" assignments like +=), within a conditional expression:(In 3.8 and above, the := \"walrus\" operator allows simple assignment of values as an expression, which is then compatible with this syntax. But please don't write code like that; it will quickly become very difficult to understand.)Similarly, because it is an expression, the else part is mandatory:You can, however, use conditional expressions to assign a variable like so:Or for example to return a value:Think of the conditional expression as switching between two values. We can use it when we are in a 'one value or another' situation, where we will do the same thing with the result, regardless of whether the condition is met. We use the expression to compute the value, and then do something with it. If you need to do something different depending on the condition, then use a normal if statement instead.Keep in mind that it's frowned upon by some Pythonistas for several reasons:If you're having trouble remembering the order, then remember that when read aloud, you (almost) say what you mean. For example, x = 4 if b > 8 else 9 is read aloud as x will be 4 if b is greater than 8 otherwise 9.Official documentation:",
                "You can index into a tuple:test needs to return True or False.\nIt might be safer to always implement it as:or you can use the built-in bool() to assure a Boolean value:",
                "For versions prior to 2.5, there's the trick:It can give wrong results when on_true has a false Boolean value.1Although it does have the benefit of evaluating expressions left to right, which is clearer in my opinion.1. Is there an equivalent of C\u2019s \u201d?:\u201d ternary operator?",
                "<expression 1> if <condition> else <expression 2>",
                "From the documentation:Conditional expressions (sometimes called a \u201cternary operator\u201d) have the lowest priority of all Python operations.The expression x if C else y first evaluates the condition, C (not x); if C is true, x is evaluated and its value is returned; otherwise, y is evaluated and its value is returned.See PEP 308 for more details about conditional expressions.New since version 2.5.",
                "An operator for a conditional expression in Python was added in 2006 as part of Python Enhancement Proposal 308. Its form differ from common ?: operator and it's:which is equivalent to:Here is an example:Another syntax which can be used (compatible with versions before 2.5):where operands are lazily evaluated.Another way is by indexing a tuple (which isn't consistent with the conditional operator of most other languages):or explicitly constructed dictionary:Another (less reliable), but simpler method is to use and and or operators:however this won't work if x would be False.A possible workaround is to make x and y lists or tuples as in the following:or:If you're working with dictionaries, instead of using a ternary conditional, you can take advantage of get(key, default), for example:Source: ?: in Python at Wikipedia",
                "Unfortunately, thesolution doesn't have short-circuit behaviour; thus both falseValue and trueValue are evaluated regardless of the condition. This could be suboptimal or even buggy (i.e. both trueValue and falseValue could be methods and have side effects).One solution to this would be(execution delayed until the winner is known ;)), but it introduces inconsistency between callable and non-callable objects. In addition, it doesn't solve the case when using properties.And so the story goes - choosing between three mentioned solutions is a trade-off between having the short-circuit feature, using at least Python 2.5 (IMHO, not a problem anymore) and not being prone to \"trueValue-evaluates-to-false\" errors.",
                "Here I just try to show some important differences in the ternary operator between a couple of programming languages.",
                "For Python 2.5 and newer there is a specific syntax:In older Pythons a ternary operator is not implemented but it's possible to simulate it.Though, there is a potential problem, which if cond evaluates to True and on_true evaluates to False then on_false is returned instead of on_true. If you want this behavior the method is OK, otherwise use this:which can be wrapped by:and used this way:It is compatible with all Python versions.",
                "You might often findbut this leads to a problem when on_true == 0Where you would expect this result for a normal ternary operator:",
                "Yes. From the grammar file:The part of interest is:So, a ternary conditional operation is of the form:expression3 will be lazily evaluated (that is, evaluated only if expression2 is false in a boolean context). And because of the recursive definition, you can chain them indefinitely (though it may considered bad style.)Note that every if must be followed with an else. People learning list comprehensions and generator expressions may find this to be a difficult lesson to learn - the following will not work, as Python expects a third expression for an else:which raises a SyntaxError: invalid syntax.\nSo the above is either an incomplete piece of logic (perhaps the user expects a no-op in the false condition) or what may be intended is to use expression2 as a filter - notes that the following is legal Python:expression2 works as a filter for the list comprehension, and is not a ternary conditional operator.You may find it somewhat painful to write the following:expression1 will have to be evaluated twice with the above usage. It can limit redundancy if it is simply a local variable. However, a common and performant Pythonic idiom for this use-case is to use or's shortcutting behavior:which is equivalent in semantics. Note that some style-guides may limit this usage on the grounds of clarity - it does pack a lot of meaning into very little syntax.",
                "One of the alternatives to Python's conditional expressionis the following:which has the following nice extension:The shortest alternative remainswhich works because issubclass(bool, int).Careful, though: the alternative tois notbutThis works fine as long as no and yes are to be called with exactly the same parameters. If they are not, like inor inthen a similar alternative either does not exist (1) or is hardly viable (2). (In rare cases, depending on the context, something likecould make sense.)Thanks to Radek Roj\u00edk for his comment",
                "As already answered, yes, there is a ternary operator in Python:In many cases <expression 1> is also used as Boolean evaluated <condition>. Then you can use short-circuit evaluation.One big pro of short-circuit evaluation is the possibility of chaining more than two expressions:When working with functions it is more different in detail:PS: Of course, a short-circuit evaluation is not a ternary operator, but often the ternary is used in cases where the short circuit would be enough. It has a better readability and can be chained.",
                "Simulating the Python ternary operator.For exampleOutput:",
                "Just memorize this pyramid if you have trouble remembering:",
                "The ternary conditional operator simply allows testing a condition in a single line replacing the multiline if-else making the code compact.[on_true] if [expression] else [on_false]Above approach can be written as:",
                "Vinko Vrsalovic's answer is good enough. There is only one more thing:Note that conditionals are an expression, not a statement. This means you can't use assignment statements or pass or other statements within a conditional expressionAfter the walrus operator was introduced in Python 3.8, something changed.gives a = 3 and b is not defined,gives a is not defined and b = 5, andgives c = 5, a is not defined and b = 5.Even if this may be ugly, assignments can be done inside conditional expressions after Python 3.8. Anyway, it is still better to use normal if statement instead in this case.",
                "More a tip than an answer (I don't need to repeat the obvious for the hundredth time), but I sometimes use it as a one-liner shortcut in such constructs:, becomes:Some (many :) may frown upon it as unpythonic (even, Ruby-ish :), but I personally find it more natural - i.e., how you'd express it normally, plus a bit more visually appealing in large blocks of code.",
                "You can do this:Example:This would print \"odd\" if the number is odd or \"even\" if the number is even.The result: If condition is true, exp_1 is executed, else exp_2 is executed.Note: 0, None, False, emptylist, and emptyString evaluates as False.And any data other than 0 evaluates to True.If the condition [condition] becomes \"True\", then expression_1 will be evaluated, but not expression_2.If we \"and\" something with 0 (zero), the result will always to be false. So in the below statement,The expression exp won't be evaluated at all since \"and\" with 0 will always evaluate to zero and there is no need to evaluate the expression. This is how the compiler itself works, in all languages.Inthe expression exp won't be evaluated at all since \"or\" with 1 will always be 1. So it won't bother to evaluate the expression exp since the result will be 1 anyway (compiler optimization methods).But in case ofThe second expression exp2 won't be evaluated since True and exp1 would be True when exp1 isn't false.Similarly inThe expression exp1 won't be evaluated since False is equivalent to writing 0 and doing \"and\" with 0 would be 0 itself, but after exp1 since \"or\" is used, it will evaluate the expression exp2 after \"or\".Note:- This kind of branching using \"or\" and \"and\" can only be used when the expression_1 doesn't have a Truth value of False (or 0 or None or emptylist [ ] or emptystring ' '.) since if expression_1 becomes False, then the expression_2 will be evaluated because of the presence \"or\" between exp_1 and exp_2.In case you still want to make it work for all the cases regardless of what exp_1 and exp_2 truth values are, do this:",
                "Many programming languages derived from C usually have the following syntax of the ternary conditional operator:At first, the Python's benevolent dictator for life (I mean Guido van Rossum, of course) rejected it (as non-Pythonic style), since it's quite hard to understand for people not used to C language. Also, the colon sign : already has many uses in Python. After PEP 308 was approved, Python finally received its own shortcut conditional expression (what we use now):So, firstly it evaluates the condition. If it returns True, expression1 will be evaluated to give the result, otherwise expression2 will be evaluated. Due to lazy evaluation mechanics \u2013 only one expression will be executed.Here are some examples (conditions will be evaluated from left to right):Ternary operators can be chained in series:The following one is the same as previous one:",
                "Yes, Python have a ternary operator, here is the syntax and an example code to demonstrate the same :)",
                "Other answers correctly talk about the Python ternary operator. I would like to complement by mentioning a scenario for which the ternary operator is often used, but for which there is a better idiom. This is the scenario of using a default value.Suppose we want to use option_value with a default value if it is not set:or, if option_value is never set to a falsy value (0, \"\", etc.), simplyHowever, in this case an ever better solution is simply to write",
                "The syntax for the ternary operator in Python is:[on_true] if [expression] else [on_false]Using that syntax, here is how we would rewrite the code above using Python\u2019s ternary operator:It's still pretty clear, but much shorter. Note that the expression could be any type of expression, including a function call, that returns a value that evaluates to True or False.",
                "Python has a ternary form for assignments; however there may be even a shorter form that people should be aware of.It's very common to need to assign to a variable one value or another depending on a condition.^ This is the long form for doing such assignments.Below is the ternary form. But this isn't the most succinct way - see the last example.With Python, you can simply use or for alternative assignments.The above works since li1 is None and the interpreter treats that as False in logic expressions. The interpreter then moves on and evaluates the second expression, which is not None and it's not an empty list - so it gets assigned to a.This also works with empty lists. For instance, if you want to assign a whichever list has items.Knowing this, you can simply such assignments whenever you encounter them. This also works with strings and other iterables. You could assign a whichever string isn't empty.I always liked the C ternary syntax, but Python takes it a step further!I understand that some may say this isn't a good stylistic choice, because it relies on mechanics that aren't immediately apparent to all developers. I personally disagree with that viewpoint. Python is a syntax-rich language with lots of idiomatic tricks that aren't immediately apparent to the dabbler. But the more you learn and understand the mechanics of the underlying system, the more you appreciate it.",
                "Pythonic way of doing the things:But there always exists a different way of doing a ternary condition too:",
                "There are multiple ways. The simplest one is to use the condition inside the \"print\" method.You can useWhich is equivalent to:In this way, more than two statements are also possible to print. For example:can be written as:",
                "The if else-if version can be written as:",
                "Yes, it has, but it's different from C-syntax-like programming languages (which is condition ? value_if_true : value_if_falseIn Python, it goes like this: value_if_true if condition else value_if_falseExample: even_or_odd = \"even\" if x % 2 == 0 else \"odd\"",
                "A neat way to chain multiple operators:",
                "I find the default Python syntax val = a if cond else b cumbersome, so sometimes I do this:Of course, it has the downside of always evaluating both sides (a and b), but the syntax is way clearer to me."
            ]
        },
        {
            "tag": "",
            "question": [
                "var functionName = function() {} vs function functionName() {}",
                "I've recently started maintaining someone else's JavaScript code. I'm fixing bugs, adding features and also trying to tidy up the code and make it more consistent.\nThe previous developer used two ways ..."
            ],
            "url": "https://stackoverflow.com/questions/336859",
            "answer": [
                "The difference is that functionOne is a function expression and so only defined when that line is reached, whereas functionTwo is a function declaration and is defined as soon as its surrounding function or script is executed (due to hoisting).For example, a function expression:// TypeError: functionOne is not a function\r\nfunctionOne();\r\n\r\nvar functionOne = function() {\r\n  console.log(\"Hello!\");\r\n};And, a function declaration:// Outputs: \"Hello!\"\r\nfunctionTwo();\r\n\r\nfunction functionTwo() {\r\n  console.log(\"Hello!\");\r\n}Historically, function declarations defined within blocks were handled inconsistently between browsers. Strict mode (introduced in ES5) resolved this by scoping function declarations to their enclosing block.'use strict';    \r\n{ // note this block!\r\n  function functionThree() {\r\n    console.log(\"Hello!\");\r\n  }\r\n}\r\nfunctionThree(); // ReferenceError",
                "First I want to correct Greg: function abc(){} is scoped too \u2014 the name abc is defined in the scope where this definition is encountered. Example:Secondly, it is possible to combine both styles:xyz is going to be defined as usual, abc is undefined in all browsers but Internet\u00a0Explorer \u2014 do not rely on it being defined. But it will be defined inside its body:If you want to alias functions on all browsers, use this kind of declaration:In this case, both xyz and abc are aliases of the same object:One compelling reason to use the combined style is the \"name\" attribute of function objects (not supported by Internet\u00a0Explorer). Basically when you define a function likeits name is automatically assigned. But when you define it likeits name is empty \u2014 we created an anonymous function and assigned it to some variable.Another good reason to use the combined style is to use a short internal name to refer to itself, while providing a long non-conflicting name for external users:In the example above we can do the same with an external name, but it'll be too unwieldy (and slower).(Another way to refer to itself is to use arguments.callee, which is still relatively long, and not supported in the strict mode.)Deep down, JavaScript treats both statements differently. This is a function declaration:abc here is defined everywhere in the current scope:Also, it hoisted through a return statement:This is a function expression:xyz here is defined from the point of assignment:Function declaration vs. function expression is the real reason why there is a difference demonstrated by Greg.Fun fact:Personally, I prefer the \"function expression\" declaration because this way I can control the visibility. When I define the function likeI know that I defined the function locally. When I define the function likeI know that I defined it globally providing that I didn't define abc anywhere in the chain of scopes. This style of definition is resilient even when used inside eval(). While the definitiondepends on the context and may leave you guessing where it is actually defined, especially in the case of eval() \u2014 the answer is: It depends on the browser.",
                "Here's the rundown on the standard forms that create functions: (Originally written for another question, but adapted after being moved into the canonical question.)Terms:The quick list:Function Declaration\"Anonymous\" function Expression (which despite the term, sometimes create functions with names)Named function ExpressionAccessor Function Initializer (ES5+)Arrow Function Expression (ES2015+) (which, like anonymous function expressions, don't involve an explicit name, and yet can create functions with names)Method Declaration in Object Initializer (ES2015+)Constructor and Method Declarations in class (ES2015+)The first form is a function declaration, which looks like this:A function declaration is a declaration; it's not a statement or expression. As such, you don't follow it with a ; (although doing so is harmless).A function declaration is processed when execution enters the context in which it appears, before any step-by-step code is executed. The function it creates is given a proper name (x in the example above), and that name is put in the scope in which the declaration appears.Because it's processed before any step-by-step code in the same context, you can do things like this:Until ES2015, the spec didn't cover what a JavaScript engine should do if you put a function declaration inside a control structure like try, if, switch, while, etc., like this:And since they're processed before step-by-step code is run, it's tricky to know what to do when they're in a control structure.Although doing this wasn't specified until ES2015, it was an allowable extension to support function declarations in blocks. Unfortunately (and inevitably), different engines did different things.As of ES2015, the specification says what to do. In fact, it gives three separate things to do:The rules for the loose modes are tricky, but in strict mode, function declarations in blocks are easy: They're local to the block (they have block scope, which is also new in ES2015), and they're hoisted to the top of the block. So:The second common form is called an anonymous function expression:Like all expressions, it's evaluated when it's reached in the step-by-step execution of the code.In ES5, the function this creates has no name (it's anonymous). In ES2015, the function is assigned a name if possible by inferring it from context. In the example above, the name would be y. Something similar is done when the function is the value of a property initializer. (For details on when this happens and the rules, search for SetFunctionName in the the specification\u00a0\u2014 it appears all over the place.)The third form is a named function expression (\"NFE\"):The function this creates has a proper name (w in this case). Like all expressions, this is evaluated when it's reached in the step-by-step execution of the code. The name of the function is not added to the scope in which the expression appears; the name is in scope within the function itself:Note that NFEs have frequently been a source of bugs for JavaScript implementations. IE8 and earlier, for instance, handle NFEs completely incorrectly, creating two different functions at two different times. Early versions of Safari had issues as well. The good news is that current versions of browsers (IE9 and up, current Safari) don't have those issues any more. (But as of this writing, sadly, IE8 remains in widespread use, and so using NFEs with code for the web in general is still problematic.)Sometimes functions can sneak in largely unnoticed; that's the case with accessor functions. Here's an example:Note that when I used the function, I didn't use ()! That's because it's an accessor function for a property. We get and set the property in the normal way, but behind the scenes, the function is called.You can also create accessor functions with Object.defineProperty, Object.defineProperties, and the lesser-known second argument to Object.create.ES2015 brings us the arrow function. Here's one example:See that n => n * 2 thing hiding in the map() call? That's a function.A couple of things about arrow functions:They don't have their own this. Instead, they close over the this of the context where they're defined. (They also close over arguments and, where relevant, super.) This means that the this within them is the same as the this where they're created, and cannot be changed.As you'll have noticed with the above, you don't use the keyword function; instead, you use =>.The n => n * 2 example above is one form of them. If you have multiple arguments to pass the function, you use parens:(Remember that Array#map passes the entry as the first argument, and the index as the second.)In both cases, the body of the function is just an expression; the function's return value will automatically be the result of that expression (you don't use an explicit return).If you're doing more than just a single expression, use {} and an explicit return (if you need to return a value), as normal:The version without { ... } is called an arrow function with an expression body or concise body. (Also: A concise arrow function.) The one with { ... } defining the body is an arrow function with a function body. (Also: A verbose arrow function.)ES2015 allows a shorter form of declaring a property that references a function called a method definition; it looks like this:the almost-equivalent in ES5 and earlier would be:the difference (other than verbosity) is that a method can use super, but a function cannot. So for instance, if you had an object that defined (say) valueOf using method syntax, it could use super.valueOf() to get the value Object.prototype.valueOf would have returned (before presumably doing something else with it), whereas the ES5 version would have to do Object.prototype.valueOf.call(this) instead.That also means that the method has a reference to the object it was defined on, so if that object is temporary (for instance, you're passing it into Object.assign as one of the source objects), method syntax could mean that the object is retained in memory when otherwise it could have been garbage collected (if the JavaScript engine doesn't detect that situation and handle it if none of the methods uses super).ES2015 brings us class syntax, including declared constructors and methods:There are two function declarations above: One for the constructor, which gets the name Person, and one for getFullName, which is a function assigned to Person.prototype.",
                "Speaking about the global context, both, the var statement and a FunctionDeclaration at the end will create a non-deleteable property on the global object, but the value of both can be overwritten.The subtle difference between the two ways is that when the Variable Instantiation process runs (before the actual code execution) all identifiers declared with var will be initialized with undefined, and the ones used by the FunctionDeclaration's will be available since that moment, for example:The assignment of the bar FunctionExpression takes place until runtime.A global property created by a FunctionDeclaration can be overwritten without any problems just like a variable value, e.g.:Another obvious difference between your two examples is that the first function doesn't have a name, but the second has it, which can be really useful when debugging (i.e. inspecting a call stack).About your edited first example (foo = function() { alert('hello!'); };), it is an undeclared assignment, I would highly encourage you to always use the var keyword.With an assignment, without the var statement, if the referenced identifier is not found in the scope chain, it will become a deleteable property of the global object.Also, undeclared assignments throw a ReferenceError on ECMAScript 5 under Strict Mode.A must read:Note: This answer has been merged from another question, in which the major doubt and misconception from the OP was that identifiers declared with a FunctionDeclaration, couldn't be overwritten which is not the case.",
                "The two code snippets you've posted there will, for almost all purposes, behave the same way.However, the difference in behaviour is that with the first variant (var functionOne = function() {}), that function can only be called after that point in the code.With the second variant (function functionTwo()), the function is available to code that runs above where the function is declared.This is because with the first variant, the function is assigned to the variable foo at run time. In the second, the function is assigned to that identifier, foo, at parse time.More technical informationJavaScript has three ways of defining functions.",
                "A better explanation to Greg's answerWhy no error? We were always taught that expressions are executed from top to bottom(??)Function declarations and variable declarations are always moved (hoisted) invisibly to the top of their containing scope by the JavaScript interpreter. Function parameters and language-defined names are, obviously, already there. ben cherryThis means that code like this:Notice that the assignment portion of the declarations were not hoisted. Only the name is hoisted.But in the case with function declarations, the entire function body will be hoisted as well:",
                "Other commenters have already covered the semantic difference of the two variants above. I wanted to note a stylistic difference: Only the \"assignment\" variation can set a property of another object.I often build JavaScript modules with a pattern like this:With this pattern, your public functions will all use assignment, while your private functions use declaration.(Note also that assignment should require a semicolon after the statement, while declaration prohibits it.)",
                "An illustration of when to prefer the first method to the second one is when you need to avoid overriding a function's previous definitions.With, this definition of myfunction will override any previous definition, since it will be done at parse-time.Whiledoes the correct job of defining myfunction only when condition is met.",
                "An important reason is to add one and only one variable as the \"Root\" of your namespace...orThere are many techniques for namespacing. It's become more important with the plethora of JavaScript modules available.Also see How do I declare a namespace in JavaScript?",
                "Hoisting is the JavaScript interpreter\u2019s action of moving all variable and function declarations to the top of the current scope.However, only the actual declarations are hoisted. by leaving assignments where they are.VariableJavascript is called loosely typed language. Which means Javascript variables can hold value of any Data-Type. Javascript automatically takes care of changing the variable-type based on the value/literal provided during runtime.FunctionDefault return value of function is 'undefined', Variable declaration default value also 'undefined'Function DeclarationFunction ExpressionFunction assigned to variable Example:javascript interpreted asYou can check function declaration, expression test over different browser's using jsperf Test RunnerES5 Constructor Function Classes: Function objects created using Function.prototype.bindJavaScript treats functions as first-class objects, so being an object, you can assign properties to a function.ES6 introduced Arrow function: An arrow function expression has a shorter syntax, they are best suited for non-method functions, and they cannot be used as constructors.ArrowFunction : ArrowParameters => ConciseBody.",
                "I'm adding my own answer just because everyone else has covered the hoisting part thoroughly.I've wondered about which way is better for a long while now, and thanks to http://jsperf.com now I know :)Function declarations are faster, and that's what really matters in web dev right? ;)",
                "The following works because function add() is scoped to the nearest block:try {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nfunction add(a, b){\n  return a + b;\n}The following does not work because the variable is called before a function value is assigned to the variable add.try {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nvar add=function(a, b){\n  return a + b;\n}The above code is identical in functionality to the code below. Note that explicitly assigning add = undefined is superfluous because simply doing var add; is the exact same as var add=undefined.var add = undefined;\n\ntry {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nadd = function(a, b){\n  return a + b;\n}The following does not work because var add= begins an expression and causes the following function add() to be an expression instead of a block. Named functions are only visible to themselves and their surrounding block. As function add() is an expression here, it has no surrounding block, so it is only visible to itself.try {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nvar add=function add(a, b){\n  return a + b;\n}The name of a function function thefuncname(){} is thefuncname when it is declared this way.function foobar(a, b){}\n\nconsole.log(foobar.name);var a = function foobar(){};\n\nconsole.log(a.name);Otherwise, if a function is declared as function(){}, the function.name is the first variable used to store the function.var a = function(){};\nvar b = (function(){ return function(){} });\n\nconsole.log(a.name);\nconsole.log(b.name);If there are no variables set to the function, then the functions name is the empty string (\"\").console.log((function(){}).name === \"\");Lastly, while the variable the function is assigned to initially sets the name, successive variables set to the function do not change the name.var a = function(){};\nvar b = a;\nvar c = b;\n\nconsole.log(a.name);\nconsole.log(b.name);\nconsole.log(c.name);In Google's V8 and Firefox's Spidermonkey there might be a few microsecond JIT compilation difference, but ultimately the result is the exact same. To prove this, let's examine the efficiency of JSPerf at micro-benchmarks by comparing the speed of two blank code snippets. The JSPerf tests are found here. And, the jsben.ch tests are  found here. As you can see, there is a noticeable difference when there should be none. If you are really a performance freak like me, then it might be more worth your while trying to reduce the number of variables and functions in the scope and especially eliminating polymorphism (such as using the same variable to store two different types).When you use the var keyword to declare a variable, you can then reassign a different value to the variable like so.(function(){\n    \"use strict\";\n    var foobar = function(){}; // initial value\n    try {\n        foobar = \"Hello World!\"; // new value\n        console.log(\"[no error]\");\n    } catch(error) {\n        console.log(\"ERROR: \" + error.message);\n    }\n    console.log(foobar, window.foobar);\n})();However, when we use the const-statement, the variable reference becomes immutable. This means that we cannot assign a new value to the variable. Please note, however, that this does not make the contents of the variable immutable: if you do const arr = [], then you can still do arr[10] = \"example\". Only doing something like arr = \"new value\" or arr = [] would throw an error as seen below.(function(){\n    \"use strict\";\n    const foobar = function(){}; // initial value\n    try {\n        foobar = \"Hello World!\"; // new value\n        console.log(\"[no error]\");\n    } catch(error) {\n        console.log(\"ERROR: \" + error.message);\n    }\n    console.log(foobar, window.foobar);\n})();Interestingly, if we declare the variable as function funcName(){}, then the immutability of the variable is the same as declaring it with var.(function(){\n    \"use strict\";\n    function foobar(){}; // initial value\n    try {\n        foobar = \"Hello World!\"; // new value\n        console.log(\"[no error]\");\n    } catch(error) {\n        console.log(\"ERROR: \" + error.message);\n    }\n    console.log(foobar, window.foobar);\n})();The \"nearest block\" is the nearest \"function,\" (including asynchronous functions, generator functions, and asynchronous generator functions). However, interestingly, a function functionName() {} behaves like a var functionName = function() {} when in a non-closure block to items outside said closure. Observe.try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}');\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\nvar add=function(a, b){return a + b}try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\nfunction add(a, b){\n  return a + b;\n}try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n(function () {\n    function add(a, b){\n      return a + b;\n    }\n})();try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n{\n    function add(a, b){\n      return a + b;\n    }\n}try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n(() => {\n    var add=function(a, b){\n      return a + b;\n    }\n})();try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n(() => {\n    function add(a, b){\n      return a + b;\n    }\n})();",
                "A function declaration and a function expression assigned to a variable behave the same once the binding is established.There is a difference however at how and when the function object is actually associated with its variable. This difference is due to the mechanism called variable hoisting in JavaScript.Basically, all function declarations and variable declarations are hoisted to the top of the function in which the declaration occurs (this is why we say that JavaScript has function scope).When a function declaration is hoisted, the function body \"follows\"\nso when the function body is evaluated, the variable will immediately\nbe bound to a function object.When a variable declaration is hoisted, the initialization does not\nfollow, but is \"left behind\". The variable is initialized to\nundefined at the start of the function body, and will be assigned\na value at its original location in the code. (Actually, it will be assigned a value at every location where a declaration of a variable with the same name occurs.)The order of hoisting is also important: function declarations take precedence over variable declarations with the same name, and the last function declaration takes precedence over previous function declarations with the same name.Some examples...Variable foo is hoisted to the top of the function, initialized to undefined, so that !foo is true, so foo is assigned 10. The foo outside of bar's scope plays no role and is untouched.Function declarations take precedence over variable declarations, and the last function declaration \"sticks\".In this example a is initialized with the function object resulting from evaluating the second function declaration, and then is assigned 4.Here the function declaration is hoisted first, declaring and initializing variable a. Next, this variable is assigned 10. In other words: the assignment does not assign to outer variable a.",
                "The first example is a function declaration:The second example is a function expression:The main difference is how they are hoisted (lifted and declared). In the first example, the whole function declaration is hoisted. In the second example only the var 'abc' is hoisted, its value (the function) will be undefined, and the function itself remains at the position that it is declared.To put it simply:To study more about this topic I strongly recommend you this\nlink",
                "In terms of code maintenance cost, named functions are more preferable:I suspect more PROS for named functions are follow. And what is listed as an advantage of named functions is a disadvantage for anonymous ones.Historically, anonymous functions appeared from the inability of JavaScript as a language to list members with named functions:",
                "In computer science terms, we talk about anonymous functions and named functions. I think the most important difference is that an anonymous function is not bound to a name, hence the name anonymous function. In JavaScript it is a first class object dynamically declared at runtime.For more information on anonymous functions and lambda calculus, Wikipedia is a good start: Anonymous Functions.",
                "I use the variable approach in my code for a very specific reason, the theory of which has been covered in an abstract way above, but an example might help some people like me, with limited JavaScript expertise.I have code that I need to run with 160 independently-designed brandings. Most of the code is in shared files, but branding-specific stuff is in a separate file, one for each branding.Some brandings require specific functions, and some do not. Sometimes I have to add new functions to do new branding-specific things. I am happy to change the shared coded, but I don't want to have to change all 160 sets of branding files.By using the variable syntax, I can declare the variable (a function pointer essentially) in the shared code and either assign a trivial stub function, or set to null.The one or two brandings that need a specific implementation of the function can then define their version of the function and assign this to the variable if they want, and the rest do nothing. I can test for a null function before I execute it in the shared code.From people's comments above, I gather it may be possible to redefine a static function too, but I think the variable solution is nice and clear.",
                "Greg's Answer is good enough, but I still would like to add something to it that I learned just now watching Douglas Crockford's videos.Function expression:Function statement:The function statement is just a shorthand for var statement with a function value.Soexpands toWhich expands further to:And they are both hoisted to the top of the code.",
                "@EugeneLazutkin gives an example where he names an assigned function to be able to use shortcut() as an internal reference to itself. John Resig gives another example - copying a recursive function assigned to another object in his Learning Advanced Javascript tutorial. While assigning functions to properties isn't strictly the question here, I recommend actively trying the tutorial out - run the code by clicking the button in the upper right corner, and double click the code to edit to your liking.Examples from the tutorial: recursive calls in yell():Tests fail when the original ninja object is removed. (page 13)function assert(predicate, message) { if(!predicate) { throw new Error(message); } }\n\nvar ninja = {\n  yell: function(n){\nreturn n > 0 ? ninja.yell(n-1) + \"a\" : \"hiy\";\n  }\n};\nassert( ninja.yell(4) == \"hiyaaaa\", \"A single object isn't too bad, either.\" ); \n\nvar samurai = { yell: ninja.yell };\nvar ninja = null;\n\ntry {\n  samurai.yell(4);\n} catch(e){\n  assert( false, \"Uh, this isn't good! Where'd ninja.yell go?\" );\n}If you name the function that will be called recursively, the tests will pass. (page 14)function assert(predicate, message) { if(!predicate) { throw new Error(message); } }\n\nvar ninja = {\n  yell: function yell(n){\nreturn n > 0 ? yell(n-1) + \"a\" : \"hiy\";\n  }\n};\nassert( ninja.yell(4) == \"hiyaaaa\", \"Works as we would expect it to!\" );\n \nvar samurai = { yell: ninja.yell };\nvar ninja = {};\nassert( samurai.yell(4) == \"hiyaaaa\", \"The method correctly calls itself.\" );\n\nconsole.log(samurai.yell(4));",
                "Another difference that is not mentioned in the other answers is that if you use the anonymous functionand use that as a constructor as inthen one.constructor.name will not be defined. Function.name is non-standard but is supported by Firefox, Chrome, other Webkit-derived browsers and IE 9+.Withit is possible to retrieve the name of the constructor as a string with two.constructor.name.",
                "The first one (function doSomething(x)) should be part of an object notation.The second one (var doSomething = function(x){ alert(x);}) is simply creating an anonymous function and assigning it to a variable, doSomething. So doSomething() will call the function.You may want to know what a function declaration and function expression is.A function declaration defines a named function variable without requiring variable assignment. Function declarations occur as standalone constructs and cannot be nested within non-function blocks.ECMA 5 (13.0) defines the syntax as \n  function Identifier ( FormalParameterListopt ) { FunctionBody }In above condition the function name is visible within its scope and the scope of its parent (otherwise it would be unreachable).And in a function expressionA function expression defines a function as a part of a larger expression syntax (typically a variable assignment ). Functions defined via functions expressions can be named or anonymous. Function expressions should not start with \u201cfunction\u201d.ECMA 5 (13.0) defines the syntax as \n  function Identifieropt ( FormalParameterListopt ) { FunctionBody }",
                "I'm listing out the differences below:A function declaration can be placed anywhere in the code. Even if it is invoked before the definition appears in code, it gets executed as function declaration is committed to memory or in a way it is hoisted up, before any other code in the page starts execution.Take a look at the function below:This is because, during execution, it looks like:-A function expression, if not defined before calling it, will result in an error. Also, here the function definition itself is not moved to the top or committed to memory like in the function declarations. But the variable to which we assign the function gets hoisted up and undefined gets assigned to it.Same function using function expressions:This is because during execution, it looks like:It is not safe to write function declarations in non-function blocks like if because they won't be accessible.Named function expression like the one below, may not work in Internet\u00a0Explorer browsers prior to version 9.",
                "About performance:New versions of V8 introduced several under-the-hood optimizations and so did SpiderMonkey.There is almost no difference now between expression and declaration. Function expression appears to be faster now.Chrome 62.0.3202FireFox 55Chrome Canary 63.0.3225Anonymous function expressions appear to have better performance\n  against Named function expression.Firefox\n\nChrome Canary\n\nChrome",
                "If you would use those functions to create objects, you would get:",
                "In JavaScript there are two ways to create functions:Function declaration:This is very basic, self-explanatory, used in many languages and standard across C family of languages. We declared a function defined it and executed it by calling it.What you should be knowing is that functions are actually objects in JavaScript; internally we have created an object for above function and given it a name called fn or the reference to the object is stored in fn. Functions are objects in JavaScript; an instance of function is actually an object instance.Function expression:JavaScript has first-class functions, that is, create a function and assign it to a variable just like you create a string or number and assign it to a variable. Here, the fn variable is assigned to a function. The reason for this concept is functions are objects in JavaScript; fn is pointing to the object instance of the above function. We have initialized a function and assigned it to a variable. It's not executing the function and assigning the result.Reference: JavaScript function declaration syntax: var fn = function() {} vs function fn() {}",
                "The first function syntax is Anonymous Function Expression:While, the second one is Function Declaration:The main difference between both is the function name since Anonymous Functions have no name to call.\nAnonymous functions are quick and easy to declare, and many libraries and tools tend to encourage this idiomatic style of code. However, anonymous functions have some drawbacks:Readability: anonymous functions omit a name which could cause less readable code.Debugging: anonymous functions have no name in stack traces, which can make debugging more difficult.Self-Reference: what if the function needs to refer to itself, for recursion for example.Providing a name for your function expression quite effectively addresses all these drawbacks, and has no tangible downsides. The best practice is to always name your function expressions:For functions assigned to a variable, naming the function, in this case, is not very common and may cause confusion, in this case, the arrow function may be a better choice.",
                "In light of the \"named functions show up in stack traces\" argument, modern JavaScript engines are actually quite capable of representing anonymous functions.As of this writing, V8, SpiderMonkey, Chakra and Nitro always refer to named functions by their names. They almost always refer to an anonymous function by its identifier if it has one.SpiderMonkey can figure out the name of an anonymous function returned from another function. The rest can't.If you really, really wanted your iterator and success callbacks to show up in the trace, you could name those too...But for the most part it's not worth stressing over.",
                "Both are different ways of defining a function. The difference is how the browser interprets and loads them into an execution context.The first case is of function expressions which loads only when the interpreter reaches that line of code. So if you do it like the following, you will get an error that the functionOne is not a function.The reason is that on the first line no value is assigned to functionOne, and hence it is undefined. We are trying to call it as a function, and hence we are getting an error.On the second line we are assigning the reference of an anonymous function to functionOne.The second case is of function declarations that loads before any code is executed. So if you do like the following you won't get any error as the declaration loads before code execution.",
                "They are pretty similar with some small differences, first one is a variable which assigned to an anonymous function (Function Declaration) and second one is the normal way to create a function in JavaScript(Anonymous function Declaration), both has usage, cons and pros:1. Function ExpressionA Function Expression defines a function as a part of a larger\n  expression syntax (typically a variable assignment ). Functions\n  defined via Functions Expressions can be named or anonymous. Function\n  Expressions must not start with \u201cfunction\u201d (hence the parentheses\n  around the self invoking example below).Assign a variable to a function, means no Hoisting, as we know functions in JavaScript can Hoist, means they can be called before they get declared, while variables need to be declared before getting access to them, so means in this case we can not access the function before where it's declared, also it could be a way that you write your functions, for the functions which return another function, this kind of declaration could make sense, also in ECMA6 & above you can assign this to an arrow function which can be used to call anonymous functions, also this way of declaring is a better way to create Constructor functions in JavaScript.2. Function DeclarationA Function Declaration defines a named function variable without\n  requiring variable assignment. Function Declarations occur as\n  standalone constructs and cannot be nested within non-function blocks.\n  It\u2019s helpful to think of them as siblings of Variable Declarations.\n  Just as Variable Declarations must start with \u201cvar\u201d, Function\n  Declarations must begin with \u201cfunction\u201d.This is the normal way of calling a function in JavaScript, this function can be called before you even declare it as in JavaScript all functions get Hoisted, but if you have 'use strict' this won't Hoist as expected, it's a good way to call all normal functions which are not big in lines and neither are a  constructor function.Also, if you need more info about how hoisting works in JavaScript, visit the link below:https://developer.mozilla.org/en-US/docs/Glossary/Hoisting",
                "This is just two possible ways of declaring functions, and in the second way, you can use the function before declaration."
            ]
        },
        {
            "tag": "",
            "question": [
                "Why is subtracting these two times (in 1927) giving a strange result?",
                "If I run the following program, which parses two date strings referencing times 1 second apart and compares them:\npublic static void main(String[] args) throws ParseException {\n    SimpleDateFormat sf ..."
            ],
            "url": "https://stackoverflow.com/questions/6841333",
            "answer": [
                "It's a time zone change on December 31st in Shanghai.See this page for details of 1927 in Shanghai. Basically at midnight at the end of 1927, the clocks went back 5 minutes and 52 seconds. So \"1927-12-31 23:54:08\" actually happened twice, and it looks like Java is parsing it as the later possible instant for that local date/time - hence the difference.Just another episode in the often weird and wonderful world of time zones.EDIT: Stop press! History changes...The original question would no longer demonstrate quite the same behaviour, if rebuilt with version 2013a of TZDB. In 2013a, the result would be 358 seconds, with a transition time of 23:54:03 instead of 23:54:08.I only noticed this because I'm collecting questions like this in Noda Time, in the form of unit tests... The test has now been changed, but it just goes to show - not even historical data is safe.EDIT: History has changed again...In TZDB 2014f, the time of the change has moved to 1900-12-31, and it's now a mere 343 second change (so the time between t and t+1 is 344 seconds, if you see what I mean).EDIT: To answer a question around a transition at 1900... it looks like the Java timezone implementation treats all time zones as simply being in their standard time for any instant before the start of 1900 UTC:The code above produces no output on my Windows machine. So any time zone which has any offset other than its standard one at the start of 1900 will count that as a transition. TZDB itself has some data going back earlier than that, and doesn't rely on any idea of a \"fixed\" standard time (which is what getRawOffset assumes to be a valid concept) so other libraries needn't introduce this artificial transition.",
                "You've encountered a local time discontinuity:When local standard time was about to reach Sunday, 1. January 1928,\n  00:00:00 clocks were turned backward 0:05:52 hours to Saturday, 31.\n  December 1927, 23:54:08 local standard time insteadThis is not particularly strange and has happened pretty much everywhere at one time or another as timezones were switched or changed due to political or administrative actions.",
                "The moral of this strangeness is:",
                "When incrementing time you should convert back to UTC and then add or subtract. Use the local time only for display.This way you will be able to walk through any periods where hours or minutes happen twice.If you converted to UTC, add each second, and convert to local time for display. You would go through 11:54:08 p.m. LMT - 11:59:59 p.m. LMT and then 11:54:08 p.m. CST - 11:59:59 p.m. CST.",
                "Instead of converting each date, you can use the following code:And then see that the result is:",
                "I'm sorry to say, but the time discontinuity has moved a bit inJDK 6 two years ago, and in JDK 7 just recently in update 25.Lesson to learn: avoid non-UTC times at all costs, except maybe for display.",
                "As explained by others, there's a time discontinuity there. There are two possible timezone offsets for 1927-12-31 23:54:08 at Asia/Shanghai, but only one offset for 1927-12-31 23:54:07. So, depending on which offset is used, there's either a one second difference or a 5 minutes and 53 seconds difference.This slight shift of offsets, instead of the usual one-hour daylight savings (summer time) we are used to, obscures the problem a bit.Note that the 2013a update of the timezone database moved this discontinuity a few seconds earlier, but the effect would still be observable.The new java.time package on Java 8 let use see this more clearly, and provide tools to handle it. Given:Then durationAtEarlierOffset will be one second, while durationAtLaterOffset will be five minutes and 53 seconds.Also, these two offsets are the same:But these two are different:You can see the same problem comparing 1927-12-31 23:59:59 with 1928-01-01 00:00:00, though, in this case, it is the earlier offset that produces the longer divergence, and it is the earlier date that has two possible offsets.Another way to approach this is to check whether there's a transition going on. We can do this like this:You can check whether the transition is an overlap where there's more than one valid offset for that date/time or a gap where that date/time is not valid for that zone id - by using the isOverlap() and isGap() methods on zot4.I hope this helps people handle this sort of issue once Java 8 becomes widely available, or to those using Java 7 who adopt the JSR 310 backport.",
                "IMHO the pervasive, implicit localization in Java is its single largest design flaw. It may be intended for user interfaces, but frankly, who really uses Java for user interfaces today except for some IDEs where you can basically ignore localization because programmers aren't exactly the target audience for it. You can fix it (especially on Linux servers) by:To the Java Community Process members I recommend:I mean, come on, aren't global static variables an anti-OO pattern? Nothing else is those pervasive defaults given by some rudimentary environment variables.......",
                "As others said, it's a time change in 1927 in Shanghai.It was 23:54:07 in Shanghai, in the local standard time, but then after 5 minutes and 52 seconds, it turned to the next day at 00:00:00, and then local standard time changed back to 23:54:08. So, that's why the difference between the two times is 343 seconds, not 1 second, as you would have expected.The time can also mess up in other places like the US. The US has Daylight Saving Time. When the Daylight Saving Time starts the time goes forward 1 hour. But after a while, the Daylight Saving Time ends, and it goes backward 1 hour back to the standard time zone. So sometimes when comparing times in the US the difference is about 3600 seconds not 1 second.But there is something different about these two-time changes. The latter changes continuously and the former was just a change. It didn't change back or change again by the same amount.It's better to use UTC unless if needed to use non-UTC time like in display.",
                "It cannot ever be \"1\" as the result because getTime() returns long milliseconds not seconds (of which 353 milliseconds is a fair point but the epoch for Date is started at 1970 not the 1920's).\ncmmnt: The API section you are using is largely considered deprecated.\nhttp://windsolarhybridaustralia.x10.mx/httpoutputtools-tomcat-java.html"
            ]
        },
        {
            "tag": "",
            "question": [
                "How to check whether a string contains a substring in JavaScript?",
                "Usually I would expect a String.contains() method, but there doesn't seem to be one. \n\nWhat is a reasonable way to check for this?"
            ],
            "url": "https://stackoverflow.com/questions/1789945",
            "answer": [
                "ECMAScript\u00a06  introduced String.prototype.includes:const string = \"foo\";\nconst substring = \"oo\";\n\nconsole.log(string.includes(substring)); // trueString.prototype.includes is case-sensitive and is not supported by Internet\u00a0Explorer without a polyfill.In ECMAScript\u00a05 or older environments, use String.prototype.indexOf, which returns -1 when a substring cannot be found:var string = \"foo\";\nvar substring = \"oo\";\n\nconsole.log(string.indexOf(substring) !== -1); // true",
                "There is a String.prototype.includes in ES6:Note that this does not work in Internet Explorer or some other old browsers with no or incomplete ES6 support. To make it work in old browsers, you may wish to use a transpiler like Babel, a shim library like es6-shim, or this polyfill from MDN:",
                "Another alternative is KMP (Knuth\u2013Morris\u2013Pratt).The KMP algorithm searches for a length-m substring in a length-n string in worst-case O(n+m) time, compared to a worst-case of O(n\u22c5m) for the naive algorithm, so using KMP may be reasonable if you care about worst-case time complexity.Here's a JavaScript implementation by Project Nayuki, taken from https://www.nayuki.io/res/knuth-morris-pratt-string-matching/kmp-string-matcher.js:function kmpSearch(pattern, text) {\n  if (pattern.length == 0)\n    return 0; // Immediate match\n\n  // Compute longest suffix-prefix table\n  var lsp = [0]; // Base case\n  for (var i = 1; i < pattern.length; i++) {\n    var j = lsp[i - 1]; // Start by assuming we're extending the previous LSP\n    while (j > 0 && pattern[i] !== pattern[j])\n      j = lsp[j - 1];\n    if (pattern[i] === pattern[j])\n      j++;\n    lsp.push(j);\n  }\n\n  // Walk through text string\n  var j = 0; // Number of chars matched in pattern\n  for (var i = 0; i < text.length; i++) {\n    while (j > 0 && text[i] != pattern[j])\n      j = lsp[j - 1]; // Fall back in the pattern\n    if (text[i]  == pattern[j]) {\n      j++; // Next char matched, increment position\n      if (j == pattern.length)\n        return i - (j - 1);\n    }\n  }\n  return -1; // Not found\n}\n\nconsole.log(kmpSearch('ays', 'haystack') != -1) // true\nconsole.log(kmpSearch('asdf', 'haystack') != -1) // false"
            ]
        },
        {
            "tag": "",
            "question": [
                "What is the difference between String and string in C#?",
                "What are the differences between these two and which one should I use?\nstring s = \"Hello world!\";\nString s = \"Hello world!\";"
            ],
            "url": "https://stackoverflow.com/questions/7074",
            "answer": [
                "string is an alias in C# for System.String.\nSo technically, there is no difference.  It's like int vs. System.Int32.As far as guidelines, it's generally recommended to use string any time you're referring to an object.e.g.Likewise, I think it's generally recommended to use String if you need to refer specifically to the class.e.g.It appears that the guidance in this area may have changed, as StyleCop now enforces the use of the C# specific aliases.",
                "Just for the sake of completeness, here's a brain dump of related information...As others have noted, string is an alias for System.String. Assuming your code using String compiles to System.String (i.e. you haven't got a using directive for some other namespace with a different String type), they compile to the same code, so at execution time there is no difference whatsoever. This is just one of the aliases in C#. The complete list is:Apart from string and object, the aliases are all to value types. decimal is a value type, but not a primitive type in the CLR. The only primitive type which doesn't have an alias is System.IntPtr.In the spec, the value type aliases are known as \"simple types\". Literals can be used for constant values of every simple type; no other value types have literal forms available. (Compare this with VB, which allows DateTime literals, and has an alias for it too.)There is one circumstance in which you have to use the aliases: when explicitly specifying an enum's underlying type. For instance:That's just a matter of the way the spec defines enum declarations - the part after the colon has to be the integral-type production, which is one token of sbyte, byte, short, ushort, int, uint, long, ulong, char... as opposed to a type production as used by variable declarations for example. It doesn't indicate any other difference.Finally, when it comes to which to use: personally I use the aliases everywhere for the implementation, but the CLR type for any APIs. It really doesn't matter too much which you use in terms of implementation - consistency among your team is nice, but no-one else is going to care. On the other hand, it's genuinely important that if you refer to a type in an API, you do so in a language-neutral way. A method called ReadInt32 is unambiguous, whereas a method called ReadInt requires interpretation. The caller could be using a language that defines an int alias for Int16, for example. The .NET framework designers have followed this pattern, good examples being in the BitConverter, BinaryReader and Convert classes.",
                "String stands for System.String and it is a .NET Framework type. string is an alias in the C# language for  System.String. Both of them are compiled to System.String in IL (Intermediate Language), so there is no difference. Choose what you like and use that. If you code in C#, I'd prefer string as it's a C# type alias and well-known by C# programmers.I can say the same about (int, System.Int32) etc..",
                "The best answer I have ever heard about using the provided type aliases in C# comes from Jeffrey Richter in his book CLR Via C#. Here are his 3 reasons:So there you have it. I think these are all really good points. I however, don't find myself using Jeffrey's advice in my own code. Maybe I am too stuck in my C# world but I end up trying to make my code look like the framework code.",
                "string is a reserved word, but String is just a class name. \nThis means that string cannot be used as a variable name by itself.If for some reason you wanted a variable called string, you'd see only the first of these compiles:If you really want a variable name called string you can use @ as a prefix:Another critical difference: Stack Overflow highlights them differently.",
                "There is one difference - you can't use String without using System; beforehand.",
                "It's been covered above; however, you can't use string in reflection; you must use String.",
                "System.String is the .NET string class - in C# string is an alias for System.String - so in use they are the same.As for guidelines I wouldn't get too bogged down and just use whichever you feel like - there are more important things in life and the code is going to be the same anyway.If you find yourselves building systems where it is necessary to specify the size of the integers you are using and so tend to use Int16, Int32, UInt16, UInt32 etc. then it might look more natural to use String - and when moving around between different .net languages it might make things more understandable - otherwise I would use string and int.",
                "I prefer the capitalized .NET types (rather than the aliases) for formatting reasons. The .NET types are colored the same as other object types (the value types are proper objects, after all).Conditional and control keywords (like if, switch, and return) are lowercase and colored dark blue (by default). And I would rather not have the disagreement in use and format.Consider:",
                "This YouTube video demonstrates practically how they differ.But now for a long textual answer.When we talk about .NET there are two different things one there is .NET framework and the other there are languages (C#, VB.NET etc) which use that framework.\"System.String\" a.k.a \"String\" (capital \"S\") is a .NET framework data type while \"string\" is a C# data type.In short \"String\" is an alias (the same thing called with different names) of \"string\". So technically both the below code statements will give the same output.orIn the same way, there are aliases for other C# data types as shown below:object: System.Object, string: System.String, bool: System.Boolean, byte: System.Byte, sbyte: System.SByte, short: System.Int16 and so on.Now the million-dollar question from programmer's point of view: So when to use \"String\" and \"string\"?The first thing to avoid confusion use one of them consistently. But from best practices perspective when you do variable declaration it's good to use \"string\" (small \"s\") and when you are using it as a class name then \"String\" (capital \"S\") is preferred.In the below code the left-hand side is a variable declaration and it is declared using \"string\". On the right-hand side, we are calling a method so \"String\" is more sensible.",
                "string and String are identical in all ways (except the uppercase \"S\").  There are no performance implications either way.Lowercase string is preferred in most projects due to the syntax highlighting",
                "C# is a language which is used together with the CLR.string is a type in C#.System.String is a type in the CLR.When you use C# together with the CLR string will be mapped to System.String.Theoretically, you could implement a C#-compiler that generated Java bytecode. A sensible implementation of this compiler would probably map string to java.lang.String in order to interoperate with the Java runtime library.",
                "Lower case string is an alias for System.String.\nThey are the same in C#.There's a debate over whether you should use the System types (System.Int32, System.String, etc.) types or the C# aliases (int, string, etc). I personally believe you should use the C# aliases, but that's just my personal preference.",
                "string is just an alias for System.String. The compiler will treat them identically.The only practical difference is the syntax highlighting as you mention, and that you have to write using System if you use String.",
                "Both are same. But from coding guidelines perspective it's better to use string instead of String. This is what generally developers use. e.g. instead of using Int32 we use int as int is alias to Int32FYI\n\u201cThe keyword string is simply an alias for the predefined class System.String.\u201d - C# Language Specification 4.2.3\nhttp://msdn2.microsoft.com/En-US/library/aa691153.aspx",
                "As the others are saying, they're the same.  StyleCop rules, by default, will enforce you to use string as a C# code style best practice, except when referencing System.String static functions, such as String.Format, String.Join, String.Concat, etc...",
                "New answer after 6 years and 5 months (procrastination).While string is a reserved C# keyword that always has a fixed meaning, String is just an ordinary identifier which could refer to anything. Depending on members of the current type, the current namespace and the applied using directives and their placement, String could be a value or a type distinct from global::System.String.I shall provide two examples where using directives will not help.First, when String is a value of the current type (or a local variable):The above will not compile because IEnumerable<> does not have a non-static member called Format, and no extension methods apply. In the above case, it may still be possible to use String in other contexts where a type is the only possibility syntactically. For example String local = \"Hi mum!\"; could be OK (depending on namespace and using directives).Worse: Saying String.Concat(someSequence) will likely (depending on usings) go to the Linq extension method Enumerable.Concat. It will not go to the static method string.Concat.Secondly, when String is another type, nested inside the current type:Neither statement in the Example method compiles. Here String is always a piano string, MyPiano.String. No member (static or not) Format exists on it (or is inherited from its base class). And the value \"Goodbye\" cannot be converted into it.",
                "Using System types makes it easier to port between C# and VB.Net, if you are into that sort of thing.",
                "Against what seems to be common practice among other programmers, I prefer String over string, just to highlight the fact that String is a reference type, as Jon Skeet mentioned.",
                "string is an alias (or shorthand) of System.String. That means, by typing string we meant System.String. You can read more in think link: 'string' is an alias/shorthand of System.String.",
                "I'd just like to add this to lfousts answer, from Ritchers book:The C# language specification states, \u201cAs a matter of style, use of the keyword is favored over\n  use of the complete system type name.\u201d I disagree with the language specification; I prefer\n  to use the FCL type names and completely avoid the primitive type names. In fact, I wish that\n  compilers didn\u2019t even offer the primitive type names and forced developers to use the FCL\n  type names instead. Here are my reasons:I\u2019ve seen a number of developers confused, not knowing whether to use string\n  or String in their code. Because in C# string (a keyword) maps exactly to\n  System.String (an FCL type), there is no difference and either can be used. Similarly,\n  I\u2019ve heard some developers say that int represents a 32-bit integer when the application\n  is running on a 32-bit OS and that it represents a 64-bit integer when the application\n  is running on a 64-bit OS. This statement is absolutely false: in C#, an int always maps\n  to System.Int32, and therefore it represents a 32-bit integer regardless of the OS the\n  code is running on. If programmers would use Int32 in their code, then this potential\n  confusion is also eliminated.In C#, long maps to System.Int64, but in a different programming language, long\n  could map to an Int16 or Int32. In fact, C++/CLI does treat long as an Int32.\n  Someone reading source code in one language could easily misinterpret the code\u2019s\n  intention if he or she were used to programming in a different programming language.\n  In fact, most languages won\u2019t even treat long as a keyword and won\u2019t compile code\n  that uses it.The FCL has many methods that have type names as part of their method names. For\n  example, the BinaryReader type offers methods such as ReadBoolean, ReadInt32,\n  ReadSingle, and so on, and the System.Convert type offers methods such as\n  ToBoolean, ToInt32, ToSingle, and so on. Although it\u2019s legal to write the following\n  code, the line with float feels very unnatural to me, and it\u2019s not obvious that the line is\n  correct:Many programmers that use C# exclusively tend to forget that other programming\n  languages can be used against the CLR, and because of this, C#-isms creep into the\n  class library code. For example, Microsoft\u2019s FCL is almost exclusively written in C# and\n  developers on the FCL team have now introduced methods into the library such as\n  Array\u2019s GetLongLength, which returns an Int64 value that is a long in C# but not\n  in other languages (like C++/CLI). Another example is System.Linq.Enumerable\u2019s\n  LongCount method.I didn't get his opinion before I read the complete paragraph.",
                "String (System.String) is a class in the base class library. string (lower case) is a reserved work in C# that is an alias for System.String. Int32 vs int is a similar situation as is Boolean vs. bool. These C# language specific keywords enable you to declare primitives in a style similar to C.",
                "It's a matter of convention, really.  string just looks more like C/C++ style.  The general convention is to use whatever shortcuts your chosen language has provided (int/Int for Int32).  This goes for \"object\" and decimal as well.Theoretically this could help to port code into some future 64-bit standard in which \"int\" might mean Int64, but that's not the point, and I would expect any upgrade wizard to change any int references to Int32 anyway just to be safe.",
                "@JaredPar (a developer on the C# compiler and prolific SO user!) wrote a great blog post on this issue. I think it is worth sharing here. It is a nice perspective on our subject.[...]The keyword string has concrete meaning in C#. It is the type System.String which exists in the core runtime assembly. The runtime intrinsically understands this type and provides the capabilities developers expect for strings in .NET. Its presence is so critical to C# that if that type doesn\u2019t exist the compiler will exit before attempting to even parse a line of code. Hence string has a precise, unambiguous meaning in C# code.The identifier String though has no concrete meaning in C#. It is an identifier that goes through all the name lookup rules as Widget, Student, etc \u2026 It could bind to string or it could bind to a type in another assembly entirely whose purposes may be entirely different than string. Worse it could be defined in a way such that code like String s = \"hello\"; continued to compile.The actual meaning of String will always depend on name resolution.\nThat means it depends on all the source files in the project and all\nthe types defined in all the referenced assemblies. In short it\nrequires quite a bit of context to know what it means.True that in the vast majority of cases String and string will bind to\nthe same type. But using String still means developers are leaving\ntheir program up to interpretation in places where there is only one\ncorrect answer. When String does bind to the wrong type it can leave\ndevelopers debugging for hours, filing bugs on the compiler team, and\ngenerally wasting time that could\u2019ve been saved by using string.Another way to visualize the difference is with this sample:Many will argue that while this is information technically accurate using String is still fine because it\u2019s exceedingly rare that a codebase would define a type of this name. Or that when String is defined it\u2019s a sign of a bad codebase.[...]You\u2019ll see that String is defined for a number of completely valid purposes: reflection helpers, serialization libraries, lexers, protocols, etc \u2026 For any of these libraries String vs. string has real consequences depending on where the code is used.So remember when you see the String vs. string debate this is about semantics, not style. Choosing string gives crisp meaning to your codebase. Choosing String isn\u2019t wrong but it\u2019s leaving the door open for surprises in the future.Note: I copy/pasted most of the blog posts for archive reasons. I ignore some parts, so I recommend skipping and reading the blog post if you can.",
                "String is not a keyword and it can be used as Identifier whereas string is a keyword and cannot be used as Identifier. And in function point of view both are same.",
                "Coming late to the party: I use the CLR types 100% of the time (well, except if forced to use the C# type, but I don't remember when the last time that was).I originally started doing this years ago, as per the CLR books by Ritchie. It made sense to me that all CLR languages ultimately have to be able to support the set of CLR types, so using the CLR types yourself provided clearer, and possibly more \"reusable\" code.Now that I've been doing it for years, it's a habit and I like the coloration that VS shows for the CLR types.The only real downer is that auto-complete uses the C# type, so I end up re-typing automatically generated types to specify the CLR type instead.Also, now, when I see \"int\" or \"string\", it just looks really wrong to me, like I'm looking at 1970's C code.",
                "There is no difference.The C# keyword string maps to the .NET type System.String - it is an alias that keeps to the naming conventions of the language.Similarly, int maps to System.Int32.",
                "There's a quote on this issue from Daniel Solis' book.All the predefined types  are mapped directly to\n  underlying .NET types. The C# type names (string) are simply aliases for the\n  .NET types (String or System.String), so using the .NET names works fine syntactically, although\n  this is discouraged. Within a C# program, you should use the C# names\n  rather than the .NET names.",
                "Yes, that's no difference between them, just like the bool and Boolean.",
                "string is a keyword, and you can't use string as an identifier.String is not a keyword, and you can use it as an identifier:ExampleThe keyword string  is an alias for\n System.String aside from the keyword issue, the two are exactly\n equivalent."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I remove a property from a JavaScript object?",
                "Given an object:\nlet myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\nHow do I remove the property ..."
            ],
            "url": "https://stackoverflow.com/questions/208105",
            "answer": [
                "To remove a property from an object (mutating the object), you can do it like this:Demo\n\n\nvar myObject = {\n    \"ircEvent\": \"PRIVMSG\",\n    \"method\": \"newURI\",\n    \"regex\": \"^http://.*\"\n};\ndelete myObject.regex;\n\nconsole.log(myObject);For anyone interested in reading more about it, Stack Overflow user kangax has written an incredibly in-depth blog post about the delete statement on their blog, Understanding delete. It is highly recommended.If you'd like a new object with all the keys of the original except some, you could use destructuring.Demo\n\n\nlet myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\n// assign the key regex to the variable _ indicating it will be unused\nconst {regex: _, ...newObj} = myObject;\n\nconsole.log(newObj);   // has no 'regex' key\nconsole.log(myObject); // remains unchanged",
                "Objects in JavaScript can be thought of as maps between keys and values. The delete operator is used to remove these keys, more commonly known as object properties, one at a time.var obj = {\r\n  myProperty: 1    \r\n}\r\nconsole.log(obj.hasOwnProperty('myProperty')) // true\r\ndelete obj.myProperty\r\nconsole.log(obj.hasOwnProperty('myProperty')) // falseThe delete operator does not directly free memory, and it differs from simply assigning the value of null or undefined to a property, in that the property itself is removed from the object. Note that if the value of a deleted property was a reference type (an object), and another part of your program still holds a reference to that object, then that object will, of course, not be garbage collected until all references to it have disappeared.delete will only work on properties whose descriptor marks them as configurable.",
                "Old question, modern answer. Using object destructuring, an ECMAScript\u00a06 feature, it's as simple as:Or with the questions sample:You can see it in action in the Babel try-out editor.Edit:To reassign to the same variable, use a let:",
                "var myObject = {\"ircEvent\": \"PRIVMSG\", \"method\": \"newURI\", \"regex\": \"^http://.*\"};\r\n    \r\ndelete myObject.regex;\r\n\r\nconsole.log ( myObject.regex); // logs: undefinedThis works in Firefox and Internet\u00a0Explorer, and I think it works in all others.",
                "The delete operator is used to remove properties from objects.Note that, for arrays, this is not the same as removing an element. To remove an element from an array, use Array#splice or Array#pop. For example:Strictly speaking, it's impossible to truly delete anything in JavaScript. The delete operator neither deletes objects nor frees memory. Rather, it sets its operand to undefined and manipulates the parent object so that the member is gone.The object is not deleted. Only the reference is. Memory is only freed\nby the garbage collector when all references to an object are removed.Another important caveat is that the delete operator will not reorganize structures for you, which has results that can seem counterintuitive. Deleting an array index, for example, will leave a \"hole\" in it.This is because arrays are objects. So indices are the same as keys.Different built-in functions in JavaScript handle arrays with holes in them differently.for..in statements will skip the empty index completely.A naive for loop will yield undefined for the value at the index.Any method using Symbol.iterator will return undefined for the value at the index.forEach, map and reduce will simply skip the missing index, but will not remove itExample:So, the delete operator should not be used for the common use-case of removing elements from an array. Arrays have a dedicated methods for removing elements and reallocating memory: Array#splice() and Array#pop.Array#splice mutates the array, and returns any removed indices. deleteCount elements are removed from index start, and item1, item2... itemN are inserted into the array from index start. If deleteCount is omitted then elements from startIndex are removed to the end of the array.There is also a similarly named, but different, function on Array.prototype: Array#slice.Array#slice is non-destructive, and returns a new array containing the indicated indices from start to end. If end is left unspecified, it defaults to the end of the array. If end is positive, it specifies the zero-based non-inclusive index to stop at. If end is negative it, it specifies the index to stop at by counting back from the end of the array (eg. -1 will omit the final index). If end <= start, the result is an empty array.Array#pop removes the last element from an array, and returns that element. This operation changes the length of the array. The opposite operation is pushArray#shift is similar to pop, except it removes the first element. The opposite operation is unshift.",
                "To complete Koen's answer, in case you want to remove a dynamic variable using the spread syntax, you can do it like so:const key = 'a';\n\nconst { [key]: foo, ...rest } = { a: 1, b: 2, c: 3 };\n\nconsole.log(foo);  // 1\nconsole.log(rest); // { b: 2, c: 3 }* foo will be a new variable with the value of a (which is 1).There are a few common ways to remove a property from an object. Each one has its own pros and cons (check this performance comparison):Delete OperatorIt is readable and short, however, it might not be the best choice if you are operating on a large number of objects as its performance is not optimized.ReassignmentIt is more than two times faster than delete, however the property is not deleted and can be iterated.Spread OperatorThis ES6 operator allows us to return a brand new object, excluding any properties, without mutating the existing object. The downside is that it has the worse performance out of the above and is not suggested to be used when you need to remove many properties at a time.",
                "Another alternative is to use the Underscore.js library.Note that _.pick() and _.omit() both return a copy of the object and don't directly modify the original object. Assigning the result to the original object should do the trick (not shown).Reference: link _.pick(object, *keys)Return a copy of the object, filtered to only have values for the \nwhitelisted keys (or array of valid keys).Reference: link _.omit(object, *keys)Return a copy of the object, filtered to omit the \nblacklisted keys (or array of keys).For arrays, _.filter() and _.reject() can be used in a similar manner.",
                "To clone an object without a property:For example:And we need to delete a.With an explicit prop key:With a variable prop key:A cool arrow function \ud83d\ude0e:For multiple propertiesUsageOr",
                "The term you have used in your question title, Remove a property from a JavaScript object, can be interpreted in some different ways. The one is to remove it for whole the memory and the list of object keys or the other is just to remove it from your object. As it has been mentioned in some other answers, the delete keyword is the main part. Let's say you have your object like:If you do:the result would be:You can delete that specific key from your object keys like:Then your objects key using Object.keys(myJSONObject) would be:But the point is if you care about memory and you want to whole the object gets removed from the memory, it is recommended to set it to null before you delete the key:The other important point here is to be careful about your other references to the same object. For instance, if you create a variable like:Or add it as a new pointer to another object like:Then even if you remove it from your object myJSONObject, that specific object won't get deleted from the memory, since the regex variable and myOtherObject[\"regex\"] still have their values. Then how could we remove the object from the memory for sure?The answer would be to delete all the references you have in your code, pointed to that very object and also not use var statements to create new references to that object. This last point regarding var statements, is one of the most crucial issues that we are usually faced with, because using var statements would prevent the created object from getting removed.Which means in this case you won't be able to remove that object because you have created the regex variable via a var statement, and if you do:The result would be false, which means that your delete statement haven't been executed as you expected. But if you had not created that variable before, and you only had myOtherObject[\"regex\"] as your last existing reference, you could have done this just by removing it like:In other words, a JavaScript object is eligible to be killed as soon as there is no reference left in your code pointed to that object.Update:Thanks to @AgentME:Setting a property to null before deleting it doesn't accomplish\nanything (unless the object has been sealed by Object.seal and the\ndelete fails. That's not usually the case unless you specifically\ntry).To get more information on Object.seal: Object.seal()",
                "ECMAScript 2015 (or ES6) came with built-in Reflect object. It is possible to delete object property by calling Reflect.deleteProperty() function with target object and property key as parameters:which is equivalent to:But if the property of the object is not configurable it cannot be deleted neither with deleteProperty function nor delete operator:Object.freeze() makes all properties of object not configurable (besides other things). deleteProperty function (as well as delete operator) returns false when tries to delete any of it's properties. If property is configurable it returns true, even if property does not exist.The difference between delete and deleteProperty is when using strict mode:",
                "Suppose you have an object that looks like this:If you want to use the entire staff array, the proper way to do this, would be to do this:Alternatively, you could also do this:Similarly, removing the entire students array would be done by calling delete Hogwarts.students; or delete Hogwarts['students'];.Now, if you want to remove a single staff member or student, the procedure is a bit different, because both properties are arrays themselves.If you know the index of your staff member, you could simply do this:If you do not know the index, you'll also have to do an index search:While you technically can use delete for an array, using it would result in getting incorrect results when calling for example Hogwarts.staff.length later on. In other words, delete would remove the element, but it wouldn't update the value of length property. Using delete would also mess up your indexing.So, when deleting values from an object, always first consider whether you're dealing with object properties or whether you're dealing with array values, and choose the appropriate strategy based on that.If you want to experiment with this, you can use this Fiddle as a starting point.",
                "I personally use Underscore.js or Lodash for object and array manipulation:",
                "Using delete method is the best way to do that, as per MDN description, the delete operator removes a property from an object. So you can simply write:The delete operator removes a given property from an object. On\nsuccessful deletion, it will return true, else false will be returned.\nHowever, it is important to consider the following scenarios:The following snippet gives another simple example:var Employee = {\n  age: 28,\n  name: 'Alireza',\n  designation: 'developer'\n}\n\nconsole.log(delete Employee.name);   // returns true\nconsole.log(delete Employee.age);    // returns true\n\n// When trying to delete a property that does \n// not exist, true is returned \nconsole.log(delete Employee.salary); // returns trueFor more info about and seeing more examples visit the link below:https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/delete",
                "Another solution, using Array#reduce.var myObject = {\r\n  \"ircEvent\": \"PRIVMSG\",\r\n  \"method\": \"newURI\",\r\n  \"regex\": \"^http://.*\"\r\n};\r\n\r\nmyObject = Object.keys(myObject).reduce(function(obj, key) {\r\n  if (key != \"regex\") {           //key you want to remove\r\n    obj[key] = myObject[key];\r\n  }\r\n  return obj;\r\n}, {});\r\n\r\nconsole.log(myObject);However, it will mutate the original object. If you want to create a new object without the specified key, just assign the reduce function to a new variable, e.g.:(ES6)const myObject = {\r\n  ircEvent: 'PRIVMSG',\r\n  method: 'newURI',\r\n  regex: '^http://.*',\r\n};\r\n\r\nconst myNewObject = Object.keys(myObject).reduce((obj, key) => {\r\n  key !== 'regex' ? obj[key] = myObject[key] : null;\r\n  return obj;\r\n}, {});\r\n\r\nconsole.log(myNewObject);",
                "There are a lot of good answers here but I just want to chime in that when using delete to remove a property in JavaScript, it is often wise to first check if that property exists to prevent errors.E.gDue to the dynamic nature of JavaScript there are often cases where you simply don't know if the property exists or not. Checking if obj exists before the && also makes sure you don't throw an error due to calling the hasOwnProperty() function on an undefined object.Sorry if this didn't add to your specific use case but I believe this to be a good design to adapt when managing objects and their properties.",
                "This post is very old and I find it very helpful so I decided to share the unset function I wrote in case someone else see this post and think why it's not so simple as it in PHP unset function.The reason for writing this new unset function, is to keep the index of all other variables in this hash_map. Look at the following example, and see how the index of \"test2\" did not change after removing a value from the hash_map.function unset(unsetKey, unsetArr, resort) {\n  var tempArr = unsetArr;\n  var unsetArr = {};\n  delete tempArr[unsetKey];\n  if (resort) {\n    j = -1;\n  }\n  for (i in tempArr) {\n    if (typeof(tempArr[i]) !== 'undefined') {\n      if (resort) {\n        j++;\n      } else {\n        j = i;\n      }\n      unsetArr[j] = tempArr[i];\n    }\n  }\n  return unsetArr;\n}\n\nvar unsetArr = ['test', 'deletedString', 'test2'];\n\nconsole.log(unset('1', unsetArr, true)); // output Object {0: \"test\", 1: \"test2\"}\nconsole.log(unset('1', unsetArr, false)); // output Object {0: \"test\", 2: \"test2\"}",
                "Try the following method. Assign the Object property value to undefined. Then stringify the object and parse.var myObject = {\"ircEvent\": \"PRIVMSG\", \"method\": \"newURI\", \"regex\": \"^http://.*\"};\r\n\r\nmyObject.regex = undefined;\r\nmyObject = JSON.parse(JSON.stringify(myObject));\r\n\r\nconsole.log(myObject);",
                "Using ramda#dissoc you will get a new object without the attribute regex:You can also use other functions to achieve the same effect - omit, pick, ...",
                "There are a couple of ways to remove properties from an object:const myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\",\n};\n\ndelete myObject.regex;\nconsole.log(myObject);const myObject = {\n      \"ircEvent\": \"PRIVMSG\",\n      \"method\": \"newURI\",\n      \"regex\": \"^http://.*\",\n    };\n\ndelete myObject['regex'];\nconsole.log(myObject);\n// or\nconst name = 'ircEvent';\ndelete myObject[name];\nconsole.log(myObject);const myObject = {\n      \"ircEvent\": \"PRIVMSG\",\n      \"method\": \"newURI\",\n      \"regex\": \"^http://.*\",\n    };\n\nconst { regex, ...myObjectRest} = myObject;\nconsole.log(myObjectRest);",
                "If you want to delete a property deeply nested in the object then you can use the following recursive function with path to the property as the second argument:Example:",
                "const obj = {\r\n    \"Filters\":[\r\n        {\r\n            \"FilterType\":\"between\",\r\n            \"Field\":\"BasicInformationRow.A0\",\r\n            \"MaxValue\":\"2017-10-01\",\r\n            \"MinValue\":\"2017-09-01\",\r\n            \"Value\":\"Filters value\"\r\n        }\r\n    ]\r\n};\r\n\r\nlet new_obj1 = Object.assign({}, obj.Filters[0]);\r\nlet new_obj2 = Object.assign({}, obj.Filters[0]);\r\n\r\n/*\r\n\r\n// old version\r\n\r\nlet shaped_obj1 = Object.keys(new_obj1).map(\r\n    (key, index) => {\r\n        switch (key) {\r\n            case \"MaxValue\":\r\n                delete new_obj1[\"MaxValue\"];\r\n                break;\r\n            case \"MinValue\":\r\n                delete new_obj1[\"MinValue\"];\r\n                break;\r\n        }\r\n        return new_obj1;\r\n    }\r\n)[0];\r\n\r\n\r\nlet shaped_obj2 = Object.keys(new_obj2).map(\r\n    (key, index) => {\r\n        if(key === \"Value\"){\r\n            delete new_obj2[\"Value\"];\r\n        }\r\n        return new_obj2;\r\n    }\r\n)[0];\r\n\r\n\r\n*/\r\n\r\n\r\n// new version!\r\n\r\nlet shaped_obj1 = Object.keys(new_obj1).forEach(\r\n    (key, index) => {\r\n        switch (key) {\r\n            case \"MaxValue\":\r\n                delete new_obj1[\"MaxValue\"];\r\n                break;\r\n            case \"MinValue\":\r\n                delete new_obj1[\"MinValue\"];\r\n                break;\r\n            default:\r\n                break;\r\n        }\r\n    }\r\n);\r\n\r\nlet shaped_obj2 = Object.keys(new_obj2).forEach(\r\n    (key, index) => {\r\n        if(key === \"Value\"){\r\n            delete new_obj2[\"Value\"];\r\n        }\r\n    }\r\n);",
                "Here's an ES6 way to remove the entry easily:let myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\nconst removeItem = 'regex';\n\nconst { [removeItem]: remove, ...rest } = myObject;\n\nconsole.log(remove); // \"^http://.*\"\nconsole.log(rest); // Object { ircEvent: \"PRIVMSG\", method: \"newURI\" }",
                "Dan's assertion that 'delete' is very slow and the benchmark he posted were doubted. So I carried out the test myself in Chrome 59. It does seem that 'delete' is about 30 times slower:Note that I purposely carried out more than one 'delete' operations in one loop cycle to minimize the effect caused by the other operations.",
                "There are many different options presented on this page, not because most of the options are wrong\u2014or because the answers are duplicates\u2014but because the appropriate technique depends on the situation you're in and the goals of the tasks you and/or you team are trying to fulfill. To answer you question unequivocally, one needs to know:Once those four queries have been answered, there are essentially four categories of \"property removal\" in JavaScript to chose from in order to meet your goals. They are:This category is for operating on object literals or object instances when you want to retain/continue to use the original reference and aren't using stateless functional principles in your code. An example piece of syntax in this category:This category is the oldest, most straightforward & most widely supported category of property removal. It supports Symbol & array indexes in addition to strings and works in every version of JavaScript except for the very first release. However, it's mutative which violates some programming principles and has performance implications. It also can result in uncaught exceptions when used on non-configurable properties in strict mode.This category is for operating on plain object or array instances in newer ECMAScript flavors when a non-mutative approach is desired and you don't need to account for Symbol keys:This category is for operating on object literals or object instances when you want to retain/continue to use the original reference while guarding against exceptions being thrown on unconfigurable properties:In addition, while mutating objects in-place isn't stateless, you can use the functional nature of Reflect.deleteProperty to do partial application and other functional techniques that aren't possible with delete statements.This category is for operating on plain object or array instances in newer ECMAScript flavors when a non-mutative approach is desired and you don't need to account for Symbol keys:This category is generally allows for greater functional flexibility, including accounting for Symbols & omitting more than one property in one statement:",
                "You can use a filter like belowvar myObject = {\n    \"ircEvent\": \"PRIVMSG\",\n    \"method\": \"newURI\",\n    \"regex\": \"^http://.*\"\n};\n\n// Way 1\n\nlet filter1 = {}\n  Object.keys({...myObject}).filter(d => {\n  if(d !== 'regex'){\n    filter1[d] = myObject[d];\n  }\n})\n\nconsole.log(filter1)\n\n// Way 2\n\nlet filter2 = Object.fromEntries(Object.entries({...myObject}).filter(d =>\nd[0] !== 'regex'\n))\n\nconsole.log(filter2)",
                "@johnstock, we can also use JavaScript's prototyping concept to add method to objects to delete any passed key available in calling object.Above answers are appreciated.var myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\n// 1st and direct way \ndelete myObject.regex; // delete myObject[\"regex\"]\nconsole.log(myObject); // { ircEvent: 'PRIVMSG', method: 'newURI' }\n\n// 2 way -  by using the concept of JavaScript's prototyping concept\nObject.prototype.removeFromObjectByKey = function(key) {\n  // If key exists, remove it and return true\n  if (this[key] !== undefined) {\n    delete this[key]\n    return true;\n  }\n  // Else return false\n  return false;\n}\n\nvar isRemoved = myObject.removeFromObjectByKey('method')\nconsole.log(myObject) // { ircEvent: 'PRIVMSG' }\n\n// More examples\nvar obj = {\n  a: 45,\n  b: 56,\n  c: 67\n}\nconsole.log(obj) // { a: 45, b: 56, c: 67 }\n\n// Remove key 'a' from obj\nisRemoved = obj.removeFromObjectByKey('a')\nconsole.log(isRemoved); //true\nconsole.log(obj); // { b: 56, c: 67 }\n\n// Remove key 'd' from obj which doesn't exist\nvar isRemoved = obj.removeFromObjectByKey('d')\nconsole.log(isRemoved); // false\nconsole.log(obj); // { b: 56, c: 67 }",
                "I have used Lodash \"unset\" to make it happen for a nested object also... only this needs to write small logic to get the path of the property key which is expected by the omit method.var a = {\"bool\":{\"must\":[{\"range\":{\"price_index.final_price\":{\"gt\":\"450\", \"lt\":\"500\"}}}, {\"bool\":{\"should\":[{\"term\":{\"color_value.keyword\":\"Black\"}}]}}]}};\n\nfunction getPathOfKey(object,key,currentPath, t){\n    var currentPath = currentPath || [];\n\n    for(var i in object){\n        if(i == key){\n            t = currentPath;\n        }\n        else if(typeof object[i] == \"object\"){\n            currentPath.push(i)\n            return getPathOfKey(object[i], key,currentPath)\n        }\n    }\n    t.push(key);\n    return t;\n}\ndocument.getElementById(\"output\").innerHTML =JSON.stringify(getPathOfKey(a,\"price_index.final_price\"))\n<div id=\"output\">\n\n</div>var unset = require('lodash.unset');\nunset(a, getPathOfKey(a, \"price_index.final_price\"));",
                "let myObject = {\n    \"ircEvent\": \"PRIVMSG\",\n    \"method\": \"newURI\",\n    \"regex\": \"^http://.*\"\n};\n\n\nobj = Object.fromEntries(\n    Object.entries(myObject).filter(function (m){\n        return m[0] != \"regex\"/*or whatever key to delete*/\n    }\n))\n\nconsole.log(obj)You can also just treat the object like a2d array using Object.entries, and use splice to remove an element as you would in a normal array, or simply filter through the object, as one would an array, and assign the reconstructed object back to the original variable",
                "If you don't want to modify the original object.Remove a property without mutating the objectIf mutability is a concern, you can create a completely new object by copying all the properties from the old, except the one you want to remove.let myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\nlet prop = 'regex';\nconst updatedObject = Object.keys(myObject).reduce((object, key) => {\n  if (key !== prop) {\n    object[key] = myObject[key]\n  }\n  return object\n}, {})\n\nconsole.log(updatedObject);"
            ]
        },
        {
            "tag": "",
            "question": [
                "What are metaclasses in Python?",
                "What are metaclasses? What are they used for?"
            ],
            "url": "https://stackoverflow.com/questions/100003",
            "answer": [
                "Before understanding metaclasses, you need to master classes in Python. And Python has a very peculiar idea of what classes are, borrowed from the Smalltalk language.In most languages, classes are just pieces of code that describe how to produce an object. That's kinda true in Python too:But classes are more than that in Python. Classes are objects too.Yes, objects.As soon as you use the keyword class, Python executes it and creates\nan object. The instructioncreates in memory an object with the name ObjectCreator.This object (the class) is itself capable of creating objects (the instances),\nand this is why it's a class.But still, it's an object, and therefore:e.g.:Since classes are objects, you can create them on the fly, like any object.First, you can create a class in a function using class:But it's not so dynamic, since you still have to write the whole class yourself.Since classes are objects, they must be generated by something.When you use the class keyword, Python creates this object automatically. But as\nwith most things in Python, it gives you a way to do it manually.Remember the function type? The good old function that lets you know what\ntype an object is:Well, type has also a completely different ability: it can create classes on the fly. type can take the description of a class as parameters,\nand return a class.(I  know, it's silly that the same function can have two completely different uses according to the parameters you pass to it. It's an issue due to backward\ncompatibility in Python)type works this way:Where:e.g.:can be created manually this way:You'll notice that we use MyShinyClass as the name of the class\nand as the variable to hold the class reference. They can be different,\nbut there is no reason to complicate things.type accepts a dictionary to define the attributes of the class. So:Can be translated to:And used as a normal class:And of course, you can inherit from it, so:would be:Eventually, you'll want to add methods to your class. Just define a function\nwith the proper signature and assign it as an attribute.And you can add even more methods after you dynamically create the class, just like adding methods to a normally created class object.You see where we are going: in Python, classes are objects, and you can create a class on the fly, dynamically.This is what Python does when you use the keyword class, and it does so by using a metaclass.Metaclasses are the 'stuff' that creates classes.You define classes in order to create objects, right?But we learned that Python classes are objects.Well, metaclasses are what create these objects. They are the classes' classes,\nyou can picture them this way:You've seen that type lets you do something like this:It's because the function type is in fact a metaclass. type is the\nmetaclass Python uses to create all classes behind the scenes.Now you wonder \"why the heck is it written in lowercase, and not Type?\"Well, I guess it's a matter of consistency with str, the class that creates\nstrings objects, and int the class that creates integer objects. type is\njust the class that creates class objects.You see that by checking the __class__ attribute.Everything, and I mean everything, is an object in Python. That includes integers,\nstrings, functions and classes. All of them are objects. And all of them have\nbeen created from a class:Now, what is the __class__ of any __class__ ?So, a metaclass is just the stuff that creates class objects.You can call it a 'class factory' if you wish.type is the built-in metaclass Python uses, but of course, you can create your\nown metaclass.In Python 2, you can add a __metaclass__ attribute when you write a class (see next section for the Python 3 syntax):If you do so, Python will use the metaclass to create the class Foo.Careful, it's tricky.You write class Foo(object) first, but the class object Foo is not created\nin memory yet.Python will look for __metaclass__ in the class definition. If it finds it,\nit will use it to create the object class Foo. If it doesn't, it will use\ntype to create the class.Read that several times.When you do:Python does the following:Is there a __metaclass__ attribute in Foo?If yes, create in-memory a class object (I said a class object, stay with me here), with the name Foo by using what is in __metaclass__.If Python can't find __metaclass__, it will look for a __metaclass__ at the MODULE level, and try to do the same (but only for classes that don't inherit anything, basically old-style classes).Then if it can't find any __metaclass__ at all, it will use the Bar's (the first parent) own metaclass (which might be the default type) to create the class object.Be careful here that the __metaclass__ attribute will not be inherited, the metaclass of the parent (Bar.__class__) will be. If Bar used a __metaclass__ attribute that created Bar with type() (and not type.__new__()), the subclasses will not inherit that behavior.Now the big question is, what can you put in __metaclass__?The answer is something that can create a class.And what can create a class? type, or anything that subclasses or uses it.The syntax to set the metaclass has been changed in Python 3:i.e. the __metaclass__ attribute is no longer used, in favor of a keyword argument in the list of base classes.The behavior of metaclasses however stays largely the same.One thing added to metaclasses in Python 3 is that you can also pass attributes as keyword-arguments into a metaclass, like so:Read the section below for how Python handles this.The main purpose of a metaclass is to change the class automatically,\nwhen it's created.You usually do this for APIs, where you want to create classes matching the\ncurrent context.Imagine a stupid example, where you decide that all classes in your module\nshould have their attributes written in uppercase. There are several ways to\ndo this, but one way is to set __metaclass__ at the module level.This way, all classes of this module will be created using this metaclass,\nand we just have to tell the metaclass to turn all attributes to uppercase.Luckily, __metaclass__ can actually be any callable, it doesn't need to be a\nformal class (I know, something with 'class' in its name doesn't need to be\na class, go figure... but it's helpful).So we will start with a simple example, by using a function.Let's check:Now, let's do exactly the same, but using a real class for a metaclass:Let's rewrite the above, but with shorter and more realistic variable names now that we know what they mean:You may have noticed the extra argument cls. There is\nnothing special about it: __new__ always receives the class it's defined in, as the first parameter. Just like you have self for ordinary methods which receive the instance as the first parameter, or the defining class for class methods.But this is not proper OOP. We are calling type directly and we aren't overriding or calling the parent's __new__. Let's do that instead:We can make it even cleaner by using super, which will ease inheritance (because yes, you can have metaclasses, inheriting from metaclasses, inheriting from type):Oh, and in Python 3 if you do this call with keyword arguments, like this:It translates to this in the metaclass to use it:That's it. There is really nothing more about metaclasses.The reason behind the complexity of the code using metaclasses is not because\nof metaclasses, it's because you usually use metaclasses to do twisted stuff\nrelying on introspection, manipulating inheritance, vars such as __dict__, etc.Indeed, metaclasses are especially useful to do black magic, and therefore\ncomplicated stuff. But by themselves, they are simple:Since __metaclass__ can accept any callable, why would you use a class\nsince it's obviously more complicated?There are several reasons to do so:Now the big question. Why would you use some obscure error-prone feature?Well, usually you don't:Metaclasses are deeper magic that\n99% of users should never worry about it.\nIf you wonder whether you need them,\nyou don't (the people who actually\nneed them know with certainty that\nthey need them, and don't need an\nexplanation about why).Python Guru Tim PetersThe main use case for a metaclass is creating an API. A typical example of this is the Django ORM. It allows you to define something like this:But if you do this:It won't return an IntegerField object. It will return an int, and can even take it directly from the database.This is possible because models.Model defines __metaclass__ and\nit uses some magic that will turn the Person you just defined with simple statements\ninto a complex hook to a database field.Django makes something complex look simple by exposing a simple API\nand using metaclasses, recreating code from this API to do the real job\nbehind the scenes.First, you know that classes are objects that can create instances.Well, in fact, classes are themselves instances. Of metaclasses.Everything is an object in Python, and they are all either instance of classes\nor instances of metaclasses.Except for type.type is actually its own metaclass. This is not something you could\nreproduce in pure Python, and is done by cheating a little bit at the implementation\nlevel.Secondly, metaclasses are complicated. You may not want to use them for\nvery simple class alterations. You can change classes by using two different techniques:99% of the time you need class alteration, you are better off using these.But 98% of the time, you don't need class alteration at all.",
                "A metaclass is the class of a class. A class defines how an instance of the class (i.e. an object) behaves while a metaclass defines how a class behaves. A class is an instance of a metaclass.While in Python you can use arbitrary callables for metaclasses (like Jerub shows), the better approach is to make it an actual class itself. type is the usual metaclass in Python. type is itself a class, and it is its own type. You won't be able to recreate something like type purely in Python, but Python cheats a little. To create your own metaclass in Python you really just want to subclass type.A metaclass is most commonly used as a class-factory. When you create an object by calling the class, Python creates a new class (when it executes the 'class' statement) by calling the metaclass. Combined with the normal __init__ and __new__ methods, metaclasses therefore allow you to do 'extra things' when creating a class, like registering the new class with some registry or replace the class with something else entirely.When the class statement is executed, Python first executes the body of the class statement as a normal block of code. The resulting namespace (a dict) holds the attributes of the class-to-be. The metaclass is determined by looking at the baseclasses of the class-to-be (metaclasses are inherited), at the __metaclass__ attribute of the class-to-be (if any) or the __metaclass__ global variable. The metaclass is then called with the name, bases and attributes of the class to instantiate it.However, metaclasses actually define the type of a class, not just a factory for it, so you can do much more with them. You can, for instance, define normal methods on the metaclass. These metaclass-methods are like classmethods in that they can be called on the class without an instance, but they are also not like classmethods in that they cannot be called on an instance of the class. type.__subclasses__() is an example of a method on the type metaclass. You can also define the normal 'magic' methods, like __add__, __iter__ and __getattr__, to implement or change how the class behaves.Here's an aggregated example of the bits and pieces:",
                "Note, this answer is for Python 2.x as it was written in 2008, metaclasses are slightly different in 3.x.Metaclasses are the secret sauce that make 'class' work. The default metaclass for a new style object is called 'type'.Metaclasses take 3 args. 'name', 'bases' and 'dict'Here is where the secret starts. Look for where name, bases and the dict come from in this example class definition.Lets define a metaclass that will demonstrate how 'class:' calls it.And now, an example that actually means something, this will automatically make the variables in the list \"attributes\" set on the class, and set to None.Note that the magic behaviour that Initialised gains by having the metaclass init_attributes is not passed onto a subclass of Initialised.Here is an even more concrete example, showing how you can subclass 'type' to make a metaclass that performs an action when the class is created. This is quite tricky:",
                "Others have explained how metaclasses work and how they fit into the Python type system. Here's an example of what they can be used for. In a testing framework I wrote, I wanted to keep track of the order in which classes were defined, so that I could later instantiate them in this order. I found it easiest to do this using a metaclass.Anything that's a subclass of MyType then gets a class attribute _order that records the order in which the classes were defined.",
                "One use for metaclasses is adding new properties and methods to an instance automatically.For example, if you look at Django models, their definition looks a bit confusing. It looks as if you are only defining class properties:However, at runtime the Person objects are filled with all sorts of useful methods. See the source for some amazing metaclassery.",
                "I think the ONLamp introduction to metaclass programming is well written and gives a really good introduction to the topic despite being several years old already.http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html (archived at https://web.archive.org/web/20080206005253/http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html)In short: A class is a blueprint for the creation of an instance, a metaclass is a blueprint for the creation of a class. It can be easily seen that in Python classes need to be first-class objects too to enable this behavior.I've never written one myself, but I think one of the nicest uses of metaclasses can be seen in the Django framework. The model classes use a metaclass approach to enable a declarative style of writing new models or form classes. While the metaclass is creating the class, all members get the possibility to customize the class itself.The thing that's left to say is: If you don't know what metaclasses are, the probability that you will not need them is 99%.",
                "TLDR: A metaclass instantiates and defines behavior for a class just like a class instantiates and defines behavior for an instance.Pseudocode:The above should look familiar. Well, where does Class come from? It's an instance of a metaclass (also pseudocode):In real code, we can pass the default metaclass, type, everything we need to instantiate a class and we get a class:A class is to an instance as a metaclass is to a class.When we instantiate an object, we get an instance:Likewise, when we define a class explicitly with the default metaclass, type, we instantiate it:Put another way, a class is an instance of a metaclass:Put a third way, a metaclass is a class's class.When you write a class definition and Python executes it, it uses a metaclass to instantiate the class object (which will, in turn, be used to instantiate instances of that class).Just as we can use class definitions to change how custom object instances behave, we can use a metaclass class definition to change the way a class object behaves.What can they be used for? From the docs:The potential uses for metaclasses are boundless. Some ideas that have been explored include logging, interface checking, automatic delegation, automatic property creation, proxies, frameworks, and automatic resource locking/synchronization.Nevertheless, it is usually encouraged for users to avoid using metaclasses unless absolutely necessary.When you write a class definition, for example, like this,You instantiate a class object.It is the same as functionally calling type with the appropriate arguments and assigning the result to a variable of that name:Note, some things automatically get added to the __dict__, i.e., the namespace:The metaclass of the object we created, in both cases, is type.(A side-note on the contents of the class __dict__: __module__ is there because classes must know where they are defined, and  __dict__ and __weakref__ are there because we don't define __slots__ - if we define __slots__ we'll save a bit of space in the instances, as we can disallow __dict__ and __weakref__ by excluding them. For example:... but I digress.)Here's the default __repr__ of classes:One of the most valuable things we can do by default in writing a Python object is to provide it with a good __repr__. When we call help(repr) we learn that there's a good test for a __repr__ that also requires a test for equality - obj == eval(repr(obj)). The following simple implementation of __repr__ and __eq__ for class instances of our type class provides us with a demonstration that may improve on the default __repr__ of classes:So now when we create an object with this metaclass, the __repr__ echoed on the command line provides a much less ugly sight than the default:With a nice __repr__ defined for the class instance, we have a stronger ability to debug our code. However, much further checking with eval(repr(Class)) is unlikely (as functions would be rather impossible to eval from their default __repr__'s).If, for example, we want to know in what order a class's methods are created in, we could provide an ordered dict as the namespace of the class. We would do this with __prepare__ which returns the namespace dict for the class if it is implemented in Python 3:And usage:And now we have a record of the order in which these methods (and other class attributes) were created:Note, this example was adapted from the documentation - the new enum in the standard library does this.So what we did was instantiate a metaclass by creating a class. We can also treat the metaclass as we would any other class. It has a method resolution order:And it has approximately the correct repr (which we can no longer eval unless we can find a way to represent our functions.):",
                "Python 3 updateThere are (at this point) two key methods in a metaclass:__prepare__ lets you supply a custom mapping (such as an OrderedDict) to be used as the namespace while the class is being created.  You must return an instance of whatever namespace you choose.  If you don't implement __prepare__ a normal dict is used.__new__ is responsible for the actual creation/modification of the final class.A bare-bones, do-nothing-extra metaclass would like:A simple example:Say you want some simple validation code to run on your attributes -- like it must always be an int or a str.  Without a metaclass, your class would look something like:As you can see, you have to repeat the name of the attribute twice.  This makes typos possible along with irritating bugs.A simple metaclass can address that problem:This is what the metaclass would look like (not using __prepare__ since it is not needed):A sample run of:produces:Note:  This example is simple enough it could have also been accomplished with a class decorator, but presumably an actual metaclass would be doing much more.The 'ValidateType' class for reference:",
                "If you've done Python programming for more than a few months you'll eventually stumble upon code that looks like this:The latter is possible when you implement the __call__() magic method on the class.The __call__() method is invoked when an instance of a class is used as a callable. But as we've seen from previous answers a class itself is an instance of a metaclass, so when we use the class as a callable (i.e. when we create an instance of it) we're actually calling its metaclass' __call__() method. At this point most Python programmers are a bit confused because they've been told that when creating an instance like this instance = SomeClass() you're calling its __init__() method. Some who've dug a bit deeper know that before __init__() there's __new__(). Well, today another layer of truth is being revealed, before __new__() there's the metaclass' __call__().Let's study the method call chain from specifically the perspective of creating an instance of a class.This is a metaclass that logs exactly the moment before an instance is created and the moment it's about to return it.This is a class that uses that metaclassAnd now let's create an instance of Class_1Observe that the code above doesn't actually do anything more than logging the tasks. Each method delegates the actual work to its parent's implementation, thus keeping the default behavior. Since type is Meta_1's parent class (type being the default parent metaclass) and considering the ordering sequence of the output above, we now have a clue as to what would be the pseudo implementation of type.__call__():We can see that the metaclass' __call__() method is the one that's called first. It then delegates creation of the instance to the class's __new__() method and initialization to the instance's __init__(). It's also the one that ultimately returns the instance.From the above it stems that the metaclass' __call__() is also given the opportunity to decide whether or not a call to Class_1.__new__() or Class_1.__init__() will eventually be made. Over the course of its execution it could actually return an object that hasn't been touched by either of these methods. Take for example this approach to the singleton pattern:Let's observe what happens when repeatedly trying to create an object of type Class_2",
                "A metaclass is a class that tells how (some) other class should be created.This is a case where I saw metaclass as a solution to my problem:\nI had a really complicated problem, that probably could have been solved differently, but I chose to solve it using a metaclass.  Because of the complexity, it is one of the few modules I have written where the comments in the module surpass the amount of code that has been written.  Here it is...",
                "The type(obj) function gets you the type of an object.The type() of a class is its metaclass.To use a metaclass:type is its own metaclass. The class of a class is a metaclass-- the body of a class is the arguments passed to the metaclass that is used to construct the class.Here you can read about how to use metaclasses to customize class construction.",
                "type is actually a metaclass -- a class that creates another classes.\nMost metaclass are the subclasses of type. The metaclass receives the new class as its first argument and provide access to class object with details as mentioned below:Note:Notice that the class was not instantiated at any time; the simple act of creating the class triggered execution of the metaclass.",
                "Python classes are themselves objects - as in instance - of their meta-class.The default metaclass, which is applied when when you determine classes as:meta class are used to apply some rule to an entire set of classes. For example, suppose you're building an ORM to access a database, and you want records from each table to be of a class mapped to that table (based on fields, business rules, etc..,), a possible use of metaclass is for instance, connection pool logic, which is share by all classes of record from all tables. Another use is logic to to support foreign keys, which involves multiple classes of records.when you define metaclass, you subclass type, and can overrided the following magic methods to insert your logic.anyhow, those two are the most commonly used hooks. metaclassing is powerful, and above is nowhere near and exhaustive list of uses for metaclassing.",
                "The type() function can return the type of an object or create a new type,for example, we can create a Hi class with the type() function and do not  need to use this way with class Hi(object):In addition to using type() to create classes dynamically, you can control creation behavior of class and use metaclass.According to the Python object model, the class is the object, so the class must be an instance of another certain class.\nBy default, a Python class is instance of the type class. That is, type is metaclass of most of the built-in classes and metaclass of user-defined classes.Magic will take effect when we passed keyword arguments in metaclass, it indicates the Python interpreter to create the CustomList through ListMetaclass. new (), at this point, we can modify the class definition, for example, and add a new method and then return the revised definition.",
                "In addition to the published answers I can say that a metaclass defines the behaviour for a class. So, you can explicitly set your metaclass. Whenever Python gets a keyword class then it starts searching for the metaclass. If it's not found \u2013 the default metaclass type is used to create the class's object. Using the __metaclass__ attribute, you can set metaclass of your class:It'll produce the output like this:And, of course, you can create your own metaclass to define the behaviour of any class that are created using your class.For doing that, your default metaclass type class must be inherited as this is the main metaclass:The output will be:",
                "Note that in python 3.6 a new dunder method __init_subclass__(cls, **kwargs) was introduced to replace a lot of common use cases for metaclasses. Is is called when a subclass of the defining class is created. See python docs.",
                "Here's another example of what it can be used for:The metaclass is powerful, there are many things (such as monkey magic) you can do with it, but be careful this may only be known to you.",
                "The top answer is correct.But readers may be coming here searching answers about similarly named inner classes. They are present in popular libraries, such as Django and WTForms.As DavidW points out in the comments beneath this answer, these are library-specific features and are not to be confused with the advanced, unrelated Python language feature with a similar name.Rather, these are namespaces within classes' dicts. They are constructed using inner classes for sake of readability.In this example special field, abstract is visibly separate from fields of Author model.Another example is from the documentation for WTForms:This syntax does not get special treatment in the python programming language. Meta is not a keyword here, and does not trigger metaclass behavior. Rather, third-party library code in packages like Django and WTForms reads this property in the constructors of certain classes, and elsewhere.The presence of these declarations modifies the behavior of the classes that have these declarations. For example, WTForms reads self.Meta.csrf to determine if the form needs a csrf field.",
                "In object-oriented programming, a metaclass is a class whose instances are classes. Just as an ordinary class defines the behavior of certain objects, a metaclass defines the behavior of certain class and their instances\nThe term metaclass simply means something used to create classes. In other words, it is the class of a class. The metaclass is used to create the class so like the object being an instance of a class, a class is an instance of a metaclass. In python classes are also considered objects.",
                "A class, in Python, is an object, and just like any other object, it is an instance of \"something\". This \"something\" is what is termed as a Metaclass. This metaclass is a special type of class that creates other class's objects. Hence, metaclass is responsible for making new classes. This allows the programmer to customize the way classes are generated.To create a metaclass, overriding of new() and init() methods is usually done. new() can be overridden to change the way objects are created, while init() can be overridden to change the way of initializing the object. Metaclass can be created by a number of ways. One of the ways is to use type() function. type() function, when called with 3 parameters, creates a metaclass. The parameters are :-Another way of creating a metaclass comprises of 'metaclass' keyword. Define the metaclass as a simple class. In the parameters of inherited class, pass metaclass=metaclass_nameMetaclass can be specifically used in the following situations :-",
                "I saw an interesting use case for metaclasses in a package called classutilities. It checks if all class variables are in upper case format (it is convenient to have unified logic for configuration classes), and checks if there are no instance level methods in class.\nAnother interesting example for metaclases was deactivation of unittests based on complex conditions (checking values of multiple environmental variables).",
                "In Python, a metaclass is a subclass of a subclass that determines how a subclass behaves. A class is an instance of another metaclass. In Python, a class specifies how the class's instance will behave.Since metaclasses are in charge of class generation, you can\u00a0write your own custom metaclasses to change how classes are created by performing additional actions or injecting code. Custom metaclasses aren't always important, but they can be.",
                "look this:In other words, when an object was not created (type of object), we looking MetaClass."
            ]
        },
        {
            "tag": "",
            "question": [
                "How to find all files containing specific text (string) on Linux?",
                "How do I find all files containing a specific string of text within their file contents?\nThe following doesn't work. It seems to display every single file in the system.\nfind / -type f -exec grep -H '..."
            ],
            "url": "https://stackoverflow.com/questions/16956810",
            "answer": [
                "Do the following:Along with these, --exclude, --include, --exclude-dir flags could be used for efficient searching:This will only search through those files which have .c or .h extensions:This will exclude searching all the files ending with .o extension:For directories it's possible to exclude one or more directories using the --exclude-dir parameter. For example, this will exclude the dirs dir1/, dir2/ and all of them matching *.dst/:This works very well for me, to achieve almost the same purpose like yours.For more options, see man grep.",
                "Use grep -ilR:",
                "You can use ack. It is like grep for source code. You can scan your entire file system with it.Just do:In your root directory.You can also use regular expressions, specify the filetype, etc.UPDATEI just discovered The Silver Searcher, which is like ack but 3-5x faster than it and even ignores patterns from a .gitignore file.",
                "You can use:The r stands for recursive and so will search in the path specified and also its sub-directories. This will tell you the file name as well as print out the line in the file where the string appears.Or a command similar to the one you are trying (example: ) for searching in all javascript files (*.js):This will print the lines in the files where the text appears, but it does not print the file name.In addition to this command, we can write this too:\ngrep -rn \"String to search\" /path/to/directory/or/file\n-r: recursive search\nn: line number will be shown for matches",
                "Recursive and case insensitive grep with line numbers:",
                "You can use grep tool to search recursively the current folder, like:Note: -r - Recursively search subdirectories.You can also use globbing syntax to search within specific files such as:Note: By using globbing option (**), it scans all the files recursively with specific extension or pattern. To enable this syntax, run: shopt -s globstar. You may also use **/*.* for all files (excluding hidden and without extension) or any other pattern.If you've the error that your argument is too long, consider narrowing down your search, or use find syntax instead such as:Alternatively, use ripgrep.If you're working on larger projects or big files, you should use ripgrep instead, like:Checkout the docs, installation steps or source code on the GitHub project page.It's much quicker than any other tool like GNU/BSD grep, ucg, ag, sift, ack, pt or similar, since it is built on top of Rust's regex engine which uses finite automata, SIMD and aggressive literal optimizations to make searching very fast.It supports ignore patterns specified in .gitignore files, so a single file path can be matched against multiple glob patterns simultaneously.You can use common parameters such as:",
                "First of all, I believe you have used -H instead of -l. Also you can try adding the text inside quotes followed by {} \\.Let's say you are searching for files containing specific text \"Apache License\" inside your directory. It will display results somewhat similar to below (output will be different based on your directory content).Even if you are not use about the case like \"text\" vs \"TEXT\", you can use the -i switch to ignore case. You can read further details here.Hope this helps you.",
                "This grep command will give you a precise result when you are searching for specific text on Linux -grep -inRsH \"Text to be searched\"  /path/to/dir (it can be '.')i stands for ignore case distinctionsR stands for recursive and it also include symlinks. It is better to use 'R' instead of 'r'n stands for \"it will print line number\".s stands for \"suppress error messages\"H stands for \"it will print the file name for each match\"",
                "If your grep doesn't support recursive search, you can combine find with xargs:I find this easier to remember than the format for find -exec.This will output the filename and the content of the matched line, e.g.Optional flags you may want to add to grep:",
                "There's a new utility called The SilversearcherIt works closely with Git and other VCS. So you won't get anything in a .git or another directory.You can simply useAnd it will do the task for you!",
                "How do I find all files containing specific text on Linux?\n  (...)I came across this solution twice:find / -type f -exec grep -H 'text-to-find-here' {} \\;If using find like in your example, better add -s (--no-messages) to grep, and 2>/dev/null at the end of the command to avoid lots of Permission denied messages issued by grep and find:find is the standard tool for searching files - combined with grep when looking for specific text - on Unix-like platforms. The find command is often combined with xargs, by the way.Faster and easier tools exist for the same purpose - see below. Better try them, provided they're available on your platform, of course:RipGrep - fastest search tool around:The Silver Searcher:ack:Note: You can add 2>/dev/null to these commands as well, to hide many error messages.Warning: unless you really can't avoid it, don't search from '/' (the root directory) to avoid a long and inefficient search!\n So in the examples above, you'd better replace '/' by a sub-directory name, e.g. \"/home\" depending where you actually want to search...",
                "Use pwd to search from any directory you are in, recursing downwardDepending on the version of grep you are using, you can omit pwd. In newer versions . seems to be the default case for grep if no directory is given.Thus:grep -rnw -e \"pattern\"orgrep -rnw \"pattern\"will do the same thing as above!",
                "Try:",
                "For example:",
                "grep can be used even if we're not looking for a string.Simply running,will print out the path to all text files, i.e. those containing only printable characters.",
                "Silver Searcher is a terrific tool, but ripgrep may be even better.It works on Linux, Mac and Windows, and was written up on Hacker News a couple of months ago (this has a link to Andrew Gallant's Blog which has a GitHub link):Ripgrep \u2013 A new command line search tool",
                "If you strictly want to use find then use find + grep:find /path/to/somewhere/ -type f -exec grep -nw 'textPattern' {} \\;Steps:This gives you the power of find to find files.find /path/to/somewhere/ -type f -name \\*.cpp -exec grep -nw 'textPattern' {} \\;You can use different options of find to improve your file search.",
                "Here are the several list of commands that can be used to search file.",
                "If you are in a Git repository, you can use:",
                "I am fascinated by how simple grep makes it with 'rl':Use '-r' without 'l' to see the file names followed by text in which the pattern is found!It works just perfect...",
                "Hope this is of assistance...Expanding the grep a bit to give more information in the output, for example, to get the line number in the file where the text is can be done as follows:And if you have an idea what the file type is you can narrow your search down by specifying file type extensions to search for, in this case .pas OR .dfm files:Short explanation of the options:",
                "orIf you want to search the current directory:",
                "There is the ack tool that would do exactly what you are looking for:You may ignore -i for case sensitive search.",
                "Explanation from commentsfind is a command that lets you find files and other objects like directories and links in subdirectories of a given path. If you don't specify a mask that filesnames should meet, it enumerates all directory objects.",
                "Try:which will search all file systems, because / is the root folder.For home folder use:For current folder use:",
                "A Simple find can work handy. alias it in your ~/.bashrc file:Start a new terminal and issue:",
                "grep is your good friend to achieve this.If you don't care about the case of the text to find, then use:",
                "To search for the string and output just that line with the search string:e.g.:To display filename containing the search string:e.g.:",
                "I wrote a Python script which does something similar. This is how one should use this script.The first argument, path, is the directory in which we will search recursively. The second argument, pattern_to_search, is a regular expression which we want to search in a file. We use the regular expression format defined in the Python re library. In this script, the . also matches newline.The third argument, file_pattern, is optional. This is another regular expression which works on a filename. Only those files which matches this regular expression will be considered.For example, if I want to search Python files with the extension py containing Pool( followed by word Adaptor, I do the following,And voila, it generates the path of matched files and line number at which the match was found. If more than one match was found, then each line number will be appended to the filename."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I check whether a file exists without exceptions?",
                "How do I check whether a file exists or not, without using the try statement?"
            ],
            "url": "https://stackoverflow.com/questions/82831",
            "answer": [
                "If the reason you're checking is so you can do something like if file_exists: open_it(), it's safer to use a try around the attempt to open it. Checking and then opening risks the file being deleted or moved or something between when you check and when you try to open it.If you're not planning to open the file immediately, you can use os.path.isfileReturn True if path is an existing regular file. This follows symbolic links, so both islink() and isfile() can be true for the same path.if you need to be sure it's a file.Starting with Python 3.4, the pathlib module offers an object-oriented approach (backported to pathlib2 in Python 2.7):To check a directory, do:To check whether a Path object exists independently of whether is it a file or directory, use exists():You can also use resolve(strict=True) in a try block:",
                "Use os.path.exists to check both files and directories:Use os.path.isfile to check only files (note: follows symbolic links):",
                "Unlike isfile(), exists() will return True for directories. So depending on if you want only plain files or also directories, you'll use isfile() or exists(). Here is some simple REPL output:",
                "Use os.path.isfile() with os.access():",
                "Although almost every possible way has been listed in (at least one of) the existing answers (e.g. Python 3.4 specific stuff was added), I'll try to group everything together.Note: every piece of Python standard library code that I'm going to post, belongs to version 3.5.3.Problem statement:Check file (arguable: also folder (\"special\" file) ?) existenceDon't use try / except / else / finally blocksPossible solutions:Also check other function family members like os.path.isfile, os.path.isdir, os.path.lexists for slightly different behaviors:Return True if path refers to an existing path or an open file descriptor. Returns False for broken symbolic links. On some platforms, this function may return False if permission is not granted to execute os.stat() on the requested file, even if the path physically exists.All good, but if following the import tree:os.path - posixpath.py (ntpath.py)genericpath.py - line ~20+it's just a try / except block around [Python.Docs]: os.stat(path, *, dir_fd=None, follow_symlinks=True). So, your code is try / except free, but lower in the framestack there's (at least) one such block. This also applies to other functions (including os.path.isfile).It's a fancier (and more [Wiktionary]: Pythonic) way of handling paths, butUnder the hood, it does exactly the same thing (pathlib.py - line ~1330):Either:Create one:And its usage - I'll replicate the os.path.isfile behavior (note that this is just for demonstrating purposes, do not attempt to write such code for production):Use [Python.Docs]: contextlib.suppress(*exceptions) - which was specifically designed for selectively suppressing exceptionsBut, they seem to be wrappers over try / except / else / finally blocks, as [Python.Docs]: Compound statements - The with statement states:This allows common try...except...finally usage patterns to be encapsulated for convenient reuse.Search the results for matching item(s):[Python.Docs]: os.listdir(path='.') (or [Python.Docs]: os.scandir(path='.') on Python v3.5+, backport: [PyPI]: scandir)Under the hood, both use:Nix: [Man7]: OPENDIR(3) / [Man7]: READDIR(3) / [Man7]: CLOSEDIR(3)Win: [MS.Learn]: FindFirstFileW function (fileapi.h) / [MS.Learn]: FindNextFileW function (fileapi.h) / [MS.Learn]: FindClose function (fileapi.h)via [GitHub]: python/cpython - (main) cpython/Modules/posixmodule.cUsing scandir() instead of listdir() can significantly increase the performance of code that also needs file type or file attribute information, because os.DirEntry objects expose this information if the operating system provides it when scanning a directory. All os.DirEntry methods may perform a system call, but is_dir() and is_file() usually only require a system call for symbolic links; os.DirEntry.stat() always requires a system call on Unix, but only requires one for symbolic links on Windows.[Python.Docs]: os.walk(top, topdown=True, onerror=None, followlinks=False)[Python.Docs]: glob.iglob(pathname, *, root_dir=None, dir_fd=None, recursive=False, include_hidden=False) (or its predecessor: glob.glob)Since these iterate over folders, (in most of the cases) they are inefficient for our problem (there are exceptions, like non wildcarded globbing - as @ShadowRanger pointed out), so I'm not going to insist on them. Not to mention that in some cases, filename processing might be required.Its behavior is close to os.path.exists (actually it's wider, mainly because of the 2nd argument).User permissions might restrict the file \"visibility\" as the doc states:... test if the invoking user has the specified access to path. mode should be F_OK to test the existence of path...Security considerations:Using access() to check if a user is authorized to e.g. open a file before actually doing so using open() creates a security hole, because the user might exploit the short time interval between checking and opening the file to manipulate it.Since I also work in C, I use this method as well because under the hood, it calls native APIs (again, via \"${PYTHON_SRC_DIR}/Modules/posixmodule.c\"), but it also opens a gate for possible user errors, and it's not as Pythonic as other variants. So, don't use it unless you know what you're doing:Nix: [Man7]: ACCESS(2)Warning: Using these calls to check if a user is authorized to, for example, open a file before actually doing so using open(2) creates a security hole, because the user might exploit the short time interval between checking and opening the file to manipulate it. For this reason, the use of this system call should be avoided.Win: [MS.Learn]: GetFileAttributesW function (fileapi.h)As seen, this approach is highly discouraged (especially on Nix).Note: calling native APIs is also possible via [Python.Docs]: ctypes - A foreign function library for Python, but in most cases it's more complicated. Before working with CTypes, check [SO]: C function called from Python via ctypes returns incorrect value (@CristiFati's answer) out.(Win specific): since vcruntime###.dll (msvcr###.dll for older VStudio versions - I'm going to refer to it as UCRT) exports a [MS.Learn]: _access, _waccess function family as well, here's an example (note that the recommended [Python.Docs]: msvcrt - Useful routines from the MS VC++ runtime doesn't export them):Notes:Although it's not a good practice, I'm using os.F_OK in the call, but that's just for clarity (its value is 0)I'm using _waccess so that the same code works on Python 3 and Python 2 (in spite of [Wikipedia]: Unicode related differences between them - [SO]: Passing utf-16 string to a Windows function (@CristiFati's answer))Although this targets a very specific area, it was not mentioned in any of the previous answersThe Linux (Ubuntu ([Wikipedia]: Ubuntu version history) 16 x86_64 (pc064)) counterpart as well:Notes:Instead hardcoding libc.so (LibC)'s path (\"/lib/x86_64-linux-gnu/libc.so.6\") which may (and most likely, will) vary across systems, None (or the empty string) can be passed to CDLL constructor (ctypes.CDLL(None).access(b\"/tmp\", os.F_OK)). According to [Man7]: DLOPEN(3):If filename is NULL, then the returned handle is for the main\nprogram.  When given to dlsym(3), this handle causes a search for a\nsymbol in the main program, followed by all shared objects loaded at\nprogram startup, and then all shared objects loaded by dlopen() with\nthe flag RTLD_GLOBAL.Main (current) program (python) is linked against LibC, so its symbols (including access) will be loadedThis has to be handled with care, since functions like main, Py_Main and (all the) others are available; calling them could have disastrous effects (on the current program)This doesn't also apply to Windows (but that's not such a big deal, since UCRT is located in \"%SystemRoot%\\System32\" which is in %PATH% by default). I wanted to take things further and replicate this behavior on Windows (and submit a patch), but as it turns out, [MS.Learn]: GetProcAddress function (libloaderapi.h) only \"sees\" exported symbols, so unless someone declares the functions in the main executable as __declspec(dllexport) (why on Earth the common person would do that?), the main program is loadable, but it is pretty much unusableMost likely, will rely on one of the ways above (maybe with slight customizations). One example would be (again, Win specific) [GitHub]: mhammond/pywin32 - Python for Windows (pywin32) Extensions, which is a Python wrapper over WinAPIs.But, since this is more like a workaround, I'm stopping here.I consider this a (lame) workaround (gainarie): use Python as a wrapper to execute shell commands:Win:Nix ([Wikipedia]: Unix-like) - Ubuntu:Do use try / except / else / finally blocks, because they can prevent you running into a series of nasty problemsA possible counterexample that I can think of, is performance: such blocks are costly, so try not to place them in code that it's supposed to run hundreds of thousands times per second (but since (in most cases) it involves disk access, it won't be the case)",
                "Python 3.4+ has an object-oriented path module: pathlib.  Using this new module, you can check whether a file exists like this:You can (and usually should) still use a try/except block when opening files:The pathlib module has lots of cool stuff in it: convenient globbing, checking file's owner, easier path joining, etc.  It's worth checking out.  If you're on an older Python (version 2.6 or later), you can still install pathlib with pip:Then import it as follows:",
                "This is the simplest way to check if a file exists. Just because the file existed when you checked doesn't guarantee that it will be there when you need to open it.",
                "Now available since Python 3.4, import and instantiate a Path object with the file name, and check the is_file method (note that this returns True for symlinks pointing to regular files as well):If you're on Python 2, you can backport the pathlib module from pypi, pathlib2, or otherwise check isfile from the os.path module:Now the above is probably the best pragmatic direct answer here, but there's the possibility of a race condition (depending on what you're trying to accomplish), and the fact that the underlying implementation uses a try, but Python uses try everywhere in its implementation.Because Python uses try everywhere, there's really no reason to avoid an implementation that uses it.But the rest of this answer attempts to consider these caveats.Available since Python 3.4, use the new Path object in pathlib. Note that .exists is not quite right, because directories are not files (except in the unix sense that everything is a file).So we need to use is_file:Here's the help on is_file:So let's get a file that we know is a file:By default, NamedTemporaryFile deletes the file when closed (and will automatically close when no more references exist to it).If you dig into the implementation, though, you'll see that is_file uses try:We like try because it avoids race conditions. With try, you simply attempt to read your file, expecting it to be there, and if not, you catch the exception and perform whatever fallback behavior makes sense.If you want to check that a file exists before you attempt to read it, and you might be deleting it and then you might be using multiple threads or processes, or another program knows about that file and could delete it - you risk the chance of a race condition if you check it exists, because you are then racing to open it before its condition (its existence) changes.Race conditions are very hard to debug because there's a very small window in which they can cause your program to fail.But if this is your motivation, you can get the value of a try statement by using the suppress context manager.Python 3.4 gives us the suppress context manager (previously the ignore context manager), which does semantically exactly the same thing in fewer lines, while also (at least superficially) meeting the original ask to avoid a try statement:Usage:For earlier Pythons, you could roll your own suppress, but without a try will be more verbose than with. I do believe this actually is the only answer that doesn't use try at any level in the Python that can be applied to prior to Python 3.4 because it uses a context manager instead:Perhaps easier with a try:isfilefrom the docs:os.path.isfile(path)Return True if path is an existing regular file. This follows symbolic\n  links, so both islink() and isfile() can be true for the same path.But if you examine the source of this function, you'll see it actually does use a try statement:All it's doing is using the given path to see if it can get stats on it,  catching OSError and then checking if it's a file if it didn't raise the exception.If you intend to do something with the file, I would suggest directly attempting it with a try-except to avoid a race condition:os.accessAvailable for Unix and Windows is os.access, but to use you must pass flags, and it does not differentiate between files and directories. This is more used to test if the real invoking user has access in an elevated privilege environment:It also suffers from the same race condition problems as isfile. From the docs:Note:\n  Using access() to check if a user is authorized to e.g. open a file\n  before actually doing so using open() creates a security hole, because\n  the user might exploit the short time interval between checking and\n  opening the file to manipulate it. It\u2019s preferable to use EAFP\n  techniques. For example:is better written as:Avoid using os.access. It is a low level function that has more opportunities for user error than the higher level objects and functions discussed above.Another answer says this about os.access:Personally, I prefer this one because under the hood, it calls native APIs (via \"${PYTHON_SRC_DIR}/Modules/posixmodule.c\"), but it also opens a gate for possible user errors, and it's not as Pythonic as other variants:This answer says it prefers a non-Pythonic, error-prone method, with no justification. It seems to encourage users to use low-level APIs without understanding them.It also creates a context manager which, by unconditionally returning True, allows all Exceptions (including KeyboardInterrupt and SystemExit!) to pass silently, which is a good way to hide bugs.This seems to encourage users to adopt poor practices.",
                "Prefer the try statement. It's considered better style and avoids race conditions.Don't take my word for it. There's plenty of support for this theory. Here's a couple:",
                "Use:Importing os makes it easier to navigate and perform standard actions with your operating system.For reference, also see How do I check whether a file exists without exceptions?.If you need high-level operations, use shutil.",
                "Testing for files and folders with os.path.isfile(), os.path.isdir() and os.path.exists()Assuming that the \"path\" is a valid path, this table shows what is returned by each function for files and folders:You can also test if a file is a certain type of file using os.path.splitext() to get the extension (if you don't already know it)",
                "TL;DR \nThe answer is: use the pathlib modulePathlib is probably the most modern and convenient way for almost all of the file operations. For the existence of a file or a folder a single line of code is enough. If file is not exists, it will not throw any exception.The pathlib module was introduced in Python 3.4, so you need to have Python 3.4+. This library makes your life much easier while working with files and folders, and it is pretty to use. Here is more documentation about it: pathlib \u2014 Object-oriented filesystem paths.BTW, if you are going to reuse the path, then it is better to assign it to a variable.So it will become:",
                "In 2016 the best way is still using os.path.isfile:Or in Python 3 you can use pathlib:",
                "It doesn't seem like there's a meaningful functional difference between try/except and isfile(), so you should use which one makes sense.If you want to read a file, if it exists, doBut if you just wanted to rename a file if it exists, and therefore don't need to open it, doIf you want to write to a file, if it doesn't exist, doIf you need file locking, that's a different matter.",
                "You could try this (safer):The ouput would be:([Errno 2] No such file or directory:\n  'whatever.txt')Then, depending on the result, your program can just keep running from there or you can code to stop it if you want.",
                "Date: 2017-12-04Every possible solution has been listed in other answers.An intuitive and arguable way to check if a file exists is the following:I made an exhaustive cheat sheet for your reference:",
                "Although I always recommend using try and except statements, here are a few possibilities for you (my personal favourite is using os.access):Try opening the file:Opening the file will always verify the existence of the file. You can make a function just like so:If it's False, it will stop execution with an unhanded IOError\nor OSError in later versions of Python. To catch the exception,\nyou have to use a try except clause. Of course, you can always\nuse a try except` statement like so (thanks to hsandt\nfor making me think):Use os.path.exists(path):This will check the existence of what you specify. However, it checks for files and directories so beware about how you use it.Use os.access(path, mode):This will check whether you have access to the file. It will check for permissions. Based on the os.py documentation, typing in os.F_OK, it will check the existence of the path. However, using this will create a security hole, as someone can attack your file using the time between checking the permissions and opening the file. You should instead go directly to opening the file instead of checking its permissions. (EAFP vs LBYP). If you're not going to open the file afterwards, and only checking its existence, then you can use this.Anyway, here:I should also mention that there are two ways that you will not be able to verify the existence of a file. Either the issue will be permission denied or no such file or directory. If you catch an IOError, set the IOError as e (like my first option), and then type in print(e.args) so that you can hopefully determine your issue. I hope it helps! :)",
                "If the file is for opening you could use one of the following techniques:Note: This finds either a file or a directory with the given name.",
                "Additionally, os.access():Being R_OK, W_OK, and X_OK the flags to test for permissions (doc).",
                "Raising exceptions is considered to be an acceptable, and Pythonic,\napproach for flow control in your program. Consider handling missing\nfiles with IOErrors. In this situation, an IOError exception will be\nraised if the file exists but the user does not have read permissions.Source: Using Python: How To Check If A File Exists",
                "If you imported NumPy already for other purposes then there is no need to import other libraries like pathlib, os, paths, etc.This will return true or false based on its existence.",
                "You can follow these three ways:Note 1: The os.path.isfile used only for filesNote 2: The os.path.exists is used for both files and directories",
                "You can write Brian's suggestion without the try:.suppress is part of Python 3.4. In older releases you can quickly write your own suppress:",
                "Adding one more slight variation which isn't exactly reflected in the other answers.This will handle the case of the file_path being None or empty string.Adding a variant based on suggestion from ShahbazAdding a variant based on suggestion from Peter Wood",
                "I'm the author of a package that's been around for about 10 years, and it has a function that addresses this question directly. Basically, if you are on a non-Windows system, it uses Popen to access find.  However, if you are on Windows, it replicates find with an efficient filesystem walker.The code itself does not use a try block\u2026 except in determining the operating system and thus steering you to the \"Unix\"-style find or the hand-buillt find. Timing tests showed that the try was faster in determining the OS, so I did use one there (but nowhere else).And the doc\u2026The implementation, if you care to look, is here:\nhttps://github.com/uqfoundation/pox/blob/89f90fb308f285ca7a62eabe2c38acb87e89dad9/pox/shutils.py#L190",
                "Here's a one-line Python command for the Linux command line environment. I find this very handy since I'm not such a hot Bash guy.",
                "You can use the \"OS\" library of Python:",
                "How do I check whether a file exists, without using the try statement?In 2016, this is still arguably the easiest way to check if both a file exists and if it is a file:isfile is actually just a helper method that internally uses os.stat and stat.S_ISREG(mode) underneath. This os.stat is a lower-level method that will provide you with detailed information about files, directories, sockets, buffers, and more. More about os.stat hereNote: However, this approach will not lock the file in any way and therefore your code can become vulnerable to \"time of check to time of use\" (TOCTTOU) bugs.So raising exceptions is considered to be an acceptable, and Pythonic, approach for flow control in your program. And one should consider handling missing files with IOErrors, rather than if statements (just an advice)."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I merge two dictionaries in a single expression?",
                "I want to merge two dictionaries into a new dictionary.\nx = {'a': 1, 'b': 2}\ny = {'b': 3, 'c': 4}\nz = merge(x, y)\n\n>>> z\n{'a': 1, 'b': 3, 'c': 4}\n\nWhenever a key k is present in both ..."
            ],
            "url": "https://stackoverflow.com/questions/38987",
            "answer": [
                "For dictionaries x and y, their shallowly-merged dictionary z takes values from y, replacing those from x.In Python 3.9.0 or greater (released 17 October 2020, PEP-584, discussed here):In Python 3.5 or greater:In Python 2, (or 3.4 or lower) write a function:and now:Say you have two dictionaries and you want to merge them into a new dictionary without altering the original dictionaries:The desired result is to get a new dictionary (z) with the values merged, and the second dictionary's values overwriting those from the first.A new syntax for this, proposed in PEP 448 and available as of Python 3.5, isAnd it is indeed a single expression.Note that we can merge in with literal notation as well:and now:It is now showing as implemented in the release schedule for 3.5, PEP 478, and it has now made its way into the What's New in Python 3.5 document.However, since many organizations are still on Python 2, you may wish to do this in a backward-compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process:In both approaches, y will come second and its values will replace x's values, thus b will point to 3 in our final result.If you are not yet on Python 3.5 or need to write backward-compatible code, and you want this in a single expression, the most performant while the correct approach is to put it in a function:and then you have a single expression:You can also make a function to merge an arbitrary number of dictionaries, from zero to a very large number:This function will work in Python 2 and 3 for all dictionaries. e.g. given dictionaries a to g:and key-value pairs in g will take precedence over dictionaries a to f, and so on.Don't use what you see in the formerly accepted answer:In Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict. In Python 3, this will fail because you're adding two dict_items objects together, not two lists -and you would have to explicitly create them as lists, e.g. z = dict(list(x.items()) + list(y.items())). This is a waste of resources and computation power.Similarly, taking the union of items() in Python 3 (viewitems() in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable, since sets are semantically unordered, the behavior is undefined in regards to precedence. So don't do this:This example demonstrates what happens when values are unhashable:Here's an example where y should have precedence, but instead the value from x is retained due to the arbitrary order of sets:Another hack you should not use:This uses the dict constructor and is very fast and memory-efficient (even slightly more so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic.Here's an example of the usage being remediated in django.Dictionaries are intended to take hashable keys (e.g. frozensets or tuples), but this method fails in Python 3 when keys are not strings.From the mailing list, Guido van Rossum, the creator of the language, wrote:I am fine with\ndeclaring dict({}, **{1:3}) illegal, since after all it is abuse of\nthe ** mechanism.andApparently dict(x, **y) is going around as \"cool hack\" for \"call\nx.update(y) and return x\". Personally, I find it more despicable than\ncool.It is my understanding (as well as the understanding of the creator of the language) that the intended usage for dict(**y) is for creating dictionaries for readability purposes, e.g.:instead ofDespite what Guido says, dict(x, **y) is in line with the dict specification, which btw. works for both Python 2 and 3. The fact that this only works for string keys is a direct consequence of how keyword parameters work and not a short-coming of dict. Nor is using the ** operator in this place an abuse of the mechanism, in fact, ** was designed precisely to pass dictionaries as keywords.Again, it doesn't work for 3 when keys are not strings. The implicit calling contract is that namespaces take ordinary dictionaries, while users must only pass keyword arguments that are strings. All other callables enforced it. dict broke this consistency in Python 2:This inconsistency was bad given other implementations of Python (PyPy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change.I submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints.More comments:dict(x.items() + y.items()) is still the most readable solution for Python 2. Readability counts.My response: merge_two_dicts(x, y) actually seems much clearer to me, if we're actually concerned about readability. And it is not forward compatible, as Python 2 is increasingly deprecated.{**x, **y} does not seem to handle nested dictionaries. the contents of nested keys are simply overwritten, not merged [...] I ended up being burnt by these answers that do not merge recursively and I was surprised no one mentioned it. In my interpretation of the word \"merging\" these answers describe \"updating one dict with another\", and not merging.Yes. I must refer you back to the question, which is asking for a shallow merge of two dictionaries, with the first's values being overwritten by the second's - in a single expression.Assuming two dictionaries of dictionaries, one might recursively merge them in a single function, but you should be careful not to modify the dictionaries from either source, and the surest way to avoid that is to make a copy when assigning values. As keys must be hashable and are usually therefore immutable, it is pointless to copy them:Usage:Coming up with contingencies for other value types is far beyond the scope of this question, so I will point you at my answer to the canonical question on a \"Dictionaries of dictionaries merge\".These approaches are less performant, but they will provide correct behavior.\nThey will be much less performant than copy and update or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they do respect the order of precedence (latter dictionaries have precedence)You can also chain the dictionaries manually inside a dict comprehension:or in Python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced):itertools.chain will chain the iterators over the key-value pairs in the correct order:I'm only going to do the performance analysis of the usages known to behave correctly. (Self-contained so you can copy and paste yourself.)In Python 3.8.1, NixOS:",
                "In your case, you can do:This will, as you want it, put the final dict in z, and make the value for key b be properly overridden by the second (y) dict's value:If you use Python 2, you can even remove the list() calls. To create z:If you use Python version 3.9.0a4 or greater, then you can directly use:",
                "An alternative:",
                "Another, more concise, option:Note: this has become a popular answer, but it is important to point out that if y has any non-string keys, the fact that this works at all is an abuse of a CPython implementation detail, and it does not work in Python 3, or in PyPy, IronPython, or Jython. Also, Guido is not a fan. So I can't recommend this technique for forward-compatible or cross-implementation portable code, which really means it should be avoided entirely.",
                "This probably won't be a popular answer, but you almost certainly do not want to do this.  If you want a copy that's a merge, then use copy (or deepcopy, depending on what you want) and then update.  The two lines of code are much more readable - more Pythonic - than the single line creation with .items() + .items().  Explicit is better than implicit.In addition, when you use .items() (pre Python 3.0), you're creating a new list that contains the items from the dict.  If your dictionaries are large, then that is quite a lot of overhead (two large lists that will be thrown away as soon as the merged dict is created).  update() can work more efficiently, because it can run through the second dict item-by-item.In terms of time:IMO the tiny slowdown between the first two is worth it for the readability.  In addition, keyword arguments for dictionary creation was only added in Python 2.3, whereas copy() and update() will work in older versions.",
                "In a follow-up answer, you asked about the relative performance of these two alternatives:On my machine, at least (a fairly ordinary x86_64 running Python 2.5.2), alternative z2 is not only shorter and simpler but also significantly faster.  You can verify this for yourself using the timeit module that comes with Python.Example 1: identical dictionaries mapping 20 consecutive integers to themselves:z2 wins by a factor of 3.5 or so.  Different dictionaries seem to yield quite different results, but z2 always seems to come out ahead.  (If you get inconsistent results for the same test, try passing in -r with a number larger than the default 3.)Example 2: non-overlapping dictionaries mapping 252 short strings to integers and vice versa:z2 wins by about a factor of 10.  That's a pretty big win in my book!After comparing those two, I wondered if z1's poor performance could be attributed to the overhead of constructing the two item lists, which in turn led me to wonder if this variation might work better:A few quick tests, e.g.lead me to conclude that z3 is somewhat faster than z1, but not nearly as fast as z2.  Definitely not worth all the extra typing.This discussion is still missing something important, which is a performance comparison of these alternatives with the \"obvious\" way of merging two lists: using the update method.  To try to keep things on an equal footing with the expressions, none of which modify x or y, I'm going to make a copy of x instead of modifying it in-place, as follows:A typical result:In other words, z0 and z2 seem to have essentially identical performance.  Do you think this might be a coincidence?  I don't....In fact, I'd go so far as to claim that it's impossible for pure Python code to do any better than this.  And if you can do significantly better in a C extension module, I imagine the Python folks might well be interested in incorporating your code (or a variation on your approach) into the Python core.  Python uses dict in lots of places; optimizing its operations is a big deal.You could also write this asas Tony does, but (not surprisingly) the difference in notation turns out not to have any measurable effect on performance.  Use whichever looks right to you.  Of course, he's absolutely correct to point out that the two-statement version is much easier to understand.",
                "In Python 3.0 and later, you can use collections.ChainMap which groups multiple dicts or other mappings together to create a single, updateable view:Update for Python 3.5 and later: You can use PEP 448 extended dictionary packing and unpacking.  This is fast and easy:Update for Python 3.9 and later:  You can use the PEP 584 union operator:",
                "I wanted something similar, but with the ability to specify how the values on duplicate keys were merged, so I hacked this out (but did not heavily test it).  Obviously this is not a single expression, but it is a single function call.",
                "Demonstration:Outputs:Thanks rednaw for edits.",
                "Python 3.5 (PEP 448) allows a nicer syntax option:Or evenIn Python 3.9 you also use | and |= with the below example from PEP 584",
                "For items with keys in both dictionaries ('b'), you can control which one ends up in the output by putting that one last.",
                "The best version I could think while not using copy would be:It's faster than dict(x.items() + y.items()) but not as fast as n = copy(a); n.update(b), at least on CPython. This version also works in Python 3 if you change iteritems() to items(), which is automatically done by the 2to3 tool.Personally I like this version best because it describes fairly good what I want in a single  functional syntax. The only minor problem is that it doesn't make completely obvious that values from y takes precedence over values from x, but I don't believe it's difficult to figure that out.",
                "While the question has already been answered several times,\nthis simple solution to the problem has not been listed yet.It is as fast as z0 and the evil z2 mentioned above, but easy to understand and change.",
                "Among such shady and dubious answers, this shining example is the one and only good way to merge dicts in Python, endorsed by dictator for life Guido van Rossum himself!  Someone else suggested half of this, but did not put it in a function.gives:",
                "I benchmarked the suggested with perfplot and found that the good oldis the fastest solution together with the good oldandCode to reproduce the plot:",
                "Be Pythonic. Use a comprehension:",
                "If you think lambdas are evil then read no further.\nAs requested, you can write the fast and memory-efficient solution with one expression:As suggested above, using two lines or writing a function is probably a better way to go.",
                "In python3, the items method no longer returns a list, but rather a view, which acts like a set. In this case you'll need to take the set union since concatenating with + won't work:For python3-like behavior in version 2.7, the viewitems method should work in place of items:I prefer this notation anyways since it seems more natural to think of it as a set union operation rather than concatenation (as the title shows).Edit:A couple more points for python 3. First, note that the dict(x, **y) trick won't work in python 3 unless the keys in y are strings.Also, Raymond Hettinger's Chainmap answer is pretty elegant, since it can take an arbitrary number of dicts as arguments, but from the docs it looks like it sequentially looks through a list of all the dicts for each lookup:Lookups search the underlying mappings successively until a key is found.This can slow you down if you have a lot of lookups in your application:So about an order of magnitude slower for lookups. I'm a fan of Chainmap, but looks less practical where there may be many lookups.",
                "Two dictionariesn dictionariessum has bad performance. See https://mathieularose.com/how-not-to-flatten-a-list-of-lists-in-python/",
                "Simple solution using itertools that preserves order (latter dicts have precedence)And it's usage:",
                "Abuse leading to a one-expression solution for Matthew's answer:You said you wanted one expression, so I abused lambda to bind a name, and tuples to override lambda's one-expression limit. Feel free to cringe.You could also do this of course if you don't care about copying it:",
                "If you don't mind mutating x,Simple, readable, performant. You know update() always returns None, which is a false value. So the above expression will always evaluate to x, after updating it.Most mutating methods in the standard library (like .update()) return None by convention, so this kind of pattern will work on those too. However, if you're using a dict subclass or some other method that doesn't follow this convention, then or may return its left operand, which may not be what you want. Instead, you can use a tuple display and index, which works regardless of what the first element evaluates to (although it's not quite as pretty):If you don't have x in a variable yet, you can use lambda to make a local without using an assignment statement. This amounts to using lambda as a let expression, which is a common technique in functional languages, but is maybe unpythonic.Although it's not that different from the following use of the new walrus operator (Python 3.8+ only),especially if you use a default argument:If you do want a copy, PEP 584 style x | y is the most Pythonic on 3.9+. If you must support older versions, PEP 448 style {**x, **y} is easiest for 3.5+. But if that's not available in your (even older) Python version, the let expression pattern works here too.(That is, of course, nearly equivalent to (z := x.copy()).update(y) or z, but if your Python version is new enough for that, then the PEP 448 style will be available.)",
                "Drawing on ideas here and elsewhere I've comprehended a function:Usage (tested in python 3):You could use a lambda instead.",
                "New in Python 3.9: Use the union operator (|) to merge dicts similar to sets:For matching keys, the right dict takes precedence.This also works for |= to modify a dict in-place:",
                "It's so silly that .update returns nothing.\nI just use a simple helper function to solve the problem:Examples:",
                "(For Python\u00a02.7* only; there are simpler solutions for Python\u00a03*.)If you're not averse to importing a standard library module, you can do(The or a bit in the lambda is necessary because dict.update always returns None on success.)",
                "The problem I have with solutions listed to date is that, in the merged dictionary, the value for key \"b\" is 10 but, to my way of thinking, it should be 12.\nIn that light, I present the following:",
                "There will be a new option when Python 3.8 releases (scheduled for 20 October, 2019), thanks to PEP 572: Assignment Expressions. The new assignment expression operator := allows you to assign the result of the copy and still use it to call update, leaving the combined code a single expression, rather than two statements, changing:to:while behaving identically in every way. If you must also return the resulting dict (you asked for an expression returning the dict; the above creates and assigns to newdict, but doesn't return it, so you couldn't use it to pass an argument to a function as is, a la myfunc((newdict := dict1.copy()).update(dict2))), then just add or newdict to the end (since update returns None, which is falsy, it will then evaluate and return newdict as the result of the expression):Important caveat: In general, I'd discourage this approach in favor of:The unpacking approach is clearer (to anyone who knows about generalized unpacking in the first place, which you should), doesn't require a name for the result at all (so it's much more concise when constructing a temporary that is immediately passed to a function or included in a list/tuple literal or the like), and is almost certainly faster as well, being (on CPython) roughly equivalent to:but done at the C layer, using the concrete dict API, so no dynamic method lookup/binding or function call dispatch overhead is involved (where (newdict := dict1.copy()).update(dict2) is unavoidably identical to the original two-liner in behavior, performing the work in discrete steps, with dynamic lookup/binding/invocation of methods.It's also more extensible, as merging three dicts is obvious:where using assignment expressions won't scale like that; the closest you could get would be:or without the temporary tuple of Nones, but with truthiness testing of each None result:either of which is obviously much uglier, and includes further inefficiencies (either a wasted temporary tuple of Nones for comma separation, or pointless truthiness testing of each update's None return for or separation).The only real advantage to the assignment expression approach occurs if:",
                "This should solve your problem.",
                "This can be done with a single dict comprehension:In my view the best answer for the 'single expression' part as no extra functions are needed, and it is short."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I return the response from an asynchronous call?",
                "How do I return the response/result from a function foo that makes an asynchronous request?\nI am trying to return the value from the callback, as well as assigning the result to a local variable ..."
            ],
            "url": "https://stackoverflow.com/questions/14220321",
            "answer": [
                "\u2192 For a more general explanation of asynchronous behaviour with different examples, see Why is my variable unaltered after I modify it inside of a function? - Asynchronous code reference\u2192 If you already understand the problem, skip to the possible solutions below.The A in Ajax stands for asynchronous. That means sending the request (or rather receiving the response) is taken out of the normal execution flow. In your example, $.ajax returns immediately and the next statement, return result;, is executed before the function you passed as success callback was even called.Here is an analogy which hopefully makes the difference between synchronous and asynchronous flow clearer:Imagine you make a phone call to a friend and ask him to look something up for you. Although it might take a while, you wait on the phone and stare into space, until your friend gives you the answer that you needed.The same is happening when you make a function call containing \"normal\" code:Even though findItem might take a long time to execute, any code coming after var item = findItem(); has to wait until the function returns the result.You call your friend again for the same reason. But this time you tell him that you are in a hurry and he should call you back on your mobile phone. You hang up, leave the house, and do whatever you planned to do. Once your friend calls you back, you are dealing with the information he gave to you.That's exactly what's happening when you do an Ajax request.Instead of waiting for the response, the execution continues immediately and the statement after the Ajax call is executed. To get the response eventually, you provide a function to be called once the response was received, a callback (notice something? call back ?). Any statement coming after that call is executed before the callback is called.Embrace the asynchronous nature of JavaScript! While certain asynchronous operations provide synchronous counterparts (so does \"Ajax\"), it's generally discouraged to use them, especially in a browser context.Why is it bad do you ask?JavaScript runs in the UI thread of the browser and any long-running process will lock the UI, making it unresponsive. Additionally, there is an upper limit on the execution time for JavaScript and the browser will ask the user whether to continue the execution or not.All of this results in a really bad user experience. The user won't be able to tell whether everything is working fine or not. Furthermore, the effect will be worse for users with a slow connection.In the following we will look at three different solutions that are all building on top of each other:All three are available in current browsers, and node 7+.The ECMAScript version released in 2017 introduced syntax-level support for asynchronous functions. With the help of async and await, you can write asynchronous in a \"synchronous style\". The code is still asynchronous, but it's easier to read/understand.async/await builds on top of promises: an async function always returns a promise. await \"unwraps\" a promise and either result in the value the promise was resolved with or throws an error if the promise was rejected.Important: You can only use await inside an async function or in a JavaScript module. Top-level await is not supported outside of modules, so you might have to make an async IIFE (Immediately Invoked Function Expression) to start an async context if not using a module.You can read more about async and await on MDN.Here is an example that elaborates the delay function findItem() above:Current browser and node versions support async/await. You can also support older environments by transforming your code to ES5 with the help of regenerator (or tools that use regenerator, such as Babel).A callback is when function 1 is passed to function 2. Function 2 can call function 1 whenever it is ready. In the context of an asynchronous process, the callback will be called whenever the asynchronous process is done. Usually, the result is passed to the callback.In the example of the question, you can make foo accept a callback and use it as success callback. So thisbecomesHere we defined the function \"inline\" but you can pass any function reference:foo itself is defined as follows:callback will refer to the function we pass to foo when we call it and we pass it on to success. I.e. once the Ajax request is successful, $.ajax will call callback and pass the response to the callback (which can be referred to with result, since this is how we defined the callback).You can also process the response before passing it to the callback:It's easier to write code using callbacks than it may seem. After all, JavaScript in the browser is heavily event-driven (DOM events). Receiving the Ajax response is nothing else but an event.\nDifficulties could arise when you have to work with third-party code, but most problems can be solved by just thinking through the application flow.The Promise API is a new feature of ECMAScript 6 (ES2015), but it has good browser support already. There are also many libraries which implement the standard Promises API and provide additional methods to ease the use and composition of asynchronous functions (e.g., bluebird).Promises are containers for future values. When the promise receives the value (it is resolved) or when it is canceled (rejected), it notifies all of its \"listeners\" who want to access this value.The advantage over plain callbacks is that they allow you to decouple your code and they are easier to compose.Here is an example of using a promise:function delay() {\n  // `delay` returns a promise\n  return new Promise(function(resolve, reject) {\n    // Only `delay` is able to resolve or reject the promise\n    setTimeout(function() {\n      resolve(42); // After 3 seconds, resolve the promise with value 42\n    }, 3000);\n  });\n}\n\ndelay()\n  .then(function(v) { // `delay` returns a promise\n    console.log(v); // Log the value once it is resolved\n  })\n  .catch(function(v) {\n    // Or do something else if it is rejected\n    // (it would not happen in this example, since `reject` is not called).\n  });\n.as-console-wrapper { max-height: 100% !important; top: 0; }Applied to our Ajax call we could use promises like this:function ajax(url) {\n  return new Promise(function(resolve, reject) {\n    var xhr = new XMLHttpRequest();\n    xhr.onload = function() {\n      resolve(this.responseText);\n    };\n    xhr.onerror = reject;\n    xhr.open('GET', url);\n    xhr.send();\n  });\n}\n\najax(\"https://jsonplaceholder.typicode.com/todos/1\")\n  .then(function(result) {\n    console.log(result); // Code depending on result\n  })\n  .catch(function() {\n    // An error occurred\n  });\n.as-console-wrapper { max-height: 100% !important; top: 0; }Describing all the advantages that promise offer is beyond the scope of this answer, but if you write new code, you should seriously consider them. They provide a great abstraction and separation of your code.More information about promises: HTML5 rocks - JavaScript Promises.Deferred objects are jQuery's custom implementation of promises (before the Promise API was standardized). They behave almost like promises but expose a slightly different API.Every Ajax method of jQuery already returns a \"deferred object\" (actually a promise of a deferred object) which you can just return from your function:Keep in mind that promises and deferred objects are just containers for a future value, they are not the value itself. For example, suppose you had the following:This code misunderstands the above asynchronous issues. Specifically, $.ajax() doesn't freeze the code while it checks the '/password' page on your server - it sends a request to the server and while it waits, it immediately returns a jQuery Ajax Deferred object, not the response from the server. That means the if statement is going to always get this Deferred object, treat it as true, and proceed as though the user is logged in. Not good.But the fix is easy:As I mentioned, some(!) asynchronous operations have synchronous counterparts. I don't advocate their use, but for completeness' sake, here is how you would perform a synchronous call:If you directly use a XMLHttpRequest object, pass false as third argument to .open.If you use jQuery, you can set the async option to false. Note that this option is deprecated since jQuery 1.8.\nYou can then either still use a success callback or access the responseText property of the jqXHR object:If you use any other jQuery Ajax method, such as $.get, $.getJSON, etc., you have to change it to $.ajax (since you can only pass configuration parameters to $.ajax).Heads up! It is not possible to make a synchronous JSONP request. JSONP by its very nature is always asynchronous (one more reason to not even consider this option).",
                "Your code should be something along the lines of this:Felix Kling did a fine job writing an answer for people using jQuery for AJAX, but I've decided to provide an alternative for people who aren't.(Note, for those using the new fetch API, Angular or promises I've added another answer below)This is a short summary of \"Explanation of the problem\" from the other answer, if you're not sure after reading this, read that.The A in AJAX stands for asynchronous. That means sending the request (or rather receiving the response) is taken out of the normal execution flow. In your example, .send returns immediately and the next statement, return result;, is executed before the function you passed as success callback was even called.This means when you're returning, the listener you've defined did not execute yet, which means the value you're returning has not been defined.Here is a simple analogy:(Fiddle)The value of a returned is undefined since the a=5 part has not executed yet. AJAX acts like this, you're returning the value before the server got the chance to tell your browser what that value is.One possible solution to this problem is to code re-actively , telling your program what to do when the calculation completed.This is called CPS. Basically, we're passing getFive an action to perform when it completes, we're telling our code how to react when an event completes (like our AJAX call, or in this case the timeout).Usage would be:Which should alert \"5\" to the screen. (Fiddle).There are basically two ways how to solve this:As for synchronous AJAX, don't do it! Felix's answer raises some compelling arguments about why it's a bad idea. To sum it up, it'll freeze the user's browser until the server returns the response and create a very bad user experience. Here is another short summary taken from MDN on why:XMLHttpRequest supports both synchronous and asynchronous communications. In general, however, asynchronous requests should be preferred to synchronous requests for performance reasons.In short, synchronous requests block the execution of code... ...this can cause serious issues...If you have to do it, you can pass a flag. Here is how:Let your function accept a callback. In the example code foo can be made to accept a callback. We'll be telling our code how to react when foo completes.So:Becomes:Here we passed an anonymous function, but we could just as easily pass a reference to an existing function, making it look like:For more details on how this sort of callback design is done, check Felix's answer.Now, let's define foo itself to act accordingly(fiddle)We have now made our foo function accept an action to run when the AJAX completes successfully. We can extend this further by checking if the response status is not 200 and acting accordingly (create a fail handler and such). Effectively it is solving our issue.If you're still having a hard time understanding this, read the AJAX getting started guide at MDN.",
                "XMLHttpRequest 2 (first of all, read the answers from Benjamin Gruenbaum and Felix Kling)If you don't use jQuery and want a nice short XMLHttpRequest 2 which works in the modern browsers and also in the mobile browsers, I suggest to use it this way:As you can see:There are two ways to get the response of this Ajax call (three using the XMLHttpRequest var name):The simplest:Or if for some reason you bind() the callback to a class:Example:Or (the above one is better anonymous functions are always a problem):Nothing easier.Now some people will probably say that it's better to use onreadystatechange or the even the XMLHttpRequest variable name. That's wrong.Check out XMLHttpRequest advanced features.It supported all *modern browsers. And I can confirm as I have been using this approach since XMLHttpRequest 2 was created. I never had any type of problem in any browsers I used.onreadystatechange is only useful if you want to get the headers on state 2.Using the XMLHttpRequest variable name is another big error as you need to execute the callback inside the onload/oreadystatechange closures, or else you lost it.Now if you want something more complex using POST and FormData you can easily extend this function:Again ... it's a very short function, but it does GET and POST.Examples of usage:Or pass a full form element (document.getElementsByTagName('form')[0]):Or set some custom values:As you can see, I didn't implement sync... it's a bad thing.Having said that ... why don't we do it the easy way?As mentioned in the comment, the use of error && synchronous does completely break the point of the answer. Which is a nice short way to use Ajax in the proper way?Error handlerIn the above script, you have an error handler which is statically defined, so it does not compromise the function. The error handler can be used for other functions too.But to really get out an error, the only way is to write a wrong URL in which case every browser throws an error.Error handlers are maybe useful if you set custom headers, set the responseType to blob array buffer, or whatever...Even if you pass 'POSTAPAPAP' as the method it won't throw an error.Even if you pass 'fdggdgilfdghfldj' as formdata it won't throw an error.In the first case the error is inside the displayAjax() under this.statusText as Method not Allowed.In the second case, it simply works. You have to check at the server side if you passed the right post data.Cross-domain not allowed throws an error automatically.In the error response, there aren't any error codes.There is only the this.type which is set to error.Why add an error handler if you totally don't have any control over errors?\nMost of the errors are returned inside this in the callback function displayAjax().So: There isn't any need for error checks if you're able to copy and paste the URL properly. ;)PS: As the first test I wrote x('x', displayAjax)..., and it totally got a response...??? So I checked the folder where the HTML is located, and there was a file called 'x.xml'. So even if you forget the extension of your file XMLHttpRequest 2 WILL FIND IT. I LOL'dRead a file synchronousDon't do that.If you want to block the browser for a while load a nice big .txt file synchronous.Now you can doThere is no other way to do this in a non-asynchronous way. (Yeah, with setTimeout loop... but seriously?)Another point is... if you work with APIs or just your own list's files or whatever you always use different functions for each request...Only if you have a page where you load always the same XML/JSON or whatever you need only one function. In that case, modify a little the Ajax function and replace b with your special function.The functions above are for basic use.If you want to extend the function...Yes, you can.I'm using a lot of APIs and one of the first functions I integrate into every HTML page is the first Ajax function in this answer, with GET only...But you can do a lot of stuff with XMLHttpRequest 2:I made a download manager (using ranges on both sides with resume, filereader, and filesystem), various image resizers converters using canvas, populate web SQL databases with base64images and much more...But in these cases you should create a function only for that purpose... sometimes you need a blob, array buffers, you can set headers, override mimetype and there is a lot more...But the question here is how to return an Ajax response... (I added an easy way.)",
                "This means AngularJS, jQuery (with deferred), native XHR's replacement (fetch), Ember.js, Backbone.js's save or any Node.js library that returns promises.Your code should be something along the lines of this:Felix Kling did a fine job writing an answer for people using jQuery with callbacks for Ajax. I have an answer for native XHR. This answer is for generic usage of promises either on the frontend or backend.The JavaScript concurrency model in the browser and on the server with Node.js/io.js is asynchronous and reactive.Whenever you call a method that returns a promise, the then handlers are always executed asynchronously - that is, after the code below them that is not in a .then handler.This means when you're returning data the then handler you've defined did not execute yet. This in turn means that the value you're returning has not been set to the correct value in time.Here is a simple analogy for the issue:function getFive(){\n        var data;\n        setTimeout(function(){ // Set a timer for one second in the future\n           data = 5; // After a second, do this\n        }, 1000);\n        return data;\n    }\n    document.body.innerHTML = getFive(); // `undefined` here and not 5The value of data is undefined since the data = 5 part has not executed yet. It will likely execute in a second, but by that time it is irrelevant to the returned value.Since the operation did not happen yet (Ajax, server call, I/O, and timer) you're returning the value before the request got the chance to tell your code what that value is.One possible solution to this problem is to code re-actively, telling your program what to do when the calculation completed. Promises actively enable this by being temporal (time-sensitive) in nature.A Promise is a value over time. Promises have state. They start as pending with no value and can settle to:A promise can only change states once after which it will always stay at the same state forever. You can attach then handlers to promises to extract their value and handle errors. then handlers allow chaining of calls. Promises are created by using APIs that return them. For example, the more modern Ajax replacement fetch or jQuery's $.get return promises.When we call .then on a promise and return something from it - we get a promise for the processed value. If we return another promise we'll get amazing things, but let's hold our horses.Let's see how we can solve the above issue with promises. First, let's demonstrate our understanding of promise states from above by using the Promise constructor for creating a delay function:Now, after we converted setTimeout to use promises, we can use then to make it count:function delay(ms){ // Takes amount of milliseconds\n  // Returns a new promise\n  return new Promise(function(resolve, reject){\n    setTimeout(function(){ // When the time is up,\n      resolve(); // change the promise to the fulfilled state\n    }, ms);\n  });\n}\n\nfunction getFive(){\n  // We're RETURNING the promise. Remember, a promise is a wrapper over our value\n  return delay(100).then(function(){ // When the promise is ready,\n      return 5; // return the value 5. Promises are all about return values\n  })\n}\n// We _have_ to wrap it like this in the call site, and we can't access the plain value\ngetFive().then(function(five){\n   document.body.innerHTML = five;\n});Basically, instead of returning a value which we can't do because of the concurrency model - we're returning a wrapper for a value that we can unwrap with then. It's like a box you can open with then.This stands the same for your original API call, you can:So this works just as well. We've learned we can't return values from already asynchronous calls, but we can use promises and chain them to perform processing. We now know how to return the response from an asynchronous call.ES6 introduces generators which are functions that can return in the middle and then resume the point they were at. This is typically useful for sequences, for example:Is a function that returns an iterator over the sequence 1,2,3,3,3,3,.... which can be iterated. While this is interesting on its own and opens room for a lot of possibility, there is one particular interesting case.If the sequence we're producing is a sequence of actions rather than numbers - we can pause the function whenever an action is yielded and wait for it before we resume the function. So instead of a sequence of numbers, we need a sequence of future values - that is: promises.This somewhat a tricky, but very powerful trick let\u2019s us write asynchronous code in a synchronous manner. There are several \"runners\" that do this for you. Writing one is a short few lines of code, but it is beyond the scope of this answer. I'll be using Bluebird's Promise.coroutine here, but there are other wrappers like co or Q.async.This method returns a promise itself, which we can consume from other coroutines. For example:In ES7, this is further standardized. There are several proposals right now, but in all of them you can await promise. This is just \"sugar\" (nicer syntax) for the ES6 proposal above by adding the async and await keywords. Making the above example:It still returns a promise just the same :)",
                "You are using Ajax incorrectly. The idea is not to have it return anything, but instead hand off the data to something called a callback function, which handles the data.That is:Returning anything in the submit handler will not do anything. You must instead either hand off the data, or do what you want with it directly inside the success function.",
                "I will answer with a horrible-looking, hand-drawn comic. The second image is the reason why result is undefined in your code example.",
                "The simplest solution is to create a JavaScript function and call it for the Ajax success callback.",
                "People who are using AngularJS, can handle this situation using promises.Here it says,Promises can be used to unnest asynchronous functions and allows one to chain multiple functions together.You can find a nice explanation here also.An example found in documentation mentioned below.In Angular 2 with look at the following example, but its recommended to use observables with Angular 2.You can consume that in this way,See the original post here. But TypeScript does not support native ES6 Promises, if you want to use it, you might need plugin for that.Additionally, here is the promises specification.",
                "Most of the answers here give useful suggestions for when you have a single async operation, but sometimes, this comes up when you need to do an asynchronous operation for each entry in an array or other list-like structure. The temptation is to do this:Example:// WRONG\nvar theArray = [1, 2, 3];\nvar results = [];\ntheArray.forEach(function(entry) {\n    doSomethingAsync(entry, function(result) {\n        results.push(result);\n    });\n});\nconsole.log(\"Results:\", results); // E.g., using them, returning them, etc.\n\nfunction doSomethingAsync(value, callback) {\n    console.log(\"Starting async operation for \" + value);\n    setTimeout(function() {\n        console.log(\"Completing async operation for \" + value);\n        callback(value * 2);\n    }, Math.floor(Math.random() * 200));\n}\n.as-console-wrapper { max-height: 100% !important; }The reason that doesn't work is that the callbacks from doSomethingAsync haven't run yet by the time you're trying to use the results.So, if you have an array (or list of some kind) and want to do async operations for each entry, you have two options: Do the operations in parallel (overlapping), or in series (one after another in sequence).You can start all of them and keep track of how many callbacks you're expecting, and then use the results when you've gotten that many callbacks:Example:var theArray = [1, 2, 3];\nvar results = [];\nvar expecting = theArray.length;\ntheArray.forEach(function(entry, index) {\n    doSomethingAsync(entry, function(result) {\n        results[index] = result;\n        if (--expecting === 0) {\n            // Done!\n            console.log(\"Results:\", JSON.stringify(results)); // E.g., using the results\n        }\n    });\n});\n\nfunction doSomethingAsync(value, callback) {\n    console.log(\"Starting async operation for \" + value);\n    setTimeout(function() {\n        console.log(\"Completing async operation for \" + value);\n        callback(value * 2);\n    }, Math.floor(Math.random() * 200));\n}\n.as-console-wrapper { max-height: 100% !important; }(We could do away with expecting and just use results.length === theArray.length, but that leaves us open to the possibility that theArray is changed while the calls are outstanding...)Notice how we use the index from forEach to save the result in results in the same position as the entry it relates to, even if the results arrive out of order (since async calls don't necessarily complete in the order in which they were started).But what if you need to return those results from a function? As the other answers have pointed out, you can't; you have to have your function accept and call a callback (or return a Promise). Here's a callback version:Example:function doSomethingWith(theArray, callback) {\n    var results = [];\n    var expecting = theArray.length;\n    theArray.forEach(function(entry, index) {\n        doSomethingAsync(entry, function(result) {\n            results[index] = result;\n            if (--expecting === 0) {\n                // Done!\n                callback(results);\n            }\n        });\n    });\n}\ndoSomethingWith([1, 2, 3], function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value, callback) {\n    console.log(\"Starting async operation for \" + value);\n    setTimeout(function() {\n        console.log(\"Completing async operation for \" + value);\n        callback(value * 2);\n    }, Math.floor(Math.random() * 200));\n}\n.as-console-wrapper { max-height: 100% !important; }Or here's a version returning a Promise instead:Of course, if doSomethingAsync passed us errors, we'd use reject to reject the promise when we got an error.)Example:function doSomethingWith(theArray) {\n    return new Promise(function(resolve) {\n        var results = [];\n        var expecting = theArray.length;\n        theArray.forEach(function(entry, index) {\n            doSomethingAsync(entry, function(result) {\n                results[index] = result;\n                if (--expecting === 0) {\n                    // Done!\n                    resolve(results);\n                }\n            });\n        });\n    });\n}\ndoSomethingWith([1, 2, 3]).then(function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value, callback) {\n    console.log(\"Starting async operation for \" + value);\n    setTimeout(function() {\n        console.log(\"Completing async operation for \" + value);\n        callback(value * 2);\n    }, Math.floor(Math.random() * 200));\n}\n.as-console-wrapper { max-height: 100% !important; }(Or alternately, you could make a wrapper for doSomethingAsync that returns a promise, and then do the below...)If doSomethingAsync gives you a Promise, you can use Promise.all:If you know that doSomethingAsync will ignore a second and third argument, you can just pass it directly to map (map calls its callback with three arguments, but most people only use the first most of the time):Example:function doSomethingWith(theArray) {\n    return Promise.all(theArray.map(doSomethingAsync));\n}\ndoSomethingWith([1, 2, 3]).then(function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value) {\n    console.log(\"Starting async operation for \" + value);\n    return new Promise(function(resolve) {\n        setTimeout(function() {\n            console.log(\"Completing async operation for \" + value);\n            resolve(value * 2);\n        }, Math.floor(Math.random() * 200));\n    });\n}\n.as-console-wrapper { max-height: 100% !important; }Note that Promise.all resolves its promise with an array of the results of all of the promises you give it when they are all resolved, or rejects its promise when the first of the promises you give it rejects.Suppose you don't want the operations to be in parallel? If you want to run them one after another, you need to wait for each operation to complete before you start the next. Here's an example of a function that does that and calls a callback with the result:(Since we're doing the work in series, we can just use results.push(result) since we know we won't get results out of order. In the above we could have used results[index] = result;, but in some of the following examples we don't have an index to use.)Example:function doSomethingWith(theArray, callback) {\n    var results = [];\n    doOne(0);\n    function doOne(index) {\n        if (index < theArray.length) {\n            doSomethingAsync(theArray[index], function(result) {\n                results.push(result);\n                doOne(index + 1);\n            });\n        } else {\n            // Done!\n            callback(results);\n        }\n    }\n}\ndoSomethingWith([1, 2, 3], function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value, callback) {\n    console.log(\"Starting async operation for \" + value);\n    setTimeout(function() {\n        console.log(\"Completing async operation for \" + value);\n        callback(value * 2);\n    }, Math.floor(Math.random() * 200));\n}\n.as-console-wrapper { max-height: 100% !important; }(Or, again, build a wrapper for doSomethingAsync that gives you a promise and do the below...)If doSomethingAsync gives you a Promise, if you can use ES2017+ syntax (perhaps with a transpiler like Babel), you can use an async function with for-of and await:Example:async function doSomethingWith(theArray) {\n    const results = [];\n    for (const entry of theArray) {\n        results.push(await doSomethingAsync(entry));\n    }\n    return results;\n}\ndoSomethingWith([1, 2, 3]).then(function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value) {\n    console.log(\"Starting async operation for \" + value);\n    return new Promise(function(resolve) {\n        setTimeout(function() {\n            console.log(\"Completing async operation for \" + value);\n            resolve(value * 2);\n        }, Math.floor(Math.random() * 200));\n    });\n}\n.as-console-wrapper { max-height: 100% !important; }If you can't use ES2017+ syntax (yet), you can use a variation on the \"Promise reduce\" pattern (this is more complex than the usual Promise reduce because we're not passing the result from one into the next, but instead gathering up their results in an array):Example:function doSomethingWith(theArray) {\n    return theArray.reduce(function(p, entry) {\n        return p.then(function(results) {\n            return doSomethingAsync(entry).then(function(result) {\n                results.push(result);\n                return results;\n            });\n        });\n    }, Promise.resolve([]));\n}\ndoSomethingWith([1, 2, 3]).then(function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value) {\n    console.log(\"Starting async operation for \" + value);\n    return new Promise(function(resolve) {\n        setTimeout(function() {\n            console.log(\"Completing async operation for \" + value);\n            resolve(value * 2);\n        }, Math.floor(Math.random() * 200));\n    });\n}\n.as-console-wrapper { max-height: 100% !important; }...which is less cumbersome with ES2015+ arrow functions:Example:function doSomethingWith(theArray) {\n    return theArray.reduce((p, entry) => p.then(results => doSomethingAsync(entry).then(result => {\n        results.push(result);\n        return results;\n    })), Promise.resolve([]));\n}\ndoSomethingWith([1, 2, 3]).then(function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value) {\n    console.log(\"Starting async operation for \" + value);\n    return new Promise(function(resolve) {\n        setTimeout(function() {\n            console.log(\"Completing async operation for \" + value);\n            resolve(value * 2);\n        }, Math.floor(Math.random() * 200));\n    });\n}\n.as-console-wrapper { max-height: 100% !important; }",
                "Have a look at this example:As you can see getJoke is returning a resolved promise (it is resolved when returning res.data.value). So you wait until the $http.get request is completed and then console.log(res.joke) is executed (as a normal asynchronous flow).This is the plnkr:http://embed.plnkr.co/XlNR7HpCaIhJxskMJfSg/ES6 way (async - await)",
                "This is one of the places which two-way data binding or store concept that's used in many new JavaScript frameworks will work great for you...So if you are using Angular, React, or any other frameworks which do two-way data binding or store concept, this issue is simply fixed for you, so in easy words, your result is undefined at the first stage, so you have got result = undefined before you receive the data, then as soon as you get the result, it will be updated and get assigned to the new value which response of your Ajax call...But how you can do it in pure JavaScript or jQuery for example as you asked in this question?You can use a callback, promise and recently observable to handle it for you. For example, in promises we have some function like success() or then() which will be executed when your data is ready for you. The same with callback or the subscribe function on an observable.For example, in your case which you are using jQuery, you can do something like this:For more information, study promises and observables which are newer ways to do this async stuff.",
                "It's a very common issue we face while struggling with the 'mysteries' of JavaScript. Let me try demystifying this mystery today.Let's start with a simple JavaScript function:That's a simple synchronous function call (where each line of code is 'finished with its job' before the next one in sequence), and the result is same as expected.Now let's add a bit of twist, by introducing a little delay in our function, so that all lines of code are not 'finished' in sequence. Thus, it will emulate the asynchronous behavior of the function:So there you go; that delay just broke the functionality we expected! But what exactly happened? Well, it's actually pretty logical if you look at the code.The function foo(), upon execution, returns nothing (thus returned value is undefined), but it does start a timer, which executes a function after 1 second to return 'wohoo'. But as you can see, the value that's assigned to bar is the immediately returned stuff from foo(), which is nothing, i.e., just undefined.So, how do we tackle this issue?Let's ask our function for a promise.\nPromise is really about what it means: it means that the function guarantees you to provide with any output it gets in future. So let's see it in action for our little problem above:Thus, the summary is - to tackle the asynchronous functions like Ajax-based calls, etc., you can use a promise to resolve the value (which you intend to return). Thus, in short you resolve value instead of returning, in asynchronous functions.Apart from using then/catch to work with promises, there exists one more approach. The idea is to recognize an asynchronous function and then wait for the promises to resolve, before moving to the next line of code. It's still just the promises under the hood, but with a different syntactical approach. To make things clearer, you can find a comparison below:",
                "Another approach to return a value from an asynchronous function, is to pass in an object that will store the result from the asynchronous function.Here is an example of the same:I am using the result object to store the value during the asynchronous operation. This allows the result be available even after the asynchronous job.I use this approach a lot. I would be interested to know how well this approach works where wiring the result back through consecutive modules is involved.",
                "While promises and callbacks work fine in many situations, it is a pain in the rear to express something like:You'd end up going through async1; check if name is undefined or not and call the callback accordingly.While it is okay in small examples it gets annoying when you have a lot of similar cases and error handling involved.Fibers helps in solving the issue.You can checkout the project here.",
                "The following example I have written shows how toThis working example is self-contained. It will define a simple request object that uses the window XMLHttpRequest object to make calls. It will define a simple function to wait for a bunch of promises to be completed.Context. The example is querying the Spotify Web API endpoint in order to search for playlist objects for a given set of query strings:For each item, a new Promise will fire a block - ExecutionBlock, parse the result, schedule a new set of promises based on the result array, that is a list of Spotify user objects and execute the new HTTP call within the ExecutionProfileBlock asynchronously.You can then see a nested Promise structure, that lets you spawn multiple and completely asynchronous nested HTTP calls, and join the results from each subset of calls through Promise.all.NOTE\nRecent Spotify search APIs will require an access token to be specified in the request headers:So, you to run the following example you need to put your access token in the request headers:var spotifyAccessToken = \"YourSpotifyAccessToken\";\r\nvar console = {\r\n    log: function(s) {\r\n        document.getElementById(\"console\").innerHTML += s + \"<br/>\"\r\n    }\r\n}\r\n\r\n// Simple XMLHttpRequest\r\n// based on https://davidwalsh.name/xmlhttprequest\r\nSimpleRequest = {\r\n    call: function(what, response) {\r\n        var request;\r\n        if (window.XMLHttpRequest) { // Mozilla, Safari, ...\r\n            request = new XMLHttpRequest();\r\n        } else if (window.ActiveXObject) { // Internet Explorer\r\n            try {\r\n                request = new ActiveXObject('Msxml2.XMLHTTP');\r\n            }\r\n            catch (e) {\r\n                try {\r\n                  request = new ActiveXObject('Microsoft.XMLHTTP');\r\n                } catch (e) {}\r\n            }\r\n        }\r\n\r\n        // State changes\r\n        request.onreadystatechange = function() {\r\n            if (request.readyState === 4) { // Done\r\n                if (request.status === 200) { // Complete\r\n                    response(request.responseText)\r\n                }\r\n                else\r\n                    response();\r\n            }\r\n        }\r\n        request.open('GET', what, true);\r\n        request.setRequestHeader(\"Authorization\", \"Bearer \" + spotifyAccessToken);\r\n        request.send(null);\r\n    }\r\n}\r\n\r\n//PromiseAll\r\nvar promiseAll = function(items, block, done, fail) {\r\n    var self = this;\r\n    var promises = [],\r\n                   index = 0;\r\n    items.forEach(function(item) {\r\n        promises.push(function(item, i) {\r\n            return new Promise(function(resolve, reject) {\r\n                if (block) {\r\n                    block.apply(this, [item, index, resolve, reject]);\r\n                }\r\n            });\r\n        }(item, ++index))\r\n    });\r\n    Promise.all(promises).then(function AcceptHandler(results) {\r\n        if (done) done(results);\r\n    }, function ErrorHandler(error) {\r\n        if (fail) fail(error);\r\n    });\r\n}; //promiseAll\r\n\r\n// LP: deferred execution block\r\nvar ExecutionBlock = function(item, index, resolve, reject) {\r\n    var url = \"https://api.spotify.com/v1/\"\r\n    url += item;\r\n    console.log( url )\r\n    SimpleRequest.call(url, function(result) {\r\n        if (result) {\r\n\r\n            var profileUrls = JSON.parse(result).playlists.items.map(function(item, index) {\r\n                return item.owner.href;\r\n            })\r\n            resolve(profileUrls);\r\n        }\r\n        else {\r\n            reject(new Error(\"call error\"));\r\n        }\r\n    })\r\n}\r\n\r\narr = [\r\n    \"search?type=playlist&q=%22doom%20metal%22\",\r\n    \"search?type=playlist&q=Adele\"\r\n]\r\n\r\npromiseAll(arr, function(item, index, resolve, reject) {\r\n    console.log(\"Making request [\" + index + \"]\")\r\n    ExecutionBlock(item, index, resolve, reject);\r\n}, function(results) { // Aggregated results\r\n\r\n    console.log(\"All profiles received \" + results.length);\r\n    //console.log(JSON.stringify(results[0], null, 2));\r\n\r\n    ///// promiseall again\r\n\r\n    var ExecutionProfileBlock = function(item, index, resolve, reject) {\r\n        SimpleRequest.call(item, function(result) {\r\n            if (result) {\r\n                var obj = JSON.parse(result);\r\n                resolve({\r\n                    name: obj.display_name,\r\n                    followers: obj.followers.total,\r\n                    url: obj.href\r\n                });\r\n            } //result\r\n        })\r\n    } //ExecutionProfileBlock\r\n\r\n    promiseAll(results[0], function(item, index, resolve, reject) {\r\n        //console.log(\"Making request [\" + index + \"] \" + item)\r\n        ExecutionProfileBlock(item, index, resolve, reject);\r\n    }, function(results) { // aggregated results\r\n        console.log(\"All response received \" + results.length);\r\n        console.log(JSON.stringify(results, null, 2));\r\n    }\r\n\r\n    , function(error) { // Error\r\n        console.log(error);\r\n    })\r\n\r\n    /////\r\n\r\n  },\r\n  function(error) { // Error\r\n      console.log(error);\r\n  });\n<div id=\"console\" />I have extensively discussed this solution here.",
                "The short answer is, you have to implement a callback like this:",
                "JavaScript is single threaded.The browser can be divided into three parts:Event LoopWeb APIEvent QueueThe event loop runs for forever, i.e., kind of an infinite loop. The event queue is where all your functions are pushed on some event (example: click).This is one by one carried out of queue and put into the event loop which executes this function and prepares itself for the next one after the first one is executed. This means execution of one function doesn't start until the function before it in the queue is executed in the event loop.Now let us think we pushed two functions in a queue. One is for getting a data from the server and another utilises that data. We pushed the serverRequest() function in the queue first and then the utiliseData() function. The serverRequest function goes in the event loop and makes a call to server as we never know how much time it will take to get data from server, so this process is expected to take time and so we busy our event loop thus hanging our page.That's where Web API come into the role. It takes this function from the event loop and deals with the server making the event loop free, so that we can execute the next function from the queue.The next function in the queue is utiliseData() which goes in the loop, but because of no data available, it goes to waste and execution of the next function continues until the end of the queue. (This is called Async calling, i.e., we can do something else until we get data.)Let us suppose our serverRequest() function had a return statement in code. When we get back data from the server Web API, it will push it in the queue at the end of queue.As it gets pushed at the end of the queue, we cannot utilise its data as there isn't any function left in our queue to utilise this data. Thus it is not possible to return something from the async call.Thus the solution to this is callback or promise.We give our function (function utilising data returned from the server) to a function calling the server.In my code it is called as:JavaScript.info callback",
                "This is quite simple:Here's a working version of your code:await is supported in all current browsers and Node.js 8",
                "You can use this custom library (written using Promise) to make a remote call.Simple usage example:",
                "Another solution is to execute code via the sequential executor nsynjs.nsynjs will evaluate all promises sequentially, and put the promise result into the data property:function synchronousCode() {\n\n    var getURL = function(url) {\n        return window.fetch(url).data.text().data;\n    };\n    \n    var url = 'https://ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min.js';\n    console.log('received bytes:',getURL(url).length);\n    \n};\n\nnsynjs.run(synchronousCode,{},function(){\n    console.log('synchronousCode done');\n});\n<script src=\"https://rawgit.com/amaksr/nsynjs/master/nsynjs.js\"></script>Step 1. Wrap the function with a callback into the nsynjs-aware wrapper (if it has a promisified version, you can skip this step):Step 2. Put synchronous logic into function:Step 3. Run function in synchronous manner via nsynjs:Nsynjs will evaluate all operators and expressions step-by-step, pausing execution in case if the result of some slow function is not ready.More examples are here.",
                "ECMAScript 6 has 'generators' which allow you to easily program in an asynchronous style.To run the above code you do this:If you need to target browsers that don't support ES6 you can run the code through Babel or closure-compiler to generate ECMAScript 5.The callback ...args are wrapped in an array and destructured when you read them so that the pattern can cope with callbacks that have multiple arguments. For example with node fs:",
                "We find ourselves in a universe which appears to progress along a dimension we call \"time\". We don't really understand what time is, but we have developed abstractions and vocabulary that let us reason and talk about it: \"past\", \"present\", \"future\", \"before\", \"after\".The computer systems we build--more and more--have time as an important dimension. Certain things are set up to happen in the future. Then other things need to happen after those first things eventually occur. This is the basic notion called \"asynchronicity\". In our increasingly networked world, the most common case of asynchronicity is waiting for some remote system to respond to some request.Consider an example. You call the milkman and order some milk. When it comes, you want to put it in your coffee. You can't put the milk in your coffee right now, because it is not here yet. You have to wait for it to come before putting it in your coffee. In other words, the following won't work:Because JavaScript has no way to know that it needs to wait for order_milk to finish before it executes put_in_coffee. In other words, it does not know that order_milk is asynchronous--is something that is not going to result in milk until some future time. JavaScript, and other declarative languages execute one statement after another without waiting.The classic JavaScript approach to this problem, taking advantage of the fact that JavaScript supports functions as first-class objects which can be passed around, is to pass a function as a parameter to the asynchronous request, which it will then invoke when it has completed its task sometime in the future. That is the \"callback\" approach. It looks like this:order_milk kicks off, orders the milk, then, when and only when it arrives, it invokes put_in_coffee.The problem with this callback approach is that it pollutes the normal semantics of a function reporting its result with return; instead, functions must not reports their results by calling a callback given as a parameter. Also, this approach can rapidly become unwieldy when dealing with longer sequences of events. For example, let's say that I want to wait for the milk to be put in the coffee, and then and only then perform a third step, namely drinking the coffee. I end up needing to write something like this:where I am passing to put_in_coffee both the milk to put in it, and also the action (drink_coffee) to execute once the milk has been put in. Such code becomes hard to write, and read, and debug.In this case, we could rewrite the code in the question as:This was the motivation for the notion of a \"promise\", which is a particular type of value which represents a future or asynchronous outcome of some sort. It can represent something that already happened, or that is going to happen in the future, or might never happen at all. Promises have a single method, named then, to which you pass an action to be executed when the outcome the promise represents has been realized.In the case of our milk and coffee, we design order_milk to return a promise for the milk arriving, then specify put_in_coffee as a then action, as follows:One advantage of this is that we can string these together to create sequences of future occurrences (\"chaining\"):Let's apply promises to your particular problem. We will wrap our request logic inside a function, which returns a promise:Actually, all we've done is added a return to the call to $.ajax. This works because jQuery's $.ajax already returns a kind of promise-like thing. (In practice, without getting into details, we would prefer to wrap this call so as for return a real promise, or use some alternative to $.ajax that does so.) Now, if we want to load the file and wait for it to finish and then do something, we can simply sayfor instance,When using promises, we end up passing lots of functions into then, so it's often helpful to use the more compact ES6-style arrow functions:But there's still something vaguely dissatisfying about having to write code one way if synchronous and a quite different way if asynchronous. For synchronous, we writebut if a is asynchronous, with promises we have to writeAbove, we said, \"JavaScript has no way to know that it needs to wait for the first call to finish before it executes the second\". Wouldn't it be nice if there was some way to tell JavaScript that? It turns out that there is--the await keyword, used inside a special type of function called an \"async\" function. This feature is part of the upcoming version of ECMAScript (ES), but it is already available in transpilers such as Babel given the right presets. This allows us to simply writeIn your case, you would be able to write something like",
                "Short answer: Your foo() method returns immediately, while the $ajax() call executes asynchronously after the function returns. The problem is then how or where to store the results retrieved by the async call once it returns.Several solutions have been given in this thread. Perhaps the easiest way is to pass an object to the foo() method, and to store the results in a member of that object after the async call completes.Note that the call to foo() will still return nothing useful. However, the result of the async call will now be stored in result.response.",
                "var App = App || {};\n\nApp = {\n    getDataFromServer: function(){\n\n      var self = this,\n                 deferred = $.Deferred(),\n                 requests = [];\n\n      requests.push($.getJSON('request/ajax/url/1'));\n      requests.push($.getJSON('request/ajax/url/2'));\n\n      $.when.apply(jQuery, requests).done(function(xhrResponse) {\n        return deferred.resolve(xhrResponse.result);\n      });\n      return deferred;\n    },\n\n    init: function(){\n\n        this.getDataFromServer().done(_.bind(function(resp1, resp2) {\n\n           // Do the operations which you wanted to do when you\n           // get a response from Ajax, for example, log response.\n        }, this));\n    }\n};\nApp.init();",
                "As for many others, my encounter with asynchronous calls was puzzling at\nfirst.\nI don't remember the details, but I may have tried something like:let result;\n\n$.ajax({\n  url: 'https://jsonplaceholder.typicode.com/todos/1',\n  success: function (response) {\n    console.log('\\nInside $.ajax:');\n    console.log(response);\n    result = response;\n  }\n});\n\nconsole.log('Finally, the result: ' + result);\n.as-console-wrapper { max-height: 100% !important; top: 0; }\n<script src=\n\"https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js\"></script>Whoops! The output of the line\nconsole.log('Finally, the result: ' + result);\nwhich I thought would be printed last, is actually printed before the\nother output! \u2013 And it doesn't contain the result: it just prints undefined.\n1\nHow come?A helpful insightI distinctly remember my first aha! moment on how to understand asynchronous\ncalls.\nIt was this comment saying:\nyou actually don't want to get the data out of a callback;\nyou want to get your data-needing action into the callback!\n2\nThis is obvious in the example above.\nBut is it still possible to write code after the asynchronous call that\ndeals with the response once it has completed?The answer is yes! \u2013 It is possible.\nOne alternative is the use of a callback function in a continuation-passing\nstyle:\n3const url = 'https://jsonplaceholder.typicode.com/todos/2';\n\nfunction asynchronousCall (callback) {\n  const request = new XMLHttpRequest();\n  request.open('GET', url);\n  request.send();\n  request.onload = function () {\n    if (request.readyState === request.DONE) {\n      console.log('The request is done. Now calling back.');\n      callback(request.responseText);\n    }\n  };\n}\n\nasynchronousCall(function (result) {\n  console.log('This is the start of the callback function. Result:');\n  console.log(result);\n  console.log('The callback function finishes on this line. THE END!');\n});\n\nconsole.log('LAST in the code, but executed FIRST!');\n.as-console-wrapper { max-height: 100% !important; top: 0; }Note how the function asynchronousCall is void. It returns nothing.\nInstead, by calling asynchronousCall with an anonymous callback function\n(asynchronousCall(function (result) {...), this function executes the\ndesired actions on the result, but only after the request has completed \u2013\nwhen the responseText is available.Running the above snippet shows how I will probably not want to write any code\nafter the asyncronous call (such as the line\nLAST in the code, but executed FIRST!).\nWhy? \u2013 Because such code will\nhappen before the asyncronous call delivers any response data.\nDoing so is bound to cause confusion when comparing the code with the output.The .then() construct was introduced in the ECMA-262 6th Edition in June\n2015, and the async/await construct was introduced in the ECMA-262\n8th Edition in June 2017.\nThe code below is still plain JavaScript, replacing the old-school\nXMLHttpRequest with Fetch.\n4fetch('http://api.icndb.com/jokes/random')\n  .then(response => response.json())\n  .then(responseBody => {\n    console.log('.then() - the response body:');\n    console.log(JSON.stringify(responseBody) + '\\n\\n');\n  });\n\nasync function receiveAndAwaitPromise () {\n  const responseBody =\n    (await fetch('http://api.icndb.com/jokes/random')).json();\n  console.log('async/await:');\n  console.log(JSON.stringify(await responseBody) + '\\n\\n');\n}\n\nreceiveAndAwaitPromise();\n.as-console-wrapper { max-height: 100% !important; top: 0; }A word of warning is warranted if you decide to go with the async/await\nconstruct. Note in the above snippet how await is needed in two places.\nIf forgotten in the first place, there will be no output. If forgotten in the\nsecond place, the only output will be the empty object, {}\n(or [object Object] or [object Promise]).\nForgetting the async prefix of the function is maybe the worst of all \u2013 the\noutput will be \"SyntaxError: missing ) in parenthetical\" \u2013 no mentioning of\nthe missing async keyword.Suppose we need to request a whole bunch of URLs.\nI could send one request, wait till it responds, then send the next request,\nwait till it responds, and so on ...\nAargh! \u2013 That could take a loong time. Wouldn't it be better if I could send\nthem all at once, and then wait no longer than it takes for the slowest\nresponse to arrive?As a simplified example, I will use:The JSONs of the two URLs:The goal is to get an array of objects, where each object contains the title\nvalue from the corresponding URL.To make it a little more interesting, I will assume that there is already an\narray of names that I want the array of URL results (the titles) to be\nmerged with:The desired output is a mashup combining namesonly and urls into an\narray of objects:where I have changed the name of title to loremipsum.const namesonly = ['two','three'];\n\nconst urls = ['https://jsonplaceholder.typicode.com/todos/2',\n  'https://jsonplaceholder.typicode.com/todos/3'];\n\nPromise.all(urls.map(url => fetch(url)\n  .then(response => response.json())\n  .then(responseBody => responseBody.title)))\n  .then(titles => {\n    const names = namesonly.map(value => ({ name: value }));\n    console.log('names: ' + JSON.stringify(names));\n    const latins = titles.map(value => ({ loremipsum: value }));\n    console.log('latins:\\n' + JSON.stringify(latins));\n    const result =\n      names.map((item, i) => Object.assign({}, item, latins[i]));\n    console.log('result:\\n' + JSON.stringify(result));\n  });\n.as-console-wrapper { max-height: 100% !important; top: 0; }All the above examples are short and succinctly convey how asynchronous calls\nmay be used on toyish APIs.\nUsing small APIs works well to explain concepts and working code, but the\nexamples might be a bit of dry runs.The next section will show a more realistic example on how APIs may be\ncombined to create a more interesting output.The MusicBrainz API\nhas information about artists and music bands.\nAn example \u2013 a request for the British rock band Coldplay is:\nhttp://musicbrainz.org/ws/2/artist/cc197bad-dc9c-440d-a5b5-d52ba2e14234?&fmt=json&inc=url-rels+release-groups.\nThe JSON response contains \u2013 among other things \u2013 the 25 earliest album titles\nby the band.\nThis information is in the release-groups array.\nThe start of this array, including its first object is:This JSON snippet shows that the first album by Coldplay is Parachutes.\nIt also gives an id, in this case 1dc4c347-a1db-32aa-b14f-bc9cc507b843,\nwhich is a unique identifier of the album.This identifier can be used to make a lookup in the Cover Art Archive API:\nhttp://coverartarchive.org/release-group/1dc4c347-a1db-32aa-b14f-bc9cc507b843.\n7For each album, the JSON response contains some images, one of which is the\nfront cover of the album.\nThe first few lines of the response to the above request:Of interest here is the line\n\"small\": \"http://coverartarchive.org/release/435fc965-9121-461e-b8da-d9b505c9dc9b/4086974851-250.jpg\".\nThat URL is a direct link to the front cover of the Parachutes album.The code to create and visualize the mashupThe overall task is to use Postman to visualize all the album titles and front\ncovers of a music band.\nHow to write code to achieve this has already been described in quite some\ndetail in  an answer to the question\nHow can I visualize an API mashup in Postman? \u2013 Therefore I will avoid\nlengthy discussions here and just present the code and a screenshot of the\nresult:The result and documentationHow to download and run the Postman CollectionRunning the Postman Collection should be straightforward.\nAssuming you are using the desktop version of Postman, do as follows:Download and save\nhttp://henke.atwebpages.com/postman/mbid/MusicBands.pm_coll.json\nin a suitable place on your hard drive.In Postman, Ctrl + O > Upload Files >\nMusicBands.pm_coll.json > Import.\nYou should now see MusicBands among your collections in Postman.Collections > MusicBands > DummyRequest > Send.\n8In the Postman Response Body, click Visualize.You should now be able to scroll 15 albums as indicated by the\nscreenshot above.1 Expressed by the original poster as: they all return\nundefined.\n2 If you think asynchronous calls are confusing, consider having a\nlook at some questions and answers about asynchronous calls to see if that helps.\n3 The name XMLHttpRequest is as misleading as the X in\nAJAX \u2013 these days the data format of Web APIs is ubiquitously JSON, not XML.\n4 Fetch\nreturns a Promise.\nI was surprised to learn that neither XMLHttpRequest nor Fetch are part of\nthe ECMAScript standard.\nThe reason JavaScript can access them here is because the web browser provides\nthem.\nThe Fetch Standard and\nthe XMLHttpRequest Standard are both upheld by\nthe Web Hypertext Application Technology Working Group (WHATWG) that was formed in June 2004.\n5 This section borrows a lot from\nHow can I fetch an array of URLs with Promise.all?.\n6 This section relies heavily on\nHow can I visualize an API mashup in Postman?.\n7 This URL is automatically redirected to:\nhttps://ia800503.us.archive.org/29/items/mbid-435fc965-9121-461e-b8da-d9b505c9dc9b/index.json.\n8 If you get an error,\nSomething went wrong while running your scripts,\ntry hitting Send again.",
                "Use a callback() function inside the foo() success.\nTry it in this way. It is simple and easy to understand.",
                "The most perfect answer to this question is using Promise.There is a problem with using promises!I was using this solution for a while until I figured out there is an error in old browsers:Uncaught ReferenceError: Promise is not definedSo I decided to implement my own Promise class for ES3 to below JavaScript compilers if it's not defined. Just add this code before your main code and then safely use Promise!",
                "Of course there are many approaches like synchronous request, promise, but from my experience I think you should use the callback approach. It's natural to asynchronous behavior of JavaScript.So, your code snippet can be rewritten to be a little different:",
                "The question was:How do I return the response from an asynchronous call?which can be interpreted as:How to make asynchronous code look synchronous?The solution will be to avoid callbacks, and use a combination of Promises and async/await.I would like to give an example for an Ajax request.(Although it can be written in JavaScript, I prefer to write it in Python, and compile it to JavaScript using Transcrypt. It will be clear enough.)Let\u2019s first enable jQuery usage, to have $ available as S:Define a function which returns a Promise, in this case an Ajax call:Use the asynchronous code as if it were synchronous:",
                "Rather than throwing code at you, there are two concepts that are key to understanding how JavaScript handles callbacks and asynchronicity (is that even a word?)There are three things you need to be aware of; The queue; the event loop and the stackIn broad, simplistic terms, the event loop is like the project manager, it is constantly listening for any functions that want to run and communicates between the queue and the stack.Once it receives a message to run something it adds it to the queue. The queue is the list of things that are waiting to execute (like your AJAX request). imagine it like this:When one of these messages is going to execute it pops the message from the queue and creates a stack, the stack is everything JavaScript needs to execute to perform the instruction in the message. So in our example it's being told to call foobarFuncSo anything that foobarFunc needs to execute (in our case anotherFunction) will get pushed onto the stack. executed, and then forgotten about - the event loop will then move onto the next thing in the queue (or listen for messages)The key thing here is the order of execution. That isWhen you make a call using AJAX to an external party or run any asynchronous code (a setTimeout for example), JavaScript is dependant upon a response before it can proceed.The big question is when will it get the response? The answer is we don't know - so the event loop is waiting for that message to say \"hey run me\". If JavaScript just waited around for that message synchronously your app would freeze and it will suck. So JavaScript carries on executing the next item in the queue whilst waiting for the message to get added back to the queue.That's why with asynchronous functionality we use things called callbacks. - A function or handler that, when passed into another function, will be executed at a later date. A promise uses callbacks (functions passed to .then() for example) as a way to reason about this asynchronous behaviour in a more linear way. The promise is a way of saying \"I promise to return something at some point\" and the callback is how we handle that value that is eventually returned. jQuery uses specific callbacks called deffered.done deffered.fail and deffered.always (amongst others). You can see them all hereSo what you need to do is pass a function that is promised to execute at some point with data that is passed to it.Because a callback is not executed immediately but at a later time it's important to pass the reference to the function not it executed. soso most of the time (but not always) you'll pass foo not foo()Hopefully that will make some sense. When you encounter things like this that seem confusing - i highly recommend reading the documentation fully to at least get an understanding of it. It will make you a much better developer."
            ]
        },
        {
            "tag": "",
            "question": [
                "What is the difference between px, dip, dp, and sp?",
                "What is the difference between the units of measure\npx, dip, dp, and sp?"
            ],
            "url": "https://stackoverflow.com/questions/2025282",
            "answer": [
                "From the Android Developer Documentation:px\nPixels - corresponds to actual pixels on the screen.in\nInches - based on the physical size of the screen.\n1 Inch OR 2.54 centimetersmm\n> Millimeters - based on the physical size of the screen.pt\n> Points - 1/72 of an inch based on the physical size of the screen.dp or dip\n> Density-independent Pixels - an abstract unit that is based on the physical density of the screen. These units are relative to a 160\ndpi screen, so one dp is one pixel on a 160 dpi screen. The ratio of dp-to-pixel will change with the screen density, but not necessarily in direct proportion. Note: The compiler accepts both \"dip\" and \"dp\", though \"dp\" is more consistent with \"sp\".sp\n> Scaleable Pixels OR scale-independent pixels - this is like the dp unit, but it is also scaled by the user's font size preference. It is recommended you\nuse this unit when specifying font sizes, so they will be adjusted\nfor both the screen density and the user's preference. Note, the Android documentation is inconsistent on what sp actually stands for, one doc says \"scale-independent pixels\", the other says \"scaleable pixels\".From Understanding Density Independence In Android:More info can be also be found in the Google Design Documentation.",
                "Pretty much everything about this and how to achieve the best support for multiple screens of different sizes and densities is very well documented here:Screen size\nActual physical size, measured as the screen's diagonal.\nFor simplicity, Android groups all actual screen sizes into four\ngeneralized sizes: small, normal, large, and extra-large.Screen density\nThe number of pixels within a physical area of the\nscreen; usually referred to as dpi (dots per inch). For example, a\n\"low\" density screen has fewer pixels within a given physical area,\ncompared to a \"normal\" or \"high\" density screen. For simplicity,\nAndroid groups all actual screen densities into six generalized\ndensities: low, medium, high, extra-high, extra-extra-high, and\nextra-extra-extra-high.OrientationThe orientation of the screen from the user's point of\nview. This is either landscape or portrait, meaning that the screen's\naspect ratio is either wide or tall, respectively. Be aware that not\nonly do different devices operate in different orientations by\ndefault, but the orientation can change at runtime when the user\nrotates the device.Resolution The total number of physical pixels on\na screen. When adding support for multiple screens, applications do\nnot work directly with resolution; applications should be concerned\nonly with screen size and density, as specified by the generalized\nsize and density groups.Density-independent pixel (dp) A virtual\npixel unit that you should use when defining UI layout, to express\nlayout dimensions or position in a density-independent way.\nThe density-independent pixel is equivalent to one physical pixel on a 160\ndpi screen, which is the baseline density assumed by the system for a\n\"medium\" density screen. At runtime, the system transparently handles\nany scaling of the dp units, as necessary, based on the actual density\nof the screen in use. The conversion of dp units to screen pixels is\nsimple:\npx = dp * (dpi / 160).\nFor example, on a 240 dpi screen, 1 dp\nequals 1.5 physical pixels. You should always use dp units when\ndefining your application's UI, to ensure proper display of your UI on\nscreens with different densities.If you are at all serious about developing an Android app for more than one type of device, you should have read the screens support development document at least once. In addition to that, it is always a good thing to know the actual number of active devices that have a particular screen configuration.",
                "I will elaborate more on how exactly does dp convert to px:The other way around: say, you want to add an image to your application and you need it to fill a 100 * 100 dp control. You'll need to create different size images for supported screen sizes:",
                "Moreover you should have a clear understanding of the following concepts:Screen size:Actual physical size, measured as the screen's diagonal. For simplicity, Android groups all actual screen sizes into\nfour generalized sizes: small, normal, large, and extra-large.Screen density:The number of pixels within a physical area of the screen; usually referred to as dpi (dots per inch). For example, a\n\"low\" density screen has fewer pixels within a given physical area,\ncompared to a \"normal\" or \"high\" density screen. For simplicity,\nAndroid groups all actual screen densities into four generalized\ndensities: low, medium, high, and extra high.Orientation:The orientation of the screen from the user's point of view. This is either landscape or portrait, meaning that the\nscreen's aspect ratio is either wide or tall, respectively. Be aware\nthat not only do different devices operate in different orientations\nby default, but the orientation can change at runtime when the user\nrotates the device.Resolution:The total number of physical pixels on a screen. When adding support for multiple screens, applications do not work directly\nwith resolution; applications should be concerned only with screen\nsize and density, as specified by the generalized size and density\ngroups.Density-independent pixel (dp):A virtual pixel unit that you should use when defining UI layout, to express layout dimensions or\nposition in a density-independent way. The density-independent pixel\nis equivalent to one physical pixel on a 160 dpi screen, which is the\nbaseline density assumed by the system for a \"medium\" density screen.\nAt runtime, the system transparently handles any scaling of the dp\nunits, as necessary, based on the actual density of the screen in use.\nThe conversion of dp units to screen pixels is simple: px = dp * (dpi\n/ 160). For example, on a 240 dpi screen, 1 dp equals 1.5 physical\npixels. You should always use dp units when defining your\napplication's UI, to ensure proper display of your UI on screens with\ndifferent densities.Reference: Android developers site",
                "dp is  dip. Use it for everything (margin, padding, etc.).Use sp for {text-size} only.See the difference between px, dp and sp on different screen sizes.Source: Android Programming: The Big Nerd Ranch Guide",
                "px or dot is a pixel on the physical screen.dpi are pixels per inch on the physical screen and represent the density of the display.Android gives alias names to several densitiesdip or dp are density-indenpendant pixels, i.e. they correspond to more or less pixels depending on the physical density.sp or sip is a scale-independant pixel. They are scaled when the Large Text option is turned on in Settings > AccessibilityUse sp for Text size.Use dp for everything else.",
                "I have calculated the formula below to make the conversions dpi to dp and sp",
                "Source 1Source 2Source 3: (data from source 3 is given below)These are dimension values defined in XML. A dimension is specified\nwith a number followed by a unit of measure. For example: 10px, 2in,\n5sp. The following units of measure are supported by Android:dpDensity-independent Pixels - An abstract unit that is based on the\nphysical density of the screen. These units are relative to a 160 dpi\n(dots per inch) screen, on which 1dp is roughly equal to 1px. When\nrunning on a higher density screen, the number of pixels used to draw\n1dp is scaled up by a factor appropriate for the screen's dpi.\nLikewise, when on a lower density screen, the number of pixels used\nfor 1dp is scaled down. The ratio of dp-to-pixel will change with the\nscreen density, but not necessarily in direct proportion. Using dp\nunits (instead of px units) is a simple solution to making the view\ndimensions in your layout resize properly for different screen\ndensities. In other words, it provides consistency for the real-world\nsizes of your UI elements across different devices.spScale-independent Pixels - This is like the dp unit, but it is also\nscaled by the user's font size preference. It is recommended that you use\nthis unit when specifying font sizes, so they will be adjusted for\nboth the screen density and the user's preference.ptPoints - 1/72 of an inch based on the physical size of the screen.pxPixels - Corresponds to actual pixels on the screen. This unit of\nmeasure is not recommended because the actual representation can vary\nacross devices; each device may have a different number of pixels per\ninch and may have more or fewer total pixels available on the screen.mmMillimeters - Based on the physical size of the screen.inInches - Based on the physical size of the screen.Note: A dimension is a simple resource that is referenced using the value provided in the name attribute (not the name of the XML file). As such, you can combine dimension resources with other simple resources in one XML file, under one  element.",
                "Basically the only time where px applies is one px, and that's if you want exactly one pixel on the screen like in the case of a divider:On >160 dpi, you may get 2-3 pixels,On >120 dpi, it rounds to 0.",
                "A virtual pixel unit that you should use when defining UI layout, to express layout dimensions or position in a density-independent way. As described above, the density-independent pixel is equivalent to one physical pixel on a 160 dpi screen, which is the baseline density assumed by the system for a \"medium\" density screen. At runtime, the system transparently handles any scaling of the dp units, as necessary, based on the actual density of the screen in use. The conversion of dp units to screen pixels is\nsimple:px = dp * (dpi / 160).For example, on a 240 dpi screen, 1 dp equals 1.5 physical pixels. You should always use dp units when defining your application's UI, to ensure\nproper display of your UI on screens with different densities.Understanding pixel to dp and vice versa is very essential (especially for giving exact dp values to creative team)It is explained above. Try to avoid in layout files. But there are some cases, where px is required. for example, ListView divider line. px is better here for giving a one-pixel line as a divider for all across screen resolutions.Use sp for font sizes. Then only the font inside the application will change while device fonts size changes (that is, Display -> Fonts on Device). If you want to keep a static sized font inside the app, you can give the font dimension in dp. In such a case, it will never change. Developers may get such a requirement for some specific screens, for that, developers can use dp instead of sp. In all other cases, sp is recommended.",
                "You can see the difference between px and dp from the below picture, and you can also find that the px and dp could not guarantee the same physical sizes on the different screens.",
                "Anything related with the size of text and appearance must use sp or pt. Whereas, anything related to the size of the controls, the layouts, etc. must be used with dp.You can use both dp and dip at its places.",
                "I would only use dp.There is a lot of talk about using \"sp\" for font sizes, and while I appreciate the point, I don't think that it is the right thing to do from a design point of view. You can end up breaking your design if the user has some wonky font size selection, and the user will end up blaming the app, and not their own life choices.Also, if you take an sp-font app on a 160\u00a0dpi tablet, you will find that everything scales up... but your font, which is going to look tiny in comparison. It isn't a good look.While the idea of \"sp\" fonts has a good heart, it is a poor idea. Stick with dp for everything.",
                "sp = scale independent pixeldp = dip = density independent pixelsdpi = dots per inchWe should avoid to use sp.We should use dp to support multiple screens.Android supports different screen resolutionsAn 120 dp ldpi device has 120 pixels in 1 inch size.The same for other densities...We as software engineers should use this conversion formula:pixel = dp * (density / 160)So 240 dpi device's 1 dp will have = 1 * (240/160) = 3/2 = 1.5 pixels.And 480 dpi device's 1 dp will have = 1 * (480/160) = 3 pixels.Using this 1.5 and 3 pixels knowledge, a software engineer can design layouts for different densities.To check screen parameters of any device:",
                "Difference between dp and sp units mentioned as \"user's font size preference\" by the answers copied from official documentation can be seen at run time by changing Settings->Accessibility->Large Text option.Large Text option forces text to become 1.3 times bigger.This might be well of course vendor dependent since it lies in packages/apps/Settings.",
                "dpi -px - pixelpt - pointsin - inch\n - with respect to physical screen size(1 inch = 2.54 cm).mm- milimeter\n - with respect to physical screen size.sp - scale-independent pixel.dip -In standard, dp and sp are used. sp for font size and dp for everything else.Formula for conversion of units:px = dp * ( dpi / 160 );",
                "Please read the answer from the community wiki.\nBelow mentioned is some information to be considered in addition to the above answers. Most Android developers miss this while developing apps, so I am adding these points.sp = scale independent pixeldp = density independent pixelsdpi = density pixelsI have gone through the above answers...not finding them exactly correct.\nsp for text size, dp for layout bounds - standard.\nBut sp for text size will break the layout if used carelessly in most of the devices.sp take the text size of the device, whereas dp take that of device density standard( never change in a device)\nSay 100sp text can occupy 80% of the screen or 100% of the screen depending on the font size set in the deviceYou can use sp for layout bounds also, it will work :)\nNo standard app use sp for whole textUse sp and dp for text size considering UX.Some people use huge FONT size in their phone for more readability, giving them small hardcoded sized text will be a UX issue. Put sp for text where necessary, but make sure it won't break the layout when the user changes his settings.Similarly, if you have a single app supporting all dimensions, adding xxxhdpi assets increases the app size a lot. But now xxxhdpi phones are common so we have to include xxxhdpi assets at least for icons in the sidebar, toolbar, and bottom bar. It's better to move to vector images to have a uniform and better quality images for all screen sizes.Also, note that people use custom fonts on their phones. So lack of a font can cause problems regarding spacing and all. Say text size 12sp for a custom font may take some pixels extra than the default font.Refer to google developer site for screen densities and base density details for android.\nhttps://developer.android.com/training/multiscreen/screendensities",
                "Screen Size in Android is grouped into categories small, medium, large, extra large, double-extra and triple-extra. Screen density is the number of pixels within an area (like an inch) of the screen. Generally, it is measured in dots-per-inch (dpi). Screen density is grouped as low, medium, high, and extra high. Resolution is the total number of pixels on the screen.Formula for Conversion between Unitsdp to px in deviceThe following example may help understand better. The scaling occurs based on bucket sizes of 120(ldpi), 160(mdpi), 240(hdpi), 320(xhdpi), 480(xxhdpi), and 640(xxxhdpi). The Google suggested ratio for designing is 3:4:6:8:12 for ldpi:mdpi:hdpi:xhdpi:xxhdpiA 150px X 150px image will occupy,You may use the following DPI calculator to fix your image sizes and other dimensions when you wish to have a uniform UI design on all Android devices.More Information refer to the following link.http://javapapers.com/android/difference-between-dp-dip-sp-px-in-mm-pt-in-android/",
                "Here's the formula used by Android:px = dp * (dpi / 160)Where dpi is one of the following screen densities. For a list of all possible densities go hereIt defines the \"DENSITY_*\" constants.Taken from here.This will sort out a lot of the confusion when translating between px and dp, if you know your screen dpi.So, let's say you want an image of 60 dp for an hdpi screen then the physical pixel size of 60 dp is:",
                "Normally sp is used for font sizes, while dip is used (also called dp) for others.",
                "I've come across a good article about designing Android apps UI for different screen resolutions, and I'd like to leave it here just for somebody searching in this area. Yes, I know that it's somehow described in Google docs (and mentioned in the posts above), I read that but it was not good for me (yeah, I may be too stupid)). It remained unclear to me how to design layouts capable to handle different screen sizes. I hate the DP concept and so on when I need to implement a \"flexible\" UI layout for different screens. (Hey iOS developers - yes, you're right it's a Storyboard concept).Android has not bad UI concept, but lacks iOS Storyboard features, unfortunately. Designing flexible UI in Android is not an easy thing (at the best).Here goes the article that helped me to understand what to do in Android to make layouts for different screen sizes:JMSTUDIO Blog:- Decide Android App Screen SizeHow to Design UI for Android Apps for Different Screen SizeTo design an app UI for different screen sizes, our initial design has to\nmeet a minimum required space for each screen size. Android defines a\nminimum size (in dp) for each generalized screen type. Here is an\nAndroid screen size guideline.\n\nWhen we get the screen size in dp, it is not enough for us to design\nthe Android app UI. For each screen size, we need to prepare graphics\nand bitmap images for each density. Here is an Android screen density\nguideline.For easy calculation, we can follow the 3:4:6:8 scaling ratio between\nthe four generalized densities. If we create a 36\u00d736 pixel picture for\nldpi device, the rest densities pictures size will be 48\u00d748 for mdpi,\n72\u00d772 for hdpi, and 96\u00d796 for xhdpi.How to Design Android Apps UI in PhotoshopMany designers have problems designing Android app UI in photoshop or another pixel\nbased graphic design tools because of the density-independent unit, dp.\nDesigners don\u2019t know how to map dp to pixel. Google also doesn\u2019t give\na clear Android UI design guide for them, though they give a basic\nformula for dp and pixel translation.As Android\u2019s definition, 1pd equal to 1px under 160 dpi device (mdpi).\nSo we want to design an Android app for xlarge Android devices with\nmdpi density, we can define our UI size in pixel as 960 pixels in width\nand 720px in height; Follow the same mapping rule, we can get\nfollowing Android App screen size UI design guideline:ADDED: If you are interested in \"flexible\" UI too, have a look at this library: An Android SDK that provides a new size unit - sdp (scalable dp). This size unit scales with the screen size (this also mentioned in an answer here, about SDP library)ADDED2 Google has finally understood the usefulness of the iOS Storeboard UI concept, and here goes ConstraintLayout for Android world: Build a Responsive UI with ConstraintLayout",
                "1) dp: (density independent pixels)The number of pixels represented in one unit of dp will increase as the screen resolution increases (when you have more dots/pixels per inch). Conversely on devices with lower resolution, the number of pixels represented in on unit of dp will decrease. Since this is a relative unit, it needs to have a baseline to be compared with. This baseline is a 160 dpi screen. This is the equation: px = dp * (dpi / 160).2) sp: (scale independent pixels)This unit scales according to the screen dpi (similar to dp) as well as the user\u2019s font size preference.3) px: (pixels)Actual pixels or dots on the screen.For more details you can visitAndroid Developer Guide > Dimension\nAndroid Developer Guide > Screens",
                "Screen size in Android is grouped into categories ldpi, mdpi, hdpi, xhdpi, xxhdpi and xxxhdpi. Screen density is the amount of pixels within an area (like inch) of the screen. Generally it is measured in dots-per-inch (dpi).PX(Pixels):DP/DIP(Density pixels / Density independent pixels):dip == dp. In earlier Android versions dip was used and later changed to dp. This is alternative of px.Generally we never use px because it is absolute value. If you use px to set width or height, and if that application is being downloaded into different screen sized devices, then that view will not stretch as per the screen original size.dp is highly recommended to use in place of px. Use dp if you want to mention width and height to grow & shrink dynamically  based on screen sizes.if we give dp/dip, android will automatically calculate the pixel size on the basis of 160 pixel sized screen.SP(Scale independent pixels):scaled based on user\u2019s font size preference. Fonts should use sp.when mentioning the font sizes to fit for various screen sizes, use sp. This is similar to dp.Use sp especially for font sizes to grow & shrink dynamically based on screen sizesAndroid Documentation says:when specifying dimensions, always use either dp or sp units. A dp is\n  a density-independent pixel that corresponds to the physical size of a\n  pixel at 160 dpi. An sp is the same base unit, but is scaled by the\n  user's preferred text size (it\u2019s a scale-independent pixel), so you\n  should use this measurement unit when defining text size",
                "Screen pixel density and resolution vary depending on the platform. Device-independent pixels and scalable pixels are units that provide a flexible way to accommodate a design across platforms.The number of pixels that fit into an inch is referred to as pixel density. High-density screens have more pixels per inch than low-density ones...The number of pixels that fit into an inch is referred to as pixel density. High-density screens have more pixels per inch than low-density ones. As a result, UI elements of the same pixel dimensions appear larger on low-density screens, and smaller on high-density screens.To calculate screen density, you can use this equation:Screen density = Screen width (or height) in pixels / Screen width (or height) in inchesScreen pixel density and resolution vary depending on the platform. Device-independent pixels and scalable pixels are units that provide a flexible way to accommodate a design across platforms.Calculating pixel density\nThe number of pixels that fit into an inch is referred to as pixel density. High-density screens have more pixels per inch than low-density ones...Density independence refers to the uniform display of UI elements on screens with different densities.Density-independent pixels, written as dp (pronounced \u201cdips\u201d), are flexible units that scale to have uniform dimensions on any screen. Material UIs use density-independent pixels to display elements consistently on screens with different densities.Read full text\nhttps://material.io/design/layout/pixel-density.html",
                "The screen of a mobile phone is made up of thousands of tiny dots known as pixels (px). A pixel is the smallest element which goes to make the picture. The more the number of pixels to make a picture or wording, the sharper it becomes and makes the smartphone screen more easily readable.Screen resolution is measured in terms of number of pixels on the screen. Screen resolution is a commonly-used specification when buying a device, but it's actually not that useful when designing for Android because thinking of screens in terms of pixels ignores the notion of physical size, which for a touch device is really really important.Density independent pixel (dp or dip) allow the designer to create assets that appear in a expected way, no matter the resolution or density of target device.A density independent pixel (dp or dip) is equal to one pixel at the baseline density or 160 dpi (dots per inch).1 px/1dp = 160 dpi/160 dpi2 px/1dp = 320 dpi(2x)/160 dpiwhere,dpi is dots per inchSo, at 320 dpi, 1 dp is equal to 2 px.Formulapx/dp = dpi/160dpiDots per inch (dpi) is a measure of the sharpness (that is, the density of illuminated points) on a display screen. The dots per inch for a given picture resolution will differ based on the overall screen size since the same number of pixels are being spread out over a different space.Working with density independent pixels help us to deal with a situation like where you have two devices with same pixel resolution, but differing amount of space. Suppose in a case, a tablet and phone has the same pixel resolution 1280 by 800 pixels (160 dpi) and 800 by 1280 pixels (320 dpi) respectively.Now because a tablet is at baseline density (160 dpi) its physical and density independent pixels sizes are the same, 1280 by 800. The phone on the other hand has a higher pixel density, so it has half as many density independent pixels as physical pixels. So a phone has 400 by 640 density independent pixels. So using a density-independent pixel makes it easier to mentally picture that tablet has much more space than the phone.Similarly, if you have two devices with similar screen size, but different pixel density, say one is 800 by 1280 pixels (320 dpi), and the other is 400 by 640 pixels (160 dpi), we don't need to define totally different layouts for these two devices as we can measure assets in terms of density independent pixel which is same for both devices.800 by 1280 pixels (320dpi)=400 by 640 density independent pixel (dp)400 by 640 pixels (160 dpi)=400 by 640 density independent pixel (dp)Scale independent pixels(sp) is the preferred unit for font size.\nFor accessibility purposes, Android allows users to customize their device's font size. Users that have trouble reading text can increase their device's font size. You can normally find this option in the display setting on your phone or tablet under font size. It's often also available through the accessibility settings.With scale independent pixels, 16 sp is exactly the same as 16 dp when the device's font size is normal or 100%. But when device's font size is large, for example 125%, 16 sp will translate to 20 dp or 1.25 times 16.If you use dp as the unit for font size, then that piece of text has a specific physical size no matter if the user has customize device's font size. Using sp units will make a better experience for people with impaired eyesight.Reference: Udacity, Google",
                "sp: scale independent pixelYou should use it with texts because it is automatically scaled according to the font size that is being used by the user in his device.px: pixel or picture element is the single point on the screen",
                "Pixels(px) \u2013 corresponds to actual pixels on the screen. This is used if you want to give in terms of absolute pixels for width or height.Density-independent Pixels (dp or dip) \u2013 an abstract unit that is based on the physical density of the screen. These units are relative to a 160 dpi screen, so one dp is one pixel on a 160 dpi screen. The ratio of dp-to-pixel will change with the screen density, but not necessarily in direct proportion. Note: The compiler accepts both \u201cdip\u201d and \u201cdp\u201d, though \u201cdp\u201d is more consistent with \u201csp\u201d.Scale-independent Pixels(sp) \u2013 this is like the dp unit, but it is also scaled by the user\u2019s font size preference. It is recommended you use this unit when specifying font sizes, so they will be adjusted for both the screen density and user\u2019s preference.Always use dp and sp only. sp for font sizes and dp for everything else. It will make UI compatible for Android devices with different densities.\nYou can learn more about pixel and dp from\nhttps://www.google.com/design/spec/layout/units-measurements.html#units-measurements-density-independent-pixels-dp-Source URL:- http://www.androidtutorialshub.com/what-is-the-difference-between-px-dp-dip-sp-on-android/",
                "I want to provide an easy way to understand dp. In fact, I think dp is the easiest one to understand. dp is just a physical length unit. It's of the same dimension as mm or inch. It's just convenient for us to write 50dp, 60dp rather than 50/160 inch or 60/160 inch, because one dp is just 1/160 inch whatever the screen size or resolution is.The only problem is that, the android dpi of some screens are not accurate. For example, a screen classified to 160dpi may have 170dpi indeed. So the computation result of dp is fuzzy. It should be approximately the same as 1/160 inch.",
                "SDP - a scalable size unit - basically it is not a unit, but dimension resources for different screen size.Try the sdp library from Intuit. It's very handy to solve unit problems, and you can quickly support multiple screens.Usageandroid:paddingBottom=\"@dimen/_15sdp\" for positive and android:layout_marginTop=\"@dimen/_minus10sdp\"  for negative sdp sdpIt has equivalent value in dp for each size in values-sw<N>dp folders (sw = smallestWidth).AttentionUse it carefully! In most cases you still need to design a different layout for tablets.ExampleYou can use db for text size, but I prefer ssp for text size.For more details, check the library GitHub page.",
                "The ratio of dp-to-pixel will change with the screen density, but not necessarily in direct proportion.Note: The compiler accepts both \"dip\" and \"dp\", though \"dp\" is more consistent with \"sp\".Scale-independent Pixels - this is like the dp unit, but it is also scaled by the user's font size preference."
            ]
        },
        {
            "tag": "",
            "question": [
                "Move the most recent commit(s) to a new branch with Git",
                "How do I move my recent commits on master to a new branch, and reset master to before those commits were made? e.g. From this:\nmaster A - B - C - D - E\n\nTo this:\nnewbranch     C - D - E\n             /\n..."
            ],
            "url": "https://stackoverflow.com/questions/1628563",
            "answer": [
                "If you want to move your commits to an existing branch, it will look like this:You can store uncommitted edits to your stash before doing this, using git stash. Once complete, you can retrieve the stashed uncommitted edits with git stash popWARNING: This method works because you are creating a new branch with the first command: git branch newbranch. If you want to move commits to an existing branch you need to merge your changes into the existing branch before executing git reset --hard HEAD~3 (see Moving to an existing branch above). If you don't merge your changes first, they will be lost.Unless there are other circumstances involved, this can be easily done by branching and rolling back.But do make sure how many commits to go back. Alternatively, you can instead of HEAD~3, simply provide the hash of the commit (or the reference like origin/master) you want to \"revert back to\" on the master (/current) branch, e.g:*1 You will only be \"losing\" commits from the master branch, but don't worry, you'll have those commits in newbranch!Lastly, you may need to force push your latest changes to main repo:WARNING: With Git version 2.0 and later, if you later git rebase the new branch upon the original (master) branch, you may need an explicit --no-fork-point option during the rebase to avoid losing the carried-over commits.  Having branch.autosetuprebase always set makes this more likely.  See John Mellor's answer for details.",
                "For those wondering why it works (as I was at first):You want to go back to C, and move D and E to the new branch.  Here's what it looks like at first:After git branch newBranch:After git reset --hard HEAD~2:Since a branch is just a pointer, master pointed to the last commit.  When you made newBranch, you simply made a new pointer to the last commit.  Then using git reset you moved the master pointer back two commits.  But since you didn't move newBranch, it still points to the commit it originally did.",
                "The method exposed by sykora is the best option in this case. But sometimes is not the easiest and it's not a general method. For a general method use git cherry-pick:To achieve what OP wants, its a 2-step process:ExecuteNote the hashes of (say 3) commits you want on newbranch. Here I shall use:\nC commit: 9aa1233\nD commit: 453ac3d\nE commit: 612ecb3Note: You can use the first seven characters or\n  the whole commit hashgit cherry-pick applies those three commits to newbranch.",
                "Do NOT do this:As the next time you run git rebase (or git pull --rebase) those 3 commits would be silently discarded from newbranch! (see explanation below)Instead do this:Warning: the reflog is enabled by default, but if you've manually disabled it (e.g. by using a \"bare\" git repository), you won't be able to get the 3 commits back after running git reset --keep HEAD~3.An alternative that doesn't rely on the reflog is:(if you prefer you can write @{-1} - the previously checked out branch - instead of oldbranch).Why would git rebase discard the 3 commits after the first example? It's because git rebase with no arguments enables the --fork-point option by default, which uses the local reflog to try to be robust against the upstream branch being force-pushed.Suppose you branched off origin/master when it contained commits M1, M2, M3, then made three commits yourself:but then someone rewrites history by force-pushing origin/master to remove M2:Using your local reflog, git rebase can see that you forked from an earlier incarnation of the origin/master branch, and hence that the M2 and M3 commits are not really part of your topic branch. Hence it reasonably assumes that since M2 was removed from the upstream branch, you no longer want it in your topic branch either once the topic branch is rebased:This behavior makes sense, and is generally the right thing to do when rebasing.So the reason that the following commands fail:is because they leave the reflog in the wrong state. Git sees newbranch as having forked off the upstream branch at a revision that includes the 3 commits, then the reset --hard rewrites the upstream's history to remove the commits, and so next time you run git rebase it discards them like any other commit that has been removed from the upstream.But in this particular case we want those 3 commits to be considered as part of the topic branch. To achieve that, we need to fork off the upstream at the earlier revision that doesn't include the 3 commits. That's what my suggested solutions do, hence they both leave the reflog in the correct state.For more details, see the definition of --fork-point in the git rebase and git merge-base docs.",
                "Yet another way to do this, using just 2 commands. Also keeps your current working tree intact.Old version - before I learned about git branch -fBeing able to push to . is a nice trick to know.",
                "Here's a far simpler solution for commits to the wrong branch. Starting on branch master that has three mistaken commits:You can now use git add and git commit as you normally would. All new commits will be added to newbranch.The OP stated the goal was to \"take master back to before those commits were made\" without losing changes and this solution does that.I do this at least once a week when I accidentally make new commits to master instead of develop. Usually I have only one commit to rollback in which case using git reset HEAD^ on line 1 is a simpler way to rollback just one commit.Don't do this if you pushed master's changes upstreamSomeone else may have pulled those changes. If you are only rewriting your local master there's no impact when it's pushed upstream, but pushing a rewritten history to collaborators can cause headaches.",
                "This doesn't \"move\" them in the technical sense but it has the same effect:",
                "1. Rename master branch to your newbranch (assuming you are on master branch):2. Create master branch from the commit that you wish:e.g. git checkout -b master a34bc22NOTE:\nThe upstream for newbranch would be origin/master.",
                "To do this without rewriting history (i.e. if you've already pushed the commits):Both branches can then be pushed without force!",
                "Had just this situation:I performed:I expected that commit I would be the HEAD, but commit L is it now...To be sure to land on the right spot in the history its easier to work with the hash of the commit",
                "How can I go from thisto this?With two commandsgivingandgiving",
                "If you just need to move all your unpushed commits to a new branch,\nthen you just need to,create a new branch from the current one :git branch new-branch-namepush your new branch: git push origin new-branch-namerevert your old(current) branch to the last pushed/stable state: git reset --hard origin/old-branch-nameSome people also have other upstreams rather than origin, \nthey should use appropriate upstream",
                "TLDRFor meworks best to identify the commit hashes in question.",
                "You can do this is just 3  simple step that i used.1) make new branch where you want to commit you recent update.git branch <branch name>2)  Find  Recent Commit Id for commit on new branch.git log3)  Copy that commit id  note that Most Recent commit list take place on top. so you can find your commit. you also find this via message.git cherry-pick d34bcef232f6c...you can also provide some rang of commit id.git cherry-pick d34bcef...86d2aecNow your job done. If you picked correct id and correct branch then you will success. So before do this be careful. else another problem can occur.Now you can push your codegit push",
                "1) Create a new branch, which moves all your changes to new_branch.2) Then go back to old branch.3) Do git rebase4) Then the opened editor contains last 3 commit information.5) Change pick to drop in all those 3 commits. Then save and close the editor.6) Now last 3 commits are removed from current branch (master). Now push the branch forcefully, with + sign before branch name.",
                "Most of the solutions here count the amount of commits you'd like to go back. I think this is an error prone methodology. Counting would require recounting.You can simply pass the commit hash of the commit you want to be at HEAD or in other words, the commit you'd like to be the last commit via:(Notice see commit hash)To avoid this:",
                "I was surprised that nobody recommended this way:to explain:",
                "Using Emacs' git porcelain Magit, you can do this simply by hitting b s (magit-branch-spinoff). You'll be asked to enter a name for your new branch and once you hit enter, voila.From the Magit documentation:This command creates and checks out a new branch starting at and tracking the current branch. That branch in turn is reset to the last commit it shares with its upstream. If the current branch has no upstream or no unpushed commits, then the new branch is created anyway and the previously current branch is not touched.This is useful to create a feature branch after work has already began on the old branch (likely but not necessarily \"master\").",
                "I got to move 7 commits from one old-branch to a new-branch.After that, both branches were related to the 7 commits I have done. After git checkout new-branch, I was getting fine git log and git status, but, when accessing the old-branch (git checkout old-branch), I'd got the message \"git is behind by 7 commits and can be fast-forwarded\". What worked for me to erase this message was the followind:After that step, the last 7 commits was referenced only for the new-branch and the previous ones were referenced as old-branch and new-branch in the Bitbucket tree.",
                "If you are a UI person like me and you are using Visual Studio. Then you can do the following:\nIn my case, I want to take the latest commit to another branch.So all commit changes will appear in the Git Changes pane.Now, stash your changesFrom \"Git Changes\" double click on your latest Stash.\"Stash details\" pane will be opened. Click on \"Pop\", then resolve conflicts (if exists).",
                "Taking some ideas from other posts, avoiding anything to do with reset, and being ultra paranoid, my solution is:I'm not proud, but I kept my data ;)"
            ]
        },
        {
            "tag": "",
            "question": [
                "What is the difference between POST and PUT in HTTP?",
                "According to RFC 2616, \u00a7 9.5, POST is used to create a resource:\n\nThe POST method is used to request that the origin server accept the entity enclosed in the request as a new subordinate of the ..."
            ],
            "url": "https://stackoverflow.com/questions/630453",
            "answer": [
                "Overall:Both PUT and POST can be used for creating.You have to ask, \"what are you performing the action upon?\", to distinguish what you should be using. Let's assume you're designing an API for asking questions.  If you want to use POST, then you would do that to a list of questions. If you want to use PUT, then you would do that to a particular question.Great, both can be used, so which one should I use in my RESTful design:You do not need to support both PUT and POST.Which you use is up to you.  But just remember to use the right one depending on what object you are referencing in the request.Some considerations:An example:I wrote the following as part of another answer on SO regarding this:POST:Used to modify and update a resourceNote that the following is an error:If the URL is not yet created, you\nshould not be using POST to create it\nwhile specifying the name.  This should\nresult in a 'resource not found' error\nbecause <new_question> does not exist\nyet.  You should PUT the <new_question>\nresource on the server first.You could though do something like\nthis to create a resources using POST:Note that in this case the resource\nname is not specified, the new objects\nURL path would be returned to you.PUT:Used to create a resource, or\noverwrite it.  While you specify the\nresources new URL.For a new resource:To overwrite an existing resource:Additionally, and a bit more concisely, RFC 7231 Section 4.3.4 PUT states (emphasis added),4.3.4.  PUTThe PUT method requests that the state of the target resource be\ncreated or replaced with the state defined by the representation\nenclosed in the request message payload.",
                "You can find assertions on the web that sayNeither is quite right.Better is to choose between PUT and POST based on idempotence of the action.PUT implies putting a resource - completely replacing whatever is available at the given URL with a different thing.  By definition, a PUT is idempotent.  Do it as many times as you like, and the result is the same. x=5 is idempotent.  You can PUT a resource whether it previously exists, or not (eg, to Create, or to Update)!POST updates a resource, adds a subsidiary resource, or causes a change.  A POST is not idempotent, in the way that x++ is not idempotent.By this argument, PUT is for creating when you know the URL of the thing you will create. POST can be used to create when you know the URL of the \"factory\" or manager for the category of things you want to create.so:or:",
                "The relevant specification for PUT and POST is RFC 2616 \u00a79.5ff.POST creates a child resource, so POST to /items creates a resources that lives under the /items resource.\nEg. /items/1. Sending the same post packet twice will create two resources.PUT is for creating or replacing a resource at a URL known by the client.Therefore: PUT is only a candidate for CREATE where the client already knows the url before the resource is created. Eg. /blogs/nigel/entry/when_to_use_post_vs_put as the title is used as the resource keyPUT replaces the resource at the known url if it already exists, so sending the same request twice has no effect. In other words, calls to PUT are idempotent.The RFC reads like this:The fundamental difference between the POST and PUT requests is reflected in the different meaning of the Request-URI. The URI in a POST request identifies the resource that will handle the enclosed entity. That resource might be a data-accepting process, a gateway to some other protocol, or a separate entity that accepts annotations. In contrast, the URI in a PUT request identifies the entity enclosed with the request -- the user agent knows what URI is intended and the server MUST NOT attempt to apply the request to some other resource. If the server desires that the request be applied to a different URI,Note: PUT has mostly been used to update resources (by replacing them in their entireties), but recently there is movement towards using PATCH for updating existing resources, as PUT specifies that it replaces the whole resource. RFC 5789.Update 2018: There is a case that can be made to avoid PUT. See \"REST without PUT\"With \u201cREST without PUT\u201d technique, the idea is that consumers are\nforced to post new 'nounified' request resources. As discussed\nearlier, changing a customer\u2019s mailing address is a POST to a new\n\u201cChangeOfAddress\u201d resource, not a PUT of a \u201cCustomer\u201d resource with a\ndifferent mailing address field value.taken from REST API Design - Resource Modeling by Prakash Subramaniam of ThoughtworksThis forces the API to avoid state transition problems with multiple clients updating a single resource, and matches more nicely with event sourcing and CQRS. When the work is done asynchronously, POSTing the transformation and waiting for it to be applied seems appropriate.",
                "POST means \"create new\" as in \"Here is the input for creating a user, create it for me\".PUT means \"insert, replace if already exists\" as in \"Here is the data for user 5\".You POST to example.com/users since you don't know the URL of the user yet, you want the server to create it.You PUT to example.com/users/id since you want to replace/create a specific user.POSTing twice with the same data means create two identical users with different ids. PUTing twice with the same data creates the user the first and updates him to the same state the second time (no changes). Since you end up with the same state after a PUT no matter how many times you perform it, it is said to be \"equally potent\" every time - idempotent. This is useful for automatically retrying requests. No more 'are you sure you want to resend' when you push the back button on the browser.A general advice is to use POST when you need the server to be in control of URL generation of your resources. Use PUT otherwise.  Prefer PUT  over POST.",
                "Can be performed with both PUT or POST in the following way:Creates THE new resource with newResourceId as the identifier, under the /resources URI, or collection.Creates A new resource under the /resources URI, or collection. Usually the identifier is returned by the server.Can only be performed with PUT in the following way:Updates the resource with existingResourceId as the identifier, under the /resources URI, or collection.When dealing with REST and URI as general, you have generic on the left and specific on the right. The generics are usually called collections and the more specific items can be called resource. Note that a resource can contain a collection.<-- generic -- specific -->When you use POST you are always refering to a collection, so whenever you say:you are posting a new user to the users collection.If you go on and try something like this:it will work, but semantically you are saying that you want to add a resource to the john collection under the users collection.Once you are using PUT you are refering to a resource or single item, possibly inside a collection. So when you say:you are telling to the server update, or create if it doesn't exist, the john resource under the users collection.Let me highlight some important parts of the spec:The POST method is used to request that the origin server accept the entity enclosed in the request as a new subordinate of the resource identified by the Request-URI in the Request-LineHence, creates a new resource on a collection.The PUT method requests that the enclosed entity be stored under the supplied Request-URI. If the Request-URI refers to an already existing resource, the enclosed entity SHOULD be considered as a modified version of the one residing on the origin server. If the Request-URI does not point to an existing resource, and that URI is capable of being defined as a new resource by the requesting user agent, the origin server can create the resource with that URI.\"Hence, create or update based on existence of the resource.",
                "I'd like to add my \"pragmatic\" advice. Use PUT when you know the \"id\" by which the object you are saving can be retrieved. Using PUT won't work too well if you need, say, a database generated id to be returned for you to do future lookups or updates.So: To save an existing user, or one where the client generates the id and it's been verified that the id is unique:Otherwise, use POST to initially create the object, and PUT to update the object:",
                "Both are used for data transmission between client to server, but there are subtle differences between them, which are:Analogy:Social Media/Network Analogy:",
                "Use POST to create, and PUT to update. That's how Ruby on Rails is doing it, anyway.",
                "REST is a very high-level concept. In fact, it doesn't even mention HTTP at all!If you have any doubts about how to implement REST in HTTP, you can always take a look at the Atom Publication Protocol (AtomPub) specification. AtomPub is a standard for writing RESTful webservices with HTTP that was developed by many HTTP and REST luminaries, with some input from Roy Fielding, the inventor of REST and (co-)inventor of HTTP himself.In fact, you might even be able to use AtomPub directly. While it came out of the blogging community, it is in no way restricted to blogging: it is a generic protocol for RESTfully interacting with arbitrary (nested) collections of arbitrary resources via HTTP. If you can represent your application as a nested collection of resources, then you can just use AtomPub and not worry about whether to use PUT or POST, what HTTP Status Codes to return and all those details.This is what AtomPub has to say about resource creation (section 9.2):To add members to a Collection, clients send POST requests to the URI of the Collection.",
                "The decision of whether to use PUT or POST to create a resource on a server with an HTTP + REST API is based on who owns the URL structure. Having the client know, or participate in defining, the URL struct is an unnecessary coupling akin to the undesirable couplings that arose from SOA. Escaping types of couplings is the reason REST is so popular. Therefore, the proper method to use is POST. There are exceptions to this rule and they occur when the client wishes to retain control over the location structure of the resources it deploys. This is rare and likely means something else is wrong.At this point some people will argue that if RESTful-URL's are used, the client does knows the URL of the resource and therefore a PUT is acceptable. After all, this is why canonical, normalized, Ruby on Rails, Django URLs are important, look at the Twitter API \u2026 blah blah blah. Those people need to understand there is no such thing as a Restful-URL and that Roy Fielding himself states that:A REST API must not define fixed resource names or hierarchies (an\nobvious coupling of client and server). Servers must have the freedom\nto control their own namespace. Instead, allow servers to instruct\nclients on how to construct appropriate URIs, such as is done in HTML\nforms and URI templates, by defining those instructions within media\ntypes and link relations. [Failure here implies that clients are\nassuming a resource structure due to out-of band information, such as\na domain-specific standard, which is the data-oriented equivalent to\nRPC's functional coupling].http://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-drivenThe idea of a RESTful-URL is actually a violation of REST as the server is in charge of the URL structure and should be free to decide how to use it to avoid coupling. If this confuses you read about the significance of self discovery on API design.Using POST to create resources comes with a design consideration because POST is not idempotent. This means that repeating a POST several times does not guarantee the same behavior each time. This scares people into using PUT to create resources when they should not. They know it's wrong (POST is for CREATE) but they do it anyway because they don't know how to solve this problem.  This concern is demonstrated in the following situation:Step 6 is where people commonly get confused about what to do. However, there is no reason to create a kludge to solve this issue. Instead, HTTP can be used as specified in RFC 2616 and the server replies:10.4.10 409 ConflictThe request could not be completed due to a conflict with the current\nstate of the resource. This code is only allowed in situations where\nit is expected that the user might be able to resolve the conflict and\nresubmit the request. The response body SHOULD include enoughinformation for the user to recognize the source of the conflict.\nIdeally, the response entity would include enough information for the\nuser or user agent to fix the problem; however, that might not be\npossible and is not required.Conflicts are most likely to occur in response to a PUT request. For\nexample, if versioning were being used and the entity being PUT\nincluded changes to a resource which conflict with those made by an\nearlier (third-party) request, the server might use the 409 response\nto indicate that it can\u2019t complete the request. In this case, the\nresponse entity would likely contain a list of the differences between\nthe two versions in a format defined by the response Content-Type.Replying with a status code of 409 Conflict is the correct recourse because:Update based on release of RFC 7231 to Replace 2616RFC 7231 is designed to replace 2616 and in Section 4.3.3 describes the follow possible response for a POSTIf the result of processing a POST would be equivalent to a\nrepresentation of an existing resource, an origin server MAY redirect\nthe user agent to that resource by sending a 303 (See Other) response\nwith the existing resource's identifier in the Location field.  This\nhas the benefits of providing the user agent a resource identifier\nand transferring the representation via a method more amenable to\nshared caching, though at the cost of an extra request if the user\nagent does not already have the representation cached.It now may be tempting to simply return a 303 in the event that a POST is repeated. However, the opposite is true. Returning a 303 would only make sense if multiple create requests (creating different resources) return the same content. An example would be a \"thank you for submitting your request message\" that the client need not re-download each time. RFC 7231 still maintains in section 4.2.2 that POST is not to be idempotent and continues to maintain that POST should be used for create.For more information about this, read this article.",
                "I like this advice, from RFC 2616's definition of PUT:The fundamental difference between the POST and PUT requests is reflected in the different meaning of the Request-URI. The URI in a POST request identifies the resource that will handle the enclosed entity. That resource might be a data-accepting process, a gateway to some other protocol, or a separate entity that accepts annotations. In contrast, the URI in a PUT request identifies the entity enclosed with the request -- the user agent knows what URI is intended and the server MUST NOT attempt to apply the request to some other resource.This jibes with the other advice here, that PUT is best applied to resources that already have a name, and POST is good for creating a new object under an existing resource (and letting the server name it).I interpret this, and the idempotency requirements on PUT, to mean that:",
                "In short:PUT is idempotent, where the resource state will be the same if the same operation is executed one time or multiple times.POST is non-idempotent, where the resource state may become different if the operation is executed multiple times as compared to executing a single time.PUT You can think of similar to \"UPDATE STUDENT SET address = \"abc\" where id=\"123\";POST You can think of something like \"INSERT INTO STUDENT(name, address) VALUES (\"abc\", \"xyzzz\");Student Id is auto generated.With PUT, if the same query is executed multiple times or one time, the STUDENT table state remains the same.In case of POST, if the same query is executed multiple times then multiple Student records get created in the database and the database state changes on each execution of an \"INSERT\" query.NOTE: PUT needs a resource location (already-resource) on which update needs to happen, whereas POST doesn't require that. Therefore intuitively POST is meant for creation of a new resource, whereas PUT is needed for updating the already existing resource.Some may come up with that updates can be performed with POST. There is no hard rule which one to use for updates or which one to use for create. Again these are conventions, and intuitively I'm inclined with the above mentioned reasoning and follow it.",
                "POST is like posting a letter to a mailbox or posting an email to an email queue.\nPUT is like when you put an object in a cubby hole or a place on a shelf (it has a known address).With POST, you're posting to the address of the QUEUE or COLLECTION. With PUT, you're putting to the address of the ITEM.PUT is idempotent. You can send the request 100 times and it will not matter. POST is not idempotent. If you send the request 100 times, you'll get 100 emails or 100 letters in your postal box.A general rule: if you know the id or name of the item, use PUT. If you want the id or name of the item to be assigned by the receiving party, use POST.",
                "Short Answer:Simple rule of thumb: Use POST to create, use PUT to update.Long Answer:POST:PUT:Longer Answer:To understand it we need to question why PUT was required, what were the problems PUT was trying to solve that POST couldn't.From a REST architecture's point of view there is none that matters. We could have lived without PUT as well. But from a client developer's point of view it made his/her life a lot simpler.Prior to PUT, clients couldn't directly know the URL that the server generated or if all it had generated any or whether the data to be sent to the server is already updated or not. PUT relieved the developer of all these headaches. PUT is idempotent, PUT handles race conditions, and PUT lets the client choose the URL.",
                "New answer (now that I understand REST better):PUT is merely a statement of what content the service should, from now on, use to render representations of the resource identified by the client; POST is a statement of what content the service should, from now on, contain (possibly duplicated) but it's up to the server how to identify that content.PUT x (if x identifies a resource): \"Replace the content of the resource identified by x with my content.\"PUT x (if x does not identify a resource): \"Create a new resource containing my content and use x to identify it.\"POST x: \"Store my content and give me an identifier that I can use to identify a resource (old or new) containing said content (possibly mixed with other content). Said resource should be identical or subordinate to that which x identifies.\" \"y's resource is subordinate to x's resource\" is typically but not necessarily implemented by making y a subpath of x (e.g. x = /foo and y = /foo/bar) and modifying the representation(s) of x's resource to reflect the existence of a new resource, e.g. with a hyperlink to y's resource and some metadata. Only the latter is really essential to good design, as URLs are opaque in REST -- you're supposed to use hypermedia instead of client-side URL construction to traverse the service anyways.In REST, there's no such thing as a resource containing \"content\". I refer as \"content\" to data that the service uses to render representations consistently. It typically consists of some related rows in a database or a file (e.g. an image file). It's up to the service to convert the user's content into something the service can use, e.g. converting a JSON payload into SQL statements.Original answer (might be easier to read):PUT /something (if /something already exists): \"Take whatever you have at /something and replace it with what I give you.\"PUT /something (if /something does not already exist): \"Take what I give you and put it at /something.\"POST /something: \"Take what I give you and put it anywhere you want under /something as long as you give me its URL when you're done.\"",
                "Ruby on Rails 4.0 will use the 'PATCH' method instead of PUT to do partial updates.RFC 5789 says about PATCH (since 1995):A new method is necessary to improve interoperability and prevent\n     errors.  The PUT method is already defined to overwrite a resource\n     with a complete new body, and cannot be reused to do partial changes.\n     Otherwise, proxies and caches, and even clients and servers, may get\n     confused as to the result of the operation.  POST is already used but\n     without broad interoperability (for one, there is no standard way to\n     discover patch format support).  PATCH was mentioned in earlier HTTP\n     specifications, but not completely defined.\"Edge Rails: PATCH is the new primary HTTP method for updates\" explains it.",
                "In addition to differences suggested by others, I want to add one more.In POST method you can send body params in form-dataIn PUT method you have to send body params in x-www-form-urlencodedHeader Content-Type:application/x-www-form-urlencodedAccording to this, you cannot send files or multipart data in the PUT methodEDITThe content type \"application/x-www-form-urlencoded\" is inefficient\n  for sending large quantities of binary data or text containing\n  non-ASCII characters. The content type \"multipart/form-data\" should be\n  used for submitting forms that contain files, non-ASCII data, and\n  binary data.Which means if you have to submitfiles, non-ASCII data, and binary datayou should use POST method",
                "At the risk of restating what has already been said, it seems important to remember that PUT implies that the client controls what the URL is going to end up being, when creating a resource. So part of the choice between PUT and POST is going to be about how much you can trust the client to provide correct, normalized URL that are coherent with whatever your URL scheme is.When you can't fully trust the client to do the right thing, it would be \nmore appropriate to use POST to create a new item and then send the URL back to the client in the response.",
                "In a very simple way I'm taking the example of the Facebook timeline.Case 1: When you post something on your timeline, it's a fresh new entry. So in this case they use the POST method because the POST method is non-idempotent.Case 2: If your friend comment on your post the first time, that also will create a new entry in the database so the POST method used.Case 3: If your friend edits his comment, in this case, they had a comment id, so they will update an existing comment instead of creating a new entry in the database. Therefore for this type of operation use the PUT method because it is idempotent.*In a single line, use POST to add a new entry in the database and PUT to update something in the database.",
                "The most important consideration is reliability. If a POST message gets lost the state of the system is undefined. Automatic recovery is impossible. For PUT messages, the state is undefined only until the first successful retry.For instance, it may not be a good idea to create credit card transactions with POST.If you happen to have auto generated  URI's on your resource you can still use PUT by passing a generated URI (pointing to an empty resource) to the client.Some other considerations:",
                "Readers new to this topic will be struck by the endless discussion about what you should do, and the relative absence of lessons from experience. The fact that REST is \"preferred\" over SOAP is, I suppose, a high-level learning from experience, but goodness we must have progressed from there? It's 2016. Roy's dissertation was in 2000. What have we developed? Was it fun? Was it easy to integrate with? To support? Will it handle the rise of smartphones and flaky mobile connections?According to ME, real-life networks are unreliable. Requests timeout. Connections are reset. Networks go down for hours or days at a time. Trains go into tunnels with mobile users aboard. For any given request (as occasionally acknowledged in all this discussion) the request can fall in the water on its way, or the response can fall in the water on its way back. In these conditions, issuing PUT, POST and DELETE requests directly against substantive resources has always struck me as a little brutal and naive.HTTP does nothing to ensure reliable completion of the request-response, and that's just fine because this is properly the job of network-aware applications. Developing such an application, you can jump through hoops to use PUT instead of POST, then more hoops to give a certain kind of error on the server if you detect duplicate requests. Back at the client, you then have to jump through hoops to interpret these errors, refetch, revalidate and repost.Or you can do this: consider your unsafe requests as ephemeral single-user resources (let's call them actions). Clients request a new \"action\" on a substantive resource with an empty POST to the resource. POST will be used only for this. Once safely in possession of the URI of the freshly minted action, the client PUTs the unsafe request to the action URI, not the target resource. Resolving the action and updating the \"real\" resource is properly the job of your API, and is here decoupled from the unreliable network.The server does the business, returns the response and stores it against the agreed action URI. If anything goes wrong, the client repeats the request (natural behaviour!), and if the server has already seen it, it repeats the stored response and does nothing else.You will quickly spot the similarity with promises: we create and return the placeholder for the result before doing anything. Also like a promise, an action can succeed or fail one time, but its result can be fetched repeatedly.Best of all, we give sending and receiving applications a chance to link the uniquely identified action to uniqueness in their respective environments. And we can start to demand, and enforce!, responsible behaviour from clients: repeat your requests as much as you like, but don't go generating a new action until you're in possession of a definitive result from the existing one.As such, numerous thorny problems go away. Repeated insert requests won't create duplicates, and we don't create the real resource until we're in possession of the data. (database columns can stay not-nullable). Repeated update requests won't hit incompatible states and won't overwrite subsequent changes. Clients can (re)fetch and seamlessy process the original confirmation for whatever reason (client crashed, response went missing, etc.).Successive delete requests can see and process the original confirmation, without hitting a 404 error. If things take longer than expected, we can respond provisionally, and we have a place where the client can check back for the definitive result. The nicest part of this pattern is its Kung-Fu (Panda) property. We take a weakness, the propensity for clients to repeat a request any time they don't understand the response, and turn it into a strength :-)Before telling me this is not RESTful, please consider the numerous ways in which REST principles are respected. Clients don't construct URLs. The API stays discoverable, albeit with a little change in semantics. HTTP verbs are used appropriately. If you think this is a huge change to implement, I can tell you from experience that it's not.If you think you'll have huge amounts of data to store, let's talk volumes: a typical update confirmation is a fraction of a kilobyte. HTTP currently gives you a minute or two to respond definitively. Even if you only store actions for a week, clients have ample chance to catch up. If you have very high volumes, you may want a dedicated acid-compliant key value store, or an in-memory solution.",
                "There seems to always be some confusion as to when to use the HTTP POST versus the HTTP PUT method for REST services. Most developers will try to associate CRUD operations directly to HTTP methods. I will argue that this is not correct and one can not simply associate the CRUD concepts to the HTTP methods. That is:It is true that the R(etrieve) and D(elete) of the CRUD operations can be mapped directly to the HTTP methods GET and DELETE respectively. However, the confusion lies in the C(reate) and U(update) operations. In some cases, one can use the PUT for a create while in other cases a POST will be required. The ambiguity lies in the definition of an HTTP PUT method versus an HTTP POST method.According to the HTTP 1.1 specifications the GET, HEAD, DELETE, and PUT methods must be idempotent, and the POST method is not idempotent. That is to say that an operation is idempotent if it can be performed on a resource once or many times and always return the same state of that resource. Whereas a non idempotent operation can return a modified state of the resource from one request to another. Hence, in a non idempotent operation, there is no guarantee that one will receive the same state of a resource.Based on the above idempotent definition, my take on using the HTTP PUT method versus using the HTTP POST method for REST services is:\nUse the HTTP PUT method when:In both cases, these operations can be performed multiple times with the same results. That is the resource will not be changed by requesting the operation more than once. Hence, a true idempotent operation.\nUse the HTTP POST method when:ConclusionDo not directly correlate and map CRUD operations to HTTP methods for REST services. The use of an HTTP PUT method versus an HTTP POST method should be based on the idempotent aspect of that operation. That is, if the operation is idempotent, then use the HTTP PUT method. If the operation is non idempotent, then use the HTTP POST method.",
                "the origin server can create the resource with that URISo you use POST and probably, but not necessary PUT for resource creation. You don't have to support both. For me POST is perfectly enough. So it is a design decision.As your quote mentioned, you use PUT for creation of there is no resource assigned to an IRI, and you want to create a resource anyway. For example, PUT /users/123/password usually replaces the old password with a new one, but you can use it to create a password if it does not exist already (for example, by freshly registered users or by restoring banned users).",
                "I'm going to land with the following:PUT refers to a resource, identified by the URI. In this case, you are updating it. It is the part of the three verbs referring to resources -- delete and get being the other two.POST is basically a free form message, with its meaning being defined 'out of band'. If the message can be interpreted as adding a resource to a directory, that would be OK, but basically you need to understand the message you are sending (posting) to know what will happen with the resource.Because PUT and GET and DELETE refer to a resource, they are also by definition idempotent.POST can perform the other three functions, but then the semantics of the request will be lost on the intermediaries such as caches and proxies. This also applies to providing security on the resource, since a post's URI doesn't necessarily indicate the resource it is applying to (it can though).A PUT doesn't need to be a create; the service could error if the resource isn't already created, but otherwise update it. Or vice versa -- it may create the resource, but not allow updates. The only thing required about PUT is that it points to a specific resource, and its payload is the representation of that resource. A successful PUT means (barring interference) that a GET would retrieve the same resource.Edit: One more thing -- a PUT can create, but if it does then the ID has to be a natural ID -- AKA an email address. That way when you PUT twice, the second put is an update of the first. This makes it idempotent.If the ID is generated (a new employee ID, for example), then the second PUT with the same URL would create a new record, which violates the idempotent rule. In this case the verb would be POST, and the message (not resource) would be to create a resource using the values defined in this message.",
                "Here's a simple rule:PUT to a URL should be used to update or create the resource that can be located at that URL.POST to a URL should be used to update or create a resource which is located at some other (\"subordinate\") URL, or is not locatable via HTTP.",
                "The semantics are supposed be different, in that \"PUT\", like \"GET\" is supposed to be idempotent -- meaning, you can the same exact PUT request multiple times and the result will be as if you executed it only once.I will describe the conventions which I think are most widely used and are most useful:When you PUT a resource at a particular URL what happens is that it should get saved at that URL, or something along those lines.When you POST to a resource at a particular URL, often you are posting a related piece of information to that URL. This implies that the resource at the URL already exists.For example, when you want to create a new stream, you can PUT it to some URL. But when you want to POST a message to an existing stream, you POST to its URL.As for modifying the properties of the stream, you can do that with either PUT or POST. Basically, only use \"PUT\" when the operation is idempotent - otherwise use POST.Note, however, that not all modern browsers support HTTP verbs other than GET or POST.",
                "Most of the time, you will use them like this:For example:In both cases, the request body contains the data for the resource to be created or updated. It should be obvious from the route names that POST is not idempotent (if you call it 3 times it will create 3 objects), but PUT is idempotent (if you call it 3 times the result is the same). PUT is often used for \"upsert\" operation (create or update), but you can always return a 404 error if you only want to use it to modify.Note that POST \"creates\" a new element in the collection, and PUT \"replaces\" an element at a given URL, but it is a very common practice to use PUT for partial modifications, that is, use it only to update existing resources and only modify the included fields in the body (ignoring the other fields). This is technically incorrect, if you want to be REST-purist, PUT should replace the whole resource and you should use PATCH for the partial update. I personally don't care much as far as the behavior is clear and consistent across all your API endpoints.Remember, REST is a set of conventions and guidelines to keep your API simple. If you end up with a complicated work-around just to check the \"RESTfull\" box then you are defeating the purpose ;)",
                "To me, the key of understanding the difference was to understand who defines the ID of the resource:Example (with some address service)There are many great answers with great details below, but that helped me to get to the point.",
                "If you are familiar with database operations,\nthere areI use PUT for Merge and update like operations and use POST for Insertions.",
                "While there is probably an agnostic way to describe these, it does seem to be conflicting with various statements from answers to websites.Let's be very clear and direct here. If you are a .NET developer working with Web API, the facts are (from the Microsoft API documentation),\nhttp://www.asp.net/web-api/overview/creating-web-apis/creating-a-web-api-that-supports-crud-operations:Sure you \"can\" use \"POST\" to update, but just follow the conventions laid out for you with your given framework. In my case it is .NET / Web API, so PUT is for UPDATE there is no debate.I hope this helps any Microsoft developers that read all comments with Amazon and Sun/Java website links."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I include a JavaScript file in another JavaScript file?",
                "How do I include a JavaScript file inside another JavaScript file, similar to @import in CSS?"
            ],
            "url": "https://stackoverflow.com/questions/950087",
            "answer": [
                "The old versions of JavaScript had no import, include, or require, so many different approaches to this problem have been developed.But since 2015 (ES6), JavaScript has had the ES6 modules standard to import modules in Node.js, which is also supported by most modern browsers.For compatibility with older browsers, build tools like Webpack and Rollup and/or transpilation tools like Babel can be used.ECMAScript (ES6) modules have been supported in Node.js since v8.5, with the --experimental-modules flag, and since at least Node.js v13.8.0 without the flag. To enable \"ESM\" (vs. Node.js's previous CommonJS-style module system [\"CJS\"]) you either use \"type\": \"module\" in package.json or give the files the extension .mjs. (Similarly, modules written with Node.js's previous CJS module can be named .cjs if your default is ESM.)Using package.json:Then module.js:Then main.js:Using .mjs, you'd have module.mjs:Then main.mjs:Browsers have had support for loading ECMAScript modules directly (no tools like Webpack required) since Safari 10.1, Chrome 61, Firefox 60, and Edge 16. Check the current support at caniuse. There is no need to use Node.js' .mjs extension; browsers completely ignore file extensions on modules/scripts.Read more at https://jakearchibald.com/2017/es-modules-in-browsers/Dynamic imports let the script load other scripts as needed:Read more at https://developers.google.com/web/updates/2017/11/dynamic-importThe older CJS module style, still widely used in Node.js, is the module.exports/require system.There are other ways for JavaScript to include external JavaScript contents in browsers that do not require preprocessing.You could load an additional script with an AJAX call and then use eval to run it. This is the most straightforward way, but it is limited to your domain because of the JavaScript sandbox security model. Using eval also opens the door to bugs, hacks and security issues.Like Dynamic Imports you can load one or many scripts with a fetch call using promises to control order of execution for script dependencies using the Fetch Inject library:The jQuery library provides loading functionality in one line:You could add a script tag with the script URL into the HTML. To avoid the overhead of jQuery, this is an ideal solution.The script can even reside on a different server. Furthermore, the browser evaluates the code. The <script> tag can be injected into either the web page <head>, or inserted just before the closing </body> tag.Here is an example of how this could work:This function will add a new <script> tag to the end of the head section of the page, where the src attribute is set to the URL which is given to the function as the first parameter.Both of these solutions are discussed and illustrated in JavaScript Madness: Dynamic Script Loading.Now, there is a big issue you must know about. Doing that implies that you remotely load the code. Modern web browsers will load the file and keep executing your current script because they load everything asynchronously to improve performance. (This applies to both the jQuery method and the manual dynamic script loading method.)It means that if you use these tricks directly, you won't be able to use your newly loaded code the next line after you asked it to be loaded, because it will be still loading.For example: my_lovely_script.js contains MySuperObject:Then you reload the page hitting F5. And it works! Confusing...So what to do about it ?Well, you can use the hack the author suggests in the link I gave you. In summary, for people in a hurry, he uses an event to run a callback function when the script is loaded. So you can put all the code using the remote library in the callback function. For example:Then you write the code you want to use AFTER the script is loaded in a lambda function:Then you run all that:Note that the script may execute after the DOM has loaded, or before, depending on the browser and whether you included the line script.async = false;. There's a great article on Javascript loading in general which discusses this.As mentioned at the top of this answer, many developers use build/transpilation tool(s) like Parcel, Webpack, or Babel in their projects, allowing them to use upcoming JavaScript syntax, provide backward compatibility for older browsers, combine files, minify, perform code splitting etc.",
                "If anyone is looking for something more advanced, try out RequireJS. You'll get added benefits such as dependency management, better concurrency, and avoid duplication (that is, retrieving a script more than once).You can write your JavaScript files in \"modules\" and then reference them as dependencies in other scripts. Or you can use RequireJS as a simple \"go get this script\" solution.Example:Define dependencies as modules:some-dependency.jsimplementation.js is your \"main\" JavaScript file that depends on some-dependency.jsExcerpt from the GitHub README:RequireJS loads plain JavaScript files as well as more defined\n  modules. It is optimized for in-browser use, including in a Web\n  Worker, but it can be used in other JavaScript environments, like\n  Rhino and Node. It implements the Asynchronous Module API.RequireJS uses plain script tags to load modules/files, so it should\n  allow for easy debugging. It can be used simply to load existing\n  JavaScript files, so you can add it to your existing project without\n  having to re-write your JavaScript files....",
                "There actually is a way to load a JavaScript file not asynchronously, so you could use the functions included in your newly loaded file right after loading it, and I think it works in all browsers.You need to use jQuery.append() on the <head> element of your page, that is:However, this method also has a problem: if an error happens in the imported JavaScript file, Firebug (and also Firefox Error Console and Chrome Developer Tools as well) will report its place incorrectly, which is a big problem if you use Firebug to track JavaScript errors down a lot (I do). Firebug simply doesn't know about the newly loaded file for some reason, so if an error occurs in that file, it reports that it occurred in your main HTML file, and you will have trouble finding out the real reason for the error.But if that is not a problem for you, then this method should work.I have actually written a jQuery plugin called $.import_js() which uses this method:So all you would need to do to import JavaScript is:I also made a simple test for this at Example.It includes a main.js file in the main HTML and then the script in main.js uses $.import_js() to import an additional file called included.js, which defines this function:And right after including included.js, the hello() function is called, and you get the alert.(This answer is in response to e-satis' comment).",
                "Another way, that in my opinion is much cleaner, is to make a synchronous Ajax request instead of using a <script> tag. Which is also how Node.js handles includes.Here's an example using jQuery:You can then use it in your code as you'd usually use an include:And be able to call a function from the required script in the next line:",
                "It is possible to dynamically generate a JavaScript tag and append it to HTML document from inside other JavaScript code. This will load targeted JavaScript file.",
                "There is a good news for you. Very soon you will be able to load JavaScript code easily. It will become a standard way of importing modules of JavaScript code and will be part of core JavaScript itself.You simply have to write import cond from 'cond.js'; to load a macro named cond from a file cond.js.So you don't have to rely upon any JavaScript framework nor do you have to explicitly make Ajax calls.Refer to:Static module resolutionModule loaders",
                "Statement import is in ECMAScript 6.Syntax",
                "Maybe you can use this function that I found on this page How do I include a JavaScript file in a JavaScript file?:",
                "Here is a synchronous version without jQuery:Note that to get this working cross-domain, the server will need to set allow-origin header in its response.",
                "I just wrote this JavaScript code (using Prototype for DOM manipulation):Usage:Gist: http://gist.github.com/284442.",
                "If you want it in pure JavaScript, you can use document.write.If you use the jQuery library, you can use the $.getScript method.",
                "Here's the generalized version of how Facebook does it for their ubiquitous Like button:<script>\r\n  var firstScript = document.getElementsByTagName('script')[0],\r\n      js = document.createElement('script');\r\n  js.src = 'https://cdnjs.cloudflare.com/ajax/libs/Snowstorm/20131208/snowstorm-min.js';\r\n  js.onload = function () {\r\n    // do stuff with your dynamically loaded script\r\n    snowStorm.snowColor = '#99ccff';\r\n  };\r\n  firstScript.parentNode.insertBefore(js, firstScript);\r\n</script>If it works for Facebook, it will work for you.The reason why we look for the first script element instead of head or body is because some browsers don't create one if missing, but we're guaranteed to have a script element - this one. Read more at http://www.jspatterns.com/the-ridiculous-case-of-adding-a-script-element/.",
                "You can also assemble your scripts using PHP:File main.js.php:",
                "Most of solutions shown here imply dynamical loading. I was searching instead for a compiler which assemble all the depended files into a single output file. The same as Less/Sass preprocessors deal with the CSS @import at-rule. Since I didn't find anything decent of this sort, I wrote a simple tool solving the issue.So here is the compiler, https://github.com/dsheiko/jsic, which replaces $import(\"file-path\") with the requested file content securely. Here is the corresponding Grunt plugin: https://github.com/dsheiko/grunt-jsic.On the jQuery master branch, they simply concatenate atomic source files into a single one starting with intro.js and ending with outtro.js. That doesn't suits me as it provides no flexibility on the source code design. Check out how it works with jsic:src/main.jssrc/Form/Input/Tel.jsNow we can run the compiler:And get the combined filebuild/main.js",
                "If your intention to load the JavaScript file is using the functions from the imported/included file, you can also define a global object and set the functions as object items. For instance:You just need to be careful when you are including scripts in an HTML file. The order should be as in below:",
                "This should do:",
                "Or rather than including at run time, use a script to concatenate prior to upload.I use Sprockets (I don't know if there are others). You build your JavaScript code in separate files and include comments that are processed by the Sprockets engine as includes. For development you can include files sequentially, then for production to merge them...See also:",
                "I had a simple issue, but I was baffled by responses to this question.I had to use a variable (myVar1) defined in one JavaScript file (myvariables.js) in another JavaScript file (main.js).For this I did as below:Loaded the JavaScript code in the HTML file, in the correct order, myvariables.js first, then main.js:File: myvariables.jsFile: main.jsAs you saw, I had use a variable in one JavaScript file in another JavaScript file, but I didn't need to include one in another. I just needed to ensure that the first JavaScript file loaded before the second JavaScript file, and, the first JavaScript file's variables are accessible in the second JavaScript file, automatically.This saved my day. I hope this helps.",
                "In a modern language with the check if script has already been loaded, it would be:Usage (async/await):orUsage (Promise):",
                "The @import syntax for achieving CSS-like JavaScript importing is possible using a tool such as Mixture via their special .mix file type (see here). I assume the application does this via one of above-mentioned methods.From the Mixture documentation on .mix files:Mix files are simply .js or .css files with .mix. in the file name. A\nmix file simply     extends the functionality of a normal style or\nscript file and allows you to import and combine.Here's an example .mix file that combines multiple .js files into one:Mixture outputs this as scripts-global.js and also as a minified version (scripts-global.min.js).Note: I'm not in any way affiliated with Mixture, other than using it as a front-end development tool. I came across this question upon seeing a .mix JavaScript file in action (in one of the Mixture boilerplates) and being a bit confused by it (\"you can do this?\" I thought to myself). Then I realized that it was an application-specific file type (somewhat disappointing, agreed). Nevertheless, figured the knowledge might be helpful for others.Note: Mixture was discontinued on 2016/07/26 (after being open sourced on 2015/04/12).",
                "In case you are using Web Workers and want to include additional scripts in the scope of the worker, the other answers provided about adding scripts to the head tag, etc. will not work for you.Fortunately, Web Workers have their own importScripts function which is a global function in the scope of the Web Worker, native to the browser itself as it is part of the specification.Alternatively, as the second highest voted answer to your question highlights, RequireJS can also handle including scripts inside a Web Worker (likely calling importScripts itself, but with a few other useful features).",
                "Yes, use type=\"module\" in a script tag (support):And in a script.js file include another file like this:In 'module.js' you must export the function/class that you will import:A working example is here.",
                "Although these answers are great, there is a simple \"solution\" that has been around since script loading existed, and it will cover 99.999% of most people's use cases. Just include the script you need before the script that requires it. For most projects it does not take long to determine which scripts are needed and in what order.If script2 requires script1, this really is the absolute easiest way to do something like this. I'm very surprised no-one has brought this up, as it's the most obvious and simplest answer that will apply in nearly every single case.",
                "My usual method is:It works great and uses no page-reloads for me. I've tried the AJAX method (one of the other answers) but it doesn't seem to work as nicely for me.Here's an explanation of how the code works for those that are curious: essentially, it creates a new script tag (after the first one) of the URL. It sets it to asynchronous mode so it doesn't block the rest of the code, but calls a callback when the readyState (the state of the content to be loaded) changes to 'loaded'.",
                "I wrote a simple module that automates the job of importing/including module scripts in JavaScript. For detailed explanation of the code, refer to the blog post JavaScript require / import / include modules.",
                "This script will add a JavaScript file to the top of any other <script> tag:",
                "Keep it nice, short, simple, and maintainable! :]This code is simply a short functional example that could require additional feature functionality for full support on any (or given) platform.",
                "I came to this question because I was looking for a simple way to maintain a collection of useful JavaScript plugins. After seeing some of the solutions here, I came up with this:Set up a file called \"plugins.js\" (or extensions.js or whatever you want). Keep your plugin files together with that one master file.plugins.js will have an array called pluginNames[] that we will iterate over each(),\nthen append a <script> tag to the head for each pluginBUT:Even though all of the plugins get dropped into the head tag the way they ought to, they don't always get run by the browser when you click into the page or refresh.I've found it's more reliable to just write the script tags in a PHP include. You only have to write it once and that's just as much work as calling the plugin using JavaScript.",
                "There are several ways to implement modules in JavaScript. Here are the two most popular ones:Browsers do not support this moduling system yet, so in order for you to use this syntax you must use a bundler like Webpack. Using a bundler is better anyway because this can combine all of your different files into a single (or a couple of related) files. This will serve the files from the server to the client faster because each HTTP request has some associated overhead accompanied with it. Thus by reducing the overall HTTP request we improve the performance. Here is an example of ES6 modules:This moduling system is used in Node.js. You basically add your exports to an object which is called module.exports. You then can access this object via a require('modulePath'). Important here is to realize that these modules are being cached, so if you require() a certain module twice it will return the already created module."
            ]
        },
        {
            "tag": "",
            "question": [
                "What is the difference between \"let\" and \"var\"?",
                "ECMAScript 6 introduced the let statement.\nI've heard that it's described as a local variable, but I'm still not quite sure how it behaves differently than the var keyword.\nWhat are the differences? ..."
            ],
            "url": "https://stackoverflow.com/questions/762011",
            "answer": [
                "The main difference is scoping rules. Variables declared by var keyword are scoped to the immediate function body (hence the function scope) while let variables are scoped to the immediate enclosing block denoted by { } (hence the block scope).function run() {\n  var foo = \"Foo\";\n  let bar = \"Bar\";\n\n  console.log(foo, bar); // Foo Bar\n\n  {\n    var moo = \"Mooo\"\n    let baz = \"Bazz\";\n    console.log(moo, baz); // Mooo Bazz\n  }\n\n  console.log(moo); // Mooo\n  console.log(baz); // ReferenceError\n}\n\nrun();The reason why let keyword was introduced to the language was function scope is confusing and was one of the main sources of bugs in JavaScript.Take a look at this example from another Stack Overflow question:var funcs = [];\n// let's create 3 functions\nfor (var i = 0; i < 3; i++) {\n  // and store them in funcs\n  funcs[i] = function() {\n    // each should log its value.\n    console.log(\"My value: \" + i);\n  };\n}\nfor (var j = 0; j < 3; j++) {\n  // and now let's run each one to see\n  funcs[j]();\n}My value: 3 was output to console each time funcs[j](); was invoked since anonymous functions were bound to the same variable.People had to create immediately invoked functions to capture correct values from the loops but that was also hairy.While variables declared with var keyword are hoisted (initialized with undefined before the code is run) which means they are accessible in their enclosing scope even before they are declared:function run() {\n  console.log(foo); // undefined\n  var foo = \"Foo\";\n  console.log(foo); // Foo\n}\n\nrun();let variables are not initialized until their definition is evaluated. Accessing them before the initialization results in a ReferenceError. The variable is said to be in \"temporal dead zone\" from the start of the block until the initialization is processed.function checkHoisting() {\n  console.log(foo); // ReferenceError\n  let foo = \"Foo\";\n  console.log(foo); // Foo\n}\n\ncheckHoisting();At the top level, let, unlike var, does not create a property on the global object:var foo = \"Foo\";  // globally scoped\nlet bar = \"Bar\"; // not allowed to be globally scoped\n\nconsole.log(window.foo); // Foo\nconsole.log(window.bar); // undefinedIn strict mode, var will let you re-declare the same variable in the same scope while let raises a SyntaxError.'use strict';\nvar foo = \"foo1\";\nvar foo = \"foo2\"; // No problem, 'foo1' is replaced with 'foo2'.\n\nlet bar = \"bar1\"; \nlet bar = \"bar2\"; // SyntaxError: Identifier 'bar' has already been declared",
                "let can also be used to avoid problems with closures. It binds fresh value rather than keeping an old reference as shown in examples below.for(var i=1; i<6; i++) {\r\n  $(\"#div\" + i).click(function () { console.log(i); });\r\n}\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\r\n<p>Clicking on each number will log to console:</p> \r\n<div id=\"div1\">1</div>\r\n<div id=\"div2\">2</div>\r\n<div id=\"div3\">3</div>\r\n<div id=\"div4\">4</div>\r\n<div id=\"div5\">5</div>Code above demonstrates a classic JavaScript closure problem. Reference to the i variable is being stored in the click handler closure, rather than the actual value of i.Every single click handler will refer to the same object because there\u2019s only one counter object which holds 6 so you get six on each click.A general workaround is to wrap this in an anonymous function and pass i as an argument. Such issues can also be avoided now by using let instead var as shown in the code below.(Tested in Chrome and Firefox 50)for(let i=1; i<6; i++) {\r\n  $(\"#div\" + i).click(function () { console.log(i); });\r\n}\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\r\n<p>Clicking on each number will log to console:</p> \r\n<div id=\"div1\">1</div>\r\n<div id=\"div2\">2</div>\r\n<div id=\"div3\">3</div>\r\n<div id=\"div4\">4</div>\r\n<div id=\"div5\">5</div>",
                "To understand the difference, consider the following code:Here, we can see that our variable j is only known in the first for loop, but not before and after. Yet, our variable i is known in the entire function.Also, consider that block scoped variables are not known before they are declared because they are not hoisted. You're also not allowed to redeclare the same block scoped variable within the same block. This makes block scoped variables less error prone than globally or functionally scoped variables, which are hoisted and which do not produce any errors in case of multiple declarations.Some people would argue that in the future we'll ONLY use let statements and that var statements will become obsolete. JavaScript guru Kyle Simpson wrote a very elaborate article on why he believes that won't be the case.Today, however, that is definitely not the case. In fact, we need actually to ask ourselves whether it's safe to use the let statement. The answer to that question depends on your environment:If you're writing server-side JavaScript code (Node.js), you can safely use the let statement.If you're writing client-side JavaScript code and use a browser based transpiler (like Traceur or babel-standalone), you can safely use the let statement, however your code is likely to be anything but optimal with respect to performance.If you're writing client-side JavaScript code and use a Node based transpiler (like the traceur shell script or Babel), you can safely use the let statement. And, because your browser will only know about the transpiled code, performance drawbacks should be limited.If you're writing client-side JavaScript code and don't use a transpiler, you need to consider browser support.There are still some browsers that don't support let at all :For an up-to-date overview of which browsers support the let statement at the time of your reading this answer, see this Can I Use page.(*) Globally and functionally scoped variables can be initialized and used before they are declared because JavaScript variables are hoisted. This means that declarations are always moved to the top of the scope.(**) Block scoped variables are not hoisted",
                "Here's an explanation of the let keyword with some examples.let works very much like var. The main difference is that the scope of a var variable is the entire enclosing functionThis table on Wikipedia shows which browsers support Javascript 1.7.Note that only Mozilla and Chrome browsers support it. IE, Safari, and potentially others don't.",
                "Variables declared using the let keyword are block-scoped, which means that they are available only in the block in which they were declared.At the top level, variables declared using let don't create properties on the global object.Inside a function (but outside of a block), let has the same scope as var.Variables declared using let inside a block can't be accessed outside that block.Variables declared with let in loops can be referenced only inside that loop.If you use let instead of var in a loop, with each iteration you get a new variable. That means that you can safely use a closure inside a loop.Because of the temporal dead zone, variables declared using let can't be accessed before they are declared. Attempting to do so throws an error.You can't declare the same variable multiple times using let. You also can't declare a variable using let with the same identifier as another variable which was declared using var.const is quite similar to let\u2014it's block-scoped and has TDZ. There are, however, two things which are different.Variable declared using const can't be re-assigned.Note that it doesn't mean that the value is immutable. Its properties still can be changed.If you want to have an immutable object, you should use Object.freeze().You always must specify a value when declaring a variable using const.",
                "The accepted answer is missing a point:",
                "\u26a1\ufe0f Sandbox to play around \u2193",
                "The main difference is the scope difference, while let can be only available inside the scope it's declared, like in for loop, var can be accessed outside the loop for example. From the documentation in MDN (examples also from MDN):let allows you to declare variables that are limited in scope to the block, statement, or expression on which it is used. This is unlike the var keyword, which defines a variable globally, or locally to an entire function regardless of block scope.Variables declared by let have as their scope the block in which they are defined, as well as in any contained sub-blocks. In this way, let works very much like var. The main difference is that the scope of a var variable is the entire enclosing function:At the top level of programs and functions, let, unlike var, does not create a property on the global object. For example:When used inside a block, let limits the variable's scope to that block. Note the difference between var whose scope is inside the function where it is declared.Also don't forget it's ECMA6 feature, so it's not fully supported yet, so it's better always transpiles it to ECMA5 using Babel etc... for more info about visit babel website",
                "Here is an example for the difference between the two (support just started for chrome):As you can see the var j variable is still having a value outside of the for loop scope (Block Scope), but the let i variable is undefined outside of the for loop scope.\"use strict\";\r\nconsole.log(\"var:\");\r\nfor (var j = 0; j < 2; j++) {\r\n  console.log(j);\r\n}\r\n\r\nconsole.log(j);\r\n\r\nconsole.log(\"let:\");\r\nfor (let i = 0; i < 2; i++) {\r\n  console.log(i);\r\n}\r\n\r\nconsole.log(i);",
                "There are some subtle differences \u2014 let scoping behaves more like variable scoping does in more or less any other languages.e.g. It scopes to the enclosing block, They don't exist before they're declared, etc.However it's worth noting that let is only a part of newer Javascript implementations and has varying degrees of browser support.",
                "Variable Not Hoistinglet will not hoist to the entire scope of the block they appear in. By contrast, var could hoist as below.Actually, Per @Bergi, Both var and let are hoisted.Garbage CollectionBlock scope of let is useful relates to closures and garbage collection to reclaim memory. Consider,The click handler callback does not need the hugeData variable at all. Theoretically, after process(..) runs, the huge data structure hugeData could be garbage collected. However, it's possible that some JS engine will still have to keep this huge structure, since the click function has a closure over the entire scope.However, the block scope can make this huge data structure to garbage collected.let loopslet in the loop can re-binds it to each iteration of the loop, making sure to re-assign it the value from the end of the previous loop iteration. Consider,However, replace var with letBecause let create a new lexical environment with those names for a) the initialiser expression b) each iteration (previosly to evaluating the increment expression), more details are here.",
                "The difference is in the scope of the variables declared with each.In practice, there are a number of useful consequences of the difference in scope:The restrictions imposed by let reduce the visibility of the variables and increase the likelihood that unexpected name collisions will be found early.  This makes it easier to track and reason about variables, including their reachability(helping with reclaiming unused memory).Consequently, let variables are less likely to cause problems when used in large programs or when independently-developed frameworks are combined in new and unexpected ways.var may still be useful if you are sure you want the single-binding effect when using a closure in a loop (#5) or for declaring externally-visible global variables in your code (#4).  Use of var for exports may be supplanted if export migrates out of transpiler space and into the core language.1. No use outside nearest enclosing block:\nThis block of code will throw a reference error because the second use of x occurs outside of the block where it is declared with let:In contrast, the same example with var works.2. No use before declaration:\nThis block of code will throw a ReferenceError before the code can be run because x is used before it is declared:In contrast, the same example with var parses and runs without throwing any exceptions.3. No redeclaration:\nThe following code demonstrates that a variable declared with let may not be redeclared later:4. Globals not attached to window:5. Easy use with closures:\nVariables declared with var do not work well with closures inside loops.  Here is a simple loop that outputs the sequence of values that the variable i has at different points in time:Specifically, this outputs:In JavaScript we often use variables at a significantly later time than when they are created.  When we demonstrate this by delaying the output with a closure passed to setTimeout:... the output remains unchanged as long as we stick with let.  In contrast, if we had used var i instead:... the loop unexpectedly outputs \"i is 5\" five times:",
                "Here's an example to add on to what others have already written. Suppose you want to make an array of functions, adderFunctions, where each function takes a single Number argument and returns the sum of the argument and the function's index in the array. Trying to generate adderFunctions with a loop using the var keyword won't work the way someone might na\u00efvely expect:The process above doesn't generate the desired array of functions because i's scope extends beyond the iteration of the for block in which each function was created. Instead, at the end of the loop, the i in each function's closure refers to i's value at the end of the loop (1000) for every anonymous function in adderFunctions. This isn't what we wanted at all: we now have an array of 1000 different functions in memory with exactly the same behavior. And if we subsequently update the value of i, the mutation will affect all the adderFunctions.However, we can try again using the let keyword:This time, i is rebound on each iteration of the for loop. Each function now keeps the value of i at the time of the function's creation, and adderFunctions behaves as expected.Now, image mixing the two behaviors and you'll probably see why it's not recommended to mix the newer let and const with the older var in the same script. Doing so can result is some spectacularly confusing code.Don't let this happen to you. Use a linter.NOTE: This is a teaching example intended to demonstrate the var/let behavior in loops and with function closures that would also be easy to understand. This would be a terrible way to add numbers. But the general technique of capturing data in anonymous function closures might be encountered in the real world in other contexts. YMMV.",
                "May the following two functions show the difference:",
                "ES6 introduced two new keyword(let and const) alternate to var.When you need a block level deceleration you can go with let and const instead of var.The below table summarize the difference between var, let and const",
                "The main difference between var and let is that variables declared with var are function scoped. Whereas functions declared with let are block scoped. For example:variables with var:When the first function testVar gets called the variable foo, declared with var, is still accessible outside the if statement. This variable foo would be available everywhere within the scope of the testVar function.variables with let:When the second function testLet gets called the variable bar, declared with let, is only accessible inside the if statement. Because variables declared with let are block scoped (where a block is the code between curly brackets e.g if{} , for{}, function{}).Another difference between var and let is variables with declared with let don't get hoisted. An example is the best way to illustrate this behavior:variables with let don't get hoisted:variables with var do get hoisted:A variable declared with let in the global scope (which is code that is not in a function) doesn't get added as a property on the global window object. For example (this code is in global scope):When should let be used over var?Use let over var whenever you can because it is simply scoped more specific. This reduces potential naming conflicts which can occur when dealing with a large number of variables. var can be used when you want a global variable explicitly to be on the window object (always consider carefully if this is really necessary).",
                "let is interesting, because it allows us to do something like this:Which results in counting [0, 7].WhereasOnly counts [0, 1].",
                "It also appears that, at least in Visual Studio 2015, TypeScript 1.5, \"var\" allows multiple declarations of the same variable name in a block, and \"let\" doesn't.This won't generate a compile error:This will:",
                "This explanation was taken from an article I wrote at Medium:Hoisting is a JavaScript mechanism where variables and function\ndeclarations are moved to the top of their scope by the parser which\nreads the source code into an intermediate representation before the\nactual code execution starts by the JavaScript interpreter. So, it actually\ndoesn\u2019t matter where variables or functions are declared, they will be\nmoved to the top of their scope regardless of whether their scope is\nglobal or local. This means thatis actually interpreted toSo, as we saw just now, var variables are being hoisted to the top\nof their scope and are being initialized with the value of undefined\nwhich means that we can actually assign their value before actually\ndeclaring them in the code like so:Regarding function declarations, we can invoke them before actually declaring them like so:Function expressions, on the other hand, are not hoisted, so we\u2019ll get the following error:ES6 introduced JavaScript developers the let and const keywords. While let and const are block-scoped and not function\nscoped as var it shouldn\u2019t make a difference while discussing their\nhoisting behavior. We\u2019ll start from the end, JavaScript hoists let\nand const.As we can see above, let doesn\u2019t allow us to use undeclared\nvariables, hence the interpreter explicitly output a reference error\nindicating that the hi variable cannot be accessed before\ninitialization. The same error will occur if we change the above let\nto constSo, bottom line, the JavaScript parser searches for variable\ndeclarations and functions and hoists them to the top of their scope\nbefore code execution and assign values to them in the memory so in\ncase the interpreter will encounter them while executing the code he\nwill recognize them and will be able to execute the code with their\nassigned values. Variables declared with let or const remain\nuninitialized at the beginning of execution while that variables\ndeclared with var are being initialized with a value of undefined.I added this visual illustration to help understanding of how are the hoisted\nvariables and function are being saved in the memory",
                "var is global scope (hoist-able) variable.let and const is block scope.test.js{\r\n    let l = 'let';\r\n    const c = 'const';\r\n    var v = 'var';\r\n    v2 = 'var 2';\r\n}\r\n\r\nconsole.log(v, this.v);\r\nconsole.log(v2, this.v2);\r\nconsole.log(l); // ReferenceError: l is not defined\r\nconsole.log(c); // ReferenceError: c is not defined",
                "varIn this code sample, variable i is declared using var. Therefore, it has a function scope. It means you can access i from only inside the function x. You can't read it from outside the function xfunction x(){\n  var i = 100;\n  console.log(i); // 100\n}\n \nconsole.log(i); // Error. You can't do this\n\nx();In this sample, you can see i is declared inside a if block. But it's declared using var. Therefore, it gets function scope. It means still you can access variable i inside function x. Because var always get scoped to functions. Even though variable i is declared inside if block, because of it's using var it get scoped to parent function x.function x(){\n  if(true){\n    var i = 100;\n  }\n  console.log(i); \n}\n\nx();Now variable i is declared inside the function y. Therefore, i scoped to function y. You can access i inside function y. But not from outside function y.function x(){\n  function y(){\n    var i = 100;\n    console.log(i);\n  }\n  \n  y();\n}\n\nx();function x(){\n  function y(){\n    var i = 100;\n  }\n  console.log(i); // ERROR\n}\n\nx();let, constlet and const has block scope.const and let behave same. But the difference is, when you assign value to const you can't re-assign. But you can re-assign values with let.In this example, variable i is declared inside an if block. So it can be only accessed from inside that if block. We can't access it from outside that if block. (here const work same as let)if(true){\n  let i = 100;\n  console.log(i); // Output: 100\n}\n\nconsole.log(i); // Errorfunction x(){\n  if(true){\n    let i = 100;\n    console.log(i); // Output: 100\n  }\n  console.log(i); // Error\n}\n\nx();Another difference with (let, const) vs var is you can access var defined variable before declaring it. It will give you undefined. But if you do that with let or const defined variable it will give you an error.console.log(x);\nvar x = 100;console.log(x); // ERROR\nlet x = 100;",
                "If I read the specs right then let thankfully can also be leveraged to avoid self invoking functions used to simulate private only members - a popular design pattern that decreases code readability, complicates debugging, that adds no real code protection or other benefit - except maybe satisfying someone's desire for semantics, so stop using it. /rantSee 'Emulating private interfaces'",
                "When Using letThe let keyword attaches the variable declaration to the scope of whatever block (commonly a { .. } pair) it's contained in. In other words,let implicitly hijacks any block's scope for its variable declaration.let variables cannot be accessed in the window object because they cannot be globally accessed.When Using varvar and variables in ES5 has scopes in functions meaning the variables are valid within the function and not outside the function itself.var variables can be accessed in the window object because they cannot be globally accessed.If you want to know more continue reading belowone of the most famous interview questions on scope also can suffice the exact use of let and var as below;When using letThis is because when using let, for every loop iteration the variable is scoped and has its own copy.When using varThis is because when using var, for every loop iteration the variable is scoped and has shared copy.",
                "Some hacks with let:1.2.3.",
                "let vs var. It's all about scope.var variables are global and can be accessed basically everywhere, while let variables are not global and only exist until a closing parenthesis kills them.See my example below, and note how the lion (let) variable acts differently in the two console.logs; it becomes out of scope in the 2nd console.log.",
                "I just came across one use case that I had to use var over let to introduce new variable. Here's a case:I want to create a new variable with dynamic variable names.The above code doesn't work because eval introduces a new block of code. The declaration using var will declare a variable outside of this block of code since var declares a variable in the function scope.let, on the other hand, declares a variable in a block scope. So, a variable will only be visible in eval block.",
                "The below shows how 'let' and 'var' are different in the scope:The gfoo, defined by let initially is in the global scope, and when we declare gfoo again inside the if clause its scope changed and when a new value is assigned to the variable inside that scope it does not affect the global scope.Whereas hfoo, defined by var is initially in the global scope, but again when we declare it inside the if clause, it considers the global scope hfoo, although var has been used again to declare it. And when we re-assign its value we see that the global scope hfoo is also affected. This is the primary difference.",
                "let is a part of es6. These functions will explain the difference in easy way.",
                "As mentioned above:The difference is scoping. var is scoped to the nearest function\n  block and let is scoped to the nearest enclosing block, which\n  can be smaller than a function block. Both are global if outside any\n  block.Lets see an example:Example1:In my both examples I have a function myfunc. myfunc contains a variable myvar equals to 10. \nIn my first example  I check   if myvar equals to 10 (myvar==10) . If yes, I agian declare  a variable  myvar (now I have two myvar variables)using var keyword and assign it a new value (20). In next line I  print its value on my console.  After the conditional block I again print the value of myvar on my console. If you look at the output of myfunc,   myvar has value equals to 20.Example2:\nIn my second example  instead of using var keyword in my conditional block I declare myvar using let keyword . Now when I call myfunc  I get two different outputs: myvar=20 and myvar=10.So the difference is very simple i.e its scope.",
                "As I am currently trying to get an in depth understanding of JavaScript I will share my brief research which contains some of the great pieces already discussed plus some other details in a different perspective.Understanding the difference between var and let can be easier if we understand the difference between function and block scope.Let's consider the following cases:when timer() gets called an ExecutionContext is created which will contain both the VariableEnvironment and all the LexicalEnvironments corresponding to each iteration.And a simpler exampleFunction ScopeBlock Scope"
            ]
        },
        {
            "tag": "",
            "question": [
                "How to disable text selection highlighting",
                "For anchors that act like buttons (for example, the buttons on the sidebar of this Stack\u00a0Overflow page titled Questions, Tags, and Users) or tabs, is there a CSS standard way to disable the ..."
            ],
            "url": "https://stackoverflow.com/questions/826782",
            "answer": [
                "UPDATE January, 2017:According to Can I use, the user-select + -webkit-user-select for Safari is enough to achieve desired behavior in all major browsers.These are all of the available correct CSS variations:.noselect {\n  -webkit-touch-callout: none; /* iOS Safari */\n    -webkit-user-select: none; /* Safari */\n     -khtml-user-select: none; /* Konqueror HTML */\n       -moz-user-select: none; /* Old versions of Firefox */\n        -ms-user-select: none; /* Internet Explorer/Edge */\n            user-select: none; /* Non-prefixed version, currently\n                                  supported by Chrome, Edge, Opera and Firefox */\n}\n<p>\n  Selectable text.\n</p>\n<p class=\"noselect\">\n  Unselectable text.\n</p>Note that user-select is in standardization process (currently in a W3C working draft). It is not guaranteed to work everywhere and there might be differences in implementation among browsers. Also, browsers can drop support for it in the future.More information can be found in Mozilla Developer Network documentation.The values of this attribute are none, text, toggle, element, elements, all and inherit.",
                "In most browsers, this can be achieved using proprietary variations on the CSS user-select property, originally proposed and then abandoned in CSS\u00a03 and now proposed in CSS UI Level 4:For Internet Explorer < 10 and Opera < 15, you will need to use the unselectable attribute of the element you wish to be unselectable. You can set this using an attribute in HTML:Sadly this property isn't inherited, meaning you have to put an attribute in the start tag of every element inside the <div>. If this is a problem, you could instead use JavaScript to do this recursively for an element's descendants:Update 30 April 2014: This tree traversal needs to be rerun whenever a new element is added to the tree, but it seems from a comment by @Han that it is possible to avoid this by adding a mousedown event handler that sets unselectable on the target of the event. See http://jsbin.com/yagekiji/1 for details.This still doesn't cover all possibilities. While it is impossible to initiate selections in unselectable elements, in some browsers (Internet\u00a0Explorer and Firefox, for example) it's still impossible to prevent selections that start before and end after the unselectable element without making the whole document unselectable.",
                "Until CSS 3's user-select property becomes available, Gecko-based browsers support the -moz-user-select property you already found. WebKit and Blink-based browsers support the -webkit-user-select property.This of course is not supported in browsers that do not use the Gecko rendering engine.There is no \"standards\" compliant quick-and-easy way to do it; using JavaScript is an option.The real question is, why do you want users to not be able to highlight and presumably copy and paste certain elements? I have not come across a single time that I wanted to not let users highlight a certain portion of my website. Several of my friends, after spending many hours reading and writing code will use the highlight feature as a way to remember where on the page they were, or providing a marker so that their eyes know where to look next.The only place I could see this being useful is if you have buttons for forms that should not be copy and pasted if a user copy and pasted the website.",
                "A JavaScript solution for Internet\u00a0Explorer is:",
                "If you want to disable text selection on everything except on <p> elements, you can do this in CSS (watch out for the -moz-none which allows override in sub-elements, which is allowed in other browsers with none):",
                "In the solutions in previous answers selection is stopped, but the user still thinks you can select text because the cursor still changes. To keep it static, you'll have to set your CSS cursor:.noselect {\r\n    cursor: default;\r\n    -webkit-touch-callout: none;\r\n    -webkit-user-select: none;\r\n    -khtml-user-select: none;\r\n    -moz-user-select: none;\r\n    -ms-user-select: none;\r\n    user-select: none;\r\n}\n<p>\r\n  Selectable text.\r\n</p>\r\n<p class=\"noselect\">\r\n  Unselectable text.\r\n</p>This will make your text totally flat, like it would be in a desktop application.",
                "You can do so in Firefox and Safari (Chrome also?)",
                "Workaround for WebKit:I found it in a CardFlip example.",
                "I like the hybrid CSS + jQuery solution.To make all elements inside <div class=\"draggable\"></div> unselectable, use this CSS:And then, if you're using jQuery, add this inside a $(document).ready() block:I figure you still want any input elements to be interactable, hence the :not() pseudo-selector. You could use '*' instead if you don't care.Caveat: Internet\u00a0Explorer\u00a09 may not need this extra jQuery piece, so you may want to add a version check in there.",
                ".hidden:after {\r\n    content: attr(data-txt);\r\n}\n<p class=\"hidden\" data-txt=\"Some text you don't want to be selected\"></p>It's not the best way, though.",
                "You can use CSS or JavaScript for that.The JavaScript way is supported in older browsers, like old versions of Internet\u00a0Explorer as well, but if it's not your case, use the CSS way then:HTML/JavaScript:<html onselectstart='return false;'>\r\n  <body>\r\n    <h1>This is the Heading!</h1>\r\n    <p>And I'm the text, I won't be selected if you select me.</p>\r\n  </body>\r\n</html>HTML/CSS:.not-selectable {\r\n  -webkit-touch-callout: none;\r\n  -webkit-user-select: none;\r\n  -khtml-user-select: none;\r\n  -moz-user-select: none;\r\n  -ms-user-select: none;\r\n  user-select: none;\r\n}\n<body class=\"not-selectable\">\r\n  <h1>This is the Heading!</h1>\r\n  <p>And I'm the text, I won't be selected if you select me.</p>\r\n</body>",
                "For Internet Explorer in addition, you need to add pseudo class focus (.ClassName:focus) and outline-style: none.",
                "Try to insert these rows into the CSS and call the \"disHighlight\" at class property:",
                "A Quick Hack UpdateIf you use the value none for all the CSS user-select properties (including browser prefixes of it), there is a problem which can be still occurred by this.As CSS-Tricks says, the problem is:WebKit still allows the text to be copied, if you select elements around it.You can also use the below one to enforce that an entire element gets selected which means if you click on an element, all the text wrapped in that element will get selected. For this all you have to do is changing the value none to all.",
                "You can do this with a mixin:In an HTML tag:Try it in this CodePen.If you are using an autoprefixer you can remove other prefixes.Browser compatibility here.",
                "For those who have trouble achieving the same in the Android browser with the touch event, use:",
                "If you are using Less and Bootstrap you could write:",
                "Aside from the Mozilla-only property, no, there is no way to disable text selection with just standard CSS (as of now).If you notice, Stack Overflow doesn't disable text selection for their navigation buttons, and I would recommend against doing so in most cases, since it modifies normal selection behavior and makes it conflict with a user's expectations.",
                "This works in some browsers:Simply add your desired elements/ids in front of the selectors separated by commas without spaces, like so:The other answers are better; this should probably be seen as a last resort/catchall.",
                "Suppose there are two divs like this:.second {\r\n  cursor: default;\r\n  user-select: none;\r\n  -webkit-user-select: none;\r\n  /* Chrome/Safari/Opera */\r\n  -moz-user-select: none;\r\n  /* Firefox */\r\n  -ms-user-select: none;\r\n  /* Internet Explorer/Edge */\r\n  -webkit-touch-callout: none;\r\n  /* iOS Safari */\r\n}\n<div class=\"first\">\r\n  This is my first div\r\n</div>\r\n\r\n<div class=\"second\">\r\n  This is my second div\r\n</div>Set cursor to default so that it will give a unselectable feel to the user.Prefix need to be used to support it in all browsers. Without a prefix this may not work in all the answers.",
                "This will be useful if color selection is also not needed:...all other browser fixes. It will work in Internet\u00a0Explorer\u00a09 or later.",
                "Add this to the first div in which you want to disable the selection for text:",
                "NOTE:The correct answer is correct in that it prevents you from being able to select the text. However, it does not prevent you from being able to copy the text, as I'll show with the next couple of screenshots (as of 7th Nov 2014).As you can see, we were unable to select the numbers, but we were able to copy them.Tested on: Ubuntu, Google Chrome 38.0.2125.111.",
                "It is easily done with:Alternatively:Let's say you have a <h1 id=\"example\">Hello, World!</h1>. You will have to remove the innerHTML of that h1, in this case Hello, World. Then you will have to go to CSS and do this:Now it simply thinks it is a block-element, and not text.",
                "To get the result I needed, I found I had to use both ::selection and user-select",
                "This is not CSS, but it is worth a mention:jQuery UI Disable Selection:",
                "Check my solution without JavaScript:jsFiddleli:hover {\r\n    background-color: silver;\r\n}\r\n#id1:before {\r\n    content: \"File\";\r\n}\r\n#id2:before {\r\n    content: \"Edit\";\r\n}\r\n#id3:before {\r\n    content: \"View\";\r\n}\n<ul>\r\n    <li><a id=\"id1\" href=\"www.w1.com\"></a>\r\n    <li><a id=\"id2\" href=\"www.w2.com\"></a>\r\n    <li><a id=\"id3\" href=\"www.w3.com\"></a>\r\n</ul>Popup menu with my technique applied: http://jsfiddle.net/y4Lac/2/",
                "Though this pseudo-element was in drafts of CSS Selectors Level 3, it was removed during the Candidate Recommendation phase, as it appeared that its behavior was under-specified, especially with nested elements, and interoperability wasn't achieved.It's being discussed in How ::selection works on nested elements.Despite it is being implemented in browsers, you can make an illusion of text not being selected by using the same color and background color on selection as of the tab design (in your case).Disallowing users to select the text will raise usability issues.",
                "I have learned from the CSS-Tricks website.And this also:"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I discard unstaged changes in Git?",
                "How do I discard changes in my working copy that are not in the index?"
            ],
            "url": "https://stackoverflow.com/questions/52704",
            "answer": [
                "For all unstaged files in current working directory use:For a specific file use:That together with git switch replaces the overloaded git checkout (see here), and thus removes the argument disambiguation.If a file has both staged and unstaged changes, only the unstaged changes shown in git diff are reverted. Changes shown in git diff --staged stay intact.Before Git 2.23For all unstaged files in current working directory:For a specific file:-- here to remove ambiguity (this is known as  argument disambiguation).",
                "Another quicker way is:You don't need to include --include-untracked if you don't want to be thorough about it.After that, you can drop that stash with a git stash drop command if you like.",
                "It seems like the complete solution is:WARNING: while it won't delete ignored files mentioned directly in .gitignore, git clean -df may delete ignored files residing in folders.git clean removes all untracked files and git checkout clears all unstaged changes.",
                "This checks out the current index for the current directory, throwing away all changes in files from the current directory downwards.or this which checks out all files from the index, overwriting working tree files.",
                "Cleans the working tree by recursively removing files that are not under version control, starting from the current directory.-d: Remove untracked directories in addition to untracked files-f: Force (might be not necessary depending on  clean.requireForce setting)Run git help clean to see the manual",
                "You can now discard unstaged changes in one tracked file with:and in all tracked files in the current directory (recursively) with:If you run the latter from the root of the repository, it will discard unstaged changes in all tracked files in the project.",
                "My favorite isThat lets you selectively revert chunks.See also:",
                "Since no answer suggests the exact option combination that I use, here it is:This is the online help text for the used git clean options:-dRemove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository, it is not removed by default. Use -f option twice if you really want to remove such a directory.-xDon\u2019t use the standard ignore rules read from .gitignore (per directory) and $GIT_DIR/info/exclude, but do still use the ignore rules given with -e options. This allows removing all untracked files, including build products. This can be used (possibly in conjunction with git reset) to create a pristine working directory to test a clean build.-nDon\u2019t actually remove anything, just show what would be done.-fIf the Git configuration variable clean.requireForce is not set to false, Git clean will refuse to delete files or directories unless given -f, -n, or -i. Git will refuse to delete directories within the .git subdirectory or file, unless a second -f is given.",
                "If you merely wish to remove changes to existing files, use checkout (documented here).If you want to remove files added since your last commit, use clean (documented here):If you wish to move changes to a holding space for later access, use stash (documented here):",
                "The easiest way to do this is by using this command:This command is used to discard changes in working directory -https://git-scm.com/docs/git-checkoutIn git command, stashing of untracked files is achieved by using:http://git-scm.com/docs/git-stash",
                "I really found this article helpful for explaining when to use what command: http://www.szakmeister.net/blog/2011/oct/12/reverting-changes-git/There are a couple different cases:If you haven't staged the file, then you use git checkout.  Checkout \"updates files in the working tree to match the version in the index\".  If the files have not been staged (aka added to the index)... this command will essentially revert the files to what your last commit was.git checkout -- foo.txtIf you have staged the file, then use git reset.  Reset changes the index to match a commit.git reset -- foo.txtI suspect that using git stash is a popular choice since it's a little less dangerous.  You can always go back to it if you accidently blow too much away when using git reset.  Reset is recursive by default.Take a look at the article above for further advice.",
                "If you aren't interested in keeping the unstaged changes (especially if the staged changes are new files), I found this handy:",
                "As you type git status, \n(use \"git checkout -- ...\" to discard changes in working directory)\nis shown.e.g. git checkout -- .",
                "You can use git stash - if something goes wrong, you can still revert from the stash.\nSimilar to some other answer here, but this one also removes all unstaged files and also all unstaged deletes:if you check that everything is OK, throw the stash away:The answer from Bilal Maqsood with git clean also worked for me, but with the stash I have more control - if I do sth accidentally, I can still get my changes backUPDATEI think there is 1 more change (don't know why this worked for me before):git add . -A instead of git add .without the -A the removed files will not be staged",
                "git checkout -fman git-checkout:-f, --forceWhen switching branches, proceed even if the index or the working tree differs from HEAD. This is used to throw away local changes.When checking out paths from the index, do not fail upon unmerged entries; instead, unmerged entries are ignored.",
                "Instead of discarding changes, I reset my remote to the origin. Note - this method is to completely restore your folder to that of the repo.So I do this to make sure they don't sit there when I git reset (later - excludes gitignores on the Origin/branchname)NOTE: If you want to keep files not yet tracked, but not in GITIGNORE you may wish to skip this step, as it will Wipe these untracked files not found on your remote repository (thanks @XtrmJosh).Then IThen I reset to originThat will put it back to square one. Just like RE-Cloning the branch, WHILE keeping all my gitignored files locally and in place.Updated per user comment below:\nVariation to reset the to whatever current branch the user is on.",
                "Tried all the solutions above but still couldn't get rid of new, unstaged files.Use git clean -f to remove those new files - with caution though! Note the force option.",
                "To do a permanent discard:\ngit reset --hardTo save changes for later:\ngit stash",
                "Just use:Done. Easy.If you really care about your stash stack then you can follow with git stash drop. But at that point you're better off using (from Mariusz Nowak):Nonetheless, I like git stash -u the best because it \"discards\" all tracked and untracked changes in just one command. Yet git checkout -- . only discards tracked changes,\nand git clean -df only discards untracked changes... and typing both commands is far too much work :)",
                "simply sayIt will remove all your local changes. You also can use later by sayingor \n    git stash pop",
                "you have a very simple git command git checkout .",
                "This works even in directories that are; outside of normal git permissions.Happened to me recently",
                "No matter what state your repo is in you can always reset to any previous commit:This will discard all changes which were made after that commit.",
                "In my opinion,should do the trick. As per Git documentation on git cleangit-clean - Remove untracked files from the working treeDescriptionCleans the working tree by recursively removing files that\n  are not under version control, starting from the current directory.Normally, only files unknown to Git are removed, but if the -x option\n  is specified, ignored files are also removed. This can, for example,\n  be useful to remove all build products.If any optional ... arguments are given, only those paths are\n  affected.Options-d Remove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository, it is\n  not removed by default. Use -f option twice if you really want to\n  remove such a directory.-f\n  --force If the Git configuration variable clean.requireForce is not set to false, git clean will refuse to run unless given -f, -n or -i.",
                "Another way to get rid of new files that is more specific than git clean -df (it will allow you to get rid of some files not necessarily all), is to add the new files to the index first, then stash, then drop the stash.This technique is useful when, for some reason, you can't easily delete all of the untracked files by some ordinary mechanism (like rm).",
                "What follows is really only a solution if you are working with a fork of a repository where you regularly synchronize (e.g. pull request) with another repo. Short answer: delete fork and refork, but read the warnings on github.I had a similar problem, perhaps not identical, and I'm sad to say my solution is not ideal, but it is ultimately effective.I would often have git status messages like this (involving at least 2/4 files):A keen eye will note that these files have dopplegangers that are a single letter in case off. Somehow, and I have no idea what led me down this path to start with (as I was not working with these files myself from the upstream repo), I had switched these files. Try the many solutions listed on this page (and other pages) did not seem to help.I was able to fix the problem by deleting my forked repository and all local repositories, and reforking. This alone was not enough; upstream had to rename the files in question to new filenames. As long as you don't have any uncommited work, no wikis, and no issues that diverge from the upstream repository, you should be just fine. Upstream may not be very happy with you, to say the least. As for my problem, it is undoubtedly a user error as I'm not that proficient with git, but the fact that it is far from easy to fix points to an issue with git as well.",
                "I had a weird situation where a file is always unstaged, this helps me to resolve.git rm .gitattributes\n  git add -A\n  git reset --hard",
                "When you want to transfer a stash to someone else:[edit] as commented, it \u00eds possible to name stashes. Well, use this if you want to share your stash ;)",
                "You could create your own alias which describes how to do it in a descriptive way.I use the next alias to discard changes.Then you can use it as next to discard all changes:Or just a file:Otherwise, if you want to discard all changes and also the untracked files, I use a mix of checkout and clean:So the use is simple as next:Now is available in the next Github repo which contains a lot of aliases:"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I get the directory where a Bash script is located from within the script itself?",
                "How do I get the path of the directory in which a Bash script is located, inside that script?\nI want to use a Bash script as a launcher for another application. I want to change the working directory ..."
            ],
            "url": "https://stackoverflow.com/questions/59895",
            "answer": [
                "is a useful one-liner which will give you the full directory name of the script no matter where it is being called from.It will work as long as the last component of the path used to find the script is not a symlink (directory links are OK).  If you also want to resolve any links to the script itself, you need a multi-line solution:This last one will work with any combination of aliases, source, bash -c, symlinks, etc.Beware: if you cd to a different directory before running this snippet, the result may be incorrect!Also, watch out for $CDPATH gotchas, and stderr output side effects if the user has smartly overridden cd to redirect output to stderr instead (including escape sequences, such as when calling update_terminal_cwd >&2 on Mac). Adding >/dev/null 2>&1 at the end of your cd command will take care of both possibilities.To understand how it works, try running this more verbose form:And it will print something like:",
                "Use dirname \"$0\":Using pwd alone will not work if you are not running the script from the directory it is contained in.",
                "The dirname command is the most basic, simply parsing the path up to the filename off of the $0 (script name) variable:But, as matt b pointed out, the path returned is different depending on how the script is called. pwd doesn't do the job because that only tells you what the current directory is, not what directory the script resides in. Additionally, if a symbolic link to a script is executed, you're going to get a (probably relative) path to where the link resides, not the actual script.Some others have mentioned the readlink command, but at its simplest, you can use:readlink will resolve the script path to an absolute path from the root of the filesystem. So, any paths containing single or double dots, tildes and/or symbolic links will be resolved to a full path.Here's a script demonstrating each of these, whatdir.sh:Running this script in my home dir, using a relative path:Again, but using the full path to the script:Now changing directories:And finally using a symbolic link to execute the script:There is however one case where this doesn't work, when the script is sourced (instead of executed) in bash:",
                "It works for all versions, includingAlternatively, if the Bash script itself is a relative symlink you want to follow it and return the full path of the linked-to script:SCRIPT_PATH is given in full path, no matter how it is called.Just make sure you locate this at start of the script.",
                "You can use $BASH_SOURCE:Note that you need to use #!/bin/bash and not #!/bin/sh since it's a Bash extension.",
                "Short answer:or (preferably):",
                "Here is an easy-to-remember script:",
                "This should do it:This works with symlinks and spaces in path.Please see the man pages for dirname and realpath.Please add a comment on how to support MacOS. I'm sorry I can verify it.",
                "pwd can be used to find the current working directory, and dirname to find the directory of a particular file (command that was run, is $0, so dirname $0 should give you the directory of the current script).However, dirname gives precisely the directory portion of the filename, which more likely than not is going to be relative to the current working directory. If your script needs to change directory for some reason, then the output from dirname becomes meaningless.I suggest the following:This way, you get an absolute, rather than a relative directory.Since the script will be run in a separate Bash instance, there isn't any need to restore the working directory afterwards, but if you do want to change back in your script for some reason, you can easily assign the value of pwd to a variable before you change directory, for future use.Although justsolves the specific scenario in the question, I find having the absolute path to more more useful generally.",
                "I don't think this is as easy as others have made it out to be.  pwd doesn't work, as the current directory is not necessarily the directory with the script.  $0 doesn't always have the information either.  Consider the following three ways to invoke a script:In the first and third ways $0 doesn't have the full path information.  In the second and third, pwd does not work.  The only way to get the directory in the third way would be to run through the path and find the file with the correct match.  Basically the code would have to redo what the OS does.One way to do what you are asking would be to just hardcode the data in the /usr/share directory, and reference it by its full path.  Data shoudn't be in the /usr/bin directory anyway, so this is probably the thing to do.",
                "This gets the current working directory on Mac\u00a0OS\u00a0X\u00a0v10.6.6 (Snow\u00a0Leopard):",
                "This is Linux specific, but you could use:",
                "Here is a POSIX compliant one-liner:",
                "The shortest and most elegant way to do this is:This would work on all platforms and is super clean.More details can be found in \"Which directory is that bash script in?\".",
                "...even when the called script is called from within another bash function or script, or when nested sourcing is being used!For many cases, all you need to acquire is the full path to the script you just called. This can be easily accomplished using realpath. Note that realpath is part of GNU coreutils. If you don't have it already installed (it comes default on Ubuntu), you can install it with sudo apt update && sudo apt install coreutils.get_script_path.sh (for the latest version of this script, see get_script_path.sh in my eRCaGuy_hello_world repo):IMPORTANT note on nested source calls: if \"${BASH_SOURCE[-1]}\" above doesn't give you quite what you want, try using \"${BASH_SOURCE[0]}\" instead. The first (0) index gives you the first entry in the array, and the last (-1) index gives you the last last entry in the array. Depending on what it is you're after, you may actually want the first entry. I discovered this to be the case when I sourced ~/.bashrc with . ~/.bashrc, which sourced ~/.bash_aliases with . ~/.bash_aliases, and I wanted the realpath (with expanded symlinks) to the ~/.bash_aliases file, NOT to the ~/.bashrc file. Since these are nested source calls, using \"${BASH_SOURCE[0]}\" gave me what I wanted: the expanded path to ~/.bash_aliases! Using \"${BASH_SOURCE[-1]}\", however, gave me what I did not want: the expanded path to ~/.bashrc.Example command and output:If you use \"$0\" in the script instead of \"${BASH_SOURCE[-1]}\", you'll get the same output as above when running the script, but this undesired output instead when sourcing the script:And, apparently if you use \"$BASH_SOURCE\" instead of \"${BASH_SOURCE[-1]}\", it will not work if the script is called from within another bash function. So, using \"${BASH_SOURCE[-1]}\" is therefore the best way to do it, as it solves both of these problems! See the references below.Difference between realpath and realpath -s:Note that realpath also successfully walks down symbolic links to determine and point to their targets rather than pointing to the symbolic link. If you do NOT want this behavior (sometimes I don't), then add -s to the realpath command above, making that line look like this instead:This way, symbolic links are NOT expanded. Rather, they are left as-is, as symbolic links in the full path.The code above is now part of my eRCaGuy_hello_world repo in this file here: bash/get_script_path.sh. Reference and run this file for full examples both with and withOUT symlinks in the paths. See the bottom of the file for example output in both cases.BASH_SOURCEAn array variable whose members are the source filenames where the corresponding shell function names in the FUNCNAME array variable are defined. The shell function ${FUNCNAME[$i]} is defined in the file ${BASH_SOURCE[$i]} and called from ${BASH_SOURCE[$i+1]}.",
                "Here is the simple, correct way:Explanation:${BASH_SOURCE[0]} - the full path to the script. The value of this will be correct even when the script is being sourced, e.g. source <(echo 'echo $0') prints bash, while replacing it with ${BASH_SOURCE[0]} will print the full path of the script. (Of course, this assumes you're OK taking a dependency on Bash.)readlink -f - Recursively resolves any symlinks in the specified path. This is a GNU extension, and not available on (for example) BSD systems. If you're running a Mac, you can use Homebrew to install GNU coreutils and supplant this with greadlink -f.And of course dirname gets the parent directory of the path.",
                "I tried all of these and none worked. One was very close, but it had a tiny bug that broke it badly; they forgot to wrap the path in quotation marks.Also a lot of people assume you're running the script from a shell, so they forget when you open a new script it defaults to your home.Try this directory on for size:This gets it right regardless how or where you run it:So to make it actually useful, here's how to change to the directory of the running script:",
                "This is a slight revision to the solution e-satis and 3bcdnlklvc04a pointed out in their answer:This should still work in all the cases they listed.This will prevent popd after a failed pushd. Thanks to konsolebox.",
                "I would use something like this:",
                "For systems having GNU coreutils readlink (for example, Linux):There's no need to use BASH_SOURCE when $0 contains the script filename.",
                "Try using:",
                "$_ is worth mentioning as an alternative to $0.  If you're running a script from Bash, the accepted answer can be shortened to:Note that this has to be the first statement in your script.",
                "These are short ways to get script information:Folders and files:Using these commands:And I got this output:Also see: https://pastebin.com/J8KjxrPF",
                "This works in Bash 3.2:If you have a ~/bin directory in your $PATH, you have  A inside this directory. It sources the script ~/bin/lib/B. You know where the included script is relative to the original one, in the lib subdirectory, but not where it is relative to the user's current directory.This is solved by the following (inside A):It doesn't matter where the user is or how he/she calls the script. This will always work.",
                "I've compared many of the answers given, and came up with some more compact solutions. These seem to handle all of the crazy edge cases that arise from your favorite combination of:If you're running from Linux, it seems that using the proc handle is the best solution to locate the fully resolved source of the currently running script (in an interactive session, the link points to the respective /dev/pts/X):This has a small bit of ugliness to it, but the fix is compact and easy to understand. We aren't using bash primitives only, but I'm okay with that because readlink simplifies the task considerably. The echo X adds an X to the end of the variable string so that any trailing whitespace in the filename doesn't get eaten, and the parameter substitution ${VAR%X} at the end of the line gets rid of the X. Because readlink adds a newline of its own (which would normally be eaten in the command substitution if not for our previous trickery), we have to get rid of that, too. This is most easily accomplished using the $'' quoting scheme, which lets us use escape sequences such as \\n to represent newlines (this is also how you can easily make deviously named directories and files).The above should cover your needs for locating the currently running script on Linux, but if you don't have the proc filesystem at your disposal, or if you're trying to locate the fully resolved path of some other file, then maybe you'll find the below code helpful. It's only a slight modification from the above one-liner. If you're playing around with strange directory/filenames, checking the output with both ls and readlink is informative, as ls will output \"simplified\" paths, substituting ? for things like newlines.",
                "I believe I've got this one. I'm late to the party, but I think some will appreciate it being here if they come across this thread. The comments should explain:",
                "Try the following cross-compatible solution:As the commands such as realpath or readlink could be not available (depending on the operating system).Note: In Bash, it's recommended to use ${BASH_SOURCE[0]} instead of $0, otherwise path can break when sourcing the file (source/.).Alternatively you can try the following function in Bash:This function takes one argument. If argument has already absolute path, print it as it is, otherwise print $PWD variable + filename argument (without ./ prefix).Related:"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I execute a program or call a system command?",
                "How do I call an external command within Python as if I had typed it in a shell or command prompt?"
            ],
            "url": "https://stackoverflow.com/questions/89228",
            "answer": [
                "Use the subprocess module in the standard library:The advantage of subprocess.run over os.system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...).Even the documentation for os.system recommends using subprocess instead:The subprocess module provides more powerful facilities for spawning new processes and retrieving their results; using that module is preferable to using this function. See the Replacing Older Functions with the subprocess Module section in the subprocess documentation for some helpful recipes.On Python 3.4 and earlier, use subprocess.call instead of .run:",
                "Here is a summary of ways to call external programs, including their advantages and disadvantages:os.system passes the command and arguments to your system's shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example:However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, et cetera. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.os.popen will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don't need to worry about escaping anything. Example:subprocess.Popen. This is intended as a replacement for os.popen, but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you'd say:instead ofbut it is nice to have all of the options there in one unified class instead of 4 different popen functions. See the documentation.subprocess.call. This is basically just like the Popen class and takes all of the same arguments, but it simply waits until the command completes and gives you the return code. For example:subprocess.run. Python 3.5+ only. Similar to the above but even more flexible and returns a CompletedProcess object when the command finishes executing.os.fork, os.exec, os.spawn are similar to their C language counterparts, but I don't recommend using them directly.The subprocess module should probably be what you use.Finally, please be aware that for all methods where you pass the final command to be executed by the shell as a string and you are responsible for escaping it. There are serious security implications if any part of the string that you pass can not be fully trusted. For example, if a user is entering some/any part of the string. If you are unsure, only use these methods with constants. To give you a hint of the implications consider this code:and imagine that the user enters something \"my mama didnt love me && rm -rf /\" which could erase the whole filesystem.",
                "Typical implementation:You are free to do what you want with the stdout data in the pipe.  In fact, you can simply omit those parameters (stdout= and stderr=) and it'll behave like os.system().",
                "Some hints on detaching the child process from the calling one (starting the child process in background).Suppose you want to start a long task from a CGI script. That is, the child process should live longer than the CGI script execution process.The classical example from the subprocess module documentation is:The idea here is that you do not want to wait in the line 'call subprocess' until the longtask.py is finished. But it is not clear what happens after the line 'some more code here' from the example.My target platform was FreeBSD, but the development was on Windows, so I faced the problem on Windows first.On Windows (Windows\u00a0XP), the parent process will not finish until the longtask.py has finished its work. It is not what you want in a CGI script. The problem is not specific to Python; in the PHP community the problems are the same.The solution is to pass DETACHED_PROCESS Process Creation Flag to the underlying CreateProcess function in Windows API.\nIf you happen to have installed pywin32, you can import the flag from the win32process module, otherwise you should define it yourself:/* UPD 2015.10.27 @eryksun in a comment below notes, that the semantically correct flag is CREATE_NEW_CONSOLE (0x00000010) */On FreeBSD we have another problem: when the parent process is finished, it finishes the child processes as well. And that is not what you want in a CGI script either. Some experiments showed that the problem seemed to be in sharing sys.stdout. And the working solution was the following:I have not checked the code on other platforms and do not know the reasons of the behaviour on FreeBSD. If anyone knows, please share your ideas. Googling on starting background processes in Python does not shed any light yet.",
                "Note that this is dangerous, since the command isn't cleaned. I leave it up to you to google for the relevant documentation on the 'os' and 'sys' modules. There are a bunch of functions (exec* and spawn*) that will do similar things.",
                "I'd recommend using the subprocess module instead of os.system because it does shell escaping for you and is therefore much safer.",
                "If you want to return the results of the command, you can use os.popen. However, this is deprecated since version 2.6 in favor of the subprocess module, which other answers have covered well.",
                "There are lots of different libraries which allow you to call external commands with Python. For each library I've given a description and shown an example of calling an external command. The command I used as the example is ls -l (list all files). If you want to find out more about any of the libraries I've listed and linked the documentation for each of them.Hopefully this will help you make a decision on which library to use :)Subprocess allows you to call external commands and connect them to their input/output/error pipes (stdin, stdout, and stderr). Subprocess is the default choice for running commands, but sometimes other modules are better.os is used for \"operating system dependent functionality\". It can also be used to call external commands with os.system and os.popen (Note: There is also a subprocess.popen). os will always run the shell and is a simple alternative for people who don't need to, or don't know how to use subprocess.run.sh is a subprocess interface which lets you call programs as if they were functions. This is useful if you want to run a command multiple times.plumbum is a library for \"script-like\" Python programs. You can call programs like functions as in sh. Plumbum is useful if you want to run a pipeline without the shell.pexpect lets you spawn child applications, control them and find patterns in their output. This is a better alternative to subprocess for commands that expect a tty on Unix.fabric is a Python 2.5 and 2.7 library. It allows you to execute local and remote shell commands. Fabric is simple alternative for running commands in a secure shell (SSH)envoy is known as \"subprocess for humans\". It is used as a convenience wrapper around the subprocess module.commands contains wrapper functions for os.popen, but it has been removed from Python 3 since subprocess is a better alternative.",
                "Use the subprocess module (Python 3):It is the recommended standard way. However, more complicated tasks (pipes, output, input, etc.) can be tedious to construct and write.Note on Python version: If you are still using Python 2, subprocess.call works in a similar way.ProTip: shlex.split can help you to parse the command for run, call, and other subprocess functions in case you don't want (or you can't!) provide them in form of lists:If you do not mind external dependencies, use plumbum:It is the best subprocess wrapper. It's cross-platform, i.e. it works on both Windows and Unix-like systems. Install by pip install plumbum.Another popular library is sh:However, sh dropped Windows support, so it's not as awesome as it used to be. Install by pip install sh.",
                "I always use fabric for this things like:But this seem to be a good tool: sh (Python subprocess interface).Look at an example:",
                "Check the \"pexpect\" Python library, too.It allows for interactive controlling of external programs/commands, even ssh, ftp, telnet, etc. You can just type something like:",
                "If you need the output from the command you are calling,\nthen you can use subprocess.check_output (Python 2.7+).Also note the shell parameter.If shell is True, the specified command will be executed through the shell. This can be useful if you are using Python primarily for the enhanced control flow it offers over most system shells and still want convenient access to other shell features such as shell pipes, filename wildcards, environment variable expansion, and expansion of ~ to a user\u2019s home directory. However, note that Python itself offers implementations of many shell-like features (in particular, glob, fnmatch, os.walk(), os.path.expandvars(), os.path.expanduser(), and shutil).",
                "subprocess.run is the recommended approach as of Python 3.5 if your code does not need to maintain compatibility with earlier Python versions. It's more consistent and offers similar ease-of-use as Envoy. (Piping isn't as straightforward though. See this question for how.)Here's some examples from the documentation.Run a process:Raise on failed run:Capture output:I recommend trying Envoy. It's a wrapper for subprocess, which in turn aims to replace the older modules and functions. Envoy is subprocess for humans.Example usage from the README:Pipe stuff around too:",
                "This is how I run my commands. This code has everything you need pretty much",
                "Simple, use subprocess.run, which returns a CompletedProcess object:(run wants a list of lexically parsed shell arguments - this is what you'd type in a shell, separated by spaces, but not where the spaces are quoted, so use a specialized function, split, to split up what you would literally type into your shell)As of Python 3.5, the documentation recommends subprocess.run:The recommended approach to invoking subprocesses is to use the run() function for all use cases it can handle. For more advanced use cases, the underlying Popen interface can be used directly.Here's an example of the simplest possible usage - and it does exactly as asked:run waits for the command to successfully finish, then returns a CompletedProcess object. It may instead raise TimeoutExpired (if you give it a timeout= argument) or CalledProcessError (if it fails and you pass check=True).As you might infer from the above example, stdout and stderr both get piped to your own stdout and stderr by default.We can inspect the returned object and see the command that was given and the returncode:If you want to capture the output, you can pass subprocess.PIPE to the appropriate stderr or stdout:And those respective attributes return bytes.One might easily move from manually providing a command string (like the question suggests) to providing a string built programmatically. Don't build strings programmatically. This is a potential security issue. It's better to assume you don't trust the input.Note, only args should be passed positionally.Here's the actual signature in the source and as shown by help(run):The popenargs and kwargs are given to the Popen constructor. input can be a string of bytes (or unicode, if specify encoding or universal_newlines=True) that will be piped to the subprocess's stdin.The documentation describes timeout= and check=True better than I could:The timeout argument is passed to Popen.communicate(). If the timeout\nexpires, the child process will be killed and waited for. The\nTimeoutExpired exception will be re-raised after the child process has\nterminated.If check is true, and the process exits with a non-zero exit code, a\nCalledProcessError exception will be raised. Attributes of that\nexception hold the arguments, the exit code, and stdout and stderr if\nthey were captured.and this example for check=True is better than one I could come up with:Here's an expanded signature, as given in the documentation:Note that this indicates that only the args list should be passed positionally. So pass the remaining arguments as keyword arguments.When use Popen instead? I would struggle to find use-case based on the arguments alone. Direct usage of Popen would, however, give you access to its methods, including poll, 'send_signal', 'terminate', and 'wait'.Here's the Popen signature as given in the source. I think this is the most precise encapsulation of the information (as opposed to help(Popen)):But more informative is the Popen documentation:Execute a child program in a new process. On POSIX, the class uses\nos.execvp()-like behavior to execute the child program. On Windows,\nthe class uses the Windows CreateProcess() function. The arguments to\nPopen are as follows.Understanding the remaining documentation on Popen will be left as an exercise for the reader.",
                "Use subprocess....or for a very simple command:",
                "As of Python 3.7.0 released on June 27th 2018 (https://docs.python.org/3/whatsnew/3.7.html), you can achieve your desired result in the most powerful while equally simple way. This answer intends to show you the essential summary of various options in a short manner. For in-depth answers, please see the other ones.The big advantage of os.system(...) was its simplicity. subprocess is better and still easy to use, especially as of Python 3.5.Note: This is the exact answer to your question - running a commandlike in a shellIf possible, remove the shell overhead and run the command directly (requires a list).Pass program arguments in a list. Don't include \\\"-escaping for arguments containing spaces.The following code speaks for itself:result.stdout is all normal program output excluding errors. Read result.stderr to get them.capture_output=True - turns capturing on. Otherwise result.stderr and result.stdout would be None. Available from Python 3.7.text=True - a convenience argument added in Python 3.7 which converts the received binary data to Python strings you can easily work with.DoIf you just want to check if the program succeeded (returncode == 0) and otherwise throw an Exception, there is a more convenient function:But it's Python, so there's an even more convenient argument check which does the same thing automatically for you:You might want to have all program output inside stdout, even errors. To accomplish this, runresult.stderr will then be None and result.stdout will contain everything.shell=False expects a list of arguments. You might however, split an argument string on your own using shlex.That's it.Chances are high you just started using Python when you come across this question. Let's look at some common problems.FileNotFoundError: [Errno 2] No such file or directory: 'ls -a': 'ls -a'You're running a subprocess without shell=True . Either use a list ([\"ls\", \"-a\"]) or set shell=True.TypeError: [...] NoneType [...]Check that you've set capture_output=True.TypeError: a bytes-like object is required, not [...]You always receive byte results from your program. If you want to work with it like a normal string, set text=True.subprocess.CalledProcessError: Command '[...]' returned non-zero exit status 1.Your command didn't run successfully. You could disable returncode checking or check your actual program's validity.TypeError: init() got an unexpected keyword argument [...]You're likely using a version of Python older than 3.7.0; update it to the most recent one available. Otherwise there are other answers in this Stack Overflow post showing you older alternative solutions.",
                "os.system is OK, but kind of dated.  It's also not very secure.  Instead, try subprocess.  subprocess does not call sh directly and is therefore more secure than os.system.Get more information here.",
                "There is also Plumbum",
                "Use:os - This module provides a portable way of using operating system-dependent functionality.For the more os functions, here is the documentation.",
                "It can be this simple:",
                "There is another difference here which is not mentioned previously.subprocess.Popen executes the <command> as a subprocess. In my case, I need to execute file <a> which needs to communicate with another program, <b>.I tried subprocess, and execution was successful. However <b> could not communicate with <a>.\nEverything is normal when I run both from the terminal.One more: \n(NOTE: kwrite behaves different from other applications. If you try the below with Firefox, the results will not be the same.)If you try os.system(\"kwrite\"), program flow freezes until the user closes kwrite. To overcome that I tried instead os.system(konsole -e kwrite). This time program continued to flow, but kwrite became the subprocess of the console.Anyone runs the kwrite not being a subprocess (i.e. in the system monitor it must appear at the leftmost edge of the tree).",
                "os.system does not allow you to store results, so if you want to store results in some list or something, a subprocess.call works.",
                "subprocess.check_call is convenient if you don't want to test return values. It throws an exception on any error.",
                "I tend to use subprocess together with shlex (to handle escaping of quoted strings):",
                "I wrote a library for this, shell.py.It's basically a wrapper for popen and shlex for now. It also supports piping commands, so you can chain commands easier in Python. So you can do things like:",
                "In Windows you can just import the subprocess module and run external commands by calling subprocess.Popen(), subprocess.Popen().communicate() and subprocess.Popen().wait() as below:Output:",
                "Under Linux, in case you would like to call an external command that will execute independently (will keep running after the Python script terminates), you can use a simple queue as task spooler or the at command.An example with task spooler:Notes about task spooler (ts):You could set the number of concurrent processes to be run (\"slots\") with:ts -S <number-of-slots>Installing ts doesn't requires admin privileges. You can download and compile it from source with a simple make, add it to your path and you're done.",
                "Invoke is a Python (2.7 and 3.4+) task execution tool and library. It provides a clean, high-level API for running shell commands:",
                "You can use Popen, and then you can check the procedure's status:Check out subprocess.Popen."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I change the URI (URL) for a remote Git repository?",
                "I have a repo (origin) on a USB key that I cloned on my hard drive (local). I moved \"origin\" to a NAS and successfully tested cloning it from here.\nI would like to know if I can change the ..."
            ],
            "url": "https://stackoverflow.com/questions/2432764",
            "answer": [
                "You canSee git help remote. You also can edit .git/config and change the URLs there.You're not in any danger of losing history unless you do something very silly (and if you're worried, just make a copy of your repo, since your repo is your history.)",
                "Changing a remote's URL",
                "git remote set-url {name} {url}",
                "Change Host for a Git Origin Serverfrom: http://pseudofish.com/blog/2010/06/28/change-host-for-a-git-origin-server/Hopefully this isn\u2019t something you need to do. The server that I\u2019ve been using to collaborate on a few git projects with had the domain name expire. This meant finding a way of migrating the local repositories to get back in sync.Update: Thanks to @mawolf for pointing out there is an easy way with recent git versions (post Feb, 2010):See the man page for details.If you\u2019re on an older version, then try this:As a caveat, this works only as it is the same server, just with different names.Assuming that the new hostname is newhost.com, and the old one was oldhost.com, the change is quite simple.Edit the .git/config file in your working directory. You should see something like:Change oldhost.com to newhost.com, save the file and you\u2019re done.From my limited testing (git pull origin; git push origin; gitx) everything seems in order. And yes, I know it is bad form to mess with git internals.",
                "This is very easy and simple; just follow these instructions.",
                "Open Terminal.Ist Step:- Change the current working directory to your local project.2nd Step:- List your existing remotes in order to get the name of the remote you want to change.git remote -vChange your remote's URL from HTTPS to SSH with the git remote set-url command.3rd Step:-  git remote set-url origin git@github.com:USERNAME/REPOSITORY.git4th Step:- Now Verify that the remote URL has changed.git remote -v\nVerify new remote URL",
                "(alternatively, open .git/config, look for [remote \"origin\"], and edit the url = line.You can check it worked by examining the remotes:Next time you push, you'll have to specify the new upstream branch, e.g.:See also: GitHub: Changing a remote's URL",
                "As seen here,",
                "First you need to type this command to view existing remotesgit remote -vThen second you need to type this command to Change the 'origin' remote's URLgit remote set-url origin <paste your GitHub URL>",
                "Write the below command from your repo terminal:Refer this link for more details about changing the url in the remote.",
                "To check git remote connection:Now, set the local repository to remote git:Now to make it upstream or push use following code:git push --set-upstream origin master -f",
                "Navigate to the project root of the local repository and check for existing remotes:If your repository is using SSH you will see something like:And if your repository is using HTTPS you will see something like:Changing the URL is done with git remote set-url. Depending on the output of git remote -v, you can change the URL in the following manner:In case of SSH, you can change the URL from REPOSITORY.git to NEW_REPOSITORY.git like:And in case of HTTPS, you can change the URL from REPOSITORY.git to NEW_REPOSITORY.git like:NOTE: If you've changed your GitHub username, you can follow the same process as above to update the change in the username associated with your repository. You would only have to update the USERNAME in the git remote set-url command.",
                "if you cloned your local will automatically consist,remote URL where it gets  cloned.you can check  it using git remote -vif you want to made change in it,here,origin - your branchif you want to overwrite existing branch you can still use it.. it will override your existing ... it will do,for you...",
                "Troubleshooting :You may encounter these errors when trying to changing a remote.\nNo such remote '[name]'This error means that the remote you tried to change doesn't exist:git remote set-url sofake https://github.com/octocat/Spoon-Knife\nfatal: No such remote 'sofake'Check that you've correctly typed the remote name.Reference : https://help.github.com/articles/changing-a-remote-s-url/",
                "I worked:",
                "In the Git Bash, enter the command:git remote set-url origin https://NewRepoLink.gitEnter the CredentialsDone",
                "You have a lot of ways to do that:ConsoleJust be sure that you've opened it in a place where a repository is.ConfigIt is placed in .git/config (same folder as repository)TortoiseGitThen just edit URL.SourceTreeClick on the \"Settings\" button on the toolbar to open the Repository Settings window.Click \"Add\" to add a remote repository path to the repository. A \"Remote details\" window will open.Enter a name for the remote path.Enter the URL/Path for the remote repositoryEnter the username for the hosting service for the remote repository.Click 'OK' to add the remote path.Back on the Repository Settings window, click 'OK'. The new remote path should be added on the repository now.If you need to edit an already added remote path, just click the 'Edit' button. You should be directed to the \"Remote details\" window where you can edit the details (URL/Path/Host Type) of the remote path.To remove a remote repository path, click the 'Remove' buttonref. Support",
                "For me, the accepted answer worked only in the case of fetch but not pull. I did the following to make it work for push as well.So to update the fetch URL:To update the pull URL:",
                "Change remote git URI to git@github.com rather than https://github.comExample:The benefit is that you may do git push automatically when you use ssh-agent :Put a script file $HOME/.ssh/agent to let it runs ssh-add using expect as below:",
                "To change the remote upstream:\ngit remote set-url origin <url>To add more upstreams:\ngit remote add newplace <url>So you can choose where to work\ngit push origin <branch> or git push newplace <branch>",
                "You can change the url by editing the config file.\nGo to your project root:Then edit the url field and set your new url. \nSave the changes. You can verify the changes by using the command.",
                "An alternative approach is to rename the 'old' origin (in the example below I name it simply old-origin) and adding a new one. This might be the desired approach if you still want to be able to push to the old origin every now and then:And in case you need to push your local state to the new origin:",
                "If you're using TortoiseGit then follow the below steps:Your branch and all your local commits will remain intact and you can keep working as you were before.",
                "Removing a remoteUse the git remote rm command to remove a remote URL from your repository.",
                "If you would like to set the username and password as well in the origin url, you can follow the below steps.Exporting the password in a variable would avoid issues with special characters.Steps:",
                "check your privilegein my case i need to check  my usernamei have two or three repository with seperate credentials.problem is my permission i have two private git server and repositoriesthis second account is admin of that new repo and first one is my default user account and i should grant permission to first",
                "For those who want to make this change from Visual Studio 2019Open Team Explorer (Ctrl+M)Home -> SettingsGit -> Repository SettingsRemotes -> Edit",
                "If your repository is private thenReference"
            ]
        },
        {
            "tag": "",
            "question": [
                "Which equals operator (== vs ===) should be used in JavaScript comparisons?",
                "I'm using JSLint to go through JavaScript, and it's returning many suggestions to replace == (two equals signs) with === (three equals signs) when doing things like comparing idSele_UNVEHtype.value...."
            ],
            "url": "https://stackoverflow.com/questions/359494",
            "answer": [
                "The strict equality operator (===) behaves identically to the abstract equality operator (==) except no type conversion is done, and the types must be the same to be considered equal.Reference: Javascript Tutorial: Comparison OperatorsThe == operator will compare for equality after doing any necessary type conversions.  The === operator will not do the conversion, so if two values are not the same type === will simply return false. Both are equally quick.To quote Douglas Crockford's excellent JavaScript: The Good Parts,JavaScript has two sets of equality operators: === and !==, and their evil twins == and !=.  The good ones work the way you would expect.  If the two operands are of the same type and have the same value, then === produces true and !== produces false.  The evil twins do the right thing when the operands are of the same type, but if they are of different types, they attempt to coerce the values.  the rules by which they do that are complicated and unmemorable.  These are some of the interesting cases:The lack of transitivity is alarming.  My advice is to never use the evil twins.  Instead, always use === and !==.  All of the comparisons just shown produce false with the === operator.A good point was brought up by @Casebash in the comments and in @Phillipe Laybaert's answer concerning objects.  For objects, == and === act consistently with one another (except in a special case).The special case is when you compare a primitive with an object that evaluates to the same primitive, due to its toString or valueOf method. For example, consider the comparison of a string primitive with a string object created using the String constructor.Here the == operator is checking the values of the two objects and returning true, but the === is seeing that they're not the same type and returning false.  Which one is correct?  That really depends on what you're trying to compare.  My advice is to bypass the question entirely and just don't use the String constructor to create string objects from string literals.Reference\nhttp://www.ecma-international.org/ecma-262/5.1/#sec-11.9.3",
                "This is because the equality operator == does type coercion, meaning that the interpreter implicitly tries to convert the values before comparing.On the other hand, the identity operator === does not do type coercion, and thus does not convert the values when comparing.",
                "Here's an interesting visualisation of the equality comparison between == and ===.Source: https://github.com/dorey/JavaScript-Equality-Table (demo, unified demo)When using === for JavaScript equality testing, everything is as is.\nNothing gets converted before being evaluated.When using == for JavaScript equality testing, some funky conversions take place.Always use ===, unless you fully understand the funky conversions that take place with ==.",
                "In the answers here, I didn't read anything about what equal means. Some will say that === means equal and of the same type, but that's not really true. It actually means that both operands reference the same object, or in case of value types, have the same value.So, let's take the following code:The same here:Or even:This behavior is not always obvious. There's more to the story than being equal and being of the same type.The rule is:For value types (numbers):\na === b returns true if a and b have the same value and are of the same typeFor reference types:\na === b returns true if a and b reference the exact same objectFor strings:\na === b returns true if a and b are both strings and contain the exact same charactersStrings are not value types, but in Javascript they behave like value types, so they will be \"equal\" when the characters in the string are the same and when they are of the same length (as explained in the third rule)Now it becomes interesting:But how about this?:I thought strings behave like value types? Well, it depends who you ask... In this case a and b are not the same type. a is of type Object, while b is of type string. Just remember that creating a string object using the String constructor creates something of type Object that behaves as a string most of the time.",
                "Let me add this counsel:If in doubt, read the specification!ECMA-262 is the specification for a scripting language of which JavaScript is a dialect. Of course in practice it matters more how the most important browsers behave than an esoteric definition of how something is supposed to be handled. But it is helpful to understand why new String(\"a\") !== \"a\".Please let me explain how to read the specification to clarify this question. I see that in this very old topic nobody had an answer for the very strange effect. So, if you can read a specification, this will help you in your profession tremendously. It is an acquired skill. So, let's continue.Searching the PDF file for === brings me to page 56 of the specification: 11.9.4. The Strict Equals Operator ( === ), and after wading through the specificationalese I find:11.9.6 The Strict Equality Comparison Algorithm\nThe comparison x === y, where x and y are values, produces true or false. Such a comparison is performed as follows:\n\u00a0\u00a01. If Type(x) is different from Type(y), return false.\n\u00a0\u00a02. If Type(x) is Undefined, return true.\n\u00a0\u00a03. If Type(x) is Null, return true.\n\u00a0\u00a04. If Type(x) is not Number, go to step 11.\n\u00a0\u00a05. If x is NaN, return false.\n\u00a0\u00a06. If y is NaN, return false.\n\u00a0\u00a07. If x is the same number value as y, return true.\n\u00a0\u00a08. If x is +0 and y is \u22120, return true.\n\u00a0\u00a09. If x is \u22120 and y is +0, return true.\n\u00a0\u00a010. Return false.\n\u00a0\u00a011. If Type(x) is String, then return true if x and y are exactly the same sequence of characters (same length and same characters in corresponding positions); otherwise, return false.\n\u00a0\u00a012. If Type(x) is Boolean, return true if x and y are both true or both false; otherwise, return false.\n\u00a0\u00a013. Return true if x and y refer to the same object or if they refer to objects joined to each other (see 13.1.2). Otherwise, return false.Interesting is step 11. Yes, strings are treated as value types. But this does not explain why new String(\"a\") !== \"a\". Do we have a browser not conforming to ECMA-262?Not so fast!Let's check the types of the operands. Try it out for yourself by wrapping them in typeof(). I find that new String(\"a\") is an object, and step 1 is used: return false if the types are different.If you wonder why new String(\"a\") does not return a string, how about some exercise reading a specification? Have fun!Aidiakapi wrote this in a comment below:From the specification11.2.2 The new Operator:If Type(constructor) is not Object, throw a TypeError exception.With other words, if String wouldn't be of type Object it couldn't be used with the new operator.new always returns an Object, even for String constructors, too. And alas! The value semantics for strings (see step 11) is lost.And this finally means: new String(\"a\") !== \"a\".",
                "I tested this in Firefox with Firebug using code like this:console.time(\"testEquality\");\nvar n = 0;\nwhile (true) {\n  n++;\n  if (n == 100000)\n    break;\n}\nconsole.timeEnd(\"testEquality\");andconsole.time(\"testTypeEquality\");\nvar n = 0;\nwhile (true) {\n  n++;\n  if (n === 100000)\n    break;\n}\nconsole.timeEnd(\"testTypeEquality\");My results (tested five times each and averaged):So I'd say that the miniscule difference (this is over 100000 iterations, remember) is negligible. Performance isn't a reason to do ===. Type safety (well, as safe as you're going to get in JavaScript), and code quality is.",
                "In PHP and JavaScript, it is a strict equality operator. Which means, it will compare both type and values.",
                "In JavaScript it means of the same value and type.For example,but",
                "Why == is so unpredictable?What do you get when you compare an empty string \"\" with the number zero 0?trueYep, that's right according to == an empty string and the number zero are the same time.And it doesn't end there, here's another one:Things get really weird with arrays.Then weirder with stringsIt get's worse:When is equal not equal?Let me say that again:And this is just the crazy stuff you get with primitives.It's a whole new level of crazy when you use == with objects.At this point your probably wondering...Why does this happen?Well it's because unlike \"triple equals\" (===) which just checks if two values are the same.== does a whole bunch of other stuff.It has special handling for functions, special handling for nulls, undefined, strings, you name it.It get's pretty wacky.In fact, if you tried to write a function that does what == does it would look something like this:So what does this mean?It means == is complicated.Because it's complicated it's hard to know what's going to happen when you use it.Which means you could end up with bugs.So the moral of the story is...Make your life less complicated.Use === instead of ==.The End.",
                "The === operator is called a strict comparison operator, it does differ from the == operator.Lets take 2 vars a and b.For \"a == b\" to evaluate to true a and b need to be the same value.In the case of \"a === b\" a and b must be the same value and also the same type for it to evaluate to true.Take the following exampleIn summary; using the == operator might evaluate to true in situations where you do not want it to so using the === operator would be safer.In the 90% usage scenario it won't matter which one you use, but it is handy to know the difference when you get some unexpected behaviour one day.",
                "Many times an untyped check would be handy because you do not care if the value is either undefined, null, 0  or \"\"",
                "Javascript execution flow diagram for strict equality / Comparison '==='Javascript execution flow diagram for non strict equality / comparison '=='",
                "JavaScript === vs == .",
                "It means equality without type coercion\ntype coercion means JavaScript do not automatically convert any other data types to string data types",
                "In a typical script there will be no performance difference. More important may be the fact that thousand \"===\" is 1\u00a0KB heavier than thousand \"==\" :) JavaScript profilers can tell you if there is a performance difference in your case.But personally I would do what JSLint suggests. This recommendation is there not because of performance issues, but because type coercion means ('\\t\\r\\n' == 0) is true.",
                "The equal comparison operator == is confusing and should be avoided.If you HAVE TO live with it, then remember the following 3 things:EQUAL OPERATOR TRUTH TABLE IN JAVASCRIPT** STRANGE: note that any two values on the first column are not equal in that sense.**",
                "There is unlikely to be any performance difference between the two operations in your usage. There is no type-conversion to be done because both parameters are already the same type. Both operations will have a type comparison followed by a value comparison.",
                "Yes! It does matter.=== operator in javascript checks value as well as type where as == operator just checks the value (does type conversion if required).You can easily test it. Paste following code in an HTML file and open it in browserYou will get 'false' in alert. Now modify the onPageLoad() method to alert(x == 5); you will get true.",
                "Simply== means comparison between operands with type coercionand=== means comparison between operands without type coercion.Type coercion in JavaScript means automatically converting data types to other data types.For example:",
                "As a rule of thumb, I would generally use === instead of == (and !== instead of !=).Reasons are explained in in the answers above and also Douglas Crockford is pretty clear about it (JavaScript: The Good Parts).However there is one single exception:\n== null is an efficient way to check for 'is null or undefined':For example jQuery 1.9.1 uses this pattern 43 times, and  the JSHint syntax checker even provides the eqnull relaxing option for this reason.From the jQuery style guide:Strict equality checks (===) should be used in favor of ==. The only\nexception is when checking for undefined and null by way of null.EDIT 2021-03:Nowadays most browsers\nsupport the Nullish coalescing operator (??)\nand the Logical nullish assignment (??=), which allows a more concise way to\nassign a default value if a variable is null or undefined, for example:can be written as any of these forms",
                "It's a strict check test.It's a good thing especially if you're checking between 0 and false and null.For example, if you have:Then:All returns true and you may not want this. Let's suppose you have a function that can return the 0th index of an array or false on failure. If you check with \"==\" false, you can get a confusing result.So with the same thing as above, but a strict test:",
                "=== operator  checks the values as well as the types of the variables for equality.== operator just checks the value of the variables for equality.",
                "JSLint sometimes gives you unrealistic reasons to modify stuff. === has exactly the same performance as == if the types are already the same.It is faster only when the types are not the same, in which case it does not try to convert types but directly returns a false.So, IMHO, JSLint maybe used to write new code, but useless over-optimizing should be avoided at all costs.Meaning, there is no reason to change == to === in a check like if (a == 'test') when you know it for a fact that a can only be a String.Modifying a lot of code that way wastes developers' and reviewers' time and achieves nothing.",
                "A simple example is",
                "The top 2 answers both mentioned == means equality and === means identity. Unfortunately, this statement is incorrect.If both operands of == are objects, then they are compared to see if they are the same object. If both operands point to the same object, then the equal operator returns true. Otherwise,\nthe two are not equal.In the code above, both == and === get false because a and b are not the same objects.That's to say: if both operands of == are objects, == behaves same as ===, which also means identity. The essential difference of this two operators is about type conversion. == has conversion before it checks equality, but === does not.",
                "The problem is that you might easily get into trouble since JavaScript have a lot of implicit conversions meaning...Which pretty soon becomes a problem. The best sample of why implicit conversion is \"evil\" can be taken from this code in MFC / C++ which actually will compile due to an implicit conversion from CString to HANDLE which is a pointer typedef type...Which obviously during runtime does very undefined things...Google for implicit conversions in C++ and STL to get some of the arguments against it...",
                "From the core javascript reference=== Returns true if the operands are strictly equal (see above)\n  with no type conversion.",
                "Equality comparison:Operator ==Returns true, when both operands are equal. The operands are converted to the same type before being compared.Equality and type comparison:Operator ===Returns true if both operands are equal and of the same type. It's generally \nbetter and safer if you compare this way, because there's no behind-the-scenes type conversions.",
                "Here is a handy comparison table that shows the conversions that happen and the differences between == and ===.As the conclusion states:\"Use three equals unless you fully understand the conversions that take\n  place for two-equals.\"http://dorey.github.io/JavaScript-Equality-Table/",
                "null and undefined are nothingness, that is,Here a and b do not have values. Whereas, 0, false and '' are all values. One thing common beween all these are that they are all falsy values, which means they all satisfy falsy conditions.So, the 0, false and '' together form a sub-group. And on other hand, null & undefined form the second sub-group. Check the comparisons in the below image. null and undefined would equal. The other three would equal to each other. But, they all are treated as falsy conditions in JavaScript.This is same as any object (like {}, arrays, etc.), non-empty string & Boolean true are all truthy conditions. But, they are all not equal."
            ]
        },
        {
            "tag": "",
            "question": [
                "What is the maximum length of a URL in different browsers?",
                "What is the maximum length of a URL for each browser?\nIs a maximum URL length part of the HTTP specification?"
            ],
            "url": "https://stackoverflow.com/questions/417142",
            "answer": [
                "If you keep URLs under 2000 characters, they'll work in virtually any combination of client and server software.If you are targeting particular browsers, see below for more details on specific limits.RFC 2616 (Hypertext Transfer Protocol HTTP/1.1) section 3.2.1 saysThe HTTP protocol does not place\nany a priori limit on the length of\na URI. Servers MUST be able to handle\nthe URI of any resource they    serve,\nand SHOULD be able to handle URIs of\nunbounded length if they    provide\nGET-based forms that could generate\nsuch URIs. A server    SHOULD return\n414 (Request-URI Too Long) status if a\nURI is longer    than the server can\nhandle (see section 10.4.15).That RFC has been obsoleted by RFC7230 which is a refresh of the HTTP/1.1 specification. It contains similar language, but also goes on to suggest this:Various ad hoc limitations on request-line length are found in\npractice. It is RECOMMENDED that all HTTP senders and recipients\nsupport, at a minimum, request-line lengths of 8000 octets.That's what the standards say. For the reality, there was an article on boutell.com (link goes to Internet Archive backup) that discussed what individual browser and server implementations will support. The executive summary is:Extremely long URLs are usually a\nmistake. URLs over 2,000 characters\nwill not work in the most popular web\nbrowsers. Don't use them if you intend\nyour site to work for the majority of\nInternet users.(Note: this is a quote from an article written in 2006, but in 2015 IE's declining usage means that longer URLs do work for the majority. However, IE still has the limitation...)IE8's maximum URL length is 2083 chars, and it seems IE9 has a similar limit.I've tested IE10 and the address bar will only accept 2083 chars. You can click a URL which is longer than this, but the address bar will still only show 2083 characters of this link.There's a nice writeup on the IE Internals blog which goes into some of the background to this.There are mixed reports IE11 supports longer URLs - see comments below. Given some people report issues, the general advice still stands.Be aware that the sitemaps protocol, which allows a site to inform search engines about available pages, has a limit of 2048 characters in a URL. If you intend to use sitemaps, a limit has been decided for you! (see Calin-Andrei Burloiu's answer below)There's also some research from 2010 into the maximum URL length that search engines will crawl and index. They found the limit was 2047 chars, which appears allied to the sitemap protocol spec. However, they also found the Google SERP tool wouldn't cope with URLs longer than 1855 chars.CDNs also impose limits on URI length, and will return a 414 Too long request when these limits are reached, for example:(credit to timrs2998 for providing that info in the comments)I tested the following against an Apache 2.4 server configured with a very large LimitRequestLine and LimitRequestFieldSize.See also this answer from Matas Vaitkevicius below.This is a popular question, and as the original research is ~14 years old I'll try to keep it up to date: As of Jan 2021, the advice still stands. Even though IE11 may possibly accept longer URLs, the ubiquity of older IE installations plus the search engine limitations mean staying under 2000 chars is the best general policy.",
                "The longest URLs I came across are data URLsExample image URL from Google image results (11747 characters)",
                "I wrote this test that keeps on adding 'a' to parameter until the browser failsC# part:View:PART 1On Chrome I got:It then blew up with:HTTP Error 404.15 - Not Found The request filtering module is\n  configured to deny a request where the query string is too long.Same on Internet\u00a0Explorer\u00a08 and FirefoxPART 2I went easy mode and added additional limits to IISExpress applicationhost.config and web.config setting maxQueryStringLength=\"32768\".after 7744 characters.PART 3Addedwhich didn't help at all. I finally decided to use fiddler to remove the referrer from header.Which did nicely.Chrome: got to 15613 characters. (I guess it's a 16K limit for IIS)And it failed again with:Firefox:Internet Explorer 8 failed with iexplore.exe crashing.After 2505Android EmulatorInternet Explorer 11Internet Explorer 10Internet Explorer 9",
                "WWW FAQs: What is the maximum length of a URL? has its own answer based on empirical testing and research. The short answer is that going over 2048 characters makes Internet\u00a0Explorer unhappy and thus this is the limit you should use. See the page for a long answer.",
                "On Apple platforms (iOS/macOS/tvOS/watchOS), the limit may be a 2 GB long URL scheme, as seen by this comment in the source code of Swift:On iOS, I've tested and confirmed that even a 300+ MB long URL is accepted. You can try such a long URL like this in Objective-C:And catch if it succeed with:",
                "There is really no universal maximum URL length. The max length is determined only by what the client browser chooses to support, which varies widely. The 2,083 limit is only present in Internet Explorer (all versions up to 7.0). The max length in Firefox and Safari seems to be unlimited, although instability occurs with URLs reaching around 65,000 characters.\nOpera seems to have no max URL length whatsoever, and doesn't suffer instability at extremely long lengths.",
                "The URI RFC (of which URLs are a subset) doesn't define a maximum length, however, it does recommend that the hostname part of the URI (if applicable) not exceed 255 characters in length:URI producers should use names that\nconform to the DNS syntax, even when\nuse of DNS is not immediately\napparent, and should limit these names\nto no more than 255 characters in\nlength.As noted in other posts though, some browsers have a practical limitation on the length of a URL.",
                "The HTTP 1.1 specification says:URIs in HTTP can be represented in\n  absolute form or relative to some\n  known base URI [11], depending upon\n  the context of their use. The two\n  forms are differentiated by the fact\n  that absolute URIs always begin\n  with a scheme name followed by a\n  colon. For definitive information on\n  URL syntax and semantics, see \"Uniform\n  Resource Identifiers (URI):    Generic\n  Syntax and Semantics,\" RFC 2396 [42]\n  (which replaces RFCs    1738 [4] and\n  RFC 1808 [11]). This specification\n  adopts the    definitions of\n  \"URI-reference\", \"absoluteURI\",\n  \"relativeURI\", \"port\",\n  \"host\",\"abs_path\", \"rel_path\", and\n  \"authority\" from that\n  specification.The HTTP protocol does not place\n  any a priori limit on the length of\n  a URI. Servers MUST be able to handle\n  the URI of any resource they    serve,\n  and SHOULD be able to handle URIs of\n  unbounded length if they    provide\n  GET-based forms that could generate\n  such URIs.* A server    SHOULD return\n  414 (Request-URI Too Long) status if a\n  URI is longer    than the server can\n  handle (see section 10.4.15).Note: Servers ought to be cautious about depending on URI\n  lengths\n        above 255 bytes, because some older client or proxy\n        implementations might not properly support these lengths.As mentioned by @Brian, the HTTP clients (e.g. browsers) may have their own limits, and HTTP servers will have different limits.",
                "Microsoft Support says \"Maximum URL length is 2,083 characters in Internet Explorer\".IE has problems with URLs longer than that. Firefox seems to work fine with >4k chars.",
                "In URL as UI Jakob Nielsen recommends:the social interface to the Web relies on email when users want to recommend Web pages to each other, and email is the second-most common way users get to new sites (search engines being the most common): make sure that all URLs on your site are less than 78 characters long so that they will not wrap across a line feed.This is not the maximum but I'd consider this a practical maximum if you want your URL to be shared.",
                "Sitemaps protocol, which is a way for webmasters to inform search engines about pages on their sites (also used by Google in Webmaster Tools), supports URLs with less than 2048 characters. So if you are planning to use this feature for Search Engine Optimization, take this into account.",
                "ASP.NET 2 and SQL Server reporting services 2005 have a limit of 2028. I found this out the hard way, where my dynamic URL generator would not pass over some parameters to a report beyond that point. This was under Internet\u00a0Explorer\u00a08.",
                "Why is the Internet\u00a0Explorer limit only 2K while IIS has a limit of 16K? I don't think it makes sense.So I want to start an experiment about Ajax request URL size limits.I have set my Tomcat HTTP connector's maxHttpHeaderSize=\"1048576\". And prepared a very long URL.Then I send a request with the long URL like the following:jQuery reports done. Tomcat reports the URL requested is 1048015 bytes. It was tested with Chrome 50 and Internet\u00a0Explorer\u00a011.So web browsers won't truncate or limit your URL intentionally when sending Ajax requests.",
                "Limit request line directive sets the maximum length of a URL. By default, it is set to 8190, which gives you a lot of room. However other servers and some browses, limit the length more.Because all parameters are passed on the URL line, items that were in password of hidden fields will also be displayed in the URL of course. Neither mobile should be used for real security measures and should be considered cosmetic security at best.",
                "It seems that Chrome at least has raised this limit. I pasted 20,000 characters into the bookmarklet and it took it.",
                "I have experience with SharePoint 2007, 2010 and there is a limit of the length URL you can create from the server side in this case SharePoint, so it depends mostly on, 1) the client (browser, version, and OS) and 2) the server technology, IIS, Apache, etc.",
                "According to the HTTP spec, there is no limit to a URL's length. Keep your URLs under 2048 characters; this will ensure the URLs work in all clients & server configurations. Also, search engines like URLs to remain under approximately 2000 characters."
            ]
        },
        {
            "tag": "",
            "question": [
                "Loop over an array in JavaScript",
                "How can I loop through all the entries in an array using JavaScript?"
            ],
            "url": "https://stackoverflow.com/questions/9329446",
            "answer": [
                "TL;DRYour best bets are usuallySome quick \"don't\"s:But there's lots more to explore, read on...JavaScript has powerful semantics for looping through arrays and array-like objects. I've split the answer into two parts: Options for genuine arrays, and options for things that are just array-like, such as the arguments object, other iterable objects (ES2015+), DOM collections, and so on.Okay, let's look at our options:You have five options (two supported basically forever, another added by ECMAScript\u00a05 [\"ES5\"], and two more added in ECMAScript\u00a02015 (\"ES2015\", aka \"ES6\"):(You can see those old specs here: ES5, ES2015, but both have been superceded; the current editor's draft is always here.)Details:ES2015 added iterators and iterables to JavaScript. Arrays are iterable (so are strings, Maps, and Sets, as well as DOM collections and lists, as you'll see later). Iterable objects provide iterators for their values. The new for-of statement loops through the values returned by an iterator:const a = [\"a\", \"b\", \"c\"];\nfor (const element of a) { // You can use `let` instead of `const` if you like\n    console.log(element);\n}\n// a\n// b\n// cIt doesn't get simpler than that! Under the covers, that gets an iterator from the array and loops through the values the iterator returns. The iterator provided by arrays provides the values of the array elements, in order beginning to end.Notice how element is scoped to each loop iteration; trying to use element after the end of the loop would fail because it doesn't exist outside the loop body.In theory, a for-of loop involves several function calls (one to get the iterator, then one to get each value from it). Even when that's true, it's nothing to worry about, function calls are very cheap in modern JavaScript engines (it bothered me for forEach [below] until I looked into it; details). But additionally, JavaScript engines optimize those calls away (in performance-critical code) when dealing with native iterators for things like arrays.for-of is entirely async-friendly. If you need the work in a loop body to be done in series (not in parallel), an await in the loop body will wait for the promise to settle before continuing. Here's a silly example:function delay(ms) {\n    return new Promise(resolve => {\n        setTimeout(resolve, ms);\n    });\n}\n\nasync function showSlowly(messages) {\n    for (const message of messages) {\n        await delay(400);\n        console.log(message);\n    }\n}\n\nshowSlowly([\n    \"So\", \"long\", \"and\", \"thanks\", \"for\", \"all\", \"the\", \"fish!\"\n]);\n// `.catch` omitted because we know it never rejectsNote how the words appear with a delay before each one.It's a matter of coding style, but for-of is the first thing I reach for when looping through anything iterable.In any even vaguely-modern environment (so, not IE8) where you have access to the Array features added by ES5, you can use forEach (spec | MDN) if you're only dealing with synchronous code (or you don't need to wait for an asynchronous process to finish during the loop):const a = [\"a\", \"b\", \"c\"];\na.forEach((element) => {\n    console.log(element);\n});forEach accepts a callback function and, optionally, a value to use as this when calling that callback (not used above). The callback is called for each element in the array, in order, skipping non-existent elements in sparse arrays. Although I only used one parameter above, the callback is called with three arguments: The element for that iteration, the index of that element, and a reference to the array you're iterating over (in case your function doesn't already have it handy).Like for-of, forEach has the advantage that you don't have to declare indexing and value variables in the containing scope; in this case, they're supplied as arguments to the iteration function, and so nicely scoped to just that iteration.Unlike for-of, forEach has the disadvantage that it doesn't understand async functions and await. If you use an async function as the callback, forEach does not wait for that function's promise to settle before continuing. Here's the async example from for-of using forEach instead\u00a0\u2014 notice how there's an initial delay, but then all the text appears right away instead of waiting:function delay(ms) {\n    return new Promise(resolve => {\n        setTimeout(resolve, ms);\n    });\n}\n\nasync function showSlowly(messages) {\n    // INCORRECT, doesn't wait before continuing,\n    // doesn't handle promise rejections\n    messages.forEach(async message => {\n        await delay(400);\n        console.log(message);\n    });\n}\n\nshowSlowly([\n    \"So\", \"long\", \"and\", \"thanks\", \"for\", \"all\", \"the\", \"fish!\"\n]);\n// `.catch` omitted because we know it never rejectsforEach is the \"loop through them all\" function, but ES5 defined several other useful \"work your way through the array and do things\" functions, including:As with forEach, if you use an async function as your callback, none of those waits for the function's promise to settle. That means:Sometimes the old ways are the best:const a = [\"a\", \"b\", \"c\"];\nfor (let index = 0; index < a.length; ++index) {\n    const element = a[index];\n    console.log(element);\n}If the length of the array won't change during the loop, and it's in highly performance-sensitive code, a slightly more complicated version grabbing the length up front might be a tiny bit faster:const a = [\"a\", \"b\", \"c\"];\nfor (let index = 0, len = a.length; index < len; ++index) {\n    const element = a[index];\n    console.log(element);\n}And/or counting backward:const a = [\"a\", \"b\", \"c\"];\nfor (let index = a.length - 1; index >= 0; --index) {\n    const element = a[index];\n    console.log(element);\n}But with modern JavaScript engines, it's rare you need to eke out that last bit of juice.Before ES2015, the loop variable had to exist in the containing scope, because var only has function-level scope, not block-level scope. But as you saw in the examples above, you can use let within the for to scope the variables to just the loop. And when you do that, the index variable is recreated for each loop iteration, meaning closures created in the loop body keep a reference to the index for that specific iteration, which solves the old \"closures in loops\" problem:// (The `NodeList` from `querySelectorAll` is array-like)\nconst divs = document.querySelectorAll(\"div\");\nfor (let index = 0; index < divs.length; ++index) {\n    divs[index].addEventListener('click', e => {\n        console.log(\"Index is: \" + index);\n    });\n}\n<div>zero</div>\n<div>one</div>\n<div>two</div>\n<div>three</div>\n<div>four</div>In the above, you get \"Index is: 0\" if you click the first and \"Index is: 4\" if you click the last. This does not work if you use var instead of let (you'd always see \"Index is: 5\").Like for-of, for loops work well in async functions. Here's the earlier example using a for loop:function delay(ms) {\n    return new Promise(resolve => {\n        setTimeout(resolve, ms);\n    });\n}\n\nasync function showSlowly(messages) {\n    for (let i = 0; i < messages.length; ++i) {\n        const message = messages[i];\n        await delay(400);\n        console.log(message);\n    }\n}\n\nshowSlowly([\n    \"So\", \"long\", \"and\", \"thanks\", \"for\", \"all\", \"the\", \"fish!\"\n]);\n// `.catch` omitted because we know it never rejectsfor-in isn't for looping through arrays, it's for looping through the names of an object's properties. It does often seem to work for looping through arrays as a by-product of the fact that arrays are objects, but it doesn't just loop through the array indexes, it loops through all enumerable properties of the object (including inherited ones). (It also used to be that the order wasn't specified; it is now [details in this other answer], but even though the order is specified now, the rules are complex, there are exceptions, and relying on the order is not best practice.)The only real use cases for for-in on an array are:Looking only at that first example: You can use for-in to visit those sparse array elements if you use appropriate safeguards:// `a` is a sparse array\nconst a = [];\na[0] = \"a\";\na[10] = \"b\";\na[10000] = \"c\";\nfor (const name in a) {\n    if (Object.hasOwn(a, name) &&       // These checks are\n        /^0$|^[1-9]\\d*$/.test(name) &&  // explained\n        name <= 4294967294              // below\n       ) {\n        const element = a[name];\n        console.log(a[name]);\n    }\n}Note the three checks:That the object has its own property by that name (not one it inherits from its prototype; this check is also often written as a.hasOwnProperty(name) but ES2022 adds Object.hasOwn which can be more reliable), andThat the name is all decimal digits (e.g., normal string form, not scientific notation), andThat the name's value when coerced to a number is <= 2^32 - 2 (which is 4,294,967,294). Where does that number come from? It's part of the definition of an array index in the specification. Other numbers (non-integers, negative numbers, numbers greater than 2^32 - 2) are not array indexes. The reason it's 2^32 - 2 is that that makes the greatest index value one lower than 2^32 - 1, which is the maximum value an array's length can have. (E.g., an array's length fits in a 32-bit unsigned integer.)...although with that said, most code only does the hasOwnProperty check.You wouldn't do that in inline code, of course. You'd write a utility function. Perhaps:// Utility function for antiquated environments without `forEach`\nconst hasOwn = Object.prototype.hasOwnProperty.call.bind(Object.prototype.hasOwnProperty);\nconst rexNum = /^0$|^[1-9]\\d*$/;\nfunction sparseEach(array, callback, thisArg) {\n    for (const name in array) {\n        const index = +name;\n        if (hasOwn(a, name) &&\n            rexNum.test(name) &&\n            index <= 4294967294\n           ) {\n            callback.call(thisArg, array[name], index, array);\n        }\n    }\n}\n\nconst a = [];\na[5] = \"five\";\na[10] = \"ten\";\na[100000] = \"one hundred thousand\";\na.b = \"bee\";\n\nsparseEach(a, (value, index) => {\n    console.log(\"Value at \" + index + \" is \" + value);\n});Like for, for-in works well in asynchronous functions if the work within it needs to be done in series.function delay(ms) {\n    return new Promise(resolve => {\n        setTimeout(resolve, ms);\n    });\n}\n\nasync function showSlowly(messages) {\n    for (const name in messages) {\n        if (messages.hasOwnProperty(name)) { // Almost always this is the only check people do\n            const message = messages[name];\n            await delay(400);\n            console.log(message);\n        }\n    }\n}\n\nshowSlowly([\n    \"So\", \"long\", \"and\", \"thanks\", \"for\", \"all\", \"the\", \"fish!\"\n]);\n// `.catch` omitted because we know it never rejectsfor-of uses an iterator implicitly, doing all the scut work for you. Sometimes, you might want to use an iterator explicitly. It looks like this:const a = [\"a\", \"b\", \"c\"];\nconst it = a.values(); // Or `const it = a[Symbol.iterator]();` if you like\nlet entry;\nwhile (!(entry = it.next()).done) {\n    const element = entry.value;\n    console.log(element);\n}An iterator is an object matching the Iterator definition in the specification. Its next method returns a new result object each time you call it. The result object has a property, done, telling us whether it's done, and a property value with the value for that iteration. (done is optional if it would be false, value is optional if it would be undefined.)What you get for value varies depending on the iterator. On arrays, the default iterator provides the value of each array element (\"a\", \"b\", and \"c\" in the example earlier). Arrays also have three other methods that return iterators:Since iterator objects don't advance until you call next, they work well in async function loops. Here's the earlier for-of example using the iterator explicitly:function delay(ms) {\n    return new Promise(resolve => {\n        setTimeout(resolve, ms);\n    });\n}\n\nasync function showSlowly(messages) {\n    const it = messages.values()\n    while (!(entry = it.next()).done) {\n        await delay(400);\n        const element = entry.value;\n        console.log(element);\n    }\n}\n\nshowSlowly([\n    \"So\", \"long\", \"and\", \"thanks\", \"for\", \"all\", \"the\", \"fish!\"\n]);\n// `.catch` omitted because we know it never rejectsAside from true arrays, there are also array-like objects that have a length property and properties with all-digits names: NodeList instances, HTMLCollection instances, the arguments object, etc. How do we loop through their contents?At least some, and possibly most or even all, of the array approaches above apply equally well to array-like objects:Use for-of (use an iterator implicitly) (ES2015+)for-of uses the iterator provided by the object (if any). That includes host-provided objects (like DOM collections and lists). For instance, HTMLCollection instances from getElementsByXYZ methods and NodeLists instances from querySelectorAll both support iteration. (This is defined quite subtly by the HTML and DOM specifications. Basically, any object with length and indexed access is automatically iterable. It doesn't have to be marked iterable; that is used only for collections that, in addition to being iterable, support forEach, values, keys, and entries methods. NodeList does; HTMLCollection doesn't, but both are iterable.)Here's an example of looping through div elements:const divs = document.querySelectorAll(\"div\");\nfor (const div of divs) {\n    div.textContent = Math.random();\n}\n<div>zero</div>\n<div>one</div>\n<div>two</div>\n<div>three</div>\n<div>four</div>Use forEach and related (ES5+)The various functions on Array.prototype are \"intentionally generic\" and can be used on array-like objects via Function#call (spec | MDN) or Function#apply (spec | MDN). (If you have to deal with IE8 or earlier [ouch], see the \"Caveat for host-provided objects\" at the end of this answer, but it's not an issue with vaguely-modern browsers.)Suppose you wanted to use forEach on a Node's childNodes collection (which, being an HTMLCollection, doesn't have forEach natively). You'd do this:(Note, though, that you could just use for-of on node.childNodes.)If you're going to do that a lot, you might want to grab a copy of the function reference into a variable for reuse, e.g.:Use a simple for loopPerhaps obviously, a simple for loop works for array-like objects.Use an iterator explicitly (ES2015+)See #1.You may be able to get away with for-in (with safeguards), but with all of these more appropriate options, there's no reason to try.Other times, you may want to convert an array-like object into a true array. Doing that is surprisingly easy:Use Array.fromArray.from (spec) | (MDN) (ES2015+, but easily polyfilled) creates an array from an array-like object, optionally passing the entries through a mapping function first. So:...takes the NodeList from querySelectorAll and makes an array from it.The mapping function is handy if you were going to map the contents in some way. For instance, if you wanted to get an array of the tag names of the elements with a given class:Use spread syntax (...)It's also possible to use ES2015's spread syntax. Like for-of, this uses the iterator provided by the object (see #1 in the previous section):So for instance, if we want to convert a NodeList into a true array, with spread syntax this becomes quite succinct:Use the slice method of arraysWe can use the slice method of arrays, which like the other methods mentioned above is \"intentionally generic\" and so can be used with array-like objects, like this:So for instance, if we want to convert a NodeList into a true array, we could do this:(If you still have to handle IE8 [ouch], will fail; IE8 didn't let you use host-provided objects as this like that.)If you use Array.prototype functions with host-provided array-like objects (for example, DOM collections and such provided by the browser rather than the JavaScript engine), obsolete browsers like IE8 didn't necessarily handle that way, so if you have to support them, be sure to test in your target environments. But it's not an issue with vaguely-modern browsers. (For non-browser environments, naturally it'll depend on the environment.)",
                "Note: This answer is hopelessly out-of-date. For a more modern approach, look at the methods available on an array. Methods of interest might be:The standard way to iterate an array in JavaScript is a vanilla for-loop:Note, however, that this approach is only good if you have a dense array, and each index is occupied by an element. If the array is sparse, then you can run into performance problems with this approach, since you will iterate over a lot of indices that do not really exist in the array. In this case, a for .. in-loop might be a better idea. However, you must use the appropriate safeguards to ensure that only the desired properties of the array (that is, the array elements) are acted upon, since the for..in-loop will also be enumerated in legacy browsers, or if the additional properties are defined as enumerable.In ECMAScript 5 there will be a forEach method on the array prototype, but it is not supported in legacy browsers. So to be able to use it consistently you must either have an environment that supports it (for example, Node.js for server side JavaScript), or use a \"Polyfill\". The Polyfill for this functionality is, however, trivial and since it makes the code easier to read, it is a good polyfill to include.",
                "If you\u2019re using the jQuery library, you can use jQuery.each:EDIT :As per question, user want code in javascript instead of jquery so the edit is",
                "I think the reverse for loop deserves a mention here:Some developers use the reverse for loop by default, unless there is a good reason to loop forwards.Although the performance gains are usually insignificant, it sort of screams:\"Just do this to every item in the list, I don't care about the order!\"However in practice that is not actually a reliable indication of intent, since it is indistinguishable from those occasions when you do care about the order, and really do need to loop in reverse.  So in fact another construct would be needed to accurately express the \"don't care\" intent, something currently unavailable in most languages, including ECMAScript, but which could be called, for example, forEachUnordered().If order doesn't matter, and efficiency is a concern (in the innermost loop of a game or animation engine), then it may be acceptable to use the reverse for loop as your go-to pattern.  Just remember that seeing a reverse for loop in existing code does not necessarily mean that the order irrelevant!In general for higher level code where clarity and safety are greater concerns, I previously recommended using Array::forEach as your default pattern for looping (although these days I prefer to use for..of).  Reasons to prefer forEach over a reverse loop are:Then when you do see the reverse for loop in your code, that is a hint that it is reversed for a good reason (perhaps one of the reasons described above).  And seeing a traditional forward for loop may indicate that shifting can take place.(If the discussion of intent makes no sense to you, then you and your code may benefit from watching Crockford's lecture on Programming Style & Your Brain.)There is a debate about whether for..of or forEach() are preferable:For maximum browser support, for..of requires a polyfill for iterators, making your app slightly slower to execute and slightly larger to download.For that reason (and to encourage use of map and filter), some front-end style guides ban for..of completely!But the above concerns is not applicable to Node.js applications, where for..of is now well supported.And furthermore await does not work inside forEach().  Using for..of is the clearest pattern in this case.Personally, I tend to use whatever looks easiest to read, unless performance or minification has become a major concern.  So these days I prefer to use for..of instead of forEach(), but I will always use map or filter or find or some when applicable. \n (For the sake of my colleagues, I rarely use reduce.)You will notice that i-- is the middle clause (where we usually see a comparison) and the last clause is empty (where we usually see i++).  That means that i-- is also used as the condition for continuation.  Crucially, it is executed and checked before each iteration.How can it start at array.length without exploding?Because i-- runs before each iteration, on the first iteration we will actually be accessing the item at array.length - 1 which avoids any issues with Array-out-of-bounds undefined items.Why doesn't it stop iterating before index 0?The loop will stop iterating when the condition i-- evaluates to a falsey value (when it yields 0).The trick is that unlike --i, the trailing i-- operator decrements i but yields the value before the decrement.  Your console can demonstrate this:> var i = 5; [i, i--, i];[5, 5, 4]So on the final iteration, i was previously 1 and the i-- expression changes it to 0 but actually yields 1 (truthy), and so the condition passes.  On the next iteration i-- changes i to -1 but yields 0 (falsey), causing execution to immediately drop out of the bottom of the loop.In the traditional forwards for loop, i++ and ++i are interchangeable (as Douglas Crockford points out).  However in the reverse for loop, because our decrement is also our condition expression, we must stick with i-- if we want to process the item at index 0.Some people like to draw a little arrow in the reverse for loop, and end with a wink:Credits go to WYL for showing me the benefits and horrors of the reverse for loop.",
                "Some C-style languages use foreach to loop through enumerations. In JavaScript this is done with the for..in loop structure:There is a catch. for..in will loop through each of the object's enumerable members, and the members on its prototype. To avoid reading values that are inherited through the object's prototype, simply check if the property belongs to the object:Additionally, ECMAScript 5 has added a forEach method to Array.prototype which can be used to enumerate over an array using a calback (the polyfill is in the docs so you can still use it for older browsers):It's important to note that Array.prototype.forEach doesn't break when the callback returns false. jQuery and Underscore.js provide their own variations on each to provide loops that can be short-circuited.",
                "\ud83d\udc49\ud83c\udffd \u00a0 for...of\ud83d\udc49\ud83c\udffd \u00a0 forEach\ud83d\udc49\ud83c\udffd \u00a0 map*Different from the two above, map() creates a new array and expects you to return something after each iteration.\ud83d\uded1\u00a0 Important: As map() is meant to return a value at each iteration, it is an ideal method for transforming elements in arrays:On the other hand, for...of and forEach( ) don't need to return anything and that's why we typically use them to perform logic tasks that manipulate stuff outside.So to speak, you're going to find if () statements, side effects, and logging activities in these two.\ud83d\udc4c\ud83c\udffe\u00a0 TIP: you can also have the index (as well as the whole array) in each iteration in your .map() or .forEach() functions.Just pass additional arguments to them:",
                "If you want to loop over an array, use the standard three-part for loop.You can get some performance optimisations by caching myArray.length or iterating over it backwards.",
                "If you don't mind emptying the array:x will contain the last value of y and it will be removed from the array. You can also use shift() which will give and remove the first item from y.",
                "A forEach implementation (see in jsFiddle):",
                "I know this is an old post, and there are so many great answers already. For a little more completeness I figured I'd throw in another one using AngularJS. Of course, this only applies if you're using Angular, obviously, nonetheless I'd like to put it anyway.angular.forEach takes 2 arguments and an optional third argument. The first argument is the object (array) to iterate over, the second argument is the iterator function, and the optional third argument is the object context (basically referred to inside the loop as 'this'.There are different ways to use the forEach loop of angular. The simplest and probably most used isAnother way that is useful for copying items from one array to another isThough, you don't have to do that, you can simply do the following and it's equivalent to the previous example:Now there are pros and cons of using the angular.forEach function as opposed to the built in vanilla-flavored for loop.ProsConsider the following 2 nested loops, which do exactly the same thing. Let's say that we have 2 arrays of objects and each object contains an array of results, each of which has a Value property that's a string (or whatever). And let's say we need to iterate over each of the results and if they're equal then perform some action:Granted this is a very simple hypothetical example, but I've written triple embedded for loops using the second approach and it was very hard to read, and write for that matter.ConsI'm sure there's various other pros and cons as well, and please feel free to add any that you see fit. I feel that, bottom line, if you need efficiency, stick with just the native for loop for your looping needs. But, if your datasets are smaller and a some efficiency is okay to give up in exchange for readability and writability, then by all means throw an angular.forEach in that bad boy.",
                "As of ECMAScript\u00a06:list = [0, 1, 2, 3]\r\nfor (let obj of list) {\r\n    console.log(obj)\r\n}Where of avoids the oddities associated with in and makes it work like the for loop of any other language, and let binds i within the loop as opposed to within the function.The braces ({}) can be omitted when there is only one command (e.g. in the example above).",
                "Probably the for(i = 0; i < array.length; i++) loop is not the best choice. Why? If you have this:The method will call from array[0] to array[2]. First, this will first reference variables you don't even have, second you would not have the variables in the array, and third this will make the code bolder. Look here, it's what I use:And if you want it to be a function, you can do this:If you want to break, a little more logic:Example:It returns:",
                "There are three implementations of foreach in jQuery as follows.",
                "An easy solution now would be to use the underscore.js library. It's providing many useful tools, such as each and will automatically delegate the job to the native forEach if available.A CodePen example of how it works is:",
                "There isn't any for each loop in native JavaScript. You can either use libraries to get this functionality (I recommend Underscore.js), use a simple for in loop.However, note that there may be reasons to use an even simpler for loop (see Stack Overflow question Why is using \u201cfor\u2026in\u201d with array iteration such a bad idea?)",
                "ECMAScript\u00a05 (the version on JavaScript) to work with Arrays:forEach - Iterates through every item in the array and do whatever you need with each item.In case, more interested on operation on array using some inbuilt feature.map - It creates a new array with the result of the callback function. This method is good to be used when you need to format the elements of your array.reduce - As the name says, it reduces the array to a single value by calling the given function passing in the current element and the result of the previous execution.every - Returns true or false if all the elements in the array pass the test in the callback function.filter - Very similar to every except that filter returns an array with the elements that return true to the given function.",
                "There are a few ways to loop through an array in JavaScript, as below:for - it's the most common one. Full block of code for loopingvar languages = [\"Java\", \"JavaScript\", \"C#\", \"Python\"];\r\nvar i, len, text;\r\nfor (i = 0, len = languages.length, text = \"\"; i < len; i++) {\r\n    text += languages[i] + \"<br>\";\r\n}\r\ndocument.getElementById(\"example\").innerHTML = text;\n<p id=\"example\"></p>while - loop while a condition is through. It seems to be the fastest loopvar text = \"\";\r\nvar i = 0;\r\nwhile (i < 10) {\r\n    text +=  i + \") something<br>\";\r\n    i++;\r\n}\r\ndocument.getElementById(\"example\").innerHTML = text;\n<p id=\"example\"></p>do/while - also loop through a block of code while the condition is true, will run at least one timevar text = \"\"\r\nvar i = 0;\r\n\r\ndo {\r\n    text += i + \") something <br>\";\r\n    i++;\r\n}\r\nwhile (i < 10);\r\n\r\ndocument.getElementById(\"example\").innerHTML = text;\n<p id=\"example\"></p>Functional loops - forEach, map, filter, also reduce (they loop through the function, but they are used if you need to do something with your array, etc.// For example, in this case we loop through the number and double them up using the map function\r\nvar numbers = [65, 44, 12, 4];\r\ndocument.getElementById(\"example\").innerHTML = numbers.map(function(num){return num * 2});\n<p id=\"example\"></p>For more information and examples about functional programming on arrays, look at the blog post Functional programming in JavaScript: map, filter and reduce.",
                "This is an iterator for NON-sparse list where the index starts at 0, which is the typical scenario when dealing with document.getElementsByTagName or document.querySelectorAll)Examples of usage:Example #1Example #2Each p tag gets class=\"blue\"Example #3Every other p tag gets class=\"red\">Example #4And finally the first 20 blue p tags are changed to greenCaution when using string as function: the function is created out-of-context and ought to be used only where you are certain of variable scoping.  Otherwise, better to pass functions where scoping is more intuitive.",
                "There's no inbuilt ability to break in forEach. To interrupt execution use the Array#some like below:This works because some returns true as soon as any of the callbacks, executed in array order, returns true, short-circuiting the execution of the rest. \nOriginal Answer\nsee Array prototype for some",
                "I also would like to add this as a composition of a reverse loop and an answer above for someone that would like this syntax too.Pros:The benefit for this: You have the reference already in the first like that won't need to be declared later with another line. It is handy when looping trough the object array.Cons:This will break whenever the reference is false - falsey (undefined, etc.). It can be used as an advantage though. However, it would make it a little bit harder to read. And also depending on the browser it can be \"not\" optimized to work faster than the original one.",
                "jQuery way using $.map:",
                "Using loops with ECMAScript\u00a06  destructuring and the spread operatorDestructuring and using of the spread operator have proven quite useful for newcomers to ECMAScript\u00a06 as being more human-readable/aesthetic, although some JavaScript veterans might consider it messy. Juniors or some other people might find it useful.The following examples will use the for...of statement and the .forEach method.Examples 6, 7, and 8 can be used with any functional loops like .map, .filter, .reduce, .sort, .every, .some. For more information about these methods, check out the Array Object.Example 1: Normal for...of loop - no tricks here.let arrSimple = ['a', 'b', 'c'];\n\nfor (let letter of arrSimple) {\n  console.log(letter);\n}Example 2: Split words to characterslet arrFruits = ['apple', 'orange', 'banana'];\n\nfor (let [firstLetter, ...restOfTheWord] of arrFruits) {\n  // Create a shallow copy using the spread operator\n  let [lastLetter] = [...restOfTheWord].reverse();\n  console.log(firstLetter, lastLetter, restOfTheWord);\n}Example 3: Looping with a key and value// let arrSimple = ['a', 'b', 'c'];\n\n// Instead of keeping an index in `i` as per example `for(let i = 0 ; i<arrSimple.length;i++)`\n// this example will use a multi-dimensional array of the following format type:\n// `arrWithIndex: [number, string][]`\n\nlet arrWithIndex = [\n  [0, 'a'],\n  [1, 'b'],\n  [2, 'c'],\n];\n\n// Same thing can be achieved using `.map` method\n// let arrWithIndex = arrSimple.map((i, idx) => [idx, i]);\n\n// Same thing can be achieved using `Object.entries`\n// NOTE: `Object.entries` method doesn't work on Internet Explorer  unless it's polyfilled\n// let arrWithIndex = Object.entries(arrSimple);\n\nfor (let [key, value] of arrWithIndex) {\n  console.log(key, value);\n}Example 4: Get object properties inlinelet arrWithObjects = [{\n    name: 'Jon',\n    age: 32\n  },\n  {\n    name: 'Elise',\n    age: 33\n  }\n];\n\nfor (let { name, age: aliasForAge } of arrWithObjects) {\n  console.log(name, aliasForAge);\n}Example 5: Get deep object properties of what you needlet arrWithObjectsWithArr = [{\n    name: 'Jon',\n    age: 32,\n    tags: ['driver', 'chef', 'jogger']\n  },\n  {\n    name: 'Elise',\n    age: 33,\n    tags: ['best chef', 'singer', 'dancer']\n  }\n];\n\nfor (let { name, tags: [firstItemFromTags, ...restOfTags] } of arrWithObjectsWithArr) {\n  console.log(name, firstItemFromTags, restOfTags);\n}Example 6: Is Example 3 used with .forEachlet arrWithIndex = [\n  [0, 'a'],\n  [1, 'b'],\n  [2, 'c'],\n];\n\n// Not to be confused here, `forEachIndex` is the real index\n// `mappedIndex` was created by \"another user\", so you can't really trust it\n\narrWithIndex.forEach(([mappedIndex, item], forEachIndex) => {\n  console.log(forEachIndex, mappedIndex, item);\n});Example 7: Is Example 4 used with .forEachlet arrWithObjects = [{\n    name: 'Jon',\n    age: 32\n  },\n  {\n    name: 'Elise',\n    age: 33\n  }\n];\n// NOTE: Destructuring objects while using shorthand functions\n// are required to be surrounded by parentheses\narrWithObjects.forEach( ({ name, age: aliasForAge }) => {\n  console.log(name, aliasForAge)\n});Example 8: Is Example 5 used with .forEachlet arrWithObjectsWithArr = [{\n    name: 'Jon',\n    age: 32,\n    tags: ['driver', 'chef', 'jogger']\n  },\n  {\n    name: 'Elise',\n    age: 33,\n    tags: ['best chef', 'singer', 'dancer']\n  }\n];\n\narrWithObjectsWithArr.forEach(({\n  name,\n  tags: [firstItemFromTags, ...restOfTags]\n}) => {\n  console.log(name, firstItemFromTags, restOfTags);\n});",
                "When iterating over an array, we often want to accomplish one of the following goals:We want to iterate over the array and create a new array:Array.prototype.mapWe want to iterate over the array and don't create a new array:Array.prototype.forEach \nfor..of loopIn JavaScript, there are many ways of accomplishing both of these goals. However, some are more convenient than others. Below you can find some commonly used methods (the most convenient IMO) to accomplish array iteration in JavaScript.map() is a function located on Array.prototype which can transform every element of an array and then returns a new array. map() takes as an argument a callback function and works in the following manner:let arr = [1, 2, 3, 4, 5];\r\n\r\nlet newArr = arr.map((element, index, array) => {\r\n  return element * 2;\r\n})\r\n\r\nconsole.log(arr);\r\nconsole.log(newArr);The callback which we have passed into map() as an argument gets executed for every element. Then an array gets returned which has the same length as the original array. In this new array element is transformed by the callback function passed in as an argument to map().The distinct difference between map and another loop mechanism like forEach and a for..of loop is that map returns a new array and leaves the old array intact (except if you explicitly manipulate it with thinks like splice).Also, note that the map function's callback provides the index number of the current iteration as a second argument. Furthermore, does the third argument provide the array on which map was called? Sometimes these properties can be very useful.forEach is a function which is located on Array.prototype which takes a callback function as an argument. It then executes this callback function for every element in the array. In contrast to the map() function, the forEach function returns nothing (undefined). For example:let arr = [1, 2, 3, 4, 5];\r\n\r\narr.forEach((element, index, array) => {\r\n\r\n  console.log(element * 2);\r\n\r\n  if (index === 4) {\r\n    console.log(array)\r\n  }\r\n  // index, and oldArray are provided as 2nd and 3th argument by the callback\r\n\r\n})\r\n\r\nconsole.log(arr);Just like the map function, the forEach callback provides the index number of the current iteration as a second argument. Also, does the third argument provide the array on which forEach was called?The for..of loop loops through every element of an array (or any other iterable object). It works in the following manner:let arr = [1, 2, 3, 4, 5];\r\n\r\nfor(let element of arr) {\r\n  console.log(element * 2);\r\n}In the above example, element stands for an array element and arr is the array which we want to loop. Note that the name element is arbitrary, and we could have picked any other name like 'el' or something more declarative when this is applicable.Don't confuse the for..in loop with the for..of loop. for..in will loop through all enumerable properties of the array whereas the for..of loop will only loop through the array elements. For example:let arr = [1, 2, 3, 4, 5];\r\n\r\narr.foo = 'foo';\r\n\r\nfor(let element of arr) {\r\n  console.log(element);\r\n}\r\n\r\nfor(let element in arr) {\r\n  console.log(element);\r\n}",
                "Today (2019-12-18) I perform test on my macOS v10.13.6 (High Sierra), on Chrome v 79.0, Safari v13.0.4 and Firefox v71.0 (64 bit) - conclusions about optimisation (and micro-optimisation which usually is not worth to introduce it to code because the benefit is small, but code complexity grows).It looks like the traditional for i (Aa) is a good choice to write fast code on all browsers.The other solutions, like for-of (Ad), all in group C.... are usually 2 - 10 (and more) times slower than Aa, but for small arrays it is ok to use it - for the sake of increase code clarity.The loops with array length cached in n (Ab, Bb, Be) are sometimes faster, sometimes not. Probably compilers automatically detect this situation and introduce caching. The speed differences between the cached and no-cached versions (Aa, Ba, Bd) are about ~1%, so it looks like introduce n is a micro-optimisation.The i-- like solutions where the loop starts from the last array element (Ac, Bc) are usually ~30% slower than forward solutions - probably the reason is the way of CPU memory cache working - forward memory reading is more optimal for CPU caching). Is recommended to NOT USE such solutions.In tests we calculate the sum of array elements. I perform a test for small arrays (10 elements) and big arrays (1M elements) and divide them into three groups:let arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\r\n//let arr = Array.from(Array(1000000), (x, i) => i%10);\r\n\r\nfunction Aa(a, s=0) {\r\n  for(let i=0; i<a.length; i++) {\r\n    s += a[i];\r\n  }\r\n  console.log('Aa=', s);\r\n}\r\n\r\nfunction Ab(a, s=0) {\r\n  let n = a.length;\r\n  for(let i=0; i<n; i++) {\r\n    s += a[i];\r\n  }\r\n  console.log('Ab=', s);\r\n}\r\n\r\nfunction Ac(a, s=0) {\r\n  for(let i=a.length; i--;) {\r\n    s += a[i];\r\n  }\r\n  console.log('Ac=', s);\r\n}\r\n\r\nfunction Ad(a, s=0) {\r\n  for(let x of a) {\r\n    s += x;\r\n  }\r\n  console.log('Ad=', s);\r\n}\r\n\r\nfunction Ae(a, s=0) {\r\n  for(let i in a) if (a.hasOwnProperty(i)) {\r\n    s += a[i];\r\n  }\r\n  console.log('Ae=', s);\r\n}\r\n\r\nfunction Ba(a, s=0) {\r\n  let i = -1;\r\n  while(++i < a.length) {\r\n    s+= a[i];\r\n  }\r\n  console.log('Ba=', s);\r\n}\r\n\r\nfunction Bb(a, s=0) {\r\n  let i = -1;\r\n  let n = a.length;\r\n  while(++i < n) {\r\n    s+= a[i];\r\n  }\r\n  console.log('Bb=', s);\r\n}\r\n\r\nfunction Bc(a, s=0) {\r\n  let i = a.length;\r\n  while(i--) {\r\n    s += a[i];\r\n  }\r\n  console.log('Bc=', s);\r\n}\r\n\r\nfunction Bd(a, s=0) {\r\n  let i = 0;\r\n  do {\r\n    s+= a[i]\r\n  } while (++i < a.length);\r\n  console.log('Bd=', s);\r\n}\r\n\r\nfunction Be(a, s=0) {\r\n  let i = 0;\r\n  let n = a.length;\r\n  do {\r\n    s += a[i]\r\n  } while (++i < n);\r\n  console.log('Be=', s);\r\n}\r\n\r\nfunction Bf(a, s=0) {\r\n  const it = a.values(); \r\n  let e;\r\n  while (!(e = it.next()).done) { \r\n    s+= e.value; \r\n  }\r\n  console.log('Bf=', s);\r\n}\r\n\r\nfunction Ca(a, s=0) {\r\n  a.map(x => { s+=x });\r\n  console.log('Ca=', s);\r\n}\r\n\r\nfunction Cb(a, s=0) {\r\n  a.forEach(x => { s+=x });\r\n  console.log('Cb=', s);\r\n}\r\n\r\nfunction Cc(a, s=0) {\r\n  a.every(x => (s += x, 1));\r\n  console.log('Cc=', s);\r\n}\r\n\r\nfunction Cd(a, s=0) {\r\n  a.filter(x => { s+=x });\r\n  console.log('Cd=',s);\r\n}\r\n\r\nfunction Ce(a, s=0) {\r\n  a.reduce((z, c) => { s+=c }, 0);\r\n  console.log('Ce=', s);\r\n}\r\n\r\nfunction Cf(a, s=0) {\r\n  a.reduceRight((z, c) => { s += c }, 0);\r\n  console.log('Cf=', s);\r\n}\r\n\r\nfunction Cg(a, s=0) {\r\n  a.some(x => { s += x } );\r\n  console.log('Cg=', s);\r\n}\r\n\r\nfunction Ch(a, s=0) {\r\n  Array.from(a, x=> s += x);\r\n  console.log('Cc=', s);\r\n}\r\n\r\n\r\nAa(arr);\r\nAb(arr);\r\nAc(arr);\r\nAd(arr);\r\nAe(arr);\r\n\r\nBa(arr);\r\nBb(arr);\r\nBc(arr);\r\nBd(arr);\r\nBe(arr);\r\nBf(arr);\r\n\r\nCa(arr);\r\nCb(arr);\r\nCc(arr);\r\nCd(arr);\r\nCe(arr);\r\nCf(arr);\r\nCg(arr);\r\nCh(arr);\n<p style=\"color: red\">This snippets only PRESENTS code used for benchmark - it not perform test itself</p>Cross browser resultsResults for all tested browsersbrowsers**Array with 10 elementsResults for Chrome. You can perform the test on your machine here.Array with 1,000,000 elementsResults for Chrome. You can perform the test on your machine here",
                "A way closest to your idea would be to use Array.forEach() which accepts a closure function which will be executed for each element of the array.Another viable way would be to use Array.map() which works in the same way, but it also takes all values that you return and returns them in a new array (essentially mapping each element to a new one), like this:",
                "As per the new updated feature ECMAScript 6 (ES6) and ECMAScript 2015, you can use the following options with loops:for loopsfor...in loopsArray.forEach()for...of loopswhile loopsdo...while loops",
                "As one can see in the table above, for...of should be used wherever it fits. Since it supports async functions, skips non-numeric properties and prevents messing up the loop by accidentally modifying the loop index.See for...of reference for more examples, link to specification and difference between for...of and for...in. Or maybe check this tutorial for some explanation on how they differ.",
                "The lambda syntax doesn't usually work in Internet\u00a0Explorer\u00a010  or below.I usually use theIf you are a jQuery fan and already have a jQuery file running, you should reverse the positions of the index and value parameters",
                "You can call forEach like this:forEach will iterate over the array you provide and for each iteration it will have element which holds the value of that iteration. If you need index you can get the current index by passing the i as the second parameter in the callback function for forEach.Foreach is basically a High Order Function, Which takes another function as its parameter.Output:You can also iterate over an array like this:",
                "If you want to use forEach(), it will look like -If you want to use for(), it will look like -"
            ]
        },
        {
            "tag": "",
            "question": [
                "The definitive guide to form-based website authentication [closed]",
                "Moderator note:\nThis question is not a good fit for our question and answer format with the topicality rules which currently apply for Stack Overflow. We normally use a \"historical lock\" for ..."
            ],
            "url": "https://stackoverflow.com/questions/549",
            "answer": [
                "We'll assume you already know how to build a login+password HTML form which POSTs the values to a script on the server side for authentication. The sections below will deal with patterns for sound practical auth, and how to avoid the most common security pitfalls.To HTTPS or not to HTTPS?Unless the connection is already secure (that is, tunneled through HTTPS using SSL/TLS), your login form values will be sent in cleartext, which allows anyone eavesdropping on the line between browser and web server will be able to read logins as they pass through. This type of wiretapping is done routinely by governments, but in general, we won't address 'owned' wires other than to say this: Just use HTTPS.In essence, the only practical way to protect against wiretapping/packet sniffing during login is by using HTTPS or another certificate-based encryption scheme (for example, TLS) or a proven & tested challenge-response scheme (for example, the Diffie-Hellman-based SRP). Any other method can be easily circumvented by an eavesdropping attacker.Of course, if you are willing to get a little bit impractical, you could also employ some form of two-factor authentication scheme (e.g. the Google Authenticator app, a physical 'cold war style' codebook, or an RSA key generator dongle). If applied correctly, this could work even with an unsecured connection, but it's hard to imagine that a dev would be willing to implement two-factor auth but not SSL.(Do not) Roll-your-own JavaScript encryption/hashingGiven the perceived (though now avoidable) cost and technical difficulty of setting up an SSL certificate on your website, some developers are tempted to roll their own in-browser hashing or encryption schemes in order to avoid passing cleartext logins over an unsecured wire.While this is a noble thought, it is essentially useless (and can be a security flaw) unless it is combined with one of the above - that is, either securing the line with strong encryption or using a tried-and-tested challenge-response mechanism (if you don't know what that is, just know that it is one of the most difficult to prove, most difficult to design, and most difficult to implement concepts in digital security).While it is true that hashing the password can be effective against password disclosure, it is vulnerable to replay attacks, Man-In-The-Middle attacks / hijackings (if an attacker can inject a few bytes into your unsecured HTML page before it reaches your browser, they can simply comment out the hashing in the JavaScript), or brute-force attacks (since you are handing the attacker both username, salt and hashed password).CAPTCHAS against humanityCAPTCHA is meant to thwart one specific category of attack: automated dictionary/brute force trial-and-error with no human operator. There is no doubt that this is a real threat, however, there are ways of dealing with it seamlessly that don't require a CAPTCHA, specifically properly designed server-side login throttling schemes - we'll discuss those later.Know that CAPTCHA implementations are not created alike; they often aren't human-solvable, most of them are actually ineffective against bots, all of them are ineffective against cheap third-world labor (according to OWASP, the current sweatshop rate is $12 per 500 tests), and some implementations may be technically illegal in some countries (see OWASP Authentication Cheat Sheet). If you must use a CAPTCHA, use Google's reCAPTCHA, since it is OCR-hard by definition (since it uses already OCR-misclassified book scans) and tries very hard to be user-friendly.Personally, I tend to find CAPTCHAS annoying, and use them only as a last resort when a user has failed to log in a number of times and throttling delays are maxed out. This will happen rarely enough to be acceptable, and it strengthens the system as a whole.Storing Passwords / Verifying loginsThis may finally be common knowledge after all the highly-publicized hacks and user data leaks we've seen in recent years, but it has to be said: Do not store passwords in cleartext in your database. User databases are routinely hacked, leaked or gleaned through SQL injection, and if you are storing raw, plaintext passwords, that is instant game over for your login security.So if you can't store the password, how do you check that the login+password combination POSTed from the login form is correct? The answer is hashing using a key derivation function. Whenever a new user is created or a password is changed, you take the password and run it through a KDF, such as Argon2, bcrypt, scrypt or PBKDF2, turning the cleartext password (\"correcthorsebatterystaple\") into a long, random-looking string, which is a lot safer to store in your database. To verify a login, you run the same hash function on the entered password, this time passing in the salt and compare the resulting hash string to the value stored in your database. Argon2, bcrypt and scrypt store the salt with the hash already. Check out this article on sec.stackexchange for more detailed information.The reason a salt is used is that hashing in itself is not sufficient -- you'll want to add a so-called 'salt' to protect the hash against rainbow tables. A salt effectively prevents two passwords that exactly match from being stored as the same hash value, preventing the whole database being scanned in one run if an attacker is executing a password guessing attack.A cryptographic hash should not be used for password storage because user-selected passwords are not strong enough (i.e. do not usually contain enough entropy) and a password guessing attack could be completed in a relatively short time by an attacker with access to the hashes. This is why KDFs are used - these effectively \"stretch the key\", which means that every password guess an attacker makes causes multiple repetitions of the hash algorithm, for example 10,000 times, which causes the attacker to guess the password 10,000 times slower.Session data - \"You are logged in as Spiderman69\"Once the server has verified the login and password against your user database and found a match, the system needs a way to remember that the browser has been authenticated. This fact should only ever be stored server side in the session data.If you are unfamiliar with session data, here's how it works: A single randomly-generated string is stored in an expiring cookie and used to reference a collection of data - the session data - which is stored on the server. If you are using an MVC framework, this is undoubtedly handled already.If at all possible, make sure the session cookie has the secure and HTTP Only flags set when sent to the browser. The HttpOnly flag provides some protection against the cookie being read through XSS attack. The secure flag ensures that the cookie is only sent back via HTTPS, and therefore protects against network sniffing attacks. The value of the cookie should not be predictable. Where a cookie referencing a non-existent session is presented, its value should be replaced immediately to prevent session fixation.Session state can also be maintained on the client side. This is achieved by using techniques like JWT (JSON Web Token).Persistent Login Cookies (\"remember me\" functionality) are a danger zone; on the one hand, they are entirely as safe as conventional logins when users understand how to handle them; and on the other hand, they are an enormous security risk in the hands of careless users, who may use them on public computers and forget to log out, and who may not know what browser cookies are or how to delete them.Personally, I like persistent logins for the websites I visit on a regular basis, but I know how to handle them safely. If you are positive that your users know the same, you can use persistent logins with a clean conscience. If not - well, then you may subscribe to the philosophy that users who are careless with their login credentials brought it upon themselves if they get hacked. It's not like we go to our user's houses and tear off all those facepalm-inducing Post-It notes with passwords they have lined up on the edge of their monitors, either.Of course, some systems can't afford to have any accounts hacked; for such systems, there is no way you can justify having persistent logins.If you DO decide to implement persistent login cookies, this is how you do it:First, take some time to read Paragon Initiative's article on the subject. You'll need to get a bunch of elements right, and the article does a great job of explaining each.And just to reiterate one of the most common pitfalls, DO NOT STORE THE PERSISTENT LOGIN COOKIE (TOKEN) IN YOUR DATABASE, ONLY A HASH OF IT! The login token is Password Equivalent, so if an attacker got their hands on your database, they could use the tokens to log in to any account, just as if they were cleartext login-password combinations. Therefore, use hashing (according to https://security.stackexchange.com/a/63438/5002 a weak hash will do just fine for this purpose) when storing persistent login tokens.Don't implement 'secret questions'. The 'secret questions' feature is a security anti-pattern. Read the paper from link number 4 from the MUST-READ list. You can ask Sarah Palin about that one, after her Yahoo! email account got hacked during a previous presidential campaign because the answer to her security question was... \"Wasilla High School\"!Even with user-specified questions, it is highly likely that most users will choose either:A 'standard' secret question like mother's maiden name or favorite petA simple piece of trivia that anyone could lift from their blog, LinkedIn profile, or similarAny question that is easier to answer than guessing their password. Which, for any decent password, is every question you can imagineIn conclusion, security questions are inherently insecure in virtually all their forms and variations, and should not be employed in an authentication scheme for any reason.The true reason why security questions even exist in the wild is that they conveniently save the cost of a few support calls from users who can't access their email to get to a reactivation code. This at the expense of security and Sarah Palin's reputation. Worth it? Probably not.I already mentioned why you should never use security questions for handling forgotten/lost user passwords; it also goes without saying that you should never e-mail users their actual passwords. There are at least two more all-too-common pitfalls to avoid in this field:Don't reset a forgotten password to an autogenerated strong password - such passwords are notoriously hard to remember, which means the user must either change it or write it down - say, on a bright yellow Post-It on the edge of their monitor. Instead of setting a new password, just let users pick a new one right away - which is what they want to do anyway. (An exception to this might be if the users are universally using a password manager to store/manage passwords that would normally be impossible to remember without writing it down).Always hash the lost password code/token in the database. AGAIN, this code is another example of a Password Equivalent, so it MUST be hashed in case an attacker got their hands on your database. When a lost password code is requested, send the plaintext code to the user's email address, then hash it, save the hash in your database -- and throw away the original. Just like a password or a persistent login token.A final note: always make sure your interface for entering the 'lost password code' is at least as secure as your login form itself, or an attacker will simply use this to gain access instead. Making sure you generate very long 'lost password codes' (for example, 16 case-sensitive alphanumeric characters) is a good start, but consider adding the same throttling scheme that you do for the login form itself.First, you'll want to read this small article for a reality check: The 500 most common passwordsOkay, so maybe the list isn't the canonical list of most common passwords on any system anywhere ever, but it's a good indication of how poorly people will choose their passwords when there is no enforced policy in place. Plus, the list looks frighteningly close to home when you compare it to publicly available analyses of recently stolen passwords.So: With no minimum password strength requirements, 2% of users use one of the top 20 most common passwords. Meaning: if an attacker gets just 20 attempts, 1 in 50 accounts on your website will be crackable.Thwarting this requires calculating the entropy of a password and then applying a threshold.  The National Institute of Standards and Technology (NIST) Special Publication 800-63 has a set of very good suggestions.  That, when combined with a dictionary and keyboard layout analysis (for example, 'qwertyuiop' is a bad password), can reject 99% of all poorly selected passwords at a level of 18 bits of entropy.  Simply calculating password strength and showing a visual strength meter to a user is good, but insufficient.  Unless it is enforced, a lot of users will most likely ignore it.And for a refreshing take on user-friendliness of high-entropy passwords, Randall Munroe's Password Strength xkcd is highly recommended.Utilize Troy Hunt's Have I Been Pwned API to check users passwords against passwords compromised in public data breaches.First, have a look at the numbers: Password Recovery Speeds - How long will your password stand upIf you don't have the time to look through the tables in that link, here's the list of them:It takes virtually no time to crack a weak password, even if you're cracking it with an abacusIt takes virtually no time to crack an alphanumeric 9-character password if it is case insensitiveIt takes virtually no time to crack an intricate, symbols-and-letters-and-numbers, upper-and-lowercase password if it is less than 8 characters long (a desktop PC can search the entire keyspace up to 7 characters in a matter of days or even hours)It would, however, take an inordinate amount of time to crack even a 6-character password, if you were limited to one attempt per second!So what can we learn from these numbers? Well, lots, but we can focus on the most important part: the fact that preventing large numbers of rapid-fire successive login attempts (ie. the brute force attack) really isn't that difficult. But preventing it right isn't as easy as it seems.Generally speaking, you have three choices that are all effective against brute-force attacks (and dictionary attacks, but since you are already employing a strong passwords policy, they shouldn't be an issue):Present a CAPTCHA after N failed attempts (annoying as hell and often ineffective -- but I'm repeating myself here)Locking accounts and requiring email verification after N failed attempts (this is a DoS attack waiting to happen)And finally, login throttling: that is, setting a time delay between attempts after N failed attempts (yes, DoS attacks are still possible, but at least they are far less likely and a lot more complicated to pull off).Best practice #1: A short time delay that increases with the number of failed attempts, like:DoS attacking this scheme would be very impractical, since the resulting lockout time is slightly larger than the sum of the previous lockout times.To clarify: The delay is not a delay before returning the response to the browser. It is more like a timeout or refractory period during which login attempts to a specific account or from a specific IP address will not be accepted or evaluated at all. That is, correct credentials will not return in a successful login, and incorrect credentials will not trigger a delay increase.Best practice #2: A medium length time delay that goes into effect after N failed attempts, like:DoS attacking this scheme would be quite impractical, but certainly doable. Also, it might be relevant to note that such a long delay can be very annoying for a legitimate user. Forgetful users will dislike you.Best practice #3: Combining the two approaches - either a fixed, short time delay that goes into effect after N failed attempts, like:Or, an increasing delay with a fixed upper bound, like:This final scheme was taken from the OWASP best-practices suggestions (link 1 from the MUST-READ list) and should be considered best practice, even if it is admittedly on the restrictive side.As a rule of thumb, however, I would say: the stronger your password policy is, the less you have to bug users with delays. If you require strong (case-sensitive alphanumerics + required numbers and symbols) 9+ character passwords, you could give the users 2-4 non-delayed password attempts before activating the throttling.DoS attacking this final login throttling scheme would be very impractical. And as a final touch, always allow persistent (cookie) logins (and/or a CAPTCHA-verified login form) to pass through, so legitimate users won't even be delayed while the attack is in progress. That way, the very impractical DoS attack becomes an extremely impractical attack.Additionally, it makes sense to do more aggressive throttling on admin accounts, since those are the most attractive entry pointsJust as an aside, more advanced attackers will try to circumvent login throttling by 'spreading their activities':Distributing the attempts on a botnet to prevent IP address flaggingRather than picking one user and trying the 50.000 most common passwords (which they can't, because of our throttling), they will pick THE most common password and try it against 50.000 users instead. That way, not only do they get around maximum-attempts measures like CAPTCHAs and login throttling, their chance of success increases as well, since the number 1 most common password is far more likely than number 49.995Spacing the login requests for each user account, say, 30 seconds apart, to sneak under the radarHere, the best practice would be logging the number of failed logins, system-wide, and using a running average of your site's bad-login frequency as the basis for an upper limit that you then impose on all users.Too abstract? Let me rephrase:Say your site has had an average of 120 bad logins per day over the past 3 months. Using that (running average), your system might set the global limit to 3 times that -- ie. 360 failed attempts over a 24 hour period. Then, if the total number of failed attempts across all accounts exceeds that number within one day (or even better, monitor the rate of acceleration and trigger on a calculated threshold), it activates system-wide login throttling - meaning short delays for ALL users (still, with the exception of cookie logins and/or backup CAPTCHA logins).I also posted a question with more details and a really good discussion of how to avoid tricky pitfals in fending off distributed brute force attacksCredentials can be compromised, whether by exploits, passwords being written down and lost, laptops with keys being stolen, or users entering logins into phishing sites.  Logins can be further protected with two-factor authentication, which uses out-of-band factors such as single-use codes received from a phone call, SMS message, app, or dongle. Several providers offer two-factor authentication services.Authentication can be completely delegated to a single-sign-on service, where another provider handles collecting credentials. This pushes the problem to a trusted third party. Google and Twitter both provide standards-based SSO services, while Facebook provides a similar proprietary solution.",
                "The only practical way to send credentials 100% securely is by using SSL. Using JavaScript to hash the password is not safe. Common pitfalls for client-side password hashing:There's another secure method called SRP, but it's patented (although it is freely licensed) and there are few good implementations available.Don't ever store passwords as plaintext in the database. Not even if you don't care about the security of your own site. Assume that some of your users will reuse the password of their online bank account. So, store the hashed password, and throw away the original. And make sure the password doesn't show up in access logs or application logs. OWASP recommends the use of Argon2 as your first choice for new applications. If this is not available, PBKDF2 or scrypt should be used instead. And finally if none of the above are available, use bcrypt.Hashes by themselves are also insecure. For instance, identical passwords mean identical hashes--this makes hash lookup tables an effective way of cracking lots of passwords at once. Instead, store the salted hash. A salt is a string appended to the password prior to hashing - use a different (random) salt per user. The salt is a public value, so you can store them with the hash in the database. See here for more on this.This means that you can't send the user their forgotten passwords (because you only have the hash). Don't reset the user's password unless you have authenticated the user (users must prove that they are able to read emails sent to the stored (and validated) email address.)Security questions are insecure - avoid using them. Why? Anything a security question does, a password does better. Read PART III: Using Secret Questions in @Jens Roland answer here in this wiki.After the user logs in, the server sends the user a session cookie. The server can retrieve the username or id from the cookie, but nobody else can generate such a cookie (TODO explain mechanisms).Cookies can be hijacked: they are only as secure as the rest of the client's machine and other communications. They can be read from disk, sniffed in network traffic, lifted by a cross-site scripting attack, phished from a poisoned DNS so the client sends their cookies to the wrong servers. Don't send persistent cookies. Cookies should expire at the end of the client session (browser close or leaving your domain).If you want to autologin your users, you can set a persistent cookie, but it should be distinct from a full-session cookie. You can set an additional flag that the user has auto-logged in, and needs to log in for real for sensitive operations. This is popular with shopping sites that want to provide you with a seamless, personalized shopping experience but still protect your financial details. For example, when you return to visit Amazon, they show you a page that looks like you're logged in, but when you go to place an order (or change your shipping address, credit card etc.), they ask you to confirm your password.Financial websites such as banks and credit cards, on the other hand, only have sensitive data and should not allow auto-login or a low-security mode.",
                "First, a strong caveat that this answer is not the best fit for this exact question. It should definitely not be the top answer!I will go ahead and mention Mozilla\u2019s proposed BrowserID (or perhaps more precisely, the Verified Email Protocol) in the spirit of finding an upgrade path to better approaches to authentication in the future.I\u2019ll summarize it this way:This is not strictly \u201cform-based authentication for websites\u201d. But it is an effort to transition from the current norm of form-based authentication to something more secure: browser-supported authentication.",
                "I just thought I'd share this solution that I found to be working just fine.I call it the Dummy Field (though I haven't invented this so don't credit me). Others know this as a honey pot.In short: you just have to insert this into your <form> and check for it to be empty at when validating:The trick is to fool a bot into thinking it has to insert data into a required field, that's why I named the input \"email\". If you already have a field called email that you're using you should try naming the dummy field something else like \"company\", \"phone\" or \"emailaddress\". Just pick something you know you don't need and what sounds like something people would normally find logical to fill in into a web form. Now hide the input field using CSS or JavaScript/jQuery - whatever fits you best - just don't set the input type to hidden or else the bot won't fall for it.When you are validating the form (either client or server side) check if your dummy field has been filled to determine if it was sent by a human or a bot.Example:In case of a human:\nThe user will not see the dummy field (in my case named \"email\") and will not attempt to fill it. So the value of the dummy field should still be empty when the form has been sent.In case of a bot: The bot will see a field whose type is text and a name email (or whatever it is you called it) and will logically attempt to fill it with appropriate data. It doesn't care if you styled the input form with some fancy CSS, web-developers do it all the time. Whatever the value in the dummy field is, we don't care as long as it's larger than 0 characters.I used this method on a guestbook in combination with CAPTCHA, and I haven't seen a single spam post since. I had used a CAPTCHA-only solution before, but eventually, it resulted in about five spam posts every hour. Adding the dummy field in the form has stopped (at least until now) all the spam from appearing.I believe this can also be used just fine with a login/authentication form.Warning: Of course this method is not 100% foolproof. Bots can be programmed to ignore input fields with the style display:none applied to it. You also have to think about people who use some form of auto-completion (like most browsers have built-in!) to auto-fill all form fields for them. They might just as well pick up a dummy field.You can also vary this up a little by leaving the dummy field visible but outside the boundaries of the screen, but this is totally up to you.Be creative!",
                "I do not think the above answer is \"wrong\" but there are large areas of authentication that are not touched upon (or rather the emphasis is on \"how to implement cookie sessions\", not on \"what options are available and what are the trade-offs\".My suggested edits/answers areDo NOT try to implement your own login form or database storage of passwords, unless \nthe data being stored is valueless at account creation and self-generated (that is, web 2.0 style like Facebook, Flickr, etc.)This avoids any need to have \"sessions\" or cookies as the browser itself will re-encrypt the communication each time. It is the most \"lightweight\" development approach.However, I do not recommend this, except for public, low-value services. This is an issue with some of the other answers above - do not try an re-implement server-side authentication mechanisms - this problem has been solved and is supported by most major browsers. Do not use cookies. Do not store anything in your own hand-rolled database. Just ask, per request, if the request is authenticated. Everything else should be supported by configuration and third-party trusted software.So ...First, we are confusing the initial creation of an account (with a password) with the re-checking of the password subsequently. If I am Flickr and creating your site for the first time, the new user has access to zero value (blank web space). I truly do not care if the person creating the account is lying about their name. If I am creating an account of the hospital intranet/extranet, the value lies in all the medical records, and so I do care about the identity (*) of the account creator.This is the very very hard part. The only decent solution is a web of trust. For example, you join the hospital as a doctor. You create a web page hosted somewhere with your photo, your passport number, and a public key, and hash them all with the private key. You then visit the hospital and the system administrator looks at your passport, sees if the photo matches you, and then hashes the web page/photo hash with the hospital private key. From now on we can securely exchange keys and tokens. As can anyone who trusts the hospital (there is the secret sauce BTW). The system administrator can also give you an RSA dongle or other two-factor authentication.But this is a lot of a hassle, and not very web 2.0. However, it is the only secure way to create new accounts that have access to valuable information that is not self-created.Kerberos and SPNEGO - single sign-on mechanisms with a trusted third party - basically the user verifies against a trusted third party. (NB this is not in any way the not to be trusted OAuth)SRP - sort of clever password authentication without a trusted third party. But here we are getting into the realms of \"it's safer to use two-factor authentication, even if that's costlier\"SSL client side - give the clients a public key certificate (support in all major browsers - but raises questions over client machine security).In the end, it's a tradeoff - what is the cost of a security breach vs the cost of implementing more secure approaches. One day, we may see a proper PKI widely accepted and so no more own rolled authentication forms and databases. One day...",
                "When hashing, don't use fast hash algorithms such as MD5 (many hardware implementations exist).  Use something like SHA-512.  For passwords, slower hashes are better.The faster you can create hashes, the faster any brute force checker can work. Slower hashes will therefore slow down brute forcing. A slow hash algorithm will make brute forcing impractical for longer passwords (8 digits +)",
                "My favourite rule in regards to authentication systems: use passphrases, not passwords. Easy to remember, hard to crack.\nMore info: Coding Horror: Passwords vs. Pass Phrases",
                "I'd like to add one suggestion I've used, based on defense in depth. You don't need to have the same auth&auth system for admins as regular users. You can have a separate login form on a separate url executing separate code for requests that will grant high privileges. This one can make choices that would be a total pain to regular users. One such that I've used is to actually scramble the login URL for admin access and email the admin the new URL. Stops any brute force attack right away as your new URL can be arbitrarily difficult (very long random string) but your admin user's only inconvenience is following a link in their email. The attacker no longer knows where to even POST to.",
                "I dont't know whether it was best to answer this as an answer or as a comment. I opted for the first option.Regarding the poing PART IV: Forgotten Password Functionality in the first answer, I would make a point about Timing Attacks.In the Remember your password forms, an attacker could potentially check a full list of emails and detect which are registered to the system (see link below).Regarding the Forgotten Password Form, I would add that it is a good idea to equal times between successful and unsucessful queries with some delay function.https://crypto.stanford.edu/~dabo/papers/webtiming.pdf",
                "I would like to add one very important comment: -Many corporations deploy \"internal use only\" websites which are, effectively, \"corporate applications\" that happen to have been implemented through URLs. These URLs can (supposedly ...) only be resolved within \"the company's internal network.\" (Which network magically includes all VPN-connected 'road warriors.')When a user is dutifully-connected to the aforesaid network, their identity (\"authentication\") is [already ...] \"conclusively known,\" as is their permission (\"authorization\") to do certain things ... such as ... \"to access this website.\"This \"authentication + authorization\" service can be provided by several different technologies, such as LDAP (Microsoft OpenDirectory), or Kerberos.From your point-of-view, you simply know this: that anyone who legitimately winds-up at your website must be accompanied by [an environment-variable magically containing ...] a \"token.\" (i.e. The absence of such a token must be immediate grounds for 404 Not Found.)The token's value makes no sense to you, but, should the need arise, \"appropriate means exist\" by which your website can \"[authoritatively] ask someone who knows (LDAP... etc.)\" about any and every(!) question that you may have. In other words, you do not avail yourself of any \"home-grown logic.\" Instead, you inquire of The Authority and implicitly trust its verdict.Uh huh ... it's quite a mental-switch from the \"wild-and-wooly Internet.\"",
                "Use OpenID Connect or User-Managed Access.As nothing is more efficient than not doing it at all."
            ]
        },
        {
            "tag": "",
            "question": [
                "Why is processing a sorted array faster than processing an unsorted array?",
                "Here is a piece of C++ code that shows some very peculiar behavior.\nFor some reason, sorting the data (before the timed region) miraculously makes the primary loop almost six times faster:\n#include &..."
            ],
            "url": "https://stackoverflow.com/questions/11227809",
            "answer": [
                "You are a victim of branch prediction fail.Consider a railroad junction:Image by Mecanismo, via Wikimedia Commons. Used under the CC-By-SA 3.0 license.Now for the sake of argument, suppose this is back in the 1800s - before long-distance or radio communication.You are a blind operator of a junction and you hear a train coming. You have no idea which way it is supposed to go. You stop the train to ask the driver which direction they want. And then you set the switch appropriately.Trains are heavy and have a lot of inertia, so they take forever to start up and slow down.Is there a better way? You guess which direction the train will go!If you guess right every time, the train will never have to stop.\nIf you guess wrong too often, the train will spend a lot of time stopping, backing up, and restarting.Consider an if-statement: At the processor level, it is a branch instruction:You are a processor and you see a branch. You have no idea which way it will go. What do you do? You halt execution and wait until the previous instructions are complete. Then you continue down the correct path.Modern processors are complicated and have long pipelines. This means they take forever to \"warm up\" and \"slow down\".Is there a better way? You guess which direction the branch will go!If you guess right every time, the execution will never have to stop.\nIf you guess wrong too often, you spend a lot of time stalling, rolling back, and restarting.This is branch prediction. I admit it's not the best analogy since the train could just signal the direction with a flag. But in computers, the processor doesn't know which direction a branch will go until the last moment.How would you strategically guess to minimize the number of times that the train must back up and go down the other path? You look at the past history! If the train goes left 99% of the time, then you guess left. If it alternates, then you alternate your guesses. If it goes one way every three times, you guess the same...In other words, you try to identify a pattern and follow it. This is more or less how branch predictors work.Most applications have well-behaved branches. Therefore, modern branch predictors will typically achieve >90% hit rates. But when faced with unpredictable branches with no recognizable patterns, branch predictors are virtually useless.Further reading: \"Branch predictor\" article on Wikipedia.Notice that the data is evenly distributed between 0 and 255. When the data is sorted, roughly the first half of the iterations will not enter the if-statement. After that, they will all enter the if-statement.This is very friendly to the branch predictor since the branch consecutively goes the same direction many times. Even a simple saturating counter will correctly predict the branch except for the few iterations after it switches direction.Quick visualization:However, when the data is completely random, the branch predictor is rendered useless, because it can't predict random data. Thus there will probably be around 50% misprediction (no better than random guessing).What can be done?If the compiler isn't able to optimize the branch into a conditional move, you can try some hacks if you are willing to sacrifice readability for performance.Replace:with:This eliminates the branch and replaces it with some bitwise operations.(Note that this hack is not strictly equivalent to the original if-statement. But in this case, it's valid for all the input values of data[].)Benchmarks: Core i7 920 @ 3.5 GHzC++ - Visual Studio 2010 - x64 ReleaseJava - NetBeans 7.1.1 JDK 7 - x64Observations:A general rule of thumb is to avoid data-dependent branching in critical loops (such as in this example).Update:GCC 4.6.1 with -O3 or -ftree-vectorize on x64 is able to generate a conditional move, so there is no difference between the sorted and unsorted data - both are fast.(Or somewhat fast: for the already-sorted case, cmov can be slower especially if GCC puts it on the critical path instead of just add, especially on Intel before Broadwell where cmov has 2 cycle latency: gcc optimization flag -O3 makes code slower than -O2)VC++ 2010 is unable to generate conditional moves for this branch even under /Ox.Intel C++ Compiler (ICC) 11 does something miraculous. It interchanges the two loops, thereby hoisting the unpredictable branch to the outer loop. Not only is it immune to the mispredictions, it's also twice as fast as whatever VC++ and GCC can generate! In other words, ICC took advantage of the test-loop to defeat the benchmark...If you give the Intel compiler the branchless code, it just outright vectorizes it... and is just as fast as with the branch (with the loop interchange).This goes to show that even mature modern compilers can vary wildly in their ability to optimize code...",
                "Branch prediction.With a sorted array, the condition data[c] >= 128 is first false for a streak of values, then becomes true for all later values. That's easy to predict. With an unsorted array, you pay for the branching cost.",
                "The reason why performance improves drastically when the data is sorted is that the branch prediction penalty is removed, as explained beautifully in Mysticial's answer.Now, if we look at the codewe can find that the meaning of this particular if... else... branch is to add something when a condition is satisfied. This type of branch can be easily transformed into a conditional move statement, which would be compiled into a conditional move instruction: cmovl, in an x86 system. The branch and thus the potential branch prediction penalty is removed.In C, thus C++, the statement, which would compile directly (without any optimization) into the conditional move instruction in x86, is the ternary operator ... ? ... : .... So we rewrite the above statement into an equivalent one:While maintaining readability, we can check the speedup factor.On an Intel Core i7-2600K @ 3.4\u00a0GHz and Visual Studio 2010 Release Mode, the benchmark is:x86x64The result is robust in multiple tests. We get a great speedup when the branch result is unpredictable, but we suffer a little bit when it is predictable. In fact, when using a conditional move, the performance is the same regardless of the data pattern.Now let's look more closely by investigating the x86 assembly they generate. For simplicity, we use two functions max1 and max2.max1 uses the conditional branch if... else ...:max2 uses the ternary operator ... ? ... : ...:On an x86-64 machine, GCC -S generates the assembly below.max2 uses much less code due to the usage of instruction cmovge. But the real gain is that max2 does not involve branch jumps, jmp, which would have a significant performance penalty if the predicted result is not right.So why does a conditional move perform better?In a typical x86 processor, the execution of an instruction is divided into several stages. Roughly, we have different hardware to deal with different stages. So we do not have to wait for one instruction to finish to start a new one. This is called pipelining.In a branch case, the following instruction is determined by the preceding one, so we cannot do pipelining. We have to either wait or predict.In a conditional move case, the execution of conditional move instruction is divided into several stages, but the earlier stages like Fetch and Decode do not depend on the result of the previous instruction; only the latter stages need the result. Thus, we wait a fraction of one instruction's execution time. This is why the conditional move version is slower than the branch when the prediction is easy.The book Computer Systems: A Programmer's Perspective, second edition explains this in detail. You can check Section 3.6.6 for Conditional Move Instructions, entire Chapter 4 for Processor Architecture, and Section 5.11.2 for special treatment for Branch Prediction and Misprediction Penalties.Sometimes, some modern compilers can optimize our code to assembly with better performance, and sometimes some compilers can't (the code in question is using Visual Studio's native compiler). Knowing the performance difference between a branch and a conditional move when unpredictable can help us write code with better performance when the scenario gets so complex that the compiler can not optimize them automatically.",
                "If you are curious about even more optimizations that can be done to this code, consider this:Starting with the original loop:With loop interchange, we can safely change this loop to:Then, you can see that the if conditional is constant throughout the execution of the i loop, so you can hoist the if out:Then, you see that the inner loop can be collapsed into one single expression, assuming the floating point model allows it (/fp:fast is thrown, for example)That one is 100,000 times faster than before.",
                "No doubt some of us would be interested in ways of identifying code that is problematic for the CPU's branch-predictor. The Valgrind tool cachegrind has a branch-predictor simulator, enabled by using the --branch-sim=yes flag. Running it over the examples in this question, with the number of outer loops reduced to 10000 and compiled with g++, gives these results:Sorted:Unsorted:Drilling down into the line-by-line output produced by cg_annotate we see for the loop in question:Sorted:Unsorted:This lets you easily identify the problematic line - in the unsorted version the if (data[c] >= 128) line is causing 164,050,007 mispredicted conditional branches (Bcm) under cachegrind's branch-predictor model, whereas it's only causing 10,006 in the sorted version.Alternatively, on Linux you can use the performance counters subsystem to accomplish the same task, but with native performance using CPU counters.Sorted:Unsorted:It can also do source code annotation with dissassembly.See the performance tutorial for more details.",
                "I just read up on this question and its answers, and I feel an answer is missing.A common way to eliminate branch prediction that I've found to work particularly good in managed languages is a table lookup instead of using a branch (although I haven't tested it in this case).This approach works in general if:Background and whyFrom a processor perspective, your memory is slow. To compensate for the difference in speed, a couple of caches are built into your processor (L1/L2 cache). So imagine that you're doing your nice calculations and figure out that you need a piece of memory. The processor will get its 'load' operation and loads the piece of memory into cache -- and then uses the cache to do the rest of the calculations. Because memory is relatively slow, this 'load' will slow down your program.Like branch prediction, this was optimized in the Pentium processors: the processor predicts that it needs to load a piece of data and attempts to load that into the cache before the operation actually hits the cache. As we've already seen, branch prediction sometimes goes horribly wrong -- in the worst case scenario you need to go back and actually wait for a memory load, which will take forever (in other words: failing branch prediction is bad, a memory load after a branch prediction fail is just horrible!).Fortunately for us, if the memory access pattern is predictable, the processor will load it in its fast cache and all is well.The first thing we need to know is what is small? While smaller is generally better, a rule of thumb is to stick to lookup tables that are <= 4096 bytes in size. As an upper limit: if your lookup table is larger than 64K it's probably worth reconsidering.Constructing a tableSo we've figured out that we can create a small table. Next thing to do is get a lookup function in place. Lookup functions are usually small functions that use a couple of basic integer operations (and, or, xor, shift, add, remove and perhaps multiply). You want to have your input translated by the lookup function to some kind of 'unique key' in your table, which then simply gives you the answer of all the work you wanted it to do.In this case: >= 128 means we can keep the value, < 128 means we get rid of it. The easiest way to do that is by using an 'AND': if we keep it, we AND it with 7FFFFFFF; if we want to get rid of it, we AND it with 0. Notice also that 128 is a power of 2 -- so we can go ahead and make a table of 32768/128 integers and fill it with one zero and a lot of 7FFFFFFFF's.Managed languagesYou might wonder why this works well in managed languages. After all, managed languages check the boundaries of the arrays with a branch to ensure you don't mess up...Well, not exactly... :-)There has been quite some work on eliminating this branch for managed languages. For example:In this case, it's obvious to the compiler that the boundary condition will never be hit. At least the Microsoft JIT compiler (but I expect Java does similar things) will notice this and remove the check altogether. WOW, that means no branch. Similarly, it will deal with other obvious cases.If you run into trouble with lookups in managed languages -- the key is to add a & 0x[something]FFF to your lookup function to make the boundary check predictable -- and watch it going faster.The result of this case",
                "As data is distributed between 0 and 255 when the array is sorted, around the first half of the iterations will not enter the if-statement (the if statement is shared below).The question is: What makes the above statement not execute in certain cases as in case of sorted data? Here comes the \"branch predictor\". A branch predictor is a digital circuit that tries to guess which way a branch (e.g. an if-then-else structure) will go before this is known for sure. The purpose of the branch predictor is to improve the flow in the instruction pipeline. Branch predictors play a critical role in achieving high effective performance!Let's do some bench marking to understand it betterThe performance of an if-statement depends on whether its condition has a predictable pattern. If the condition is always true or always false, the branch prediction logic in the processor will pick up the pattern. On the other hand, if the pattern is unpredictable, the if-statement will be much more expensive.Let\u2019s measure the performance of this loop with different conditions:Here are the timings of the loop with different true-false patterns:A \u201cbad\u201d true-false pattern can make an if-statement up to six times slower than a \u201cgood\u201d pattern! Of course, which pattern is good and which is bad depends on the exact instructions generated by the compiler and on the specific processor.So there is no doubt about the impact of branch prediction on performance!",
                "One way to avoid branch prediction errors is to build a lookup table, and index it using the data.  Stefan de Bruijn discussed that in his answer.But in this case, we know values are in the range [0, 255] and we only care about values >= 128.  That means we can easily extract a single bit that will tell us whether we want a value or not: by shifting the data to the right 7 bits, we are left with a 0 bit or a 1 bit, and we only want to add the value when we have a 1 bit.  Let's call this bit the \"decision bit\".By using the 0/1 value of the decision bit as an index into an array, we can make code that will be equally fast whether the data is sorted or not sorted.  Our code will always add a value, but when the decision bit is 0, we will add the value somewhere we don't care about.  Here's the code:This code wastes half of the adds but never has a branch prediction failure.  It's tremendously faster on random data than the version with an actual if statement.But in my testing, an explicit lookup table was slightly faster than this, probably because indexing into a lookup table was slightly faster than bit shifting.  This shows how my code sets up and uses the lookup table (unimaginatively called lut for \"LookUp Table\" in the code).  Here's the C++ code:In this case, the lookup table was only 256 bytes, so it fits nicely in a cache and all was fast.  This technique wouldn't work well if the data was 24-bit values and we only wanted half of them... the lookup table would be far too big to be practical.  On the other hand, we can combine the two techniques shown above: first shift the bits over, then index a lookup table.  For a 24-bit value that we only want the top half value, we could potentially shift the data right by 12 bits, and be left with a 12-bit value for a table index.  A 12-bit table index implies a table of 4096 values, which might be practical.The technique of indexing into an array, instead of using an if statement, can be used for deciding which pointer to use.  I saw a library that implemented binary trees, and instead of having two named pointers (pLeft and pRight or whatever) had a length-2 array of pointers and used the \"decision bit\" technique to decide which one to follow.  For example, instead of:this library would do something like:Here's a link to this code: Red Black Trees, Eternally Confuzzled",
                "In the sorted case, you can do better than relying on successful branch prediction or any branchless comparison trick: completely remove the branch.Indeed, the array is partitioned in a contiguous zone with data < 128 and another with data >= 128. So you should find the partition point with a dichotomic search (using Lg(arraySize) = 15 comparisons), then do a straight accumulation from that point.Something like (unchecked)or, slightly more obfuscatedA yet faster approach, that gives an approximate solution for both sorted or unsorted is: sum= 3137536; (assuming a truly uniform distribution, 16384 samples with expected value 191.5) :-)",
                "The above behavior is happening because of Branch prediction.To understand branch prediction one must first understand an Instruction Pipeline.The the steps of running an instruction can be overlapped with the sequence of steps of running the previous and next instruction, so that different steps can be executed concurrently in parallel. This technique is known as instruction pipelining and is used to increase throughput in modern processors. To understand this better please see this example on Wikipedia.Generally, modern processors have quite long (and wide) pipelines, so many instruction can be in flight.  See Modern Microprocessors\nA 90-Minute Guide! which starts by introducing basic in-order pipelining and goes from there.But for ease let's consider a simple in-order pipeline with these 4 steps only.\n(Like a classic 5-stage RISC, but omitting a separate MEM stage.)4-stage pipeline in general for 2 instructions.Moving back to the above question let's consider the following instructions:Without branch prediction, the following would occur:To execute instruction B or instruction C the processor will have to wait (stall) till the instruction A leaves the EX stage in the pipeline, as the decision to go to instruction B or instruction C depends on the result of instruction A.  (i.e. where to fetch from next.) So the pipeline will look like this:Without prediction: when if condition is true:Without prediction: When if condition is false:As a result of waiting for the result of instruction A, the total CPU cycles spent in the above case (without branch prediction; for both true and false) is 7.So what is branch prediction?Branch predictor will try to guess which way a branch (an if-then-else structure) will go before this is known for sure. It will not wait for the instruction A to reach the EX stage of the pipeline, but it will guess the decision and go to that instruction (B or C in case of our example).In case of a correct guess, the pipeline looks something like this:If it is later detected that the guess was wrong then the partially executed instructions are discarded and the pipeline starts over with the correct branch, incurring a delay.\nThe time that is wasted in case of a branch misprediction is equal to the number of stages in the pipeline from the fetch stage to the execute stage. Modern microprocessors tend to have quite long pipelines so that the misprediction delay is between 10 and 20 clock cycles. The longer the pipeline the greater the need for a good branch predictor.In the OP's code, the first time when the conditional, the branch predictor does not have any information to base up prediction, so the first time it will randomly choose the next instruction. (Or fall back to static prediction, typically forward not-taken, backward taken).  Later in the for loop, it can base the prediction on the history.\nFor an array sorted in ascending order, there are three possibilities:Let us assume that the predictor will always assume the true branch on the first run.So in the first case, it will always take the true branch since historically all its predictions are correct.\nIn the 2nd case, initially it will predict wrong, but after a few iterations, it will predict correctly.\nIn the 3rd case, it will initially predict correctly till the elements are less than 128. After which it will fail for some time and the correct itself when it sees branch prediction failure in history.In all these cases the failure will be too less in number and as a result, only a few times it will need to discard the partially executed instructions and start over with the correct branch, resulting in fewer CPU cycles.But in case of a random unsorted array, the prediction will need to discard the partially executed instructions and start over with the correct branch most of the time and result in more CPU cycles compared to the sorted array.Further reading:",
                "An official answer would be fromYou can also see from this lovely diagram why the branch predictor gets confused.Each element in the original code is a random valueso the predictor will change sides as the std::rand() blow.On the other hand, once it's sorted, the predictor will first move into a state of strongly not taken and when the values change to the high value the predictor will in three runs through change all the way from strongly not taken to strongly taken.",
                "In the same line (I think this was not highlighted by any answer) it's good to mention that sometimes (specially in software where the performance matters\u2014like in the Linux kernel) you can find some if statements like the following:or similarly:Both likely() and unlikely() are in fact macros that are defined by using something like the GCC's __builtin_expect to help the compiler insert prediction code to favour the condition taking into account the information provided by the user. GCC supports other builtins that could change the behavior of the running program or emit low level instructions like clearing the cache, etc. See this documentation that goes through the available GCC's builtins.Normally this kind of optimizations are mainly found in hard-real time applications or embedded systems where execution time matters and it's critical. For example, if you are checking for some error condition that only happens 1/10000000 times, then why not inform the compiler about this? This way, by default, the branch prediction would assume that the condition is false.",
                "Frequently used Boolean operations in C++ produce many branches in the compiled program. If these branches are inside loops and are hard to predict they can slow down execution significantly. Boolean variables are stored as 8-bit integers with the value 0 for false and 1 for true.Boolean variables are overdetermined in the sense that all operators that have Boolean variables as input check if the inputs have any other value than 0 or 1, but operators that have Booleans as output can produce no other value than 0 or 1. This makes operations with Boolean variables as input less efficient than necessary.\nConsider example:This is typically implemented by the compiler in the following way:This code is far from optimal. The branches may take a long time in case of mispredictions. The Boolean operations can be made much more efficient if it is known with certainty that the operands have no other values than 0 and 1. The reason why the compiler does not make such an assumption is that the variables might have other values if they are uninitialized or come from unknown sources. The above code can be optimized if a and b has been initialized to valid values or if they come from operators that produce Boolean output. The optimized code looks like this:char is used instead of bool in order to make it possible to use the bitwise operators (& and |) instead of the Boolean operators (&& and ||). The bitwise operators are single instructions that take only one clock cycle. The OR operator (|) works even if a and b have other values than 0 or 1. The AND operator (&) and the EXCLUSIVE OR operator (^) may give inconsistent results if the operands have other values than 0 and 1.~ can not be used for NOT. Instead, you can make a Boolean NOT on a variable which is known to be 0 or 1 by XOR'ing it with 1:can be optimized to:a && b cannot be replaced with a & b if b is an expression that should not be evaluated if a is false ( && will not evaluate b, & will). Likewise, a || b can not be replaced with a | b if b is an expression that should not be evaluated if a is true.Using bitwise operators is more advantageous if the operands are variables than if the operands are comparisons:is optimal in most cases (unless you expect the && expression to generate many branch mispredictions).",
                "That's for sure!...Branch prediction makes the logic run slower, because of the switching which happens in your code! It's like you are going a straight street or a street with a lot of turnings, for sure the straight one is going to be done quicker!...If the array is sorted, your condition is false at the first step: data[c] >= 128, then becomes a true value for the whole way to the end of the street. That's how you get to the end of the logic faster. On the other hand, using an unsorted array, you need a lot of turning and processing which make your code run slower for sure...Look at the image I created for you below. Which street is going to be finished faster?So programmatically, branch prediction causes the process to be slower...Also at the end, it's good to know we have two kinds of branch predictions that each is going to affect your code differently:1. Static2. DynamicStatic branch prediction is used by the microprocessor the first time\na conditional branch is encountered, and dynamic branch prediction is\nused for succeeding executions of the conditional branch code.In order to effectively write your code to take advantage of these\nrules, when writing if-else or switch statements, check the most\ncommon cases first and work progressively down to the least common.\nLoops do not necessarily require any special ordering of code for\nstatic branch prediction, as only the condition of the loop iterator\nis normally used.",
                "This question has already been answered excellently many times over. Still I'd like to draw the group's attention to yet another interesting analysis.Recently this example (modified very slightly) was also used as a way to demonstrate how a piece of code can be profiled within the program itself on Windows. Along the way, the author also shows how to use the results to determine where the code is spending most of its time in both the sorted & unsorted case. Finally the piece also shows how to use a little known feature of the HAL (Hardware Abstraction Layer) to determine just how much branch misprediction is happening in the unsorted case.The link is here:\nA Demonstration of Self-Profiling",
                "As what has already been mentioned by others, what behind the mystery is Branch Predictor.I'm not trying to add something but explaining the concept in another way. \nThere is a concise introduction on the wiki which contains text and diagram.\nI do like the explanation below which uses a diagram to elaborate the Branch Predictor intuitively.In computer architecture, a branch predictor is a\n  digital circuit that tries to guess which way a branch (e.g. an\n  if-then-else structure) will go before this is known for sure. The\n  purpose of the branch predictor is to improve the flow in the\n  instruction pipeline. Branch predictors play a critical role in\n  achieving high effective performance in many modern pipelined\n  microprocessor architectures such as x86.Two-way branching is usually implemented with a conditional jump\n  instruction. A conditional jump can either be \"not taken\" and continue\n  execution with the first branch of code which follows immediately\n  after the conditional jump, or it can be \"taken\" and jump to a\n  different place in program memory where the second branch of code is\n  stored. It is not known for certain whether a conditional jump will be\n  taken or not taken until the condition has been calculated and the\n  conditional jump has passed the execution stage in the instruction\n  pipeline (see fig. 1).Based on the described scenario, I have written an animation demo to show how instructions are executed in a pipeline in different situations.Without branch prediction, the processor would have to wait until the\n  conditional jump instruction has passed the execute stage before the\n  next instruction can enter the fetch stage in the pipeline.The example contains three instructions and the first one is a conditional jump instruction. The latter two instructions can go into the pipeline until the conditional jump instruction is executed.It will take 9 clock cycles for 3 instructions to be completed.It will take 7 clock cycles for 3 instructions to be completed.It will take 9 clock cycles for 3 instructions to be completed.The time that is wasted in case of a branch misprediction is equal to\n  the number of stages in the pipeline from the fetch stage to the\n  execute stage. Modern microprocessors tend to have quite long\n  pipelines so that the misprediction delay is between 10 and 20 clock\n  cycles. As a result, making a pipeline longer increases the need for a\n  more advanced branch predictor.As you can see, it seems we don't have a reason not to use Branch Predictor.It's quite a simple demo that clarifies the very basic part of Branch Predictor. If those gifs are annoying, please feel free to remove them from the answer and visitors can also get the live demo source code from BranchPredictorDemo",
                "Branch-prediction gain!It is important to understand that branch misprediction doesn't slow down programs. The cost of a missed prediction is just as if branch prediction didn't exist and you waited for the evaluation of the expression to decide what code to run (further explanation in the next paragraph).Whenever there's an if-else \\ switch statement, the expression has to be evaluated to determine which block should be executed. In the assembly code generated by the compiler, conditional branch instructions are inserted.A branch instruction can cause a computer to begin executing a different instruction sequence and thus deviate from its default behavior of executing instructions in order (i.e. if the expression is false, the program skips the code of the if block) depending on some condition, which is the expression evaluation in our case.That being said, the compiler tries to predict the outcome prior to it being actually evaluated. It will fetch instructions from the if block, and if the expression turns out to be true, then wonderful! We gained the time it took to evaluate it and made progress in the code; if not then we are running the wrong code, the pipeline is flushed, and the correct block is run.Let's say you need to pick route 1 or route 2. Waiting for your partner to check the map, you have stopped at ## and waited, or you could just pick route1 and if you were lucky (route 1 is the correct route), then great you didn't have to wait for your partner to check the map (you saved the time it would have taken him to check the map), otherwise you will just turn back.While flushing pipelines is super fast, nowadays taking this gamble is worth it. Predicting sorted data or a data that changes slowly is always easier and better than predicting fast changes.",
                "On ARM, there is no branch needed, because every instruction has a 4-bit condition field, which tests (at zero cost) any of 16 different different conditions that may arise in the Processor Status Register, and if the condition on an instruction is false, the instruction is skipped. This eliminates the need for short branches, and there would be no branch prediction hit for this algorithm. Therefore, the sorted version of this algorithm would run slower than the unsorted version on ARM, because of the extra overhead of sorting.The inner loop for this algorithm would look something like the following in ARM assembly language:But this is actually part of a bigger picture:CMP opcodes always update the status bits in the Processor Status Register (PSR), because that is their purpose, but most other instructions do not touch the PSR unless you add an optional S suffix to the instruction, specifying that the PSR should be updated based on the result of the instruction. Just like the 4-bit condition suffix, being able to execute instructions without affecting the PSR is a mechanism that reduces the need for branches on ARM, and also facilitates out of order dispatch at the hardware level, because after performing some operation X that updates the status bits, subsequently (or in parallel) you can do a bunch of other work that explicitly should not affect (or be affected by) the status bits, then you can test the state of the status bits set earlier by X.The condition testing field and the optional \"set status bit\" field can be combined, for example:Most processor architectures do not have this ability to specify whether or not the status bits should be updated for a given operation, which can necessitate writing additional code to save and later restore status bits, or may require additional branches, or may limit the processor's out of order execution efficiency: one of the side effects of most CPU instruction set architectures forcibly updating status bits after most instructions is that it is much harder to tease apart which instructions can be run in parallel without interfering with each other. Updating status bits has side effects, therefore has a linearizing effect on code. ARM's ability to mix and match branch-free condition testing on any instruction with the option to either update or not update the status bits after any instruction is extremely powerful, for both assembly language programmers and compilers, and produces very efficient code.When you don't have to branch, you can avoid the time cost of flushing the pipeline for what would otherwise be short branches, and you can avoid the design complexity of many forms of speculative evalution. The performance impact of the initial naive imlementations of the mitigations for many recently discovered processor vulnerabilities (Spectre etc.) shows you just how much the performance of modern processors depends upon complex speculative evaluation logic. With a short pipeline and the dramatically reduced need for branching, ARM just doesn't need to rely on speculative evaluation as much as CISC processors. (Of course high-end ARM implementations do include speculative evaluation, but it's a smaller part of the performance story.)If you have ever wondered why ARM has been so phenomenally successful, the brilliant effectiveness and interplay of these two mechanisms (combined with another mechanism that lets you \"barrel shift\" left or right one of the two arguments of any arithmetic operator or offset memory access operator at zero additional cost) are a big part of the story, because they are some of the greatest sources of the ARM architecture's efficiency. The brilliance of the original designers of the ARM ISA back in 1983, Steve Furber and Roger (now Sophie) Wilson, cannot be overstated.",
                "It's about branch prediction. What is it?A branch predictor is one of the ancient performance-improving techniques which still finds relevance in modern architectures. While the simple prediction techniques provide fast lookup and power efficiency they suffer from a high misprediction rate.On the other hand, complex branch predictions \u2013either neural-based or variants of two-level branch prediction \u2013provide better prediction accuracy, but they consume more power and complexity increases exponentially.In addition to this, in complex prediction techniques, the time taken to predict the branches is itself very high \u2013ranging from 2 to 5 cycles \u2013which is comparable to the execution time of actual branches.Branch prediction is essentially an optimization (minimization) problem where the emphasis is on to achieve lowest possible miss rate, low power consumption, and low complexity with minimum resources.There really are three different kinds of branches:Forward conditional branches - based on a run-time condition, the PC (program counter) is changed to point to an address forward in the instruction stream.Backward conditional branches - the PC is changed to point backward in the instruction stream. The branch is based on some condition, such as branching backwards to the beginning of a program loop when a test at the end of the loop states the loop should be executed again.Unconditional branches - this includes jumps, procedure calls, and returns that have no specific condition. For example, an unconditional jump instruction might be coded in assembly language as simply \"jmp\", and the instruction stream must immediately be directed to the target location pointed to by the jump instruction, whereas a conditional jump that might be coded as \"jmpne\" would redirect the instruction stream only if the result of a comparison of two values in a previous \"compare\" instructions shows the values to not be equal. (The segmented addressing scheme used by the x86 architecture adds extra complexity since jumps can be either \"near\" (within a segment) or \"far\" (outside the segment). Each type has different effects on branch prediction algorithms.)Static/dynamic Branch Prediction: Static branch prediction is used by the microprocessor the first time a conditional branch is encountered, and dynamic branch prediction is used for succeeding executions of the conditional branch code.References:Branch predictorA Demonstration of Self-ProfilingBranch Prediction ReviewBranch Prediction (Using wayback machine)",
                "Besides the fact that the branch prediction may slow you down, a sorted array has another advantage:You can have a stop condition instead of just checking the value, this way you only loop over the relevant data, and ignore the rest.\nThe branch prediction will miss only once.",
                "Sorted arrays are processed faster than an unsorted array, due to a phenomena called branch prediction.The branch predictor is a digital circuit (in computer architecture) trying to predict which way a branch will go, improving the flow in the instruction pipeline. The circuit/computer predicts the next step and executes it.Making a wrong prediction leads to going back to the previous step, and executing with another prediction. Assuming the prediction is correct, the code will continue to the next step. A wrong prediction results in repeating the same step, until a correct prediction occurs.The answer to your question is very simple.In an unsorted array, the computer makes multiple predictions, leading to an increased chance of errors.\nWhereas, in a sorted array, the computer makes fewer predictions, reducing the chance of errors.\nMaking more predictions requires more time.Sorted Array: Straight RoadUnsorted Array: Curved RoadBranch prediction: Guessing/predicting which road is straight and following it without checkingAlthough both the roads reach the same destination, the straight road is shorter, and the other is longer. If then you choose the other by mistake, there is no turning back, and so you will waste some extra time if you choose the longer road. This is similar to what happens in the computer, and I hope this helped you understand better.Also I want to cite @Simon_Weaver from the comments:It doesn\u2019t make fewer predictions - it makes fewer incorrect predictions. It still has to predict for each time through the loop...",
                "I tried the same code with MATLAB 2011b with my MacBook Pro (Intel i7, 64 bit, 2.4 GHz) for the following MATLAB code:The results for the above MATLAB code are as follows:The results of the C code as in @GManNickG I get:Based on this, it looks MATLAB is almost 175 times slower than the C implementation without sorting and 350 times slower with sorting. In other words, the effect (of branch prediction) is 1.46x for MATLAB implementation and 2.7x for the C implementation.",
                "The assumption by other answers that one needs to sort the data is not correct.The following code does not sort the entire array, but only 200-element segments of it, and thereby runs the fastest.Sorting only k-element sections completes the pre-processing in linear time, O(n), rather than the O(n.log(n)) time needed to sort the entire array.This also \"proves\" that it has nothing to do with any algorithmic issue such as sort order, and it is indeed branch prediction.",
                "Bjarne Stroustrup's Answer to this question:That sounds like an interview question. Is it true? How would you know? It is a bad idea to answer questions about efficiency without first doing some measurements, so it is important to know how to measure.So, I tried with a vector of a million integers and got:I ran that a few times to be sure. Yes, the phenomenon is real. My key code was:At least the phenomenon is real with this compiler, standard library, and optimizer settings. Different implementations can and do give different answers. In fact, someone did do a more systematic study (a quick web search will find it) and most implementations show that effect.One reason is branch prediction: the key operation in the sort algorithm is \u201cif(v[i] < pivot]) \u2026\u201d or equivalent. For a sorted sequence that test is always true whereas, for a random sequence, the branch chosen varies randomly.Another reason is that when the vector is already sorted, we never need to move elements to their correct position. The effect of these little details is the factor of five or six that we saw.Quicksort (and sorting in general) is a complex study that has attracted some of the greatest minds of computer science. A good sort function is a result of both choosing a good algorithm and paying attention to hardware performance in its implementation.If you want to write efficient code, you need to know a bit about machine architecture.",
                "This question is rooted in branch prediction models on CPUs. I'd recommend reading this paper:Increasing the Instruction Fetch Rate via Multiple Branch Prediction and a Branch Address Cache  (But real CPUs these days still don't make multiple taken branch-predictions per clock cycle, except for Haswell and later effectively unrolling tiny loops in its loop buffer.  Modern CPUs can predict multiple branches not-taken to make use of their fetches in large contiguous blocks.)When you have sorted elements, branch prediction easily predicts correctly except right at the boundary, letting instructions flow through the CPU pipeline efficiently, without having to rewind and take the correct path on mispredictions.",
                "An answer for quick and simple understanding (read the others for more details)This concept is called branch predictionBranch prediction is an optimization technique that predicts the path the code will take before it is known with certainty. This is important because during the code execution, the machine prefetches several code statements and stores them in the pipeline.The problem arises in conditional branching, where there are two possible paths or parts of the code that can be executed.When the prediction was true, the optimization technique worked out.When the prediction was false, to explain it in a simple way, the code statement stored in the pipeline gets proved wrong and the actual code has to be completely reloaded, which takes up a lot of time.As common sense suggests, predictions of something sorted are way more accurate than predictions of something unsorted.branch prediction visualisation:sorted\n\nunsorted",
                "It is a branch prediction failure. You don't need to sort the array, but you just need to partition it with the value 128. Sorting is n*log(n), whereas partitioning is just linear. Basically it is just one run of the quick sort partitioning step with the pivot chosen to be 128. Unfortunately in C++ there is just nth_element function, which partition by position, not by value.The answer to this question is that it auto-vectorizes. As usual compilers don't pick perfect strategies. (Although GCC's might be optimal for SSE2 or SSE4.)"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I undo the most recent local commits in Git?",
                "I accidentally committed the wrong files to Git, but didn't push the commit to the server yet.\n\nHow do I undo those commits from the local repository?"
            ],
            "url": "https://stackoverflow.com/questions/927358",
            "answer": [
                "Alternatively, to edit the previous commit (or just its commit message), commit --amend will add changes within the current index to the previous commit.To remove (not revert) a commit that has been pushed to the server, rewriting history with git push origin main --force[-with-lease] is necessary. It's almost always a bad idea to use --force; prefer --force-with-lease instead, and as noted in the git manual:You should understand the implications of rewriting history if you [rewrite history] has already been published.You can use git reflog to determine the SHA-1 for the commit to which you wish to revert. Once you have this value, use the sequence of commands as explained above.HEAD~ is the same as HEAD~1. The article What is the HEAD in git? is helpful if you want to uncommit multiple commits.",
                "Undoing a commit is a little scary if you don't know how it works.  But it's actually amazingly easy if you do understand. I'll show you the 4 different ways you can undo a commit.Say you have this, where C is your HEAD and (F) is the state of your files.You want to destroy commit C and also throw away any uncommitted changes.  You do this:The result is:Now B is the HEAD.  Because you used --hard, your files are reset to their state at commit B.Maybe commit C wasn't a disaster, but just a bit off.  You want to undo the commit but keep your changes for a bit of editing before you do a better commit.  Starting again from here, with C as your HEAD:Do this, leaving off the --hard:In this case, the result is:In both cases, HEAD is just a pointer to the latest commit.  When you do a git reset HEAD~1, you tell Git to move the HEAD pointer back one commit.  But (unless you use --hard) you leave your files as they were.  So now git status shows the changes you had checked into C.  You haven't lost a thing!For the lightest touch, you can even undo your commit but leave your files and your index:This not only leaves your files alone, it even leaves your index alone.  When you do git status, you'll see that the same files are in the index as before.  In fact, right after this command, you could do git commit and you'd be redoing the same commit you just had.One more thing: Suppose you destroy a commit as in the first example, but then discover you needed it after all?  Tough luck, right?Nope, there's still a way to get it back.  Type thisand you'll see a list of (partial) commit shas (that is, hashes) that you've moved around in.  Find the commit you destroyed, and do this:You've now resurrected that commit.  Commits don't actually get destroyed in Git for some 90 days, so you can usually go back and rescue one you didn't mean to get rid of.",
                "There are two ways to \"undo\" your last commit, depending on whether or not you have already made your commit public (pushed to your remote repository):Let's say I committed locally, but now I want to remove that commit.To restore everything back to the way it was prior to the last commit, we need to reset to the commit before HEAD:Now git log will show that our last commit has been removed.If you have already made your commits public, you will want to create a new commit which will \"revert\" the changes you made in your previous commit (current HEAD).Your changes will now be reverted and ready for you to commit:For more information, check out Git Basics - Undoing Things.",
                "Add/remove files to get things the way you want:Then amend the commit:The previous, erroneous commit will be edited to reflect the new index state - in other words, it'll be like you never made the mistake in the first place.Note that you should only do this if you haven't pushed yet. If you have pushed, then you'll just have to commit a fix normally.",
                "This will add a new commit which deletes the added files.Or you can rewrite history to undo the last commit.Warning: this command will permanently remove the modifications to the .java files (and any other files) that you committed -- and delete all your changes from your working directory:The hard reset to HEAD-1 will set your working copy to the state of the commit before your wrong commit.",
                "Replace the files in the index:Then, if it's a private branch, amend the commit:Or, if it's a shared branch, make a new commit:(To change a previous commit, use the awesome interactive rebase.)ProTip\u2122: Add *.class to a gitignore to stop this happening again.Amending a commit is the ideal solution if you need to change the last commit, but a more general solution is reset.You can reset Git to any commit with:Where N is the number of commits before HEAD, and @~ resets to the previous commit.Instead of amending the commit, you could use:Check out git help reset, specifically the sections on --soft --mixed and --hard, for a better understanding of what this does.If you mess up, you can always use the reflog to find dropped commits:",
                "Use git revert <commit-id>.To get the commit ID, just use git log.",
                "If you are planning to undo a local commit entirely, whatever you change you did on the commit, and if you don't worry anything about that, just do the following command.(This command will ignore your entire commit and your changes will be lost completely from your local working tree). If you want to undo your commit, but you want your changes in the staging area (before commit just like after git add) then do the following command.Now your committed files come into the staging area. Suppose if you want to upstage the files, because you need to edit some wrong content, then do the following commandNow committed files to come from the staged area into the unstaged area. Now files are ready to edit, so whatever you change, you want to go edit and added it and make a fresh/new commit.More (link broken) (Archived version)",
                "If you have Git Extras installed, you can run git undo to undo the latest commit. git undo 3 will undo the last three commits.",
                "I wanted to undo the latest five commits in our shared repository. I looked up the revision id that I wanted to rollback to. Then I typed in the following.",
                "I prefer to use git rebase -i for this job, because a nice list pops up where I can choose the commits to get rid of. It might not be as direct as some other answers here, but it just feels right.Choose how many commits you want to list, then invoke like this (to enlist last three)Sample listThen Git will remove commits for any line that you remove.",
                "Use git-gui (or similar) to perform a git commit --amend. From the GUI you can add or remove individual files from the commit. You can also modify the commit message.Just reset your branch to the previous location (for example, using gitk or git rebase). Then reapply your changes from a saved copy. After garbage collection in your local repository, it will be like the unwanted commit never happened. To do all of that in a single command, use git reset HEAD~1.Word of warning: Careless use of git reset is a good way to get your working copy into a confusing state. I recommend that Git novices avoid this if they can.Perform a reverse cherry pick (git-revert) to undo the changes.If you haven't yet pulled other changes onto your branch, you can simply do...Then push your updated branch to the shared repository.The commit history will show both commits, separately.Also note: You don't want to do this if someone else may be working on the branch.Clean up your branch locally then repush...In the normal case, you probably needn't worry about your private-branch commit history being pristine.  Just push a followup commit (see 'How to undo a public commit' above), and later, do a squash-merge to hide the history.",
                "If you want to permanently undo it and you have cloned some repository.The commit id can be seen by:Then you can do like:",
                "If you have committed junk but not pushed,HEAD~1 is a shorthand for the commit before head. Alternatively you can refer to the SHA-1 of the hash if you want to reset to. --soft option will delete the commit but it will leave all your changed files \"Changes to be committed\", as git status would put it.If you want to get rid of any changes to tracked files in the working tree since the commit before head use \"--hard\" instead.ORIf you already pushed and someone pulled which is usually my case, you can't use git reset. You can however do a git revert,This will create a new commit that reverses everything introduced by the accidental commit.",
                "On SourceTree (GUI for GitHub), you may right-click the commit and do a 'Reverse Commit'. This should undo your changes.On the terminal:You may alternatively use:Or:",
                "A single command:It works great to undo the last local commit!",
                "Just reset it doing the command below using git:Explain: what git reset does, it's basically reset to any commit you'd like to go back to, then if you combine it with --soft key, it will go back, but keep the  changes in your file(s), so you get back to the stage which the file was just added, HEAD is the head of the branch and if you combine with ~1 (in this case you also use HEAD^), it will go back only one commit which what you want...I create the steps in the image below in more details for you, including all steps that may happens in real situations and committing the code:",
                "\"Reset the working tree to the last commit\"\"Clean unknown files from the working tree\"see - Git Quick ReferenceNOTE: This command will delete your previous commit, so use with caution! git reset --hard is safer.",
                "How to undo the last Git commit?To restore everything back to the way it was prior to the last commit, we need to reset to the commit before HEAD.If you don't want to keep your changes that you made:If you want to keep your changes:Now check your git log. It will show that our last commit has been removed.",
                "Use reflog to find a correct stateREFLOG BEFORE RESETSelect the correct reflog (f3cb6e2 in my case) and typeAfter that the repo HEAD will be reset to that HEADid\n\nLOG AFTER RESETFinally the reflog looks like the picture belowREFLOG FINAL",
                "First run:It will show you all the possible actions you have performed on your repository, for example, commit, merge, pull, etc.Then do:",
                "git reset --soft HEAD^ or git reset --soft HEAD~This will undo the last commit.Here --soft means reset into staging.HEAD~ or HEAD^ means to move to commit before HEAD.It will replace the last commit with the new commit.",
                "Another way:Checkout the branch you want to revert, then reset your local working copy back to the commit that you want to be the latest one on the remote server (everything after it will go bye-bye). To do this, in SourceTree I right-clicked on the and selected \"Reset BRANCHNAME to this commit\".Then navigate to your repository's local directory and run this command:This will erase all commits after the current one in your local repository but only for that one branch.",
                "Type git log and find the last commit hash code and then enter:",
                "In my case I accidentally committed some files I did not want to. So I did the following and it worked:Verify the results with gitk or git log --stat",
                "Simple, run this in your command line:",
                "I am just adding two cents for @Kyralessa's answer:If you are unsure what to use go for --soft (I used this convention to remember it --soft for safe).If you choose --hard by mistake you will LOSE your changes as it wasn't before.\nIf you choose --soft by mistake you can achieve the same results of --hard by applying additional commandsCredits goes to @Kyralessa.",
                "There are many ways to do it:Git command to undo the last commit/ previous commits:Warning: Do Not use --hard if you do not know what you are doing.\n--hard is too dangerous, and it might delete your files.Basic command to revert the commit in Git is:orCOMMIT-ID: ID for the commitn:  is the number of last commits you want to revertYou can get the commit id as shown below:where d81d3f1 and be20eb8 are commit id.Now, let's see some cases:Suppose you want to revert the last commit 'd81d3f1'.  Here are two options:orSuppose you want to revert the commit 'be20eb8':For more detailed information, you can refer to and try out some other commands too for resetting the head to a specified state:",
                "There are two main scenariosYou haven't pushed the commit yetIf the problem was extra files you commited (and you don't want those on repository), you can remove them using git rm and then commiting with --amendYou can also remove entire directories with -r, or even combine with other Bash commandsAfter removing the files, you can commit, with --amend optionThis will rewrite your recent local commit removing the extra files, so, these files will never be sent on push and also will be removed from your local .git repository by GC.You already pushed the commitYou can apply the same solution of the other scenario and then doing git push with the -f option, but it is not recommended since it overwrites the remote history with a divergent change (it can mess your repository).Instead, you have to do the commit without --amend (remember this about -amend`: That option rewrites the history on the last commit).",
                "or if you do not remember exactly in which commit it is, you might useThe proper way of removing files from the repository history is using git filter-branch. That is,But I recomnend you use this command with care. Read more at git-filter-branch(1) Manual Page."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I delete a Git branch locally and remotely?",
                "Failed Attempts to Delete a Remote Branch:\n$ git branch -d remotes/origin/bugfix\nerror: branch 'remotes/origin/bugfix' not found.\n\n$ git branch -d origin/bugfix\nerror: branch 'origin/bugfix' not found...."
            ],
            "url": "https://stackoverflow.com/questions/2003505",
            "answer": [
                "Note: In most cases, <remote_name> will be origin.To delete the local branch use one of the following:As of Git v1.7.0, you can delete a remote branch usingwhich might be easier to remember thanwhich was added in Git v1.5.0 \"to delete a remote branch or a tag.\"Starting with Git v2.8.0, you can also use git push with the -d option as an alias for --delete. Therefore, the version of Git you have installed will dictate whether you need to use the easier or harder syntax.From Chapter 3 of Pro Git by Scott Chacon:Suppose you\u2019re done with a remote branch \u2014 say, you and your collaborators are finished with a feature and have merged it into your remote\u2019s main branch (or whatever branch your stable code-line is in). You can delete a remote branch using the rather obtuse syntax git push [remotename] :[branch]. If you want to delete your server-fix branch from the server, you run the following:Boom. No more branches on your server. You may want to dog-ear this page, because you\u2019ll need that command, and you\u2019ll likely forget the syntax. A way to remember this command is by recalling the git push [remotename] [localbranch]:[remotebranch] syntax that we went over a bit earlier. If you leave off the [localbranch] portion, then you\u2019re basically saying, \u201cTake nothing on my side and make it be [remotebranch].\u201dI issued git push origin: bugfix and it worked beautifully. Scott Chacon was right\u2014I will want to dog ear that page (or virtually dog ear by answering this on Stack\u00a0Overflow).Then you should execute this on other machinesto propagate changes.",
                "Matthew\u2019s answer is great for removing remote branches and I also appreciate the explanation, but to make a simple distinction between the two commands:to remove a local branch from your machine: git branch -d {local_branch} (use -D instead to force deleting the branch without checking merged status);to remove a remote branch from the server: git push origin -d {remote_branch}.Reference: Git: Delete a branch (local or remote).",
                "If you want more detailed explanations of the following commands, then see the long answers in the next section.When you're dealing with deleting branches both locally and remotely, keep in mind that there are three different branches involved:The original poster used:Which only deleted his local remote-tracking branch origin/bugfix, and not the actual remote branch bugfix on origin.To delete that actual remote branch, you needThe following sections describe additional details to consider when deleting your remote and remote-tracking branches.Note that deleting the remote branch X from the command line using a git push will also remove the local remote-tracking branch origin/X, so it is not necessary to prune the obsolete remote-tracking branch with git fetch --prune or git fetch -p. However, it wouldn't hurt if you did it anyway.You can verify that the remote-tracking branch origin/X was also deleted by running the following:If you didn't delete your remote branch X from the command line (like above), then your local repository will still contain (a now obsolete) remote-tracking branch origin/X. This can happen if you deleted a remote branch directly through GitHub's web interface, for example.A typical way to remove these obsolete remote-tracking branches (since Git version 1.6.6) is to simply run git fetch with the --prune or shorter -p. Note that this removes all obsolete local remote-tracking branches for any remote branches that no longer exist on the remote:Here is the relevant quote from the 1.6.6 release notes (emphasis mine):\"git fetch\" learned --all and --multiple options, to run fetch from\nmany repositories, and --prune option to remove remote tracking\nbranches that went stale.  These make \"git remote update\" and \"git\nremote prune\" less necessary (there is no plan to remove \"remote\nupdate\" nor \"remote prune\", though).Alternatively, instead of pruning your obsolete local remote-tracking branches through git fetch -p, you can avoid making the extra network operation by just manually removing the branch(es) with the --remotes or -r flags:",
                "For deleting the remote branch:For deleting the local branch, you have three ways:Explain: OK, just explain what's going on here!Simply do git push origin --delete to delete your remote branch only, add the name of the branch at the end and this will delete and push it to remote at the same time...Also, git branch -D, which simply delete the local branch only!...-D stands for --delete --force which will delete the branch even it's not merged (force delete), but you can also use -d which stands for --delete which throw an error respective of the branch merge status...I also create the image below to show the steps:",
                "You can also use the following to delete the remote branchWhich does the same thing asbut it may be easier to remember.",
                "It's very simple:To delete the remote branchOr-- You can also delete tags with this syntaxTo forcefully delete local branchNote: do a git fetch --all --prune on other machines after deleting remote branch, to remove obsolete tracking branches.Exampleto remove local branchto remove remote branchWith the new version of git, its also possible to remove branch withTIP:\nif you want to see all available branches you can use git branch -a,and to see just remote branches, you can use git branch -r",
                "Tip: When you delete branches usingoronly the references are deleted. Even though the branch is actually removed on the remote, the references to it still exists in the local repositories of your team members. This means that for other team members the deleted branches are still visible when they do a git branch -a.To solve this, your team members can prune the deleted branches withThis is typically git remote prune origin.",
                "If you want to delete a branch, first checkout to the branch other than the branch to be deleted.Deleting the local branch:Deleting the remote branch:",
                "This is simple: Just run the following command:To delete a Git branch both locally and remotely, first delete the local branch using this command:(Here example is the branch name.)And after that, delete the remote branch using this command:",
                "Another approach is:WARNING: This will delete all remote branches that do not exist locally. Or more comprehensively,will effectively make the remote repository look like the local copy of the repository (local heads, remotes and tags are mirrored on remote).",
                "I use the following in my Bash settings:Then you can call:",
                "Delete locally:To delete a local branch, you can use:To delete a branch forcibly, use -D instead of -d.Delete remotely:There are two options:I would suggest you use the second way as it is more intuitive.",
                "If you want to complete both these steps with a single command, you can make an alias for it by adding the below to your ~/.gitconfig:Alternatively, you can add this to your global configuration from the command line usingNOTE: If using -d (lowercase d), the branch will only be deleted if it has been merged. To force the delete to happen, you will need to use -D (uppercase D).",
                "Since January 2013, GitHub included a Delete branch button next to each branch in your \"Branches\" page.Relevant blog post: Create and delete branches",
                "To delete your branch locally and remotelyCheckout to master branch -  git checkout masterDelete your remote branch - git push origin --delete <branch-name>Delete your local branch - git branch --delete <branch-name>",
                "You can also do this using git remote prune originIt prunes and deletes remote-tracking branches from a git branch -r listing.",
                "In addition to the other answers, I often use the git_remote_branch tool. It's an extra install, but it gets you a convenient way to interact with remote branches. In this case, to delete:I find that I also use the publish and track commands quite often.",
                "A one-liner command to delete both local, and remote:Or add the alias below to your ~/.gitconfig. Usage: git kill branch-name",
                "Deleting BranchesLet's assume our work on branch \"contact-form\" is done and we've already integrated it into \"master\". Since we don't need it anymore, we can delete it (locally):And for deleting the remote branch:",
                "Delete remote branchgit push origin :<branchname>Delete local branchgit branch -D <branchname>Delete local branch steps:",
                "Simply say:",
                "To delete locally - (normal)If your branch is in a rebasing/merging progress and that was not done properly, it means you will get an error, Rebase/Merge in progress, so in that case, you won't be able to delete your branch.So either you need to solve the rebasing/merging. Otherwise, you can do force delete by using,To delete in remote:You can do the same using:Graphical representation:",
                "Now you can do it with the GitHub Desktop application.After launching the applicationSwitch to the branch you would like to deleteFrom the \"Branch\" menu, select, \"Unpublish...\", to have the branch deleted from the GitHub servers.From the \"Branch\" menu, select, 'Delete \"branch_name\"...', to have the branch deleted off of your local machine (AKA the machine you are currently working on)",
                "is easier to remember than",
                "This won't work if you have a tag with the same name as the branch on the remote:In that case you need to specify that you want to delete the branch, not the tag:Similarly, to delete the tag instead of the branch you would use:",
                "Many of the other answers will lead to errors/warnings. This approach is relatively fool proof although you may still need git branch -D branch_to_delete if it's not fully merged into some_other_branch, for example.Remote pruning isn't needed if you deleted the remote branch. It's only used to get the most up-to-date remotes available on a repository you're tracking. I've observed git fetch will add remotes, not remove them. Here's an example of when git remote prune origin will actually do something:User A does the steps above. User B would run the following commands to see the most up-to-date remote branches:",
                "I got sick of googling for this answer, so I took a similar approach to the answer that crizCraig posted earlier.I added the following to my Bash profile:Then every time I'm done with a branch (merged into master, for example) I run the following in my terminal:...which then deletes my-branch-name from origin as as well as locally.",
                "According to the latest document using a terminal we can delete in the following way.Delete in local:Delete in remote location:",
                "Before executingmake sure you determine first what the exact name of the remote branch is by executing:This will tell you what to enter exactly for <branch> value. (branch is case sensitive!)"
            ]
        },
        {
            "tag": "",
            "question": [
                "What is the difference between 'git pull' and 'git fetch'?",
                "What are the differences between git pull and git fetch?"
            ],
            "url": "https://stackoverflow.com/questions/292357",
            "answer": [
                "In the simplest terms, git pull does a git fetch followed by a git merge.git fetch updates your remote-tracking branches under refs/remotes/<remote>/. This operation is safe to run at any time since it never changes any of your local branches under refs/heads.git pull brings a local branch up-to-date with its remote version, while also updating your other remote-tracking branches.From the Git documentation for git pull:git pull runs git fetch with the given parameters and then depending on configuration options or command line flags, will call either git rebase or git merge to reconcile diverging branches.It is helpful to keep in mind that when working on any Git respository on any particular machine, the repository contains a copy of all branches from all remotes as well as a copy of each local branch you have done some work on.You can see this using git branch -a, which should show your local branches, including master, and all branches from all remotes.Above, I have indicated the existance of a remote origin repo as well as another remote by another name another-remote-machine.Note you do not necessarily have to have a copy of each branch on all repositories. (Remotes and local.) It will depend on when you have synchronized things by running git pull, git push, git fetch, from the different machines/repositories involved.",
                "git pull tries to automatically merge after fetching commits. It is context sensitive, so all pulled commits will be merged into your currently active branch.  git pull automatically merges the commits without letting you review them first. If you don\u2019t carefully manage your branches, you may run into frequent conflicts.git fetch gathers any commits from the target branch that do not exist in the current branch and stores them in your local repository. However, it does not merge them with your current branch. This is particularly useful if you need to keep your repository up to date, but are working on something that might break if you update your files. To integrate the commits into your current branch, you must use git merge afterwards.",
                "It is important to contrast the design philosophy of git with the philosophy of a more traditional source control tool like SVN.Subversion was designed and built with a client/server model. There is a single repository that is the server, and several clients can fetch code from the server, work on it, then commit it back to the server. The assumption is that the client can always contact the server when it needs to perform an operation.Git was designed to support a more distributed model with no need for a central repository (though you can certainly use one if you like). Also git was designed so that the client and the \"server\" don't need to be online at the same time. Git was designed so that people on an unreliable link could exchange code via email, even. It is possible to work completely disconnected and burn a CD to exchange code via git.In order to support this model git maintains a local repository with your code and also an additional local repository that mirrors the state of the remote repository. By keeping a copy of the remote repository locally, git can figure out the changes needed even when the remote repository is not reachable.  Later when you need to send the changes to someone else, git can transfer them as a set of changes from a point in time known to the remote repository.git fetch is the command that says \"bring my local copy of the remote repository up to date.\"git pull says \"bring the changes in the remote repository to where I keep my own code.\"Normally git pull does this by doing a git fetch to bring the local copy of the remote repository up to date, and then merging the changes into your own code repository and possibly your working copy.The take away is to keep in mind that there are often at least three copies of a project on your workstation. One copy is your own repository with your own commit history. The second copy is your working copy where you are editing and building. The third copy is your local \"cached\" copy of a remote repository.",
                "Here is Oliver Steele's image of how all it all fits together:",
                "One use case of git fetch is that the following will tell you any changes in the remote branch since your last pull... so you can check before doing an actual pull, which could change files in your current branch and working copy.See git diff documentation regarding the double- .. and triple-dot ... syntax.",
                "It cost me a little bit to understand what was the difference, but this is a simple explanation. master in your localhost is a branch.When you clone a repository you fetch the entire repository to you local host. This means that at that time you have an origin/master pointer to HEAD and master pointing to the same HEAD.when you start working and do commits you advance the master pointer to HEAD + your commits. But the origin/master pointer is still pointing to what it was when you cloned.So the difference will be:",
                "Sometimes a visual representation helps.",
                "Even more brieflygit fetch fetches updates but does not merge them.git pull does a git fetch under the hood and then a merge.Brieflygit fetch is similar to pull but doesn't merge. i.e. it fetches remote updates (refs and objects) but your local stays the same (i.e. origin/master gets updated but master stays the same) .git pull pulls down from a remote and instantly merges.Moregit clone clones a repo.git rebase saves stuff from your current branch that isn't in the upstream branch to a temporary area. Your branch is now the same as before you started your changes. So, git pull -rebase will pull down the remote changes, rewind your local branch, replay your changes over the top of your current branch one by one until you're up-to-date.Also, git branch -a will show you exactly what\u2019s going on with all your branches - local and remote.This blog post was useful:The difference between git pull, git fetch and git clone (and git rebase) - Mike Pearceand covers git pull, git fetch, git clone and git rebase.I thought I'd update this to show how you'd actually use this in practice.Update your local repo from the remote (but don't merge):After downloading the updates, let's see the differences:If you're happy with those updates, then merge:Notes:On step 2: For more on diffs between local and remotes, see: How to compare a local Git branch with its remote branchOn step 3: It's probably more accurate (e.g. on a fast changing repo) to do a git rebase origin here. See @Justin Ohms comment in another answer.See also: http://longair.net/blog/2009/04/16/git-fetch-and-merge/Note also: I've mentioned a merge during a pull however you can configure a pull to use a rebase instead.",
                "You would pull if you want the histories merged, you'd fetch if you just 'want the codez' as some person has been tagging some articles around here.",
                "OK, here is some information about git pull and git fetch, so you can understand the actual differences... in few simple words, fetch gets the latest data, but not the code changes and not going to mess with your current  local branch code, but pull get the code changes and merge it your local branch, read on to get more details about each:It will download all refs and objects and any new branches to your local Repository...Fetch branches and/or tags (collectively, \"refs\") from one or more\nother repositories, along with the objects necessary to complete their\nhistories. Remote-tracking branches are updated (see the description\nof  below for ways to control this behavior).By default, any tag that points into the histories being fetched is\nalso fetched; the effect is to fetch tags that point at branches that\nyou are interested in. This default behavior can be changed by using\nthe --tags or --no-tags options or by configuring\nremote..tagOpt. By using a refspec that fetches tags explicitly,\nyou can fetch tags that do not point into branches you are interested\nin as well.git fetch can fetch from either a single named repository or URL or\nfrom several repositories at once if  is given and there is a\nremotes. entry in the configuration file. (See git-config1).When no remote is specified, by default the origin remote will be\nused, unless there\u2019s an upstream branch configured for the current\nbranch.The names of refs that are fetched, together with the object names\nthey point at, are written to .git/FETCH_HEAD. This information may be\nused by scripts or other git commands, such as git-pull.It will apply the changes from remote to the current branch in local...Incorporates changes from a remote repository into the current branch.\nIn its default mode, git pull is shorthand for git fetch followed by\ngit merge FETCH_HEAD.More precisely, git pull runs git fetch with the given parameters and\ncalls git merge to merge the retrieved branch heads into the current\nbranch. With --rebase, it runs git rebase instead of git merge.should be the name of a remote repository as passed to\ngit-fetch1.  can name an arbitrary remote ref (for example,\nthe name of a tag) or even a collection of refs with corresponding\nremote-tracking branches (e.g., refs/heads/:refs/remotes/origin/),\nbut usually it is the name of a branch in the remote repository.Default values for  and  are read from the\n\"remote\" and \"merge\" configuration for the current branch as set by\ngit-branch --track.I also create the visual below to show you how git fetch and git pull working together...",
                "The short and easy answer is that git pull is simply git fetch followed by git merge.It is very important to note that git pull will automatically merge whether you like it or not. This could, of course, result in merge conflicts. Let's say your remote is origin and your branch is master. If you git diff origin/master before pulling, you should have some idea of potential merge conflicts and could prepare your local branch accordingly.In addition to pulling and pushing, some workflows involve git rebase, such as this one, which I paraphrase from the linked article:If you find yourself in such a situation, you may be tempted to git pull --rebase. Unless you really, really know what you are doing, I would advise against that. This warning is from the man page for git-pull, version 2.3.5:This is a potentially dangerous mode of operation. It rewrites\n  history, which does not bode well when you published that history\n  already. Do not use this option unless you have read git-rebase(1)\n  carefully.",
                "You can fetch from a remote repository, see the differences and then pull or merge.This is an example for a remote repository called origin and a branch called master tracking the remote branch origin/master:",
                "This interactive graphical representation is very helpful in understanging git: http://ndpsoftware.com/git-cheatsheet.htmlgit fetch just \"downloads\" the changes from the remote to your local repository. git pull downloads the changes and merges them into your current branch. \"In its default mode, git pull is shorthand for git fetch followed by git merge FETCH_HEAD.\"",
                "In speaking of pull & fetch in the above answers, I would like to share an interesting trick,This above command is the most useful command in my git life which saved a lots of time.Before pushing your new commits to server, try this command and it will automatically sync latest server changes (with a fetch + merge) and will place your commit at the top in git log. No need to worry about manual pull/merge.Find details at: http://gitolite.com/git-pull--rebase",
                "I like to have some visual representation of the situation to grasp these things. Maybe other developers would like to see it too, so here's my addition. I'm not totally sure that it all is correct, so please comment if you find any mistakes.Some major advantages for having a fetched mirror of the remote are:",
                "The Difference between GIT Fetch and GIT Pull can be explained with the following scenario:\n(Keeping in mind that pictures speak louder than words!, I have provided pictorial representation)Let's take an example that you are working on a project with your team members. So there will be one main Branch of the project and all the contributors must fork it to their own local repository and then work on this local branch to modify/Add modules then push back to the main branch.So,\nInitial State of the two Branches when you forked the main project on your local repository will be like this- (A, B and C are Modules already completed of the project)Now, you have started working on the new module (suppose D)  and when you have completed the D module you want to push it to the main branch, But meanwhile what happens is that one of your teammates has developed new Module E, F and modified C.\nSo now what has happened is that your local repository is lacking behind the original progress of the project and thus pushing of your changes to the main branch can lead to conflict and may cause your Module D to malfunction.To avoid such issues and to work parallel with the original progress of the project there are Two ways:1. Git Fetch- This will Download all the changes that have been made to the origin/main branch project which are not present in your local branch. And will wait for the Git Merge command to apply the changes that have been fetched to your Repository or branch.So now You can carefully monitor the files before merging it to your repository. And you can also modify D if required because of Modified C.2. Git Pull- This will update your local branch with the origin/main branch i.e. actually what it does is a combination of Git Fetch and Git merge one after another.\nBut this may Cause Conflicts to occur, so it\u2019s recommended to use Git Pull with a clean copy.",
                "I have struggled with this as well.  In fact I got here with a google search of exactly the same question.  Reading all these answers finally painted a picture in my head and I decided to try to get this down looking at the state of the 2 repositories and 1 sandbox and actions performed over time while watching the version of them.  So here is what I came up with.  Please correct me if I messed up anywhere.The three repos with a fetch:The three repos with a pullThis helped me understand why a fetch is pretty important.",
                "In simple terms, if you were about to hop onto a plane without any Internet connection\u2026 before departing you could just do git fetch origin <branch>. It would fetch all the changes into your computer, but keep it separate from your local development/workspace.On the plane, you could make changes to your local workspace and then merge it with what you've previously fetched and then resolve potential merge conflicts all without a connection to the Internet. And unless someone had made new changes to the remote repository then once you arrive at the destination you would do git push origin <branch> and go get your coffee.From this awesome Atlassian tutorial:The git fetch command downloads commits, files, and refs from a\nremote repository into your local repository.Fetching is what you do when you want to see what everybody else has\nbeen working on. It\u2019s similar to SVN update in that it lets you see\nhow the central history has progressed, but it doesn\u2019t force you to\nactually merge the changes into your repository. Git isolates\nfetched content as a from existing local content, it has absolutely\nno effect on your local development work. Fetched content has to be explicitly checked out using the git checkout command. This makes\nfetching a safe way to review commits before integrating them with\nyour local repository.When downloading content from a remote repository, git pull and git fetch commands are available to accomplish the task. You can consider\ngit fetch the 'safe' version of the two commands. It will download\nthe remote content, but not update your local repository's working state,\nleaving your current work intact. git pull is the more aggressive\nalternative, it will download the remote content for the active local\nbranch and immediately execute git merge to create a merge commit\nfor the new remote content. If you have pending changes in progress\nthis will cause conflicts and kickoff the merge conflict resolution\nflow.With git pull:Hmmm...so if I'm not updating the working copy with git fetch, then where am I making changes? Where does Git fetch store the new commits?Great question. First and foremost, the heads or remotes don't store the new commits. They just have pointers to commits. So with git fetch you download the latest git objects (blob, tree, commits. To fully understand the objects watch this video on git internals), but only update your remotes pointer to point to the latest commit of that branch.  It's still isolated from your working copy, because your branch's pointer in the heads directory hasn't updated. It will only update upon a merge/pull. But again where? Let's find out.In your project directory (i.e., where you do your git commands) do:ls. This will show the files & directories. Nothing cool, I know.Now do ls -a. This will show dot files, i.e., files beginning with . You will then be able to see a directory named: .git.Do cd .git. This will obviously change your directory.Now comes the fun part; do ls. You will see a list of directories. We're looking for refs. Do cd refs.It's interesting to see what's inside all directories, but let's focus on two of them. heads and remotes. Use cd to check inside them too.Any git fetch that you do will update the pointer in the /.git/refs/remotes directory. It won't update anything in the /.git/refs/heads directory.Any git pull will first do the git fetch and update items in the /.git/refs/remotes directory.  It will then also merge with your local and then change the head inside the /.git/refs/heads directory.A very good related answer can also be found in Where does 'git fetch' place itself?.Also, look for \"Slash notation\" from the Git branch naming conventions post. It helps you better understand how Git places things in different directories.Just do:If the remote master was updated you'll get a message like this:If you didn't fetch and just did git checkout master then your local git wouldn't know that there are 2 commits added. And it would just say:But that's outdated and incorrect. It's because git will give you feedback solely based on what it knows. It's oblivious to new commits that it hasn't pulled down yet...Some IDEs (e.g. Xcode) are super smart and use the result of a git fetch and can annotate the lines of code that have been changed in remote branch of your current working branch. If that line has been changed by both local changes and remote branch, then that line gets annotated with red. This isn't a merge conflict. It's a potential merge conflict. It's a headsup that you can use to resolve the future merge conflict before doing git pull from the remote branch.If you fetched a remote branch e.g. did:Then this would go into your remotes directory. It's still not available to your local directory. However, it simplifies your checkout to that remote branch by DWIM (Do what I mean):you no longer need to do:For more on that read here",
                "We simply say:If you run git pull, you do not need to merge the data to local. If you run git fetch, it means you must run git merge for getting the latest code to your local machine. Otherwise, the local machine code would not be changed without merge.So in the Git Gui, when you do fetch, you have to merge the data. Fetch itself won't make the code changes at your local. You can check that when you update the code by fetching\nonce fetch and see; the code it won't change. Then you merge... You will see the changed code.",
                "git fetch pulls down the code from the remote server to your tracking branches in your local repository.  If your remote is named origin (the default) then these branches will be within origin/, for example origin/master, origin/mybranch-123, etc.  These are not your current branches, they are local copies of those branches from the server.git pull does a git fetch but then also merges the code from the tracking branch into your current local version of that branch.  If you're not ready for that changes yet, just git fetch first.",
                "git fetch will retrieve remote branches so that you can git diff or git merge them with the current branch. git pull will run fetch on the remote brach tracked by the current branch and then merge the result. You can use git fetch to see if there are any updates to the remote branch without necessary merging them with your local branch.",
                "Git FetchYou download changes to your local branch from origin through fetch. Fetch asks the remote repo for all commits that others have made but you don't have on your local repo. Fetch downloads these commits and adds them to the local repository.Git MergeYou can apply changes downloaded through fetch using the merge command. Merge will take the commits retrieved from fetch and try to add them to your local branch. The merge will keep the commit history of your local changes so that when you share your branch with push, Git will know how others can merge your changes.Git PullFetch and merge run together often enough that a command that combines the two, pull, was created. Pull does a fetch and then a merge to add the downloaded commits into your local branch.",
                "The only difference between git pull and git fetch is that :git pull pulls from a remote branch and merges it.git fetch only fetches from the remote branch but it does not mergei.e. git pull = git fetch + git merge ...",
                "Git allows chronologically older commits to be applied after newer commits.\nBecause of this, the act of transferring commits between repositories is split into two steps:Copying new commits from remote branch to copy of this remote branch inside local repo.(repo to repo operation) master@remote >> remote/origin/master@localIntegrating new commits to local branch(inside-repo operation) remote/origin/master@local >> master@localThere are two ways of doing step 2. You can:In git terminology, step 1 is git fetch, step 2 is git merge or git rebasegit pull is git fetch and git merge",
                "The git pull command is actually a shortcut for git fetch followed by the git merge or the git rebase command depending on your configuration. You can configure your Git repository so that git pull is a fetch followed by a rebase.",
                "Git obtains the branch of the latest version from the remote to the local using two commands:git fetch: Git is going to get the latest version from remote to local,  but it do not automatically merge.\n\u00a0\u00a0\u00a0\u00a0\ngit fetch origin master\ngit log -p master..origin/master\ngit merge origin/masterThe commands above mean that download latest version of the main branch from origin from the remote to origin master branch. And then compares the local master branch and origin master branch. Finally, merge.git pull: Git is going to get the latest version from the remote and merge into the local.git pull origin masterThe command above is the equivalent to git fetch and git merge. In practice, git fetch maybe more secure because before the merge we can see the changes and decide whether to merge.",
                "What is the difference between git pull and git fetch?To understand this, you first need to understand that your local git maintains not only your local repository, but it also maintains a local copy of the remote repository.git fetch brings your local copy of the remote repository up to date. For example, if your remote repository is GitHub - you may want to fetch any changes made in the remote repository to your local copy of it the remote repository. This will allow you to perform operations such as compare or merge.git pull on the other hand will bring down the changes in the remote repository to where you keep your own code. Typically, git pull will do a git fetch first to bring the local copy of the remote repository up to date, and then it will merge the changes into your own code repository and possibly your working copy.",
                "A simple Graphical Representation for Beginners,here,will fetch code from repository and rebase with your local... in git pull there is possibility of new commits getting created.but in ,git fetchwill fetch code from repository and we need to rebase it manually by using git rebaseeg: i am going to fetch from server master and rebase it in my local master.1) git pull ( rebase will done automatically):here origin is your remote repo master is your branch2) git fetch (need to rebase manually):it will fetch server changes from origin. and it will be in your local until you rebase it on your own. we need to fix conflicts manually by checking codes.this will rebase code into local. before that ensure you're in right branch.",
                "Actually Git maintains a copy of your own code and \nthe remote repository.The command git fetch makes your local copy up to date by getting data from remote repository. The reason we need this is because somebody else might have made some changes to the code and you want to keep yourself updated.The command git pull brings the changes in the remote repository to where you keep your own code. Normally, git pull does this by doing a \u2018git fetch\u2019 first to bring the local copy of the remote repository up to date, and then it merges the changes into your own code repository and possibly your working copy.",
                "git pull == ( git fetch + git merge)git fetch does not changes to local branches.If you already have a local repository with a remote set up for the desired project, you can grab all branches and tags for the existing remote using git fetch . ... Fetch does not make any changes to local branches, so you will need to merge a remote branch with a paired local branch to incorporate newly fetch changes. from github"
            ]
        },
        {
            "tag": "",
            "question": [
                "What does the \"yield\" keyword do?",
                "What is the use of the yield keyword in Python? What does it do?\nFor example, I'm trying to understand this code1:\ndef _get_child_candidates(self, distance, min_dist, max_dist):\n    if self._leftchild ..."
            ],
            "url": "https://stackoverflow.com/questions/231767",
            "answer": [
                "To understand what yield does, you must understand what generators are. And before you can understand generators, you must understand iterables.When you create a list, you can read its items one by one. Reading its items one by one is called iteration:mylist is an iterable. When you use a list comprehension, you create a list, and so an iterable:Everything you can use \"for... in...\" on is an iterable; lists, strings, files...These iterables are handy because you can read them as much as you wish, but you store all the values in memory and this is not always what you want when you have a lot of values.Generators are iterators, a kind of iterable you can only iterate over once. Generators do not store all the values in memory, they generate the values on the fly:It is just the same except you used () instead of []. BUT, you cannot perform for i in mygenerator a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end calculating 4, one by one.yield is a keyword that is used like return, except the function will return a generator.Here it's a useless example, but it's handy when you know your function will return a huge set of values that you will only need to read once.To master yield, you must understand that when you call the function, the code you have written in the function body does not run. The function only returns the generator object, this is a bit tricky.Then, your code will continue from where it left off each time for uses the generator.Now the hard part:The first time the for calls the generator object created from your function, it will run the code in your function from the beginning until it hits yield, then it'll return the first value of the loop. Then, each subsequent call will run another iteration of the loop you have written in the function and return the next value. This will continue until the generator is considered empty, which happens when the function runs without hitting yield. That can be because the loop has come to an end, or because you no longer satisfy an \"if/else\".Generator:Caller:This code contains several smart parts:The loop iterates on a list, but the list expands while the loop is being iterated. It's a concise way to go through all these nested data even if it's a bit dangerous since you can end up with an infinite loop. In this case, candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) exhausts all the values of the generator, but while keeps creating new generator objects which will produce different values from the previous ones since it's not applied on the same node.The extend() method is a list object method that expects an iterable and adds its values to the list.Usually, we pass a list to it:But in your code, it gets a generator, which is good because:And it works because Python does not care if the argument of a method is a list or not. Python expects iterables so it will work with strings, lists, tuples, and generators! This is called duck typing and is one of the reasons why Python is so cool. But this is another story, for another question...You can stop here, or read a little bit to see an advanced use of a generator:Note: For Python 3, useprint(corner_street_atm.__next__()) or print(next(corner_street_atm))It can be useful for various things like controlling access to a resource.The itertools module contains special functions to manipulate iterables. Ever wish to duplicate a generator?\nChain two generators? Group values in a nested list with a one-liner? Map / Zip without creating another list?Then just import itertools.An example? Let's see the possible orders of arrival for a four-horse race:Iteration is a process implying iterables (implementing the __iter__() method) and iterators (implementing the __next__() method).\nIterables are any objects you can get an iterator from. Iterators are objects that let you iterate on iterables.There is more about it in this article about how for loops work.",
                "When you see a function with yield statements, apply this easy trick to understand what will happen:This trick may give you an idea of the logic behind the function, but what actually happens with yield is significantly different than what happens in the list-based approach. In many cases, the yield approach will be a lot more memory efficient and faster too. In other cases, this trick will get you stuck in an infinite loop, even though the original function works just fine. Read on to learn more...First, the iterator protocol - when you writePython performs the following two steps:Gets an iterator for mylist:Call iter(mylist) -> this returns an object with a next() method (or __next__() in Python 3).[This is the step most people forget to tell you about]Uses the iterator to loop over items:Keep calling the next() method on the iterator returned from step 1. The return value from next() is assigned to x and the loop body is executed. If an exception StopIteration is raised from within next(), it means there are no more values in the iterator and the loop is exited.The truth is Python performs the above two steps anytime it wants to loop over the contents of an object - so it could be a for loop, but it could also be code like otherlist.extend(mylist) (where otherlist is a Python list).Here mylist is an iterable because it implements the iterator protocol. In a user-defined class, you can implement the __iter__() method to make instances of your class iterable. This method should return an iterator. An iterator is an object with a next() method. It is possible to implement both __iter__() and next() on the same class, and have __iter__() return self. This will work for simple cases, but not when you want two iterators looping over the same object at the same time.So that's the iterator protocol, many objects implement this protocol:Note that a for loop doesn't know what kind of object it's dealing with - it just follows the iterator protocol, and is happy to get item after item as it calls next(). Built-in lists return their items one by one, dictionaries return the keys one by one, files return the lines one by one, etc. And generators return... well that's where yield comes in:Instead of yield statements, if you had three return statements in f123() only the first would get executed, and the function would exit. But f123() is no ordinary function. When f123() is called, it does not return any of the values in the yield statements! It returns a generator object. Also, the function does not really exit - it goes into a suspended state. When the for loop tries to loop over the generator object, the function resumes from its suspended state at the very next line after the yield it previously returned from, executes the next line of code, in this case, a yield statement, and returns that as the next item. This happens until the function exits, at which point the generator raises StopIteration, and the loop exits.So the generator object is sort of like an adapter - at one end it exhibits the iterator protocol, by exposing __iter__() and next() methods to keep the for loop happy. At the other end, however, it runs the function just enough to get the next value out of it, and puts it back in suspended mode.Usually, you can write code that doesn't use generators but implements the same logic. One option is to use the temporary list 'trick' I mentioned before. That will not work in all cases, for e.g. if you have infinite loops, or it may make inefficient use of memory when you have a really long list. The other approach is to implement a new iterable class SomethingIter that keeps the state in instance members and performs the next logical step in its next() (or __next__() in Python 3) method. Depending on the logic, the code inside the next() method may end up looking very complex and prone to bugs. Here generators provide a clean and easy solution.",
                "Think of it this way:An iterator is just a fancy sounding term for an object that has a next() method.  So a yield-ed function ends up being something like this:Original version:This is basically what the Python interpreter does with the above code:For more insight as to what's happening behind the scenes, the for loop can be rewritten to this:Does that make more sense or just confuse you more?  :)I should note that this is an oversimplification for illustrative purposes. :)",
                "The yield keyword is reduced to two simple facts:In a nutshell: Most commonly, a generator is a lazy, incrementally-pending list, and yield statements allow you to use function notation to program the list values the generator should incrementally spit out. Furthermore, advanced usage lets you use generators as coroutines (see below).Basically, whenever the yield statement is encountered, the function pauses and saves its state, then emits \"the next return value in the 'list'\" according to the python iterator protocol (to some syntactic construct like a for-loop that repeatedly calls next() and catches a StopIteration exception, etc.). You might have encountered generators with generator expressions; generator functions are more powerful because you can pass arguments back into the paused generator function, using them to implement coroutines. More on that later.Let's define a function makeRange that's just like Python's range. Calling makeRange(n) RETURNS A GENERATOR:To force the generator to immediately return its pending values, you can pass it into list() (just like you could any iterable):The above example can be thought of as merely creating a list which you append to and return:There is one major difference, though; see the last section.An iterable is the last part of a list comprehension, and all generators are iterable, so they're often used like so:To get a better feel for generators, you can play around with the itertools module (be sure to use chain.from_iterable rather than chain when warranted). For example, you might even use generators to implement infinitely-long lazy lists like itertools.count(). You could implement your own def enumerate(iterable): zip(count(), iterable), or alternatively do so with the yield keyword in a while-loop.Please note: generators can actually be used for many more things, such as implementing coroutines or non-deterministic programming or other elegant things. However, the \"lazy lists\" viewpoint I present here is the most common use you will find.This is how the \"Python iteration protocol\" works. That is, what is going on when you do list(makeRange(5)). This is what I describe earlier as a \"lazy, incremental list\".The built-in function next() just calls the objects .__next__() function, which is a part of the \"iteration protocol\" and is found on all iterators. You can manually use the next() function (and other parts of the iteration protocol) to implement fancy things, usually at the expense of readability, so try to avoid doing that...Coroutine example:A coroutine (generators which generally accept input via the yield keyword e.g. nextInput = yield nextOutput, as a form of two-way communication) is basically a computation which is allowed to pause itself and request input (e.g. to what it should do next). When the coroutine pauses itself (when the running coroutine eventually hits a yield keyword), the computation is paused and control is inverted (yielded) back to the 'calling' function (the frame which requested the next value of the computation). The paused generator/coroutine remains paused until another invoking function (possibly a different function/context) requests the next value to unpause it (usually passing input data to direct the paused logic interior to the coroutine's code).You can think of python coroutines as lazy incrementally-pending lists, where the next element doesn't just depend on the previous computation, but also on input you may opt to inject during the generation process.Normally, most people would not care about the following distinctions and probably want to stop reading here.In Python-speak, an iterable is any object which \"understands the concept of a for-loop\" like a list [1,2,3], and an iterator is a specific instance of the requested for-loop like [1,2,3].__iter__(). A generator is exactly the same as any iterator, except for the way it was written (with function syntax).When you request an iterator from a list, it creates a new iterator. However, when you request an iterator from an iterator (which you would rarely do), it just gives you a copy of itself.Thus, in the unlikely event that you are failing to do something like this...... then remember that a generator is an iterator; that is, it is one-time-use. If you want to reuse it, you should call myRange(...) again. If you need to use the result twice, convert the result to a list and store it in a variable x = list(myRange(5)). Those who absolutely need to clone a generator (for example, who are doing terrifyingly hackish metaprogramming) can use itertools.tee (still works in Python 3) if absolutely necessary, since the copyable iterator Python PEP standards proposal has been deferred.",
                "What does the yield keyword do in Python?yield is only legal inside of a function definition, and the inclusion of yield in a function definition makes it return a generator.The idea for generators comes from other languages (see footnote 1) with varying implementations. In Python's Generators, the execution of the code is frozen at the point of the yield. When the generator is called (methods are discussed below) execution resumes and then freezes at the next yield.yield provides an\neasy way of implementing the iterator protocol, defined by the following two methods:\n__iter__ and __next__.  Both of those methods\nmake an object an iterator that you could type-check with the Iterator Abstract Base\nClass from the collections module.Let's do some introspection:The generator type is a sub-type of iterator:And if necessary, we can type-check like this:A feature of an Iterator is that once exhausted, you can't reuse or reset it:You'll have to make another if you want to use its functionality again (see footnote 2):One can yield data programmatically, for example:The above simple generator is also equivalent to the below - as of Python 3.3 you can use yield from:However, yield from also allows for delegation to subgenerators,\nwhich will be explained in the following section on cooperative delegation with sub-coroutines.yield forms an expression that allows data to be sent into the generator (see footnote 3)Here is an example, take note of the received variable, which will point to the data that is sent to the generator:First, we must queue up the generator with the builtin function, next. It will\ncall the appropriate next or __next__ method, depending on the version of\nPython you are using:And now we can send data into the generator. (Sending None is\nthe same as calling next.) :Now, recall that yield from is available in Python 3. This allows us to delegate coroutines to a subcoroutine:And now we can delegate functionality to a sub-generator and it can be used\nby a generator just as above:Now simulate adding another 1,000 to the account plus the return on the account (60.0):You can read more about the precise semantics of yield from in PEP 380.The close method raises GeneratorExit at the point the function\nexecution was frozen. This will also be called by __del__ so you\ncan put any cleanup code where you handle the GeneratorExit:You can also throw an exception which can be handled in the generator\nor propagated back to the user:Raises:I believe I have covered all aspects of the following question:What does the yield keyword do in Python?It turns out that yield does a lot. I'm sure I could add even more\nthorough examples to this. If you want more or have some constructive criticism, let me know by commenting\nbelow.The top/accepted answer is a very incomplete answer.The grammar currently allows any expression in a list comprehension.Since yield is an expression, it has been touted by some as interesting to use it in comprehensions or generator expression - in spite of citing no particularly good use-case.The CPython core developers are discussing deprecating its allowance.\nHere's a relevant post from the mailing list:On 30 January 2017 at 19:05, Brett Cannon  wrote:On Sun, 29 Jan 2017 at 16:39 Craig Rodrigues  wrote:I'm OK with either approach.  Leaving things the way they are in Python 3\nis no good, IMHO.My vote is it be a SyntaxError since you're not getting what you expect from\nthe syntax.I'd agree that's a sensible place for us to end up, as any code\nrelying on the current behaviour is really too clever to be\nmaintainable.In terms of getting there, we'll likely want:Cheers, Nick.--  Nick Coghlan   |   ncoghlan at gmail.com   |   Brisbane, AustraliaFurther, there is an outstanding issue (10544) which seems to be pointing in the direction of this never being a good idea (PyPy, a Python implementation written in Python, is already raising syntax warnings.)Bottom line, until the developers of CPython tell us otherwise: Don't put yield in a generator expression or comprehension.In Python 3:In a generator function, the return statement indicates that the generator is done and will cause StopIteration to be raised. The returned value (if any) is used as an argument to construct StopIteration and becomes the StopIteration.value attribute.Historical note, in Python 2:\n\"In a generator function, the return statement is not allowed to include an expression_list. In that context, a bare return indicates that the generator is done and will cause StopIteration to be raised.\"\nAn expression_list is basically any number of expressions separated by commas - essentially, in Python 2, you can stop the generator with return, but you can't return a value.The languages CLU, Sather, and Icon were referenced in the proposal\nto introduce the concept of generators to Python. The general idea is\nthat a function can maintain internal state and yield intermediate\ndata points on demand by the user. This promised to be superior in performance\nto other approaches, including Python threading, which isn't even available on some systems.This means, for example, that range objects aren't Iterators, even though they are iterable, because they can be reused. Like lists, their __iter__ methods return iterator objects.yield was originally introduced as a statement, meaning that it\ncould only appear at the beginning of a line in a code block.\nNow yield creates a yield expression.\nhttps://docs.python.org/2/reference/simple_stmts.html#grammar-token-yield_stmt\nThis change was proposed to allow a user to send data into the generator just as\none might receive it. To send data, one must be able to assign it to something, and\nfor that, a statement just won't work.",
                "yield is just like return - it returns whatever you tell it to (as a generator). The difference is that the next time you call the generator, execution starts from the last call to the yield statement. Unlike return, the stack frame is not cleaned up when a yield occurs, however control is transferred back to the caller, so its state will resume the next time the function is called.In the case of your code, the function get_child_candidates is acting like an iterator so that when you extend your list, it adds one element at a time to the new list.list.extend calls an iterator until it's exhausted. In the case of the code sample you posted, it would be much clearer to just return a tuple and append that to the list.",
                "There's one extra thing to mention: a function that yields doesn't actually have to terminate. I've written code like this:Then I can use it in other code like this:It really helps simplify some problems, and makes some things easier to work with.",
                "For those who prefer a minimal working example, meditate on this interactive Python session:",
                "TL;DRWhenever you find yourself building a list from scratch, yield each piece instead.This was my first \"aha\" moment with yield.yield is a sugary way to saybuild a series of stuffSame behavior:Different behavior:Yield is single-pass: you can only iterate through once. When a function has a yield in it we call it a generator function. And an iterator is what it returns. Those terms are revealing. We lose the convenience of a container, but gain the power of a series that's computed as needed, and arbitrarily long.Yield is lazy, it puts off computation. A function with a yield in it doesn't actually execute at all when you call it. It returns an iterator object that remembers where it left off. Each time you call next() on the iterator (this happens in a for-loop) execution inches forward to the next yield. return raises StopIteration and ends the series (this is the natural end of a for-loop).Yield is versatile. Data doesn't have to be stored all together, it can be made available one at a time. It can be infinite.If you need multiple passes and the series isn't too long, just call list() on it:Brilliant choice of the word yield because both meanings apply:yield \u2014 produce or provide (as in agriculture)...provide the next data in the series.yield \u2014 give way or relinquish (as in political power)...relinquish CPU execution until the iterator advances.",
                "Yield gives you a generator.As you can see, in the first case foo holds the entire list in memory at once. It's not a big deal for a list with 5 elements, but what if you want a list of 5 million? Not only is this a huge memory eater, it also costs a lot of time to build at the time that the function is called.In the second case, bar just gives you a generator. A generator is an iterable--which means you can use it in a for loop, etc, but each value can only be accessed once. All the values are also not stored in memory at the same time; the generator object \"remembers\" where it was in the looping the last time you called it--this way, if you're using an iterable to (say) count to 50 billion, you don't have to count to 50 billion all at once and store the 50 billion numbers to count through.Again, this is a pretty contrived example, you probably would use itertools if you really wanted to count to 50 billion. :)This is the most simple use case of generators. As you said, it can be used to write efficient permutations, using yield to push things up through the call stack instead of using some sort of stack variable. Generators can also be used for specialized tree traversal, and all manner of other things.",
                "It's returning a generator. I'm not particularly familiar with Python, but I believe it's the same kind of thing as C#'s iterator blocks if you're familiar with those.The key idea is that the compiler/interpreter/whatever does some trickery so that as far as the caller is concerned, they can keep calling next() and it will keep returning values - as if the generator method was paused. Now obviously you can't really \"pause\" a method, so the compiler builds a state machine for you to remember where you currently are and what the local variables etc look like. This is much easier than writing an iterator yourself.",
                "There is one type of answer that I don't feel has been given yet, among the many great answers that describe how to use generators. Here is the programming language theory answer:The yield statement in Python returns a generator. A generator in Python is a function that returns continuations (and specifically a type of coroutine, but continuations represent the more general mechanism to understand what is going on).Continuations in programming languages theory are a much more fundamental kind of computation, but they are not often used, because they are extremely hard to reason about and also very difficult to implement. But the idea of what a continuation is, is straightforward: it is the state of a computation that has not yet finished. In this state, the current values of variables, the operations that have yet to be performed, and so on, are saved. Then at some point later in the program the continuation can be invoked, such that the program's variables are reset to that state and the operations that were saved are carried out.Continuations, in this more general form, can be implemented in two ways. In the call/cc way, the program's stack is literally saved and then when the continuation is invoked, the stack is restored.In continuation passing style (CPS), continuations are just normal functions (only in languages where functions are first class) which the programmer explicitly manages and passes around to subroutines. In this style, program state is represented by closures (and the variables that happen to be encoded in them) rather than variables that reside somewhere on the stack. Functions that manage control flow accept continuation as arguments (in some variations of CPS, functions may accept multiple continuations) and manipulate control flow by invoking them by simply calling them and returning afterwards. A very simple example of continuation passing style is as follows:In this (very simplistic) example, the programmer saves the operation of actually writing the file into a continuation (which can potentially be a very complex operation with many details to write out), and then passes that continuation (i.e, as a first-class closure) to another operator which does some more processing, and then calls it if necessary. (I use this design pattern a lot in actual GUI programming, either because it saves me lines of code or, more importantly, to manage control flow after GUI events trigger.)The rest of this post will, without loss of generality, conceptualize continuations as CPS, because it is a hell of a lot easier to understand and read.Now let's talk about generators in Python. Generators are a specific subtype of continuation. Whereas continuations are able in general to save the state of a computation (i.e., the program's call stack), generators are only able to save the state of iteration over an iterator. Although, this definition is slightly misleading for certain use cases of generators. For instance:This is clearly a reasonable iterable whose behavior is well defined -- each time the generator iterates over it, it returns 4 (and does so forever). But it isn't probably the prototypical type of iterable that comes to mind when thinking of iterators (i.e., for x in collection: do_something(x)). This example illustrates the power of generators: if anything is an iterator, a generator can save the state of its iteration.To reiterate: Continuations can save the state of a program's stack and generators can save the state of iteration. This means that continuations are more a lot powerful than generators, but also that generators are a lot, lot easier. They are easier for the language designer to implement, and they are easier for the programmer to use (if you have some time to burn, try to read and understand this page about continuations and call/cc).But you could easily implement (and conceptualize) generators as a simple, specific case of continuation passing style:Whenever yield is called, it tells the function to return a continuation.  When the function is called again, it starts from wherever it left off. So, in pseudo-pseudocode (i.e., not pseudocode, but not code) the generator's next method is basically as follows:where the yield keyword is actually syntactic sugar for the real generator function, basically something like:Remember that this is just pseudocode and the actual implementation of generators in Python is more complex. But as an exercise to understand what is going on, try to use continuation passing style to implement generator objects without use of the yield keyword.",
                "Here is an example in plain language. I will provide a correspondence between high-level human concepts to low-level Python concepts.I want to operate on a sequence of numbers, but I don't want to bother my self with the creation of that sequence, I want only to focus on the operation I want to do. So, I do the following:This is what a generator does (a function that contains a yield); it starts executing on the first next(), pauses whenever it does a yield, and when asked for the next() value it continues from the point it was last. It fits perfectly by design with the iterator protocol of Python, which describes how to sequentially request values.The most famous user of the iterator protocol is the for command in Python. So, whenever you do a:it doesn't matter if sequence is a list, a string, a dictionary or a generator object like described above; the result is the same: you read items off a sequence one by one.Note that defining a function which contains a yield keyword is not the only way to create a generator; it's just the easiest way to create one.For more accurate information, read about iterator types, the yield statement and generators in the Python documentation.",
                "While a lot of answers show why you'd use a yield to create a generator, there are more uses for yield.  It's quite easy to make a coroutine, which enables the passing of information between two blocks of code.  I won't repeat any of the fine examples that have already been given about using yield to create a generator.To help understand what a yield does in the following code, you can use your finger to trace the cycle through any code that has a yield.  Every time your finger hits the yield, you have to wait for a next or a send to be entered.  When a next is called, you trace through the code until you hit the yield\u2026 the code on the right of the yield is evaluated and returned to the caller\u2026 then you wait.  When next is called again, you perform another loop through the code.  However, you'll note that in a coroutine, yield can also be used with a send\u2026 which will send a value from the caller into the yielding function. If a send is given, then yield receives the value sent, and spits it out the left hand side\u2026 then the trace through the code progresses until you hit the yield again (returning the value at the end, as if next was called).For example:",
                "There is another yield use and meaning (since Python 3.3):From PEP 380 -- Syntax for Delegating to a Subgenerator:A syntax is proposed for a generator to delegate part of its operations to another generator. This allows a section of code containing 'yield' to be factored out and placed in another generator. Additionally, the subgenerator is allowed to return with a value, and the value is made available to the delegating generator.The new syntax also opens up some opportunities for optimisation when one generator re-yields values produced by another.Moreover this will introduce (since Python 3.5):to avoid coroutines being confused with a regular generator (today yield is used in both).",
                "All great answers, however a bit difficult for newbies.I assume you have learned the return statement.As an analogy, return and yield are twins. return means 'return and stop' whereas 'yield` means 'return, but continue'Run it:See, you get only a single number rather than a list of them. return never allows you prevail happily, just implements once and quit.Replace return with yield:Now, you win to get all the numbers.Comparing to return which runs once and stops, yield runs times you planed.\nYou can interpret return as return one of them, and yield as return all of them. This is called iterable.It's the core about yield.The difference between a list return outputs and the object yield output is:You will always get [0, 1, 2] from a list object but only could retrieve them from 'the object yield output' once. So, it has a new name generator object as displayed in Out[11]: <generator object num_list at 0x10327c990>.In conclusion, as a metaphor to grok it:",
                "From a programming viewpoint, the iterators are implemented as thunks.To implement iterators, generators, and thread pools for concurrent execution, etc. as thunks, one uses messages sent to a closure object, which has a dispatcher, and the dispatcher answers to \"messages\".\"next\" is a message sent to a closure, created by the \"iter\" call.There are lots of ways to implement this computation. I used mutation, but it is possible to do this kind of computation without mutation, by returning the current value and the next yielder (making it referential transparent).  Racket uses a sequence of transformations of the initial program in some intermediary languages, one of such rewriting making the yield operator to be transformed in some language with simpler operators.Here is a demonstration of how yield could be rewritten, which uses the structure of R6RS, but the semantics is identical to Python's. It's the same model of computation, and only a change in syntax is required to rewrite it using yield of Python.",
                "Here are some Python examples of how to actually implement generators as if Python did not provide syntactic sugar for them:As a Python generator:Using lexical closures instead of generatorsUsing object closures instead of generators (because ClosuresAndObjectsAreEquivalent)",
                "I was going to post \"read page 19 of Beazley's 'Python: Essential Reference' for a quick description of generators\", but so many others have posted good descriptions already.Also, note that yield can be used in coroutines as the dual of their use in generator functions.  Although it isn't the same use as your code snippet, (yield) can be used as an expression in a function.  When a caller sends a value to the method using the send() method, then the coroutine will execute until the next (yield) statement is encountered.Generators and coroutines are a cool way to set up data-flow type applications.  I thought it would be worthwhile knowing about the other use of the yield statement in functions.",
                "Here is a simple example:Output:I am not a Python developer, but it looks to me yield holds the position of program flow and the next loop start from \"yield\" position. It seems like it is waiting at that position, and just before that, returning a value outside, and next time continues to work.It seems to be an interesting and nice ability :D",
                "Here is a mental image of what yield does.I like to think of a thread as having a stack (even when it's not implemented that way).When a normal function is called, it puts its local variables on the stack, does some computation, then clears the stack and returns. The values of its local variables are never seen again.With a yield function, when its code begins to run (i.e. after the function is called, returning a generator object, whose next() method is then invoked), it similarly puts its local variables onto the stack and computes for a while. But then, when it hits the yield statement, before clearing its part of the stack and returning, it takes a snapshot of its local variables and stores them in the generator object. It also writes down the place where it's currently up to in its code (i.e. the particular yield statement).So it's a kind of a frozen function that the generator is hanging onto.When next() is called subsequently, it retrieves the function's belongings onto the stack and re-animates it. The function continues to compute from where it left off, oblivious to the fact that it had just spent an eternity in cold storage.Compare the following examples:When we call the second function, it behaves very differently to the first. The yield statement might be unreachable, but if it's present anywhere, it changes the nature of what we're dealing with.Calling yielderFunction() doesn't run its code, but makes a generator out of the code. (Maybe it's a good idea to name such things with the yielder prefix for readability.)The gi_code and gi_frame fields are where the frozen state is stored. Exploring them with dir(..), we can confirm that our mental model above is credible.",
                "Imagine that you have created a remarkable machine that is capable of generating thousands and thousands of lightbulbs per day. The machine generates these lightbulbs in boxes with a unique serial number. You don't have enough space to store all of these lightbulbs at the same time, so you would like to adjust it to generate lightbulbs on-demand.Python generators don't differ much from this concept. Imagine that you have a function called barcode_generator that generates unique serial numbers for the boxes. Obviously, you can have a huge number of such barcodes returned by the function, subject to the hardware (RAM) limitations. A wiser, and space efficient, option is to generate those serial numbers on-demand.Machine's code:Note the next(barcode) bit.As you can see, we have a self-contained \u201cfunction\u201d to generate the next unique serial number each time. This function returns a generator! As you can see, we are not calling the function each time we need a new serial number, but instead we are using next() given the generator to obtain the next serial number.To be more precise, this generator is a lazy iterator! An iterator is an object that helps us traverse a sequence of objects. It's called lazy because it does not load all the items of the sequence in memory until they are needed. The use of next in the previous example is the explicit way to obtain the next item from the iterator. The implicit way is using for loops:This will print barcodes infinitely, yet you will not run out of memory.In other words, a generator looks like a function but behaves like an iterator.Finally, real-world applications? They are usually useful when you work with big sequences. Imagine reading a huge file from disk with billions of records. Reading the entire file in memory, before you can work with its content, will probably be infeasible (i.e., you will run out of memory).",
                "An easy example to understand what it is: yieldThe output is:",
                "Like every answer suggests, yield is used for creating a sequence generator. It's used for generating some sequence dynamically. For example, while reading a file line by line on a network, you can use the yield function as follows:You can use it in your code as follows:Execution Control Transfer gotchaThe execution control will be transferred from getNextLines() to the for loop when yield is executed. Thus, every time getNextLines() is invoked, execution begins from the point where it was paused last time.Thus in short, a function with the following codewill print",
                "(My below answer only speaks from the perspective of using Python generator, not the underlying implementation of generator mechanism, which involves some tricks of stack and heap manipulation.)When yield is used instead of a return in a python function, that function is turned into something special called generator function. That function will return an object of generator type. The yield keyword is a flag to notify the python compiler to treat such function specially. Normal functions will terminate once some value is returned from it. But with the help of the compiler, the generator function can be thought of as resumable. That is, the execution context will be restored and the execution will continue from last run. Until you explicitly call return, which will raise a StopIteration exception (which is also part of the iterator protocol), or reach the end of the function. I found a lot of references about generator but this one from the functional programming perspective is the most digestable.(Now I want to talk about the rationale behind generator, and the iterator based on my own understanding. I hope this can help you grasp the essential motivation of iterator and generator. Such concept shows up in other languages as well such as C#.)As I understand, when we want to process a bunch of data, we usually first store the data somewhere and then process it one by one. But this naive approach is problematic. If the data volume is huge, it's expensive to store them as a whole beforehand. So instead of storing the data itself directly, why not store some kind of metadata indirectly, i.e. the logic how the data is computed.There are 2 approaches to wrap such metadata.Either way, an iterator is created, i.e. some object that can give you the data you want. The OO approach may be a bit complex. Anyway, which one to use is up to you.",
                "In summary, the yield statement transforms your function into a factory that produces a special object called a generator which wraps around the body of your original function. When the generator is iterated, it executes your function  until it reaches the next yield then suspends execution and evaluates to the value passed to yield. It repeats this process on each iteration until the path of execution exits the function. For instance,simply outputsThe power comes from using the generator with a loop that calculates a sequence, the generator executes the loop stopping each time to 'yield' the next result of the calculation, in this way it calculates a list on the fly, the benefit being the memory saved for especially large calculationsSay you wanted to create a your own range function that produces an iterable range of numbers, you could do it like so,and use it like this;But this is inefficient becauseLuckily Guido and his team were generous enough to develop generators so we could just do this;Now upon each iteration a function on the generator called next() executes the function until it either reaches a 'yield' statement in which it stops and  'yields' the value or reaches the end of the function. In this case on the first call, next() executes up to the yield statement and yield 'n', on the next call it will execute the  increment statement, jump back to the 'while', evaluate it, and if true, it will stop and yield 'n' again, it will continue that way until the while condition returns false and the generator jumps to the end of the function.",
                "Yield is an objectA return in a function will return a single value.If you want a function to return a huge set of values, use yield.More importantly, yield is a barrier.like barrier in the CUDA language, it will not transfer control until it gets\n  completed.That is, it will run the code in your function from the beginning until it hits yield. Then, it\u2019ll return the first value of the loop.Then, every other call will run the loop you have written in the function one more time, returning the next value until there isn't any value to return.",
                "Many people use return rather than yield, but in some cases yield can be more efficient and easier to work with.Here is an example which yield is definitely best for:return (in function)yield (in function)Calling functionsBoth functions do the same thing, but yield uses three lines instead of five and has one less variable to worry about.This is the result from the code:As you can see both functions do the same thing. The only difference is return_dates() gives a list and yield_dates() gives a generator.A real life example would be something like reading a file line by line or if you just want to make a generator.",
                "The yield keyword simply collects returning results. Think of yield like return +=",
                "yield is like a return element for a function. The difference is, that the yield element turns a function into a generator. A generator behaves just like a function until something is 'yielded'. The generator stops until it is next called, and continues from exactly the same point as it started. You can get a sequence of all the 'yielded' values in one, by calling list(generator())."
            ]
        },
        {
            "tag": "",
            "question": [
                "Which JSON content type do I use?",
                "There are many \"standards\" for the JSON content type:\napplication/json\napplication/x-javascript\ntext/javascript\ntext/x-javascript\ntext/x-json\n\nWhich one do I use, and where? I assume ..."
            ],
            "url": "https://stackoverflow.com/questions/477816",
            "answer": [
                "For JSON text:The MIME media type for JSON text is application/json. The default encoding is UTF-8. (Source: RFC 4627)For JSONP (runnable JavaScript) with callback:Here are some blog posts that were mentioned in the relevant comments:",
                "IANA has registered the official MIME Type for JSON as application/json.When asked about why not text/json, Crockford seems to have said JSON is not really JavaScript nor text and also IANA was more likely to hand out application/* than text/*.More resources:",
                "For JSON:For JSON-P:",
                "Of course, the correct MIME media type for JSON is application/json, but it's necessary to realize what type of data is expected in your application.For example, I use Ext GWT and the server response must go as text/html but contains JSON data.Client side, Ext GWT form listenerIn case of using application/json response type, the browser suggests me to save the file.Server side source code snippet using Spring MVC",
                "Response is dynamically generated data, according to the query parameters passed in the URL.Example:Content-Type: application/jsonJSON with padding.\nResponse is JSON data, with a function call wrapped around it.Example:Content-Type: application/javascript",
                "If you are using Ubuntu or Debian and you serve .json files through Apache, you might want to serve the files with the correct content type. I am doing this primarily because I want to use the Firefox extension JSONViewThe Apache module mod_mime will help to do this easily. However, with Ubuntu you need to edit the file /etc/mime.types and add the lineThen restart Apache:",
                "If you're calling ASP.NET Web Services from the client-side you have to use application/json for it to work. I believe this is the same for the jQuery and Ext frameworks.",
                "The right content type for JSON is application/json UNLESS you're using JSONP, also known as JSON with Padding, which is actually JavaScript and so the right content type would be application/javascript.",
                "There is no doubt that application/json is the best MIME type for a JSON response.But I had some experience where I had to use application/x-javascript because of some compression issues. My hosting environment is shared hosting with GoDaddy. They do not allow me to change server configurations. I had added the following code to my web.config file for compressing responses.By using this, the .aspx pages was compressed with g-zip but JSON responses were not. I addedin the static and dynamic types sections. But this does not compress JSON responses at all.After that I removed this newly added type and addedin both the static and dynamic types sections, and changed the response type in.ashx (asynchronous handler) toAnd now I found that my JSON responses were compressed with g-zip. So I personally recommend to useonly if you want to compress your JSON responses on a shared hosting environment. Because in shared hosting, they do not allow you to change IIS configurations.",
                "Only when using application/json as the MIME type I have the following (as of November 2011 with the most recent versions of Chrome, Firefox with Firebug):",
                "Not everything works for content type application/json.If you are using Ext\u00a0JS form submit to upload file, be aware that the server response is parsed by the browser to create the document for the <iframe>.If the server is using JSON to send the return object, then the Content-Type header must be set to text/html in order to tell the browser to insert the text unchanged into the document body.See the Ext JS 3.4.0 API documentation.",
                "JSON is a domain-specific language (DSL) and a data format independent of JavaScript, and as such has its own MIME type, application/json. Respect for MIME types is of course client driven, so text/plain may do for transfer of bytes, but then you would be pushing up interpretation to the vendor application domain unnecessarily - application/json. Would you transfer XML via text/plain?But honestly, your choice of MIME type is advice to the client as to how to interpret the data- text/plain or text/HTML (when it's not HTML) is like type erasure- it's as uninformative as making all your objects of type Object in a typed language.No browser runtime I know of will take a JSON document and automatically make it available to the runtime as a JavaScript accessible object without intervention, but if you are working with a crippled client, that's an entirely different matter. But that's not the whole story- RESTful JSON services often don't have JavaScript runtimes, but it doesn't stop them using JSON as a viable data interchange format. If clients are that crippled... then I would consider perhaps HTML injection via an Ajax templating service instead.Application/JSON!",
                "If you're in a client-side environment, investigating about the cross-browser support is mandatory for a well supported web application.The right HTTP Content-Type would be application/json, as others already highlighted too, but some clients do not handle it very well, that's why jQuery recommends the default text/html.",
                "The correct answer is:",
                "As many others have mentioned, application/json is the correct answer.But what haven't been explained yet is what the other options you proposed mean.application/x-javascript: Experimental MIME type for JavaScript before application/javascript was made standard.text/javascript: Now obsolete. You should use application/javascript when using javascript.text/x-javascript: Experimental MIME type for the above situation.text/x-json: Experimental MIME type for JSON before application/json got officially registered.All in all, whenever you have any doubts about content types, you should check this link",
                "In JSP, you can use this in page directive:The correct MIME media type for JSON is application/json.  JSP will use it for sending a response to the client.",
                "\u201capplication/json\u201d is the correct JSON content type.",
                "The IANA registration for application/json saysApplications that use this media type:  JSON has been used to\n     exchange data between applications written in all of these\n     programming languages: ActionScript, C, C#, Clojure, ColdFusion,\n     Common Lisp, E, Erlang, Go, Java, JavaScript, Lua, Objective CAML,\n     Perl, PHP, Python, Rebol, Ruby, Scala, and Scheme.You'll notice that IANA.org doesn't list any of these other media types, in fact even application/javascript is now obsolete. So application/json is really the only possible correct answer.Browser support is another thing.The most widely supported non-standard media types are text/json or text/javascript. But some big names even use text/plain.Even more strange is the Content-Type header sent by Flickr, who returns JSON as text/xml. Google uses text/javascript for some of it's ajax apis.Examples:Output: Content-Type: text/javascriptOutput: Content-Type: text/xml",
                "The right MIME type is application/jsonBUTI experienced many situations where the browser type or the framework user needed:",
                "I use the below",
                "The Content-Type header should be set to 'application/json' when posting. Server listening for the request should include \"Accept=application/json\".\nIn Spring MVC you can do it like this:Add headers to the response:",
                "The application/json works great in PHP to store an array or object\n  data.I use this code to put data in JSON on Google Cloud Storage (GCS) which is set publically viewable:To get back the data is straight forward:",
                "In Spring you have a defined type: MediaType.APPLICATION_JSON_VALUE which is equivalent to application/json.",
                "For JSON, I am using:This is described in the IETF's JSON Data Interchange Format 7158 proposal, Section 1.2: Specifications of JSON.",
                "If the JSON is with padding then it will be application/jsonp. If the JSON is without padding then it will be application/json.To deal with both, it is a good practice to use: 'application/javascript' without bothering whether it is with padding or without padding.",
                "Extending the accepted responses, when you are using JSON in a REST context...There is a strong argument about using application/x-resource+json and application/x-collection+json when you are representing REST resources and collections.And if you decide to follow the jsonapi specification, you should use of application/vnd.api+json, as it is documented.Altough there is not an universal standard, it is clear that the added semantic to the resources being transfered justify a more explicit Content-Type than just application/json.Following this reasoning, other contexts could justify a more specific Content-Type.",
                "If you get data from REST API in JSON, you have to use Content-Type:",
                "PHP developers use this:",
                "JSON (JavaScript Object Notation) and JSONP (\"JSON with padding\") formats seems to be very similar and therefore it might be very confusing which MIME type they should be using. Even though the formats are similar, there are some subtle differences between them.So whenever in any doubts, I have a very simple approach (which works perfectly fine in most cases), namely, go and check corresponding RFC document.JSON\nRFC 4627 (The application/json Media Type for JavaScript Object Notation (JSON)) is a specifications of JSON format. It says in section 6, that the MIME media type for JSON text isJSONP\nJSONP (\"JSON with padding\") is handled different way than JSON, in a browser. JSONP is treated as a regular JavaScript script and therefore it should use application/javascript, the current official MIME type for JavaScript. In many cases, however, text/javascript MIME type will work fine too.Note that text/javascript has been marked as obsolete by RFC 4329 (Scripting Media Types) document and it is recommended to use application/javascript type instead. However, due to legacy reasons, text/javascript is still widely used and it has cross-browser support (which is not always a case with application/javascript MIME type, especially with older browsers)."
            ]
        },
        {
            "tag": "",
            "question": [
                "How can I remove a specific item from an array?",
                "How do I remove a specific value from an array? Something like:\narray.remove(value);\n\nI have to use core JavaScript. Frameworks are not allowed."
            ],
            "url": "https://stackoverflow.com/questions/5767325",
            "answer": [
                "Find the index of the array element you want to remove using indexOf, and then remove that index with splice.The splice() method changes the contents of an array by removing\nexisting elements and/or adding new elements.const array = [2, 5, 9];\n\nconsole.log(array);\n\nconst index = array.indexOf(5);\nif (index > -1) { // only splice array when item is found\n  array.splice(index, 1); // 2nd parameter means remove one item only\n}\n\n// array = [2, 9]\nconsole.log(array);The second parameter of splice is the number of elements to remove. Note that splice modifies the array in place and returns a new array containing the elements that have been removed.For the reason of completeness, here are functions. The first function removes only a single occurrence (i.e. removing the first match of 5 from [2,5,9,1,5,8,5]), while the second function removes all occurrences:function removeItemOnce(arr, value) {\n  var index = arr.indexOf(value);\n  if (index > -1) {\n    arr.splice(index, 1);\n  }\n  return arr;\n}\n\nfunction removeItemAll(arr, value) {\n  var i = 0;\n  while (i < arr.length) {\n    if (arr[i] === value) {\n      arr.splice(i, 1);\n    } else {\n      ++i;\n    }\n  }\n  return arr;\n}\n// Usage\nconsole.log(removeItemOnce([2,5,9,1,5,8,5], 5))\nconsole.log(removeItemAll([2,5,9,1,5,8,5], 5))In TypeScript, these functions can stay type-safe with a type parameter:",
                "Edited on 2016 OctoberIn this code example I use array.filter(...) function to remove unwanted items from an array. This function doesn't change the original array and creates a new one. If your browser doesn't support this function (e.g. Internet Explorer before version 9, or Firefox before version 1.5), consider polyfilling with core-js.IMPORTANT ECMAScript 6 () => {} arrow function syntax is not supported in Internet Explorer at all, Chrome before version 45, Firefox before version 22, and Safari before version 10. To use ECMAScript 6 syntax in old browsers you can use BabelJS.An additional advantage of this method is that you can remove multiple itemsIMPORTANT array.includes(...) function is not supported in Internet Explorer at all, Chrome before version 47, Firefox before version 43, Safari before version 9, and Edge before version 14 but you can polyfill with core-js.If the \"This-Binding Syntax\" proposal is ever accepted, you'll be able to do this:Try it yourself in BabelJS :)Reference",
                "I don't know how you are expecting array.remove(int) to behave. There are three possibilities I can think of that you might want.To remove an element of an array at an index i:If you want to remove every element with value number from the array:If you just want to make the element at index i no longer exist, but you don't want the indexes of the other elements to change:",
                "It depends on whether you want to keep an empty spot or not.If you do want an empty slot:If you don't want an empty slot:And if you need the value of that item, you can just store the returned array's element:If you want to remove at either end of the array, you can use array.pop() for the last one or array.shift() for the first one (both return the value of the item as well).If you don't know the index of the item, you can use array.indexOf(item) to get it (in a if() to get one item or in a while() to get all of them). array.indexOf(item) returns either the index or -1 if not found.",
                "A friend was having issues in Internet\u00a0Explorer\u00a08 and showed me what he did. I told him it was wrong, and he told me he got the answer here. The current top answer will not work in all browsers (Internet\u00a0Explorer\u00a08 for example), and it will only remove the first occurrence of the item.It loops through the array backwards (since indices and length will change as items are removed) and removes the item if it's found. It works in all browsers.",
                "There are two major approachessplice(): anArray.splice(index, 1);delete: delete anArray[index];Be careful when you use the delete for an array. It is good for deleting attributes of objects, but not so good for arrays. It is better to use splice for arrays.Keep in mind that when you use delete for an array you could get wrong results for anArray.length. In other words, delete would remove the element, but it wouldn't update the value of the length property.You can also expect to have holes in index numbers after using delete, e.g. you could end up with having indexes 1, 3, 4, 8, 9, and 11 and length as it was before using delete. In that case, all indexed for loops would crash, since indexes are no longer sequential.If you are forced to use delete for some reason, then you should use for each loops when you need to loop through arrays. As the matter of fact, always avoid using indexed for loops, if possible. That way the code would be more robust and less prone to problems with indexes.",
                "Array.prototype.removeByValue = function (val) {\n  for (var i = 0; i < this.length; i++) {\n    if (this[i] === val) {\n      this.splice(i, 1);\n      i--;\n    }\n  }\n  return this;\n}\n\nvar fruits = ['apple', 'banana', 'carrot', 'orange'];\nfruits.removeByValue('banana');\n\nconsole.log(fruits);\n// -> ['apple', 'carrot', 'orange']",
                "There isn't any need to use indexOf or splice. However, it performs better if you only want to remove one occurrence of an element.Find and move (move):Use indexOf and splice (indexof):Use only splice (splice):Run-times on Node.js for an array with 1000 elements (averaged over 10,000 runs):indexof is approximately 10 times slower than move. Even if improved by removing the call to indexOf in splice, it performs much worse than move.",
                "This provides a predicate instead of a value.NOTE: it will update the given array, and return the affected rows.",
                "You can do it easily with the filter method:function remove(arrOriginal, elementToRemove){\n    return arrOriginal.filter(function(el){return el !== elementToRemove});\n}\nconsole.log(remove([1, 2, 1, 0, 3, 1, 4], 1));This removes all elements from the array and also works faster than a combination of slice and indexOf.",
                "John Resig posted a good implementation:If you don\u2019t want to extend a global object, you can do something like the following, instead:But the main reason I am posting this is to warn users against the alternative implementation suggested in the comments on that page (Dec 14, 2007):It seems to work well at first, but through a painful process I discovered it fails when trying to remove the second to last element in an array. For example, if you have a 10-element array and you try to remove the 9th element with this:You end up with an 8-element array. I don't know why, but I confirmed John's original implementation doesn't have this problem.",
                "You can use ES6. For example to delete the value '3' in this case:Output :",
                "Underscore.js can be used to solve issues with multiple browsers. It uses in-build browser methods if present. If they are absent like in the case of older Internet\u00a0Explorer versions it uses its own custom methods.A simple example to remove elements from array (from the website):",
                "Using filter is an elegant way to achieve this requirement.\nfilter will not mutate the original array.const num = 3;\nlet arr = [1, 2, 3, 4];\nconst arr2 = arr.filter(x => x !== num);\nconsole.log(arr); // [1, 2, 3, 4]\nconsole.log(arr2); // [1, 2, 4]You can use filter and then assign the result to the original array if you want to achieve a mutation removal behaviour.const num = 3;\nlet arr = [1, 2, 3, 4];\narr = arr.filter(x => x !== num);\nconsole.log(arr); // [1, 2, 4]By the way, filter will remove all of the occurrences matched in the condition (not just the first occurrence) like you can see in the following exampleconst num = 3;\nlet arr = [1, 2, 3, 3, 3, 4];\narr = arr.filter(x => x !== num);\nconsole.log(arr); // [1, 2, 4]In case, you just want to remove the first occurrence, you can use the splice methodconst num = 3;\nlet arr = [1, 2, 3, 3, 3, 4];\narr.splice(arr.indexOf(num), 1);\nconsole.log(arr); // [1, 2, 3, 3, 4]",
                "Here are a few ways to remove an item from an array using JavaScript.All the method described do not mutate the original array, and instead create a new one.Suppose you have an array, and you want to remove an item in position i.One method is to use slice():const items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst i = 3\nconst filteredItems = items.slice(0, i).concat(items.slice(i+1, items.length))\n\nconsole.log(filteredItems)slice() creates a new array with the indexes it receives. We simply create a new array, from start to the index we want to remove, and concatenate another array from the first position following the one we removed to the end of the array.In this case, one good option is to use filter(), which offers a more declarative approach:const items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst valueToRemove = 'c'\nconst filteredItems = items.filter(item => item !== valueToRemove)\n\nconsole.log(filteredItems)This uses the ES6 arrow functions. You can use the traditional functions to support older browsers:const items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst valueToRemove = 'c'\nconst filteredItems = items.filter(function(item) {\n  return item !== valueToRemove\n})\n\nconsole.log(filteredItems)or you can use Babel and transpile the ES6 code back to ES5 to make it more digestible to old browsers, yet write modern JavaScript in your code.What if instead of a single item, you want to remove many items?Let's find the simplest solution.You can just create a function and remove items in series:const items = ['a', 'b', 'c', 'd', 'e', 'f']\n\nconst removeItem = (items, i) =>\n  items.slice(0, i-1).concat(items.slice(i, items.length))\n\nlet filteredItems = removeItem(items, 3)\nfilteredItems = removeItem(filteredItems, 5)\n//[\"a\", \"b\", \"c\", \"d\"]\n\nconsole.log(filteredItems)You can search for inclusion inside the callback function:const items = ['a', 'b', 'c', 'd', 'e', 'f']\nconst valuesToRemove = ['c', 'd']\nconst filteredItems = items.filter(item => !valuesToRemove.includes(item))\n//\u00a0[\"a\", \"b\", \"e\", \"f\"]\n\nconsole.log(filteredItems)splice() (not to be confused with slice()) mutates the original array, and should be avoided.(originally posted on my site https://flaviocopes.com/how-to-remove-item-from-array/)",
                "If you want a new array with the deleted positions removed, you can always delete the specific element and filter out the array. It might need an extension of the array object for browsers that don't implement the filter method, but in the long term it's easier since all you do is this:It should display [1, 2, 3, 4, 6].",
                "Check out this code. It works in every major browser.remove_item = function(arr, value) {\n var b = '';\n for (b in arr) {\n  if (arr[b] === value) {\n   arr.splice(b, 1);\n   break;\n  }\n }\n return arr;\n};\n\nvar array = [1,3,5,6,5,9,5,3,55]\nvar res = remove_item(array,5);\nconsole.log(res)",
                "Removing a particular element/string from an array can be done in a one-liner:where:theArray: the array you want to remove something particular fromstringToRemoveFromArray: the string you want to be removed and 1 is the number of elements you want to remove.NOTE: If \"stringToRemoveFromArray\" is not located in the array, this will remove the last element of the array.It's always good practice to check if the element exists in your array first, before removing it.Depending if you have newer or older version of Ecmascript running on your client's computers:ORWhere '3' is the value you want to be removed from the array.\nThe array would then become : ['1','2','4','5','6']",
                "This post summarizes common approaches to element removal from an array as of ECMAScript 2019 (ES10).| In-place: Yes | \n| Removes duplicates: Yes(loop), No(indexOf) | \n| By value / index: By index |If you know the value you want to remove from an array you can use the splice method. First, you must identify the index of the target item. You then use the index as the start element and remove just one element.| In-place: No | \n| Removes duplicates: Yes | \n| By value / index: By value |The specific element can be filtered out from the array, by providing a filtering function. Such function is then called for every element in the array.| In-place: Yes/No (Depends on implementation) | \n| Removes duplicates: Yes/No (Depends on implementation) | \n| By value / index: By index / By value (Depends on implementation) |The prototype of Array can be extended with additional methods. Such methods will be then available to use on created arrays.Note: Extending prototypes of objects from the standard library of JavaScript (like Array) is considered by some as an antipattern.| In-place: Yes | \n| Removes duplicates: No | \n| By value / index: By index |Using the delete operator does not affect the length property. Nor does it affect the indexes of subsequent elements. The array becomes sparse, which is a fancy way of saying the deleted item is not removed but becomes undefined.The delete operator is designed to remove properties from JavaScript objects, which arrays are objects.| In-place: No | \n| Removes duplicates: Yes | \n| By value / index: By value |ES10 introduced Object.fromEntries, which can be used to create the desired Array from any Array-like object and filter unwanted elements during the process.| In-place: Yes | \n| Removes duplicates: No | \n| By value / index: N/A |JavaScript Array elements can be removed from the end of an array by setting the length property to a value less than the current value. Any element whose index is greater than or equal to the new length will be removed.| In-place: Yes | \n| Removes duplicates: No | \n| By value / index: N/A |The pop method removes the last element of the array, returns that element, and updates the length property. The pop method modifies the array on which it is invoked, This means unlike using delete the last element is removed completely and the array length reduced.| In-place: Yes | \n| Removes duplicates: No | \n| By value / index: N/A |The .shift() method works much like the pop method except it removes the first element of a JavaScript array instead of the last. When the element is removed the remaining elements are shifted down.| In-place: Yes | \n| Removes duplicates: N/A | \n| By value / index: N/A |The fastest technique is to set an array variable to an empty array.Alternatively technique from 2.1.1 can be used by setting length to 0.",
                "You can use lodash _.pull (mutate array), _.pullAt (mutate array) or _.without (does't mutate array),",
                "ES6 & without mutation:  (October 2016)const removeByIndex = (list, index) =>\r\n      [\r\n        ...list.slice(0, index),\r\n        ...list.slice(index + 1)\r\n      ];\r\n         \r\noutput = removeByIndex([33,22,11,44],1) //=> [33,11,44]\r\n      \r\nconsole.log(output)",
                "Today (2019-12-09) I conduct performance tests on macOS v10.13.6 (High Sierra) for chosen solutions. I show delete (A), but I do not use it in comparison with other methods, because it left empty space in the array.The conclusionsIn tests, I remove the middle element from the array in different ways. The A, C solutions are in-place. The B, D, E, F, G, H solutions are immutable.Results for an array with 10 elementsIn Chrome the array.splice (C) is the fastest in-place solution. The array.filter (D) is the fastest immutable solution. The slowest is array.slice (F). You can perform the test on your machine here.Results for an array with 1.000.000 elementsIn Chrome the array.splice (C) is the fastest in-place solution (the delete (C) is similar fast - but it left an empty slot in the array (so it does not perform a 'full remove')). The array.slice-splice (H) is the fastest immutable solution. The slowest is array.filter (D and E). You can perform the test on your machine here.var a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];\nvar log = (letter,array) => console.log(letter, array.join `,`);\n\nfunction A(array) {\n  var index = array.indexOf(5);\n  delete array[index];\n  log('A', array);\n}\n\nfunction B(array) {\n  var index = array.indexOf(5);\n  var arr = Array.from(array);\n  arr.splice(index, 1)\n  log('B', arr);\n}\n\nfunction C(array) {\n  var index = array.indexOf(5);\n  array.splice(index, 1);\n  log('C', array);\n}\n\nfunction D(array) {\n  var arr = array.filter(item => item !== 5)\n  log('D', arr);\n}\n\nfunction E(array) {\n  var index = array.indexOf(5);\n  var arr = array.filter((item, i) => i !== index)\n  log('E', arr);\n}\n\nfunction F(array) {\n  var index = array.indexOf(5);\n  var arr = array.slice(0, index).concat(array.slice(index + 1))\n  log('F', arr);\n}\n\nfunction G(array) {\n  var index = array.indexOf(5);\n  var arr = [...array.slice(0, index), ...array.slice(index + 1)]\n  log('G', arr);\n}\n\nfunction H(array) {\n  var index = array.indexOf(5);\n  var arr = array.slice(0);\n  arr.splice(index, 1);\n  log('H', arr);\n}\n\nA([...a]);\nB([...a]);\nC([...a]);\nD([...a]);\nE([...a]);\nF([...a]);\nG([...a]);\nH([...a]);\nThis snippet only presents code used in performance tests - it does not perform tests itself.Comparison for browsers: Chrome v78.0.0, Safari v13.0.4, and Firefox v71.0.0",
                "OK, for example you have the array below:And we want to delete number 4. You can simply use the below code:If you are reusing this function, you write a reusable function which will be attached to the native array function like below:But how about if you have the below array instead with a few [5]s in the array?We need a loop to check them all, but an easier and more efficient way is using built-in JavaScript functions, so we write a function which use a filter like below instead:Also there are third-party libraries which do help you to do this, like Lodash or Underscore. For more information, look at lodash _.pull, _.pullAt or _.without.",
                "I'm pretty new to JavaScript and needed this functionality. I merely wrote this:Then when I want to use it:Output - As expected.\n[\"item1\", \"item1\"]You may have different needs than I, so you can easily modify it to suit them. I hope this helps someone.",
                "I want to answer based on ECMAScript\u00a06. Assume you have an array like below:If you want to delete at a special index like 2, write the below code:But if you want to delete a special item like 3 and you don't know its index, do like below:Hint: please use an arrow function for filter callback unless you will get an empty array.",
                "If you have complex objects in the array you can use filters? \nIn situations where $.inArray or array.splice is not as easy to use. Especially if the objects are perhaps shallow in the array.E.g. if you have an object with an Id field and you want the object removed from an array:",
                "Update: This method is recommended only if you cannot use ECMAScript 2015 (formerly known as ES6). If you can use it, other answers here provide much neater implementations.This gist here will solve your problem, and also deletes all occurrences of the argument instead of just 1 (or a specified value).Usage:",
                "You should never mutate your array as this is against the functional programming pattern. You can create a new array without referencing the one you want to change data of using the ECMAScript\u00a06 method filter;Suppose you want to remove 5 from the array, you can simply do it like this:This will give you a new array without the value you wanted to remove. So the result will be:For further understanding you can read the MDN documentation on Array.filter.",
                "A more modern, ECMAScript 2015 (formerly known as Harmony or ES 6) approach. Given:Then:Yielding:You can use Babel and a polyfill service to ensure this is well supported across browsers.",
                "You can do a backward loop to make sure not to screw up the indexes, if there are multiple instances of the element.var myElement = \"chocolate\";\nvar myArray = ['chocolate', 'poptart', 'poptart', 'poptart', 'chocolate', 'poptart', 'poptart', 'chocolate'];\n\n/* Important code */\nfor (var i = myArray.length - 1; i >= 0; i--) {\n  if (myArray[i] == myElement) myArray.splice(i, 1);\n}\nconsole.log(myArray);"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I rename a local Git branch?",
                "How do I rename a local branch which has not yet been pushed to a remote repository?\nRelated:\n\nRename master branch for both local and remote Git repositories\nHow do I rename both a Git local and ..."
            ],
            "url": "https://stackoverflow.com/questions/6591213",
            "answer": [
                "To rename the current branch:To rename a branch while pointed to any branch:-m is short for --move.To push the  local branch and reset the upstream branch:To delete the  remote branch:To create a git rename alias:On Windows or another case-insensitive filesystem, use -M if there are only capitalization changes in the name. Otherwise, Git will throw a \"branch already exists\" error.",
                "The above command will change your branch name, but you have to be very careful using the renamed branch, because it will still refer to the old upstream branch associated with it, if any.If you want to push some changes into master after your local branch is renamed into new_branch_name (example name):git push origin new_branch_name:master (now changes will go to master branch but your local branch name is new_branch_name)For more details, see \"How to rename your local branch name in Git.\"",
                "To rename your current branch:",
                "Here are the steps to rename the branch:EDIT (12/01/2017): Make sure you run command git status and check that the newly created branch is pointing to its own ref and not the older one. If you find the reference to the older branch, you need to unset the upstream using:",
                "Rename the branch will be useful once your branch is finished. Then new stuff is coming, and you want to develop in the same branch instead of deleting it and create the new one.From my experience, to rename a local and remote branch in Git you should do the following steps.Quoting from Multiple States - Rename a local and remote branch in\n  gitIf you are on the branch you want to rename:If you are on a different branch:",
                "The answers so far have been correct, but here is some additional information:One can safely rename a branch with '-m' (move), but one has to be careful with '-M', because it forces the rename, even if there is an existing branch with the same name already. Here is the excerpt from the 'git-branch' man page:With a -m or -M option, <oldbranch> will be renamed to <newbranch>. If <oldbranch> had a corresponding reflog, it is renamed to match <newbranch>, and a reflog entry is created to remember the branch renaming. If <newbranch> exists, -M must be used to force the rename to happen.",
                "If it is your current branch, just doIf it is another branch you want to rename- If your branch was pushed, then after renaming you need to delete it from the remote Git repository and ask your new local to track a new remote branch:",
                "I foolishly named a branch starting with a hyphen, and then checked out master.  I didn't want to delete my branch, I had work in it.Neither of these worked:git checkout -dumb-namegit checkout -- -dumb-name\"s, 's and \\s didn't help either.  git branch -m doesn't work.Here's how I finally fixed it. Go into your working copy's .git/refs/heads, find the filename \"-dumb-name\", get the hash of the branch.  Then this will check it out, make a new branch with a sane name, and delete the old one.",
                "Just three steps to replicate change in name on remote as well as on GitHub:Step 1 git branch -m old_branchname new_branchnameStep 2 git push origin :old_branchname new_branchnameStep 3 git push --set-upstream origin new_branchname",
                "To rename a branch locally:Now you'll have to propagate these changes on your remote server as well.To push changes of the deleted old branch:To push changes of creation of new branch:",
                "Trying to answer specifically the question (at least the title).You can also rename the local branch, but keep tracking the old name on the remote.Now, when you run git push, the remote old_branch ref is updated with your local new_branch.You have to know and remember this configuration. But it can be useful if you don't have the choice for the remote branch name, but you don't like it (oh, I mean, you've got a very good reason not to like it !) and prefer a clearer name for your local branch.Playing with the fetch configuration, you can even rename the local remote-reference. i.e, having a refs/remote/origin/new_branch ref pointer to the branch, that is in fact the old_branch on origin. However, I highly discourage this, for the safety of your mind.",
                "Update 2022Before we begin, make sure you\u2019ve selected the branch you want to rename:If you want to see all of your local branches, use the following command:When you\u2019re all clear, follow these steps:Using the Git rename branch command will require you to add an -m option to your command:You can also rename a local branch from another branch by using the following two commands:Lastly, this command will list all \u2014 both local and remote \u2014 branches to verify that it has been renamed:Although it isn\u2019t possible to rename a remote branch directly, the process of renaming one involves these two easy steps:To start, you will need to rename a local branch by following the previous steps.\n2.Then delete the old branch and push the new one. You can do this easily with the following command:Reset the upstream branch for your new local branch, and you will be all set:",
                "Rename the branch using this command:-m: It renames/moves the branch. If there is already a branch, you will get an error.If there is already a branch and you want to rename with that branch, use:For more information about help, use this command in the terminal:or",
                "Advanced Git users can rename manually using:",
                "If you are on the branch you want to rename:If you are on a different branch:git push origin :old-name new-namegit push origin -u new-nameOr for a fast way to do that, you can use these 3 steps:# Rename branch locally# Delete the old remote branch# Push the new branch, set local branch to track the new remoteReferance: https://www.w3docs.com/snippets/git/how-to-rename-git-local-and-remote-branches.html",
                "Here are three steps: A command that you can call inside your terminal and change branch name.If you need more: step-by-step, How To Change Git Branch Name is a good article about that.",
                "Probably as mentioned by others, this will be a case mismatch in branch naming.If you have such a situation, I can guess that you're on Windows which will also lead you to:Then you have to do an intermediate step:Nothing more.",
                "Changing the branch locally is quite easy...If you are on the branch you want to change the name for, simply do this:Otherwise, if you are on master or any other branch other than the one you'd like to change the name, simply do:Also, I create the image below to show this in action on a command line. In this case, you are on master branch, for example:",
                "To rename the current branch (except for detached HEAD state) you can also use this alias:",
                "Since you do not want to push the branch to a remote server, this example will be useful:Let's say you have an existing branch called \"my-hot-feature,\" and you want to rename it to \"feature-15.\"First, you want to change your local branch. This couldn't be easier:For more information, you can visit Locally and Remotely Renaming a Branch in Git.",
                "If you are willing to use SourceTree (which I strongly recommend), you can right click your branch and chose 'Rename'.",
                "This will set the new name for the current branch you are working with.Here you have to provide the old branch name and the new branch name.",
                "Another option is not to use the command line at all. Git GUI clients such as SourceTree take away much of the syntactical learning curve / pain that causes questions such as this one to be amongst the most viewed on Stack Overflow.In SourceTree, right click on any local branch in the \"Branches\" pane on the left and select \"Rename ...\".",
                "A simple way to do it:For more, see this.",
                "Git version 2.9.2If you want to change the name of the local branch you are on:If you want to change the name of a different branch:If you want to change the name of a different branch to a name that already exists:Note: The last command is destructive and will rename your branch, but you will lose the old branch with that name and those commits because branch names must be unique.",
                "If you want to change the name of the current branch, run:If you want to delete the old remote branch, run:If you want to delete the old remote branch and create a new remote branch, run:",
                "Actually you have three steps because the local branch has a duplicate on the server so we have one step for local on two steps on the server:",
                "Git branch rename can be done by using:git branch -m oldBranch newBranchgit branch -M oldBranch ExistingBranchThe difference between -m and -M:-m: if you're trying to rename your branch with an existing branch name using -m.\nIt will raise an error saying that the branch already exists. You need to give unique name.But,-M: this will help you to force rename with a given name, even it is exists. So an existing branch will overwrite entirely with it...Here is a Git terminal example,",
                "All of the previous answers are talking about git branch -m. Of course, it's easy to operate, but for me, it may be a little hard to remember another Git command. So I tried to get the work done by the command I was familiar with. Yeah, you may guessed it.I use git branch -b <new_branch_name>. And if you don't want to save the old branch now you can execute git branch -D <old_branch_name> to remove it.I know it may be a little tedious, but it's easier to understand and remember. I hope it\u2018s helpful for you.",
                "For Git GUI users it couldn't be much simpler.\nIn Git GUI, choose the branch name from the drop down list in the \"Rename Branch\" dialog box created from the menu item Branch:Rename, type a New Name, and click \"Rename\". I have highlighted where to find the drop down list."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I undo 'git add' before commit?",
                "I mistakenly added files to Git using the command:\ngit add myfile.txt\n\nI have not yet run git commit. How do I undo this so that these changes will not be included in the commit?"
            ],
            "url": "https://stackoverflow.com/questions/348170",
            "answer": [
                "Undo git add for uncommitted changes with:That will remove the file from the current index (the \"about to be committed\" list) without changing anything else.To unstage all changes for all files:In old versions of Git, the above commands are equivalent to git reset HEAD <file> and git reset HEAD respectively, and will fail if HEAD is undefined (because you haven't yet made any commits in your repository) or ambiguous (because you created a branch called HEAD, which is a stupid thing that you shouldn't do). This was changed in Git 1.8.2, though, so in modern versions of Git you can use the commands above even prior to making your first commit:\"git reset\" (without options or parameters) used to error out when\nyou do not have any commits in your history, but it now gives you\nan empty index (to match non-existent commit you are not even on).Documentation: git reset",
                "You want:Reasoning:When I was new to this, I first tried(to undo my entire initial add), only to get this (not so) helpful message:It turns out that this is because the HEAD ref (branch?) doesn't exist until after the first commit. That is, you'll run into the same beginner's problem as me if your workflow, like mine, was something like:git status... lots of crap scrolls by ...=> Damn, I didn't want to add all of that.google \"undo git add\"=> find Stack Overflow - yaygit reset .=>    fatal: Failed to resolve 'HEAD' as a valid ref.It further turns out that there's a bug logged against the unhelpfulness of this in the mailing list.And that the correct solution was right there in the Git status output (which, yes, I glossed over as 'crap)And the solution indeed is to use git rm --cached FILE.Note the warnings elsewhere here - git rm deletes your local working copy of the file, but not if you use --cached.  Here's the result of git help rm:--cached\n      Use this option to unstage and remove paths only from the index.\n      Working tree files, whether modified or not, will be left.I proceed to useto remove everything and start again. Didn't work though, because while add . is recursive, turns out rm needs -r to recurse. Sigh.Okay, now I'm back to where I started. Next time I'm going to use -n to do a dry run and see what will be added:I zipped up everything to a safe place before trusting git help rm about the --cached not destroying anything (and what if I misspelled it).",
                "If you type:Git will tell you what is staged, etc., including instructions on how to unstage:I find Git does a pretty good job of nudging me to do the right thing in situations like this.Note: Recent Git versions (1.8.4.x) have changed this message:",
                "To clarify: git add moves changes from the current working directory to the staging area (index).This process is called staging. So the most natural command to stage the changes (changed files) is the obvious one:git add is just an easier-to-type alias for git stagePity there is no git unstage nor git unadd commands. The relevant one is harder to guess or remember, but it is pretty obvious:We can easily create an alias for this:And finally, we have new commands:Personally I use even shorter aliases:",
                "An addition to the accepted answer, if your mistakenly-added file was huge, you'll probably notice that, even after removing it from the index with 'git reset', it still seems to occupy space in the .git directory.This is nothing to be worried about; the file is indeed still in the repository, but only as a \"loose object\". It will not be copied to other repositories (via clone, push), and the space will be eventually reclaimed - though perhaps not very soon. If you are anxious, you can run:Update (what follows is my attempt to clear some confusion that can arise from the most upvoted answers):So, which is the real undo of git add?git reset HEAD <file> ?orgit rm --cached <file>?Strictly speaking, and if I'm not mistaken: none.git add cannot be undone - safely, in general.Let's recall first what git add <file> actually does:If <file> was not previously tracked, git add adds it to the cache, with its current content.If <file> was already tracked, git add saves the current content (snapshot, version) to the cache. In Git, this action is still called add, (not mere update it), because two different versions (snapshots) of a file are regarded as two different items: hence, we are indeed adding a new item to the cache, to be eventually committed later.In light of this, the question is slightly ambiguous:I mistakenly added files using the command...The OP's scenario seems to be the first one (untracked file),  we want the \"undo\" to remove the file (not just the current contents) from the tracked items. If this is the case, then it's ok to run  git rm --cached <file>.And we could also run git reset HEAD <file>. This is in general preferable, because it works in both scenarios: it also does the undo when we wrongly added a version of an already tracked item.But there are two caveats.First: There is (as pointed out in the answer) only one scenario in which git reset HEAD doesn't work, but git rm --cached does: a new repository (no commits). But, really, this a practically irrelevant case.Second: Be aware that git reset HEAD  can't magically recover the previously cached file contents, it just resynchronises it from the HEAD. If our misguided git add overwrote a previous staged uncommitted version, we can't recover it. That's why, strictly speaking, we cannot undo [*].Example:Of course, this is not very critical if we just follow the usual lazy workflow of doing 'git add' only for adding new files (case 1), and we update new contents via the commit, git commit -a command.* (Edit: the above is practically correct, but still there can be some slightly hackish/convoluted ways for recovering changes that were staged, but not committed and then overwritten - see the comments by Johannes Matokic and iolsmit)",
                "Undo a file which has already been added is quite easy using Git. For resetting myfile.txt, which have already been added, use:Explanation:After you staged unwanted file(s), to undo, you can do git reset. Head is head of your file in the local and the last parameter is the name of your file.I have created the steps in the image below in more details for you, including all steps which may happen in these cases:",
                "will \"un-add\" everything you've added from your current directory recursively",
                "Git has commands for every action imaginable, but it needs extensive knowledge to get things right and because of that it is counter-intuitive at best...What you did before:What you want:Remove the file from the index, but keep it versioned and left with uncommitted changes in working copy:Reset the file to the last state from HEAD, undoing changes and removing them from the index:This is needed since git reset --hard HEAD won't work with single files.Remove <file> from index and versioning, keeping the un-versioned file with changes in working copy:Remove <file> from working copy and versioning completely:",
                "Runand remove all the files manually or by selecting all of them and clicking on the unstage from commit button.",
                "The question is not clearly posed. The reason is that git add has two meanings:If in doubt, useBecause it does the expected thing in both cases.Warning: if you do git rm --cached file on a file that was modified (a file that existed before in the repository), then the file will be removed on git commit! It will still exist in your file system, but if anybody else pulls your commit, the file will be deleted from their work tree.git status will tell you if the file was a new file or modified:",
                "As per many of the other answers, you can use git resetBUT:I found this great little post that actually adds the Git command (well, an alias) for git unadd: see git unadd for details or..Simply,Now you canAlternatively / directly:",
                "will remove a file named filename.txt from the current index (also called the \u201cstaging area\u201d, which is where changes \u201cabout to be committed\u201d are saved), without changing anything else (the working directory is not overwritten).",
                "If you're on your initial commit and you can't use git reset, just declare \"Git bankruptcy\" and delete the .git folder and start over",
                "As pointed out by others in related questions (see here, here, here, here, here, here, and here), you can now unstage a single file with:and unstage all files (from the root of the repo) with:git restore was introduced in July 2019 and released in version 2.23.\nWith the --staged flag, it restores the content of the index (what is asked here).When running git status with staged uncommitted file(s), this is now what Git suggests to use to unstage file(s) (instead of git reset HEAD <file> as it used to prior to v2.23).",
                "Use git add -i to remove just-added files from your upcoming commit.  Example:Adding the file you didn't want:Going into interactive add to undo your add (the commands typed at git here are \"r\" (revert), \"1\" (first entry in the list revert shows), 'return' to drop out of revert mode, and \"q\" (quit):That's it!  Here's your proof, showing that \"foo\" is back on the untracked list:",
                "Here's a way to avoid this vexing problem when you start a new project:Git makes it really hard to do git reset if you don't have any commits.  If you create a tiny initial commit just for the sake of having one, after that you can git add -A and git reset as many times as you want in order to get everything right.Another advantage of this method is that if you run into line-ending troubles later and need to refresh all your files, it's easy:",
                "Note that if you fail to specify a revision then you have to include a separator. Example from my console:(Git version 1.7.5.4)",
                "Maybe Git has evolved since you posted your question.Now, you can try:This should be what you are looking for.",
                "To remove new files from the staging area (and only in case of a new file), as suggested above:Use rm --cached only for new files accidentally added.",
                "To reset every file in a particular folder (and its subfolders), you can use the following command:",
                "Use the * command to handle multiple files at a time:etc.",
                "Just type git reset it will revert back and it is like you never typed git add . since your last commit. Make sure you have committed before.",
                "Suppose I create a new file, newFile.txt:Suppose I add the file accidentally, git add newFile.txt:Now I want to undo this add, before commit, git reset newFile.txt:",
                "You can unstage or undo using the git command or GUI Git.Single fileMultiple filesSuppose you have added Home.js, ListItem.js, Update.js by mistake,and want to undo/reset =>The same example using Git GUIOpens a window. Uncheck your files from Staged changes (will commit)",
                "For a specific file:For all added files:Note: checkout changes the code in the files and moves to the last updated (committed) state. reset doesn't change the codes; it just resets the header.",
                "To undo git add, use:",
                "There is also interactive mode:Choose option 3 to un add files. In my case I often want to add more than one file, and with interactive mode you can use numbers like this to add files. This will take all but 4: 1, 2, 3, and 5To choose a sequence, just type 1-5 to take all from 1 to 5.Git staging files",
                "This command will unstash your changes:You can also useto add parts of files.",
                "Will remove a file named filename.txt from the current index, the \"about to be committed\" area, without changing anything else.",
                "git add myfile.txt # This will add your file into the to-be-committed listQuite opposite to this command is,so, you will be in the previous state. Specified will be again in untracked list (previous state).It will reset your head with that specified file. so, if your head doesn't have it means, it will simply reset it."
            ]
        },
        {
            "tag": "",
            "question": [
                "What is the \"-->\" operator in C++?",
                "After reading Hidden Features and Dark Corners of C++/STL on comp.lang.c++.moderated, I was completely surprised that the following snippet compiled and worked in both Visual Studio 2008 and G++ 4.4.\n..."
            ],
            "url": "https://stackoverflow.com/questions/1642028",
            "answer": [
                "--> is not an operator. It is in fact two separate operators, -- and >.The conditional's code decrements x, while returning x's original (not decremented) value, and then compares the original value with 0 using the > operator.To better understand, the statement could be written as follows:",
                "Or for something completely different... x slides to 0.Not so mathematical, but... every picture paints a thousand words...",
                "That's a very complicated operator, so even ISO/IEC JTC1 (Joint Technical Committee 1) placed its description in two different parts of the C++ Standard.Joking aside, they are two different operators: -- and > described respectively in \u00a75.2.6/2 and \u00a75.9 of the C++03 Standard.",
                "x can go to zero even faster in the opposite direction in C++:8 6 4 2You can control speed with an arrow!90 80 70 60 50 40 30 20 10;)",
                "It's equivalent tox-- (post decrement) is equivalent to x = x-1 (but returning the original value of x), so the code transforms to:",
                "It'sJust the space makes the things look funny, -- decrements and > compares.",
                "The usage of --> has historical relevance. Decrementing was (and still is in some cases), faster than incrementing on the x86 architecture. Using --> suggests that x is going to 0, and appeals to those with mathematical backgrounds.",
                "Utterly geek, but I will be using this:",
                "is how that's parsed.",
                "One book I read (I don't remember correctly which book) stated: Compilers try to parse expressions to the biggest token by using the left right rule.In this case, the expression:Parses to biggest tokens:The same rule applies to this expression:After parse:",
                "This is exactly the same as",
                "Anyway, we have a \"goes to\" operator now. \"-->\" is easy to be remembered as a direction, and \"while x goes to zero\" is meaning-straight.Furthermore, it is a little more efficient than \"for (x = 10; x > 0; x --)\" on some platforms.",
                "This code first compares x and 0 and then decrements x. (Also said in the first answer: You're post-decrementing x and then comparing x and 0 with the > operator.) See the output of this code:We now first compare and then decrement by seeing 0 in the output.If we want to first decrement and then compare, use this code:That output is:",
                "My compiler will print out 9876543210 when I run this code.As expected. The while( x-- > 0 ) actually means while( x > 0). The x-- post decrements x.is a different way of writing the same thing.It is nice that the original looks like \"while x goes to 0\" though.",
                "There is a space missing between -- and >. x is post decremented, that is, decremented after checking the condition x>0 ?.",
                "-- is the decrement operator and > is the greater-than operator.The two operators are applied as a single one like -->.",
                "It's a combination of two operators. First -- is for decrementing the value, and > is for checking whether the value is greater than the right-hand operand.The output will be:",
                "C and C++ obey the \"maximal munch\" rule. The same way a---b is translated to (a--) - b, in your case  x-->0 translates to (x--)>0.What the rule says essentially is that going left to right, expressions are formed by taking the maximum of characters which will form a valid token.",
                "Actually, x is post-decrementing and with that condition is being checked. It's not -->, it's (x--) > 0Note: value of x is changed after the condition is checked, because it post-decrementing. Some similar cases can also occur, for example:",
                "Instead of regular arrow operator (-->) you can use armor-piercing arrow operator: --x> (note those sharp barbs on the arrow tip). It adds +1 to armor piercing, so it finishes the loop 1 iteration faster than regular arrow operator. Try it yourself:",
                "For larger numbers, C++20 introduces some more advanced looping features.\nFirst to catch i we can build an inverse loop-de-loop and deflect it onto the std::ostream. However, the speed of i is implementation-defined, so we can use the new C++20 speed operator <<i<< to speed it up. We must also catch it by building wall, if we don't, i leaves the scope and de referencing it causes undefined behavior. To specify the separator, we can use:and there we have a for loop from 67 to 1.",
                "Why all the complication?The simple answer to the original question is just:It does the same thing. I am not saying you should do it like this, but it does the same thing and would have answered the question in one post.The x-- is just shorthand for the above, and > is just a normal greater-than operator. No big mystery!There are too many people making simple things complicated nowadays  ;)",
                "Conventional way we define condition in while loop parenthesis\"()\" and terminating condition inside the braces\"{}\", but this -- & > is a way one defines all at once.\nFor example:It says, decrement a and run the loop till the time a is greater than 0Other way it should have been like:Both ways, we do the same thing and achieve the same goals.",
                "(x --> 0) means (x-- > 0).Output:  9 8 7 6 5 4 3 2 1Output: 9 8 7 6 5 4 3 2 1 0Output: 9 8 7 6 5 4 3 2 1 0Output: 9 8 7 6 5 4 3 2 1 0Likewise, you can try lot of methods to execute this command successfully.",
                "This --> is not an operator at all. We have an operator like ->, but not like -->. It is just a wrong interpretation of while(x-- >0) which simply means x has the post decrement operator and this loop will run till it is greater than zero.Another simple way of writing this code would be while(x--). The  while loop will stop whenever it gets a false condition and here there is only one case, i.e., 0. So it will stop when the x value is decremented to zero.",
                "Here -- is the unary post decrement operator.",
                "--> is not an operator, it is the juxtaposition of -- (post-decrement) and > (greater than comparison).The loop will look more familiar as:This loop is a classic idiom to enumerate values between 10 (the excluded upper bound) and 0 the included lower bound, useful to iterate over the elements of an array from the last to the first.The initial value 10 is the total number of iterations (for example the length of the array), and one plus the first value used inside the loop. The 0 is the last value of x inside the loop, hence the comment x goes to 0.Note that the value of x after the loop completes is -1.Note also that this loop will operate the same way if x has an unsigned type such as size_t, which is a strong advantage over the naive alternative for (i = length-1; i >= 0; i--).For this reason, I am actually a fan of this surprising syntax: while (x --> 0). I find this idiom eye-catching and elegant, just like for (;;) vs: while (1) (which looks confusingly similar to while (l)). It also works in other languages whose syntax is inspired by C: C++, Objective-C, java, javascript, C# to name a few.",
                "That's what you mean.We heard in childhood,Stop don't, Let Go (\u0631\u0648\u06a9\u0648 \u0645\u062a\u060c \u062c\u0627\u0646\u06d2 \u062f\u0648)Where a Comma makes confusionStop, don't let go. (\u0631\u0648\u06a9\u0648\u060c \u0645\u062a \u062c\u0627\u0646\u06d2 \u062f\u0648)Same Happens in Programming now, a SPACE makes confusion. :D",
                "The operator you use is called \"decrement-and-then-test\". It is defined in the C99 standard, which is the latest version of the C programming language standard. The C99 standard added a number of new operators, including the \"decrement-and-then-test\" operator, to the C language. Many C++ compilers have adopted these new operators as extensions to the C++ language.Here is how the code without using the \"decrement-and-then-test\" operator:In this version of the code, the while loop uses the > operator to test whether x is greater than 0. The x-- statement is used to decrement x by 1 at the end of each iteration of the loop."
            ]
        },
        {
            "tag": "",
            "question": [
                "Can comments be used in JSON?",
                "Can I use comments inside a JSON file? If so, how?"
            ],
            "url": "https://stackoverflow.com/questions/244777",
            "answer": [
                "No.JSON is data-only. If you include a comment, then it must be data too.You could have a designated data element called \"_comment\" (or something) that should be ignored by apps that use the JSON data.You would probably be better having the comment in the processes that generates/receives the JSON, as they are supposed to know what the JSON data will be in advance, or at least the structure of it.But if you decided to:",
                "No, comments of the form //\u2026 or /*\u2026*/ are not allowed in JSON. This answer is based on:",
                "Include comments if you choose; strip them out with a minifier before parsing or transmitting.I just released JSON.minify() which strips out comments and whitespace from a block of JSON and makes it valid JSON that can be parsed. So, you might use it like:When I released it, I got a huge backlash of people disagreeing with even the idea of it, so I decided that I'd write a comprehensive blog post on why comments make sense in JSON. It includes this notable comment from the creator of JSON:Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser. - Douglas Crockford, 2012Hopefully that's helpful to those who disagree with why JSON.minify() could be useful.",
                "Comments were removed from JSON by design.I removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability. I know that the lack of comments makes some people sad, but it shouldn't.Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser.Source: Public statement by Douglas Crockford on G+",
                "JSON does not support comments. It was also never intended to be used for configuration files where comments would be needed.Hjson is a configuration file format for humans. Relaxed syntax, fewer mistakes, more comments.See hjson.github.io for JavaScript, Java, Python, PHP, Rust, Go, Ruby, C++ and C# libraries.",
                "DISCLAIMER: YOUR WARRANTY IS VOIDAs has been pointed out, this hack takes advantage of the implementation of the spec. Not all JSON parsers will understand this sort of JSON. Streaming parsers in particular will choke.It's an interesting curiosity, but you should really not be using it for anything at all. Below is the original answer.I've found a little hack that allows you to place comments in a JSON file that will not affect the parsing, or alter the data being represented in any way.It appears that when declaring an object literal you can specify two values with the same key, and the last one takes precedence. Believe it or not, it turns out that JSON parsers work the same way. So we can use this to create comments in the source JSON that will not be present in a parsed object representation.If we apply this technique, your commented JSON file might look like this:The above code is valid JSON. If you parse it, you'll get an object like this:Which means there is no trace of the comments, and they won't have weird side-effects.Happy hacking!",
                "Consider using YAML. It's nearly a superset of JSON (virtually all valid JSON is valid YAML) and it allows comments.",
                "You can't. At least that's my experience from a quick glance at json.org.JSON has its syntax visualized on that page. There isn't any note about comments.",
                "Comments are not an official standard, although some parsers support C++-style comments. One that I use is JsonCpp. In the examples there is this one:jsonlint does not validate this. So comments are a parser specific extension and not standard.Another parser is JSON5.An alternative to JSON TOML.A further alternative is jsonc.The latest version of nlohmann/json has optional support for ignoring comments on parsing.",
                "Here is what I found in the Google Firebase documentation that allows you to put comments in JSON:",
                "You should write a JSON schema instead. JSON schema is currently a proposed Internet draft specification. Besides documentation, the schema can also be used for validating your JSON data.Example:You can provide documentation by using the description schema attribute.",
                "If you are using Jackson as your JSON parser then this is how you enable it to allow comments:Then you can have comments like this:And you can also have comments starting with # by setting:But in general (as answered before) the specification does not allow comments.",
                "NO. JSON used to support comments but they were abused and removed from the standard.From the creator of JSON:I removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability.  I know that the lack of comments makes some people sad, but it shouldn't.  - Douglas Crockford, 2012The official JSON site is at JSON.org. JSON is defined as a standard by ECMA International. There is always a petition process to have standards revised. It is unlikely that annotations will be added to the JSON standard for several reasons.JSON by design is an easily reverse-engineered (human parsed) alternative to XML. It is simplified even to the point that annotations are unnecessary. It is not even a markup language. The goal is stability and  interoperablilty.Anyone who understands the \"has-a\" relationship of object orientation can understand any JSON structure - that is the whole point. It is just a  directed acyclic graph (DAG) with node tags (key/value pairs), which is a near universal data structure.This only annotation required might be \"//These are DAG tags\". The key names can be as informative as required, allowing arbitrary semantic arity.Any platform can parse JSON with just a few lines of code. XML requires complex OO libraries that are not viable on many platforms.Annotations would just make JSON less interoperable. There is simply nothing else to add unless what you really need is a markup language (XML), and don't care if your persisted data is easily parsed.BUT as the creator of JSON also observed, there has always been JS pipeline support for comments:Go ahead and insert all the comments you like.\nThen pipe it through JSMin before handing it to your JSON parser. - Douglas Crockford, 2012",
                "If you are using the Newtonsoft.Json library with ASP.NET to read/deserialize you can use comments in the JSON content://\"name\": \"string\"//\"id\": intor/* This is acomment example */PS: Single-line comments are only supported with 6+ versions of Newtonsoft Json.Additional note for people who can't think out of the box: I use the JSON format for basic settings in an ASP.NET web application I made. I read the file, convert it into the settings object with the Newtonsoft library and use it when necessary.I prefer writing comments about each individual setting in the JSON file itself, and I really don't care about the integrity of the JSON format as long as the library I use is OK with it.I think this is an 'easier to use/understand' way than creating a separate 'settings.README' file and explaining the settings in it.If you have a problem with this kind of usage; sorry, the genie is out of the lamp. People would find other usages for JSON format, and there is nothing you can do about it.",
                "If your text file, which is a JSON string, is going to be read by some program, how difficult would it be to strip out either C or C++ style comments before using it?Answer: It would be a one liner. If you do that then JSON files could be used as configuration files.",
                "The idea behind JSON is to provide simple data exchange between applications. These are typically web based and the language is JavaScript.It doesn't really allow for comments as such, however, passing a comment as one of the name/value pairs in the data would certainly work, although that data would obviously need to be ignored or handled specifically by the parsing code.All that said, it's not the intention that the JSON file should contain comments in the traditional sense. It should just be the data.Have a look at the JSON website for more detail.",
                "JSON does not support comments natively, but you can make your own decoder or at least preprocessor to strip out comments, that's perfectly fine (as long as you just ignore comments and don't use them to guide how your application should process the JSON data).JSON does not have comments. A JSON encoder MUST NOT output comments.\nA JSON decoder MAY accept and ignore comments.Comments should never be used to transmit anything meaningful. That is\nwhat JSON is for.Cf: Douglas Crockford, author of JSON spec.",
                "I just encountering this for configuration files. I don't want to use XML (verbose, graphically, ugly, hard to read), or \"ini\" format (no hierarchy, no real standard, etc.) or Java \"Properties\" format (like .ini).JSON can do all they can do, but it is way less verbose and more human readable - and parsers are easy and ubiquitous in many languages. It's just a tree of data. But out-of-band comments are a necessity often to document \"default\" configurations and the like. Configurations are never to be \"full documents\", but trees of saved data that can be human readable when needed.I guess one could use \"#\": \"comment\", for \"valid\" JSON.",
                "It depends on your JSON library. Json.NET supports JavaScript-style comments, /* commment */.See another Stack\u00a0Overflow question.",
                "Yes, the new standard, JSON5 allows the C++ style comments, among many other extensions:The JSON5 Data Interchange Format (JSON5) is a superset of JSON that aims to alleviate some of the limitations of JSON. It is fully backwards compatible, and using it is probably better than writing the custom non standard parser, turning non standard features on for the existing one or using various hacks like string fields for commenting. Or, if the parser in use supports, simply agree we are using JSON 5 subset that is JSON and C++ style comments. It is much better than we tweak JSON standard the way we see fit.There is already npm package, Python package, Java package and C library available. It is backwards compatible. I see no reason to stay with the \"official\" JSON restrictions.I think that removing comments from JSON has been driven by the same reasons as removing the operator overloading in Java: can be used the wrong way yet some clearly legitimate use cases were overlooked. For operator overloading, it is matrix algebra and complex numbers. For JSON comments, its is configuration files and other documents that may be written, edited or read by humans and not just by parser.",
                "JSON makes a lot of sense for config files and other local usage because it's ubiquitous and because it's much simpler than XML.If people have strong reasons against having comments in JSON when communicating data (whether valid or not), then possibly JSON could be split into two:JSON-DOC will allow comments, and other minor differences might exist such as handling whitespace. Parsers can easily convert from one spec to the other.With regards to the remark made by Douglas Crockford on this issues (referenced by @Artur Czajka)Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser.We're talking about a generic config file issue (cross language/platform), and he's answering with a JS specific utility!Sure a JSON specific minify can be implemented in any language,\nbut standardize this so it becomes ubiquitous across parsers in all languages and platforms so people stop wasting their time lacking the feature because they have good use-cases for it, looking the issue up in online forums, and getting people telling them it's a bad idea or suggesting it's easy to implement stripping comments out of text files.The other issue is interoperability. Suppose you have a library or API or any kind of subsystem which has some config or data files associated with it. And this subsystem is\nto be accessed from different languages.  Then do you go about telling people: by the way\ndon't forget to strip out the comments from the JSON files before passing them to the parser!",
                "If you use JSON5 you can include comments.JSON5 is a proposed extension to JSON that aims to make it easier for humans to write and maintain by hand. It does this by adding some minimal syntax features directly from ECMAScript\u00a05.",
                "The Dojo Toolkit JavaScript toolkit (at least as of version 1.4), allows you to include comments in your JSON. The comments can be of /* */ format. Dojo Toolkit consumes the JSON via the dojo.xhrGet() call.Other JavaScript toolkits may work similarly.This can be helpful when experimenting with alternate data structures (or even data lists) before choosing a final option.",
                "JSON is not a framed protocol. It is a language free format. So a comment's format is not defined for JSON.As many people have suggested, there are some tricks, for example, duplicate keys or a specific key _comment that you can use. It's up to you.",
                "Disclaimer: This is sillyThere is actually a way to add comments, and stay within the specification (no additional parser needed). It will not result into human-readable comments without any sort of parsing though.You could abuse the following:Insignificant whitespace is allowed before or after any token.\nWhitespace is any sequence of one or more of the following code\npoints: character tabulation (U+0009), line feed (U+000A), carriage\nreturn (U+000D), and space (U+0020).In a hacky way, you can abuse this to add a comment. For instance: start and end your comment with a tab. Encode the comment in base3 and use the other whitespace characters to represent them. For instance.(hello base three in ASCII) But instead of 0 use space, for 1 use line feed and for 2 use carriage return.This will just leave you with a lot of unreadable whitespace (unless you make an IDE plugin to encode/decode it on the fly).I never even tried this, for obvious reasons and neither should you.",
                "You can have comments in JSONP, but not in pure JSON. I've just spent an hour trying to make my program work with this example from Highcharts.If you follow the link, you will seeSince I had a similar file in my local folder, there were no issues with the Same-origin policy, so I decided to use pure JSON\u2026 and, of course, $.getJSON was failing silently because of the comments.Eventually I just sent a manual HTTP request to the address above and realized that the content-type was text/javascript since, well, JSONP returns pure JavaScript. In this case comments are allowed. But my application returned content-type application/json, so I had to remove the comments.",
                "JSON doesn't allow comments, per se. The reasoning is utterly foolish, because you can use JSON itself to create comments, which obviates the reasoning entirely, and loads the parser data space for no good reason at all for exactly the same result and potential issues, such as they are: a JSON file with comments.If you try to put comments in (using // or /* */ or # for instance), then some parsers will fail because this is strictly not\nwithin the JSON specification. So you should never do that.Here, for instance, where my image manipulation system has saved image notations and some basic formatted (comment) information relating to them (at the bottom):",
                "This is a \"can you\" question. And here is a \"yes\" answer.No, you shouldn't use duplicative object members to stuff side channel data into a JSON encoding. (See \"The names within an object SHOULD be unique\" in the RFC).And yes, you could insert comments around the JSON, which you could parse out.But if you want a way of inserting and extracting arbitrary side-channel data to a valid JSON, here is an answer. We take advantage of the non-unique representation of data in a JSON encoding. This is allowed* in section two of the RFC under \"whitespace is allowed before or after any of the six structural characters\".*The RFC only states \"whitespace is allowed before or after any of the six structural characters\", not explicitly mentioning strings, numbers, \"false\", \"true\", and \"null\". This omission is ignored in ALL implementations.First, canonicalize your JSON by minifying it:Then encode your comment in binary:Then steg your binary:Here is your output:",
                "In my case, I need to use comments for debug purposes just before the output of the JSON. So I put the debug information in the HTTP header, to avoid breaking the client:",
                "We are using strip-json-comments for our project. It supports something like:Simply npm install --save strip-json-comments to install and use it like:"
            ]
        },
        {
            "tag": "",
            "question": [
                "What and where are the stack and heap?",
                "What are the stack and heap?\nWhere are they located physically in a computer's memory?\nTo what extent are they controlled by the OS or language run-time?\nWhat is their scope?\nWhat determines their ..."
            ],
            "url": "https://stackoverflow.com/questions/79923",
            "answer": [
                "The stack is the memory set aside as scratch space for a thread of execution.  When a function is called, a block is reserved on the top of the stack for local variables and some bookkeeping data.  When that function returns, the block becomes unused and can be used the next time a function is called.  The stack is always reserved in a LIFO (last in first out) order; the most recently reserved block is always the next block to be freed.  This makes it really simple to keep track of the stack; freeing a block from the stack is nothing more than adjusting one pointer.The heap is memory set aside for dynamic allocation.  Unlike the stack, there's no enforced pattern to the allocation and deallocation of blocks from the heap; you can allocate a block at any time and free it at any time.  This makes it much more complex to keep track of which parts of the heap are allocated or free at any given time; there are many custom heap allocators available to tune heap performance for different usage patterns.Each thread gets a stack, while there's typically only one heap for the application (although it isn't uncommon to have multiple heaps for different types of allocation).To answer your questions directly:To what extent are they controlled by the OS or language runtime?The OS allocates the stack for each system-level thread when the thread is created.  Typically the OS is called by the language runtime to allocate the heap for the application.What is their scope?The stack is attached to a thread, so when the thread exits the stack is reclaimed.  The heap is typically allocated at application startup by the runtime, and is reclaimed when the application (technically process) exits.What determines the size of each of them?The size of the stack is set when a thread is created.  The size of the heap is set on application startup, but can grow as space is needed (the allocator requests more memory from the operating system).What makes one faster?The stack is faster because the access pattern makes it trivial to allocate and deallocate memory from it (a pointer/integer is simply incremented or decremented), while the heap has much more complex bookkeeping involved in an allocation or deallocation.  Also, each byte in the stack tends to be reused very frequently which means it tends to be mapped to the processor's cache, making it very fast. Another performance hit for the heap is that the heap, being mostly a global resource, typically has to be multi-threading safe, i.e. each allocation and deallocation needs to be - typically - synchronized with \"all\" other heap accesses in the program.A clear demonstration:\n\nImage source: vikashazrati.wordpress.com",
                "Stack:Heap:Example:",
                "The most important point is that heap and stack are generic terms for ways in which memory can be allocated.  They can be implemented in many different ways, and the terms apply to the basic concepts.In a stack of items, items sit one on top of the other in the order they were placed there, and you can only remove the top one (without toppling the whole thing over).The simplicity of a stack is that you do not need to maintain a table containing a record of each section of allocated memory; the only state information you need is a single pointer to the end of the stack.  To allocate and de-allocate, you just increment and decrement that single pointer.  Note: a stack can sometimes be implemented to start at the top of a section of memory and extend downwards rather than growing upwards.In a heap, there is no particular order to the way items are placed.  You can reach in and remove items in any order because there is no clear 'top' item.Heap allocation requires maintaining a full record of what memory is allocated and what isn't, as well as some overhead maintenance to reduce fragmentation, find contiguous memory segments big enough to fit the requested size, and so on.  Memory can be deallocated at any time leaving free space.  Sometimes a memory allocator will perform maintenance tasks such as defragmenting memory by moving allocated memory around, or garbage collecting - identifying at runtime when memory is no longer in scope and deallocating it.These images should do a fairly good job of describing the two ways of allocating and freeing memory in a stack and a heap.  Yum!To what extent are they controlled by the OS or language runtime?As mentioned, heap and stack are general terms, and can be implemented in many ways.  Computer programs typically have a stack called a call stack which stores information relevant to the current function such as a pointer to whichever function it was called from, and any local variables.  Because functions call other functions and then return, the stack grows and shrinks to hold information from the functions further down the call stack.  A program doesn't really have runtime control over it; it's determined by the programming language, OS and even the system architecture.A heap is a general term used for any memory that is allocated dynamically and randomly; i.e. out of order.  The memory is typically allocated by the OS, with the application calling API functions to do this allocation.  There is a fair bit of overhead required in managing dynamically allocated memory, which is usually handled by the runtime code of the programming language or environment used.What is their scope?The call stack is such a low level concept that it doesn't relate to 'scope' in the sense of programming.  If you disassemble some code you'll see relative pointer style references to portions of the stack, but as far as a higher level language is concerned, the language imposes its own rules of scope.  One important aspect of a stack, however, is that once a function returns, anything local to that function is immediately freed from the stack.  That works the way you'd expect it to work given how your programming languages work.  In a heap, it's also difficult to define.  The scope is whatever is exposed by the OS, but your programming language probably adds its rules about what a \"scope\" is in your application.  The processor architecture and the OS use virtual addressing, which the processor translates to physical addresses and there are page faults, etc.  They keep track of what pages belong to which applications.  You never really need to worry about this, though, because you just use whatever method your programming language uses to allocate and free memory, and check for errors (if the allocation/freeing fails for any reason).What determines the size of each of them?Again, it depends on the language, compiler, operating system and architecture.  A stack is usually pre-allocated, because by definition it must be contiguous memory.  The language compiler or the OS determine its size.  You don't store huge chunks of data on the stack, so it'll be big enough that it should never be fully used, except in cases of unwanted endless recursion (hence, \"stack overflow\") or other unusual programming decisions.A heap is a general term for anything that can be dynamically allocated.  Depending on which way you look at it, it is constantly changing size.  In modern processors and operating systems the exact way it works is very abstracted anyway, so you don't normally need to worry much about how it works deep down, except that (in languages where it lets you) you mustn't use memory that you haven't allocated yet or memory that you have freed.What makes one faster?The stack is faster because all free memory is always contiguous.  No list needs to be maintained of all the segments of free memory, just a single pointer to the current top of the stack.  Compilers usually store this pointer in a special, fast register for this purpose.  What's more, subsequent operations on a stack are usually concentrated within very nearby areas of memory, which at a very low level is good for optimization by the processor on-die caches.",
                "(I have moved this answer from another question that was more or less a dupe of this one.)The answer to your question is implementation specific and may vary across compilers and processor architectures. However, here is a simplified explanation.Can a function be allocated on the heap instead of a stack?No, activation records for functions (i.e. local or automatic variables) are allocated on the stack that is used not only to store these variables, but also to keep track of nested function calls.How the heap is managed is really up to the runtime environment. C uses malloc and C++ uses new, but many other languages have garbage collection.However, the stack is a more low-level feature closely tied to the processor architecture. Growing the heap when there is not enough space isn't too hard since it can be implemented in the library call that handles the heap. However, growing the stack is often impossible as the stack overflow only is discovered when it is too late; and shutting down the thread of execution is the only viable option.",
                "In the following C# codeHere's how the memory is managedLocal Variables that only need to last as long as the function invocation go in the stack. The heap is used for variables whose lifetime we don't really know up front but we expect them to last a while. In most languages it's critical that we know at compile time how large a variable is if we want to store it on the stack.Objects (which vary in size as we update them) go on the heap because we don't know at creation time how long they are going to last. In many languages the heap is garbage collected to find objects (such as the cls1 object) that no longer have any references.In Java, most objects go directly into the heap. In languages like C / C++, structs and classes can often remain on the stack when you're not dealing with pointers.More information can be found here:The difference between stack and heap memory allocation \u00ab  timmurphy.organd here:Creating Objects on the Stack and HeapThis article is the source of picture above: Six important .NET concepts: Stack, heap, value types, reference types, boxing, and unboxing - CodeProjectbut be aware it may contain some inaccuracies.",
                "The Stack\nWhen you call a function the arguments to that function plus some other overhead is put on the stack. Some info (such as where to go on return) is also stored there.\nWhen you declare a variable inside your function, that variable is also allocated on the stack.Deallocating the stack is pretty simple because you always deallocate in the reverse order in which you allocate. Stack stuff is added as you enter functions, the corresponding data is removed as you exit them. This means that you tend to stay within a small region of the stack unless you call lots of functions that call lots of other functions (or create a recursive solution).The Heap\nThe heap is a generic name for where you put the data that you create on the fly. If you don't know how many spaceships your program is going to create, you are likely to use the new (or malloc or equivalent) operator to create each spaceship. This allocation is going to stick around for a while, so it is likely we will free things in a different order than we created them.Thus, the heap is far more complex, because there end up being regions of memory that are unused interleaved with chunks that are - memory gets fragmented. Finding free memory of the size you need is a difficult problem. This is why the heap should be avoided (though it is still often used).Implementation\nImplementation of both the stack and heap is usually down to the runtime / OS. Often games and other applications that are performance critical create their own memory solutions that grab a large chunk of memory from the heap and then dish it out internally to avoid relying on the OS for memory.This is only practical if your memory usage is quite different from the norm - i.e for games where you load a level in one huge operation and can chuck the whole lot away in another huge operation.Physical location in memory\nThis is less relevant than you think because of a technology called Virtual Memory which makes your program think that you have access to a certain address where the physical data is somewhere else (even on the hard disc!). The addresses you get for the stack are in increasing order as your call tree gets deeper. The addresses for the heap are un-predictable (i.e implimentation specific) and frankly not important.",
                "Other answers just avoid explaining what static allocation means. So I will explain the three main forms of allocation and how they usually relate to the heap, stack, and data segment below. I also will show some examples in both C/C++ and Python to help people understand.\"Static\" (AKA statically allocated) variables are not allocated on the stack. Do not assume so - many people do only because \"static\" sounds a lot like \"stack\". They actually exist in neither the stack nor the heap. They are part of what's called the data segment.However, it is generally better to consider \"scope\" and \"lifetime\" rather than \"stack\" and \"heap\".Scope refers to what parts of the code can access a variable. Generally we think of local scope (can only be accessed by the current function) versus global scope (can be accessed anywhere) although scope can get much more complex.Lifetime refers to when a variable is allocated and deallocated during program execution. Usually we think of static allocation (variable will persist through the entire duration of the program, making it useful for storing the same information across several function calls) versus automatic allocation (variable only persists during a single call to a function, making it useful for storing information that is only used during your function and can be discarded once you are done) versus dynamic allocation (variables whose duration is defined at runtime, instead of compile time like static or automatic).Although most compilers and interpreters implement this behavior similarly in terms of using stacks, heaps, etc, a compiler may sometimes break these conventions if it wants as long as behavior is correct. For instance, due to optimization a local variable may only exist in a register or be removed entirely, even though most local variables exist in the stack. As has been pointed out in a few comments, you are free to implement a compiler that doesn't even use a stack or a heap, but instead some other storage mechanisms (rarely done, since stacks and heaps are great for this).I will provide some simple annotated C code to illustrate all of this. The best way to learn is to run a program under a debugger and watch the behavior. If you prefer to read python, skip to the end of the answer :)A particularly poignant example of why it's important to distinguish between lifetime and scope is that a variable can have local scope but static lifetime - for instance, \"someLocalStaticVariable\" in the code sample above. Such variables can make our common but informal naming habits very confusing. For instance when we say \"local\" we usually mean \"locally scoped automatically allocated variable\" and when we say global we usually mean \"globally scoped statically allocated variable\". Unfortunately when it comes to things like \"file scoped statically allocated variables\" many people just say... \"huh???\".Some of the syntax choices in C/C++ exacerbate this problem - for instance many people think global variables are not \"static\" because of the syntax shown below.Note that putting the keyword \"static\" in the declaration above prevents var2 from having global scope. Nevertheless, the global var1 has static allocation. This is not intuitive! For this reason, I try to never use the word \"static\" when describing scope, and instead say something like \"file\" or \"file limited\" scope. However many people use the phrase \"static\" or \"static scope\" to describe a variable that can only be accessed from one code file. In the context of lifetime, \"static\" always means the variable is allocated at program start and deallocated when program exits.Some people think of these concepts as C/C++ specific. They are not. For instance, the Python sample below illustrates all three types of allocation (there are some subtle differences possible in interpreted languages that I won't get into here).",
                "Others have answered the broad strokes pretty well, so I'll throw in a few details.Stack and heap need not be singular. A common situation in which you have more than one stack is if you have more than one thread in a process.  In this case each thread has its own stack. You can also have more than one heap, for example some DLL configurations can result in different DLLs allocating from different heaps, which is why it's generally a bad idea to release memory allocated by a different library.In C you can get the benefit of variable length allocation through the use of alloca, which allocates on the stack, as opposed to alloc, which allocates on the heap. This memory won't survive your return statement, but it's useful for a scratch buffer.Making a huge temporary buffer on Windows that you don't use much of is not free. This is because the compiler will generate a stack probe loop that is called every time your function is entered to make sure the stack exists (because Windows uses a single guard page at the end of your stack to detect when it needs to grow the stack. If you access memory more than one page off the end of the stack you will crash). Example:",
                "Others have directly answered your question, but when trying to understand the stack and the heap, I think it is helpful to consider the memory layout of a traditional UNIX process (without threads and mmap()-based allocators). The Memory Management Glossary web page has a diagram of this memory layout.The stack and heap are traditionally located at opposite ends of the process's virtual address space. The stack grows automatically when accessed, up to a size set by the kernel (which can be adjusted with setrlimit(RLIMIT_STACK, ...)). The heap grows when the memory allocator invokes the brk() or sbrk() system call, mapping more pages of physical memory into the process's virtual address space.In systems without virtual memory, such as some embedded systems, the same basic layout often applies, except the stack and heap are fixed in size. However, in other embedded systems (such as those based on Microchip PIC microcontrollers), the program stack is a separate block of memory that is not addressable by data movement instructions, and can only be modified or read indirectly through program flow instructions (call, return, etc.). Other architectures, such as Intel Itanium processors, have multiple stacks. In this sense, the stack is an element of the CPU architecture.",
                "What is a stack?A stack is a pile of objects, typically one that is neatly arranged.Stacks in computing architectures are regions of memory where data is added or removed in a last-in-first-out manner. \nIn a multi-threaded application, each thread will have its own stack.What is a heap?A heap is an untidy collection of things piled up haphazardly.In computing architectures the heap is an area of dynamically-allocated memory that is managed automatically by the operating system or the memory manager library. \nMemory on the heap is allocated, deallocated, and resized regularly during program execution, and this can lead to a problem called fragmentation. \nFragmentation occurs when memory objects are allocated with small spaces in between that are too small to hold additional memory objects. \nThe net result is a percentage of the heap space that is not usable for further memory allocations.Both togetherIn a multi-threaded application, each thread will have its own stack. But, all the different threads will share the heap. \nBecause the different threads share the heap in a multi-threaded application, this also means that there has to be some coordination between the threads so that they don\u2019t try to access and manipulate the same piece(s) of memory in the heap at the same time.Which is faster \u2013 the stack or the heap? And why?The stack is much faster than the heap. \nThis is because of the way that memory is allocated on the stack. \nAllocating memory on the stack is as simple as moving the stack pointer up.For people new to programming, it\u2019s probably a good idea to use the stack since it\u2019s easier. \nBecause the stack is small, you would want to use it when you know exactly how much memory you will need for your data, or if you know the size of your data is very small. \nIt\u2019s better to use the heap when you know that you will need a lot of memory for your data, or you just are not sure how much memory you will need (like with a dynamic array).The stack is the area of memory where local variables (including method parameters) are stored. When it comes to object variables, these are merely references (pointers) to the actual objects on the heap.\nEvery time an object is instantiated, a chunk of heap memory is set aside to hold the data (state) of that object. Since objects can contain other objects, some of this data can in fact hold references to those nested objects.",
                "The stack is a portion of memory that can be manipulated via several key assembly language instructions, such as 'pop' (remove and return a value from the stack) and 'push' (push a value to the stack), but also call (call a subroutine - this pushes the address to return to the stack) and return (return from a subroutine - this pops the address off of the stack and jumps to it).  It's the region of memory below the stack pointer register, which can be set as needed.  The stack is also used for passing arguments to subroutines, and also for preserving the values in registers before calling subroutines.The heap is a portion of memory that is given to an application by the operating system, typically through a syscall like malloc.  On modern OSes this memory is a set of pages that only the calling process has access to.The size of the stack is determined at runtime, and generally does not grow after the program launches.  In a C program, the stack needs to be large enough to hold every variable declared within each function.  The heap will grow dynamically as needed, but the OS is ultimately making the call (it will often grow the heap by more than the value requested by malloc, so that at least some future mallocs won't need to go back to the kernel to get more memory.  This behavior is often customizable)Because you've allocated the stack before launching the program, you never need to malloc before you can use the stack, so that's a slight advantage there.  In practice, it's very hard to predict what will be fast and what will be slow in modern operating systems that have virtual memory subsystems, because how the pages are implemented and where they are stored is an implementation detail.",
                "I think many other people have given you mostly correct answers on this matter.One detail that has been missed, however, is that the \"heap\" should in fact probably be called the \"free store\".  The reason for this distinction is that the original free store was implemented with a data structure known as a \"binomial heap.\"  For that reason, allocating from early implementations of malloc()/free() was allocation from a heap.  However, in this modern day, most free stores are implemented with very elaborate data structures that are not binomial heaps.",
                "You can do some interesting things with the stack.  For instance, you have functions like alloca (assuming you can get past the copious warnings concerning its use), which is a form of malloc that specifically uses the stack, not the heap, for memory.That said, stack-based memory errors are some of the worst I've experienced.  If you use heap memory, and you overstep the bounds of your allocated block, you have a decent chance of triggering a segment fault.  (Not 100%: your block may be incidentally contiguous with another that you have previously allocated.)  But since variables created on the stack are always contiguous with each other, writing out of bounds can change the value of another variable.  I have learned that whenever I feel that my program has stopped obeying the laws of logic, it is probably buffer overflow.",
                "Simply, the stack is where local variables get created. Also, every time you call a subroutine the program counter (pointer to the next machine instruction) and any important registers, and sometimes the parameters get pushed on the stack. Then any local variables inside the subroutine are pushed onto the stack (and used from there). When the subroutine finishes, that stuff all gets popped back off the stack. The PC and register data gets and put back where it was as it is popped, so your program can go on its merry way.The heap is the area of memory dynamic memory allocations are made out of (explicit \"new\" or \"allocate\" calls). It is a special data structure that can keep track of blocks of memory of varying sizes and their allocation status.In \"classic\" systems RAM was laid out such that the stack pointer started out at the bottom of memory, the heap pointer started out at the top, and they grew towards each other. If they overlap, you are out of RAM. That doesn't work with modern multi-threaded OSes though. Every thread has to have its own stack, and those can get created dynamicly.",
                "From WikiAnwser.When a function or a method calls another function which in turns calls another function, etc., the execution of all those functions remains suspended until the very last function returns its value.This chain of suspended function calls is the stack, because elements in the stack (function calls) depend on each other.The stack is important to consider in exception handling and thread executions.The heap is simply the memory used by programs to store variables.\nElement of the heap (variables) have no dependencies with each other and can always be accessed randomly at any time.",
                "StackHeap",
                "A stack is used for static memory allocation and a heap for dynamic memory allocation, both stored in the computer's RAM.The StackThe stack is a \"LIFO\" (last in, first out) data structure, that is managed and optimized by the CPU quite closely. Every time a function declares a new variable, it is \"pushed\" onto the stack. Then every time a function exits, all of the variables pushed onto the stack by that function, are freed (that is to say, they are deleted). Once a stack variable is freed, that region of memory becomes available for other stack variables.The advantage of using the stack to store variables, is that memory is managed for you. You don't have to allocate memory by hand, or free it once you don't need it any more. What's more, because the CPU organizes stack memory so efficiently, reading from and writing to stack variables is very fast.More can be found here.The HeapThe heap is a region of your computer's memory that is not managed automatically for you, and is not as tightly managed by the CPU. It is a more free-floating region of memory (and is larger). To allocate memory on the heap, you must use malloc() or calloc(), which are built-in C functions. Once you have allocated memory on the heap, you are responsible for using free() to deallocate that memory once you don't need it any more.If you fail to do this, your program will have what is known as a memory leak. That is, memory on the heap will still be set aside (and won't be available to other processes). As we will see in the debugging section, there is a tool called Valgrind that can help you detect memory leaks.Unlike the stack, the heap does not have size restrictions on variable size (apart from the obvious physical limitations of your computer). Heap memory is slightly slower to be read from and written to, because one has to use pointers to access memory on the heap. We will talk about pointers shortly.Unlike the stack, variables created on the heap are accessible by any function, anywhere in your program. Heap variables are essentially global in scope.More can be found here.Variables allocated on the stack are stored directly to the memory and access to this memory is very fast, and its allocation is dealt with when the program is compiled. When a function or a method calls another function which in turns calls another function, etc., the execution of all those functions remains suspended until the very last function returns its value. The stack is always reserved in a LIFO order, the most recently reserved block is always the next block to be freed. This makes it really simple to keep track of the stack, freeing a block from the stack is nothing more than adjusting one pointer.Variables allocated on the heap have their memory allocated at run time and accessing this memory is a bit slower, but the heap size is only limited by the size of virtual memory. Elements of the heap have no dependencies with each other and can always be accessed randomly at any time. You can allocate a block at any time and free it at any time. This makes it much more complex to keep track of which parts of the heap are allocated or free at any given time.You can use the stack if you know exactly how much data you need to allocate before compile time, and it is not too big. You can use the heap if you don't know exactly how much data you will need at runtime or if you need to allocate a lot of data.In a multi-threaded situation each thread will have its own completely independent stack, but they will share the heap. The stack is thread specific and the heap is application specific. The stack is important to consider in exception handling and thread executions.Each thread gets a stack, while there's typically only one heap for the application (although it isn't uncommon to have multiple heaps for different types of allocation).At run-time, if the application needs more heap, it can allocate memory from free memory and if the stack needs memory, it can allocate memory from free memory allocated memory for the application.Even, more detail is given here and here.Now come to your question's answers.To what extent are they controlled by the OS or language runtime?The OS allocates the stack for each system-level thread when the thread is created. Typically the OS is called by the language runtime to allocate the heap for the application.More can be found here.What is their scope?Already given in top.\"You can use the stack if you know exactly how much data you need to allocate before compile time, and it is not too big. You can use the heap if you don't know exactly how much data you will need at runtime or if you need to allocate a lot of data.\"More can be found in here.What determines the size of each of them?The size of the stack is set by OS when a thread is created. The size of the heap is set on application startup, but it can grow as space is needed (the allocator requests more memory from the operating system).What makes one faster?Stack allocation is much faster since all it really does is move the stack pointer. Using memory pools, you can get comparable performance out of heap allocation, but that comes with a slight added complexity and its own headaches.Also, stack vs. heap is not only a performance consideration; it also tells you a lot about the expected lifetime of objects.Details can be found from here.",
                "OK, simply and in short words, they mean ordered and not ordered...!Stack: In stack items, things get on the top of each-other, means gonna be faster and more efficient to be processed!...So there is always an index to point the specific item, also processing gonna be faster, there is relationship between the items as well!...Heap: No order, processing gonna be slower and values are messed up together with no specific order or index... there are random and there is no relationship between them... so execution and usage time could be vary...I also create the image below to show how they may look like:",
                "stack, heap and data of each process in virtual memory:",
                "In the 1980s, UNIX propagated like bunnies with big companies rolling their own.\nExxon had one as did dozens of brand names lost to history.\nHow memory was laid out was at the discretion of the many implementors.A typical C program was laid out flat in memory with\nan opportunity to increase by changing the brk() value.\nTypically, the HEAP was just below this brk value\nand increasing brk increased the amount of available heap.The single STACK was typically an area below HEAP which was a tract of memory\ncontaining nothing of value until the top of the next fixed block of memory.\nThis next block was often CODE which could be overwritten by stack data\nin one of the famous hacks of its era.One typical memory block was BSS (a block of zero values)\nwhich was accidentally not zeroed in one manufacturer's offering.\nAnother was DATA containing initialized values, including strings and numbers.\nA third was CODE containing CRT (C runtime), main, functions, and libraries.The advent of virtual memory in UNIX changes many of the constraints.\nThere is no objective reason why these blocks need be contiguous,\nor fixed in size, or ordered a particular way now.\nOf course, before UNIX was Multics which didn't suffer from these constraints.\nHere is a schematic showing one of the memory layouts of that era.",
                "A couple of cents: I think, it will be good to draw memory graphical and more simple:Arrows - show where grow stack and heap, process stack size have limit, defined in OS, thread stack size limits by parameters in thread create API usually. Heap usually limiting by process maximum virtual memory size, for 32 bit 2-4\u00a0GB for example.So simple way: process heap is general for process and all threads inside, using for memory allocation in common case with something like malloc().Stack is quick memory for store in common case function return pointers and variables, processed as parameters in function call, local function variables.",
                "Since some answers went nitpicking, I'm going to contribute my mite.Surprisingly, no one has mentioned that multiple (i.e. not related to the number of running OS-level threads) call stacks are to be found not only in exotic languages (PostScript) or platforms (Intel Itanium), but also in fibers, green threads and some implementations of coroutines.Fibers, green threads and coroutines are in many ways similar, which leads to much confusion.  The difference between fibers and green threads is that the former use cooperative multitasking, while the latter may feature either cooperative or preemptive one (or even both). For the distinction between fibers and coroutines, see here.In any case, the purpose of both fibers, green threads and coroutines is having multiple functions executing concurrently, but not in parallel (see this SO question for the distinction) within a single OS-level thread, transferring control back and forth from one another in an organized fashion.When using fibers, green threads or coroutines, you usually have a separate stack per function. (Technically, not just a stack but a whole context of execution is per function. Most importantly, CPU registers.) For every thread there're as many stacks as there're concurrently running functions, and the thread is switching between executing each function according to the logic of your program. When a function runs to its end, its stack is destroyed. So, the number and lifetimes of stacks are dynamic and are not determined by the number of OS-level threads!Note that I said \"usually have a separate stack per function\". There're both stackful and stackless implementations of couroutines. Most notable stackful C++ implementations are Boost.Coroutine and Microsoft PPL's async/await. (However, C++'s resumable functions (a.k.a. \"async and await\"), which were proposed to C++17, are likely to use stackless coroutines.)Fibers proposal to the C++ standard library is forthcoming. Also, there're some third-party libraries. Green threads are extremely popular in languages like Python and Ruby.",
                "I have something to share, although the major points are already covered.StackHeapInteresting note:",
                "Wow! So many answers and I don't think one of them got it right...1) Where and what are they (physically in a real computer's memory)?The stack is memory that begins as the highest memory address allocated to your program image, and it then decrease in value from there. It is reserved for called function parameters and for all temporary variables used in functions.There are two heaps: public and private.The private heap begins on a 16-byte boundary (for 64-bit programs) or a 8-byte boundary (for 32-bit programs) after the last byte of code in your program, and then increases in value from there. It is also called the default heap.If the private heap gets too large it will overlap the stack area, as will the stack overlap the heap if it gets too big. Because the stack starts at a higher address and works its way down to lower address, with proper hacking you can get make the stack so large that it will overrun the private heap area and overlap the code area. The trick then is to overlap enough of the code area that you can hook into the code. It's a little tricky to do and you risk a program crash, but it's easy and very effective.The public heap resides in it's own memory space outside of your program image space. It is this memory that will be siphoned off onto the hard disk if memory resources get scarce.2) To what extent are they controlled by the OS or language runtime?The stack is controlled by the programmer, the private heap is managed by the OS, and the public heap is not controlled by anyone because it is an OS service -- you make requests and either they are granted or denied.2b) What is their scope?They are all global to the program, but their contents can be private, public, or global.2c) What determines the size of each of them?The size of the stack and the private heap are determined by your compiler runtime options. The public heap is initialized at runtime using a size parameter.2d) What makes one faster?They are not designed to be fast, they are designed to be useful. How the programmer utilizes them determines whether they are \"fast\" or \"slow\"REF:https://norasandler.com/2019/02/18/Write-a-Compiler-10.htmlhttps://learn.microsoft.com/en-us/windows/desktop/api/heapapi/nf-heapapi-getprocessheaphttps://learn.microsoft.com/en-us/windows/desktop/api/heapapi/nf-heapapi-heapcreate",
                "A lot of answers are correct as concepts, but we must note that a stack is needed by the hardware (i.e. microprocessor) to allow calling subroutines (CALL in assembly language..). (OOP guys will call it methods)On the stack you save return addresses and call \u2192 push / ret \u2192 pop is managed directly in hardware.You can use the stack to pass parameters.. even if it is slower than using registers (would a microprocessor guru say or a good 1980s BIOS book...)Stack usage is faster as:",
                "Where and what are they (physically in a real computer's memory)?ANSWER: Both are in RAM.ASIDE:RAM is like a desk and HDDs/SSDs (permanent storage) are like bookshelves. To read anything, you must have a book open on your desk, and you can only have as many books open as fit on your desk. To get a book, you pull it from your bookshelf and open it on your desk. To return a book, you close the book on your desk and return it to its bookshelf.Stack and heap are names we give to two ways compilers store different kinds of data in the same place (i.e. in RAM).What is their scope?\nWhat determines the size of each of them?\nWhat makes one faster?ANSWER:The stack is for static (fixed size) dataa. At compile time, the compiler reads the variable types used in your code.i. It allocates a fixed amount of memory for these variables.\nii. This size of this memory cannot grow.b. The memory is contiguous (a single block), so access is sometimes faster than the heapc. An object placed on the stack that grows in memory during runtime beyond the size of the stack causes a stack overflow errorThe heap is for dynamic (changing size) dataa. The amount of memory is limited only by the amount of empty space available in RAM\ni. The amount used can grow or shrink as needed at runtimeb. Since items are allocated on the heap by finding empty space wherever it exists in RAM, data is not always in a contiguous section, which sometimes makes access slower than the stackc. Programmers manually put items on the heap with the new keyword and MUST manually deallocate this memory when they are finished using it.\ni. Code that repeatedly allocates new memory without deallocating it when it is no longer needed leads to a memory leak.ASIDE:The stack and heap were not primarily introduced to improve speed; they were introduced to handle memory overflow. The first concern regarding use of the stack vs. the heap should be whether memory overflow will occur. If an object is intended to grow in size to an unknown amount (like a linked list or an object whose members can hold an arbitrary amount of data), place it on the heap. As far as possible, use the C++ standard library (STL) containers vector, map, and list as they are memory and speed efficient and added to make your life easier (you don't need to worry about memory allocation/deallocation).After getting your code to run, if you find it is running unacceptably slow, then go back and refactor your code and see if it can be programmed more efficiently. It may turn out the problem has nothing to do with the stack or heap directly at all (e.g. use an iterative algorithm instead of a recursive one, look at I/O vs. CPU-bound tasks, perhaps add multithreading or multiprocessing).I say sometimes slower/faster above because the speed of the program might not have anything to do with items being allocated on the stack or heap.To what extent are they controlled by the OS or language run-time?ANSWER:The stack size is determined at compile time by the compiler.The heap size varies during runtime. (The heap works with the OS during runtime to allocate memory.)ASIDE:Below is a little more about control and compile-time vs. runtime operations.Each computer has a unique instruction set architecture (ISA), which are its hardware commands (e.g. \"MOVE\", \"JUMP\", \"ADD\", etc.).An OS is nothing more than a resource manager (controls how/when/ and where to use memory, processors, devices, and information).The ISA of the OS is called the bare machine and the remaining commands are called the extended machine. The kernel is the first layer of the extended machine. It controls things likeWhen we say \"compiler\", we generally mean the compiler, assembler, and linker togetherThe machine code gets passed to the kernel when executed, which determines when it should run and take control, but the machine code itself contains ISA commands for requesting files, requesting memory, etc. So the code issues ISA commands, but everything has to pass by the kernel.",
                "The stack is essentially an easy-to-access memory that simply manages its items \n  as a - well - stack. Only items for which the size is known in advance can go onto the stack. This is the case for numbers, strings, booleans.The heap is a memory for items of which you can\u2019t predetermine the\n  exact size and structure. Since objects and arrays can be mutated and\n  change at runtime, they have to go into the heap.Source: Academind",
                "CPU stack and heap are physically related to how CPU and registers works with memory, how machine-assembly language works, not high-level languages themselves, even if these languages can decide little things.All modern CPUs work with the \"same\" microprocessor theory: they are all based on what's called \"registers\" and some are for \"stack\" to gain performance. All CPUs have stack registers since the beginning and they had been always here, way of talking, as I know. Assembly languages are the same since the beginning, despite variations... up to Microsoft and its Intermediate Language (IL) that changed the paradigm to have a OO virtual machine assembly language. So we'll be able to have some CLI/CIL CPU in the future (one project of MS).CPUs have stack registers to speed up memories access, but they are limited compared to the use of others registers to get full access to all the available memory for the processus. It why we talked about stack and heap allocations.In summary, and in general, the heap is hudge and slow and is for \"global\" instances and objects content, as the stack is little and fast and for \"local\" variables and references (hidden pointers to forget to manage them).So when we use the new keyword in a method, the reference (an int) is created in the stack, but the object and all its content (value-types as well as objects) is created in the heap, if I remember. But local elementary value-types and arrays are created in the stack.The difference in memory access is at the cells referencing level: addressing the heap, the overall memory of the process, requires more complexity in terms of handling CPU registers, than the stack which is \"more\" locally in terms of addressing because the CPU stack register is used as base address, if I remember.It is why when we have very long or infinite recurse calls or loops, we got stack overflow quickly, without freezing the system on modern computers...C# Heap(ing) Vs Stack(ing) In .NETStack vs Heap: Know the DifferenceStatic class memory allocation where it is stored C#What and where are the stack and heap?https://en.wikipedia.org/wiki/Memory_managementhttps://en.wikipedia.org/wiki/Stack_registerAssembly language resources:Assembly Programming TutorialIntel\u00ae 64 and IA-32 Architectures Software Developer Manuals",
                "Thank you for a really good discussion but as a real noob I wonder where instructions are kept? In the BEGINNING scientists were deciding between two architectures (von NEUMANN where everything is considered DATA and HARVARD where an area of memory was reserved for instructions and another for data). Ultimately, we went with the von Neumann design and now everything is considered 'the same'. This made it hard for me when I was learning assembly \nhttps://www.cs.virginia.edu/~evans/cs216/guides/x86.html\nbecause they talk about registers and stack pointers.Everything above talks about DATA. My guess is that since an instruction is a defined thing with a specific memory footprint, it would go on the stack and so all 'those' registers discussed in assembly are on the stack. Of course then came object oriented programming with instructions and data comingled into a structure that was dynamic so now instructions would be kept on the heap as well?",
                "When a process is created then after loading code and data OS setup heap start just after data ends and stack to top of address space based on architectureWhen more heap is required OS will allocate dynamically and heap chunk is always virtually contiguousPlease see brk(), sbrk() and alloca() system call in linux"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I force \"git pull\" to overwrite local files?",
                "How do I force an overwrite of local files on a git pull? My local repository contains a file of the same filename as on the server.\n\nerror: Untracked working tree file 'example.txt' would be ..."
            ],
            "url": "https://stackoverflow.com/questions/1125968",
            "answer": [
                "Any uncommitted local changes to tracked files will be lost.Any local files that are not tracked by Git will not be affected.First, update all origin/<branch> refs to latest:Backup your current branch (e.g. master):Jump to the latest commit on origin/master and checkout those files:git fetch downloads the latest from remote without trying to merge or rebase anything.git reset resets the master branch to what you just fetched. The --hard option changes all the files in your working tree to match the files in origin/master.[*]: It's worth noting that it is possible to maintain current local commits by creating a branch from master before resetting:After this, all of the old commits will be kept in new-branch-to-save-current-commits.Uncommitted changes, however (even staged), will be lost. Make sure to stash and commit anything you need. For that you can run the following:And then to reapply these uncommitted changes:",
                "This will remove all uncommitted changes and then pull:",
                "WARNING: git clean deletes all your untracked files/directories and can't be undone.Sometimes just clean -f does not help. In case you have untracked DIRECTORIES, -d option also needed:WARNING: git clean deletes all your untracked files/directories and can't be undone.Consider using -n (--dry-run) flag first. This will show you what will be deleted without actually deleting anything:Example output:",
                "Like Hedgehog I think the answers are terrible. But though Hedgehog's answer might be better, I don't think it is as elegant as it could be.  The way I found to do this is by using fetch and merge with a defined strategy. Which should make it so that your local changes are preserved as long as they are not one of the files that you are trying to force an overwrite with.-X is an option name, and theirs is the value for that option. You're choosing to use their changes (the other option is ours changes) if there is a conflict.",
                "Instead of doing:I'd advise doing the following:No need to fetch all remotes and branches if you're going to reset to the origin/master branch right?",
                "It looks like the best way is to first do:To delete all untracked files and then continue with the usual git pull...",
                "Warning, doing this will permanently delete your files if you have any directory/* entries in your gitignore file.Some answers seem to be terrible. Terrible in the sense of what happened to @Lauri by following David Avsajanishvili suggestion.Rather (git > v1.7.6):Later you can clean the stash history.Manually, one-by-one:Brutally, all-at-once:Of course if you want to go back to what you stashed:",
                "You might find this command helpful to throw away local changes:And then do a cleanup (removes untracked files from the working tree):If you want to remove untracked directories in addition to untracked files:",
                "Instead of merging with git pull, try this:git fetch --allfollowed by:git reset --hard origin/master.",
                "The only thing that worked for me was:This will take you back five commits and then withI found that by looking up how to undo a Git merge.",
                "The problem with all these solutions is that they are all either too complex or, an even bigger problem, is that they remove all untracked files from the webserver, which we don't want since there are always needed configuration files which are on the server and not in the Git repository.Here is the cleanest solution which we are using:The first command fetches the newest data.The second command checks if there are any files that are being added to the repository and deletes those untracked files from the local repository which would cause conflicts.The third command checks-out all the files which were locally modified.Finally, we do a pull to update to the newest version, but this time without any conflicts, since untracked files which are in the repo don't exist anymore and all the locally modified files are already the same as in the repository.",
                "First of all, try the standard way:Warning: Above commands can results in data/files loss only if you don't have them committed! If you're not sure, make the backup first of your whole repository folder.Then pull it again.If above won't help and you don't care about your untracked files/directories (make the backup first just in case), try the following simple steps:This will REMOVE all git files (excempt .git/ dir, where you have all commits) and pull it again.Why git reset HEAD --hard could fail in some cases?Custom rules in .gitattributes fileHaving eol=lf rule in .gitattributes could cause git to modify some file changes by converting CRLF line-endings into LF in some text files.If that's the case, you've to commit these CRLF/LF changes (by reviewing them in git status), or try: git config core.autcrlf false to temporary ignore them.File system incompabilityWhen you're using file-system which doesn't support permission attributes.\nIn example you have two repositories, one on Linux/Mac (ext3/hfs+) and another one on FAT32/NTFS based file-system.As you notice, there are two different kind of file systems, so the one which doesn't support Unix permissions basically can't reset file permissions on system which doesn't support that kind of permissions, so no matter how --hard you try, git always detect some \"changes\".",
                "I had the same problem. No one gave me this solution, but it worked for me.I solved it by:Now it works.",
                "In speaking of pull/fetch/merge in the previous answers, I would like to share an interesting and productive trick,This above command is the most useful command in my Git life which saved a lot of time.Before pushing your newly commit to server, try this command and it will automatically synchronise the latest server changes (with a fetch + merge) and will place your commit at the top in the Git log. There isn't any need to worry about manual pull/merge.Find details in What does \"git pull --rebase\" do?.",
                "Here is a generic solution if you do not always want to paste the branch name or you want to automate this within a scriptIf you want to reset your local changes too:You also could add a bash alias using this command:",
                "I had a similar problem.  I had to do this:",
                "I summarized other answers. You can execute git pull without errors:Warning: This script is very powerful, so you could lose your changes.",
                "Based on my own similar experiences, the solution offered by Strahinja Kustudic above is by far the best.  As others have pointed out, simply doing hard reset will remove all the untracked files which could include lots of things that you don't want removed, such as config files.  What is safer, is to remove only the files that are about to be added, and for that matter, you'd likely also want to checkout any locally-modified files that are about to be updated.That in mind, I updated Kustudic's script to do just that.  I also fixed a typo (a missing ' in the original).",
                "I had the same problem and for some reason, even a git clean -f -d would not do it. Here is why: For some reason, if your file is ignored by Git (via a .gitignore entry, I assume), it still bothers about overwriting this with a later pull, but a clean will not remove it, unless you add -x.",
                "I believe there are two possible causes of conflict, which must be solved separately, and as far as I can tell none of the above answers deals with both:Local files that are untracked need to be deleted, either manually (safer) or as suggested in other answers, by git clean -f -dLocal commits that are not on the remote branch need to be deleted as well. IMO the easiest way to achieve this is with: git reset --hard origin/master (replace 'master' by whatever branch you are working on, and run a git fetch origin first)",
                "It seems like most answers here are focused on the master branch; however, there are times when I'm working on the same feature branch in two different places and I want a rebase in one to be reflected in the other without a lot of jumping through hoops.Based on a combination of RNA's answer and torek's answer to a similar question, I've come up with this which works splendidly:Run this from a branch and it'll only reset your local branch to the upstream version.This can be nicely put into a git alias (git forcepull) as well:git config alias.forcepull \"!git fetch ; git reset --hard @{u}\"Or, in your .gitconfig file:Enjoy!",
                "An easier way would be to:This will override your local file with the file on git",
                "I just solved this myself by:where the last command gives a list of what your local changes were. Keep modifying the \"tmp\" branch until it is acceptable and then merge back onto master with:For next time, you can probably handle this in a cleaner way by looking up \"git stash branch\" though stash is likely to cause you trouble on the first few tries, so do first experiment on a non-critical project...",
                "I have a strange situation that neither git clean or git reset works. I have to remove the conflicting file from git index by using the following script on every untracked file:Then I am able to pull just fine.",
                "I know of a much easier and less painful method:That's it!",
                "I am not sure why anyone did not talk about FETCH_HEAD yet.If you want to put it in an alias, the command would be:",
                "Requirements:Solution:Fetch with a clean of files and directories ignoring .gitignore and hard reset to origin.",
                "Just doSo you avoid all unwanted side effects, like deleting files or directories you wanted to keep, etc.",
                "Despite the original question, the top answers can cause problems for people who have a similar problem, but don't want to lose their local files. For example, see Al-Punk and crizCraig's comments.The following version commits your local changes to a temporary branch (tmp), checks out the original branch (which I'm assuming is master) and merges the updates. You could do this with stash, but I've found it's usually easier to simply use the branch / merge approach.where we assume the other repository is origin master.",
                "Reset the index and the head to origin/master, but do not reset the working tree:"
            ]
        },
        {
            "tag": "",
            "question": [
                "Why does HTML think \u201cchucknorris\u201d is a color?",
                "Why do certain random strings produce colors when entered as background colors in HTML?\nFor example, bgcolor=\"chucknorris\" produces a red background:\n\r\n\r\n<body bgcolor=\"chucknorris\"> ..."
            ],
            "url": "https://stackoverflow.com/questions/8318911",
            "answer": [
                "It\u2019s a holdover from the Netscape days:Missing digits are treated as 0[...]. An incorrect digit is simply interpreted as 0. For example the values #F0F0F0, F0F0F0, F0F0F, #FxFxFx and FxFxFx are all the same.It is from the blog post A little rant about Microsoft Internet Explorer's color parsing which covers it in great detail, including varying lengths of color values, etc.If we apply the rules in turn from the blog post, we get the following:Replace all nonvalid hexadecimal characters with 0\u2019s:Pad out to the next total number of characters divisible by\u00a03 (11\u00a0\u2192 12):Split into three equal groups, with each component representing the corresponding colour component of an RGB colour:Truncate each of the arguments from the right down to two characters.Which, finally, gives the following result:Here\u2019s an example demonstrating the bgcolor attribute in action, to produce this \u201camazing\u201d colour swatch:<table>\n  <tr>\n    <td bgcolor=\"chucknorris\" cellpadding=\"8\" width=\"100\" align=\"center\">chuck norris</td>\n    <td bgcolor=\"mrt\"         cellpadding=\"8\" width=\"100\" align=\"center\" style=\"color:#ffffff\">Mr T</td>\n    <td bgcolor=\"ninjaturtle\" cellpadding=\"8\" width=\"100\" align=\"center\" style=\"color:#ffffff\">ninjaturtle</td>\n  </tr>\n  <tr>\n    <td bgcolor=\"sick\"  cellpadding=\"8\" width=\"100\" align=\"center\">sick</td>\n    <td bgcolor=\"crap\"  cellpadding=\"8\" width=\"100\" align=\"center\">crap</td>\n    <td bgcolor=\"grass\" cellpadding=\"8\" width=\"100\" align=\"center\">grass</td>\n  </tr>\n</table>This also answers the other part of the question: Why does bgcolor=\"chucknorr\" produce a yellow colour? Well, if we apply the rules, the string is:Which gives a light yellow gold colour. As the string starts off as 9\u00a0characters, we keep the second\u00a0\u2018C\u2019 this time around, hence it ends up in the final colour value.I originally encountered this when someone pointed out that you could do color=\"crap\" and, well, it comes out brown.",
                "I'm sorry to disagree, but according to the rules for parsing a legacy color value posted by Yuhong Bao, chucknorris does not equate to #CC0000, but rather to #C00000, a very similar but slightly different hue of red. I used the Firefox ColorZilla add-on to verify this.The rules state:I was able to use these rules to correctly interpret the following strings:The original answerers who said the color was #CC0000 have since edited their answers to include the correction.",
                "The reason is the browser can not understand it and try to somehow translate it to what it can understand and in this case into a hexadecimal value!...chucknorris starts with c which is recognised character in hexadecimal, also it's converting all unrecognised characters into 0!So chucknorris in hexadecimal format becomes: c00c00000000, all other characters become 0 and c remains where they are...Now they get divided by 3 for RGB(red, green, blue)... R: c00c, G: 0000, B:0000...But we know valid hexadecimal for RGB is just 2 characters, means R: c0, G: 00, B:00So the real result is:I also added the steps in the image as a quick reference for you:",
                "Most browsers will simply ignore any non-hexadecimal values in your color string, substituting non-hexadecimal digits with zeros.ChuCknorris translates to c00c0000000.  At this point, the browser will divide the string into three equal sections, indicating Red, Green and Blue values: c00c 0000 0000.  Extra bits in each section will be ignored, which makes the final result #c00000 which is a reddish color.Note, this does not apply to CSS color parsing, which follow the CSS standard.<p><font color='chucknorris'>Redish</font></p>\n<p><font color='#c00000'>Same as above</font></p>\n<p><span style=\"color: chucknorris\">Black</span></p>",
                "The browser is trying to convert chucknorris into hexadecimal colour code, because it\u2019s not a valid value.This seems to be an issue primarily with Internet\u00a0Explorer and Opera\u00a0(12) as both Chrome\u00a0(31) and Firefox\u00a0(26) just ignore this.P.S. The numbers in brackets are the browser versions I tested on.Similarly, Rajnikanth (Indian Chuck Noris) converse to a shade of black:0a00 00a0 0000 => #0a0000On a lighter noteChuck Norris doesn\u2019t conform to web standards. Web standards conform\nto him. #BADA55",
                "The WHATWG HTML specification has the exact algorithm for parsing a legacy color value.The code Netscape Classic used for parsing color strings is open source: netscape/lib/layout/layimage.c.For example, notice that each character is parsed as a hex digit and then is shifted into a 32-bit integer without checking for overflow. Only eight hex digits fit into a 32-bit integer, which is why only the last 8 characters are considered. After parsing the hex digits into 32-bit integers, they are then truncated into 8-bit integers by dividing them by 16 until they fit into 8-bit, which is why leading zeros are ignored.This code does not exactly match what is defined in the spec, but the only difference there is a few lines of code. I think it is these lines that were added (in Netscape 4):",
                "chucknorris starts with c, and the browser reads it into a hexadecimal value.Because A, B, C, D, E, and F are characters in hexadecimal.The browser converts chucknorris to a hexadecimal value, C00C00000000.Then the C00C00000000 hexadecimal value is converted to RGB format (divided by 3):C00C00000000\u00a0\u21d2 R:C00C, G:0000, B:0000The browser needs only two digits to indicate the colour:R:C00C, G:0000, B:0000\u00a0\u21d2 R:C0, G:00, B:00\u00a0\u21d2 C00000Finally, show bgcolor = C00000 in the web browser.Here's an example demonstrating it:<table>\n  <tr>\n    <td bgcolor=\"chucknorris\" cellpadding=\"10\" width=\"150\" align=\"center\">chucknorris</td>\n    <td bgcolor=\"c00c00000000\" cellpadding=\"10\" width=\"150\" align=\"center\">c00c00000000</td>\n    <td bgcolor=\"c00000\" cellpadding=\"10\" width=\"150\" align=\"center\">c00000</td>\n  </tr>\n</table>",
                "The rules for parsing colors on legacy attributes involves additional steps than those mentioned in existing answers. The truncate component to 2 digits part is described as:Some examples:Below is a partial implementation of the algorithm. It does not handle errors or cases where the user enters a valid color.function parseColor(input) {\r\n  // todo: return error if input is \"\"\r\n  input = input.trim();\r\n  // todo: return error if input is \"transparent\"\r\n  // todo: return corresponding #rrggbb if input is a named color\r\n  // todo: return #rrggbb if input matches #rgb\r\n  // todo: replace unicode code points greater than U+FFFF with 00\r\n  if (input.length > 128) {\r\n    input = input.slice(0, 128);\r\n  }\r\n  if (input.charAt(0) === \"#\") {\r\n    input = input.slice(1);\r\n  }\r\n  input = input.replace(/[^0-9A-Fa-f]/g, \"0\");\r\n  while (input.length === 0 || input.length % 3 > 0) {\r\n    input += \"0\";\r\n  }\r\n  var r = input.slice(0, input.length / 3);\r\n  var g = input.slice(input.length / 3, input.length * 2 / 3);\r\n  var b = input.slice(input.length * 2 / 3);\r\n  if (r.length > 8) {\r\n    r = r.slice(-8);\r\n    g = g.slice(-8);\r\n    b = b.slice(-8);\r\n  }\r\n  while (r.length > 2 && r.charAt(0) === \"0\" && g.charAt(0) === \"0\" && b.charAt(0) === \"0\") {\r\n    r = r.slice(1);\r\n    g = g.slice(1);\r\n    b = b.slice(1);\r\n  }\r\n  if (r.length > 2) {\r\n    r = r.slice(0, 2);\r\n    g = g.slice(0, 2);\r\n    b = b.slice(0, 2);\r\n  }\r\n  return \"#\" + r.padStart(2, \"0\") + g.padStart(2, \"0\") + b.padStart(2, \"0\");\r\n}\r\n\r\n$(function() {\r\n  $(\"#input\").on(\"change\", function() {\r\n    var input = $(this).val();\r\n    var color = parseColor(input);\r\n    var $cells = $(\"#result tbody td\");\r\n    $cells.eq(0).attr(\"bgcolor\", input);\r\n    $cells.eq(1).attr(\"bgcolor\", color);\r\n\r\n    var color1 = $cells.eq(0).css(\"background-color\");\r\n    var color2 = $cells.eq(1).css(\"background-color\");\r\n    $cells.eq(2).empty().append(\"bgcolor: \" + input, \"<br>\", \"getComputedStyle: \" + color1);\r\n    $cells.eq(3).empty().append(\"bgcolor: \" + color, \"<br>\", \"getComputedStyle: \" + color2);\r\n  });\r\n});\nbody { font: medium monospace; }\r\ninput { width: 20em; }\r\ntable { table-layout: fixed; width: 100%; }\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js\"></script>\r\n\r\n<p><input id=\"input\" placeholder=\"Enter color e.g. chucknorris\"></p>\r\n<table id=\"result\">\r\n  <thead>\r\n    <tr>\r\n      <th>Left Color</th>\r\n      <th>Right Color</th>\r\n    </tr>\r\n  </thead>\r\n  <tbody>\r\n    <tr>\r\n      <td>&nbsp;</td>\r\n      <td>&nbsp;</td>\r\n    </tr>\r\n    <tr>\r\n      <td>&nbsp;</td>\r\n      <td>&nbsp;</td>\r\n    </tr>\r\n  </tbody>\r\n</table>"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I check if an element is hidden in jQuery?",
                "How do I toggle the visibility of an element using  .hide(), .show(), or .toggle()?\nHow do I test if an element is visible or hidden?"
            ],
            "url": "https://stackoverflow.com/questions/178325",
            "answer": [
                "Since the question refers to a single element, this code might be more suitable:It is the same as twernt's suggestion, but applied to a single element; and it matches the algorithm recommended in the jQuery FAQ.We use jQuery's is() to check the selected element with another element, selector or any jQuery object. This method traverses along the DOM elements to find a match, which satisfies the passed parameter. It will return true if there is a match, otherwise return false.",
                "You can use the hidden selector:And the visible selector:",
                "The above method does not consider the visibility of the parent. To consider the parent as well, you should use .is(\":hidden\") or .is(\":visible\").For example,The above method will consider div2 visible while :visible not. But the above might be useful in many cases, especially when you need to find if there is any error divs visible in the hidden parent because in such conditions :visible will not work.",
                "None of these answers address what I understand to be the question, which is what I was searching for, \"How do I handle items that have visibility: hidden?\". Neither :visible nor :hidden will handle this, as they are both looking for display per the documentation.  As far as I could determine, there is no selector to handle CSS visibility.  Here is how I resolved it (standard jQuery selectors, there may be a more condensed syntax):",
                "From How do I determine the state of a toggled element?You can determine whether an element is collapsed or not by using the :visible and :hidden selectors.If you're simply acting on an element based on its visibility, you can just include :visible or :hidden in the selector expression. For example:",
                "Often when checking if something is visible or not, you are going to go right ahead immediately and do something else with it. jQuery chaining makes this easy.So if you have a selector and you want to perform some action on it only if is visible or hidden, you can use filter(\":visible\") or filter(\":hidden\") followed by chaining it with the action you want to take.So instead of an if statement, like this:Or more efficient, but even uglier:You can do it all in one line:",
                "The :visible selector according to the jQuery documentation:Elements with visibility: hidden or opacity: 0 are considered to be visible, since they still consume space in the layout.This is useful in some cases and useless in others, because if you want to check if the element is visible (display != none), ignoring the parents visibility, you will find that doing .css(\"display\") == 'none' is not only faster, but will also return the visibility check correctly.If you want to check visibility instead of display, you should use: .css(\"visibility\") == \"hidden\".Also take into consideration the additional jQuery notes:Because :visible is a jQuery extension and not part of the CSS specification, queries using :visible cannot take advantage of the performance boost provided by the native DOM querySelectorAll() method. To achieve the best performance when using :visible to select elements, first select the elements using a pure CSS selector, then use .filter(\":visible\").Also, if you are concerned about performance, you should check Now you see me\u2026 show/hide performance (2010-05-04). And use other methods to show and hide elements.",
                "How element visibility and jQuery works;An element could be hidden with display:none, visibility:hidden or opacity:0. The difference between those methods:opacity:0 hides the element as \"visibility:hidden\", and it still takes up space in the layout; the only difference is that opacity lets one to make an element partly transparent;Useful jQuery toggle methods:",
                "This works for me, and I am using show() and hide() to make my div hidden/visible:",
                "You can also do this using plain JavaScript:Notes:Works everywhereWorks for nested elementsWorks for CSS and inline stylesDoesn't require a framework",
                "I would use CSS class .hide { display: none!important; }.For hiding/showing, I call .addClass(\"hide\")/.removeClass(\"hide\"). For checking visibility, I use .hasClass(\"hide\").It's a simple and clear way to check/hide/show elements, if you don't plan to use .toggle() or .animate() methods.",
                "Demo Link$('#clickme').click(function() {\n  $('#book').toggle('slow', function() {\n    // Animation complete.\n    alert($('#book').is(\":visible\")); //<--- TRUE if Visible False if Hidden\n  });\n});\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<div id=\"clickme\">\n  Click here\n</div>\n<img id=\"book\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/87/Google_Chrome_icon_%282011%29.png\" alt=\"\" width=\"300\"/>Source (from my blog):Blogger Plug n Play - jQuery Tools and Widgets: How to See if Element is hidden or Visible Using jQuery",
                "ebdiv should be set to style=\"display:none;\". It works for both show and hide:",
                "One can simply use the hidden or visible attribute, like:Or you can simplify the same with is as follows.",
                "Another answer you should put into consideration is if you are hiding an element, you should use jQuery, but instead of actually hiding it, you remove the whole element, but you copy its HTML content and the tag itself into a jQuery variable, and then all you need to do is test if there is such a tag on the screen, using the normal if (!$('#thetagname').length).",
                "When testing an element against :hidden selector in jQuery it should be considered that an absolute positioned element may be recognized as hidden although their child elements are visible.This seems somewhat counter-intuitive in the first place \u2013 though having a closer look at the jQuery documentation gives the relevant information:Elements can be considered hidden for several reasons: [...] Their width and height are explicitly set to 0. [...]So this actually makes sense in regards to the box-model and the computed style for the element. Even if width and height are not set explicitly to 0 they may be set implicitly.Have a look at the following example:console.log($('.foo').is(':hidden')); // true\r\nconsole.log($('.bar').is(':hidden')); // false\n.foo {\r\n  position: absolute;\r\n  left: 10px;\r\n  top: 10px;\r\n  background: #ff0000;\r\n}\r\n\r\n.bar {\r\n  position: absolute;\r\n  left: 10px;\r\n  top: 10px;\r\n  width: 20px;\r\n  height: 20px;\r\n  background: #0000ff;\r\n}\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\r\n<div class=\"foo\">\r\n  <div class=\"bar\"></div>\r\n</div>Update for jQuery 3.x:With jQuery 3 the described behavior will change! Elements will be considered visible if they have any layout boxes, including those of zero width and/or height.JSFiddle with jQuery 3.0.0-alpha1:http://jsfiddle.net/pM2q3/7/The same JavaScript code will then have this output:",
                "$(document).ready(function() {\n  if ($(\"#checkme:hidden\").length) {\n    console.log('Hidden');\n  }\n});\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\n<div id=\"checkme\" class=\"product\" style=\"display:none\">\n  <span class=\"itemlist\"><!-- Shows Results for Fish --></span> Category:Fish\n  <br>Product: Salmon Atlantic\n  <br>Specie: Salmo salar\n  <br>Form: Steaks\n</div>",
                "To check if it is not visible I use !:Or the following is also the sam, saving the jQuery selector in a variable to have better performance when you need it multiple times:",
                "Using classes designated for \"hiding\" elements is easy and also one of the most efficient methods. Toggling a class 'hidden' with a Display style of 'none' will perform faster than editing that style directly. I explained some of this pretty thoroughly in Stack Overflow question Turning two elements visible/hidden in the same div.Here is a truly enlightening video of a Google Tech Talk by Google front-end engineer Nicholas Zakas:",
                "After all, none of examples suits me, so I wrote my own.Tests (no support of Internet\u00a0Explorer filter:alpha):a) Check if the document is not hiddenb) Check if an element has zero width / height / opacity or display:none / visibility:hidden in inline stylesc) Check if the center (also because it is faster than testing every pixel / corner) of element is not hidden by other element (and all ancestors, example: overflow:hidden / scroll / one element over another) or screen edgesd) Check if an element has zero width / height / opacity or display:none / visibility:hidden in computed styles (among all ancestors)Tested onAndroid 4.4 (Native browser/Chrome/Firefox), Firefox (Windows/Mac), Chrome (Windows/Mac), Opera (Windows Presto/Mac WebKit), Internet\u00a0Explorer (Internet\u00a0Explorer 5-11 document modes + Internet\u00a0Explorer 8 on a virtual machine), and Safari (Windows/Mac/iOS).How to use:",
                "Example of using the visible check for adblocker is activated:$(document).ready(function(){\r\n  if(!$(\"#ablockercheck\").is(\":visible\"))\r\n    $(\"#ablockermsg\").text(\"Please disable adblocker.\").show();\r\n});\n<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js\"></script>\r\n<div class=\"ad-placement\" id=\"ablockercheck\"></div>\r\n<div id=\"ablockermsg\" style=\"display: none\"></div>\"ablockercheck\" is a ID which adblocker blocks. So checking it if it is visible you are able to detect if adblocker is turned On.",
                "You need to check both... Display as well as visibility:If we check for $(this).is(\":visible\"), jQuery checks for both the things automatically.",
                "$(document).ready(function() {\n   var visible = $('#tElement').is(':visible');\n\n   if(visible) {\n      alert(\"visible\");\n                    // Code\n   }\n   else\n   {\n      alert(\"hidden\");\n   }\n});\n<script src=\"https://code.jquery.com/jquery-1.10.2.js\"></script>\n\n<input type=\"text\" id=\"tElement\" style=\"display:block;\">Firstname</input>",
                "Simply check visibility by checking for a boolean value, like:I used this code for each function. Otherwise you can use is(':visible') for checking the visibility of an element.",
                "Because Elements with visibility: hidden or opacity: 0 are considered visible, since they still consume space in the layout (as described for jQuery :visible Selector) - we can check if element is really visible in this way:",
                "But what if the element's CSS is like the following?So this answer to Stack Overflow question How to check if an element is off-screen should also be considered.",
                "A function can be created in order to check for visibility/display attributes in order to gauge whether the element is shown in the UI or not.Working Fiddle",
                "Also here's a ternary conditional expression to check the state of the element and then to toggle it:"
            ]
        },
        {
            "tag": "",
            "question": [
                "What does \"use strict\" do in JavaScript, and what is the reasoning behind it?",
                "Recently, I ran some of my JavaScript code through Crockford's JSLint, and it gave the following error:\n\nProblem at line 1 character 1: Missing \"use strict\" statement.\n\nDoing some searching, ..."
            ],
            "url": "https://stackoverflow.com/questions/1335851",
            "answer": [
                "Inside native ECMAScript modules (with import and export statements) and ES6 classes, strict mode is always enabled and cannot be disabled.This article about Javascript Strict Mode might interest you: John Resig - ECMAScript 5 Strict Mode, JSON, and MoreTo quote some interesting parts:Strict Mode is a new feature in ECMAScript 5 that allows you to place a program, or a function, in a \"strict\" operating context. This strict context prevents certain actions from being taken and throws more exceptions.And:Strict mode helps out in a couple ways:Also note you can apply \"strict mode\" to the whole file... Or you can use it only for a specific function (still quoting from John Resig's article):Which might be helpful if you have to mix old and new code ;-)So, I suppose it's a bit like the \"use strict\" you can use in Perl (hence the name?): it helps you make fewer errors, by detecting more things that could lead to breakages.Strict mode is now supported by all major browsers.",
                "It's a new feature of ECMAScript 5. John Resig wrote up a nice summary of it.It's just a string you put in your JavaScript files (either at the top of your file or inside of a function) that looks like this:Putting it in your code now shouldn't cause any problems with current browsers as it's just a string. It may cause problems with your code in the future if your code violates the pragma.  For instance, if you currently have foo = \"bar\" without defining foo first, your code will start failing...which is a good thing in my opinion.",
                "The statement \"use strict\";  instructs the browser to use the Strict mode, which is a reduced and safer feature set of JavaScript.Disallows global variables. (Catches missing var declarations and typos in variable names)Silent failing assignments will throw error in strict mode (assigning NaN = 5;)Attempts to delete undeletable properties will throw (delete Object.prototype)Requires all property names in an object literal to be unique (var x = {x1: \"1\", x1: \"2\"})Function parameter names must be unique (function sum (x, x) {...})Forbids octal syntax (var x = 023; some devs assume wrongly that a preceding zero does nothing to change the number.)Forbids the with keywordeval in strict mode does not introduce new variablesForbids deleting plain names (delete x;)Forbids binding or assignment of the names eval and arguments in any formStrict mode does not alias properties of the arguments object with the formal parameters. (e.g. in function sum (a,b) { return arguments[0] + b;} This works because arguments[0] is bound to a and so on. ) (See examples section below to understand the difference)arguments.callee is not supported[Ref: Strict mode, Mozilla Developer Network]Examples:",
                "If people are worried about using use strict it might be worth checking out this article:ECMAScript 5 'Strict mode' support in browsers. What does this mean?\nNovoGeek.com - Krishna's weblogIt talks about browser support, but more importantly how to deal with it safely:",
                "A word of caution, all you hard-charging programmers:  applying \"use strict\" to existing code can be hazardous!  This thing is not some feel-good, happy-face sticker that you can slap on the code to make it 'better'.  With the \"use strict\" pragma, the browser will suddenly THROW exceptions in random places that it never threw before just because at that spot you are doing something that default/loose JavaScript happily allows but strict JavaScript abhors!  You may have strictness violations hiding in seldom used calls in your code that will only throw an exception when they do eventually get run - say, in the production environment that your paying customers use!If you are going to take the plunge, it is a good idea to apply \"use strict\" alongside comprehensive unit tests and a strictly configured JSHint build task that will give you some confidence that there is no dark corner of your module that will blow up horribly just because you've turned on Strict Mode.  Or, hey, here's another option:  just don't add \"use strict\" to any of your legacy code, it's probably safer that way, honestly.  DEFINITELY DO NOT add \"use strict\" to any modules you do not own or maintain, like third party modules.I think even though it is a deadly caged animal, \"use strict\" can be good stuff, but you have to do it right.  The best time to go strict is when your project is greenfield and you are starting from scratch. Configure JSHint/JSLint with all the warnings and options cranked up as tight as your team can stomach, get a good build/test/assert system du jour rigged like Grunt+Karma+Chai, and only THEN start marking all your new modules as \"use strict\".  Be prepared to cure lots of niggly errors and warnings.  Make sure everyone understands the gravity by configuring the build to FAIL if JSHint/JSLint produces any violations.My project was not a greenfield project when I adopted \"use strict\".  As a result, my IDE is full of red marks because I don't have \"use strict\" on half my modules, and JSHint complains about that.  It's a reminder to me about what refactoring I should do in the future.  My goal is to be red mark free due to all of my missing \"use strict\" statements, but that is years away now.",
                "The JavaScript strict mode is a feature in ECMAScript 5. You can enable the strict mode by declaring this in the top of your script/function.When a JavaScript engine sees this directive, it will start to interpret the code in a special mode. In this mode, errors are thrown up when certain coding practices that could end up being potential bugs are detected (which is the reasoning behind the strict mode).Consider this example:In their obsession to line up the numeric literals, the developer has inadvertently initialized variable b with an octal literal. Non-strict mode will interpret this as a numeric literal with value 24 (in base 10). However, strict mode will throw an error.For a non-exhaustive list of specialties in strict mode, see this answer.In my new JavaScript application: Absolutely! Strict mode can be used as a whistleblower when you are doing something stupid with your code.In my existing JavaScript code: Probably not! If your existing JavaScript code has statements that are prohibited in strict-mode, the application will simply break. If you want strict mode, you should be prepared to debug and correct your existing code. This is why using 'use strict'; does not suddenly make your code better.Insert a 'use strict'; statement on top of your script:Note that everything in the file myscript.js will be interpreted in strict mode.Or, insert a 'use strict'; statement on top of your function body:Everything in the lexical scope of function doSomething will be interpreted in strict mode. The word lexical scope is important here. For example, if your strict code calls a function of a library that is not strict, only your code is executed in strict mode, and not the called function. See this answer for a better explanation.I found a nice article describing several things that are prohibited in strict mode (note that this is not an exhaustive list):Historically, JavaScript has been confused about how functions\nare scoped. Sometimes they seem to be statically scoped, but some\nfeatures make them behave like they are dynamically scoped. This is\nconfusing, making programs difficult to read and understand.\nMisunderstanding causes bugs. It also is a problem for performance.\nStatic scoping would permit variable binding to happen at compile\ntime, but the requirement for dynamic scope means the binding must be\ndeferred to runtime, which comes with a significant performance\npenalty.Strict mode requires that all variable binding be done statically.\nThat means that the features that previously required dynamic binding\nmust be eliminated or modified. Specifically, the with statement is\neliminated, and the eval function\u2019s ability to tamper with the\nenvironment of its caller is severely restricted.One of the benefits of strict code is that tools like YUI Compressor\ncan do a better job when processing it.JavaScript has implied global variables. If\nyou do not explicitly declare a variable, a global variable is\nimplicitly declared for you. This makes programming easier for\nbeginners because they can neglect some of their basic housekeeping\nchores. But it makes the management of larger programs much more\ndifficult and it significantly degrades reliability. So in strict\nmode, implied global variables are no longer created. You should\nexplicitly declare all of your variables.There are a number of situations that could cause this\nto be bound to the global object. For example, if you forget to\nprovide the new prefix when calling a constructor function, the\nconstructor's this will be bound unexpectedly to the global object, so\ninstead of initializing a new object, it will instead be silently\ntampering with global variables. In these situations, strict mode will\ninstead bind this to undefined, which will cause the constructor to\nthrow an exception instead, allowing the error to be detected much\nsooner.JavaScript has always had read-only properties, but you\ncould not create them yourself until ES5\u2019s Object.createProperty\nfunction exposed that capability. If you attempted to assign a value\nto a read-only property, it would fail silently. The assignment would\nnot change the property\u2019s value, but your program would proceed as\nthough it had. This is an integrity hazard that can cause programs to\ngo into an inconsistent state. In strict mode, attempting to change a\nread-only property will throw an exception.The octal (or base 8) representation of numbers was extremely\nuseful when doing machine-level programming on machines whose word\nsizes were a multiple of 3. You needed octal when working with the CDC\n6600 mainframe, which had a word size of 60 bits. If you could read\noctal, you could look at a word as 20 digits. Two digits represented\nthe op code, and one digit identified one of 8 registers. During the\nslow transition from machine codes to high level languages, it was\nthought to be useful to provide octal forms in programming languages.In C, an extremely unfortunate representation of octalness was\nselected: Leading zero. So in C, 0100 means 64, not 100, and 08 is an\nerror, not 8. Even more unfortunately, this anachronism has been\ncopied into nearly all modern languages, including JavaScript, where\nit is only used to create errors. It has no other purpose. So in\nstrict mode, octal forms are no longer allowed.The arguments pseudo array becomes a little bit more\narray-like in ES5. In strict mode, it loses its callee and caller\nproperties. This makes it possible to pass your arguments to untrusted\ncode without giving up a lot of confidential context. Also, the\narguments property of functions is eliminated.In strict mode, duplicate keys in a function literal will produce a\nsyntax error. A function can\u2019t have two parameters with the same name.\nA function can\u2019t have a variable with the same name as one of its\nparameters. A function can\u2019t delete its own variables. An attempt to\ndelete a non-configurable property now throws an exception. Primitive\nvalues are not implicitly wrapped.ECMAScript 5 adds a list of reserved words. If you use them as variables or arguments, strict mode will throw an error. The reserved words are:implements, interface, let, package, private, protected, public, static, and yield",
                "I strongly recommend every developer to start using strict mode now. There are enough browsers supporting it that strict mode will legitimately help save us from errors we didn\u2019t even know were in your code.Apparently, at the initial stage there will be errors we have never encountered before. To get the full benefit, we need to do proper testing after switching to strict mode to make sure we have caught everything. Definitely we don\u2019t just throw use strict in our code and assume there are no errors. So the churn is that it\u2019s time to start using this incredibly useful language feature to write better code.For example,JSLint is a debugger written by Douglas Crockford. Simply paste in your script, and it\u2019ll quickly scan for any noticeable issues and errors in your code.",
                "I would like to offer a somewhat more founded answer complementing the other answers. I was hoping to edit the most popular answer, but failed. I tried to make it as comprehensive and complete as I could.You can refer to the MDN documentation for more information.\"use strict\" a directive introduced in ECMAScript 5.Directives are similar to statements, yet different.The use strict directive indicates that the following code (in a script or a function) is strict code.\nThe code in the highest level of a script (code that is not in a function) is considered strict code when the script contains a use strict directive.\nThe content of a function is considered strict code when the function itself is defined in a strict code or when the function contains a use strict directive.\nCode that is passed to an eval() method is considered strict code when eval() was called from a strict code or contains the use strict directive itself.The strict mode of ECMAScript 5 is a restricted subset of the JavaScript language, which eliminates relevant deficits of the language and features more stringent error checking and higher security. The following lists the differences between strict mode and normal mode (of which the first three are particularly important):Also when a function is invoked with call() or apply in strict mode, then this is exactly the value of the first argument of the call()or apply() invocation. (In normal mode null and undefined are replaced by the global Object and values, which are not objects, are cast into objects.)In strict mode you will get a TypeError, when you try to assign to readonly properties or to define new properties for a non extensible object. (In normal mode both simply fail without error message.)In strict mode, when passing code to eval(), you cannot declare or define variables or functions in the scope of the caller (as you can do it in normal mode). Instead, a new scope is created for eval() and the variables and functions are within that scope. That scope is destroyed after eval() finishes execution.In strict mode the arguments-object of a function contains a static copy of the values, which are passed to that function. In normal mode the arguments-object has a somewhat \"magical\" behaviour: The elements of the array and the named function parameters reference both the same value.In strict mode you will get a SyntaxError when the delete operator is followed by a non qualified identifier (a variable, function or function parameter). In normal mode the delete expression would do nothing and is evaluated to false.In strict mode you will get a TypeError when you try to delete a non configurable property. (In normal mode the attempt simply fails and the delete expression is evaluated to false).In strict mode it is considered a syntactical error when you try to define several properties with the same name for an object literal. (In normal mode there is no error.)In strict mode it is considered a syntactical error when a function declaration has multiple parameters with the same name. (In normal mode there is no error.)In strict mode octal literals are not allowed (these are literals that start with 0. (In normal mode some implementations do allow octal literals.)In strict mode the identifiers eval and arguments are treated like keywords. You cannot change their value, cannot assign a value to them, and you cannot use them as names for variables, functions, function parameters or identifiers of a catch block.In strict mode are more restrictions on the possibilities to examine the call stack. arguments.caller and arguments.callee cause a TypeError in a function in strict mode. Furthermore, some caller- and arguments properties of functions in strict mode cause a TypeError when you try to read them.",
                "My two cents:One of the goals of strict mode is to allow for faster debugging of issues. It helps the developers by throwing exception when certain wrong things occur that can cause silent & strange behaviour of your webpage. The moment we use  use strict, the code will throw out errors which helps developer to fix it in advance.Few important things which I have learned after using  use strict :Prevents Global Variable Declaration:\"use strict\";\nvar tree1Data = { name: 'Banana Tree',age: 100,leafCount: 100000};\n\nfunction Tree(typeOfTree) {\n    var age;\n    var leafCount;\n\n    age = typeOfTree.age;\n    leafCount = typeOfTree.leafCount;\n    nameoftree = typeOfTree.name;\n};\n\nvar tree1 = new Tree(tree1Data);\nconsole.log(window);Now,this code creates nameoftree in global scope which could be accessed using window.nameoftree. When we implement use strict the code would throw error.Uncaught ReferenceError: nameoftree is not definedEliminates with statement :with statements can't be minified using tools like uglify-js. They're also deprecated and removed from future JavaScript versions.Sample:\"use strict\";\nvar tree1Data = {\n    name: 'Banana Tree',\n    age: 100,\n    leafCount: 100000\n};\n\nfunction Tree(typeOfTree) {\n    var age;\n    var leafCount;\n\n    age = typeOfTree.age;\n    leafCount = typeOfTree.leafCount;\n   // nameoftree = typeOfTree.name;\n\n    for (var i = 0; i < 2; ++i) {\n       // let(leafCount = i) { /*do something*/ }\n    }\n    for (var i = 0; i < 2; ++i) {\n        with(leafCount = i) { /*do something*/ }\n    }\n};\n\nvar tree1 = new Tree(tree1Data);\nconsole.log(window);Prevents Duplicates :When we have duplicate property, it throws an exceptionUncaught SyntaxError: Duplicate data property in object literal not\nallowed in strict mode\"use strict\";\nvar tree1Data = {\n    name: 'Banana Tree',\n    age: 100,\n    leafCount: 100000,\n    name:'Banana Tree'\n};There are few more but I need to gain more knowledge on that.",
                "If you use a browser released in the last year or so then it most likely supports JavaScript Strict mode. Only older browsers around before ECMAScript 5 became the current standard don't support it.The quotes around the command make sure that the code will still work in older browsers as well (although the things that generate a syntax error in strict mode will generally just cause the script to malfunction in some hard to detect way in those older browsers).",
                "When adding \"use strict\";, the following cases will throw a SyntaxError before the script is executing:Paving the way for future ECMAScript versions, using one of the newly reserved keywords (in prevision for ECMAScript 6): implements, interface, let, package, private, protected, public, static, and yield.Declaring function in blocksOctal syntaxthis point to the global object.Declaring twice the same name for a property name in an object literalThis is no longer the case in ECMAScript 6 (bug 1041128).Declaring two function arguments with the same name functionSetting a value to an undeclared variableUsing delete on a variable name delete myVariable;Using eval or arguments as variable or function argument nameSources:Transitioning to strict mode on MDNStrict mode on MDNJavaScript\u2019s Strict Mode and Why You Should Use It on Colin J. Ihrig's blog (archived version)",
                "Strict mode makes several changes to normal JavaScript semantics:eliminates some JavaScript silent errors by changing them\nto throw errors.fixes mistakes that make it difficult for JavaScript\nengines to perform optimizations.prohibits some syntax likely to be defined in future\nversions of ECMAScript.for more information vistit Strict Mode- Javascript",
                "\"Use Strict\"; is an insurance that programmer will not use the loose or the bad properties of JavaScript. It is a guide, just like a ruler will help you make straight lines. \"Use Strict\" will help you do \"Straight coding\".Those that prefer not to use rulers to do their lines straight usually end up in those pages asking for others to debug their code.Believe me. The overhead is negligible compared to poorly designed code. Doug Crockford, who has been a senior JavaScript developer for several years, has a very interesting post here. Personally, I like to return to his site all the time to make sure I don't forget my good practice.Modern JavaScript practice should always evoke the \"Use Strict\"; pragma. The only reason that the ECMA Group has made the \"Strict\" mode optional is to permit less experienced coders access to JavaScript and give then time to adapt to the new and safer coding practices.",
                "Including use strict in the beginning of your all sensitive JavaScript files from this point is a small way to be a better JavaScript programmer and avoid random variables becoming global and things change silently.",
                "Quoting from w3schools:The \"use strict\" directive is new in JavaScript 1.8.5 (ECMAScript\n  version 5).It is not a statement, but a literal expression, ignored by earlier\n  versions of JavaScript.The purpose of \"use strict\" is to indicate that the code should be\n  executed in \"strict mode\".With strict mode, you can not, for example, use undeclared variables.Strict mode makes it easier to write \"secure\" JavaScript.Strict mode changes previously accepted \"bad syntax\" into real errors.As an example, in normal JavaScript, mistyping a variable name creates\n  a new global variable. In strict mode, this will throw an error,\n  making it impossible to accidentally create a global variable.In normal JavaScript, a developer will not receive any error feedback\n  assigning values to non-writable properties.In strict mode, any assignment to a non-writable property, a\n  getter-only property, a non-existing property, a non-existing\n  variable, or a non-existing object, will throw an error.Please refer to http://www.w3schools.com/js/js_strict.asp to know more",
                "\"use strict\" makes JavaScript code to run in strict mode, which basically means everything needs to be defined before use. The main reason for using strict mode is to avoid accidental global uses of undefined methods.Also in strict mode, things run faster, some warnings or silent warnings throw fatal errors, it's better to always use it to make a neater code.\"use strict\" is widely needed to be used in ECMA5, in ECMA6 it's part of JavaScript by default, so it doesn't need to be added if you're using ES6.Look at these statements and examples from MDN:The \"use strict\" Directive The \"use strict\" directive is new in\n  JavaScript 1.8.5 (ECMAScript version 5). It is not a statement, but a\n  literal expression, ignored by earlier versions of JavaScript. The\n  purpose of \"use strict\" is to indicate that the code should be\n  executed in \"strict mode\". With strict mode, you can not, for example,\n  use undeclared variables.Examples of using \"use strict\":\n  Strict mode for functions: Likewise, to invoke strict mode for a\n  function, put the exact statement \"use strict\"; (or 'use strict';) in\n  the function's body before any other statements.1) strict mode in functions2) whole-script strict mode3) Assignment to a non-writable globalYou can read more on MDN.",
                "There's a good talk by some people who were on the ECMAScript committee: Changes to JavaScript, Part 1: ECMAScript 5\" about how incremental use of the \"use strict\" switch allows JavaScript implementers to clean up a lot of the dangerous features of JavaScript without suddenly breaking every website in the world.Of course it also talks about just what a lot of those misfeatures are (were) and how ECMAScript 5 fixes them.",
                "Small examples to compare:Non-strict mode:for (i of [1,2,3]) console.log(i)\r\n    \r\n// output:\r\n// 1\r\n// 2\r\n// 3Strict mode:'use strict';\r\nfor (i of [1,2,3]) console.log(i)\r\n\r\n// output:\r\n// Uncaught ReferenceError: i is not definedNon-strict mode:String.prototype.test = function () {\r\n  console.log(typeof this === 'string');\r\n};\r\n\r\n'a'.test();\r\n\r\n// output\r\n// falseString.prototype.test = function () {\r\n  'use strict';\r\n  \r\n  console.log(typeof this === 'string');\r\n};\r\n\r\n'a'.test();\r\n\r\n// output\r\n// true",
                "Note that use strict was introduced in EcmaScript 5 and was kept since then.Below are the conditions to trigger strict mode in ES6 and ES7:",
                "The main reasons why developers should use \"use strict\" are:Prevents accidental declaration of global variables.Using \"use strict()\" will make sure that variables are declared with var before use. \nEg:The string \"arguments\" cannot be used as a variable:Will restrict uses of keywords as variables. Trying to use them will throw errors.In short will make your code less error prone and in turn will make you write good code.To read more about it you can refer here.",
                "use strict is a way to make your code safer, because you can't use dangerous features that can work not as you expect. And, as was written before, it makes code more strict.",
                "JavaScript \u201cstrict\u201d mode was introduced in ECMAScript 5.Writing \"use strict\"; at the very top of your JS file turns on strict\nsyntax checking. It does the following tasks for us:shows an error if you try to assign to an undeclared variablestops you from overwriting key JS system librariesforbids some unsafe or error-prone language featuresuse strict also works inside of individual functions. It is always a better practice to include use strict in your code.Browser compatibility issue: \nThe \"use\" directives are meant to be backwards-compatible. Browsers that do not support them will just see a string literal that isn't referenced further. So, they will pass over it and move on.",
                "\"use strict\"; is the ECMA effort to make JavaScript a little bit more robust. It brings in JS an attempt to make it at least a little \"strict\" (other languages implement strict rules since the 90s). It actually \"forces\" JavaScript developers to follow some sort of coding best practices.\nStill, JavaScript is very fragile. There is no such thing as typed variables, typed methods, etc.\nI strongly recommend JavaScript developers to learn a more robust language such as Java or ActionScript3, and implement the same best practices in your JavaScript code, it will work better and be easier to debug.",
                "Normally, JavaScript does not follow strict rules, hence increasing chances of errors. After using \"use strict\", the JavaScript code should follow strict set of rules as in other programming languages such as use of terminators, declaration before initialization, etc.If \"use strict\" is used, the code should be written by following a strict set of rules, hence decreasing the chances of errors and ambiguities.",
                "Use Strict is used to show common and repeated errors so that it is handled differently , and changes the way java script runs , such changes are :Prevents accidental globalsNo duplicatesEliminates withEliminates this coercionSafer eval()Errors for immutablesyou can also read this article for the details",
                "\"use strict\"; Defines that JavaScript code should be executed in\n   \"strict mode\".All modern browsers support \"use strict\" except Internet Explorer 9 and lower.DisadvantageIf a developer used a library that was in strict mode, but the developer was used to working in normal mode, they might call some actions on the library that wouldn\u2019t work as expected.Worse, since the developer is in normal mode, they don\u2019t have the advantages of extra errors being thrown, so the error might fail silently.Also, as listed above, strict mode stops you from doing certain things.People generally think that you shouldn\u2019t use those things in the first place, but some developers don\u2019t like the constraint and want to use all the features of the language.For basic example and for reference go through :https://www.tutorialsteacher.com/javascript/javascript-strict",
                "JavaScript was designed and implemented hastily because of the browser wars and bad management. As a result many poor design decisions, un-intuitive syntax and confusing semantics found their way into the language. Strict mode aims to amend some of these mistakes.But fixing these mistakes without creating alternative interpretation breaks backward compatibility. So, \"use strict\" directive creates that alternative interpretation of the code while communicating it to the programmer.For example, this keywords refers to the object in a method definition, like this or self in other languages.this has no purpose outside the method context but all JavaScript functions have this keyword whether they are methods or not:Here this resolves to the global object which does not make sense and serves no purpose because global object is already available in the scope.In strict mode this in a global function resolves to undefined, which is what we expect.Some mistakes can not be fixed even in strict mode because syntax should be valid for older browsers since they ignore \"strict mode\" directive. This is by design.",
                "Strict mode can prevent memory leaks.Please check the function below written in non-strict mode:In this function, we are using a variable called name inside the function. Internally, the compiler will first check if there is any variable declared with that particular name in that particular function scope. Since the compiler understood that there is no such variable, it will check in the outer scope. In our case, it is the global scope. Again, the compiler understood that there is also no variable declared in the global space with that name, so it creates such a variable for us in the global space. Conceptually, this variable will be created in the global scope and will be available in the entire application.Another scenario is that, say, the variable is declared in a child function. In that case, the compiler checks the validity of that variable in the outer scope, i.e., the parent function. Only then it will check in the global space and create a variable for us there.\nThat means additional checks need to be done. This will affect the performance of the application.Now let's write the same function in strict mode.We will get the following error.Here, the compiler throws the reference error. In strict mode, the compiler does not allow us to use the variable without declaring it. So memory leaks can be prevented. In addition, we can write more optimized code.",
                "Strict mode eliminates errors that would be ignored in non-strict mode, thus making javascript \u201cmore secured\u201d.Is it considered among best practices?Yes, It's considered part of the best practices while working with javascript to include Strict mode. This is done by adding the below line of code in your JS file.'use strict';in your code.What does it mean to user agents?Indicating that code should be interpreted in strict mode specifies to user agents like browsers that they should treat code literally as written, and throw an error if the code doesn't make sense.For example: Consider in your .js file you have the following code:Scenario 1: [NO STRICT MODE]Scenario 2: [NO STRICT MODE]So why does the variable name is being printed in both cases?Without strict mode turned on, user agents often go through a series of modifications to problematic code in an attempt to get it to make sense. On the surface, this can seem like a fine thing, and indeed, working outside of strict mode makes it possible for people to get their feet wet with JavaScript code without having all the details quite nailed down. However, as a developer, I don't want to leave a bug in my code, because I know it could come back and bite me later on, and I also just want to write good code. And that's where strict mode helps out.Scenario 3: [STRICT MODE]Additional tip: To maintain code quality using strict mode, you don't need to write this over and again especially if you have multiple .js file. You can enforce this rule globally in eslint rules as follows:Filename: .eslintrc.jsOkay, so what is prevented in strict mode?Using a variable without declaring it will throw an error in strict mode. This is to prevent unintentionally creating global variables throughout your application. The example with printing Chicago covers this in particular.Deleting a variable or a function or an argument is a no-no in strict mode.Duplicating a parameter name is not allowed in strict mode.Reserved words in the Javascript language are not allowed in strict mode. The words are implements interface, let, packages, private, protected, public. static, and yieldFor a more comprehensive list check out the MDN documentation here: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Strict_mode",
                "strict mode enables strict features in the v8 engine. Short example of some features:You can enable it globally by writing:Per function you just include in function:es6 features are enabled (this is browser dependent), for node v4+ this is important.Performance, in some cases, is better.There are more features as well, check here for more!"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I check out a remote Git branch?",
                "Somebody pushed a branch called test with git push origin test to a shared repository. I can see the branch with git branch -r. How do I check out the remote test branch? I've tried:\n\ngit checkout ..."
            ],
            "url": "https://stackoverflow.com/questions/1783405",
            "answer": [
                "The answer has been split depending on whether there is one remote repository configured or multiple. The reason for this is that for the single remote case, some of the commands can be simplified as there is less ambiguity.Updated for Git 2.23: For older versions, see the section at the end.In both cases, start by fetching from the remote repository to make sure you have all the latest changes downloaded.This will fetch all of the remote branches for you. You can see the branches available for checkout with:The branches that start with remotes/* can be thought of as read only copies of the remote branches. To work on a branch you need to create a local branch from it. This is done with the Git command switch (since Git 2.23) by giving it the name of the remote branch (minus the remote name):In this case Git is guessing (can be disabled with --no-guess) that you are trying to checkout and track the remote branch with the same name.In the case where multiple remote repositories exist, the remote repository needs to be explicitly named.As before, start by fetching the latest remote changes:This will fetch all of the remote branches for you. You can see the branches available for checkout with:With the remote branches in hand, you now need to check out the branch you are interested in with -c to create a new local branch:For more information about using git switch:I also created the image below for you to share the differences, look at how to fetch works, and also how it's different to pull:git switch was added in Git 2.23, prior to this git checkout was used to switch branches.To checkout out with only a single remote repository:if there there are multiple remote repositories configured it becomes a bit longer",
                "Sidenote: With modern Git (>= 1.6.6), you are able to use just(note that it is 'test' not 'origin/test') to perform magical DWIM-mery and create local branch 'test' for you, for which upstream would be remote-tracking branch 'origin/test'.The * (no branch) in git branch output means that you are on unnamed branch, in so called \"detached HEAD\" state (HEAD points directly to commit, and is not symbolic reference to some local branch).  If you made some commits on this unnamed branch, you can always create local branch off current commit:A more modern approach as suggested in the comments:@Dennis: git checkout <non-branch>, for example git checkout origin/test results in detached HEAD / unnamed branch, while git checkout test or git checkout -b test origin/test results in local\nbranch test (with remote-tracking branch origin/test as upstream) \u2013\nJakub Nar\u0119bski Jan 9 '14 at 8:17emphasis on git checkout origin/test",
                "In this case, you probably want to create a local test branch which is tracking the remote test branch:In earlier versions of git, you needed an explicit --track option, but that is the default now when you are branching off a remote branch.To create the local branch and switch to it, use:",
                "While the first and selected answer is technically correct, there's the possibility you have not yet retrieved all objects and refs from the remote repository. If that is the case, you'll receive the following error:fatal: git checkout: updating paths is incompatible with switching branches.\n  Did you intend to checkout 'origin/remote_branch' which can not be resolved as commit?If you receive this message, you must first do a git fetch origin where origin is the name of the remote repository prior to running git checkout remote_branch. Here's a full example with responses:As you can see, running git fetch origin retrieved any remote branches we were not yet setup to track on our local machine. From there, since we now have a ref to the remote branch, we can simply run git checkout remote_branch and we'll gain the benefits of remote tracking.",
                "I tried the above solution, but it didn't work. Try this, it works:This will fetch the remote branch and create a new local branch (if not exists already) with name local_branch_name and track the remote one in it.",
                "This will DWIM for a remote not named origin (documentation):To add a new remote, you will need to do the following first:The first tells Git the remote exists, the second gets the commits.",
                "Use:Other answers do not work with modern Git in my benign case. You might need to pull first if the remote branch is new, but I haven't checked that case.",
                "You basically see the branch, but you don't have a local copy yet!...You need to fetch the branch...You can simply fetch and then checkout to the branch, use the one line command below to do that:I also created the image below for you to share the differences, look at how fetch works and also how it's different to pull:",
                "To clone a Git repository, do:The above command checks out all of the branches, but only the master branch will be initialized. If you want to checkout the other branches, do:This command checks out the remote branch, and your local branch name will be same as the remote branch.If you want to override your local branch name on checkout:Now your local branch name is enhancement, but your remote branch name is future_branch.",
                "You can tryor",
                "I was stuck in a situation seeing error: pathspec 'desired-branch' did not match any file(s) known to git. for all of the suggestions above. I'm on Git version 1.8.3.1.So this worked for me:The explanation behind is that I've noticed that when fetching the remote branch, it was fetched to FETCH_HEAD:",
                "I always do:git fetch origin && git checkout --track origin/branch_name",
                "First, you need to do:git fetch # If you don't know about branch nameSecond, you can check out remote branch into your local by:-b will create new branch in specified name from your selected remote branch.",
                "I use the following command:",
                "Commandsare equal toand thenBoth will create a latest fixes_for_dev from development",
                "Simply run git checkout with the name of the remote branch. Git will automatically create a local branch that tracks the remote one:However, if that branch name is found in more than one remote, this won't work as Git doesn't know which to use. In that case you can use either:orIn 2.19, Git learned the checkout.defaultRemote configuration, which specifies a remote to default to when resolving such an ambiguity.",
                "The git remote show <origin name> command will list all branches (including un-tracked branches). Then you can find the remote branch name that you need to fetch.Example:Use these steps to fetch remote branches:Example:",
                "If the branch is on something other than the origin remote I like to do the following:This will checkout the next branch on the upstream remote in to a local branch called second/next. Which means if you already have a local branch named next it will not conflict.",
                "None of these answers worked for me. This worked:",
                "git fetch && git checkout your-branch-name",
                "git branch -r says the object name is invalid, because that branch name isn't in Git's local branch list. Update your local branch list from origin with:And then try checking out your remote branch again.This worked for me.I believe git fetch pulls in all remote branches, which is not what the original poster wanted.",
                "Fetch from the remote and checkout the branch.E.g.:git fetch origin && git checkout feature/XYZ-1234-Add-alerts",
                "Other guys and gals give the solutions, but maybe I can tell you why.git checkout test which does nothingDoes nothing doesn't equal doesn't work, so I guess when you type 'git checkout test' in your terminal and press enter key, no message appears and no error occurs. Am I right?If the answer is 'yes', I can tell you the cause.The cause is that there is a file (or folder) named 'test' in your work tree.When git checkout xxx parsed,",
                "To get newly created branchesTo switch into another branch",
                "git checkout -b \"Branch_name\" [ B means Create local branch]git branch --allgit checkout -b \"Your Branch name\"git branchgit pull origin \"Your Branch name\"successfully checkout from the master branch to dev branch",
                "There are many alternatives, for example:Alternative 1:It's the simplest way.Alternative 2:It's the same, but in two steps.",
                "TL;DRUsing git switch rather than git checkout. More details are on this page.I think the answer is obsolete. Git split some functions of checkout to switch and restore now.The following is my summary:If you want to update something for a remote branch, you should create a local branch to \"track\" the remote branch. You can update anything you want in local and finally push to remote. If you check out to the remote branch directly after cloning your repository, you may see the \"detached HEAD\" status and the following message from Git:So how can we create a local branch to track a remote branch?To create a local branch to track a remote branch, you can use git checkout <remote branch name> or git switch <remote branch name>. If you have a file or folder has same name as your remote branch name, git checkout would output some error message, but git switch can work normally!Example:See all branches, and we want to create a local branch to track the remote branch remotes/origin/asd, and we also have the file name asd:The filename is same as remote branch, and Git should output some error messages if we are using the git checkout command to create a local branch to track a remote branchIt works if we are using git switch!",
                "I used that one:",
                "To get all remote branches, use this:Then check out to the branch:",
                "For us, it seems the remote.origin.fetch configuration gave a problem. Therefore, we could not see any other remote branches than master, so git fetch [--all] did not help. Neither git checkout mybranch nor git checkout -b mybranch --track origin/mybranch did work, although it certainly was at remote.The previous configuration only allowed master to be fetched:Fix it by using * and fetch the new information from origin:Now we could git checkout the remote branch locally.I don't have any idea how this configuration ended up in our local repository."
            ]
        },
        {
            "tag": "",
            "question": [
                "What does if __name__ == \"__main__\": do?",
                "What does this do, and why should one include the if statement?\nif __name__ == \"__main__\":\n    print(\"Hello, World!\")\r\nIf you are trying to close a question where someone should be ..."
            ],
            "url": "https://stackoverflow.com/questions/419163",
            "answer": [
                "It's boilerplate code that protects users from accidentally invoking the script when they didn't intend to. Here are some common problems when the guard is omitted from a script:If you import the guardless script in another script (e.g. import my_script_without_a_name_eq_main_guard), then the latter script will trigger the former to run at import time and using the second script's command line arguments. This is almost always a mistake.If you have a custom class in the guardless script and save it to a pickle file, then unpickling it in another script will trigger an import of the guardless script, with the same problems outlined in the previous bullet.To better understand why and how this matters, we need to take a step back to understand how Python initializes scripts and how this interacts with its module import mechanism.Whenever the Python interpreter reads a source file, it does two things:it sets a few special variables like __name__, and thenit executes all of the code found in the file.Let's see how this works and how it relates to your question about the __name__ checks we always see in Python scripts.Let's use a slightly different code sample to explore how imports and scripts work.  Suppose the following is in a file called foo.py.When the Python interpreter reads a source file, it first defines a few special variables. In this case, we care about the __name__ variable.When Your Module Is the Main ProgramIf you are running your module (the source file) as the main program, e.g.the interpreter will assign the hard-coded string \"__main__\" to the __name__ variable, i.e.When Your Module Is Imported By AnotherOn the other hand, suppose some other module is the main program and it imports your module. This means there's a statement like this in the main program, or in some other module the main program imports:The interpreter will search for your foo.py file (along with searching for a few other variants), and prior to executing that module, it will assign the name \"foo\" from the import statement to the __name__ variable, i.e.After the special variables are set up, the interpreter executes all the code in the module, one statement at a time. You may want to open another window on the side with the code sample so you can follow along with this explanation.AlwaysIt prints the string \"before import\" (without quotes).It loads the math module and assigns it to a variable called math. This is equivalent to replacing import math with the following (note that __import__ is a low-level function in Python that takes a string and triggers the actual import):It prints the string \"before function_a\".It executes the def block, creating a function object, then assigning that function object to a variable called function_a.It prints the string \"before function_b\".It executes the second def block, creating another function object, then assigning it to a variable called function_b.It prints the string \"before __name__ guard\".Only When Your Module Is the Main ProgramOnly When Your Module Is Imported by AnotherAlwaysSummaryIn summary, here's what'd be printed in the two cases:You might naturally wonder why anybody would want this.  Well, sometimes you want to write a .py file that can be both used by other programs and/or modules as a module, and can also be run as the main program itself.  Examples:Your module is a library, but you want to have a script mode where it runs some unit tests or a demo.Your module is only used as a main program, but it has some unit tests, and the testing framework works by importing .py files like your script and running special test functions. You don't want it to try running the script just because it's importing the module.Your module is mostly used as a main program, but it also provides a programmer-friendly API for advanced users.Beyond those examples, it's elegant that running a script in Python is just setting up a few magic variables and importing the script. \"Running\" the script is a side effect of importing the script's module.Question: Can I have multiple __name__ checking blocks?  Answer: it's strange to do so, but the language won't stop you.Suppose the following is in foo2.py.  What happens if you say python foo2.py on the command-line? Why?",
                "When your script is run by passing it as a command to the Python interpreter,all of the code that is at indentation level 0 gets executed.  Functions and classes that are defined are, well, defined, but none of their code gets run.  Unlike other languages, there's no main() function that gets run automatically - the main() function is implicitly all the code at the top level.In this case, the top-level code is an if block.  __name__ is a built-in variable which evaluates to the name of the current module.  However, if a module is being run directly (as in myscript.py above), then __name__ instead is set to the string \"__main__\".  Thus, you can test whether your script is being run directly or being imported by something else by testingIf your script is being imported into another module, its various function and class definitions will be imported and its top-level code will be executed, but the code in the then-body of the if clause above won't get run as the condition is not met. As a basic example, consider the following two scripts:Now, if you invoke the interpreter asThe output will beIf you run two.py instead:You getThus, when module one gets loaded, its __name__ equals \"one\" instead of \"__main__\".",
                "Create the following two files:Now run each file individually.Running python a.py:When a.py is executed, it imports the module b. This causes all the code inside b to run. Python sets globals()['__name__'] in the b module to the module's name, b.Running python b.py:When only the file b.py is executed, Python sets globals()['__name__'] in this file to \"__main__\". Therefore, the if statement evaluates to True this time.",
                "To outline the basics:The global variable, __name__, in the module that is the entry point to your program, is '__main__'. Otherwise, it's the name you import the module by.So, code under the if block will only run if the module is the entry point to your program.It allows the code in the module to be importable by other modules, without executing the code block beneath on import.Why do we need this?Say you're writing a Python script designed to be used as a module:You could test the module by adding this call of the function to the bottom:and running it (on a command prompt) with something like:However, if you want to import the module to another script:On import, the do_important function would be called, so you'd probably comment out your function call, do_important(), at the bottom.And then you'll have to remember whether or not you've commented out your test function call. And this extra complexity would mean you're likely to forget, making your development process more troublesome.The __name__ variable points to the namespace wherever the Python interpreter happens to be at the moment.Inside an imported module, it's the name of that module.But inside the primary module (or an interactive Python session, i.e. the interpreter's Read, Eval, Print Loop, or REPL) you are running everything from its \"__main__\".So if you check before executing:With the above, your code will only execute when you're running it as the primary module (or intentionally call it from another script).There's a Pythonic way to improve on this, though.What if we want to run this business process from outside the module?If we put the code we want to exercise as we develop and test in a function like this and then do our check for '__main__' immediately after:We now have a final function for the end of our module that will run if we run the module as the primary module.It will allow the module and its functions and classes to be imported into other scripts without running the main function, and will also allow the module (and its functions and classes) to be called when running from a different '__main__' module, i.e.This idiom can also be found in the Python documentation in an explanation of the __main__ module. That text states:This module represents the (otherwise anonymous) scope in which the\n  interpreter\u2019s main program executes \u2014 commands read either from\n  standard input, from a script file, or from an interactive prompt. It\n  is this environment in which the idiomatic \u201cconditional script\u201d stanza\n  causes a script to run:",
                "if __name__ == \"__main__\" is the part that runs when the script is run from (say) the command line using a command like python myscript.py.",
                "__name__ is a global variable (in Python, global actually means on the module level) that exists in all namespaces. It is typically the module's name (as a str type).As the only special case, however, in whatever Python process you run, as in mycode.py:the otherwise anonymous global namespace is assigned the value of '__main__' to its __name__.Thus, including the final lineswill cause your script's uniquely defined main function to run.Another benefit of using this construct: you can also import your code as a module in another script and then run the main function if and when your program decides:",
                "There are lots of different takes here on the mechanics of the code in question, the \"How\", but for me none of it made sense until I understood the \"Why\". This should be especially helpful for new programmers.Take file \"ab.py\":And a second file \"xy.py\":What is this code actually doing?When you execute xy.py, you import ab. The import statement runs the module immediately on import, so ab's operations get executed before the remainder of xy's. Once finished with ab, it continues with xy.The interpreter keeps track of which scripts are running with __name__. When you run a script - no matter what you've named it - the interpreter calls it \"__main__\", making it the master or 'home' script that gets returned to after running an external script.Any other script that's called from this \"__main__\" script is assigned its filename as its __name__ (e.g., __name__ == \"ab.py\"). Hence, the line if __name__ == \"__main__\": is the interpreter's test to determine if it's interpreting/parsing the 'home' script that was initially executed, or if it's temporarily peeking into another (external) script. This gives the programmer flexibility to have the script behave differently if it's executed directly vs. called externally.Let's step through the above code to understand what's happening, focusing first on the unindented lines and the order they appear in the scripts. Remember that function - or def - blocks don't do anything by themselves until they're called. What the interpreter might say if mumbled to itself:The bottom two lines mean: \"If this is the \"__main__\" or 'home' script, execute the function called main()\". That's why you'll see a def main(): block up top, which contains the main flow of the script's functionality.Why implement this?Remember what I said earlier about import statements? When you import a module it doesn't just 'recognize' it and wait for further instructions - it actually runs all the executable operations contained within the script. So, putting the meat of your script into the main() function effectively quarantines it, putting it in isolation so that it won't immediately run when imported by another script.Again, there will be exceptions, but common practice is that main() doesn't usually get called externally. So you may be wondering one more thing: if we're not calling main(), why are we calling the script at all? It's because many people structure their scripts with standalone functions that are built to be run independent of the rest of the code in the file. They're then later called somewhere else in the body of the script. Which brings me to this:But the code works without itYes, that's right. These separate functions can be called from an in-line script that's not contained inside a main() function. If you're accustomed (as I am, in my early learning stages of programming) to building in-line scripts that do exactly what you need, and you'll try to figure it out again if you ever need that operation again ... well, you're not used to this kind of internal structure to your code, because it's more complicated to build and it's not as intuitive to read.But that's a script that probably can't have its functions called externally, because if it did it would immediately start calculating and assigning variables. And chances are if you're trying to re-use a function, your new script is related closely enough to the old one that there will be conflicting variables.In splitting out independent functions, you gain the ability to re-use your previous work by calling them into another script. For example, \"example.py\" might import \"xy.py\" and call x(), making use of the 'x' function from \"xy.py\". (Maybe it's capitalizing the third word of a given text string; creating a NumPy array from a list of numbers and squaring them; or detrending a 3D surface. The possibilities are limitless.)(As an aside, this question contains an answer by @kindall that finally helped me to understand - the why, not the how. Unfortunately it's been marked as a duplicate of this one, which I think is a mistake.)",
                "The code under if __name__ == '__main__': will only be executed if the module is invoked as a script.As an example, consider the following module my_test_module.py:First possibility: Import my_test_module.py in another moduleNow if you invoke main.py:Note that only the top-level print() statement in my_test_module is executed.Second possibility: Invoke my_test_module.py as a scriptNow if you run my_test_module.py as a Python script, both print() statements will be executed:For a more comprehensive explanation, you can read What does if __name__ == '__main__' do in Python.",
                "When there are certain statements in our module (M.py) we want to be executed when it'll be running as main (not imported), we can place those statements (test-cases, print statements) under this if block.As by default (when module running as main, not imported) the __name__ variable is set to \"__main__\", and when it'll be imported the __name__ variable will get a different value, most probably the name of the module ('M').\nThis is helpful in running different variants of a modules together, and separating their specific input & output statements and also if there are any test-cases.In short, use this 'if __name__ == \"main\" ' block to prevent (certain) code from being run when the module is imported.",
                "Put simply, __name__ is a variable defined for each script that defines whether the script is being run as the main module or it is being run as an imported module.So if we have two scripts;andThe output from executing script1 isAnd the output from executing script2 is:As you can see, __name__ tells us which code is the 'main' module.\nThis is great, because you can just write code and not have to worry about structural issues like in C/C++, where, if a file does not implement a 'main' function then it cannot be compiled as an executable and if it does, it cannot then be used as a library.Say you write a Python script that does something great and you implement a boatload of functions that are useful for other purposes. If I want to use them I can just import your script and use them without executing your program (given that your code only executes within the  if __name__ == \"__main__\": context). Whereas in C/C++ you would have to portion out those pieces into a separate module that then includes the file. Picture the situation below;The arrows are import links. For three modules each trying to include the previous modules code there are six files (nine, counting the implementation files) and five links. This makes it difficult to include other code into a C project unless it is compiled specifically as a library. Now picture it for Python:You write a module, and if someone wants to use your code they just import it and the __name__ variable can help to separate the executable portion of the program from the library part.",
                "To be short, you need to know several points:import a action actually runs all that can be run in a.py, meaning each line in a.pyBecause of point 1, you may not want everything to be run in a.py when importing itTo solve the problem in point 2, Python allows you to use a condition check__name__ is an implicit variable in all .py modules:The important thing that Python is special at is point 4! The rest is just basic logic.I've been reading so much throughout the answers on this page. I would say, if you know the thing, for sure you will understand those answers, otherwise, you are still confused.",
                "Let's look at the answer in a more abstract way:Suppose we have this code in x.py:Blocks A and B are run when we are running x.py.But just block A (and not B) is run when we are running another module, y.py for example, in which x.py is imported and the code is run from there (like when a function in x.py is called from y.py).",
                "When you run Python interactively the local __name__ variable is assigned a value of __main__. Likewise, when you execute a Python module from the command line, rather than importing it into another module, its __name__ attribute is assigned a value of __main__, rather than the actual name of the module. In this way, modules can look at their own __name__ value to determine for themselves how they are being used, whether as support for another program or as the main application executed from the command line. Thus, the following idiom is quite common in Python modules:",
                "Consider:It checks if the __name__ attribute of the Python script is \"__main__\". In other words, if the program itself is executed, the attribute will be __main__, so the program will be executed (in this case the main() function).However, if your Python script is used by a module, any code outside of the if statement will be executed, so if __name__ == \"__main__\" is used just to check if the program is used as a module or not, and therefore decides whether to run the code.",
                "Before explaining anything about if __name__ == '__main__' it is important to understand what __name__ is and what it does.__name__ is a DunderAlias - can be thought of as a global variable (accessible from modules) and works in a similar way to global.It is a string (global as mentioned above) as indicated by type(__name__) (yielding <class 'str'>), and is an inbuilt standard for both Python 3 and Python 2 versions.It can not only be used in scripts but can also be found in both the interpreter and modules/packages.test_file.py:Resulting in __main__somefile.py:test_file.py:Resulting in somefileNotice that when used in a package or module, __name__ takes the name of the file.  The path of the actual module or package path is not given, but has its own DunderAlias __file__, that allows for this.You should see that, where __name__, where it is the main file (or program) will always return __main__, and if it is a module/package, or anything that is running off some other Python script, will return the name of the file where it has originated from.Being a variable means that it's value can be overwritten (\"can\" does not mean \"should\"), overwriting the value of __name__ will result in a lack of readability.  So do not do it, for any reason.  If you need a variable define a new variable.It is always assumed that the value of __name__ to be __main__ or the name of the file.  Once again changing this default value will cause more confusion that it will do good, causing problems further down the line.It is considered good practice in general to include the if __name__ == '__main__' in scripts.Now we know the behaviour of __name__ things become clearer:An if is a flow control statement that contains the block of code will execute if the value given is true. We have seen that __name__ can take either\n__main__ or the file name it has been imported from.This means that if __name__ is equal to __main__ then the file must be the main file and must actually be running (or it is the interpreter), not a module or package imported into the script.If indeed __name__ does take the value of __main__ then whatever is in that block of code will execute.This tells us that if the file running is the main file (or you are running from the interpreter directly) then that condition must execute.  If it is a package then it should not, and the value will not be __main__.__name__ can also be used in modules to define the name of a moduleIt is also possible to do other, less common but useful things with __name__, some I will show here:You can also use it to provide runnable help functions/utilities on packages and modules without the elaborate use of libraries.It also allows modules to be run from the command line as main scripts, which can be also very useful.",
                "I think it's best to break the answer in depth and in simple words:__name__: Every module in Python has a special attribute called __name__.\nIt is a built-in variable that returns the name of the module.__main__: Like other programming languages, Python too has an execution entry point, i.e., main. '__main__' is the name of the scope in which top-level code executes. Basically you have two ways of using a Python module: Run it directly as a script, or import it. When a module is run as a script, its __name__ is set to __main__.Thus, the value of the __name__ attribute is set to __main__ when the module is run as the main program. Otherwise the value of __name__  is set to contain the name of the module.",
                "It is a special for when a Python file is called from the command line. This is typically used to call a \"main()\" function or execute other appropriate startup code, like commandline arguments handling for instance.It could be written in several ways. Another is:I am not saying you should use this in production code, but it serves to illustrate that there is nothing \"magical\" about if __name__ == '__main__'.It just a convention for invoking a main function in Python files.",
                "There are a number of variables that the system (Python interpreter) provides for source files (modules).  You can get their values anytime you want, so, let us focus on the __name__ variable/attribute:When Python loads a source code file, it executes all of the code found in it. (Note that it doesn't call all of the methods and functions defined in the file, but it does define them.)Before the interpreter executes the source code file though, it defines a few special variables for that file; __name__ is one of those special variables that Python automatically defines for each source code file.If Python is loading this source code file as the main program (i.e. the file you run), then it sets the special __name__ variable for this file to have a value \"__main__\".If this is being imported from another module, __name__ will be set to that module's name.So, in your example in part:means that the code block:will be executed only when you run the module directly; the code block will not execute if another module is calling/importing it because the value of __name__ will not equal to \"main\" in that particular instance.Hope this helps out.",
                "if __name__ == \"__main__\": is basically the top-level script environment, and it specifies the interpreter that ('I have the highest priority to be executed first').'__main__' is the name of the scope in which top-level code executes. A module\u2019s __name__ is set equal to '__main__' when read from standard input, a script, or from an interactive prompt.",
                "Consider:The output for the above is __main__.The above statement is true and prints \"direct method\". Suppose if they imported this class in another class it doesn't print \"direct method\" because, while importing, it will set __name__ equal to \"first model name\".",
                "In simple words:The code you see under if __name__ == \"__main__\": will only get called upon when your Python file is executed as python example1.pyHowever, if you wish to import your Python file example1.py as a module to work with another Python file, say example2.py, the code under if __name__ == \"__main__\": will not run or take any effect.",
                "You can make the file usable as a script as well as an importable module.fibo.py (a module named fibo)Reference: https://docs.python.org/3.5/tutorial/modules.html",
                "The reason foris primarily to avoid the import lock problems that would arise from having code directly imported. You want main() to run if your file was directly invoked (that's the __name__ == \"__main__\" case), but if your code was imported then the importer has to enter your code from the true main module to avoid import lock problems.A side-effect is that you automatically sign on to a methodology that supports multiple entry points. You can run your program using main() as the entry point, but you don't have to. While setup.py expects main(), other tools use alternate entry points. For example, to run your file as a gunicorn process, you define an app() function instead of a main(). Just as with setup.py, gunicorn imports your code so you don't want it do do anything while it's being imported (because of the import lock issue).",
                "If you are a beginner, probably the only answer you need right now is that this code is unnecessary for a simple script. It is only useful if you want to be able to import your script (or unpickle etc; see the other answers here for some other non-beginner scenarios).In slightly different words, the if __name__ guard is a mechanism for hiding code from other code. If you don't have a specific reason to hide something, don't: If you don't need to hide some code from import, don't put it behind this guard, and if you do, hide as little as possible.In slightly more detail, let's say you have a simple script fib.py (adapted from this answer):Now, if you simply run python fib.py it works fine. But __name__ will always be \"__main__\" in this scenario, so the condition is actually unnecessary. The script could be simplified to justNow, you can't import fib with the new version, but if you didn't plan to do that in the first place, this version is actually better, because it's simpler and clearer.If you do want to be able to import fib, the first version is useless, too, because the useful code is in a section which will not run when you import this file (in which case __name__ will not be \"__main__\"). The proper design in that case would be to refactor the code so that the useful parts are in a function you can run when you want to after you have imported it.Now, if you import fib, the call to main() will not be executed; but when you run python fib.py, it will.Actually, a better design still would be to isolate the reusable part (the actual calculation) from the user-visible input/output:Now, you can from fib import fibn and call the fibn() function from the code which performs this import.(I called the function fibn() just to make it clearer what is what in this example. In real life, you might call it fib() and do from fib import fib.)Similarly, you could import and call the main function if you wanted to reuse it.Returning to the code in the question, I would similarly move the code from the if into a function as well, so that callers can invoke that function if they want to.This changes the scope of the lock variable; if the surrounding code needs access to it, you will need to make it global (or, perhaps, better, refactor main to return lock, and have the caller capture the value in a local variable of its own).(Unlike in languages like C, the name main has no specific meaning to Python; but it's a common convention to use it as the name of the thing which will be run. You still have to actually explicitly call it, like main(), unlike in C.)",
                "Every module in Python has an attribute called __name__. The value of __name__  attribute is  __main__ when the module is run directly, like python my_module.py. Otherwise (like when you say import my_module) the value of __name__  is the name of the module.Small example to explain in short.We can execute this directly asOutputNow suppose we call the above script from another script:When you execute this,OutputSo, the above is self-explanatory that when you call test from another script, if loop __name__ in test.py will not execute.",
                "This answer is for Java programmers learning Python.\nEvery Java file typically contains one public class. You can use that class in two ways:Call the class from other files. You just have to import it in the calling program.Run the class stand alone, for testing purposes.For the latter case, the class should contain a public static void main() method. In Python this purpose is served by the globally defined label '__main__'.",
                "If this .py file are imported by other .py files, the code under the if statement will not be executed.If this .py are run by python this_py.py under shell, or double clicked in Windows. the code under the if statement will be executed.It is usually written for testing.",
                "We see if __name__ == '__main__': quite often.It checks if a module is being imported or not.In other words, the code within the if block will be executed only when the code runs directly. Here directly means not imported.Let's see what it does using a simple code that prints the name of the module:If we run the code directly via python test.py, the module name is __main__:",
                "If the Python interpreter is running a particular module then the __name__ global variable will have the value \"__main__\":When you run this script, it prints:If you import this file, say A to file B, and execute the file B then if __name__ == \"__main__\" in file A becomes False, so it prints:",
                "All the answers have pretty much explained the functionality. But I will provide one example of its usage which might help clearing out the concept further.Assume that you have two Python files, a.py and b.py. Now, a.py imports b.py. We run the a.py file, where the import b.py code is executed first. Before the rest of the a.py code runs, the code in the file b.py must run completely.In the b.py code, there is some code that is exclusive to that file b.py and we don't want any other file (other than the b.py file), that has imported the b.py file, to run it.So that is what this line of code checks. If it is the main file (i.e., b.py) running the code, which in this case it is not (a.py is the main file running), then only the code gets executed."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I remove local (untracked) files from the current Git working tree?",
                "How do I delete untracked local files from the current working tree?"
            ],
            "url": "https://stackoverflow.com/questions/61212",
            "answer": [
                "Cleans the working tree by recursively removing files that are not under version control, starting from the current directory.Normally, only files unknown to Git are removed, but if the -x option is specified, ignored files are also removed. This can, for example, be useful to remove all build products.If any optional <path>... arguments are given, only those paths are affected.Step 1 is to show what will be deleted by using the -n option:Clean Step - beware: this will delete files:Note the case difference on the X for the two latter commands.If clean.requireForce is set to \"true\" (the default) in your configuration, one needs to specify -f otherwise nothing will actually happen.Again see the git-clean docs for more information.-f, --forceIf the Git configuration variable clean.requireForce is not set to\nfalse, git clean will refuse to run unless given -f, -n or -i.-xDon\u2019t use the standard ignore rules read from .gitignore (per\ndirectory) and $GIT_DIR/info/exclude, but do still use the ignore\nrules given with -e options. This allows removing all untracked files,\nincluding build products. This can be used (possibly in conjunction\nwith git reset) to create a pristine working directory to test a clean\nbuild.-XRemove only files ignored by Git. This may be useful to rebuild\neverything from scratch, but keep manually created files.-n, --dry-runDon\u2019t actually remove anything, just show what would be done.-dRemove untracked directories in addition to untracked files. If an\nuntracked directory is managed by a different Git repository, it is\nnot removed by default. Use -f option twice if you really want to\nremove such a directory.",
                "Use git clean -f -d to make sure that directories are also removed.Don\u2019t actually remove anything, just show what would be done.orRemove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository, it is not removed by default. Use the -f option twice if you really want to remove such a directory.You can then check if your files are really gone with git status.",
                "I am surprised nobody mentioned this before:That stands for interactive and you will get a quick overview of what is going to be deleted offering you the possibility to include/exclude the affected files. Overall, still faster than running the mandatory --dry-run before the real cleaning.You will have to toss in a -d if you also want to take care of empty folders. At the end, it makes  for a nice alias:That being said, the extra hand holding of interactive commands can be tiring for experienced users.  These days I just use the already mentioned git clean -fd",
                "git-clean - Remove untracked files from the working tree",
                "To remove all untracked files, The simple\nway is to add all of them first and reset the repo as below",
                "If untracked directory is a git repository of its own (e.g. submodule), you need to use -f twice:git clean -d -f -f",
                "This is what I always use:For a very large project you might want to run it a couple of times.",
                "I like git stash push -u because you can undo them all with git stash pop.EDIT: Also I found a way to show untracked file in a stash (e.g. git show stash@{0}^3) https://stackoverflow.com/a/12681856/338986EDIT2: git stash save is deprecated in favor of push. Thanks @script-wolf.",
                "Always use -n before running the clean command as it will show you what files would get removed.-d Normally, when no  is specified, git clean will not recurse into untracked directories to avoid removing too much. Specify -d to have it recurse into such directories as well. If any paths are specified, -d is irrelevant; all untracked files matching the specified paths (with exceptions for nested git directories mentioned under --force) will be removed.-f | --force\nIf the Git configuration variable clean.requireForce is not set to false, git clean will refuse to delete files or directories unless given -f or -i. Git will refuse to modify untracked nested git repositories (directories with a .git subdirectory) unless a second -f is given.Now run without -n if output was what you intend to remove.By default, git clean will only remove untracked files that are not ignored. Any file that matches a pattern in your .gitignore or other ignore files will not be removed. If you want to remove those files too, you can add a -x to the clean command.There is also interactive mode available -i with the clean commandBefore you use stash --all note:\nIf the --all option is used, then the ignored files are stashed and cleaned in addition to the untracked files.If the --keep-index option is used, all changes already added to the index are left intact. Your staged changes remain in your workspace, but at the same time, they are also saved into your stash.Calling git stash without any arguments is equivalent to git stash push.Stashing based on the used flags can clear your directory from unstaged / staged files by writing them to stash storage. I give\u2019s flexibility to retrieve the files at any point in time using stash with apply or pop. Then if you are fine with removing your stashed files you could run:To see full instruction on how to work with stash see this How to name and retrieve a stash by name in git?",
                "git-clean is what you are looking for. It is used to remove untracked files from the working tree.",
                "If needed to remove untracked files from particular subdirectory,And combined way to delete untracked dir/files and ignored files.after this you will have modified files only in git status.",
                "Remove all extra folders and files in this repo + submodulesThis gets you in same state as fresh clone.Remove all extra folders and files in this repo but not its submodulesRemove extra folders but not files (ex. build or logs folder)Remove extra folders + ignored files (but not newly added files)If file wasn't ignored and not yet checked-in then  it stays. Note the capital X.New interactive mode",
                "git clean -fd removes directorygit clean -fX removes ignored filesgit clean -fx removes ignored and un-ignored filescan be used all above options in combination asgit clean -fdXxcheck git manual for more help",
                "OK, deleting unwanted untracked files and folders are easy using git in command line, just do it like this:Double check before doing it as it will delete the files and folders without making any history...Also in this case, -f stands for force and -d stands for directory...So, if you want to delete files only, you can use -f only:If you want to delete(directories) and files, you can delete only untracked directories and files like this:Also, you can use -x flag for including the files which are ignored by git. This would be helpful if you want to delete everything.And adding -i flag, makes git asking you for permission for deleting files one by one on the go.If you not sure and want to check things first, add -n flag.Use -q if you don't want to see any report after successful deletion.I also create the image below to make it more memorable, especially I have seen many people confuse -f for cleaning folder sometimes or mix it up somehow!",
                "A better way is to use: git cleanThis removes untracked files, including directories (-d) and files ignored by git (-x).Also, replace the -f argument with -n to perform a dry-run or -i for interactive mode and it will tell you what will be removed.",
                "User interactive approach:-i for interactive\n-f for force\n-d for directory\n-x for ignored files(add if required)\nNote: Add -n or --dry-run to just check what it will do.",
                "To remove Untracked files :",
                "A lifehack for such situation I just invented and tried (that works perfectly):Beware! Be sure to commit any needed changes (even in non-untracked files) before performing this.",
                "For me only following worked:In all other cases, I was getting message \"Skipping Directory\" for some subdirectories.",
                "git clean -f -d -x $(git rev-parse --show-cdup) applies clean to the root directory, no matter where you call it within a repository directory tree. I use it all the time as it does not force you to leave the folder where you working now and allows to clean & commit right from the place where you are.Be sure that flags -f, -d, -x match your needs:There are other flags as well available, just check git clean --help.",
                "If you just want to delete the files listed as untracked by 'git status'I prefer this to 'git clean' because 'git clean' will delete files\nignored by git, so your next build will have to rebuild everything\nand you may lose your IDE settings too.",
                "To know what will be deleted before actually deleting:git clean -d -nIt will output something like:Would remove sample.txtTo delete everything listed in the output of the previous command:git clean -d -fIt will output something like:Removing sample.txt",
                "git add --all, git stash and git stash drop, try these three commands in this order inorder to remove all untracked files. By adding all those untracked files to git and stashing them will move all those untracked files to stash list and dropping out top one i.e., stash@{0} will remove the stashed changes from stash list.",
                "To remove the untracked files you should first use command to view the files that will be affected by cleaningThis will show you the list of files that will be deleted. Now to actually delete those files use this command:",
                "uggested Command for Removing Untracked Files from git docs is git cleangit clean - Remove untracked files from the working treeSuggested Method:  Interative Mode by using git clean -i\nso we can have control over it. let see remaining available options.Available Options:Explanation:1. -dRemove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository,\n   it is not removed by default. Use -f option twice if you really want to remove such a directory.2. -f, --forceIf the Git configuration variable clean.requireForce is not set to false, git clean will refuse to run unless given -f, -n or\n   -i.3. -i, --interactiveShow what would be done and clean files interactively. See \u201cInteractive mode\u201d for details.4. -n, --dry-runDon\u2019t actually remove anything, just show what would be done.5. -q, --quietBe quiet, only report errors, but not the files that are successfully removed.6. -e , --exclude=In addition to those found in .gitignore (per directory) and $GIT_DIR/info/exclude, also consider these patterns to be in the\n   set of the ignore rules in effect.7. -xDon\u2019t use the standard ignore rules read from .gitignore (per directory) and $GIT_DIR/info/exclude, but do still use the ignore\n   rules given with -e options. This allows removing all untracked files, including build products. This can be used (possibly in\n   conjunction with git reset) to create a pristine working directory to test a clean build.8. -XRemove only files ignored by Git. This may be useful to rebuild everything from scratch, but keep manually created files.",
                "git clean -f to remove untracked files from working directory.I have covered some basics here in my blog, git-intro-basic-commands",
                "Normal git clean command doesn't remove untracked files with my git version 2.9.0.windows.1.",
                "We can easily removed local untracked files from the current git working tree by using below git comments.Example:Links :",
                "The following command will clean out\n  the current git repository and all its submodules recursively:",
                "oh-my-zsh with zsh provides those great aliases via the git plugin. They can be used in bash as well.gclean='git clean -fd'\ngpristine='git reset --hard && git clean -dfx'"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I redirect to another webpage?",
                "How can I redirect the user from one page to another using jQuery or pure JavaScript?"
            ],
            "url": "https://stackoverflow.com/questions/503093",
            "answer": [
                "jQuery is not necessary, and window.location.replace(...) will best simulate an HTTP redirect.window.location.replace(...) is better than using window.location.href, because replace() does not keep the originating page in the session history, meaning the user won't get stuck in a never-ending back-button fiasco.If you want to simulate someone clicking on a link, use\n location.hrefIf you want to simulate an HTTP redirect, use location.replaceFor example:",
                "WARNING: This answer has merely been provided as a possible solution; it is obviously not the best solution, as it requires jQuery. Instead, prefer the pure JavaScript solution.",
                "If you are here because you are losing HTTP_REFERER when redirecting, keep reading:(Otherwise ignore this last part)The following section is for those using HTTP_REFERER as one of many security measures (although it isn't a great protective measure). If you're using Internet\u00a0Explorer\u00a08 or lower, these variables get lost when using any form of JavaScript page redirection (location.href,  etc.).Below we are going to implement an alternative for IE8 & lower so that we don't lose HTTP_REFERER. Otherwise, you can almost always simply use window.location.href.Testing against HTTP_REFERER (URL pasting, session, etc.) can help tell whether a request is legitimate.\n(Note: there are also ways to work-around / spoof these referrers, as noted by droop's link in the comments)Simple cross-browser testing solution (fallback to window.location.href for Internet\u00a0Explorer\u00a09+ and all other browsers)Usage: redirect('anotherpage.aspx');",
                "There are lots of ways of doing this.",
                "This works for every browser:",
                "It would help if you were a little more descriptive in what you are trying to do.  If you are trying to generate paged data, there are some options in how you do this.  You can generate separate links for each page that you want to be able to get directly to.Note that the current page in the example is handled differently in the code and with CSS.If you want the paged data to be changed via AJAX, this is where jQuery would come in.  What you would do is add a click handler to each of the anchor tags corresponding to a different page.  This click handler would invoke some jQuery code that goes and fetches the next page via AJAX and updates the table with the new data.  The example below assumes that you have a web service that returns the new page data.",
                "I also think that location.replace(URL) is the best way, but if you want to notify the search engines about your redirection (they don't analyze JavaScript code to see the redirection) you should add the rel=\"canonical\" meta tag to your website.Adding a noscript section with a HTML refresh meta tag in it, is also a good solution. I suggest you to use this JavaScript redirection tool to create redirections. It also has Internet\u00a0Explorer support to pass the HTTP referrer.Sample code without delay looks like this:",
                "But if someone wants to redirect back to home page then he may use the following snippet.It would be helpful if you have three different environments as development, staging, and production.You can explore this window or window.location object by just putting these words in Chrome Console or Firebug's Console.",
                "JavaScript provides you many methods to retrieve and change the current URL which is displayed in browser's address bar. All these methods uses the Location object, which is  a property of the Window object. You can create a new Location object that has the current URL as follows..Basic Structure of a URLProtocol -- Specifies the protocol name be used to access the resource on the Internet. (HTTP (without SSL) or HTTPS (with SSL))hostname -- Host name specifies the host that owns the resource. For example, www.stackoverflow.com. A server provides services using the name of the host.port -- A port number used to recognize a specific process to which an Internet or other network message is to be forwarded when it arrives at a server.pathname -- The path gives info about the specific resource within the host that the Web client wants to access. For example, stackoverflow.com/index.html.query --  A query string follows the path component, and provides a string of information that the resource can utilize for some purpose (for example, as parameters for a search or as data to be processed).hash -- The anchor portion of a URL, includes the hash sign (#).With these Location object properties you can access all of these URL componentsNow If you want to change a page or redirect the user to some other page you can use the href property of the Location object like thisYou can use the href property of the Location object.Location Object also have these three methodsYou can use assign() and replace methods also to redirect to other pages like theseHow assign() and replace() differs -- The difference between replace() method and assign() method(), is that replace() removes the URL of the current document from the document history, means it is not possible to use the \"back\" button to navigate back to the original document. So Use the assign() method if you want to load a new document, andwant to give the option to navigate back to the original document.You can change the location object href property using jQuery also  like thisAnd hence you can redirect the user to some other url.",
                "Basically jQuery is just a JavaScript framework and for doing some of the things like redirection in this case, you can just use pure JavaScript, so in that case you have 3 options using vanilla JavaScript:1) Using location replace, this will replace the current history of the page, means that it is not possible to use the back button to go back to the original page.2) Using location assign, this will keep the history for you and with using back button, you can go back to the original page:3) I recommend using one of those previous ways, but this could be the third option using pure JavaScript:You can also write a function in jQuery to handle it, but not recommended as it's only one line pure JavaScript function, also you can use all of above functions without window if you are already in the window scope, for example window.location.replace(\"http://stackoverflow.com\"); could be location.replace(\"http://stackoverflow.com\");Also I show them all on the image below:",
                "Should just be able to set using window.location.Example:Here is a past post on the subject: How do I redirect to another webpage?",
                "Before I start, jQuery is a JavaScript library used for DOM manipulation. So you should not be using jQuery for a page redirect.A quote from Jquery.com:While jQuery might run without major issues in older browser versions,\nwe do not actively test jQuery in them and generally do not fix bugs\nthat may appear in them.It was found here:\nhttps://jquery.com/browser-support/So jQuery is not an end-all and be-all solution for backwards compatibility.The following solution using raw JavaScript works in all browsers and have been standard for a long time so you don't need any libraries for cross browser support.This page will redirect to Google after 3000 millisecondsDifferent options are as follows:When using replace, the back button will not go back to the redirect page, as if it was never in the history. If you want the user to be able to go back to the redirect page then use window.location.href or window.location.assign. If you do use an option that lets the user go back to the redirect page, remember that when you enter the redirect page it will redirect you back. So put that into consideration when picking an option for your redirect. Under conditions where the page is only redirecting when an action is done by the user then having the page in the back button history will be okay. But if the page auto redirects then you should use replace so that the user can use the back button without getting forced back to the page the redirect sends.You can also use meta data to run a page redirect as followed.META RefreshMETA LocationBASE HijackingMany more methods to redirect your unsuspecting client to a page they may not wish to go can be found on this page (not one of them is reliant on jQuery):https://code.google.com/p/html5security/wiki/RedirectionMethodsI would also like to point out, people don't like to be randomly redirected. Only redirect people when absolutely needed. If you start redirecting people randomly they will never go to your site again.The next paragraph is hypothetical:You also may get reported as a malicious site. If that happens then when people click on a link to your site the users browser may warn them that your site is malicious. What may also happen is search engines may start dropping your rating if people are reporting a bad experience on your site.Please review Google Webmaster Guidelines about redirects:\nhttps://support.google.com/webmasters/answer/2721217?hl=en&ref_topic=6001971Here is a fun little page that kicks you out of the page.If you combine the two page examples together you would have an infant loop of rerouting that will guarantee that your user will never want to use your site ever again.",
                "You can do that without jQuery as:And if you want only jQuery then you can do it like:",
                "This works with jQuery:",
                "# HTML Page Redirect Using jQuery/JavaScript MethodTry this example code:If you want to give a complete URL as window.location = \"www.google.co.in\";.",
                "Original question: \"How to redirect using jQuery?\", hence the answer implements jQuery >> Complimentary usage case.To just redirect to a page with JavaScript:Or if you need a delay:jQuery allows you to select elements from a web page with ease. You can find anything you want on a page and then use jQuery to add special effects, react to user actions, or show and hide content inside or outside the element you have selected. All these tasks start with knowing how to select an element or an event.Imagine someone wrote a script/plugin with 10000 lines of code. With jQuery you can connect to this code with just a line or two.",
                "So, the question is how to make a redirect page, and not how to redirect to a website?You only need to use JavaScript for this. Here is some tiny code that will create a dynamic redirect page.So say you just put this snippet into a redirect/index.html file on your website you can use it like so.http://www.mywebsite.com/redirect?url=http://stackoverflow.comAnd if you go to that link it will automatically redirect you to stackoverflow.com.Link to DocumentationAnd that's how you make a Simple redirect page with JavaScriptEdit:There is also one thing to note. I have added window.location.replace in my code because I think it suits a redirect page, but, you must know that when using window.location.replace and you get redirected, when you press the back button in your browser it will not got back to the redirect page, and it will go back to the page before it, take a look at this little demo thing.Example:The process: store home => redirect page to google => googleWhen at google: google => back button in browser => store homeSo, if this suits your needs then everything should be fine. If you want to include the redirect page in the browser history replace thiswith",
                "You need to put this line in your code:If you don't have jQuery, go with JavaScript:",
                "On your click function, just add:",
                "Try this:Code snippet of example.",
                "jQuery is not needed. You can do this:It is that easy!The best way to initiate an HTTP request is with document.loacation.href.replace('URL').",
                "First write properly. You want to navigate within an application for another link from your application for another link. Here is the code:And if you want to navigate pages within your application then I also have code, if you want.",
                "You can redirect in jQuery like this:",
                "JavaScript is very extensive. If you want to jump to another page you have three options.As you want to move to another page, you can use any from these if this is your requirement.\nHowever all three options are limited to different situations. Chose wisely according to your requirement.If you are interested in more knowledge about the concept, you can go through further.",
                "In JavaScript and jQuery we can use the following code to redirect the one page to another page:",
                "Please don't kill me, this is a joke. It's a joke. This is a joke.This did \"provide an answer to the question\", in the sense that it asked for a solution \"using jQuery\" which in this case entails forcing it into the equation somehow.Ferrybig apparently needs the joke explained (still joking, I'm sure there are limited options on the review form), so without further ado:Other answers are using jQuery's attr() on the location or window objects unnecessarily.This answer also abuses it, but in a more ridiculous way. Instead of using it to set the location, this uses attr() to retrieve a function that sets the location.The function is named jQueryCode even though there's nothing jQuery about it, and calling a function somethingCode is just horrible, especially when the something is not even a language.The \"85 bytes\" is a reference to Code Golf. Golfing is obviously not something you should do outside of code golf, and furthermore this answer is clearly not actually golfed.Basically, cringe.",
                "Javascript:Jquery:",
                "Here is a time-delay redirection. You can set the delay time to whatever you want:"
            ]
        },
        {
            "tag": "",
            "question": [
                "How to modify existing, unpushed commit messages?",
                "I wrote the wrong thing in a commit message.\n\nHow can I change the message? The commit has not been pushed yet."
            ],
            "url": "https://stackoverflow.com/questions/179123",
            "answer": [
                "will open your editor, allowing you to change the commit message of the most recent commit. Additionally, you can set the commit message directly in the command line with:\u2026however, this can make multi-line commit messages or small corrections more cumbersome to enter.Make sure you don't have any working copy changes staged before doing this or they will get committed too. (Unstaged changes will not get committed.)If you've already pushed your commit up to your remote branch, then - after amending your commit locally (as described above) - you'll also need to force push the commit with:Warning: force-pushing will overwrite the remote branch with the state of your local one. If there are commits on the remote branch that you don't have in your local branch, you will lose those commits.Warning: be cautious about amending commits that you have already shared with other people. Amending commits essentially rewrites them to have different SHA IDs, which poses a problem if other people have copies of the old commit that you've rewritten. Anyone who has a copy of the old commit will need to synchronize their work with your newly re-written commit, which can sometimes be difficult, so make sure you coordinate with others when attempting to rewrite shared commit history, or just avoid rewriting shared commits altogether.Another option is to use interactive rebase.\nThis allows you to edit any message you want to update even if it's not the latest message.In order to do a Git squash, follow these steps:Once you squash your commits - choose the e/r for editing the message:When you use git rebase -i HEAD~n there can be more than n commits. Git will \"collect\" all the commits in the last n commits, and if there was a merge somewhere in between that range you will see all the commits as well, so the outcome will be n + .If you have to do it for more than a single branch and you might face conflicts when amending the content, set up git rerere and let Git resolve those conflicts automatically for you.git-commit(1) Manual Pagegit-rebase(1) Manual Pagegit-push(1) Manual Page",
                "If the commit you want to fix isn\u2019t the most recent one:git rebase --interactive $parent_of_flawed_commitIf you want to fix several flawed commits, pass the parent of the oldest one of them.An editor will come up, with a list of all commits since the one you gave.For each commit you want to reword, Git will drop you back into your editor. For each commit you want to edit, Git drops you into the shell. If you\u2019re in the shell:Most of this sequence will be explained to you by the output of the various commands as you go. It\u2019s very easy; you don\u2019t need to memorise it \u2013 just remember that git rebase --interactive lets you correct commits no matter how long ago they were.Note that you will not want to change commits that you have already pushed. Or maybe you do, but in that case you will have to take great care to communicate with everyone who may have pulled your commits and done work on top of them. How do I recover/resynchronise after someone pushes a rebase or a reset to a published branch?",
                "To amend the previous commit, make the changes you want and stage those changes, and then runThis will open a file in your text editor representing your new commit message. It starts out populated with the text from your old commit message. Change the commit message as you want, then save the file and quit your editor to finish.To amend the previous commit and keep the same log message, runTo fix the previous commit by removing it entirely, runIf you want to edit more than one commit message, run(Replace commit_count with number of commits that you want to edit.) This command launches your editor. Mark the first commit (the one that you want to change) as \u201cedit\u201d instead of \u201cpick\u201d, then save and exit your editor. Make the change you want to commit and then runNote: You can also \"Make the change you want\" from the editor opened by git commit --amend",
                "As already mentioned, git commit --amend is the way to overwrite the last commit. One note: if you would like to also overwrite the files, the command would be",
                "You also can use git filter-branch for that.It's not as easy as a trivial git commit --amend, but it's especially useful, if you already have some merges after your erroneous commit message.Note that this will try to rewrite every commit between HEAD and the flawed commit, so you should choose your msg-filter command very wisely ;-)",
                "I prefer this way:Otherwise, there will be a new commit with a new commit ID.",
                "If you are using the Git GUI tool, there is a button named Amend last commit. Click on that button and then it will display your last commit files and message. Just edit that message, and you can commit it with a new commit message.Or use this command from a console/terminal:",
                "You can use Git rebasing. For example, if you want to modify back to commit bbc643cd, runIn the default editor, modify 'pick' to 'edit' in the line whose commit you want to modify. Make your changes and then stage them withNow you can useto modify the commit, and after thatto return back to the previous head commit.",
                "If you only want to modify your last commit message, then do:That will drop you into your text editor and let you change the last commit message.If you want to change the last three commit messages, or any of the commit messages up to that point, supply HEAD~3 to the git rebase -i command:",
                "If you have to change an old commit message over multiple branches (i.e., the commit with the erroneous message is present in multiple branches) you might want to use:Git will create a temporary directory for rewriting and additionally backup old references in refs/original/.-f will enforce the execution of the operation. This is necessary if the temporary directory is already present or if there are already references stored under refs/original. If that is not the case, you can drop this flag.-- separates filter-branch options from revision options.--all will make sure that all branches and tags are rewritten.Due to the backup of your old references, you can easily go back to the state before executing the command.Say, you want to recover your master and access it in branch old_master:",
                "If it's your last commit, just amend the commit:(Using the -o (--only) flag to make sure you change only the commit message)If it's a buried commit, use the awesome interactive rebase:Find the commit you want, change pick to r (reword), and save and close the file. Done!Miniature Vim tutorial (or, how to rebase with only 8 keystrokes 3jcwrEscZZ):If you edit text a lot, then switch to the Dvorak keyboard layout, learn to touch-type, and learn Vim. Is it worth the effort? Yes.ProTip\u2122: Don't be afraid to experiment with \"dangerous\" commands that rewrite history* \u2014 Git doesn't delete your commits for 90 days by default; you can find them in the reflog:* Watch out for options like --hard and --force though \u2014 they can discard data.\n*  Also, don't rewrite history on any branches you're collaborating on.",
                "UseTo understand it in detail, an excellent post is 4. Rewriting Git History. It also talks about when not to use git commit --amend.",
                "You have a couple of options here. You can doas long as it's your last commit.Otherwise, if it's not your last commit, you can do an interactive rebase,Then inside the interactive rebase you simply add edit to that commit. When it comes up, do a git commit --amend and modify the commit message. If you want to roll back before that commit point, you could also use git reflog and just delete that commit. Then you just do a git commit again.",
                "If you are using the Git GUI, you can amend the last commit which hasn't been pushed with:",
                "I use the Git GUI as much as I can, and that gives you the option to amend the last commit:Also, git rebase -i origin/masteris a nice mantra that will always present you with the commits you have done on top of master, and give you the option to amend, delete, reorder or squash. No need to get hold of that hash first.",
                "For anyone looking for a Windows/Mac GUI to help with editing older messages (i.e. not just the latest message), I'd recommend Sourcetree. The steps to follow are below the image.For commits that haven't been pushed to a remote yet:...Or... for commits that have already been pushed:Follow the steps in this answer, which are similar to above, but require a further command to be run from the command line (git push origin <branch> -f) to force-push the branch. I'd recommend reading it all and applying the necessary caution!",
                "Wow, so there are a lot of ways to do this.Yet another way to do this is to delete the last commit, but keep its changes so that you won't lose your work. You can then do another commit with the corrected message. This would look something like this:I always do this if I forget to add a file or do a change.Remember to specify --soft instead of --hard, otherwise you lose that commit entirely.",
                "If you just want to edit the latest commit, use:orBut if you want to edit several commits in a row, you should use rebasing instead:In a file, like the one above, write edit/e or one of the other options, and hit save and exit.Now you'll be at the first wrong commit. Make changes in the files, and they'll be automatically staged for you. TypeSave and exit that and typeto move to next selection until finished with all your selections.Note that these things change all your SHA hashes after that particular commit.",
                "If you only want to change your last message you should use the --only flag or its shortcut -o with commit --amend:This ensures that you don't accidentally enhance your commit with staged stuff. Of course it's best to have a proper $EDITOR configuration. Then you can leave the -m option out, and Git will pre-fill the commit message with the old one. In this way it can be easily edited.",
                "Update your last wrong commit message with the new commit message in one line:Or, try Git reset like below:git reset can help you to break one commit into multiple commits too:Here you have successfully broken your last commit into two commits.",
                "On this question there are a lot of answers, but none of them explains in super detail how to change older commit messages using Vim. I was stuck trying to do this myself, so here I'll write down in detail how I did this especially for people who have no experience in Vim!I wanted to change my five latest commits that I already pushed to the server. This is quite 'dangerous' because if someone else already pulled from this, you can mess things up by changing the commit messages. However, when you\u2019re working on your own little branch and are sure no one pulled it you can change it like this:Let's say you want to change your five latest commits, and then you type this in the terminal:*Where 5 is the number of commit messages you want to change (so if you want to change the 10th to last commit, you type in 10).This command will get you into Vim there you can \u2018edit\u2019 your commit history. You\u2019ll see your last five commits at the top like this:Instead of pick you need to write reword. You can do this in Vim by typing in i. That makes you go in to insert mode. (You see that you\u2019re in insert mode by the word INSERT at the bottom.) For the commits you want to change, type in reword instead of pick.Then you need to save and quit this screen. You do that by first going in to \u2018command-mode\u2019 by pressing the Escbutton (you can check that you\u2019re in command-mode if the word INSERT at the bottom has disappeared). Then you can type in a command by typing :. The command to save and quit is wq. So if you type in :wq you\u2019re on the right track.Then Vim will go over every commit message you want to reword, and here you can actually change the commit messages. You\u2019ll do this by going into insert mode, changing the commit message, going into the command-mode, and save and quit. Do this five times and you\u2019re out of Vim!Then, if you already pushed your wrong commits, you need to git push --force to overwrite them. Remember that git push --force is quite a dangerous thing to do, so make sure that no one pulled from the server since you pushed your wrong commits!Now you have changed your commit messages!(As you see, I'm not that experienced in Vim, so if I used the wrong 'lingo' to explain what's happening, feel free to correct me!)",
                "You can use git-rebase-rewordIt is designed to edit any commit (not just last) same way as commit --amendIt is named after the action on rebase interactive to amend a commit: \"reword\". See this post and man -section interactive mode-Examples:",
                "I have added the aliases reci and recm for recommit (amend) it. Now I can do it with git recm or git recm -m:",
                "I realised that I had pushed a commit with a typo in it. In order to undo, I did the following:Warning: force pushing your changes will overwrite the remote branch with your local one. Make sure that you aren't going to be overwriting anything that you want to keep. Also be cautious about force pushing an amended (rewritten) commit if anyone else shares the branch with you, because they'll need to rewrite their own history if they have the old copy of the commit that you've just rewritten.",
                "I like to use the following:",
                "If you have not pushed the code to your remote branch (GitHub/Bitbucket) you can change the commit message on the command line as below.If you're working on a specific branch do this:If you've already pushed the code with the wrong message, and you need to be careful when changing the message. That is, after you change the commit message and try pushing it again, you end up with having issues. To make it smooth, follow these steps.Please read my entire answer before doing it.Important note: When you use the force push directly you might end up with code issues that other developers are working on the same branch. So to avoid those conflicts, you need to pull the code from your branch before making the force push:This is the best practice when changing the commit message, if it was already pushed."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do JavaScript closures work?",
                "How would you explain JavaScript closures to someone with a knowledge of the concepts they consist of (for example functions, variables and the like), but does not understand closures themselves?\n\nI ..."
            ],
            "url": "https://stackoverflow.com/questions/111102",
            "answer": [
                "A closure is a pairing of:A lexical environment is part of every execution context (stack frame) and is a map between identifiers (i.e. local variable names) and values.Every function in JavaScript maintains a reference to its outer lexical environment. This reference is used to configure the execution context created when a function is invoked. This reference enables code inside the function to \"see\" variables declared outside the function, regardless of when and where the function is called.If a function was called by a function, which in turn was called by another function, then a chain of references to outer lexical environments is created. This chain is called the scope chain.In the following code, inner forms a closure with the lexical environment of the execution context created when foo is invoked, closing over variable secret:function foo() {\n  const secret = Math.trunc(Math.random() * 100)\n  return function inner() {\n    console.log(`The secret number is ${secret}.`)\n  }\n}\nconst f = foo() // `secret` is not directly accessible from outside `foo`\nf() // The only way to retrieve `secret`, is to invoke `f`In other words: in JavaScript, functions carry a reference to a private \"box of state\", to which only they (and any other functions declared within the same lexical environment) have access. This box of the state is invisible to the caller of the function, delivering an excellent mechanism for data-hiding and encapsulation.And remember: functions in JavaScript can be passed around like variables (first-class functions), meaning these pairings of functionality and state can be passed around your program: similar to how you might pass an instance of a class around in C++.If JavaScript did not have closures, then more states would have to be passed between functions explicitly, making parameter lists longer and code noisier.So, if you want a function to always have access to a private piece of state, you can use a closure....and frequently we do want to associate the state with a function. For example, in Java or C++, when you add a private instance variable and a method to a class, you are associating the state with functionality.In C and most other common languages, after a function returns, all the local variables are no longer accessible because the stack-frame is destroyed. In JavaScript, if you declare a function within another function, then the local variables of the outer function can remain accessible after returning from it. In this way, in the code above, secret remains available to the function object inner, after it has been returned from foo.Closures are useful whenever you need a private state associated with a function. This is a very common scenario - and remember: JavaScript did not have a class syntax until 2015, and it still does not have a private field syntax. Closures meet this need.In the following code, the function toString closes over the details of the car.function Car(manufacturer, model, year, color) {\n  return {\n    toString() {\n      return `${manufacturer} ${model} (${year}, ${color})`\n    }\n  }\n}\n\nconst car = new Car('Aston Martin', 'V8 Vantage', '2012', 'Quantum Silver')\nconsole.log(car.toString())In the following code, the function inner closes over both fn and args.function curry(fn) {\n  const args = []\n  return function inner(arg) {\n    if(args.length === fn.length) return fn(...args)\n    args.push(arg)\n    return inner\n  }\n}\n\nfunction add(a, b) {\n  return a + b\n}\n\nconst curriedAdd = curry(add)\nconsole.log(curriedAdd(2)(3)()) // 5In the following code, function onClick closes over variable BACKGROUND_COLOR.const $ = document.querySelector.bind(document)\nconst BACKGROUND_COLOR = 'rgba(200, 200, 242, 1)'\n\nfunction onClick() {\n  $('body').style.background = BACKGROUND_COLOR\n}\n\n$('button').addEventListener('click', onClick)\n<button>Set background color</button>In the following example, all the implementation details are hidden inside an immediately executed function expression. The functions tick and toString close over the private state and functions they need to complete their work. Closures have enabled us to modularize and encapsulate our code.let namespace = {};\n\n(function foo(n) {\n  let numbers = []\n\n  function format(n) {\n    return Math.trunc(n)\n  }\n\n  function tick() {\n    numbers.push(Math.random() * 100)\n  }\n\n  function toString() {\n    return numbers.map(format)\n  }\n\n  n.counter = {\n    tick,\n    toString\n  }\n}(namespace))\n\nconst counter = namespace.counter\ncounter.tick()\ncounter.tick()\nconsole.log(counter.toString())This example shows that the local variables are not copied in the closure: the closure maintains a reference to the original variables themselves. It is as though the stack-frame stays alive in memory even after the outer function exits.function foo() {\n  let x = 42\n  let inner = () => console.log(x)\n  x = x + 1\n  return inner\n}\n\nfoo()() // logs 43In the following code, three methods log, increment, and update all close over the same lexical environment.And every time createObject is called, a new execution context (stack frame) is created and a completely new variable x, and a new set of functions (log etc.) are created, that close over this new variable.function createObject() {\n  let x = 42;\n  return {\n    log() { console.log(x) },\n    increment() { x++ },\n    update(value) { x = value }\n  }\n}\n\nconst o = createObject()\no.increment()\no.log() // 43\no.update(5)\no.log() // 5\nconst p = createObject()\np.log() // 42If you are using variables declared using var, be careful you understand which variable you are closing over. Variables declared using var are hoisted. This is much less of a problem in modern JavaScript due to the introduction of let and const.In the following code, each time around the loop, a new function inner is created, which closes over i. But because var i is hoisted outside the loop, all of these inner functions close over the same variable, meaning that the final value of i (3) is printed, three times.function foo() {\n  var result = []\n  for (var i = 0; i < 3; i++) {\n    result.push(function inner() { console.log(i) } )\n  }\n\n  return result\n}\n\nconst result = foo()\n// The following will print `3`, three times...\nfor (var i = 0; i < 3; i++) {\n  result[i]() \n}",
                "Every function in JavaScript maintains a link to its outer lexical environment. A lexical environment is a map of all the names (eg. variables, parameters) within a scope, with their values.So, whenever you see the function keyword, code inside that function has access to variables declared outside the function.function foo(x) {\r\n  var tmp = 3;\r\n\r\n  function bar(y) {\r\n    console.log(x + y + (++tmp)); // will log 16\r\n  }\r\n\r\n  bar(10);\r\n}\r\n\r\nfoo(2);This will log 16 because function bar closes over the parameter x and the variable tmp, both of which exist in the lexical environment of outer function foo.Function bar, together with its link with the lexical environment of function foo is a closure.A function doesn't have to return in order to create a closure. Simply by virtue of its declaration, every function closes over its enclosing lexical environment, forming a closure.function foo(x) {\r\n  var tmp = 3;\r\n\r\n  return function (y) {\r\n    console.log(x + y + (++tmp)); // will also log 16\r\n  }\r\n}\r\n\r\nvar bar = foo(2);\r\nbar(10); // 16\r\nbar(10); // 17The above function will also log 16, because the code inside bar can still refer to argument x and variable tmp, even though they are no longer directly in scope.However, since tmp is still hanging around inside bar's closure, it is available to be incremented. It will be incremented each time you call bar.The simplest example of a closure is this:var a = 10;\r\n\r\nfunction test() {\r\n  console.log(a); // will output 10\r\n  console.log(b); // will output 6\r\n}\r\nvar b = 6;\r\ntest();When a JavaScript function is invoked, a new execution context ec is created. Together with the function arguments and the target object, this execution context also receives a link to the lexical environment of the calling execution context, meaning the variables declared in the outer lexical environment (in the above example, both a and b) are available from ec.Every function creates a closure because every function has a link to its outer lexical environment.Note that variables themselves are visible from within a closure, not copies.",
                "FOREWORD: this answer was written when the question was:Like the old Albert said : \"If you can't explain it to a six-year old, you really don't understand it yourself.\u201d. Well I tried to explain JS closures to a 27 years old friend and completely failed.Can anybody consider that I am 6 and strangely interested in that subject ?I'm pretty sure I was one of the only people that attempted to take the initial question literally. Since then, the question has mutated several times, so my answer may now seem incredibly silly & out of place. Hopefully the general idea of the story remains fun for some.I'm a big fan of analogy and metaphor when explaining difficult concepts, so let me try my hand with a story.Once upon a time:There was a princess...She lived in a wonderful world full of adventures. She met her Prince Charming, rode around her world on a unicorn, battled dragons, encountered talking animals, and many other fantastical things.But she would always have to return back to her dull world of chores and grown-ups.And she would often tell them of her latest amazing adventure as a princess.But all they would see is a little girl......telling stories about magic and fantasy.And even though the grown-ups knew of real princesses, they would never believe in the unicorns or dragons because they could never see them. The grown-ups said that they only existed inside the little girl's imagination.But we know the real truth; that the little girl with the princess inside......is really a princess with a little girl inside.",
                "Taking the question seriously, we should find out what a typical 6-year-old is capable of cognitively, though admittedly, one who is interested in JavaScript is not so typical.On  Childhood Development: 5 to 7 Years  it says:Your child will be able to follow two-step directions. For example, if you say to your child, \"Go to the kitchen and get me a trash bag\" they will be able to remember that direction.We can use this example to explain closures, as follows:The kitchen is a closure that has a local variable, called trashBags.  There is a function inside the kitchen called getTrashBag that gets one trash bag and returns it.We can code this in JavaScript like this:function makeKitchen() {\r\n  var trashBags = ['A', 'B', 'C']; // only 3 at first\r\n\r\n  return {\r\n    getTrashBag: function() {\r\n      return trashBags.pop();\r\n    }\r\n  };\r\n}\r\n\r\nvar kitchen = makeKitchen();\r\n\r\nconsole.log(kitchen.getTrashBag()); // returns trash bag C\r\nconsole.log(kitchen.getTrashBag()); // returns trash bag B\r\nconsole.log(kitchen.getTrashBag()); // returns trash bag AFurther points that explain why closures are interesting:",
                "I need to know how many times a button has been clicked and do something on every third click...// Declare counter outside event handler's scope\nvar counter = 0;\nvar element = document.getElementById('button');\n\nelement.addEventListener(\"click\", function() {\n  // Increment outside counter\n  counter++;\n\n  if (counter === 3) {\n    // Do something every third time\n    console.log(\"Third time's the charm!\");\n\n    // Reset counter\n    counter = 0;\n  }\n});\n<button id=\"button\">Click Me!</button>Now this will work, but it does encroach into the outer scope by adding a variable, whose sole purpose is to keep track of the count. In some situations, this would be preferable as your outer application might need access to this information. But in this case, we are only changing every third click's behavior, so it is preferable to enclose this functionality inside the event handler.var element = document.getElementById('button');\n\nelement.addEventListener(\"click\", (function() {\n  // init the count to 0\n  var count = 0;\n\n  return function(e) { // <- This function becomes the click handler\n    count++; //    and will retain access to the above `count`\n\n    if (count === 3) {\n      // Do something every third time\n      console.log(\"Third time's the charm!\");\n\n      //Reset counter\n      count = 0;\n    }\n  };\n})());\n<button id=\"button\">Click Me!</button>Notice a few things here.In the above example, I am using the closure behavior of JavaScript. This behavior allows any function to have access to the scope in which it was created, indefinitely. To practically apply this, I immediately invoke a function that returns another function, and because the function I'm returning has access to the internal count variable (because of the closure behavior explained above) this results in a private scope for usage by the resulting function... Not so simple? Let's dilute it down...A simple one-line closureAll variables outside the returned function are available to the returned function, but they are not directly available to the returned function object...Get it? So in our primary example, the count variable is contained within the closure and always available to the event handler, so it retains its state from click to click.Also, this private variable state is fully accessible, for both readings and assigning to its private scoped variables.There you go; you're now fully encapsulating this behavior.Full Blog Post (including jQuery considerations)",
                "Closures are hard to explain because they are used to make some behaviour work that everybody intuitively expects to work anyway. I find the best way to explain them (and the way that I learned what they do) is to imagine the situation without them:const makePlus = function(x) {\n    return function(y) { return x + y; };\n}\n\nconst plus5 = makePlus(5);\nconsole.log(plus5(3));What would happen here if JavaScript didn't know closures? Just replace the call in the last line by its method body (which is basically what function calls do) and you get:Now, where's the definition of x? We didn't define it in the current scope. The only solution is to let plus5 carry its scope (or rather, its parent's scope) around. This way, x is well-defined and it is bound to the value 5.",
                "TLDRA closure is a link between a function and its outer lexical (ie. as-written) environment, such that the identifiers (variables, parameters, function declarations etc) defined within that environment are visible from within the function, regardless of when or from where the function is invoked.DetailsIn the terminology of the ECMAScript specification, a closure can be said to be implemented by the [[Environment]] reference of every function-object, which points to the lexical environment within which the function is defined.When a function is invoked via the internal [[Call]] method, the [[Environment]] reference on the function-object is copied into the outer environment reference of the environment record of the newly-created execution context (stack frame).In the following example, function f closes over the lexical environment of the global execution context:In the following example, function h closes over the lexical environment of function g, which, in turn, closes over the lexical environment of the global execution context.If an inner function is returned by an outer, then the outer lexical environment will persist after the outer function has returned. This is because the outer lexical environment needs to be available if the inner function is eventually invoked.In the following example, function j closes over the lexical environment of function i, meaning that variable x is visible from inside function j, long after function i has completed execution:function i() {\r\n    var x = 'mochacchino'\r\n    return function j() {\r\n        console.log('Printing the value of x, from within function j: ', x)\r\n    }\r\n} \r\n\r\nconst k = i()\r\nsetTimeout(k, 500) // invoke k (which is j) after 500msIn a closure, the variables in the outer lexical environment themselves are available, not copies.function l() {\r\n  var y = 'vanilla';\r\n\r\n  return {\r\n    setY: function(value) {\r\n      y = value;\r\n    },\r\n    logY: function(value) {\r\n      console.log('The value of y is: ', y);\r\n    }\r\n  }\r\n}\r\n\r\nconst o = l()\r\no.logY() // The value of y is: vanilla\r\no.setY('chocolate')\r\no.logY() // The value of y is: chocolateThe chain of lexical environments, linked between execution contexts via outer environment references, forms a scope chain and defines the identifiers visible from any given function.Please note that in an attempt to improve clarity and accuracy, this answer has been substantially changed from the original.",
                "OK, 6-year-old closures fan. Do you want to hear the simplest example of closure?Let's imagine the next situation: a driver is sitting in a car. That car is inside a plane. Plane is in the airport. The ability of driver to access things outside his car, but inside the plane, even if that plane leaves an airport, is a closure. That's it. When you turn 27, look at the more detailed explanation or at the example below.Here is how I can convert my plane story into the code.var plane = function(defaultAirport) {\r\n\r\n  var lastAirportLeft = defaultAirport;\r\n\r\n  var car = {\r\n    driver: {\r\n      startAccessPlaneInfo: function() {\r\n        setInterval(function() {\r\n          console.log(\"Last airport was \" + lastAirportLeft);\r\n        }, 2000);\r\n      }\r\n    }\r\n  };\r\n  car.driver.startAccessPlaneInfo();\r\n\r\n  return {\r\n    leaveTheAirport: function(airPortName) {\r\n      lastAirportLeft = airPortName;\r\n    }\r\n  }\r\n}(\"Boryspil International Airport\");\r\n\r\nplane.leaveTheAirport(\"John F. Kennedy\");",
                "This is an attempt to clear up several (possible) misunderstandings about closures that appear in some of the other answers.",
                "I wrote a blog post a while back explaining closures. Here's what I said about closures in terms of why you'd want one.Closures are a way to let a function\n  have persistent, private variables -\n  that is, variables that only one\n  function knows about, where it can\n  keep track of info from previous times\n  that it was run.In that sense, they let a function act a bit like an object with private attributes.Full post:So what are these closure thingys?",
                "The original question had a quote:If you can't explain it to a six-year old, you really don't understand it yourself.This is how I'd try to explain it to an actual six-year-old:You know how grown-ups can own a house, and they call it home? When a mom has a child, the child doesn't really own anything, right? But its parents own a house, so whenever someone asks \"Where's your home?\", the child can answer \"that house!\", and point to the house of its parents.A \"Closure\" is the ability of the child to always (even if abroad) be able to refer to its home, even though it's really the parent's who own the house.",
                "The following simple example covers all the main points of JavaScript closures.*Here is a factory that produces calculators that can add and multiply:The key point: Each call to make_calculator creates a new local variable n, which continues to be usable by that calculator's add and multiply functions long after make_calculator returns.If you are familiar with stack frames, these calculators seem strange: How can they keep accessing n after make_calculator returns?  The answer is to imagine that JavaScript doesn't use \"stack frames\", but instead uses \"heap frames\", which can persist after the function call that made them returns.Inner functions like add and multiply, which access variables declared in an outer function**, are called closures.That is pretty much all there is to closures.* For example, it covers all the points in the \"Closures for Dummies\" article given in another answer, except example 6, which simply shows that variables can be used before they are declared, a nice fact to know but completely unrelated to closures. It also covers all the points in the accepted answer, except for the points (1) that functions copy their arguments into local variables (the named function arguments), and (2) that copying numbers creates a new number, but copying an object reference gives you another reference to the same object. These are also good to know but again completely unrelated to closures. It is also very similar to the example in this answer but a bit shorter and less abstract. It does not cover the point of this answer or this comment, which is that JavaScript makes it difficult to plug the current value of a loop variable into your inner function: The \"plugging in\" step can only be done with a helper function that encloses your inner function and is invoked on each loop iteration. (Strictly speaking, the inner function accesses the helper function's copy of the variable, rather than having anything plugged in.) Again, very useful when creating closures, but not part of what a closure is or how it works. There is additional confusion due to closures working differently in functional languages like ML, where variables are bound to values rather than to storage space, providing a constant stream of people who understand closures in a way (namely the \"plugging in\" way) that is simply incorrect for JavaScript, where variables are always bound to storage space, and never to values.** Any outer function, if several are nested, or even in the global context, as this answer points out clearly.",
                "I still think Google's explanation works very well and is concise:*A C# question",
                "I tend to learn better by GOOD/BAD comparisons. I like to see working code followed by non-working code that someone is likely to encounter. I put together a jsFiddle that does a comparison and tries to boil down the differences to the simplest explanations I could come up with.In the above code createClosure(n) is invoked in every iteration of the loop. Note that I named the variable n to highlight that it is a new variable created in a new function scope and is not the same variable as index which is bound to the outer scope.This creates a new scope and n is bound to that scope; this means we have 10 separate scopes, one for each iteration.createClosure(n) returns a function that returns the n within that scope.Within each scope n is bound to whatever value it had when createClosure(n) was invoked so the nested function that gets returned will always return the value of n that it had when createClosure(n) was invoked.In the above code the loop was moved within the createClosureArray() function and the function now just returns the completed array, which at first glance seems more intuitive.What might not be obvious is that since createClosureArray() is only invoked once only one scope is created for this function instead of one for every iteration of the loop.Within this function a variable named index is defined. The loop runs and adds functions to the array that return index. Note that index is defined within the createClosureArray function which only ever gets invoked one time.Because there was only one scope within the createClosureArray() function, index is only bound to a value within that scope. In other words, each time the loop changes the value of index, it changes it for everything that references it within that scope.All of the functions added to the array return the SAME index variable from the parent scope where it was defined instead of 10 different ones from 10 different scopes like the first example. The end result is that all 10 functions return the same variable from the same scope.After the loop finished and index was done being modified the end value was 10, therefore every function added to the array returns the value of the single index variable which is now set to 10.CLOSURES DONE RIGHT\nn = 0\nn = 1\nn = 2\nn = 3\nn = 4\nn = 5\nn = 6\nn = 7\nn = 8\nn = 9CLOSURES DONE WRONG\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10\nn = 10",
                "Wikipedia on closures:In computer science, a closure is a function together with a referencing environment for the nonlocal names (free variables) of that function.Technically, in JavaScript, every function is a closure. It always has an access to variables defined in the surrounding scope.Since scope-defining construction in JavaScript is a function, not a code block like in many other languages, what we usually mean by closure in JavaScript is a function working with nonlocal variables defined in already executed surrounding function.Closures are often used for creating functions with some hidden private data (but it's not always the case).emsThe example above is using an anonymous function, which was executed once. But it does not have to be. It can be named (e.g. mkdb) and executed later, generating a database function each time it is invoked. Every generated function will have its own hidden database object. Another usage example of closures is when we don't return a function, but an object containing multiple functions for different purposes, each of those function having access to the same data.",
                "I put together an interactive JavaScript tutorial to explain how closures work.\nWhat's a Closure?Here's one of the examples:",
                "The children will never forget the secrets they have shared with their parents, even after their parents are\ngone. This is what closures are for functions.The secrets for JavaScript functions are the private variablesEvery time you call it, the local variable \"name\" is created and given the name \"Mary\". And every time the function exits the variable is lost and the name is forgotten.As you may guess, because the variables are re-created every time the function is called, and nobody else will know them, there must be a secret place where they are stored. It could be called Chamber of Secrets or stack or local scope but it doesn't matter. We know they are there, somewhere, hidden in the memory.But, in JavaScript, there is this very special thing that functions which are created inside other functions, can also know the local variables of their parents and keep them as long as they live.So, as long as we are in the parent -function, it can create one or more child functions which do share the secret variables from the secret place.But the sad thing is, if the child is also a private variable of its parent function, it would also die when the parent ends, and the secrets would die with them.So to live, the child has to leave before it's too lateAnd now, even though Mary is \"no longer running\", the memory of her is not lost and her child will always remember her name and other secrets they shared during their time together.So, if you call the child \"Alice\", she will respondThat's all there is to tell.",
                "I do not understand why the answers are so complex here.Here is a closure:Yes. You probably use that many times a day.There is no reason to believe closures are a complex design hack to address specific problems. No, closures are just about using a variable that comes from a higher scope from the perspective of where the function was declared (not run).Now what it allows you to do can be more spectacular, see other answers.",
                "A closure is where an inner function has access to variables in its outer function. That's probably the simplest one-line explanation you can get for closures.",
                "Example for the first point by dlaliberte:A closure is not only created when you return an inner function. In fact, the enclosing function does not need to return at all. You might instead assign your inner function to a variable in an outer scope, or pass it as an argument to another function where it could be used immediately. Therefore, the closure of the enclosing function probably already exists at the time that enclosing function was called since any inner function has access to it as soon as it is called.",
                "I know there are plenty of solutions already, but I guess that this small and simple script can be useful to demonstrate the concept:",
                "You're having a sleep over and you invite Dan.\nYou tell Dan to bring one XBox controller.Dan invites Paul.\nDan asks Paul to bring one controller. How many controllers were brought to the party?",
                "The author of Closures has explained closures pretty well, explaining the reason why we need them and also explaining LexicalEnvironment which is necessary to understanding closures. \nHere is the summary:What if a variable is accessed, but it isn\u2019t local? Like here:In this case, the interpreter finds the variable in the\nouter LexicalEnvironment object.The process consists of two steps:When a function is created, it gets a hidden property, named [[Scope]], which references the current LexicalEnvironment.If a variable is read, but can not be found anywhere, an error is generated.Nested functionsFunctions can be nested one inside another, forming a chain of LexicalEnvironments which can also be called a scope chain.So, function g has access to g, a and f.ClosuresA nested function may continue to live after the outer function has finished:Marking up LexicalEnvironments:As we see, this.say is a property in the user object, so it continues to live after User completed.And if you remember, when this.say is created, it (as every function) gets an internal reference this.say.[[Scope]] to the current LexicalEnvironment. So, the LexicalEnvironment of the current User execution stays in memory. All variables of User also are its properties, so they are also carefully kept, not junked as usually.The whole point is to ensure that if the inner function wants to access an outer variable in the future, it is able to do so.To summarize:This is called a closure.",
                "JavaScript functions can access their:If a function accesses its environment, then the function is a closure.Note that outer functions are not required, though they do offer benefits I don't discuss here. By accessing data in its environment, a closure keeps that data alive. In the subcase of outer/inner functions, an outer function can create local data and eventually exit, and yet, if any inner function(s) survive after the outer function exits, then the inner function(s) keep the outer function's local data alive.Example of a closure that uses the global environment:Imagine that the Stack Overflow Vote-Up and Vote-Down button events are implemented as closures, voteUp_click and voteDown_click, that have access to external variables isVotedUp and isVotedDown, which are defined globally. (For simplicity's sake, I am referring to StackOverflow's Question Vote buttons, not the array of Answer Vote buttons.)When the user clicks the VoteUp button, the voteUp_click function checks whether isVotedDown == true to determine whether to vote up or merely cancel a down vote. Function voteUp_click is a closure because it is accessing its environment.All four of these functions are closures as they all access their environment.",
                "As a father of a 6-year-old, currently teaching young children (and a relative novice to coding with no formal education so corrections will be required), I think the lesson would stick best through hands-on play. If the 6-year-old is ready to understand what a closure is, then they are old enough to have a go themselves. I'd suggest pasting the code into jsfiddle.net, explaining a bit, and leaving them alone to concoct a unique song. The explanatory text below is probably more appropriate for a 10 year old.INSTRUCTIONSDATA: Data is a collection of facts. It can be numbers, words, measurements, observations or even just descriptions of things. You can't touch it, smell it or taste it. You can write it down, speak it and hear it. You could use it to create touch smell and taste using a computer. It can be made useful by a computer using code.CODE: All the writing above is called code. It is written in JavaScript.JAVASCRIPT: JavaScript is a language. Like English or French or Chinese are languages. There are lots of languages that are understood by computers and other electronic processors. For JavaScript to be understood by a computer it needs an interpreter. Imagine if a teacher who only speaks Russian comes to teach your class at school. When the teacher says \"\u0432\u0441\u0435 \u0441\u0430\u0434\u044f\u0442\u0441\u044f\", the class would not understand. But luckily you have a Russian pupil in your class who tells everyone this means \"everybody sit down\" - so you all do. The class is like a computer and the Russian pupil is the interpreter. For JavaScript the most common interpreter is called a browser.BROWSER: When you connect to the Internet on a computer, tablet or phone to visit a website, you use a browser. Examples you may know are Internet Explorer, Chrome, Firefox and Safari. The browser can understand JavaScript and tell the computer what it needs to do. The JavaScript instructions are called functions.FUNCTION: A function in JavaScript is like a factory. It might be a little factory with only one machine inside. Or it might contain many other little factories, each with many machines doing different jobs. In a real life clothes factory you might have reams of cloth and bobbins of thread going in and T-shirts and jeans coming out. Our JavaScript factory only processes data, it can't sew, drill a hole or melt metal. In our JavaScript factory data goes in and data comes out.All this data stuff sounds a bit boring, but it is really very cool; we might have a function that tells a robot what to make for dinner. Let's say I invite you and your friend to my house. You like chicken legs best, I like sausages, your friend always wants what you want and my friend does not eat meat.I haven't got time to go shopping, so the function needs to know what we have in the fridge to make decisions. Each ingredient has a different cooking time and we want everything to be served hot by the robot at the same time. We need to provide the function with the data about what we like, the function could 'talk' to the fridge, and the function could control the robot.A function normally has a name, parentheses and braces. Like this:Note that /*...*/ and // stop code being read by the browser.NAME: You can call a function just about whatever word you want. The example \"cookMeal\" is typical in joining two words together and giving the second one a capital letter at the beginning - but this is not necessary. It can't have a space in it, and it can't be a number on its own.PARENTHESES: \"Parentheses\" or () are the letter box on the JavaScript function factory's door or a post box in the street for sending packets of information to the factory. Sometimes the postbox might be marked for example cookMeal(you, me, yourFriend, myFriend, fridge, dinnerTime), in which case you know what data you have to give it.BRACES: \"Braces\" which look like this {} are the tinted windows of our factory. From inside the factory you can see out, but from the outside you can't see in.THE LONG CODE EXAMPLE ABOVEOur code begins with the word function, so we know that it is one! Then the name of the function sing - that's my own description of what the function is about. Then parentheses (). The parentheses are always there for a function. Sometimes they are empty, and sometimes they have something in. This one has a word in: (person). After this there is a brace like this { . This marks the start of the function sing(). It has a partner which marks the end of sing() like this }So this function might have something to do with singing, and might need some data about a person. It has instructions inside to do something with that data.Now, after the function sing(), near the end of the code is the lineVARIABLE: The letters var stand for \"variable\". A variable is like an envelope. On the outside this envelope is marked \"person\". On the inside it contains a slip of paper with the information our function needs, some letters and spaces joined together like a piece of string (it's called a string) that make a phrase reading \"an old lady\". Our envelope could contain other kinds of things like numbers (called integers), instructions (called functions), lists (called arrays). Because this variable is written outside of all the braces {}, and because you can see out through the tinted windows when you are inside the braces, this variable can be seen from anywhere in the code. We call this a 'global variable'.GLOBAL VARIABLE: person is a global variable, meaning that if you change its value from \"an old lady\" to \"a young man\", the person will keep being a young man until you decide to change it again and that any other function in the code can see that it's a young man. Press the F12 button or look at the Options settings to open the developer console of a browser and type \"person\" to see what this value is. Type person=\"a young man\" to change it and then type \"person\" again to see that it has changed.After this we have the lineThis line is calling the function, as if it were calling a dog\"Come on sing, Come and get person!\"When the browser has loaded the JavaScript code an reached this line, it will start the function. I put the line at the end to make sure that the browser has all the information it needs to run it.Functions define actions  - the main function is about singing. It contains a variable called firstPart which applies to the singing about the person that applies to each of the verses of the song: \"There was \" + person + \" who swallowed\". If you type firstPart into the console, you won't get an answer because the variable is locked up in a function - the browser can't see inside the tinted windows of the braces.CLOSURES: The closures are the smaller functions that are inside the big sing() function. The little factories inside the big factory. They each have their own braces which mean that the variables inside them can't be seen from the outside. That's why the names of the variables (creature and result) can be repeated in the closures but with different values. If you type these variable names in the console window, you won't get its value because it's hidden by two layers of tinted windows.The closures all know what the sing() function's variable called firstPart is, because they can see out from their tinted windows.After the closures come the linesThe sing() function will call each of these functions in the order they are given. Then the sing() function's work will be done.",
                "Okay, talking with a 6-year old child, I would possibly use following associations.Imagine - you are playing with your little brothers and sisters in the entire house, and you are moving around with your toys and brought some of them into your older brother's room. After a while your brother returned from the school and went to his room, and he locked inside it, so now you could not access toys left there anymore in a direct way. But you could knock the door and ask your brother for that toys. This is called toy's closure; your brother made it up for you, and he is now into outer scope.Compare with a situation when a door was locked by draft and nobody inside (general function execution), and then some local fire occur and burn down the room (garbage collector:D), and then a new room was build and now you may leave another toys there (new function instance), but never get the same toys which were left in the first room instance.For an advanced child I would put something like the following. It is not perfect, but it makes you feel about what it is:As you can see, the toys left in the room are still accessible via the brother and no matter if the room is locked. Here is a jsbin to play around with it.",
                "A function in JavaScript is not just a reference to a set of instructions (as in C language), but it also includes a hidden data structure which is composed of references to all nonlocal variables it uses (captured variables). Such two-piece functions are called closures. Every function in JavaScript can be considered a closure.Closures are functions with a state. It is somewhat similar to \"this\" in the sense that \"this\" also provides state for a function but function and \"this\" are separate objects (\"this\" is just a fancy parameter, and the only way to bind it permanently to a function is to create a closure). While \"this\" and function always live separately, a function cannot be separated from its closure and the language provides no means to access captured variables.Because all these external variables referenced by a lexically nested function are actually local variables in the chain of its lexically enclosing functions (global variables can be assumed to be local variables of some root function), and every single execution of a function creates new instances of its local variables, it follows that every execution of a function returning (or otherwise transferring it out, such as registering it as a callback) a nested function creates a new closure (with its own potentially unique set of referenced nonlocal variables which represent its execution context).Also, it must be understood that local variables in JavaScript are created not on the stack frame, but on the heap and destroyed only when no one is referencing them. When a function returns, references to its local variables are decremented, but they can still be non-null if during the current execution they became part of a closure and are still referenced by its lexically nested functions (which can happen only if the references to these nested functions were returned or otherwise transferred to some external code).An example:",
                "An answer for a six-year-old (assuming he knows what a function is and what a variable is, and what data is):Functions can return data. One kind of data you can return from a function is another function. When that new function gets returned, all the variables and arguments used in the function that created it don't go away. Instead, that parent function \"closes.\" In other words, nothing can look inside of it and see the variables it used except for the function it returned. That new function has a special ability to look back inside the function that created it and see the data inside of it.Another really simple way to explain it is in terms of scope:Any time you create a smaller scope inside of a larger scope, the smaller scope will always be able to see what is in the larger scope.",
                "Perhaps a little beyond all but the most precocious of six-year-olds, but a few examples that helped make the concept of closure in JavaScript click for me.A closure is a function that has access to another function's scope (its variables and functions). The easiest way to create a closure is with a function within a function; the reason being that in JavaScript a function always has access to its containing function\u2019s scope.function outerFunction() {\r\n    var outerVar = \"monkey\";\r\n    \r\n    function innerFunction() {\r\n        alert(outerVar);\r\n    }\r\n    \r\n    innerFunction();\r\n}\r\n\r\nouterFunction();ALERT: monkeyIn the above example, outerFunction is called which in turn calls innerFunction. Note how outerVar is available to innerFunction, evidenced by its correctly alerting the value of outerVar.Now consider the following:function outerFunction() {\r\n    var outerVar = \"monkey\";\r\n    \r\n    function innerFunction() {\r\n        return outerVar;\r\n    }\r\n    \r\n    return innerFunction;\r\n}\r\n\r\nvar referenceToInnerFunction = outerFunction();\r\nalert(referenceToInnerFunction());ALERT: monkeyreferenceToInnerFunction is set to outerFunction(), which simply returns a reference to innerFunction. When referenceToInnerFunction is called, it returns outerVar. Again, as above, this demonstrates that innerFunction has access to outerVar, a variable of outerFunction. Furthermore, it is interesting to note that it retains this access even after outerFunction has finished executing.And here is where things get really interesting. If we were to get rid of outerFunction, say set it to null, you might think that referenceToInnerFunction would loose its access to the value of outerVar. But this is not the case.function outerFunction() {\r\n    var outerVar = \"monkey\";\r\n    \r\n    function innerFunction() {\r\n        return outerVar;\r\n    }\r\n    \r\n    return innerFunction;\r\n}\r\n\r\nvar referenceToInnerFunction = outerFunction();\r\nalert(referenceToInnerFunction());\r\n\r\nouterFunction = null;\r\nalert(referenceToInnerFunction());ALERT: monkey\nALERT: monkeyBut how is this so? How can referenceToInnerFunction still know the value of outerVar now that outerFunction has been set to null?The reason that referenceToInnerFunction can still access the value of outerVar is because when the closure was first created by placing innerFunction inside of outerFunction, innerFunction added a reference to outerFunction\u2019s scope (its variables and functions) to its scope chain. What this means is that innerFunction has a pointer or reference to all of outerFunction\u2019s variables, including outerVar. So even when outerFunction has finished executing, or even if it is deleted or set to null, the variables in its scope, like outerVar, stick around in memory because of the outstanding reference to them on the part of the innerFunction that has been returned to referenceToInnerFunction. To truly release outerVar and the rest of outerFunction\u2019s variables from memory you would have to get rid of this outstanding reference to them, say by setting referenceToInnerFunction to null as well.//////////Two other things about closures to note. First, the closure will always have access to the last values of its containing function.function outerFunction() {\r\n    var outerVar = \"monkey\";\r\n    \r\n    function innerFunction() {\r\n        alert(outerVar);\r\n    }\r\n    \r\n    outerVar = \"gorilla\";\r\n\r\n    innerFunction();\r\n}\r\n\r\nouterFunction();ALERT: gorillaSecond, when a closure is created, it retains a reference to all of its enclosing function\u2019s variables and functions; it doesn\u2019t get to pick and choose. And but so, closures should be used sparingly, or at least carefully, as they can be memory intensive; a lot of variables can be kept in memory long after a containing function has finished executing.",
                "I'd simply point them to the Mozilla Closures page. It's the best, most concise and simple explanation of closure basics and practical usage that I've found. It is highly recommended to anyone learning JavaScript.And yes, I'd even recommend it to a 6-year old -- if the 6-year old is learning about closures, then it's logical they're ready to comprehend the concise and simple explanation provided in the article."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I revert a Git repository to a previous commit?",
                "How do I revert from my current state to a snapshot made on a certain commit?\n\nIf I do git log, then I get the following output:\n\n$ git log\ncommit a867b4af366350be2e7c21b8de9cc6504678a61b`\nAuthor: Me &..."
            ],
            "url": "https://stackoverflow.com/questions/4114095",
            "answer": [
                "This depends a lot on what you mean by \"revert\".If you want to temporarily go back to it, fool around, then come back to where you are, all you have to do is check out the desired commit:Or if you want to make commits while you're there, go ahead and make a new branch while you're at it:To go back to where you were, just check out the branch you were on again. (If you've made changes, as always when switching branches, you'll have to deal with them as appropriate. You could reset to throw them away; you could stash, checkout, stash pop to take them with you; you could commit them to a branch there if you want a branch there.)If, on the other hand, you want to really get rid of everything you've done since then, there are two possibilities. One, if you haven't published any of these commits, simply reset:If you mess up, you've already thrown away your local changes, but you can at least get back to where you were before by resetting again.On the other hand, if you've published the work, you probably don't want to reset the branch, since that's effectively rewriting history. In that case, you could indeed revert the commits. With Git, revert has a very specific meaning: create a commit with the reverse patch to cancel it out. This way you don't rewrite any history.The git-revert manpage actually covers a lot of this in its description. Another useful link is this git-scm.com section discussing git-revert.If you decide you didn't want to revert after all, you can revert the revert (as described here) or reset back to before the revert (see the previous section).You may also find this answer helpful in this case:\nHow can I move HEAD back to a previous location? (Detached head) & Undo commits",
                "Lots of complicated and dangerous answers here, but it's actually easy:This will revert everything from the HEAD back to the commit hash, meaning it will recreate that commit state in the working tree as if every commit after 0766c053 had been walked back. You can then commit the current tree, and it will create a brand new commit essentially equivalent to the commit you \"reverted\" to.(The --no-commit flag lets git revert all the commits at once- otherwise you'll be prompted for a message for each commit in the range, littering your history with unnecessary new commits.)This is a safe and easy way to rollback to a previous state. No history is destroyed, so it can be used for commits that have already been made public.",
                "Working on your own and just want it to work? Follow these instructions below, they\u2019ve worked reliably for me and many others for years.Working with others? Git is complicated. Read the comments below this answer, consider other answers, and discuss with your team before you do something rash.To revert to the previous commit, ignoring any changes:where HEAD is the last commit in your current branchTo revert to a commit that's older than the most recent commit:Credits go to a similar Stack Overflow question, Revert to a commit by a SHA hash in Git?.",
                "The best option for me and probably others is the Git reset option:This has been the best option for me! It is simple, fast and effective!** Note:** As mentioned in comments don't do this if you're sharing your branch with other people who have copies of the old commitsAlso from the comments, if you wanted a less 'ballzy' method you could use",
                "Before answering let's add some background, explaining what this HEAD is.HEAD is simply a reference to the current commit (latest) on the current branch. There can only be a single HEAD at any given time (excluding git worktree).The content of HEAD is stored inside .git/HEAD, and it contains the 40-bytes SHA-1 hash of the current commit.If you are not on the latest commit - meaning that HEAD is pointing to a prior commit in history it's called detached HEAD.On the command-line it will look like this - SHA-1 hash instead of the branch name since the HEAD is not pointing to the the tip of the current branch:This will checkout new branch pointing to the desired commit. This command will checkout to a given commit.At this point you can create a branch and start to work from this point on:You can always use the reflog as well. git reflog  will display any change which updated the HEAD and checking out the desired reflog entry will set the HEAD back to this commit.Every time the HEAD is modified there will be a new entry in the reflogThis will get you back to your desired commit.\"Move\" your HEAD back to the desired commit.This schema illustrates which command does what. As you can see there reset && checkout modify the HEAD.",
                "You can do this by the following two commands:It will remove your previous Git commit.If you want to keep your changes, you can also use:Then it will save your changes.",
                "If you want to \"uncommit\", erase the last commit message, and put the modified files back in staging, you would use the command:This is an extremely useful command in situations where you committed the wrong thing and you want to undo that last commit.Source: http://nakkaya.com/2009/09/24/git-delete-last-commit/",
                "The best way is:This will reset the branch to the specific commit and then will upload the remote server with the same commits as you have in local.Be careful with the --force flag as it removes all the subsequent commits after the selected commit without the option to recover them.",
                "I have tried a lot of ways to revert local changes in Git, and it seems that this works the best if you just want to revert to the latest commit state.Short description:I found a much more convenient and simple way to achieve the results above:where HEAD points to the latest commit at you current branch.It is the same code code as boulder_ruby suggested, but I have added git add . before  git reset --hard HEAD to erase all new files created since the last commit since this is what most people expect I believe when reverting to the latest commit.",
                "OK, going back to a previous commit in Git is quite easy...Revert back without keeping the changes:Revert back with keeping the changes:Explanation: using git reset, you can reset to a specific state. It's common using it with a commit hash as you see above.But as you see the difference is using the two flags --soft and --hard, by default git reset using --soft flag, but it's a good practice always using the flag, I explain each flag:The default flag as explained, not need to provide it, does not change the working tree, but it adds all changed files ready to commit, so you go back to the commit status which changes to files get unstaged.Be careful with this flag. It resets the working tree and all changes to tracked files and all will be gone!I also created the image below that may happen in a real life working with Git:",
                "Assuming you're talking about master and on that respective branch (that said, this could be any working branch you're concerned with):I found the answer from in a blog post (now no longer exists)Note that this is Resetting and Forcing the change to the remote, so that if others on your team have already git pulled, you will cause problems for them. You are destroying the change history, which is an important reason why people use git in the first place.Better to use revert (see other answers) than reset. \nIf you're a one man team then it probably doesn't matter.",
                "Jefromi's solutions are definitely the best ones, and you should definitely use them. However, for the sake of completeness, I also wanted to show these other alternative solutions that can also be used to revert a commit (in the sense that you create a new commit that undoes changes in previous commit, just like what git revert does).To be clear, these alternatives are not the best way to revert commits, Jefromi's solutions are, but I just want to point out that you can also use these other methods to achieve the same thing as git revert.This is a very slightly modified version of Charles Bailey's solution to Revert to a commit by a SHA hash in Git?:This basically works by using the fact that soft resets will leave the state of the previous commit staged in the index/staging-area, which you can then commit.This solution comes from svick's solution to Checkout old commit and make it a new commit:Similarly to alternative #1, this reproduces the state of <commit> in the current working copy. It is necessary to do git rm first because git checkout won't remove files that have been added since <commit>.",
                "Say you have the following commits in a text file named ~/commits-to-revert.txt (I used git log --pretty=oneline to get them)Create a Bash shell script to revert each of them:This reverts everything back to the previous state, including file and directory creations, and deletions, commit it to your branch and you retain the history, but you have it reverted back to the same file structure. Why Git doesn't have a git revert --to <hash> is beyond me.",
                "Here is a much simpler way to go back to a previous commit (and have it in an uncommited state, to do with it whatever you like):So, no need for commit ids and so on :)",
                "You can complete all these initial steps yourself and push back to the Git repository.Pull the latest version of your repository from Bitbucket using the git pull --all command.Run the Git log command with -n 4 from your terminal. The number after the -n determines the number of commits in the log starting from the most recent commit in your local history.Reset the head of your repository's history using the git reset --hard HEAD~N where N is the number of commits you want to take the head back. In the following example the head would be set back one commit, to the last commit in the repository history:Push the change to Git repository using git push --force to force push the change.If you want the Git repository to a previous commit:-",
                "Caution! This command can cause losing commit history, if user put the wrong commit mistakenly. Always have en extra backup of your git some\nwhere else just in case if you do mistakes, than you are a bit safer.\n:)I have had a similar issue and wanted to revert back to an earlier commit. In my case I was not interested to keep the newer commit, hence I used Hard.This is how I did it:This will revert on the local repository, and here after using git push -f will update the remote repository.For instance, if you want to completely ignore the commit with the name enforce non-group manage policies from the next imageyou'd runfollowed byAfter, you won't see that commit (enforce non-group manage policies) there",
                "After all the changes, when you push all these commands, you might have to use:And not only git push.",
                "Revert is the command to rollback the commits.Sample:It is capable of taking range from the HEAD like below. Here 1 says \"revert last commit.\"And then do:",
                "There is a command (not a part of core Git, but it is in the git-extras package) specifically for reverting and staging old commits:Per the man page, it can also be used as such:",
                "If the situation is an urgent one, and you just want to do what the questioner asked in a quick and dirty way, assuming your project is under a directory called, for example, \"my project\":QUICK AND DIRTY: depending on the circumstances, quick and dirty may in fact be very GOOD. What my solution here does is NOT replace irreversibly the files you have in your working directory with files hauled up/extracted from the depths of the git repository lurking beneath your .git/ directory using fiendishly clever and diabolically powerful git commands, of which there are many. YOU DO NOT HAVE TO DO SUCH DEEP-SEA DIVING TO RECOVER what may appear to be a disastrous situation, and attempting to do so without sufficient expertise may prove fatal.Copy the whole directory and call it something else, like \"my project - copy\". Assuming your git repository (\"repo\") files are under the \"my project\" directory (the default place for them, under a directory called \".git\"), you will now have copied both your work files and your repo files.Do this in the directory \"my project\":This will return the state of the repo under \"my project\" to what it was when you made that commit (a \"commit\" means a snapshot of your working files). All commits since the \"resetted\" commit will be lost forever under \"my project\", BUT... they will still be present in the repo under \"my project - copy\" since you copied all those files - including the ones in the repo, under .../.git/.You then have two versions on your system... you can examine or copy or modify files of interest, or whatever, from the previous commit. You can completely discard the files under \"my project - copy\", if you have decided the new work since the restored commit was going nowhere...The obvious thing if you want to carry on with the state of the project without actually discarding the work since this retrieved commit is to rename your directory again: Delete the project containing the retrieved commit (or give it a temporary name) and rename your \"my project - copy\" directory back to \"my project\". Then maybe try to understand some of the other answers here, and probably do another commit fairly soon.Git is a brilliant creation but absolutely no-one is able to just \"pick it up on the fly\": also people who try to explain it far too often assume prior knowledge of other VCS [Version Control Systems] and delve far too deep far too soon, and commit other terrible crimes, like using interchangeable terms for \"checking out\" - in ways which sometimes appear almost calculated to confuse a beginner.To save yourself much stress, learn from my scars. You have to pretty much have to read a book on Git - I'd recommend reading THE BOOK, Pro Git 2nd edition: available for free download etc. from git central. Published 2014 but, as at early 2022, still the best. Do it sooner rather than later: Git is destined to be part of your life from now on. If you do, bear in mind that much of the complexity of Git comes from branching and then remerging: the Pro Git book actually introduces this central aspect very gently, but you can skip those parts in any book on your first read. From your question there's no reason why people should be blinding you with science.Especially if, for example, this is a desperate situation and you're a newbie with Git!PS: (slight caution) One other thought: It is (now) actually quite simple to keep the Git repo in a directory other than the one with the working files. This would mean you would not copy the entire Git repository using the above quick & dirty solution. See the answer by Fryer using --separate-git-dir here. Bearing that in mind, be warned: If you have a \"separate-directory\" repository which you don't copy, and you do a hard reset, all versions subsequent to the reset commit really will be lost forever forever, unless you have, as you absolutely should, regularly backed up your repository, preferably to the Cloud (e.g. Google Drive) among other places.On this subject of \"backing up to the Cloud\", the next step is to open an account (free of course) with GitHub or (better in my view) GitLab. You can then regularly do a git push command to make your Cloud repo up-to-date \"properly\". But again, talking about this may be too much too soon: git push has to be configured, can fail to work for a totally baffling technical reason, involves learning about remote repos (\"origin\", etc). So a quick-and-dirty Cloud-based backup approach may be preferable until you become knowledgeable. Again, the Pro Git book introduces how remote repositories work, and relate to your local repo, very gently and rationally.",
                "Try resetting to the desired commit:To check COMMIT_ID use:This will reset all changed files to un-added state.Now you can checkout all un-added files byTo verify your changes use:UPDATEIf you have one and only commit in your repo, try",
                "Select your required commit, and check it bytill you get the required commit. To make the HEAD point to that, door git reset --hard HEAD~2 or whatever.",
                "Revert to most recent commit and ignoring all local changes:",
                "Idea: You basically want to replace the current working tree state with the one from a previous commit and then create a commit out of it. Ignored files should best be not changed. Here is how:Emtpy the working tree *.Bring the working tree in the state we want **.Create the revert commit.At first I thought that Yarins answer would be the best, but it doesn't work for merge commits. This solution does.Additionally it does not delete anything (pushed or upushed) from the history. It produces one clean commit which represents the state we want to revert back to.* by removing untracked but not ignored files (the ones specified in .gitignore) from working tree. The working tree is empty except for the ignored files which we wanted to keep (if not specifiy -x option for clean)** When a path is specified (here: .), checkout leaves HEAD alone.",
                "It directly clears all the changes that you have been making since the last commit.PS: It has a little problem; it also deletes all you recently stored stash changes. Which I guess in most cases should not matter.",
                "To completely clean a coder's directory up from some accidental changes, we used:Just git reset --hard HEAD will get rid of modifications, but it won't get rid of \"new\" files. In their case they'd accidentally dragged an important folder somewhere random, and all those files were being treated as new by Git, so a reset --hard didn't fix it. By running the git add -A . beforehand, it explicitly tracked them all with git, to be wiped out by the reset.",
                "I believe some people may come to this question wanting to know how to rollback committed changes they've made in their master - ie throw everything away and go back to origin/master, in which case, do this:https://superuser.com/questions/273172/how-to-reset-master-to-origin-master",
                "To keep the changes from the previous commit to HEAD and move to the previous commit, do:If changes are not required from the previous commit to HEAD and just discard all changes, do:",
                "As your commits are pushed remotely, you need to remove them. Let me assume your branch is develop and it is pushed over origin.You first need to remove develop from origin:Then you need to get develop to the status you want, let me assume the commit hash is EFGHIJK:Lastly, push develop again:",
                "If you want to correct some error in the last commit a good alternative would be using git commit --amend command. If the last commit is not pointed by any reference, this will do the trick, as it create a commit with the same parent as the last commit. If there is no reference to the last commit, it will simply be discarded and this commit will be the last commit. This is a good way of correcting commits without reverting commits. However it has its own limitations."
            ]
        },
        {
            "tag": "",
            "question": [
                "Is Java \"pass-by-reference\" or \"pass-by-value\"?",
                "I always thought Java uses pass-by-reference.\nHowever, I've seen a blog post that claims that Java uses pass-by-value.\nI don't think I understand the distinction they're making.\nWhat is the ..."
            ],
            "url": "https://stackoverflow.com/questions/40480",
            "answer": [
                "The terms \"pass-by-value\" and \"pass-by-reference\" have special, precisely defined meanings in computer science. These meanings differ from the intuition many people have when first hearing the terms. Much of the confusion in this discussion seems to come from this fact.The terms \"pass-by-value\" and \"pass-by-reference\" are talking about variables. Pass-by-value means that the value of a variable is passed to a function/method. Pass-by-reference means that a reference to that variable is passed to the function. The latter gives the function a way to change the contents of the variable.By those definitions, Java is always pass-by-value.  Unfortunately, when we deal with variables holding objects we are really dealing with object-handles called references which are passed-by-value as well.  This terminology and semantics easily confuse many beginners.It goes like this:In the example above aDog.getName() will still return \"Max\". The value aDog within main is not changed in the function foo with the Dog \"Fifi\" as the object reference is passed by value. If it were passed by reference, then the aDog.getName() in main would return \"Fifi\" after the call to foo.Likewise:In the above example, Fifi is the dog's name after call to foo(aDog) because the object's name was set inside of foo(...). Any operations that foo performs on d are such that, for all practical purposes, they are performed on aDog, but it is not possible to change the value of the variable aDog itself.For more information on pass by reference and pass by value, consult the following answer: https://stackoverflow.com/a/430958/6005228. This explains more thoroughly the semantics and history behind the two and also explains why Java and many other modern languages appear to do both in certain cases.",
                "I just noticed you referenced my article.The Java Spec says that everything in Java is pass-by-value. There is no such thing as \"pass-by-reference\" in Java.The key to understanding this is that something likeis not a Dog; it's actually a pointer to a Dog. The use of the term \"reference\" in Java is very misleading and is what causes most of the confusion here. What they call \"references\" act/feel more like what we'd call \"pointers\" in most other languages.What that means, is when you haveyou're essentially passing the address of the created Dog object to the foo method.(I say essentially because Java pointers/references aren't direct addresses, but it's easiest to think of them that way.)Suppose the Dog object resides at memory address 42. This means we pass 42 to the method.if the Method were defined aslet's look at what's happening.Now let's think about what happens outside the method:Did myDog change?There's the key.Keeping in mind that myDog is a pointer, and not an actual Dog, the answer is NO. myDog still has the value 42; it's still pointing to the original Dog (but note that because of line \"AAA\", its name is now \"Max\" - still the same Dog; myDog's value has not changed.)It's perfectly valid to follow an address and change what's at the end of it; that does not change the variable, however.Java works exactly like C. You can assign a pointer, pass the pointer to a method, follow the pointer in the method and change the data that was pointed to. However, the caller will not see any changes you make to where that pointer points. (In a language with pass-by-reference semantics, the method function can change the pointer and the caller will see that change.)In C++, Ada, Pascal and other languages that support pass-by-reference, you can actually change the variable that was passed.If Java had pass-by-reference semantics, the foo method we defined above would have changed where myDog was pointing when it assigned someDog on line BBB.Think of reference parameters as being aliases for the variable passed in. When that alias is assigned, so is the variable that was passed in.A discussion in the comments warrants some clarification...In C, you can writeThis is not a special case in C. Both languages use pass-by-value semantics. Here the call site is creating additional data structure to assist the function to access and manipulate data.The function is being passed pointers to data, and follows those pointers to access and modify that data.A similar approach in Java, where the caller sets up assisting structure, might be:(or if you wanted both examples to demonstrate features the other language doesn't have, create a mutable IntWrapper class to use in place of the arrays)In these cases, both C and Java are simulating pass-by-reference. They're still both passing values (pointers to ints or arrays), and following those pointers inside the called function to manipulate the data.Pass-by-reference is all about the function declaration/definition, and how it handles its parameters. Reference semantics apply to every call to that function, and the call site only needs to pass variables, no additional data structure.These simulations require the call site and the function to cooperate. No doubt it's useful, but it's still pass-by-value.",
                "Java always passes arguments by value, NOT by reference.Let me explain this through an example:I will explain this in steps:Declaring a reference named f of type Foo and assign it a new object of type Foo with an attribute \"f\".From the method side, a reference of type Foo with a name a is declared and it's initially assigned null.As you call the method changeReference, the reference a will be assigned the object which is passed as an argument.Declaring a reference named b of type Foo and assign it a new object of type Foo with an attribute \"b\".a = b makes a new assignment to the reference a, not f, of the object whose attribute is \"b\".As you call modifyReference(Foo c) method, a reference c is created and assigned the object with attribute \"f\".c.setAttribute(\"c\"); will change the attribute of the object that reference c points to it, and it's the same object that reference f points to it.I hope you understand now how passing objects as arguments works in Java :)",
                "Java is always pass by value, with no exceptions, ever.So how is it that anyone can be at all confused by this, and believe that Java is pass by reference, or think they have an example of Java acting as pass by reference? The key point is that Java never provides direct access to the values of objects themselves, in any circumstances. The only access to objects is through a reference to that object. Because Java objects are always accessed through a reference, rather than directly, it is common to talk about fields and variables and method arguments as being objects, when pedantically they are only references to objects. The confusion stems from this (strictly speaking, incorrect) change in nomenclature.So, when calling a methodSo if you have doSomething(foo) and public void doSomething(Foo foo) { .. } the two Foos have copied references that point to the same objects.Naturally, passing by value a reference to an object looks very much like (and is indistinguishable in practice from) passing an object by reference.",
                "This will give you some insights of how Java really works to the point that in your next discussion about Java passing by reference or passing by value you'll just smile :-)Step one please erase from your mind that word that starts with 'p' \"_ _ _ _ _ _ _\", especially if you come from other programming languages. Java and 'p' cannot be written in the same book, forum, or even txt.Step two remember that when you pass an Object into a method you're passing the Object reference and not the Object itself.Now think of what an Object's reference/variable does/is:In the following (please don't try to compile/execute this...):What happens?A picture is worth a thousand words:Note that the anotherReferenceToTheSamePersonObject arrows is directed towards the Object and not towards the variable person!If you didn't get it then just trust me and remember that it's better to say that Java is pass by value. Well, pass by reference value. Oh well, even better is pass-by-copy-of-the-variable-value! ;)Now feel free to hate me but note that given this there is no difference between passing primitive data types and Objects when talking about method arguments.You always pass a copy of the bits of the value of the reference!Java is pass-by-value because inside a method you can modify the referenced Object as much as you want but no matter how hard you try you'll never be able to modify the passed variable that will keep referencing (not p _ _ _ _ _ _ _) the same Object no matter what!The changeName function above will never be able to modify the actual content (the bit values) of the passed reference. In other word changeName cannot make Person person refer to another Object.Of course you can cut it short and just say that  Java is pass-by-value!",
                "Java passes references by value.So you can't change the reference that gets passed in.",
                "I feel like arguing about \"pass-by-reference vs pass-by-value\" is not super-helpful.If you say, \"Java is pass-by-whatever (reference/value)\", in either case, you're not provide a complete answer. Here's some additional information that will hopefully aid in understanding what's happening in memory.Crash course on stack/heap before we get to the Java implementation:\nValues go on and off the stack in a nice orderly fashion, like a stack of plates at a cafeteria.\nMemory in the heap (also known as dynamic memory) is haphazard and disorganized. The JVM just finds space wherever it can, and frees it up as the variables that use it are no longer needed.Okay. First off, local primitives go on the stack. So this code:results in this:When you declare and instantiate an object. The actual object goes on the heap. What goes on the stack? The address of the object on the heap. C++ programmers would call this a pointer, but some Java developers are against the word \"pointer\". Whatever. Just know that the address of the object goes on the stack.Like so:An array is an object, so it goes on the heap as well. And what about the objects in the array? They get their own heap space, and the address of each object goes inside the array.So, what gets passed in when you call a method? If you pass in an object, what you're actually passing in is the address of the object. Some might say the \"value\" of the address, and some say it's just a reference to the object. This is the genesis of the holy war between \"reference\" and \"value\" proponents. What you call it isn't as important as that you understand that what's getting passed in is the address to the object.One String gets created and space for it is allocated in the heap, and the address to the string is stored on the stack and given the identifier hisName, since the address of the second String is the same as the first, no new String is created and no new heap space is allocated, but a new identifier is created on the stack. Then we call shout(): a new stack frame is created and a new identifier, name is created and assigned the address of the already-existing String.So, value, reference? You say \"potato\".",
                "Basically, reassigning Object parameters doesn't affect the argument, e.g.,will print out \"Hah!\" instead of null. The reason this works is because bar is a copy of the value of baz, which is just a reference to \"Hah!\". If it were the actual reference itself, then foo would have redefined baz to null.",
                "Just to show the contrast, compare the following C++ and Java snippets:In C++: Note: Bad code - memory leaks!  But it demonstrates the point.In Java,Java only has the two types of passing: by value for built-in types, and by value of the pointer for object types.",
                "Java passes references to objects by value.",
                "I can't believe that nobody mentioned Barbara Liskov yet. When she designed CLU in 1974, she ran into this same terminology problem, and she invented the term call by sharing (also known as call by object-sharing and call by object) for this specific case of \"call by value where the value is a reference\".",
                "The crux of the matter is that the word reference in the expression \"pass by reference\" means something completely different from the usual meaning of the word reference in Java.Usually in Java reference means a a reference to an object. But the technical terms pass by reference/value from programming language theory is talking about a reference to the memory cell holding the variable, which is something completely different.",
                "There are already great answers that cover this. I wanted to make a small contribution by sharing a very simple example (which will compile) contrasting the behaviors between Pass-by-reference in c++ and Pass-by-value in Java.A few points:C++ pass by reference example:Java pass \"a Java reference\" by value exampleEDITSeveral people have written comments which seem to indicate that either they are not looking at my examples or they don't get the c++ example. Not sure where the disconnect is, but guessing the c++ example is not clear. I'm posting the same example in pascal because I think pass-by-reference looks cleaner in pascal, but I could be wrong. I might just be confusing people more; I hope not.In pascal, parameters passed-by-reference are called \"var parameters\". In the procedure setToNil below, please note the keyword 'var' which precedes the parameter 'ptr'. When a pointer is passed to this procedure, it will be passed by reference. Note the behavior: when this procedure sets ptr to nil (that's pascal speak for NULL), it will set the argument to nil--you can't do that in Java.EDIT 2Some excerpts from \"THE Java Programming Language\" by Ken Arnold, James Gosling (the guy who invented Java), and David Holmes, chapter 2, section 2.6.5All parameters to methods are passed \"by value\". In other words,\nvalues of parameter variables in a method are copies of the invoker\nspecified as arguments.He goes on to make the same point regarding objects . . .You should note that when the parameter is an object reference, it is\nthe object reference-not the object itself-that is passed \"by value\".And towards the end of the same section he makes a broader statement about java being only pass by value and never pass by reference.The Java programming language does not pass objects by reference; it\npasses object references by value. Because two copies of the same\nreference refer to the same actual object, changes made through one\nreference variable are visible through the other. There is exactly one\nparameter passing mode-pass by value-and that helps keep things\nsimple.This section of the book has a great explanation of parameter passing in Java and of the distinction between pass-by-reference and pass-by-value and it's by the creator of Java. I would encourage anyone to read it, especially if you're still not convinced.I think the difference between the two models is very subtle and unless you've done programming where you actually used pass-by-reference, it's easy to miss where two models differ.I hope this settles the debate, but probably won't.EDIT 3I might be a little obsessed with this post. Probably because I feel that the makers of Java inadvertently spread misinformation. If instead of using the word \"reference\" for pointers they had used something else, say\ndingleberry, there would've been no problem. You could say, \"Java passes dingleberries by value and not by reference\", and nobody would be confused.That's the reason only Java developers have issue with this. They look at the word \"reference\" and think they know exactly what that means, so they don't even bother to consider the opposing argument.Anyway, I noticed a comment in an older post, which made a balloon analogy which I really liked. So much so that I decided to glue together some clip-art to make a set of cartoons to illustrate the point.Passing a reference by value--Changes to the reference are not reflected in the caller's scope, but the changes to the object are. This is because the reference is copied, but the both the original and the copy refer to the same object.Pass by reference--There is no copy of the reference. Single reference is shared by both the caller and the function being called. Any changes to the reference or the Object's data are reflected in the caller's scope.EDIT 4I have seen posts on this topic which describe the low level implementation of parameter passing in Java, which I think is great and very helpful because it makes an abstract idea concrete. However, to me the question is more about the behavior described in the language specification than about the technical implementation of the behavior. This is an exerpt from the Java Language Specification, section 8.4.1 :When the method or constructor is invoked (\u00a715.12), the values of the\nactual argument expressions initialize newly created parameter\nvariables, each of the declared type, before execution of the body of\nthe method or constructor. The Identifier that appears in the\nDeclaratorId may be used as a simple name in the body of the method or\nconstructor to refer to the formal parameter.Which means, java creates a copy of the passed parameters before executing a method. Like most people who studied compilers in college, I used \"The Dragon Book\" which is THE compilers book. It has a good description of \"Call-by-value\" and \"Call-by-Reference\" in Chapter 1. The Call-by-value description matches up with Java Specs exactly.Back when I studied compilers-in the 90's, I used the first edition of the book from 1986 which pre-dated Java by about 9 or 10 years. However, I just ran across a copy of the 2nd Eddition from 2007 which actually mentions Java! Section 1.6.6 labeled \"Parameter Passing Mechanisms\" describes parameter passing pretty nicely. Here is an excerpt under the heading \"Call-by-value\" which mentions Java:In call-by-value, the actual parameter is evaluated (if it is an\nexpression) or copied (if it is a variable). The value is placed in\nthe location belonging to the corresponding formal parameter of the\ncalled procedure. This method is used in C and Java, and is a common\noption in C++ , as well as in most other languages.",
                "In java everything is reference, so when you have something like:\n    Point pnt1 = new Point(0,0); Java does following:Java doesn't pass method arguments by reference; it passes them by value. I will use example from this site:Flow of the program:Creating two different Point object with two different reference associated.As expected output will be:On this line 'pass-by-value' goes into the play...References pnt1 and pnt2 are passed by value to the tricky method, which means that now yours references pnt1 and pnt2 have their copies named arg1 and arg2.So pnt1 and arg1 points to the same object. (Same for the pnt2 and arg2)In the tricky method:Next in the tricky methodHere, you first create new temp Point reference which will point on same place like arg1 reference. Then you move reference arg1 to point to the same place like arg2 reference.\nFinally arg2 will point to the same place like temp.From here scope of tricky method is gone and you don't have access any more to the references: arg1, arg2, temp. But important note is that everything you do with these references when they are 'in life' will permanently affect object on which they are point to.So after executing method tricky, when you return to main, you have this situation:So now, completely execution of program will be:",
                "Java is always pass by value, not pass by referenceFirst of all, we need to understand what pass by value and pass by reference are.Pass by value means that you are making a copy in memory of the actual parameter's value that is passed in. This is a copy of the contents of the actual parameter.Pass by reference (also called pass by address) means that a copy of the address of the actual parameter is stored.Sometimes Java can give the illusion of pass by reference. Let's see how it works by using the example below:The output of this program is:Let's understand step by step:As we all know it will create an object in the heap and return the reference value back to t. For example, suppose the value of t is 0x100234 (we don't know the actual JVM internal value, this is just an example) .When passing reference t to the function it will not directly pass the actual reference value of object test,  but it will create a copy of t and then pass it to the function. Since it is passing by value, it passes a copy of the variable rather than the actual reference of it. Since we said the value of t was 0x100234, both t and f will have the same value and hence they will point to the same object.If you change anything in the function using reference f it will modify the existing contents of the object. That is why we got the output changevalue,   which is updated in the function.To understand this more clearly, consider the following example:Will this throw a NullPointerException? No, because it only passes a copy of the reference.\nIn the case of passing by reference, it could have thrown a NullPointerException, as seen below:Hopefully this will help.",
                "Java is a pass by value(stack memory)How it worksLet's first understand that where java stores primitive data type and object data type.Primitive data types itself and object references are stored in the stack.\nObjects themselves are stored in the heap.It means, Stack memory stores primitive data types and also the\naddresses of objects.And you always pass a copy of the bits of the value of the reference.If it's a primitive data type then these copied bits contain the value of the primitive data type itself, That's why when we change the value of argument inside the method then it does not reflect the changes outside.If it's an object data type like Foo foo=new Foo() then in this case copy of the address of the object passes like file shortcut  , suppose we have a text file abc.txt at C:\\desktop and suppose we make shortcut of the same file and put this inside C:\\desktop\\abc-shortcut so when you access the file from C:\\desktop\\abc.txt and write 'Stack Overflow' and close the file and again you open the file from shortcut then you write ' is the largest online community for programmers to learn' then total file change will be 'Stack Overflow is the largest online community for programmers to learn' which means it doesn't matter from where you open the file , each time we were accessing the same file , here we can assume Foo as a file and suppose foo stored at 123hd7h(original address like C:\\desktop\\abc.txt ) address and 234jdid(copied address like C:\\desktop\\abc-shortcut which actually contains the original address of the file inside) ..\nSo for better understanding make shortcut file and feel.",
                "Getting an outside of the box view, let's look at Assembly or some low level memory management. At the CPU level a reference to anything immediately becomes a value if it gets written to memory or to one of the CPU registers. (That is why pointer is a good definition. It is a value, which has a purpose at the same time).Data in memory has a Location and at that location there is a value (byte,word, whatever). In Assembly we have a convenient solution to give a Name to certain Location (aka variable), but when compiling the code, the assembler simply replaces Name with the designated location just like your browser replaces domain names with IP addresses.Down to the core it is technically impossible to pass a reference to anything in any language without representing it (when it immediately becomes a value).Lets say we have a variable Foo, its Location is at the 47th byte in memory and its Value is 5. We have another variable Ref2Foo which is at 223rd byte in memory, and its value will be 47. This Ref2Foo might be a technical variable, not explicitly created by the program. If you just look at 5 and 47 without any other information, you will see just two Values.\nIf you use them as references then to reach to 5 we have to travel:This is how jump-tables work.If we want to call a method/function/procedure with Foo's value, there are a few possible way to pass the variable to the method, depending on the language and its several method invocation modes:In every cases above a value - a copy of an existing value - has been created, it is now upto the receiving method to handle it. When you write \"Foo\" inside the method, it is either read out from EAX, or automatically  dereferenced, or double dereferenced, the process depends on how the language works and/or what the type of Foo dictates. This is hidden from the developer until she circumvents the dereferencing process. So a reference is a value when represented, because a reference is a value that has to be processed (at language level).Now we have passed Foo to the method:Nitpicking on insignificant details, even languages that do pass-by-reference will pass values to functions, but those functions know that they have to use it for dereferencing purposes. This pass-the-reference-as-value is just hidden from the programmer because it is practically useless and the terminology is only pass-by-reference.Strict pass-by-value is also useless, it would mean that a 100 Mbyte array should have to be copied every time we call a method with the array as argument, therefore Java cannot be stricly pass-by-value. Every language would pass a reference to this huge array (as a value) and either employs copy-on-write mechanism if that array can be changed locally inside the method or allows the method (as Java does) to modify the array globally (from the caller's view) and a few languages allows to modify the Value of the reference itself.So in short and in Java's own terminology, Java is pass-by-value where value can be: either a real value or a value that is a representation of a reference.",
                "In Java, method arguments are all passed by value :Java arguments are all passed by value (the value  or reference is copied when used by the method) :In the case of primitive types, Java behaviour is simple:\nThe value is copied in another instance of the primitive type.In case of Objects, this is the same:\nObject variables are references (mem buckets holding only Object\u2019s address instead of a primitive value) that was created using the \"new\" keyword, and are copied like primitive types.The behaviour can appear different from primitive types: Because the copied object-variable contains the same address (to the same Object).\nObject's content/members might still be modified within a method and later access outside, giving the illusion that the (containing) Object itself was passed by reference.\"String\" Objects appear to be a good counter-example to the urban legend saying that \"Objects are passed by reference\":In effect, using a method, you will never be able, to update the value of a String passed as argument:A String Object, holds characters by an array declared final that can't be modified.\nOnly the address of the Object might be replaced by another using \"new\".\nUsing \"new\" to update the variable, will not let the Object be accessed from outside, since the variable was initially passed by value and copied.",
                "As far as I know, Java only knows call by value. This means for primitive datatypes you will work with an copy and for objects you will work with an copy of the reference to the objects. However I think there are some pitfalls; for example, this will not work:This will populate Hello World and not World Hello because in the swap function you use copys which have no impact on the references in the main. But if your objects are not immutable you can change it for example:This will populate Hello World on the command line. If you change StringBuffer into String it will produce just Hello because String is immutable. For example:However you could make a wrapper for String like this which would make it able to use it with Strings:edit: i believe this is also the reason to use StringBuffer when it comes to \"adding\" two Strings because you can modifie the original object which u can't with immutable objects like String is.",
                "No, it's not pass by reference.Java is pass by value according to the Java Language Specification:When the method or constructor is invoked (\u00a715.12), the values of the actual argument expressions initialize newly created parameter variables, each of the declared type, before execution of the body of the method or constructor. The Identifier that appears in the DeclaratorId may be used as a simple name in the body of the method or constructor to refer to the formal parameter.",
                "Let me try to explain my understanding with the help of four examples. Java is pass-by-value, and not pass-by-reference/**Pass By ValueIn Java, all parameters are passed by value, i.e. assigning a method argument is not visible to the caller.*/Example 1:ResultExample 2:/**\n * \n * Pass By Value\n *\n */ResultExample 3:/**\n  This 'Pass By Value has a feeling of 'Pass By Reference'Some people say primitive types and 'String' are 'pass by value'\n  and objects are 'pass by reference'.But from this example, we can understand that it is infact pass by value only,\n  keeping in mind that here we are passing the reference as the value.\n  ie: reference is passed by value.\n  That's why are able to change and still it holds true after the local scope.\n  But we cannot change the actual reference outside the original scope.\n  what that means is demonstrated by next example of PassByValueObjectCase2.*/ResultExample 4:/**In addition to what was mentioned in Example3 (PassByValueObjectCase1.java),  we cannot change the actual reference outside the original scope.\"Note: I am not pasting the code for private class Student. The class definition for Student is same as Example3.*/Result",
                "I thought I'd contribute this answer to add more details from the Specifications.First, What's the difference between passing by reference vs. passing by value?Passing by reference means the called functions' parameter will be the\nsame as the callers' passed argument (not the value, but the identityPass by value means the called functions' parameter will be a copy of\nthe callers' passed argument.Or from wikipedia, on the subject of pass-by-referenceIn call-by-reference evaluation (also referred to as\npass-by-reference), a function receives an implicit reference to a\nvariable used as argument, rather than a copy of its value. This\ntypically means that the function can modify (i.e. assign to) the\nvariable used as argument\u2014something that will be seen by its caller.And on the subject of pass-by-valueIn call-by-value, the argument expression is evaluated, and the\nresulting value is bound to the corresponding variable in the function [...].\nIf the function or procedure is able to assign values to its\nparameters, only its local copy is assigned [...].Second, we need to know what Java uses in its method invocations. The Java Language Specification statesWhen the method or constructor is invoked (\u00a715.12), the values of the\nactual argument expressions initialize newly created parameter\nvariables, each of the declared type, before execution of the body of\nthe method or constructor.So it assigns (or binds) the value of the argument to the corresponding parameter variable.What is the value of the argument?Let's consider reference types, the Java Virtual Machine Specification statesThere are three kinds of reference types: class types, array types,\nand interface types. Their values are references to dynamically\ncreated class instances, arrays, or class instances or arrays that\nimplement interfaces, respectively.The Java Language Specification also statesThe reference values (often just references) are pointers to these objects, and a special null reference, which refers to no object.The value of an argument (of some reference type) is a pointer to an object. Note that a variable, an invocation of a method with a reference type return type, and an instance creation expression (new ...) all resolve to a reference type value.Soall bind the value of a reference to a String instance to the method's newly created parameter, param. This is exactly what the definition of pass-by-value describes. As such, Java is pass-by-value.The fact that you can follow the reference to invoke a method or access a field of the referenced object is completely irrelevant to the conversation. The definition of pass-by-reference wasThis typically means that the function can modify (i.e. assign to) the\nvariable used as argument\u2014something that will be seen by its caller.In Java, modifying the variable means reassigning it. In Java, if you reassigned the variable within the method, it would go unnoticed to the caller. Modifying the object referenced by the variable is a different concept entirely.Primitive values are also defined in the Java Virtual Machine Specification, here. The value of the type is the corresponding integral or floating point value, encoded appropriately (8, 16, 32, 64, etc. bits).",
                "You can never pass by reference in Java, and one of the ways that is obvious is when you want to return more than one value from a method call. Consider the following bit of code in C++:Sometimes you want to use the same pattern in Java, but you can't; at least not directly. Instead you could do something like this:As was explained in previous answers, in Java you're passing a pointer to the array as a value into getValues. That is enough, because the method then modifies the array element, and by convention you're expecting element 0 to contain the return value. Obviously you can do this in other ways, such as structuring your code so this isn't necessary, or constructing a class that can contain the return value or allow it to be set. But the simple pattern available to you in C++ above is not available in Java.",
                "The distinction, or perhaps just the way I remember as I used to be under the same impression as the original poster is this: Java is always pass by value. All objects( in Java, anything except for primitives) in Java are references. These references are passed by value.",
                "As many people mentioned it before, Java is always pass-by-valueHere is another example that will help you understand the difference (the classic swap example):Prints:Before: a = 2, b = 3\n  After: a = 2, b = 3This happens because iA and iB are new local reference variables that have the same value of the passed references (they point to a and b respectively). So, trying to change the references of iA or iB will only change in the local scope and not outside of this method.",
                "I always think of it as \"pass by copy\". It is a copy of the value be it primitive or reference. If it is a primitive it is a copy of the bits that are the value and if it is an Object it is a copy of the reference.output of java PassByCopy:name= Maxx\n  name= FidoPrimitive wrapper classes and Strings are immutable so any example using those types will not work the same as other types/objects.",
                "Unlike some other languages, Java does not allow you to choose between pass-by-value and pass-by-reference\u2014all arguments are passed by value. A method call can pass two types of values to a method\u2014copies of primitive values (e.g., values of int and double) and copies of references to objects.When a method modifies a primitive-type parameter, changes to the parameter have no effect on the original argument value in the calling method.When it comes to objects, objects themselves cannot be passed to methods. So we pass the reference(address) of the object. We can manipulate the original object using this reference.How Java creates and stores objects: When we create an object we store the object\u2019s address in a reference variable. Let's analyze the following statement.\u201cAccount account1\u201d is the type and name of the reference variable, \u201c=\u201d is the assignment operator, \u201cnew\u201d asks for the required amount of space from the system. The constructor to the right of keyword new which creates the object is called implicitly by the keyword new. Address of the created object(result of right value, which is an expression called \"class instance creation expression\") is assigned to the left value (which is a reference variable with a name and a type specified) using the assign operator.Although an object\u2019s reference is passed by value, a method can still interact with the referenced object by calling its public methods using the copy of the object\u2019s reference. Since the reference stored in the parameter is a copy of the reference that was passed as an argument, the parameter in the called method and the argument in the calling method refer to the same object in memory.Passing references to arrays, instead of the array objects themselves, makes sense for performance reasons. Because everything in Java is passed by value, if array objects were passed,\na copy of each element would be passed. For large arrays, this would waste time and consume\nconsiderable storage for the copies of the elements.In the image below you can see we have two reference variables(These are called pointers in C/C++, and I think that term makes it easier to understand this feature.) in the main method. Primitive and reference variables are kept in stack memory(left side in images below). array1 and array2 reference variables \"point\" (as C/C++ programmers call it) or reference to a and b arrays respectively, which are objects (values these reference variables hold are addresses of objects) in heap memory (right side in images below).If we pass the value of array1 reference variable as an argument to the reverseArray method, a reference variable is created in the method and that reference variable starts pointing to the same array (a).So, if we sayin reverseArray method, it will make a change in array a.We have another reference variable in reverseArray method (array2) that points to an array c. If we were to sayin reverseArray method, then the reference variable array1 in method reverseArray would stop pointing to array a and start pointing to array c (Dotted line in second image).If we return value of reference variable array2 as the return value of method reverseArray and assign this value to reference variable array1 in main method, array1 in main will start pointing to array c.So let's write all the things we have done at once now.And now that reverseArray method is over, its reference variables(array1 and array2) are gone. Which means we now only have the two reference variables in main method array1 and array2 which point to c and b arrays respectively. No reference variable is pointing to object (array) a. So it is eligible for garbage collection.You could also assign value of array2 in main to array1. array1 would start pointing to b.",
                "Java has only pass by value. A very simple example to validate this.",
                "To make a long story short, Java objects have some very peculiar properties.In general, Java has primitive types (int, bool, char, double, etc) that are passed directly by value. Then Java has objects (everything that derives from java.lang.Object). Objects are actually always handled through a reference (a reference being a pointer that you can't touch). That means that in effect, objects are passed by reference, as the references are normally not interesting. It does however mean that you cannot change which object is pointed to as the reference itself is passed by value.Does this sound strange and confusing? Let's consider how C implements pass by reference and pass by value. In C, the default convention is pass by value. void foo(int x) passes an int by value. void foo(int *x) is a function that does not want an int a, but a pointer to an int: foo(&a). One would use this with the & operator to pass a variable address.Take this to C++, and we have references. References are basically (in this context) syntactic sugar that hide the pointer part of the equation: void foo(int &x) is called by foo(a), where the compiler itself knows that it is a reference and the address of the non-reference a should be passed. In Java, all variables referring to objects are actually of reference type, in effect forcing call by reference for most intends and purposes without the fine grained control (and complexity) afforded by, for example, C++.",
                "I have created a thread devoted to these kind of questions for any programming languages here.Java is also mentioned. Here is the short summary:"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I make Git forget about a file that was tracked, but is now in .gitignore?",
                "I put a file that was previously being tracked by Git onto the .gitignore list. However, the file still shows up in git status after it is edited. How do I force Git to completely forget the file?"
            ],
            "url": "https://stackoverflow.com/questions/1274057",
            "answer": [
                ".gitignore will prevent untracked files from being added (without an add -f) to the set of files tracked by Git. However, Git will continue to track any files that are already being tracked.To stop tracking a file, we must remove it from the index:To remove a folder and all files in the folder recursively:The removal of the file from the head revision will happen on the next commit.WARNING: While this will not remove the physical file from your local machine, it will remove the files from other developers' machines on their next git pull.",
                "The series of commands below will remove all of the items from the Git index (not from the working directory or local repository), and then will update the Git index, while respecting Git ignores. PS. Index = CacheFirst:Then:Or as a one-liner:",
                "git update-index does the job for me:Note: This solution is actually independent of .gitignore as gitignore is only for untracked files.Since this answer was posted, a new option has been created and that should be preferred.  You should use --skip-worktree which is for modified tracked files that the user don't want to commit anymore and keep --assume-unchanged for performance to prevent git to check status of big tracked files. See https://stackoverflow.com/a/13631525/717372 for more details...To cancel",
                "This takes the list of the ignored files, removes them from the index, and commits the changes.",
                "Move it out, commit, and then move it back in.This has worked for me in the past, but there is probably a 'gittier' way to accomplish this.",
                "I always use this command to remove those untracked files.\nOne-line, Unix-style, clean output:It lists all your ignored files, replaces every output line with a quoted line instead to handle paths with spaces inside, and passes everything to git rm -r --cached to remove the paths/files/directories from the index.",
                "The copy/paste answer is:This command will NOT change the content of the .gitignore file. It will just ignore the files that have already been committed to a Git repository but now we have added them to .gitignore.The command git status; is just to review the changes and could be dropped.In the end, it will immediately commit the changes with the message \"Ignore unwanted files\".If you don't want to commit the changes, drop the last part of the command (git commit -m \"Ignore unwanted files\")",
                "Source: Untrack files already added to Git repository based on .gitignoreLet\u2019s say you have already added/committed some files to your Git repository and you then add them to your .gitignore file; these files will still be present in your repository index. This article we will see how to get rid of them.Before proceeding, make sure all your changes are committed, including your .gitignore file.To clear your repository, use:The rm command can be unforgiving. If you wish to try what it does beforehand, add the -n or --dry-run flag to test things out.Your repository is clean :)Push the changes to your remote to see the changes effective there as well.",
                "If you cannot git rm a tracked file because other people might need it (warning, even if you git rm --cached, when someone else gets this change, their files will be deleted in their filesystem).  These are often done due to config file overrides, authentication credentials, etc. Please look at https://gist.github.com/1423106 for ways people have worked around the problem.To summarize:",
                "I accomplished this by using git filter-branch. The exact command I used was taken from the man page:WARNING: this will delete the file from your entire historyThis command will recreate the entire commit history, executing git rm before each commit and so will get rid of the specified file. Don't forget to back it up before running the command as it will be lost.",
                "(Under Linux), I wanted to use the posts here suggesting the ls-files --ignored --exclude-standard | xargs git rm -r --cached approach.  However, (some of) the files to be removed had an embedded newline/LF/\\n in their names.  Neither of the solutions:cope with this situation (get errors about files not found).This uses the -z argument to ls-files, and the -0 argument to xargs to cater safely/correctly for \"nasty\" characters in filenames.In the manual page git-ls-files(1), it states:When -z option is not used, TAB, LF, and backslash characters in\npathnames are represented as \\t, \\n, and \\\\, respectively.so I think my solution is needed if filenames have any of these characters in them.",
                "Do the following steps for a file/folder:Remove a File:For example:I want to delete the test.txt file. I accidentally pushed to GitHub and want to remove it. Commands will be as follows:First, add \"test.txt\" in file .gitignoreRemove Folder:For example:I want to delete the .idea folder/directory. I accidentally pushed to GitHub and want to remove it. The commands will be as follows:First, add .idea in file .gitignore",
                "Update your .gitignore file \u2013 for instance, add a folder you don't want to track to .gitignore.git rm -r --cached . \u2013 Remove all tracked files, including wanted and unwanted. Your code will be safe as long as you have saved locally.git add . \u2013 All files will be added back in, except those in .gitignore.Hat tip to @AkiraYamamoto for pointing us in the right direction.",
                "Do the following steps serially, and you will be fine.Remove the mistakenly added files from the directory/storage. You can use the \"rm -r\" (for Linux) command or delete them by browsing the directories. Or move them to another location on your PC. (You maybe need to close the IDE if running for moving/removing.)Add the files / directories to the .gitignore file now and save it.Now remove them from the Git cache by using these commands (if there is more than one directory, remove them one by one by repeatedly issuing this command)Now do a commit and push by using the following commands. This will remove those files from Git remote and make Git stop tracking those files.",
                "I think, that maybe Git can't totally forget about a file because of its conception (section \"Snapshots, Not Differences\").This problem is absent, for example, when using CVS. CVS stores information as a list of file-based changes. Information for CVS is a set of files and the changes made to each file over time.But in Git every time you commit, or save the state of your project, it basically takes a picture of what all your files look like at that moment and stores a reference to that snapshot. So, if you added file once, it will always be present  in that snapshot.These two articles were helpful for me:git assume-unchanged vs skip-worktree and How to ignore changes in tracked files with GitBasing on it I do the following, if the file is already tracked:From this moment all local changes in this file will be ignored and will not go to remote. If the file is changed on remote, conflict will occur, when git pull. Stash won't work. To resolve it, copy the file content to the safe place and follow these steps:The file content will be replaced by the remote content. Paste your changes from the safe place to the file and perform again:If everyone, who works with the project, will perform git update-index --skip-worktree <file>, problems with pull should be absent. This solution is OK for configurations files, when every developer has their own project configuration.It is not very convenient to do this every time, when the file has been changed on remote, but it can protect it from overwriting by remote content.",
                "Move or copy the file to a safe location, so you don't lose it. Then 'git rm' the file and commit.The file will still show up if you revert to one of those earlier commits, or another branch where it has not been removed. However, in all future commits, you will not see the file again. If the file is in the Git ignore, then you can move it back into the folder, and Git won't see it.",
                "The answer from Matt Frear was the most effective IMHO. The following is just a PowerShell script for those on Windows to only remove files from their Git repository that matches their exclusion list.",
                "Using the git rm --cached command does not answer the original question:How do you force git to completely forget about [a file]?In fact, this solution will cause the file to be deleted in every other instance of the repository when executing a git pull!The correct way to force Git to forget about a file is documented by GitHub here.I recommend reading the documentation, but basically:Just replace full/path/to/file with the full path of the file. Make sure you've added the file to your .gitignore file.You'll also need to (temporarily) allow non-fast-forward pushes to your repository, since you're changing your Git history.",
                "git rm --cached -r <YOUR_files_or_folders>--cached  | only remove files from the index",
                "The accepted answer does not \"make Git \"forget\" about a file...\" (historically).  It only makes Git ignore the file in the present/future.This method makes Git completely forget ignored files (past/present/future), but it does not delete anything from the working directory (even when re-pulled from remote).This method requires usage of file /.git/info/exclude (preferred) or a pre-existing .gitignore in all the commits that have files to be ignored/forgotten. 1All methods of enforcing Git ignore behavior after-the-fact effectively rewrite history and thus have significant ramifications for any public/shared/collaborative repositories that might be pulled after this process. 2General advice: start with a clean repository - everything committed, nothing pending in working directory or index, and make a backup!Also, the comments/revision history of this answer (and revision history of this question) may be useful/enlightening.Finally, follow the rest of this GitHub guide (starting at step 6) which includes important warnings/information about the commands below.Other developers that pull from the now-modified remote repository should make a backup and then:1 Because /.git/info/exclude can be applied to all historical commits using the instructions above, perhaps details about getting a .gitignore file into the historical commit(s) that need it is beyond the scope of this answer.  I wanted a proper .gitignore file to be in the root commit, as if it was the first thing I did.  Others may not care since /.git/info/exclude can accomplish the same thing regardless where the .gitignore file exists in the commit history, and clearly rewriting history is a very touchy subject, even when aware of the ramifications.FWIW, potential methods may include git rebase or a git filter-branch that copies an external .gitignore into each commit, like the answers to this question.2 Enforcing Git ignore behavior after-the-fact by committing the results of a stand-alone git rm --cached command may result in newly-ignored file deletion in future pulls from the force-pushed remote. The --prune-empty flag in the following git filter-branch command avoids this problem by automatically removing the previous \"delete all ignored files\" index-only commit.  Rewriting Git history also changes commit hashes, which will wreak havoc on future pulls from public/shared/collaborative repositories.  Please understand the ramifications fully before doing this to such a repository. This GitHub guide specifies the following:Tell your collaborators to rebase, not merge, any branches they created off of your old (tainted) repository history. One merge commit could reintroduce some or all of the tainted history that you just went to the trouble of purging.Alternative solutions that do not affect the remote repository are git update-index --assume-unchanged </path/file> or git update-index --skip-worktree <file>, examples of which can be found here.",
                "In my case I needed to put \".envrc\" in the .gitignore file.And then I used:And the file was removed.Then I committed again, telling that the file was removed.But when I used the command git log -p, the content of the file (which was secret credentials of the Amazon S3) was showing the content which was removed and I don't want to show this content ever on the history of the Git repository.Then I used this command:And I don't see the content again.",
                "I liked JonBrave's answer, but I have messy enough working directories that commit -a scares me a bit, so here's what I've done:Breaking it down:",
                "The BFG is specifically designed for removing unwanted data like big files or passwords from Git repositories, so it has a simple flag that will remove any large historical (not-in-your-current-commit) files: '--strip-blobs-bigger-than'If you'd like to specify files by name, you can do that too:The BFG is 10-1000x faster than git filter-branch and is generally much easier to use - check the full usage instructions and examples for more details.Source: Reduce repository size",
                "If you don't want to use the CLI and are working on Windows, a very simple solution is to use TortoiseGit. It has the \"Delete (keep local)\" Action in the menu which works fine.",
                "This is no longer an issue in the latest Git (v2.17.1 at the time of writing).The .gitignore file finally ignores tracked-but-deleted files. You can test this for yourself by running the following script. The final git status statement should report \"nothing to commit\".",
                "This is how I solved my issue:git filter-branch --tree-filter 'rm -rf path/to/your/file' HEAD\n git pushIn this, we are basically trying to rewrite the history of that particular file in previous commits also.For more information, you can refer to the man page of filter-branch here.Source: Removing sensitive data from a repository - using filter-branchSource: Git: How to remove a big file wrongly committed",
                "In case of already committed DS_Store:Ignore them by:Finally, make a commit!",
                "Especially for the IDE-based files, I use this:For instance, for the slnx.sqlite file, I just got rid off it completely like the following:Just keep that in mind that some of those files store some local user settings and preferences for projects (like what files you had open). So every time you navigate or do some changes in your IDE, that file is changed and therefore it checks it out and show as uncommitted changes.",
                "If anyone is having a hard time on Windows and you want to ignore the entire folder, go to the desired 'folder' on file explorer, right click and do 'Git Bash Here' (Git for Windows should have been installed).Run this command:",
                "For me, the file was still available in the history and I first needed to squash the commits that added the removed files: https://gist.github.com/patik/b8a9dc5cd356f9f6f980"
            ]
        },
        {
            "tag": "",
            "question": [
                "Does Python have a ternary conditional operator?",
                "Is there a ternary conditional operator in Python?"
            ],
            "url": "https://stackoverflow.com/questions/394809",
            "answer": [
                "Yes, it was added in version 2.5. The expression syntax is:First condition is evaluated, then exactly one of either a or b is evaluated and returned based on the Boolean value of condition. If condition evaluates to True, then a is evaluated and returned but b is ignored, or else when b is evaluated and returned but a is ignored.This allows short-circuiting because when condition is true only a is evaluated and b is not evaluated at all, but when condition is false only b is evaluated and a is not evaluated at all.For example:Note that conditionals are an expression, not a statement. This means you can't use statements such as pass, or assignments with = (or \"augmented\" assignments like +=), within a conditional expression:(In 3.8 and above, the := \"walrus\" operator allows simple assignment of values as an expression, which is then compatible with this syntax. But please don't write code like that; it will quickly become very difficult to understand.)Similarly, because it is an expression, the else part is mandatory:You can, however, use conditional expressions to assign a variable like so:Or for example to return a value:Think of the conditional expression as switching between two values. We can use it when we are in a 'one value or another' situation, where we will do the same thing with the result, regardless of whether the condition is met. We use the expression to compute the value, and then do something with it. If you need to do something different depending on the condition, then use a normal if statement instead.Keep in mind that it's frowned upon by some Pythonistas for several reasons:If you're having trouble remembering the order, then remember that when read aloud, you (almost) say what you mean. For example, x = 4 if b > 8 else 9 is read aloud as x will be 4 if b is greater than 8 otherwise 9.Official documentation:",
                "You can index into a tuple:test needs to return True or False.\nIt might be safer to always implement it as:or you can use the built-in bool() to assure a Boolean value:",
                "For versions prior to 2.5, there's the trick:It can give wrong results when on_true has a false Boolean value.1Although it does have the benefit of evaluating expressions left to right, which is clearer in my opinion.1. Is there an equivalent of C\u2019s \u201d?:\u201d ternary operator?",
                "<expression 1> if <condition> else <expression 2>",
                "From the documentation:Conditional expressions (sometimes called a \u201cternary operator\u201d) have the lowest priority of all Python operations.The expression x if C else y first evaluates the condition, C (not x); if C is true, x is evaluated and its value is returned; otherwise, y is evaluated and its value is returned.See PEP 308 for more details about conditional expressions.New since version 2.5.",
                "An operator for a conditional expression in Python was added in 2006 as part of Python Enhancement Proposal 308. Its form differ from common ?: operator and it's:which is equivalent to:Here is an example:Another syntax which can be used (compatible with versions before 2.5):where operands are lazily evaluated.Another way is by indexing a tuple (which isn't consistent with the conditional operator of most other languages):or explicitly constructed dictionary:Another (less reliable), but simpler method is to use and and or operators:however this won't work if x would be False.A possible workaround is to make x and y lists or tuples as in the following:or:If you're working with dictionaries, instead of using a ternary conditional, you can take advantage of get(key, default), for example:Source: ?: in Python at Wikipedia",
                "Unfortunately, thesolution doesn't have short-circuit behaviour; thus both falseValue and trueValue are evaluated regardless of the condition. This could be suboptimal or even buggy (i.e. both trueValue and falseValue could be methods and have side effects).One solution to this would be(execution delayed until the winner is known ;)), but it introduces inconsistency between callable and non-callable objects. In addition, it doesn't solve the case when using properties.And so the story goes - choosing between three mentioned solutions is a trade-off between having the short-circuit feature, using at least Python 2.5 (IMHO, not a problem anymore) and not being prone to \"trueValue-evaluates-to-false\" errors.",
                "Here I just try to show some important differences in the ternary operator between a couple of programming languages.",
                "For Python 2.5 and newer there is a specific syntax:In older Pythons a ternary operator is not implemented but it's possible to simulate it.Though, there is a potential problem, which if cond evaluates to True and on_true evaluates to False then on_false is returned instead of on_true. If you want this behavior the method is OK, otherwise use this:which can be wrapped by:and used this way:It is compatible with all Python versions.",
                "You might often findbut this leads to a problem when on_true == 0Where you would expect this result for a normal ternary operator:",
                "Yes. From the grammar file:The part of interest is:So, a ternary conditional operation is of the form:expression3 will be lazily evaluated (that is, evaluated only if expression2 is false in a boolean context). And because of the recursive definition, you can chain them indefinitely (though it may considered bad style.)Note that every if must be followed with an else. People learning list comprehensions and generator expressions may find this to be a difficult lesson to learn - the following will not work, as Python expects a third expression for an else:which raises a SyntaxError: invalid syntax.\nSo the above is either an incomplete piece of logic (perhaps the user expects a no-op in the false condition) or what may be intended is to use expression2 as a filter - notes that the following is legal Python:expression2 works as a filter for the list comprehension, and is not a ternary conditional operator.You may find it somewhat painful to write the following:expression1 will have to be evaluated twice with the above usage. It can limit redundancy if it is simply a local variable. However, a common and performant Pythonic idiom for this use-case is to use or's shortcutting behavior:which is equivalent in semantics. Note that some style-guides may limit this usage on the grounds of clarity - it does pack a lot of meaning into very little syntax.",
                "One of the alternatives to Python's conditional expressionis the following:which has the following nice extension:The shortest alternative remainswhich works because issubclass(bool, int).Careful, though: the alternative tois notbutThis works fine as long as no and yes are to be called with exactly the same parameters. If they are not, like inor inthen a similar alternative either does not exist (1) or is hardly viable (2). (In rare cases, depending on the context, something likecould make sense.)Thanks to Radek Roj\u00edk for his comment",
                "As already answered, yes, there is a ternary operator in Python:In many cases <expression 1> is also used as Boolean evaluated <condition>. Then you can use short-circuit evaluation.One big pro of short-circuit evaluation is the possibility of chaining more than two expressions:When working with functions it is more different in detail:PS: Of course, a short-circuit evaluation is not a ternary operator, but often the ternary is used in cases where the short circuit would be enough. It has a better readability and can be chained.",
                "Simulating the Python ternary operator.For exampleOutput:",
                "Just memorize this pyramid if you have trouble remembering:",
                "The ternary conditional operator simply allows testing a condition in a single line replacing the multiline if-else making the code compact.[on_true] if [expression] else [on_false]Above approach can be written as:",
                "Vinko Vrsalovic's answer is good enough. There is only one more thing:Note that conditionals are an expression, not a statement. This means you can't use assignment statements or pass or other statements within a conditional expressionAfter the walrus operator was introduced in Python 3.8, something changed.gives a = 3 and b is not defined,gives a is not defined and b = 5, andgives c = 5, a is not defined and b = 5.Even if this may be ugly, assignments can be done inside conditional expressions after Python 3.8. Anyway, it is still better to use normal if statement instead in this case.",
                "More a tip than an answer (I don't need to repeat the obvious for the hundredth time), but I sometimes use it as a one-liner shortcut in such constructs:, becomes:Some (many :) may frown upon it as unpythonic (even, Ruby-ish :), but I personally find it more natural - i.e., how you'd express it normally, plus a bit more visually appealing in large blocks of code.",
                "You can do this:Example:This would print \"odd\" if the number is odd or \"even\" if the number is even.The result: If condition is true, exp_1 is executed, else exp_2 is executed.Note: 0, None, False, emptylist, and emptyString evaluates as False.And any data other than 0 evaluates to True.If the condition [condition] becomes \"True\", then expression_1 will be evaluated, but not expression_2.If we \"and\" something with 0 (zero), the result will always to be false. So in the below statement,The expression exp won't be evaluated at all since \"and\" with 0 will always evaluate to zero and there is no need to evaluate the expression. This is how the compiler itself works, in all languages.Inthe expression exp won't be evaluated at all since \"or\" with 1 will always be 1. So it won't bother to evaluate the expression exp since the result will be 1 anyway (compiler optimization methods).But in case ofThe second expression exp2 won't be evaluated since True and exp1 would be True when exp1 isn't false.Similarly inThe expression exp1 won't be evaluated since False is equivalent to writing 0 and doing \"and\" with 0 would be 0 itself, but after exp1 since \"or\" is used, it will evaluate the expression exp2 after \"or\".Note:- This kind of branching using \"or\" and \"and\" can only be used when the expression_1 doesn't have a Truth value of False (or 0 or None or emptylist [ ] or emptystring ' '.) since if expression_1 becomes False, then the expression_2 will be evaluated because of the presence \"or\" between exp_1 and exp_2.In case you still want to make it work for all the cases regardless of what exp_1 and exp_2 truth values are, do this:",
                "Many programming languages derived from C usually have the following syntax of the ternary conditional operator:At first, the Python's benevolent dictator for life (I mean Guido van Rossum, of course) rejected it (as non-Pythonic style), since it's quite hard to understand for people not used to C language. Also, the colon sign : already has many uses in Python. After PEP 308 was approved, Python finally received its own shortcut conditional expression (what we use now):So, firstly it evaluates the condition. If it returns True, expression1 will be evaluated to give the result, otherwise expression2 will be evaluated. Due to lazy evaluation mechanics \u2013 only one expression will be executed.Here are some examples (conditions will be evaluated from left to right):Ternary operators can be chained in series:The following one is the same as previous one:",
                "Yes, Python have a ternary operator, here is the syntax and an example code to demonstrate the same :)",
                "Other answers correctly talk about the Python ternary operator. I would like to complement by mentioning a scenario for which the ternary operator is often used, but for which there is a better idiom. This is the scenario of using a default value.Suppose we want to use option_value with a default value if it is not set:or, if option_value is never set to a falsy value (0, \"\", etc.), simplyHowever, in this case an ever better solution is simply to write",
                "The syntax for the ternary operator in Python is:[on_true] if [expression] else [on_false]Using that syntax, here is how we would rewrite the code above using Python\u2019s ternary operator:It's still pretty clear, but much shorter. Note that the expression could be any type of expression, including a function call, that returns a value that evaluates to True or False.",
                "Python has a ternary form for assignments; however there may be even a shorter form that people should be aware of.It's very common to need to assign to a variable one value or another depending on a condition.^ This is the long form for doing such assignments.Below is the ternary form. But this isn't the most succinct way - see the last example.With Python, you can simply use or for alternative assignments.The above works since li1 is None and the interpreter treats that as False in logic expressions. The interpreter then moves on and evaluates the second expression, which is not None and it's not an empty list - so it gets assigned to a.This also works with empty lists. For instance, if you want to assign a whichever list has items.Knowing this, you can simply such assignments whenever you encounter them. This also works with strings and other iterables. You could assign a whichever string isn't empty.I always liked the C ternary syntax, but Python takes it a step further!I understand that some may say this isn't a good stylistic choice, because it relies on mechanics that aren't immediately apparent to all developers. I personally disagree with that viewpoint. Python is a syntax-rich language with lots of idiomatic tricks that aren't immediately apparent to the dabbler. But the more you learn and understand the mechanics of the underlying system, the more you appreciate it.",
                "Pythonic way of doing the things:But there always exists a different way of doing a ternary condition too:",
                "There are multiple ways. The simplest one is to use the condition inside the \"print\" method.You can useWhich is equivalent to:In this way, more than two statements are also possible to print. For example:can be written as:",
                "The if else-if version can be written as:",
                "Yes, it has, but it's different from C-syntax-like programming languages (which is condition ? value_if_true : value_if_falseIn Python, it goes like this: value_if_true if condition else value_if_falseExample: even_or_odd = \"even\" if x % 2 == 0 else \"odd\"",
                "A neat way to chain multiple operators:",
                "I find the default Python syntax val = a if cond else b cumbersome, so sometimes I do this:Of course, it has the downside of always evaluating both sides (a and b), but the syntax is way clearer to me."
            ]
        },
        {
            "tag": "",
            "question": [
                "var functionName = function() {} vs function functionName() {}",
                "I've recently started maintaining someone else's JavaScript code. I'm fixing bugs, adding features and also trying to tidy up the code and make it more consistent.\nThe previous developer used two ways ..."
            ],
            "url": "https://stackoverflow.com/questions/336859",
            "answer": [
                "The difference is that functionOne is a function expression and so only defined when that line is reached, whereas functionTwo is a function declaration and is defined as soon as its surrounding function or script is executed (due to hoisting).For example, a function expression:// TypeError: functionOne is not a function\r\nfunctionOne();\r\n\r\nvar functionOne = function() {\r\n  console.log(\"Hello!\");\r\n};And, a function declaration:// Outputs: \"Hello!\"\r\nfunctionTwo();\r\n\r\nfunction functionTwo() {\r\n  console.log(\"Hello!\");\r\n}Historically, function declarations defined within blocks were handled inconsistently between browsers. Strict mode (introduced in ES5) resolved this by scoping function declarations to their enclosing block.'use strict';    \r\n{ // note this block!\r\n  function functionThree() {\r\n    console.log(\"Hello!\");\r\n  }\r\n}\r\nfunctionThree(); // ReferenceError",
                "First I want to correct Greg: function abc(){} is scoped too \u2014 the name abc is defined in the scope where this definition is encountered. Example:Secondly, it is possible to combine both styles:xyz is going to be defined as usual, abc is undefined in all browsers but Internet\u00a0Explorer \u2014 do not rely on it being defined. But it will be defined inside its body:If you want to alias functions on all browsers, use this kind of declaration:In this case, both xyz and abc are aliases of the same object:One compelling reason to use the combined style is the \"name\" attribute of function objects (not supported by Internet\u00a0Explorer). Basically when you define a function likeits name is automatically assigned. But when you define it likeits name is empty \u2014 we created an anonymous function and assigned it to some variable.Another good reason to use the combined style is to use a short internal name to refer to itself, while providing a long non-conflicting name for external users:In the example above we can do the same with an external name, but it'll be too unwieldy (and slower).(Another way to refer to itself is to use arguments.callee, which is still relatively long, and not supported in the strict mode.)Deep down, JavaScript treats both statements differently. This is a function declaration:abc here is defined everywhere in the current scope:Also, it hoisted through a return statement:This is a function expression:xyz here is defined from the point of assignment:Function declaration vs. function expression is the real reason why there is a difference demonstrated by Greg.Fun fact:Personally, I prefer the \"function expression\" declaration because this way I can control the visibility. When I define the function likeI know that I defined the function locally. When I define the function likeI know that I defined it globally providing that I didn't define abc anywhere in the chain of scopes. This style of definition is resilient even when used inside eval(). While the definitiondepends on the context and may leave you guessing where it is actually defined, especially in the case of eval() \u2014 the answer is: It depends on the browser.",
                "Here's the rundown on the standard forms that create functions: (Originally written for another question, but adapted after being moved into the canonical question.)Terms:The quick list:Function Declaration\"Anonymous\" function Expression (which despite the term, sometimes create functions with names)Named function ExpressionAccessor Function Initializer (ES5+)Arrow Function Expression (ES2015+) (which, like anonymous function expressions, don't involve an explicit name, and yet can create functions with names)Method Declaration in Object Initializer (ES2015+)Constructor and Method Declarations in class (ES2015+)The first form is a function declaration, which looks like this:A function declaration is a declaration; it's not a statement or expression. As such, you don't follow it with a ; (although doing so is harmless).A function declaration is processed when execution enters the context in which it appears, before any step-by-step code is executed. The function it creates is given a proper name (x in the example above), and that name is put in the scope in which the declaration appears.Because it's processed before any step-by-step code in the same context, you can do things like this:Until ES2015, the spec didn't cover what a JavaScript engine should do if you put a function declaration inside a control structure like try, if, switch, while, etc., like this:And since they're processed before step-by-step code is run, it's tricky to know what to do when they're in a control structure.Although doing this wasn't specified until ES2015, it was an allowable extension to support function declarations in blocks. Unfortunately (and inevitably), different engines did different things.As of ES2015, the specification says what to do. In fact, it gives three separate things to do:The rules for the loose modes are tricky, but in strict mode, function declarations in blocks are easy: They're local to the block (they have block scope, which is also new in ES2015), and they're hoisted to the top of the block. So:The second common form is called an anonymous function expression:Like all expressions, it's evaluated when it's reached in the step-by-step execution of the code.In ES5, the function this creates has no name (it's anonymous). In ES2015, the function is assigned a name if possible by inferring it from context. In the example above, the name would be y. Something similar is done when the function is the value of a property initializer. (For details on when this happens and the rules, search for SetFunctionName in the the specification\u00a0\u2014 it appears all over the place.)The third form is a named function expression (\"NFE\"):The function this creates has a proper name (w in this case). Like all expressions, this is evaluated when it's reached in the step-by-step execution of the code. The name of the function is not added to the scope in which the expression appears; the name is in scope within the function itself:Note that NFEs have frequently been a source of bugs for JavaScript implementations. IE8 and earlier, for instance, handle NFEs completely incorrectly, creating two different functions at two different times. Early versions of Safari had issues as well. The good news is that current versions of browsers (IE9 and up, current Safari) don't have those issues any more. (But as of this writing, sadly, IE8 remains in widespread use, and so using NFEs with code for the web in general is still problematic.)Sometimes functions can sneak in largely unnoticed; that's the case with accessor functions. Here's an example:Note that when I used the function, I didn't use ()! That's because it's an accessor function for a property. We get and set the property in the normal way, but behind the scenes, the function is called.You can also create accessor functions with Object.defineProperty, Object.defineProperties, and the lesser-known second argument to Object.create.ES2015 brings us the arrow function. Here's one example:See that n => n * 2 thing hiding in the map() call? That's a function.A couple of things about arrow functions:They don't have their own this. Instead, they close over the this of the context where they're defined. (They also close over arguments and, where relevant, super.) This means that the this within them is the same as the this where they're created, and cannot be changed.As you'll have noticed with the above, you don't use the keyword function; instead, you use =>.The n => n * 2 example above is one form of them. If you have multiple arguments to pass the function, you use parens:(Remember that Array#map passes the entry as the first argument, and the index as the second.)In both cases, the body of the function is just an expression; the function's return value will automatically be the result of that expression (you don't use an explicit return).If you're doing more than just a single expression, use {} and an explicit return (if you need to return a value), as normal:The version without { ... } is called an arrow function with an expression body or concise body. (Also: A concise arrow function.) The one with { ... } defining the body is an arrow function with a function body. (Also: A verbose arrow function.)ES2015 allows a shorter form of declaring a property that references a function called a method definition; it looks like this:the almost-equivalent in ES5 and earlier would be:the difference (other than verbosity) is that a method can use super, but a function cannot. So for instance, if you had an object that defined (say) valueOf using method syntax, it could use super.valueOf() to get the value Object.prototype.valueOf would have returned (before presumably doing something else with it), whereas the ES5 version would have to do Object.prototype.valueOf.call(this) instead.That also means that the method has a reference to the object it was defined on, so if that object is temporary (for instance, you're passing it into Object.assign as one of the source objects), method syntax could mean that the object is retained in memory when otherwise it could have been garbage collected (if the JavaScript engine doesn't detect that situation and handle it if none of the methods uses super).ES2015 brings us class syntax, including declared constructors and methods:There are two function declarations above: One for the constructor, which gets the name Person, and one for getFullName, which is a function assigned to Person.prototype.",
                "Speaking about the global context, both, the var statement and a FunctionDeclaration at the end will create a non-deleteable property on the global object, but the value of both can be overwritten.The subtle difference between the two ways is that when the Variable Instantiation process runs (before the actual code execution) all identifiers declared with var will be initialized with undefined, and the ones used by the FunctionDeclaration's will be available since that moment, for example:The assignment of the bar FunctionExpression takes place until runtime.A global property created by a FunctionDeclaration can be overwritten without any problems just like a variable value, e.g.:Another obvious difference between your two examples is that the first function doesn't have a name, but the second has it, which can be really useful when debugging (i.e. inspecting a call stack).About your edited first example (foo = function() { alert('hello!'); };), it is an undeclared assignment, I would highly encourage you to always use the var keyword.With an assignment, without the var statement, if the referenced identifier is not found in the scope chain, it will become a deleteable property of the global object.Also, undeclared assignments throw a ReferenceError on ECMAScript 5 under Strict Mode.A must read:Note: This answer has been merged from another question, in which the major doubt and misconception from the OP was that identifiers declared with a FunctionDeclaration, couldn't be overwritten which is not the case.",
                "The two code snippets you've posted there will, for almost all purposes, behave the same way.However, the difference in behaviour is that with the first variant (var functionOne = function() {}), that function can only be called after that point in the code.With the second variant (function functionTwo()), the function is available to code that runs above where the function is declared.This is because with the first variant, the function is assigned to the variable foo at run time. In the second, the function is assigned to that identifier, foo, at parse time.More technical informationJavaScript has three ways of defining functions.",
                "A better explanation to Greg's answerWhy no error? We were always taught that expressions are executed from top to bottom(??)Function declarations and variable declarations are always moved (hoisted) invisibly to the top of their containing scope by the JavaScript interpreter. Function parameters and language-defined names are, obviously, already there. ben cherryThis means that code like this:Notice that the assignment portion of the declarations were not hoisted. Only the name is hoisted.But in the case with function declarations, the entire function body will be hoisted as well:",
                "Other commenters have already covered the semantic difference of the two variants above. I wanted to note a stylistic difference: Only the \"assignment\" variation can set a property of another object.I often build JavaScript modules with a pattern like this:With this pattern, your public functions will all use assignment, while your private functions use declaration.(Note also that assignment should require a semicolon after the statement, while declaration prohibits it.)",
                "An illustration of when to prefer the first method to the second one is when you need to avoid overriding a function's previous definitions.With, this definition of myfunction will override any previous definition, since it will be done at parse-time.Whiledoes the correct job of defining myfunction only when condition is met.",
                "An important reason is to add one and only one variable as the \"Root\" of your namespace...orThere are many techniques for namespacing. It's become more important with the plethora of JavaScript modules available.Also see How do I declare a namespace in JavaScript?",
                "Hoisting is the JavaScript interpreter\u2019s action of moving all variable and function declarations to the top of the current scope.However, only the actual declarations are hoisted. by leaving assignments where they are.VariableJavascript is called loosely typed language. Which means Javascript variables can hold value of any Data-Type. Javascript automatically takes care of changing the variable-type based on the value/literal provided during runtime.FunctionDefault return value of function is 'undefined', Variable declaration default value also 'undefined'Function DeclarationFunction ExpressionFunction assigned to variable Example:javascript interpreted asYou can check function declaration, expression test over different browser's using jsperf Test RunnerES5 Constructor Function Classes: Function objects created using Function.prototype.bindJavaScript treats functions as first-class objects, so being an object, you can assign properties to a function.ES6 introduced Arrow function: An arrow function expression has a shorter syntax, they are best suited for non-method functions, and they cannot be used as constructors.ArrowFunction : ArrowParameters => ConciseBody.",
                "I'm adding my own answer just because everyone else has covered the hoisting part thoroughly.I've wondered about which way is better for a long while now, and thanks to http://jsperf.com now I know :)Function declarations are faster, and that's what really matters in web dev right? ;)",
                "The following works because function add() is scoped to the nearest block:try {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nfunction add(a, b){\n  return a + b;\n}The following does not work because the variable is called before a function value is assigned to the variable add.try {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nvar add=function(a, b){\n  return a + b;\n}The above code is identical in functionality to the code below. Note that explicitly assigning add = undefined is superfluous because simply doing var add; is the exact same as var add=undefined.var add = undefined;\n\ntry {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nadd = function(a, b){\n  return a + b;\n}The following does not work because var add= begins an expression and causes the following function add() to be an expression instead of a block. Named functions are only visible to themselves and their surrounding block. As function add() is an expression here, it has no surrounding block, so it is only visible to itself.try {\n  console.log(\"Success: \", add(1, 1));\n} catch(e) {\n  console.log(\"ERROR: \" + e);\n}\n\nvar add=function add(a, b){\n  return a + b;\n}The name of a function function thefuncname(){} is thefuncname when it is declared this way.function foobar(a, b){}\n\nconsole.log(foobar.name);var a = function foobar(){};\n\nconsole.log(a.name);Otherwise, if a function is declared as function(){}, the function.name is the first variable used to store the function.var a = function(){};\nvar b = (function(){ return function(){} });\n\nconsole.log(a.name);\nconsole.log(b.name);If there are no variables set to the function, then the functions name is the empty string (\"\").console.log((function(){}).name === \"\");Lastly, while the variable the function is assigned to initially sets the name, successive variables set to the function do not change the name.var a = function(){};\nvar b = a;\nvar c = b;\n\nconsole.log(a.name);\nconsole.log(b.name);\nconsole.log(c.name);In Google's V8 and Firefox's Spidermonkey there might be a few microsecond JIT compilation difference, but ultimately the result is the exact same. To prove this, let's examine the efficiency of JSPerf at micro-benchmarks by comparing the speed of two blank code snippets. The JSPerf tests are found here. And, the jsben.ch tests are  found here. As you can see, there is a noticeable difference when there should be none. If you are really a performance freak like me, then it might be more worth your while trying to reduce the number of variables and functions in the scope and especially eliminating polymorphism (such as using the same variable to store two different types).When you use the var keyword to declare a variable, you can then reassign a different value to the variable like so.(function(){\n    \"use strict\";\n    var foobar = function(){}; // initial value\n    try {\n        foobar = \"Hello World!\"; // new value\n        console.log(\"[no error]\");\n    } catch(error) {\n        console.log(\"ERROR: \" + error.message);\n    }\n    console.log(foobar, window.foobar);\n})();However, when we use the const-statement, the variable reference becomes immutable. This means that we cannot assign a new value to the variable. Please note, however, that this does not make the contents of the variable immutable: if you do const arr = [], then you can still do arr[10] = \"example\". Only doing something like arr = \"new value\" or arr = [] would throw an error as seen below.(function(){\n    \"use strict\";\n    const foobar = function(){}; // initial value\n    try {\n        foobar = \"Hello World!\"; // new value\n        console.log(\"[no error]\");\n    } catch(error) {\n        console.log(\"ERROR: \" + error.message);\n    }\n    console.log(foobar, window.foobar);\n})();Interestingly, if we declare the variable as function funcName(){}, then the immutability of the variable is the same as declaring it with var.(function(){\n    \"use strict\";\n    function foobar(){}; // initial value\n    try {\n        foobar = \"Hello World!\"; // new value\n        console.log(\"[no error]\");\n    } catch(error) {\n        console.log(\"ERROR: \" + error.message);\n    }\n    console.log(foobar, window.foobar);\n})();The \"nearest block\" is the nearest \"function,\" (including asynchronous functions, generator functions, and asynchronous generator functions). However, interestingly, a function functionName() {} behaves like a var functionName = function() {} when in a non-closure block to items outside said closure. Observe.try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}');\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\nvar add=function(a, b){return a + b}try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\nfunction add(a, b){\n  return a + b;\n}try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n(function () {\n    function add(a, b){\n      return a + b;\n    }\n})();try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n{\n    function add(a, b){\n      return a + b;\n    }\n}try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n(() => {\n    var add=function(a, b){\n      return a + b;\n    }\n})();try {\n  // typeof will simply return \"undefined\" if the variable does not exist\n  if (typeof add !== \"undefined\") {\n    add(1, 1); // just to prove it\n    console.log(\"Not a block\");\n  }else if(add===undefined){ // this throws an exception if add doesn't exist\n    console.log('Behaves like var add=function(a,b){return a+b}')\n  }\n} catch(e) {\n  console.log(\"Is a block\");\n}\n(() => {\n    function add(a, b){\n      return a + b;\n    }\n})();",
                "A function declaration and a function expression assigned to a variable behave the same once the binding is established.There is a difference however at how and when the function object is actually associated with its variable. This difference is due to the mechanism called variable hoisting in JavaScript.Basically, all function declarations and variable declarations are hoisted to the top of the function in which the declaration occurs (this is why we say that JavaScript has function scope).When a function declaration is hoisted, the function body \"follows\"\nso when the function body is evaluated, the variable will immediately\nbe bound to a function object.When a variable declaration is hoisted, the initialization does not\nfollow, but is \"left behind\". The variable is initialized to\nundefined at the start of the function body, and will be assigned\na value at its original location in the code. (Actually, it will be assigned a value at every location where a declaration of a variable with the same name occurs.)The order of hoisting is also important: function declarations take precedence over variable declarations with the same name, and the last function declaration takes precedence over previous function declarations with the same name.Some examples...Variable foo is hoisted to the top of the function, initialized to undefined, so that !foo is true, so foo is assigned 10. The foo outside of bar's scope plays no role and is untouched.Function declarations take precedence over variable declarations, and the last function declaration \"sticks\".In this example a is initialized with the function object resulting from evaluating the second function declaration, and then is assigned 4.Here the function declaration is hoisted first, declaring and initializing variable a. Next, this variable is assigned 10. In other words: the assignment does not assign to outer variable a.",
                "The first example is a function declaration:The second example is a function expression:The main difference is how they are hoisted (lifted and declared). In the first example, the whole function declaration is hoisted. In the second example only the var 'abc' is hoisted, its value (the function) will be undefined, and the function itself remains at the position that it is declared.To put it simply:To study more about this topic I strongly recommend you this\nlink",
                "In terms of code maintenance cost, named functions are more preferable:I suspect more PROS for named functions are follow. And what is listed as an advantage of named functions is a disadvantage for anonymous ones.Historically, anonymous functions appeared from the inability of JavaScript as a language to list members with named functions:",
                "In computer science terms, we talk about anonymous functions and named functions. I think the most important difference is that an anonymous function is not bound to a name, hence the name anonymous function. In JavaScript it is a first class object dynamically declared at runtime.For more information on anonymous functions and lambda calculus, Wikipedia is a good start: Anonymous Functions.",
                "I use the variable approach in my code for a very specific reason, the theory of which has been covered in an abstract way above, but an example might help some people like me, with limited JavaScript expertise.I have code that I need to run with 160 independently-designed brandings. Most of the code is in shared files, but branding-specific stuff is in a separate file, one for each branding.Some brandings require specific functions, and some do not. Sometimes I have to add new functions to do new branding-specific things. I am happy to change the shared coded, but I don't want to have to change all 160 sets of branding files.By using the variable syntax, I can declare the variable (a function pointer essentially) in the shared code and either assign a trivial stub function, or set to null.The one or two brandings that need a specific implementation of the function can then define their version of the function and assign this to the variable if they want, and the rest do nothing. I can test for a null function before I execute it in the shared code.From people's comments above, I gather it may be possible to redefine a static function too, but I think the variable solution is nice and clear.",
                "Greg's Answer is good enough, but I still would like to add something to it that I learned just now watching Douglas Crockford's videos.Function expression:Function statement:The function statement is just a shorthand for var statement with a function value.Soexpands toWhich expands further to:And they are both hoisted to the top of the code.",
                "@EugeneLazutkin gives an example where he names an assigned function to be able to use shortcut() as an internal reference to itself. John Resig gives another example - copying a recursive function assigned to another object in his Learning Advanced Javascript tutorial. While assigning functions to properties isn't strictly the question here, I recommend actively trying the tutorial out - run the code by clicking the button in the upper right corner, and double click the code to edit to your liking.Examples from the tutorial: recursive calls in yell():Tests fail when the original ninja object is removed. (page 13)function assert(predicate, message) { if(!predicate) { throw new Error(message); } }\n\nvar ninja = {\n  yell: function(n){\nreturn n > 0 ? ninja.yell(n-1) + \"a\" : \"hiy\";\n  }\n};\nassert( ninja.yell(4) == \"hiyaaaa\", \"A single object isn't too bad, either.\" ); \n\nvar samurai = { yell: ninja.yell };\nvar ninja = null;\n\ntry {\n  samurai.yell(4);\n} catch(e){\n  assert( false, \"Uh, this isn't good! Where'd ninja.yell go?\" );\n}If you name the function that will be called recursively, the tests will pass. (page 14)function assert(predicate, message) { if(!predicate) { throw new Error(message); } }\n\nvar ninja = {\n  yell: function yell(n){\nreturn n > 0 ? yell(n-1) + \"a\" : \"hiy\";\n  }\n};\nassert( ninja.yell(4) == \"hiyaaaa\", \"Works as we would expect it to!\" );\n \nvar samurai = { yell: ninja.yell };\nvar ninja = {};\nassert( samurai.yell(4) == \"hiyaaaa\", \"The method correctly calls itself.\" );\n\nconsole.log(samurai.yell(4));",
                "Another difference that is not mentioned in the other answers is that if you use the anonymous functionand use that as a constructor as inthen one.constructor.name will not be defined. Function.name is non-standard but is supported by Firefox, Chrome, other Webkit-derived browsers and IE 9+.Withit is possible to retrieve the name of the constructor as a string with two.constructor.name.",
                "The first one (function doSomething(x)) should be part of an object notation.The second one (var doSomething = function(x){ alert(x);}) is simply creating an anonymous function and assigning it to a variable, doSomething. So doSomething() will call the function.You may want to know what a function declaration and function expression is.A function declaration defines a named function variable without requiring variable assignment. Function declarations occur as standalone constructs and cannot be nested within non-function blocks.ECMA 5 (13.0) defines the syntax as \n  function Identifier ( FormalParameterListopt ) { FunctionBody }In above condition the function name is visible within its scope and the scope of its parent (otherwise it would be unreachable).And in a function expressionA function expression defines a function as a part of a larger expression syntax (typically a variable assignment ). Functions defined via functions expressions can be named or anonymous. Function expressions should not start with \u201cfunction\u201d.ECMA 5 (13.0) defines the syntax as \n  function Identifieropt ( FormalParameterListopt ) { FunctionBody }",
                "I'm listing out the differences below:A function declaration can be placed anywhere in the code. Even if it is invoked before the definition appears in code, it gets executed as function declaration is committed to memory or in a way it is hoisted up, before any other code in the page starts execution.Take a look at the function below:This is because, during execution, it looks like:-A function expression, if not defined before calling it, will result in an error. Also, here the function definition itself is not moved to the top or committed to memory like in the function declarations. But the variable to which we assign the function gets hoisted up and undefined gets assigned to it.Same function using function expressions:This is because during execution, it looks like:It is not safe to write function declarations in non-function blocks like if because they won't be accessible.Named function expression like the one below, may not work in Internet\u00a0Explorer browsers prior to version 9.",
                "About performance:New versions of V8 introduced several under-the-hood optimizations and so did SpiderMonkey.There is almost no difference now between expression and declaration. Function expression appears to be faster now.Chrome 62.0.3202FireFox 55Chrome Canary 63.0.3225Anonymous function expressions appear to have better performance\n  against Named function expression.Firefox\n\nChrome Canary\n\nChrome",
                "If you would use those functions to create objects, you would get:",
                "In JavaScript there are two ways to create functions:Function declaration:This is very basic, self-explanatory, used in many languages and standard across C family of languages. We declared a function defined it and executed it by calling it.What you should be knowing is that functions are actually objects in JavaScript; internally we have created an object for above function and given it a name called fn or the reference to the object is stored in fn. Functions are objects in JavaScript; an instance of function is actually an object instance.Function expression:JavaScript has first-class functions, that is, create a function and assign it to a variable just like you create a string or number and assign it to a variable. Here, the fn variable is assigned to a function. The reason for this concept is functions are objects in JavaScript; fn is pointing to the object instance of the above function. We have initialized a function and assigned it to a variable. It's not executing the function and assigning the result.Reference: JavaScript function declaration syntax: var fn = function() {} vs function fn() {}",
                "The first function syntax is Anonymous Function Expression:While, the second one is Function Declaration:The main difference between both is the function name since Anonymous Functions have no name to call.\nAnonymous functions are quick and easy to declare, and many libraries and tools tend to encourage this idiomatic style of code. However, anonymous functions have some drawbacks:Readability: anonymous functions omit a name which could cause less readable code.Debugging: anonymous functions have no name in stack traces, which can make debugging more difficult.Self-Reference: what if the function needs to refer to itself, for recursion for example.Providing a name for your function expression quite effectively addresses all these drawbacks, and has no tangible downsides. The best practice is to always name your function expressions:For functions assigned to a variable, naming the function, in this case, is not very common and may cause confusion, in this case, the arrow function may be a better choice.",
                "In light of the \"named functions show up in stack traces\" argument, modern JavaScript engines are actually quite capable of representing anonymous functions.As of this writing, V8, SpiderMonkey, Chakra and Nitro always refer to named functions by their names. They almost always refer to an anonymous function by its identifier if it has one.SpiderMonkey can figure out the name of an anonymous function returned from another function. The rest can't.If you really, really wanted your iterator and success callbacks to show up in the trace, you could name those too...But for the most part it's not worth stressing over.",
                "Both are different ways of defining a function. The difference is how the browser interprets and loads them into an execution context.The first case is of function expressions which loads only when the interpreter reaches that line of code. So if you do it like the following, you will get an error that the functionOne is not a function.The reason is that on the first line no value is assigned to functionOne, and hence it is undefined. We are trying to call it as a function, and hence we are getting an error.On the second line we are assigning the reference of an anonymous function to functionOne.The second case is of function declarations that loads before any code is executed. So if you do like the following you won't get any error as the declaration loads before code execution.",
                "They are pretty similar with some small differences, first one is a variable which assigned to an anonymous function (Function Declaration) and second one is the normal way to create a function in JavaScript(Anonymous function Declaration), both has usage, cons and pros:1. Function ExpressionA Function Expression defines a function as a part of a larger\n  expression syntax (typically a variable assignment ). Functions\n  defined via Functions Expressions can be named or anonymous. Function\n  Expressions must not start with \u201cfunction\u201d (hence the parentheses\n  around the self invoking example below).Assign a variable to a function, means no Hoisting, as we know functions in JavaScript can Hoist, means they can be called before they get declared, while variables need to be declared before getting access to them, so means in this case we can not access the function before where it's declared, also it could be a way that you write your functions, for the functions which return another function, this kind of declaration could make sense, also in ECMA6 & above you can assign this to an arrow function which can be used to call anonymous functions, also this way of declaring is a better way to create Constructor functions in JavaScript.2. Function DeclarationA Function Declaration defines a named function variable without\n  requiring variable assignment. Function Declarations occur as\n  standalone constructs and cannot be nested within non-function blocks.\n  It\u2019s helpful to think of them as siblings of Variable Declarations.\n  Just as Variable Declarations must start with \u201cvar\u201d, Function\n  Declarations must begin with \u201cfunction\u201d.This is the normal way of calling a function in JavaScript, this function can be called before you even declare it as in JavaScript all functions get Hoisted, but if you have 'use strict' this won't Hoist as expected, it's a good way to call all normal functions which are not big in lines and neither are a  constructor function.Also, if you need more info about how hoisting works in JavaScript, visit the link below:https://developer.mozilla.org/en-US/docs/Glossary/Hoisting",
                "This is just two possible ways of declaring functions, and in the second way, you can use the function before declaration."
            ]
        },
        {
            "tag": "",
            "question": [
                "Why is subtracting these two times (in 1927) giving a strange result?",
                "If I run the following program, which parses two date strings referencing times 1 second apart and compares them:\npublic static void main(String[] args) throws ParseException {\n    SimpleDateFormat sf ..."
            ],
            "url": "https://stackoverflow.com/questions/6841333",
            "answer": [
                "It's a time zone change on December 31st in Shanghai.See this page for details of 1927 in Shanghai. Basically at midnight at the end of 1927, the clocks went back 5 minutes and 52 seconds. So \"1927-12-31 23:54:08\" actually happened twice, and it looks like Java is parsing it as the later possible instant for that local date/time - hence the difference.Just another episode in the often weird and wonderful world of time zones.EDIT: Stop press! History changes...The original question would no longer demonstrate quite the same behaviour, if rebuilt with version 2013a of TZDB. In 2013a, the result would be 358 seconds, with a transition time of 23:54:03 instead of 23:54:08.I only noticed this because I'm collecting questions like this in Noda Time, in the form of unit tests... The test has now been changed, but it just goes to show - not even historical data is safe.EDIT: History has changed again...In TZDB 2014f, the time of the change has moved to 1900-12-31, and it's now a mere 343 second change (so the time between t and t+1 is 344 seconds, if you see what I mean).EDIT: To answer a question around a transition at 1900... it looks like the Java timezone implementation treats all time zones as simply being in their standard time for any instant before the start of 1900 UTC:The code above produces no output on my Windows machine. So any time zone which has any offset other than its standard one at the start of 1900 will count that as a transition. TZDB itself has some data going back earlier than that, and doesn't rely on any idea of a \"fixed\" standard time (which is what getRawOffset assumes to be a valid concept) so other libraries needn't introduce this artificial transition.",
                "You've encountered a local time discontinuity:When local standard time was about to reach Sunday, 1. January 1928,\n  00:00:00 clocks were turned backward 0:05:52 hours to Saturday, 31.\n  December 1927, 23:54:08 local standard time insteadThis is not particularly strange and has happened pretty much everywhere at one time or another as timezones were switched or changed due to political or administrative actions.",
                "The moral of this strangeness is:",
                "When incrementing time you should convert back to UTC and then add or subtract. Use the local time only for display.This way you will be able to walk through any periods where hours or minutes happen twice.If you converted to UTC, add each second, and convert to local time for display. You would go through 11:54:08 p.m. LMT - 11:59:59 p.m. LMT and then 11:54:08 p.m. CST - 11:59:59 p.m. CST.",
                "Instead of converting each date, you can use the following code:And then see that the result is:",
                "I'm sorry to say, but the time discontinuity has moved a bit inJDK 6 two years ago, and in JDK 7 just recently in update 25.Lesson to learn: avoid non-UTC times at all costs, except maybe for display.",
                "As explained by others, there's a time discontinuity there. There are two possible timezone offsets for 1927-12-31 23:54:08 at Asia/Shanghai, but only one offset for 1927-12-31 23:54:07. So, depending on which offset is used, there's either a one second difference or a 5 minutes and 53 seconds difference.This slight shift of offsets, instead of the usual one-hour daylight savings (summer time) we are used to, obscures the problem a bit.Note that the 2013a update of the timezone database moved this discontinuity a few seconds earlier, but the effect would still be observable.The new java.time package on Java 8 let use see this more clearly, and provide tools to handle it. Given:Then durationAtEarlierOffset will be one second, while durationAtLaterOffset will be five minutes and 53 seconds.Also, these two offsets are the same:But these two are different:You can see the same problem comparing 1927-12-31 23:59:59 with 1928-01-01 00:00:00, though, in this case, it is the earlier offset that produces the longer divergence, and it is the earlier date that has two possible offsets.Another way to approach this is to check whether there's a transition going on. We can do this like this:You can check whether the transition is an overlap where there's more than one valid offset for that date/time or a gap where that date/time is not valid for that zone id - by using the isOverlap() and isGap() methods on zot4.I hope this helps people handle this sort of issue once Java 8 becomes widely available, or to those using Java 7 who adopt the JSR 310 backport.",
                "IMHO the pervasive, implicit localization in Java is its single largest design flaw. It may be intended for user interfaces, but frankly, who really uses Java for user interfaces today except for some IDEs where you can basically ignore localization because programmers aren't exactly the target audience for it. You can fix it (especially on Linux servers) by:To the Java Community Process members I recommend:I mean, come on, aren't global static variables an anti-OO pattern? Nothing else is those pervasive defaults given by some rudimentary environment variables.......",
                "As others said, it's a time change in 1927 in Shanghai.It was 23:54:07 in Shanghai, in the local standard time, but then after 5 minutes and 52 seconds, it turned to the next day at 00:00:00, and then local standard time changed back to 23:54:08. So, that's why the difference between the two times is 343 seconds, not 1 second, as you would have expected.The time can also mess up in other places like the US. The US has Daylight Saving Time. When the Daylight Saving Time starts the time goes forward 1 hour. But after a while, the Daylight Saving Time ends, and it goes backward 1 hour back to the standard time zone. So sometimes when comparing times in the US the difference is about 3600 seconds not 1 second.But there is something different about these two-time changes. The latter changes continuously and the former was just a change. It didn't change back or change again by the same amount.It's better to use UTC unless if needed to use non-UTC time like in display.",
                "It cannot ever be \"1\" as the result because getTime() returns long milliseconds not seconds (of which 353 milliseconds is a fair point but the epoch for Date is started at 1970 not the 1920's).\ncmmnt: The API section you are using is largely considered deprecated.\nhttp://windsolarhybridaustralia.x10.mx/httpoutputtools-tomcat-java.html"
            ]
        },
        {
            "tag": "",
            "question": [
                "How to check whether a string contains a substring in JavaScript?",
                "Usually I would expect a String.contains() method, but there doesn't seem to be one. \n\nWhat is a reasonable way to check for this?"
            ],
            "url": "https://stackoverflow.com/questions/1789945",
            "answer": [
                "ECMAScript\u00a06  introduced String.prototype.includes:const string = \"foo\";\nconst substring = \"oo\";\n\nconsole.log(string.includes(substring)); // trueString.prototype.includes is case-sensitive and is not supported by Internet\u00a0Explorer without a polyfill.In ECMAScript\u00a05 or older environments, use String.prototype.indexOf, which returns -1 when a substring cannot be found:var string = \"foo\";\nvar substring = \"oo\";\n\nconsole.log(string.indexOf(substring) !== -1); // true",
                "There is a String.prototype.includes in ES6:Note that this does not work in Internet Explorer or some other old browsers with no or incomplete ES6 support. To make it work in old browsers, you may wish to use a transpiler like Babel, a shim library like es6-shim, or this polyfill from MDN:",
                "Another alternative is KMP (Knuth\u2013Morris\u2013Pratt).The KMP algorithm searches for a length-m substring in a length-n string in worst-case O(n+m) time, compared to a worst-case of O(n\u22c5m) for the naive algorithm, so using KMP may be reasonable if you care about worst-case time complexity.Here's a JavaScript implementation by Project Nayuki, taken from https://www.nayuki.io/res/knuth-morris-pratt-string-matching/kmp-string-matcher.js:function kmpSearch(pattern, text) {\n  if (pattern.length == 0)\n    return 0; // Immediate match\n\n  // Compute longest suffix-prefix table\n  var lsp = [0]; // Base case\n  for (var i = 1; i < pattern.length; i++) {\n    var j = lsp[i - 1]; // Start by assuming we're extending the previous LSP\n    while (j > 0 && pattern[i] !== pattern[j])\n      j = lsp[j - 1];\n    if (pattern[i] === pattern[j])\n      j++;\n    lsp.push(j);\n  }\n\n  // Walk through text string\n  var j = 0; // Number of chars matched in pattern\n  for (var i = 0; i < text.length; i++) {\n    while (j > 0 && text[i] != pattern[j])\n      j = lsp[j - 1]; // Fall back in the pattern\n    if (text[i]  == pattern[j]) {\n      j++; // Next char matched, increment position\n      if (j == pattern.length)\n        return i - (j - 1);\n    }\n  }\n  return -1; // Not found\n}\n\nconsole.log(kmpSearch('ays', 'haystack') != -1) // true\nconsole.log(kmpSearch('asdf', 'haystack') != -1) // false"
            ]
        },
        {
            "tag": "",
            "question": [
                "What is the difference between String and string in C#?",
                "What are the differences between these two and which one should I use?\nstring s = \"Hello world!\";\nString s = \"Hello world!\";"
            ],
            "url": "https://stackoverflow.com/questions/7074",
            "answer": [
                "string is an alias in C# for System.String.\nSo technically, there is no difference.  It's like int vs. System.Int32.As far as guidelines, it's generally recommended to use string any time you're referring to an object.e.g.Likewise, I think it's generally recommended to use String if you need to refer specifically to the class.e.g.It appears that the guidance in this area may have changed, as StyleCop now enforces the use of the C# specific aliases.",
                "Just for the sake of completeness, here's a brain dump of related information...As others have noted, string is an alias for System.String. Assuming your code using String compiles to System.String (i.e. you haven't got a using directive for some other namespace with a different String type), they compile to the same code, so at execution time there is no difference whatsoever. This is just one of the aliases in C#. The complete list is:Apart from string and object, the aliases are all to value types. decimal is a value type, but not a primitive type in the CLR. The only primitive type which doesn't have an alias is System.IntPtr.In the spec, the value type aliases are known as \"simple types\". Literals can be used for constant values of every simple type; no other value types have literal forms available. (Compare this with VB, which allows DateTime literals, and has an alias for it too.)There is one circumstance in which you have to use the aliases: when explicitly specifying an enum's underlying type. For instance:That's just a matter of the way the spec defines enum declarations - the part after the colon has to be the integral-type production, which is one token of sbyte, byte, short, ushort, int, uint, long, ulong, char... as opposed to a type production as used by variable declarations for example. It doesn't indicate any other difference.Finally, when it comes to which to use: personally I use the aliases everywhere for the implementation, but the CLR type for any APIs. It really doesn't matter too much which you use in terms of implementation - consistency among your team is nice, but no-one else is going to care. On the other hand, it's genuinely important that if you refer to a type in an API, you do so in a language-neutral way. A method called ReadInt32 is unambiguous, whereas a method called ReadInt requires interpretation. The caller could be using a language that defines an int alias for Int16, for example. The .NET framework designers have followed this pattern, good examples being in the BitConverter, BinaryReader and Convert classes.",
                "String stands for System.String and it is a .NET Framework type. string is an alias in the C# language for  System.String. Both of them are compiled to System.String in IL (Intermediate Language), so there is no difference. Choose what you like and use that. If you code in C#, I'd prefer string as it's a C# type alias and well-known by C# programmers.I can say the same about (int, System.Int32) etc..",
                "The best answer I have ever heard about using the provided type aliases in C# comes from Jeffrey Richter in his book CLR Via C#. Here are his 3 reasons:So there you have it. I think these are all really good points. I however, don't find myself using Jeffrey's advice in my own code. Maybe I am too stuck in my C# world but I end up trying to make my code look like the framework code.",
                "string is a reserved word, but String is just a class name. \nThis means that string cannot be used as a variable name by itself.If for some reason you wanted a variable called string, you'd see only the first of these compiles:If you really want a variable name called string you can use @ as a prefix:Another critical difference: Stack Overflow highlights them differently.",
                "There is one difference - you can't use String without using System; beforehand.",
                "It's been covered above; however, you can't use string in reflection; you must use String.",
                "System.String is the .NET string class - in C# string is an alias for System.String - so in use they are the same.As for guidelines I wouldn't get too bogged down and just use whichever you feel like - there are more important things in life and the code is going to be the same anyway.If you find yourselves building systems where it is necessary to specify the size of the integers you are using and so tend to use Int16, Int32, UInt16, UInt32 etc. then it might look more natural to use String - and when moving around between different .net languages it might make things more understandable - otherwise I would use string and int.",
                "I prefer the capitalized .NET types (rather than the aliases) for formatting reasons. The .NET types are colored the same as other object types (the value types are proper objects, after all).Conditional and control keywords (like if, switch, and return) are lowercase and colored dark blue (by default). And I would rather not have the disagreement in use and format.Consider:",
                "This YouTube video demonstrates practically how they differ.But now for a long textual answer.When we talk about .NET there are two different things one there is .NET framework and the other there are languages (C#, VB.NET etc) which use that framework.\"System.String\" a.k.a \"String\" (capital \"S\") is a .NET framework data type while \"string\" is a C# data type.In short \"String\" is an alias (the same thing called with different names) of \"string\". So technically both the below code statements will give the same output.orIn the same way, there are aliases for other C# data types as shown below:object: System.Object, string: System.String, bool: System.Boolean, byte: System.Byte, sbyte: System.SByte, short: System.Int16 and so on.Now the million-dollar question from programmer's point of view: So when to use \"String\" and \"string\"?The first thing to avoid confusion use one of them consistently. But from best practices perspective when you do variable declaration it's good to use \"string\" (small \"s\") and when you are using it as a class name then \"String\" (capital \"S\") is preferred.In the below code the left-hand side is a variable declaration and it is declared using \"string\". On the right-hand side, we are calling a method so \"String\" is more sensible.",
                "string and String are identical in all ways (except the uppercase \"S\").  There are no performance implications either way.Lowercase string is preferred in most projects due to the syntax highlighting",
                "C# is a language which is used together with the CLR.string is a type in C#.System.String is a type in the CLR.When you use C# together with the CLR string will be mapped to System.String.Theoretically, you could implement a C#-compiler that generated Java bytecode. A sensible implementation of this compiler would probably map string to java.lang.String in order to interoperate with the Java runtime library.",
                "Lower case string is an alias for System.String.\nThey are the same in C#.There's a debate over whether you should use the System types (System.Int32, System.String, etc.) types or the C# aliases (int, string, etc). I personally believe you should use the C# aliases, but that's just my personal preference.",
                "string is just an alias for System.String. The compiler will treat them identically.The only practical difference is the syntax highlighting as you mention, and that you have to write using System if you use String.",
                "Both are same. But from coding guidelines perspective it's better to use string instead of String. This is what generally developers use. e.g. instead of using Int32 we use int as int is alias to Int32FYI\n\u201cThe keyword string is simply an alias for the predefined class System.String.\u201d - C# Language Specification 4.2.3\nhttp://msdn2.microsoft.com/En-US/library/aa691153.aspx",
                "As the others are saying, they're the same.  StyleCop rules, by default, will enforce you to use string as a C# code style best practice, except when referencing System.String static functions, such as String.Format, String.Join, String.Concat, etc...",
                "New answer after 6 years and 5 months (procrastination).While string is a reserved C# keyword that always has a fixed meaning, String is just an ordinary identifier which could refer to anything. Depending on members of the current type, the current namespace and the applied using directives and their placement, String could be a value or a type distinct from global::System.String.I shall provide two examples where using directives will not help.First, when String is a value of the current type (or a local variable):The above will not compile because IEnumerable<> does not have a non-static member called Format, and no extension methods apply. In the above case, it may still be possible to use String in other contexts where a type is the only possibility syntactically. For example String local = \"Hi mum!\"; could be OK (depending on namespace and using directives).Worse: Saying String.Concat(someSequence) will likely (depending on usings) go to the Linq extension method Enumerable.Concat. It will not go to the static method string.Concat.Secondly, when String is another type, nested inside the current type:Neither statement in the Example method compiles. Here String is always a piano string, MyPiano.String. No member (static or not) Format exists on it (or is inherited from its base class). And the value \"Goodbye\" cannot be converted into it.",
                "Using System types makes it easier to port between C# and VB.Net, if you are into that sort of thing.",
                "Against what seems to be common practice among other programmers, I prefer String over string, just to highlight the fact that String is a reference type, as Jon Skeet mentioned.",
                "string is an alias (or shorthand) of System.String. That means, by typing string we meant System.String. You can read more in think link: 'string' is an alias/shorthand of System.String.",
                "I'd just like to add this to lfousts answer, from Ritchers book:The C# language specification states, \u201cAs a matter of style, use of the keyword is favored over\n  use of the complete system type name.\u201d I disagree with the language specification; I prefer\n  to use the FCL type names and completely avoid the primitive type names. In fact, I wish that\n  compilers didn\u2019t even offer the primitive type names and forced developers to use the FCL\n  type names instead. Here are my reasons:I\u2019ve seen a number of developers confused, not knowing whether to use string\n  or String in their code. Because in C# string (a keyword) maps exactly to\n  System.String (an FCL type), there is no difference and either can be used. Similarly,\n  I\u2019ve heard some developers say that int represents a 32-bit integer when the application\n  is running on a 32-bit OS and that it represents a 64-bit integer when the application\n  is running on a 64-bit OS. This statement is absolutely false: in C#, an int always maps\n  to System.Int32, and therefore it represents a 32-bit integer regardless of the OS the\n  code is running on. If programmers would use Int32 in their code, then this potential\n  confusion is also eliminated.In C#, long maps to System.Int64, but in a different programming language, long\n  could map to an Int16 or Int32. In fact, C++/CLI does treat long as an Int32.\n  Someone reading source code in one language could easily misinterpret the code\u2019s\n  intention if he or she were used to programming in a different programming language.\n  In fact, most languages won\u2019t even treat long as a keyword and won\u2019t compile code\n  that uses it.The FCL has many methods that have type names as part of their method names. For\n  example, the BinaryReader type offers methods such as ReadBoolean, ReadInt32,\n  ReadSingle, and so on, and the System.Convert type offers methods such as\n  ToBoolean, ToInt32, ToSingle, and so on. Although it\u2019s legal to write the following\n  code, the line with float feels very unnatural to me, and it\u2019s not obvious that the line is\n  correct:Many programmers that use C# exclusively tend to forget that other programming\n  languages can be used against the CLR, and because of this, C#-isms creep into the\n  class library code. For example, Microsoft\u2019s FCL is almost exclusively written in C# and\n  developers on the FCL team have now introduced methods into the library such as\n  Array\u2019s GetLongLength, which returns an Int64 value that is a long in C# but not\n  in other languages (like C++/CLI). Another example is System.Linq.Enumerable\u2019s\n  LongCount method.I didn't get his opinion before I read the complete paragraph.",
                "String (System.String) is a class in the base class library. string (lower case) is a reserved work in C# that is an alias for System.String. Int32 vs int is a similar situation as is Boolean vs. bool. These C# language specific keywords enable you to declare primitives in a style similar to C.",
                "It's a matter of convention, really.  string just looks more like C/C++ style.  The general convention is to use whatever shortcuts your chosen language has provided (int/Int for Int32).  This goes for \"object\" and decimal as well.Theoretically this could help to port code into some future 64-bit standard in which \"int\" might mean Int64, but that's not the point, and I would expect any upgrade wizard to change any int references to Int32 anyway just to be safe.",
                "@JaredPar (a developer on the C# compiler and prolific SO user!) wrote a great blog post on this issue. I think it is worth sharing here. It is a nice perspective on our subject.[...]The keyword string has concrete meaning in C#. It is the type System.String which exists in the core runtime assembly. The runtime intrinsically understands this type and provides the capabilities developers expect for strings in .NET. Its presence is so critical to C# that if that type doesn\u2019t exist the compiler will exit before attempting to even parse a line of code. Hence string has a precise, unambiguous meaning in C# code.The identifier String though has no concrete meaning in C#. It is an identifier that goes through all the name lookup rules as Widget, Student, etc \u2026 It could bind to string or it could bind to a type in another assembly entirely whose purposes may be entirely different than string. Worse it could be defined in a way such that code like String s = \"hello\"; continued to compile.The actual meaning of String will always depend on name resolution.\nThat means it depends on all the source files in the project and all\nthe types defined in all the referenced assemblies. In short it\nrequires quite a bit of context to know what it means.True that in the vast majority of cases String and string will bind to\nthe same type. But using String still means developers are leaving\ntheir program up to interpretation in places where there is only one\ncorrect answer. When String does bind to the wrong type it can leave\ndevelopers debugging for hours, filing bugs on the compiler team, and\ngenerally wasting time that could\u2019ve been saved by using string.Another way to visualize the difference is with this sample:Many will argue that while this is information technically accurate using String is still fine because it\u2019s exceedingly rare that a codebase would define a type of this name. Or that when String is defined it\u2019s a sign of a bad codebase.[...]You\u2019ll see that String is defined for a number of completely valid purposes: reflection helpers, serialization libraries, lexers, protocols, etc \u2026 For any of these libraries String vs. string has real consequences depending on where the code is used.So remember when you see the String vs. string debate this is about semantics, not style. Choosing string gives crisp meaning to your codebase. Choosing String isn\u2019t wrong but it\u2019s leaving the door open for surprises in the future.Note: I copy/pasted most of the blog posts for archive reasons. I ignore some parts, so I recommend skipping and reading the blog post if you can.",
                "String is not a keyword and it can be used as Identifier whereas string is a keyword and cannot be used as Identifier. And in function point of view both are same.",
                "Coming late to the party: I use the CLR types 100% of the time (well, except if forced to use the C# type, but I don't remember when the last time that was).I originally started doing this years ago, as per the CLR books by Ritchie. It made sense to me that all CLR languages ultimately have to be able to support the set of CLR types, so using the CLR types yourself provided clearer, and possibly more \"reusable\" code.Now that I've been doing it for years, it's a habit and I like the coloration that VS shows for the CLR types.The only real downer is that auto-complete uses the C# type, so I end up re-typing automatically generated types to specify the CLR type instead.Also, now, when I see \"int\" or \"string\", it just looks really wrong to me, like I'm looking at 1970's C code.",
                "There is no difference.The C# keyword string maps to the .NET type System.String - it is an alias that keeps to the naming conventions of the language.Similarly, int maps to System.Int32.",
                "There's a quote on this issue from Daniel Solis' book.All the predefined types  are mapped directly to\n  underlying .NET types. The C# type names (string) are simply aliases for the\n  .NET types (String or System.String), so using the .NET names works fine syntactically, although\n  this is discouraged. Within a C# program, you should use the C# names\n  rather than the .NET names.",
                "Yes, that's no difference between them, just like the bool and Boolean.",
                "string is a keyword, and you can't use string as an identifier.String is not a keyword, and you can use it as an identifier:ExampleThe keyword string  is an alias for\n System.String aside from the keyword issue, the two are exactly\n equivalent."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I remove a property from a JavaScript object?",
                "Given an object:\nlet myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\nHow do I remove the property ..."
            ],
            "url": "https://stackoverflow.com/questions/208105",
            "answer": [
                "To remove a property from an object (mutating the object), you can do it like this:Demo\n\n\nvar myObject = {\n    \"ircEvent\": \"PRIVMSG\",\n    \"method\": \"newURI\",\n    \"regex\": \"^http://.*\"\n};\ndelete myObject.regex;\n\nconsole.log(myObject);For anyone interested in reading more about it, Stack Overflow user kangax has written an incredibly in-depth blog post about the delete statement on their blog, Understanding delete. It is highly recommended.If you'd like a new object with all the keys of the original except some, you could use destructuring.Demo\n\n\nlet myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\n// assign the key regex to the variable _ indicating it will be unused\nconst {regex: _, ...newObj} = myObject;\n\nconsole.log(newObj);   // has no 'regex' key\nconsole.log(myObject); // remains unchanged",
                "Objects in JavaScript can be thought of as maps between keys and values. The delete operator is used to remove these keys, more commonly known as object properties, one at a time.var obj = {\r\n  myProperty: 1    \r\n}\r\nconsole.log(obj.hasOwnProperty('myProperty')) // true\r\ndelete obj.myProperty\r\nconsole.log(obj.hasOwnProperty('myProperty')) // falseThe delete operator does not directly free memory, and it differs from simply assigning the value of null or undefined to a property, in that the property itself is removed from the object. Note that if the value of a deleted property was a reference type (an object), and another part of your program still holds a reference to that object, then that object will, of course, not be garbage collected until all references to it have disappeared.delete will only work on properties whose descriptor marks them as configurable.",
                "Old question, modern answer. Using object destructuring, an ECMAScript\u00a06 feature, it's as simple as:Or with the questions sample:You can see it in action in the Babel try-out editor.Edit:To reassign to the same variable, use a let:",
                "var myObject = {\"ircEvent\": \"PRIVMSG\", \"method\": \"newURI\", \"regex\": \"^http://.*\"};\r\n    \r\ndelete myObject.regex;\r\n\r\nconsole.log ( myObject.regex); // logs: undefinedThis works in Firefox and Internet\u00a0Explorer, and I think it works in all others.",
                "The delete operator is used to remove properties from objects.Note that, for arrays, this is not the same as removing an element. To remove an element from an array, use Array#splice or Array#pop. For example:Strictly speaking, it's impossible to truly delete anything in JavaScript. The delete operator neither deletes objects nor frees memory. Rather, it sets its operand to undefined and manipulates the parent object so that the member is gone.The object is not deleted. Only the reference is. Memory is only freed\nby the garbage collector when all references to an object are removed.Another important caveat is that the delete operator will not reorganize structures for you, which has results that can seem counterintuitive. Deleting an array index, for example, will leave a \"hole\" in it.This is because arrays are objects. So indices are the same as keys.Different built-in functions in JavaScript handle arrays with holes in them differently.for..in statements will skip the empty index completely.A naive for loop will yield undefined for the value at the index.Any method using Symbol.iterator will return undefined for the value at the index.forEach, map and reduce will simply skip the missing index, but will not remove itExample:So, the delete operator should not be used for the common use-case of removing elements from an array. Arrays have a dedicated methods for removing elements and reallocating memory: Array#splice() and Array#pop.Array#splice mutates the array, and returns any removed indices. deleteCount elements are removed from index start, and item1, item2... itemN are inserted into the array from index start. If deleteCount is omitted then elements from startIndex are removed to the end of the array.There is also a similarly named, but different, function on Array.prototype: Array#slice.Array#slice is non-destructive, and returns a new array containing the indicated indices from start to end. If end is left unspecified, it defaults to the end of the array. If end is positive, it specifies the zero-based non-inclusive index to stop at. If end is negative it, it specifies the index to stop at by counting back from the end of the array (eg. -1 will omit the final index). If end <= start, the result is an empty array.Array#pop removes the last element from an array, and returns that element. This operation changes the length of the array. The opposite operation is pushArray#shift is similar to pop, except it removes the first element. The opposite operation is unshift.",
                "To complete Koen's answer, in case you want to remove a dynamic variable using the spread syntax, you can do it like so:const key = 'a';\n\nconst { [key]: foo, ...rest } = { a: 1, b: 2, c: 3 };\n\nconsole.log(foo);  // 1\nconsole.log(rest); // { b: 2, c: 3 }* foo will be a new variable with the value of a (which is 1).There are a few common ways to remove a property from an object. Each one has its own pros and cons (check this performance comparison):Delete OperatorIt is readable and short, however, it might not be the best choice if you are operating on a large number of objects as its performance is not optimized.ReassignmentIt is more than two times faster than delete, however the property is not deleted and can be iterated.Spread OperatorThis ES6 operator allows us to return a brand new object, excluding any properties, without mutating the existing object. The downside is that it has the worse performance out of the above and is not suggested to be used when you need to remove many properties at a time.",
                "Another alternative is to use the Underscore.js library.Note that _.pick() and _.omit() both return a copy of the object and don't directly modify the original object. Assigning the result to the original object should do the trick (not shown).Reference: link _.pick(object, *keys)Return a copy of the object, filtered to only have values for the \nwhitelisted keys (or array of valid keys).Reference: link _.omit(object, *keys)Return a copy of the object, filtered to omit the \nblacklisted keys (or array of keys).For arrays, _.filter() and _.reject() can be used in a similar manner.",
                "To clone an object without a property:For example:And we need to delete a.With an explicit prop key:With a variable prop key:A cool arrow function \ud83d\ude0e:For multiple propertiesUsageOr",
                "The term you have used in your question title, Remove a property from a JavaScript object, can be interpreted in some different ways. The one is to remove it for whole the memory and the list of object keys or the other is just to remove it from your object. As it has been mentioned in some other answers, the delete keyword is the main part. Let's say you have your object like:If you do:the result would be:You can delete that specific key from your object keys like:Then your objects key using Object.keys(myJSONObject) would be:But the point is if you care about memory and you want to whole the object gets removed from the memory, it is recommended to set it to null before you delete the key:The other important point here is to be careful about your other references to the same object. For instance, if you create a variable like:Or add it as a new pointer to another object like:Then even if you remove it from your object myJSONObject, that specific object won't get deleted from the memory, since the regex variable and myOtherObject[\"regex\"] still have their values. Then how could we remove the object from the memory for sure?The answer would be to delete all the references you have in your code, pointed to that very object and also not use var statements to create new references to that object. This last point regarding var statements, is one of the most crucial issues that we are usually faced with, because using var statements would prevent the created object from getting removed.Which means in this case you won't be able to remove that object because you have created the regex variable via a var statement, and if you do:The result would be false, which means that your delete statement haven't been executed as you expected. But if you had not created that variable before, and you only had myOtherObject[\"regex\"] as your last existing reference, you could have done this just by removing it like:In other words, a JavaScript object is eligible to be killed as soon as there is no reference left in your code pointed to that object.Update:Thanks to @AgentME:Setting a property to null before deleting it doesn't accomplish\nanything (unless the object has been sealed by Object.seal and the\ndelete fails. That's not usually the case unless you specifically\ntry).To get more information on Object.seal: Object.seal()",
                "ECMAScript 2015 (or ES6) came with built-in Reflect object. It is possible to delete object property by calling Reflect.deleteProperty() function with target object and property key as parameters:which is equivalent to:But if the property of the object is not configurable it cannot be deleted neither with deleteProperty function nor delete operator:Object.freeze() makes all properties of object not configurable (besides other things). deleteProperty function (as well as delete operator) returns false when tries to delete any of it's properties. If property is configurable it returns true, even if property does not exist.The difference between delete and deleteProperty is when using strict mode:",
                "Suppose you have an object that looks like this:If you want to use the entire staff array, the proper way to do this, would be to do this:Alternatively, you could also do this:Similarly, removing the entire students array would be done by calling delete Hogwarts.students; or delete Hogwarts['students'];.Now, if you want to remove a single staff member or student, the procedure is a bit different, because both properties are arrays themselves.If you know the index of your staff member, you could simply do this:If you do not know the index, you'll also have to do an index search:While you technically can use delete for an array, using it would result in getting incorrect results when calling for example Hogwarts.staff.length later on. In other words, delete would remove the element, but it wouldn't update the value of length property. Using delete would also mess up your indexing.So, when deleting values from an object, always first consider whether you're dealing with object properties or whether you're dealing with array values, and choose the appropriate strategy based on that.If you want to experiment with this, you can use this Fiddle as a starting point.",
                "I personally use Underscore.js or Lodash for object and array manipulation:",
                "Using delete method is the best way to do that, as per MDN description, the delete operator removes a property from an object. So you can simply write:The delete operator removes a given property from an object. On\nsuccessful deletion, it will return true, else false will be returned.\nHowever, it is important to consider the following scenarios:The following snippet gives another simple example:var Employee = {\n  age: 28,\n  name: 'Alireza',\n  designation: 'developer'\n}\n\nconsole.log(delete Employee.name);   // returns true\nconsole.log(delete Employee.age);    // returns true\n\n// When trying to delete a property that does \n// not exist, true is returned \nconsole.log(delete Employee.salary); // returns trueFor more info about and seeing more examples visit the link below:https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/delete",
                "Another solution, using Array#reduce.var myObject = {\r\n  \"ircEvent\": \"PRIVMSG\",\r\n  \"method\": \"newURI\",\r\n  \"regex\": \"^http://.*\"\r\n};\r\n\r\nmyObject = Object.keys(myObject).reduce(function(obj, key) {\r\n  if (key != \"regex\") {           //key you want to remove\r\n    obj[key] = myObject[key];\r\n  }\r\n  return obj;\r\n}, {});\r\n\r\nconsole.log(myObject);However, it will mutate the original object. If you want to create a new object without the specified key, just assign the reduce function to a new variable, e.g.:(ES6)const myObject = {\r\n  ircEvent: 'PRIVMSG',\r\n  method: 'newURI',\r\n  regex: '^http://.*',\r\n};\r\n\r\nconst myNewObject = Object.keys(myObject).reduce((obj, key) => {\r\n  key !== 'regex' ? obj[key] = myObject[key] : null;\r\n  return obj;\r\n}, {});\r\n\r\nconsole.log(myNewObject);",
                "There are a lot of good answers here but I just want to chime in that when using delete to remove a property in JavaScript, it is often wise to first check if that property exists to prevent errors.E.gDue to the dynamic nature of JavaScript there are often cases where you simply don't know if the property exists or not. Checking if obj exists before the && also makes sure you don't throw an error due to calling the hasOwnProperty() function on an undefined object.Sorry if this didn't add to your specific use case but I believe this to be a good design to adapt when managing objects and their properties.",
                "This post is very old and I find it very helpful so I decided to share the unset function I wrote in case someone else see this post and think why it's not so simple as it in PHP unset function.The reason for writing this new unset function, is to keep the index of all other variables in this hash_map. Look at the following example, and see how the index of \"test2\" did not change after removing a value from the hash_map.function unset(unsetKey, unsetArr, resort) {\n  var tempArr = unsetArr;\n  var unsetArr = {};\n  delete tempArr[unsetKey];\n  if (resort) {\n    j = -1;\n  }\n  for (i in tempArr) {\n    if (typeof(tempArr[i]) !== 'undefined') {\n      if (resort) {\n        j++;\n      } else {\n        j = i;\n      }\n      unsetArr[j] = tempArr[i];\n    }\n  }\n  return unsetArr;\n}\n\nvar unsetArr = ['test', 'deletedString', 'test2'];\n\nconsole.log(unset('1', unsetArr, true)); // output Object {0: \"test\", 1: \"test2\"}\nconsole.log(unset('1', unsetArr, false)); // output Object {0: \"test\", 2: \"test2\"}",
                "Try the following method. Assign the Object property value to undefined. Then stringify the object and parse.var myObject = {\"ircEvent\": \"PRIVMSG\", \"method\": \"newURI\", \"regex\": \"^http://.*\"};\r\n\r\nmyObject.regex = undefined;\r\nmyObject = JSON.parse(JSON.stringify(myObject));\r\n\r\nconsole.log(myObject);",
                "Using ramda#dissoc you will get a new object without the attribute regex:You can also use other functions to achieve the same effect - omit, pick, ...",
                "There are a couple of ways to remove properties from an object:const myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\",\n};\n\ndelete myObject.regex;\nconsole.log(myObject);const myObject = {\n      \"ircEvent\": \"PRIVMSG\",\n      \"method\": \"newURI\",\n      \"regex\": \"^http://.*\",\n    };\n\ndelete myObject['regex'];\nconsole.log(myObject);\n// or\nconst name = 'ircEvent';\ndelete myObject[name];\nconsole.log(myObject);const myObject = {\n      \"ircEvent\": \"PRIVMSG\",\n      \"method\": \"newURI\",\n      \"regex\": \"^http://.*\",\n    };\n\nconst { regex, ...myObjectRest} = myObject;\nconsole.log(myObjectRest);",
                "If you want to delete a property deeply nested in the object then you can use the following recursive function with path to the property as the second argument:Example:",
                "const obj = {\r\n    \"Filters\":[\r\n        {\r\n            \"FilterType\":\"between\",\r\n            \"Field\":\"BasicInformationRow.A0\",\r\n            \"MaxValue\":\"2017-10-01\",\r\n            \"MinValue\":\"2017-09-01\",\r\n            \"Value\":\"Filters value\"\r\n        }\r\n    ]\r\n};\r\n\r\nlet new_obj1 = Object.assign({}, obj.Filters[0]);\r\nlet new_obj2 = Object.assign({}, obj.Filters[0]);\r\n\r\n/*\r\n\r\n// old version\r\n\r\nlet shaped_obj1 = Object.keys(new_obj1).map(\r\n    (key, index) => {\r\n        switch (key) {\r\n            case \"MaxValue\":\r\n                delete new_obj1[\"MaxValue\"];\r\n                break;\r\n            case \"MinValue\":\r\n                delete new_obj1[\"MinValue\"];\r\n                break;\r\n        }\r\n        return new_obj1;\r\n    }\r\n)[0];\r\n\r\n\r\nlet shaped_obj2 = Object.keys(new_obj2).map(\r\n    (key, index) => {\r\n        if(key === \"Value\"){\r\n            delete new_obj2[\"Value\"];\r\n        }\r\n        return new_obj2;\r\n    }\r\n)[0];\r\n\r\n\r\n*/\r\n\r\n\r\n// new version!\r\n\r\nlet shaped_obj1 = Object.keys(new_obj1).forEach(\r\n    (key, index) => {\r\n        switch (key) {\r\n            case \"MaxValue\":\r\n                delete new_obj1[\"MaxValue\"];\r\n                break;\r\n            case \"MinValue\":\r\n                delete new_obj1[\"MinValue\"];\r\n                break;\r\n            default:\r\n                break;\r\n        }\r\n    }\r\n);\r\n\r\nlet shaped_obj2 = Object.keys(new_obj2).forEach(\r\n    (key, index) => {\r\n        if(key === \"Value\"){\r\n            delete new_obj2[\"Value\"];\r\n        }\r\n    }\r\n);",
                "Here's an ES6 way to remove the entry easily:let myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\nconst removeItem = 'regex';\n\nconst { [removeItem]: remove, ...rest } = myObject;\n\nconsole.log(remove); // \"^http://.*\"\nconsole.log(rest); // Object { ircEvent: \"PRIVMSG\", method: \"newURI\" }",
                "Dan's assertion that 'delete' is very slow and the benchmark he posted were doubted. So I carried out the test myself in Chrome 59. It does seem that 'delete' is about 30 times slower:Note that I purposely carried out more than one 'delete' operations in one loop cycle to minimize the effect caused by the other operations.",
                "There are many different options presented on this page, not because most of the options are wrong\u2014or because the answers are duplicates\u2014but because the appropriate technique depends on the situation you're in and the goals of the tasks you and/or you team are trying to fulfill. To answer you question unequivocally, one needs to know:Once those four queries have been answered, there are essentially four categories of \"property removal\" in JavaScript to chose from in order to meet your goals. They are:This category is for operating on object literals or object instances when you want to retain/continue to use the original reference and aren't using stateless functional principles in your code. An example piece of syntax in this category:This category is the oldest, most straightforward & most widely supported category of property removal. It supports Symbol & array indexes in addition to strings and works in every version of JavaScript except for the very first release. However, it's mutative which violates some programming principles and has performance implications. It also can result in uncaught exceptions when used on non-configurable properties in strict mode.This category is for operating on plain object or array instances in newer ECMAScript flavors when a non-mutative approach is desired and you don't need to account for Symbol keys:This category is for operating on object literals or object instances when you want to retain/continue to use the original reference while guarding against exceptions being thrown on unconfigurable properties:In addition, while mutating objects in-place isn't stateless, you can use the functional nature of Reflect.deleteProperty to do partial application and other functional techniques that aren't possible with delete statements.This category is for operating on plain object or array instances in newer ECMAScript flavors when a non-mutative approach is desired and you don't need to account for Symbol keys:This category is generally allows for greater functional flexibility, including accounting for Symbols & omitting more than one property in one statement:",
                "You can use a filter like belowvar myObject = {\n    \"ircEvent\": \"PRIVMSG\",\n    \"method\": \"newURI\",\n    \"regex\": \"^http://.*\"\n};\n\n// Way 1\n\nlet filter1 = {}\n  Object.keys({...myObject}).filter(d => {\n  if(d !== 'regex'){\n    filter1[d] = myObject[d];\n  }\n})\n\nconsole.log(filter1)\n\n// Way 2\n\nlet filter2 = Object.fromEntries(Object.entries({...myObject}).filter(d =>\nd[0] !== 'regex'\n))\n\nconsole.log(filter2)",
                "@johnstock, we can also use JavaScript's prototyping concept to add method to objects to delete any passed key available in calling object.Above answers are appreciated.var myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\n// 1st and direct way \ndelete myObject.regex; // delete myObject[\"regex\"]\nconsole.log(myObject); // { ircEvent: 'PRIVMSG', method: 'newURI' }\n\n// 2 way -  by using the concept of JavaScript's prototyping concept\nObject.prototype.removeFromObjectByKey = function(key) {\n  // If key exists, remove it and return true\n  if (this[key] !== undefined) {\n    delete this[key]\n    return true;\n  }\n  // Else return false\n  return false;\n}\n\nvar isRemoved = myObject.removeFromObjectByKey('method')\nconsole.log(myObject) // { ircEvent: 'PRIVMSG' }\n\n// More examples\nvar obj = {\n  a: 45,\n  b: 56,\n  c: 67\n}\nconsole.log(obj) // { a: 45, b: 56, c: 67 }\n\n// Remove key 'a' from obj\nisRemoved = obj.removeFromObjectByKey('a')\nconsole.log(isRemoved); //true\nconsole.log(obj); // { b: 56, c: 67 }\n\n// Remove key 'd' from obj which doesn't exist\nvar isRemoved = obj.removeFromObjectByKey('d')\nconsole.log(isRemoved); // false\nconsole.log(obj); // { b: 56, c: 67 }",
                "I have used Lodash \"unset\" to make it happen for a nested object also... only this needs to write small logic to get the path of the property key which is expected by the omit method.var a = {\"bool\":{\"must\":[{\"range\":{\"price_index.final_price\":{\"gt\":\"450\", \"lt\":\"500\"}}}, {\"bool\":{\"should\":[{\"term\":{\"color_value.keyword\":\"Black\"}}]}}]}};\n\nfunction getPathOfKey(object,key,currentPath, t){\n    var currentPath = currentPath || [];\n\n    for(var i in object){\n        if(i == key){\n            t = currentPath;\n        }\n        else if(typeof object[i] == \"object\"){\n            currentPath.push(i)\n            return getPathOfKey(object[i], key,currentPath)\n        }\n    }\n    t.push(key);\n    return t;\n}\ndocument.getElementById(\"output\").innerHTML =JSON.stringify(getPathOfKey(a,\"price_index.final_price\"))\n<div id=\"output\">\n\n</div>var unset = require('lodash.unset');\nunset(a, getPathOfKey(a, \"price_index.final_price\"));",
                "let myObject = {\n    \"ircEvent\": \"PRIVMSG\",\n    \"method\": \"newURI\",\n    \"regex\": \"^http://.*\"\n};\n\n\nobj = Object.fromEntries(\n    Object.entries(myObject).filter(function (m){\n        return m[0] != \"regex\"/*or whatever key to delete*/\n    }\n))\n\nconsole.log(obj)You can also just treat the object like a2d array using Object.entries, and use splice to remove an element as you would in a normal array, or simply filter through the object, as one would an array, and assign the reconstructed object back to the original variable",
                "If you don't want to modify the original object.Remove a property without mutating the objectIf mutability is a concern, you can create a completely new object by copying all the properties from the old, except the one you want to remove.let myObject = {\n  \"ircEvent\": \"PRIVMSG\",\n  \"method\": \"newURI\",\n  \"regex\": \"^http://.*\"\n};\n\nlet prop = 'regex';\nconst updatedObject = Object.keys(myObject).reduce((object, key) => {\n  if (key !== prop) {\n    object[key] = myObject[key]\n  }\n  return object\n}, {})\n\nconsole.log(updatedObject);"
            ]
        },
        {
            "tag": "",
            "question": [
                "What are metaclasses in Python?",
                "What are metaclasses? What are they used for?"
            ],
            "url": "https://stackoverflow.com/questions/100003",
            "answer": [
                "Before understanding metaclasses, you need to master classes in Python. And Python has a very peculiar idea of what classes are, borrowed from the Smalltalk language.In most languages, classes are just pieces of code that describe how to produce an object. That's kinda true in Python too:But classes are more than that in Python. Classes are objects too.Yes, objects.As soon as you use the keyword class, Python executes it and creates\nan object. The instructioncreates in memory an object with the name ObjectCreator.This object (the class) is itself capable of creating objects (the instances),\nand this is why it's a class.But still, it's an object, and therefore:e.g.:Since classes are objects, you can create them on the fly, like any object.First, you can create a class in a function using class:But it's not so dynamic, since you still have to write the whole class yourself.Since classes are objects, they must be generated by something.When you use the class keyword, Python creates this object automatically. But as\nwith most things in Python, it gives you a way to do it manually.Remember the function type? The good old function that lets you know what\ntype an object is:Well, type has also a completely different ability: it can create classes on the fly. type can take the description of a class as parameters,\nand return a class.(I  know, it's silly that the same function can have two completely different uses according to the parameters you pass to it. It's an issue due to backward\ncompatibility in Python)type works this way:Where:e.g.:can be created manually this way:You'll notice that we use MyShinyClass as the name of the class\nand as the variable to hold the class reference. They can be different,\nbut there is no reason to complicate things.type accepts a dictionary to define the attributes of the class. So:Can be translated to:And used as a normal class:And of course, you can inherit from it, so:would be:Eventually, you'll want to add methods to your class. Just define a function\nwith the proper signature and assign it as an attribute.And you can add even more methods after you dynamically create the class, just like adding methods to a normally created class object.You see where we are going: in Python, classes are objects, and you can create a class on the fly, dynamically.This is what Python does when you use the keyword class, and it does so by using a metaclass.Metaclasses are the 'stuff' that creates classes.You define classes in order to create objects, right?But we learned that Python classes are objects.Well, metaclasses are what create these objects. They are the classes' classes,\nyou can picture them this way:You've seen that type lets you do something like this:It's because the function type is in fact a metaclass. type is the\nmetaclass Python uses to create all classes behind the scenes.Now you wonder \"why the heck is it written in lowercase, and not Type?\"Well, I guess it's a matter of consistency with str, the class that creates\nstrings objects, and int the class that creates integer objects. type is\njust the class that creates class objects.You see that by checking the __class__ attribute.Everything, and I mean everything, is an object in Python. That includes integers,\nstrings, functions and classes. All of them are objects. And all of them have\nbeen created from a class:Now, what is the __class__ of any __class__ ?So, a metaclass is just the stuff that creates class objects.You can call it a 'class factory' if you wish.type is the built-in metaclass Python uses, but of course, you can create your\nown metaclass.In Python 2, you can add a __metaclass__ attribute when you write a class (see next section for the Python 3 syntax):If you do so, Python will use the metaclass to create the class Foo.Careful, it's tricky.You write class Foo(object) first, but the class object Foo is not created\nin memory yet.Python will look for __metaclass__ in the class definition. If it finds it,\nit will use it to create the object class Foo. If it doesn't, it will use\ntype to create the class.Read that several times.When you do:Python does the following:Is there a __metaclass__ attribute in Foo?If yes, create in-memory a class object (I said a class object, stay with me here), with the name Foo by using what is in __metaclass__.If Python can't find __metaclass__, it will look for a __metaclass__ at the MODULE level, and try to do the same (but only for classes that don't inherit anything, basically old-style classes).Then if it can't find any __metaclass__ at all, it will use the Bar's (the first parent) own metaclass (which might be the default type) to create the class object.Be careful here that the __metaclass__ attribute will not be inherited, the metaclass of the parent (Bar.__class__) will be. If Bar used a __metaclass__ attribute that created Bar with type() (and not type.__new__()), the subclasses will not inherit that behavior.Now the big question is, what can you put in __metaclass__?The answer is something that can create a class.And what can create a class? type, or anything that subclasses or uses it.The syntax to set the metaclass has been changed in Python 3:i.e. the __metaclass__ attribute is no longer used, in favor of a keyword argument in the list of base classes.The behavior of metaclasses however stays largely the same.One thing added to metaclasses in Python 3 is that you can also pass attributes as keyword-arguments into a metaclass, like so:Read the section below for how Python handles this.The main purpose of a metaclass is to change the class automatically,\nwhen it's created.You usually do this for APIs, where you want to create classes matching the\ncurrent context.Imagine a stupid example, where you decide that all classes in your module\nshould have their attributes written in uppercase. There are several ways to\ndo this, but one way is to set __metaclass__ at the module level.This way, all classes of this module will be created using this metaclass,\nand we just have to tell the metaclass to turn all attributes to uppercase.Luckily, __metaclass__ can actually be any callable, it doesn't need to be a\nformal class (I know, something with 'class' in its name doesn't need to be\na class, go figure... but it's helpful).So we will start with a simple example, by using a function.Let's check:Now, let's do exactly the same, but using a real class for a metaclass:Let's rewrite the above, but with shorter and more realistic variable names now that we know what they mean:You may have noticed the extra argument cls. There is\nnothing special about it: __new__ always receives the class it's defined in, as the first parameter. Just like you have self for ordinary methods which receive the instance as the first parameter, or the defining class for class methods.But this is not proper OOP. We are calling type directly and we aren't overriding or calling the parent's __new__. Let's do that instead:We can make it even cleaner by using super, which will ease inheritance (because yes, you can have metaclasses, inheriting from metaclasses, inheriting from type):Oh, and in Python 3 if you do this call with keyword arguments, like this:It translates to this in the metaclass to use it:That's it. There is really nothing more about metaclasses.The reason behind the complexity of the code using metaclasses is not because\nof metaclasses, it's because you usually use metaclasses to do twisted stuff\nrelying on introspection, manipulating inheritance, vars such as __dict__, etc.Indeed, metaclasses are especially useful to do black magic, and therefore\ncomplicated stuff. But by themselves, they are simple:Since __metaclass__ can accept any callable, why would you use a class\nsince it's obviously more complicated?There are several reasons to do so:Now the big question. Why would you use some obscure error-prone feature?Well, usually you don't:Metaclasses are deeper magic that\n99% of users should never worry about it.\nIf you wonder whether you need them,\nyou don't (the people who actually\nneed them know with certainty that\nthey need them, and don't need an\nexplanation about why).Python Guru Tim PetersThe main use case for a metaclass is creating an API. A typical example of this is the Django ORM. It allows you to define something like this:But if you do this:It won't return an IntegerField object. It will return an int, and can even take it directly from the database.This is possible because models.Model defines __metaclass__ and\nit uses some magic that will turn the Person you just defined with simple statements\ninto a complex hook to a database field.Django makes something complex look simple by exposing a simple API\nand using metaclasses, recreating code from this API to do the real job\nbehind the scenes.First, you know that classes are objects that can create instances.Well, in fact, classes are themselves instances. Of metaclasses.Everything is an object in Python, and they are all either instance of classes\nor instances of metaclasses.Except for type.type is actually its own metaclass. This is not something you could\nreproduce in pure Python, and is done by cheating a little bit at the implementation\nlevel.Secondly, metaclasses are complicated. You may not want to use them for\nvery simple class alterations. You can change classes by using two different techniques:99% of the time you need class alteration, you are better off using these.But 98% of the time, you don't need class alteration at all.",
                "A metaclass is the class of a class. A class defines how an instance of the class (i.e. an object) behaves while a metaclass defines how a class behaves. A class is an instance of a metaclass.While in Python you can use arbitrary callables for metaclasses (like Jerub shows), the better approach is to make it an actual class itself. type is the usual metaclass in Python. type is itself a class, and it is its own type. You won't be able to recreate something like type purely in Python, but Python cheats a little. To create your own metaclass in Python you really just want to subclass type.A metaclass is most commonly used as a class-factory. When you create an object by calling the class, Python creates a new class (when it executes the 'class' statement) by calling the metaclass. Combined with the normal __init__ and __new__ methods, metaclasses therefore allow you to do 'extra things' when creating a class, like registering the new class with some registry or replace the class with something else entirely.When the class statement is executed, Python first executes the body of the class statement as a normal block of code. The resulting namespace (a dict) holds the attributes of the class-to-be. The metaclass is determined by looking at the baseclasses of the class-to-be (metaclasses are inherited), at the __metaclass__ attribute of the class-to-be (if any) or the __metaclass__ global variable. The metaclass is then called with the name, bases and attributes of the class to instantiate it.However, metaclasses actually define the type of a class, not just a factory for it, so you can do much more with them. You can, for instance, define normal methods on the metaclass. These metaclass-methods are like classmethods in that they can be called on the class without an instance, but they are also not like classmethods in that they cannot be called on an instance of the class. type.__subclasses__() is an example of a method on the type metaclass. You can also define the normal 'magic' methods, like __add__, __iter__ and __getattr__, to implement or change how the class behaves.Here's an aggregated example of the bits and pieces:",
                "Note, this answer is for Python 2.x as it was written in 2008, metaclasses are slightly different in 3.x.Metaclasses are the secret sauce that make 'class' work. The default metaclass for a new style object is called 'type'.Metaclasses take 3 args. 'name', 'bases' and 'dict'Here is where the secret starts. Look for where name, bases and the dict come from in this example class definition.Lets define a metaclass that will demonstrate how 'class:' calls it.And now, an example that actually means something, this will automatically make the variables in the list \"attributes\" set on the class, and set to None.Note that the magic behaviour that Initialised gains by having the metaclass init_attributes is not passed onto a subclass of Initialised.Here is an even more concrete example, showing how you can subclass 'type' to make a metaclass that performs an action when the class is created. This is quite tricky:",
                "Others have explained how metaclasses work and how they fit into the Python type system. Here's an example of what they can be used for. In a testing framework I wrote, I wanted to keep track of the order in which classes were defined, so that I could later instantiate them in this order. I found it easiest to do this using a metaclass.Anything that's a subclass of MyType then gets a class attribute _order that records the order in which the classes were defined.",
                "One use for metaclasses is adding new properties and methods to an instance automatically.For example, if you look at Django models, their definition looks a bit confusing. It looks as if you are only defining class properties:However, at runtime the Person objects are filled with all sorts of useful methods. See the source for some amazing metaclassery.",
                "I think the ONLamp introduction to metaclass programming is well written and gives a really good introduction to the topic despite being several years old already.http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html (archived at https://web.archive.org/web/20080206005253/http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html)In short: A class is a blueprint for the creation of an instance, a metaclass is a blueprint for the creation of a class. It can be easily seen that in Python classes need to be first-class objects too to enable this behavior.I've never written one myself, but I think one of the nicest uses of metaclasses can be seen in the Django framework. The model classes use a metaclass approach to enable a declarative style of writing new models or form classes. While the metaclass is creating the class, all members get the possibility to customize the class itself.The thing that's left to say is: If you don't know what metaclasses are, the probability that you will not need them is 99%.",
                "TLDR: A metaclass instantiates and defines behavior for a class just like a class instantiates and defines behavior for an instance.Pseudocode:The above should look familiar. Well, where does Class come from? It's an instance of a metaclass (also pseudocode):In real code, we can pass the default metaclass, type, everything we need to instantiate a class and we get a class:A class is to an instance as a metaclass is to a class.When we instantiate an object, we get an instance:Likewise, when we define a class explicitly with the default metaclass, type, we instantiate it:Put another way, a class is an instance of a metaclass:Put a third way, a metaclass is a class's class.When you write a class definition and Python executes it, it uses a metaclass to instantiate the class object (which will, in turn, be used to instantiate instances of that class).Just as we can use class definitions to change how custom object instances behave, we can use a metaclass class definition to change the way a class object behaves.What can they be used for? From the docs:The potential uses for metaclasses are boundless. Some ideas that have been explored include logging, interface checking, automatic delegation, automatic property creation, proxies, frameworks, and automatic resource locking/synchronization.Nevertheless, it is usually encouraged for users to avoid using metaclasses unless absolutely necessary.When you write a class definition, for example, like this,You instantiate a class object.It is the same as functionally calling type with the appropriate arguments and assigning the result to a variable of that name:Note, some things automatically get added to the __dict__, i.e., the namespace:The metaclass of the object we created, in both cases, is type.(A side-note on the contents of the class __dict__: __module__ is there because classes must know where they are defined, and  __dict__ and __weakref__ are there because we don't define __slots__ - if we define __slots__ we'll save a bit of space in the instances, as we can disallow __dict__ and __weakref__ by excluding them. For example:... but I digress.)Here's the default __repr__ of classes:One of the most valuable things we can do by default in writing a Python object is to provide it with a good __repr__. When we call help(repr) we learn that there's a good test for a __repr__ that also requires a test for equality - obj == eval(repr(obj)). The following simple implementation of __repr__ and __eq__ for class instances of our type class provides us with a demonstration that may improve on the default __repr__ of classes:So now when we create an object with this metaclass, the __repr__ echoed on the command line provides a much less ugly sight than the default:With a nice __repr__ defined for the class instance, we have a stronger ability to debug our code. However, much further checking with eval(repr(Class)) is unlikely (as functions would be rather impossible to eval from their default __repr__'s).If, for example, we want to know in what order a class's methods are created in, we could provide an ordered dict as the namespace of the class. We would do this with __prepare__ which returns the namespace dict for the class if it is implemented in Python 3:And usage:And now we have a record of the order in which these methods (and other class attributes) were created:Note, this example was adapted from the documentation - the new enum in the standard library does this.So what we did was instantiate a metaclass by creating a class. We can also treat the metaclass as we would any other class. It has a method resolution order:And it has approximately the correct repr (which we can no longer eval unless we can find a way to represent our functions.):",
                "Python 3 updateThere are (at this point) two key methods in a metaclass:__prepare__ lets you supply a custom mapping (such as an OrderedDict) to be used as the namespace while the class is being created.  You must return an instance of whatever namespace you choose.  If you don't implement __prepare__ a normal dict is used.__new__ is responsible for the actual creation/modification of the final class.A bare-bones, do-nothing-extra metaclass would like:A simple example:Say you want some simple validation code to run on your attributes -- like it must always be an int or a str.  Without a metaclass, your class would look something like:As you can see, you have to repeat the name of the attribute twice.  This makes typos possible along with irritating bugs.A simple metaclass can address that problem:This is what the metaclass would look like (not using __prepare__ since it is not needed):A sample run of:produces:Note:  This example is simple enough it could have also been accomplished with a class decorator, but presumably an actual metaclass would be doing much more.The 'ValidateType' class for reference:",
                "If you've done Python programming for more than a few months you'll eventually stumble upon code that looks like this:The latter is possible when you implement the __call__() magic method on the class.The __call__() method is invoked when an instance of a class is used as a callable. But as we've seen from previous answers a class itself is an instance of a metaclass, so when we use the class as a callable (i.e. when we create an instance of it) we're actually calling its metaclass' __call__() method. At this point most Python programmers are a bit confused because they've been told that when creating an instance like this instance = SomeClass() you're calling its __init__() method. Some who've dug a bit deeper know that before __init__() there's __new__(). Well, today another layer of truth is being revealed, before __new__() there's the metaclass' __call__().Let's study the method call chain from specifically the perspective of creating an instance of a class.This is a metaclass that logs exactly the moment before an instance is created and the moment it's about to return it.This is a class that uses that metaclassAnd now let's create an instance of Class_1Observe that the code above doesn't actually do anything more than logging the tasks. Each method delegates the actual work to its parent's implementation, thus keeping the default behavior. Since type is Meta_1's parent class (type being the default parent metaclass) and considering the ordering sequence of the output above, we now have a clue as to what would be the pseudo implementation of type.__call__():We can see that the metaclass' __call__() method is the one that's called first. It then delegates creation of the instance to the class's __new__() method and initialization to the instance's __init__(). It's also the one that ultimately returns the instance.From the above it stems that the metaclass' __call__() is also given the opportunity to decide whether or not a call to Class_1.__new__() or Class_1.__init__() will eventually be made. Over the course of its execution it could actually return an object that hasn't been touched by either of these methods. Take for example this approach to the singleton pattern:Let's observe what happens when repeatedly trying to create an object of type Class_2",
                "A metaclass is a class that tells how (some) other class should be created.This is a case where I saw metaclass as a solution to my problem:\nI had a really complicated problem, that probably could have been solved differently, but I chose to solve it using a metaclass.  Because of the complexity, it is one of the few modules I have written where the comments in the module surpass the amount of code that has been written.  Here it is...",
                "The type(obj) function gets you the type of an object.The type() of a class is its metaclass.To use a metaclass:type is its own metaclass. The class of a class is a metaclass-- the body of a class is the arguments passed to the metaclass that is used to construct the class.Here you can read about how to use metaclasses to customize class construction.",
                "type is actually a metaclass -- a class that creates another classes.\nMost metaclass are the subclasses of type. The metaclass receives the new class as its first argument and provide access to class object with details as mentioned below:Note:Notice that the class was not instantiated at any time; the simple act of creating the class triggered execution of the metaclass.",
                "Python classes are themselves objects - as in instance - of their meta-class.The default metaclass, which is applied when when you determine classes as:meta class are used to apply some rule to an entire set of classes. For example, suppose you're building an ORM to access a database, and you want records from each table to be of a class mapped to that table (based on fields, business rules, etc..,), a possible use of metaclass is for instance, connection pool logic, which is share by all classes of record from all tables. Another use is logic to to support foreign keys, which involves multiple classes of records.when you define metaclass, you subclass type, and can overrided the following magic methods to insert your logic.anyhow, those two are the most commonly used hooks. metaclassing is powerful, and above is nowhere near and exhaustive list of uses for metaclassing.",
                "The type() function can return the type of an object or create a new type,for example, we can create a Hi class with the type() function and do not  need to use this way with class Hi(object):In addition to using type() to create classes dynamically, you can control creation behavior of class and use metaclass.According to the Python object model, the class is the object, so the class must be an instance of another certain class.\nBy default, a Python class is instance of the type class. That is, type is metaclass of most of the built-in classes and metaclass of user-defined classes.Magic will take effect when we passed keyword arguments in metaclass, it indicates the Python interpreter to create the CustomList through ListMetaclass. new (), at this point, we can modify the class definition, for example, and add a new method and then return the revised definition.",
                "In addition to the published answers I can say that a metaclass defines the behaviour for a class. So, you can explicitly set your metaclass. Whenever Python gets a keyword class then it starts searching for the metaclass. If it's not found \u2013 the default metaclass type is used to create the class's object. Using the __metaclass__ attribute, you can set metaclass of your class:It'll produce the output like this:And, of course, you can create your own metaclass to define the behaviour of any class that are created using your class.For doing that, your default metaclass type class must be inherited as this is the main metaclass:The output will be:",
                "Note that in python 3.6 a new dunder method __init_subclass__(cls, **kwargs) was introduced to replace a lot of common use cases for metaclasses. Is is called when a subclass of the defining class is created. See python docs.",
                "Here's another example of what it can be used for:The metaclass is powerful, there are many things (such as monkey magic) you can do with it, but be careful this may only be known to you.",
                "The top answer is correct.But readers may be coming here searching answers about similarly named inner classes. They are present in popular libraries, such as Django and WTForms.As DavidW points out in the comments beneath this answer, these are library-specific features and are not to be confused with the advanced, unrelated Python language feature with a similar name.Rather, these are namespaces within classes' dicts. They are constructed using inner classes for sake of readability.In this example special field, abstract is visibly separate from fields of Author model.Another example is from the documentation for WTForms:This syntax does not get special treatment in the python programming language. Meta is not a keyword here, and does not trigger metaclass behavior. Rather, third-party library code in packages like Django and WTForms reads this property in the constructors of certain classes, and elsewhere.The presence of these declarations modifies the behavior of the classes that have these declarations. For example, WTForms reads self.Meta.csrf to determine if the form needs a csrf field.",
                "In object-oriented programming, a metaclass is a class whose instances are classes. Just as an ordinary class defines the behavior of certain objects, a metaclass defines the behavior of certain class and their instances\nThe term metaclass simply means something used to create classes. In other words, it is the class of a class. The metaclass is used to create the class so like the object being an instance of a class, a class is an instance of a metaclass. In python classes are also considered objects.",
                "A class, in Python, is an object, and just like any other object, it is an instance of \"something\". This \"something\" is what is termed as a Metaclass. This metaclass is a special type of class that creates other class's objects. Hence, metaclass is responsible for making new classes. This allows the programmer to customize the way classes are generated.To create a metaclass, overriding of new() and init() methods is usually done. new() can be overridden to change the way objects are created, while init() can be overridden to change the way of initializing the object. Metaclass can be created by a number of ways. One of the ways is to use type() function. type() function, when called with 3 parameters, creates a metaclass. The parameters are :-Another way of creating a metaclass comprises of 'metaclass' keyword. Define the metaclass as a simple class. In the parameters of inherited class, pass metaclass=metaclass_nameMetaclass can be specifically used in the following situations :-",
                "I saw an interesting use case for metaclasses in a package called classutilities. It checks if all class variables are in upper case format (it is convenient to have unified logic for configuration classes), and checks if there are no instance level methods in class.\nAnother interesting example for metaclases was deactivation of unittests based on complex conditions (checking values of multiple environmental variables).",
                "In Python, a metaclass is a subclass of a subclass that determines how a subclass behaves. A class is an instance of another metaclass. In Python, a class specifies how the class's instance will behave.Since metaclasses are in charge of class generation, you can\u00a0write your own custom metaclasses to change how classes are created by performing additional actions or injecting code. Custom metaclasses aren't always important, but they can be.",
                "look this:In other words, when an object was not created (type of object), we looking MetaClass."
            ]
        },
        {
            "tag": "",
            "question": [
                "How to find all files containing specific text (string) on Linux?",
                "How do I find all files containing a specific string of text within their file contents?\nThe following doesn't work. It seems to display every single file in the system.\nfind / -type f -exec grep -H '..."
            ],
            "url": "https://stackoverflow.com/questions/16956810",
            "answer": [
                "Do the following:Along with these, --exclude, --include, --exclude-dir flags could be used for efficient searching:This will only search through those files which have .c or .h extensions:This will exclude searching all the files ending with .o extension:For directories it's possible to exclude one or more directories using the --exclude-dir parameter. For example, this will exclude the dirs dir1/, dir2/ and all of them matching *.dst/:This works very well for me, to achieve almost the same purpose like yours.For more options, see man grep.",
                "Use grep -ilR:",
                "You can use ack. It is like grep for source code. You can scan your entire file system with it.Just do:In your root directory.You can also use regular expressions, specify the filetype, etc.UPDATEI just discovered The Silver Searcher, which is like ack but 3-5x faster than it and even ignores patterns from a .gitignore file.",
                "You can use:The r stands for recursive and so will search in the path specified and also its sub-directories. This will tell you the file name as well as print out the line in the file where the string appears.Or a command similar to the one you are trying (example: ) for searching in all javascript files (*.js):This will print the lines in the files where the text appears, but it does not print the file name.In addition to this command, we can write this too:\ngrep -rn \"String to search\" /path/to/directory/or/file\n-r: recursive search\nn: line number will be shown for matches",
                "Recursive and case insensitive grep with line numbers:",
                "You can use grep tool to search recursively the current folder, like:Note: -r - Recursively search subdirectories.You can also use globbing syntax to search within specific files such as:Note: By using globbing option (**), it scans all the files recursively with specific extension or pattern. To enable this syntax, run: shopt -s globstar. You may also use **/*.* for all files (excluding hidden and without extension) or any other pattern.If you've the error that your argument is too long, consider narrowing down your search, or use find syntax instead such as:Alternatively, use ripgrep.If you're working on larger projects or big files, you should use ripgrep instead, like:Checkout the docs, installation steps or source code on the GitHub project page.It's much quicker than any other tool like GNU/BSD grep, ucg, ag, sift, ack, pt or similar, since it is built on top of Rust's regex engine which uses finite automata, SIMD and aggressive literal optimizations to make searching very fast.It supports ignore patterns specified in .gitignore files, so a single file path can be matched against multiple glob patterns simultaneously.You can use common parameters such as:",
                "First of all, I believe you have used -H instead of -l. Also you can try adding the text inside quotes followed by {} \\.Let's say you are searching for files containing specific text \"Apache License\" inside your directory. It will display results somewhat similar to below (output will be different based on your directory content).Even if you are not use about the case like \"text\" vs \"TEXT\", you can use the -i switch to ignore case. You can read further details here.Hope this helps you.",
                "This grep command will give you a precise result when you are searching for specific text on Linux -grep -inRsH \"Text to be searched\"  /path/to/dir (it can be '.')i stands for ignore case distinctionsR stands for recursive and it also include symlinks. It is better to use 'R' instead of 'r'n stands for \"it will print line number\".s stands for \"suppress error messages\"H stands for \"it will print the file name for each match\"",
                "If your grep doesn't support recursive search, you can combine find with xargs:I find this easier to remember than the format for find -exec.This will output the filename and the content of the matched line, e.g.Optional flags you may want to add to grep:",
                "There's a new utility called The SilversearcherIt works closely with Git and other VCS. So you won't get anything in a .git or another directory.You can simply useAnd it will do the task for you!",
                "How do I find all files containing specific text on Linux?\n  (...)I came across this solution twice:find / -type f -exec grep -H 'text-to-find-here' {} \\;If using find like in your example, better add -s (--no-messages) to grep, and 2>/dev/null at the end of the command to avoid lots of Permission denied messages issued by grep and find:find is the standard tool for searching files - combined with grep when looking for specific text - on Unix-like platforms. The find command is often combined with xargs, by the way.Faster and easier tools exist for the same purpose - see below. Better try them, provided they're available on your platform, of course:RipGrep - fastest search tool around:The Silver Searcher:ack:Note: You can add 2>/dev/null to these commands as well, to hide many error messages.Warning: unless you really can't avoid it, don't search from '/' (the root directory) to avoid a long and inefficient search!\n So in the examples above, you'd better replace '/' by a sub-directory name, e.g. \"/home\" depending where you actually want to search...",
                "Use pwd to search from any directory you are in, recursing downwardDepending on the version of grep you are using, you can omit pwd. In newer versions . seems to be the default case for grep if no directory is given.Thus:grep -rnw -e \"pattern\"orgrep -rnw \"pattern\"will do the same thing as above!",
                "Try:",
                "For example:",
                "grep can be used even if we're not looking for a string.Simply running,will print out the path to all text files, i.e. those containing only printable characters.",
                "Silver Searcher is a terrific tool, but ripgrep may be even better.It works on Linux, Mac and Windows, and was written up on Hacker News a couple of months ago (this has a link to Andrew Gallant's Blog which has a GitHub link):Ripgrep \u2013 A new command line search tool",
                "If you strictly want to use find then use find + grep:find /path/to/somewhere/ -type f -exec grep -nw 'textPattern' {} \\;Steps:This gives you the power of find to find files.find /path/to/somewhere/ -type f -name \\*.cpp -exec grep -nw 'textPattern' {} \\;You can use different options of find to improve your file search.",
                "Here are the several list of commands that can be used to search file.",
                "If you are in a Git repository, you can use:",
                "I am fascinated by how simple grep makes it with 'rl':Use '-r' without 'l' to see the file names followed by text in which the pattern is found!It works just perfect...",
                "Hope this is of assistance...Expanding the grep a bit to give more information in the output, for example, to get the line number in the file where the text is can be done as follows:And if you have an idea what the file type is you can narrow your search down by specifying file type extensions to search for, in this case .pas OR .dfm files:Short explanation of the options:",
                "orIf you want to search the current directory:",
                "There is the ack tool that would do exactly what you are looking for:You may ignore -i for case sensitive search.",
                "Explanation from commentsfind is a command that lets you find files and other objects like directories and links in subdirectories of a given path. If you don't specify a mask that filesnames should meet, it enumerates all directory objects.",
                "Try:which will search all file systems, because / is the root folder.For home folder use:For current folder use:",
                "A Simple find can work handy. alias it in your ~/.bashrc file:Start a new terminal and issue:",
                "grep is your good friend to achieve this.If you don't care about the case of the text to find, then use:",
                "To search for the string and output just that line with the search string:e.g.:To display filename containing the search string:e.g.:",
                "I wrote a Python script which does something similar. This is how one should use this script.The first argument, path, is the directory in which we will search recursively. The second argument, pattern_to_search, is a regular expression which we want to search in a file. We use the regular expression format defined in the Python re library. In this script, the . also matches newline.The third argument, file_pattern, is optional. This is another regular expression which works on a filename. Only those files which matches this regular expression will be considered.For example, if I want to search Python files with the extension py containing Pool( followed by word Adaptor, I do the following,And voila, it generates the path of matched files and line number at which the match was found. If more than one match was found, then each line number will be appended to the filename."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I check whether a file exists without exceptions?",
                "How do I check whether a file exists or not, without using the try statement?"
            ],
            "url": "https://stackoverflow.com/questions/82831",
            "answer": [
                "If the reason you're checking is so you can do something like if file_exists: open_it(), it's safer to use a try around the attempt to open it. Checking and then opening risks the file being deleted or moved or something between when you check and when you try to open it.If you're not planning to open the file immediately, you can use os.path.isfileReturn True if path is an existing regular file. This follows symbolic links, so both islink() and isfile() can be true for the same path.if you need to be sure it's a file.Starting with Python 3.4, the pathlib module offers an object-oriented approach (backported to pathlib2 in Python 2.7):To check a directory, do:To check whether a Path object exists independently of whether is it a file or directory, use exists():You can also use resolve(strict=True) in a try block:",
                "Use os.path.exists to check both files and directories:Use os.path.isfile to check only files (note: follows symbolic links):",
                "Unlike isfile(), exists() will return True for directories. So depending on if you want only plain files or also directories, you'll use isfile() or exists(). Here is some simple REPL output:",
                "Use os.path.isfile() with os.access():",
                "Although almost every possible way has been listed in (at least one of) the existing answers (e.g. Python 3.4 specific stuff was added), I'll try to group everything together.Note: every piece of Python standard library code that I'm going to post, belongs to version 3.5.3.Problem statement:Check file (arguable: also folder (\"special\" file) ?) existenceDon't use try / except / else / finally blocksPossible solutions:Also check other function family members like os.path.isfile, os.path.isdir, os.path.lexists for slightly different behaviors:Return True if path refers to an existing path or an open file descriptor. Returns False for broken symbolic links. On some platforms, this function may return False if permission is not granted to execute os.stat() on the requested file, even if the path physically exists.All good, but if following the import tree:os.path - posixpath.py (ntpath.py)genericpath.py - line ~20+it's just a try / except block around [Python.Docs]: os.stat(path, *, dir_fd=None, follow_symlinks=True). So, your code is try / except free, but lower in the framestack there's (at least) one such block. This also applies to other functions (including os.path.isfile).It's a fancier (and more [Wiktionary]: Pythonic) way of handling paths, butUnder the hood, it does exactly the same thing (pathlib.py - line ~1330):Either:Create one:And its usage - I'll replicate the os.path.isfile behavior (note that this is just for demonstrating purposes, do not attempt to write such code for production):Use [Python.Docs]: contextlib.suppress(*exceptions) - which was specifically designed for selectively suppressing exceptionsBut, they seem to be wrappers over try / except / else / finally blocks, as [Python.Docs]: Compound statements - The with statement states:This allows common try...except...finally usage patterns to be encapsulated for convenient reuse.Search the results for matching item(s):[Python.Docs]: os.listdir(path='.') (or [Python.Docs]: os.scandir(path='.') on Python v3.5+, backport: [PyPI]: scandir)Under the hood, both use:Nix: [Man7]: OPENDIR(3) / [Man7]: READDIR(3) / [Man7]: CLOSEDIR(3)Win: [MS.Learn]: FindFirstFileW function (fileapi.h) / [MS.Learn]: FindNextFileW function (fileapi.h) / [MS.Learn]: FindClose function (fileapi.h)via [GitHub]: python/cpython - (main) cpython/Modules/posixmodule.cUsing scandir() instead of listdir() can significantly increase the performance of code that also needs file type or file attribute information, because os.DirEntry objects expose this information if the operating system provides it when scanning a directory. All os.DirEntry methods may perform a system call, but is_dir() and is_file() usually only require a system call for symbolic links; os.DirEntry.stat() always requires a system call on Unix, but only requires one for symbolic links on Windows.[Python.Docs]: os.walk(top, topdown=True, onerror=None, followlinks=False)[Python.Docs]: glob.iglob(pathname, *, root_dir=None, dir_fd=None, recursive=False, include_hidden=False) (or its predecessor: glob.glob)Since these iterate over folders, (in most of the cases) they are inefficient for our problem (there are exceptions, like non wildcarded globbing - as @ShadowRanger pointed out), so I'm not going to insist on them. Not to mention that in some cases, filename processing might be required.Its behavior is close to os.path.exists (actually it's wider, mainly because of the 2nd argument).User permissions might restrict the file \"visibility\" as the doc states:... test if the invoking user has the specified access to path. mode should be F_OK to test the existence of path...Security considerations:Using access() to check if a user is authorized to e.g. open a file before actually doing so using open() creates a security hole, because the user might exploit the short time interval between checking and opening the file to manipulate it.Since I also work in C, I use this method as well because under the hood, it calls native APIs (again, via \"${PYTHON_SRC_DIR}/Modules/posixmodule.c\"), but it also opens a gate for possible user errors, and it's not as Pythonic as other variants. So, don't use it unless you know what you're doing:Nix: [Man7]: ACCESS(2)Warning: Using these calls to check if a user is authorized to, for example, open a file before actually doing so using open(2) creates a security hole, because the user might exploit the short time interval between checking and opening the file to manipulate it. For this reason, the use of this system call should be avoided.Win: [MS.Learn]: GetFileAttributesW function (fileapi.h)As seen, this approach is highly discouraged (especially on Nix).Note: calling native APIs is also possible via [Python.Docs]: ctypes - A foreign function library for Python, but in most cases it's more complicated. Before working with CTypes, check [SO]: C function called from Python via ctypes returns incorrect value (@CristiFati's answer) out.(Win specific): since vcruntime###.dll (msvcr###.dll for older VStudio versions - I'm going to refer to it as UCRT) exports a [MS.Learn]: _access, _waccess function family as well, here's an example (note that the recommended [Python.Docs]: msvcrt - Useful routines from the MS VC++ runtime doesn't export them):Notes:Although it's not a good practice, I'm using os.F_OK in the call, but that's just for clarity (its value is 0)I'm using _waccess so that the same code works on Python 3 and Python 2 (in spite of [Wikipedia]: Unicode related differences between them - [SO]: Passing utf-16 string to a Windows function (@CristiFati's answer))Although this targets a very specific area, it was not mentioned in any of the previous answersThe Linux (Ubuntu ([Wikipedia]: Ubuntu version history) 16 x86_64 (pc064)) counterpart as well:Notes:Instead hardcoding libc.so (LibC)'s path (\"/lib/x86_64-linux-gnu/libc.so.6\") which may (and most likely, will) vary across systems, None (or the empty string) can be passed to CDLL constructor (ctypes.CDLL(None).access(b\"/tmp\", os.F_OK)). According to [Man7]: DLOPEN(3):If filename is NULL, then the returned handle is for the main\nprogram.  When given to dlsym(3), this handle causes a search for a\nsymbol in the main program, followed by all shared objects loaded at\nprogram startup, and then all shared objects loaded by dlopen() with\nthe flag RTLD_GLOBAL.Main (current) program (python) is linked against LibC, so its symbols (including access) will be loadedThis has to be handled with care, since functions like main, Py_Main and (all the) others are available; calling them could have disastrous effects (on the current program)This doesn't also apply to Windows (but that's not such a big deal, since UCRT is located in \"%SystemRoot%\\System32\" which is in %PATH% by default). I wanted to take things further and replicate this behavior on Windows (and submit a patch), but as it turns out, [MS.Learn]: GetProcAddress function (libloaderapi.h) only \"sees\" exported symbols, so unless someone declares the functions in the main executable as __declspec(dllexport) (why on Earth the common person would do that?), the main program is loadable, but it is pretty much unusableMost likely, will rely on one of the ways above (maybe with slight customizations). One example would be (again, Win specific) [GitHub]: mhammond/pywin32 - Python for Windows (pywin32) Extensions, which is a Python wrapper over WinAPIs.But, since this is more like a workaround, I'm stopping here.I consider this a (lame) workaround (gainarie): use Python as a wrapper to execute shell commands:Win:Nix ([Wikipedia]: Unix-like) - Ubuntu:Do use try / except / else / finally blocks, because they can prevent you running into a series of nasty problemsA possible counterexample that I can think of, is performance: such blocks are costly, so try not to place them in code that it's supposed to run hundreds of thousands times per second (but since (in most cases) it involves disk access, it won't be the case)",
                "Python 3.4+ has an object-oriented path module: pathlib.  Using this new module, you can check whether a file exists like this:You can (and usually should) still use a try/except block when opening files:The pathlib module has lots of cool stuff in it: convenient globbing, checking file's owner, easier path joining, etc.  It's worth checking out.  If you're on an older Python (version 2.6 or later), you can still install pathlib with pip:Then import it as follows:",
                "This is the simplest way to check if a file exists. Just because the file existed when you checked doesn't guarantee that it will be there when you need to open it.",
                "Now available since Python 3.4, import and instantiate a Path object with the file name, and check the is_file method (note that this returns True for symlinks pointing to regular files as well):If you're on Python 2, you can backport the pathlib module from pypi, pathlib2, or otherwise check isfile from the os.path module:Now the above is probably the best pragmatic direct answer here, but there's the possibility of a race condition (depending on what you're trying to accomplish), and the fact that the underlying implementation uses a try, but Python uses try everywhere in its implementation.Because Python uses try everywhere, there's really no reason to avoid an implementation that uses it.But the rest of this answer attempts to consider these caveats.Available since Python 3.4, use the new Path object in pathlib. Note that .exists is not quite right, because directories are not files (except in the unix sense that everything is a file).So we need to use is_file:Here's the help on is_file:So let's get a file that we know is a file:By default, NamedTemporaryFile deletes the file when closed (and will automatically close when no more references exist to it).If you dig into the implementation, though, you'll see that is_file uses try:We like try because it avoids race conditions. With try, you simply attempt to read your file, expecting it to be there, and if not, you catch the exception and perform whatever fallback behavior makes sense.If you want to check that a file exists before you attempt to read it, and you might be deleting it and then you might be using multiple threads or processes, or another program knows about that file and could delete it - you risk the chance of a race condition if you check it exists, because you are then racing to open it before its condition (its existence) changes.Race conditions are very hard to debug because there's a very small window in which they can cause your program to fail.But if this is your motivation, you can get the value of a try statement by using the suppress context manager.Python 3.4 gives us the suppress context manager (previously the ignore context manager), which does semantically exactly the same thing in fewer lines, while also (at least superficially) meeting the original ask to avoid a try statement:Usage:For earlier Pythons, you could roll your own suppress, but without a try will be more verbose than with. I do believe this actually is the only answer that doesn't use try at any level in the Python that can be applied to prior to Python 3.4 because it uses a context manager instead:Perhaps easier with a try:isfilefrom the docs:os.path.isfile(path)Return True if path is an existing regular file. This follows symbolic\n  links, so both islink() and isfile() can be true for the same path.But if you examine the source of this function, you'll see it actually does use a try statement:All it's doing is using the given path to see if it can get stats on it,  catching OSError and then checking if it's a file if it didn't raise the exception.If you intend to do something with the file, I would suggest directly attempting it with a try-except to avoid a race condition:os.accessAvailable for Unix and Windows is os.access, but to use you must pass flags, and it does not differentiate between files and directories. This is more used to test if the real invoking user has access in an elevated privilege environment:It also suffers from the same race condition problems as isfile. From the docs:Note:\n  Using access() to check if a user is authorized to e.g. open a file\n  before actually doing so using open() creates a security hole, because\n  the user might exploit the short time interval between checking and\n  opening the file to manipulate it. It\u2019s preferable to use EAFP\n  techniques. For example:is better written as:Avoid using os.access. It is a low level function that has more opportunities for user error than the higher level objects and functions discussed above.Another answer says this about os.access:Personally, I prefer this one because under the hood, it calls native APIs (via \"${PYTHON_SRC_DIR}/Modules/posixmodule.c\"), but it also opens a gate for possible user errors, and it's not as Pythonic as other variants:This answer says it prefers a non-Pythonic, error-prone method, with no justification. It seems to encourage users to use low-level APIs without understanding them.It also creates a context manager which, by unconditionally returning True, allows all Exceptions (including KeyboardInterrupt and SystemExit!) to pass silently, which is a good way to hide bugs.This seems to encourage users to adopt poor practices.",
                "Prefer the try statement. It's considered better style and avoids race conditions.Don't take my word for it. There's plenty of support for this theory. Here's a couple:",
                "Use:Importing os makes it easier to navigate and perform standard actions with your operating system.For reference, also see How do I check whether a file exists without exceptions?.If you need high-level operations, use shutil.",
                "Testing for files and folders with os.path.isfile(), os.path.isdir() and os.path.exists()Assuming that the \"path\" is a valid path, this table shows what is returned by each function for files and folders:You can also test if a file is a certain type of file using os.path.splitext() to get the extension (if you don't already know it)",
                "TL;DR \nThe answer is: use the pathlib modulePathlib is probably the most modern and convenient way for almost all of the file operations. For the existence of a file or a folder a single line of code is enough. If file is not exists, it will not throw any exception.The pathlib module was introduced in Python 3.4, so you need to have Python 3.4+. This library makes your life much easier while working with files and folders, and it is pretty to use. Here is more documentation about it: pathlib \u2014 Object-oriented filesystem paths.BTW, if you are going to reuse the path, then it is better to assign it to a variable.So it will become:",
                "In 2016 the best way is still using os.path.isfile:Or in Python 3 you can use pathlib:",
                "It doesn't seem like there's a meaningful functional difference between try/except and isfile(), so you should use which one makes sense.If you want to read a file, if it exists, doBut if you just wanted to rename a file if it exists, and therefore don't need to open it, doIf you want to write to a file, if it doesn't exist, doIf you need file locking, that's a different matter.",
                "You could try this (safer):The ouput would be:([Errno 2] No such file or directory:\n  'whatever.txt')Then, depending on the result, your program can just keep running from there or you can code to stop it if you want.",
                "Date: 2017-12-04Every possible solution has been listed in other answers.An intuitive and arguable way to check if a file exists is the following:I made an exhaustive cheat sheet for your reference:",
                "Although I always recommend using try and except statements, here are a few possibilities for you (my personal favourite is using os.access):Try opening the file:Opening the file will always verify the existence of the file. You can make a function just like so:If it's False, it will stop execution with an unhanded IOError\nor OSError in later versions of Python. To catch the exception,\nyou have to use a try except clause. Of course, you can always\nuse a try except` statement like so (thanks to hsandt\nfor making me think):Use os.path.exists(path):This will check the existence of what you specify. However, it checks for files and directories so beware about how you use it.Use os.access(path, mode):This will check whether you have access to the file. It will check for permissions. Based on the os.py documentation, typing in os.F_OK, it will check the existence of the path. However, using this will create a security hole, as someone can attack your file using the time between checking the permissions and opening the file. You should instead go directly to opening the file instead of checking its permissions. (EAFP vs LBYP). If you're not going to open the file afterwards, and only checking its existence, then you can use this.Anyway, here:I should also mention that there are two ways that you will not be able to verify the existence of a file. Either the issue will be permission denied or no such file or directory. If you catch an IOError, set the IOError as e (like my first option), and then type in print(e.args) so that you can hopefully determine your issue. I hope it helps! :)",
                "If the file is for opening you could use one of the following techniques:Note: This finds either a file or a directory with the given name.",
                "Additionally, os.access():Being R_OK, W_OK, and X_OK the flags to test for permissions (doc).",
                "Raising exceptions is considered to be an acceptable, and Pythonic,\napproach for flow control in your program. Consider handling missing\nfiles with IOErrors. In this situation, an IOError exception will be\nraised if the file exists but the user does not have read permissions.Source: Using Python: How To Check If A File Exists",
                "If you imported NumPy already for other purposes then there is no need to import other libraries like pathlib, os, paths, etc.This will return true or false based on its existence.",
                "You can follow these three ways:Note 1: The os.path.isfile used only for filesNote 2: The os.path.exists is used for both files and directories",
                "You can write Brian's suggestion without the try:.suppress is part of Python 3.4. In older releases you can quickly write your own suppress:",
                "Adding one more slight variation which isn't exactly reflected in the other answers.This will handle the case of the file_path being None or empty string.Adding a variant based on suggestion from ShahbazAdding a variant based on suggestion from Peter Wood",
                "I'm the author of a package that's been around for about 10 years, and it has a function that addresses this question directly. Basically, if you are on a non-Windows system, it uses Popen to access find.  However, if you are on Windows, it replicates find with an efficient filesystem walker.The code itself does not use a try block\u2026 except in determining the operating system and thus steering you to the \"Unix\"-style find or the hand-buillt find. Timing tests showed that the try was faster in determining the OS, so I did use one there (but nowhere else).And the doc\u2026The implementation, if you care to look, is here:\nhttps://github.com/uqfoundation/pox/blob/89f90fb308f285ca7a62eabe2c38acb87e89dad9/pox/shutils.py#L190",
                "Here's a one-line Python command for the Linux command line environment. I find this very handy since I'm not such a hot Bash guy.",
                "You can use the \"OS\" library of Python:",
                "How do I check whether a file exists, without using the try statement?In 2016, this is still arguably the easiest way to check if both a file exists and if it is a file:isfile is actually just a helper method that internally uses os.stat and stat.S_ISREG(mode) underneath. This os.stat is a lower-level method that will provide you with detailed information about files, directories, sockets, buffers, and more. More about os.stat hereNote: However, this approach will not lock the file in any way and therefore your code can become vulnerable to \"time of check to time of use\" (TOCTTOU) bugs.So raising exceptions is considered to be an acceptable, and Pythonic, approach for flow control in your program. And one should consider handling missing files with IOErrors, rather than if statements (just an advice)."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I merge two dictionaries in a single expression?",
                "I want to merge two dictionaries into a new dictionary.\nx = {'a': 1, 'b': 2}\ny = {'b': 3, 'c': 4}\nz = merge(x, y)\n\n>>> z\n{'a': 1, 'b': 3, 'c': 4}\n\nWhenever a key k is present in both ..."
            ],
            "url": "https://stackoverflow.com/questions/38987",
            "answer": [
                "For dictionaries x and y, their shallowly-merged dictionary z takes values from y, replacing those from x.In Python 3.9.0 or greater (released 17 October 2020, PEP-584, discussed here):In Python 3.5 or greater:In Python 2, (or 3.4 or lower) write a function:and now:Say you have two dictionaries and you want to merge them into a new dictionary without altering the original dictionaries:The desired result is to get a new dictionary (z) with the values merged, and the second dictionary's values overwriting those from the first.A new syntax for this, proposed in PEP 448 and available as of Python 3.5, isAnd it is indeed a single expression.Note that we can merge in with literal notation as well:and now:It is now showing as implemented in the release schedule for 3.5, PEP 478, and it has now made its way into the What's New in Python 3.5 document.However, since many organizations are still on Python 2, you may wish to do this in a backward-compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process:In both approaches, y will come second and its values will replace x's values, thus b will point to 3 in our final result.If you are not yet on Python 3.5 or need to write backward-compatible code, and you want this in a single expression, the most performant while the correct approach is to put it in a function:and then you have a single expression:You can also make a function to merge an arbitrary number of dictionaries, from zero to a very large number:This function will work in Python 2 and 3 for all dictionaries. e.g. given dictionaries a to g:and key-value pairs in g will take precedence over dictionaries a to f, and so on.Don't use what you see in the formerly accepted answer:In Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict. In Python 3, this will fail because you're adding two dict_items objects together, not two lists -and you would have to explicitly create them as lists, e.g. z = dict(list(x.items()) + list(y.items())). This is a waste of resources and computation power.Similarly, taking the union of items() in Python 3 (viewitems() in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable, since sets are semantically unordered, the behavior is undefined in regards to precedence. So don't do this:This example demonstrates what happens when values are unhashable:Here's an example where y should have precedence, but instead the value from x is retained due to the arbitrary order of sets:Another hack you should not use:This uses the dict constructor and is very fast and memory-efficient (even slightly more so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic.Here's an example of the usage being remediated in django.Dictionaries are intended to take hashable keys (e.g. frozensets or tuples), but this method fails in Python 3 when keys are not strings.From the mailing list, Guido van Rossum, the creator of the language, wrote:I am fine with\ndeclaring dict({}, **{1:3}) illegal, since after all it is abuse of\nthe ** mechanism.andApparently dict(x, **y) is going around as \"cool hack\" for \"call\nx.update(y) and return x\". Personally, I find it more despicable than\ncool.It is my understanding (as well as the understanding of the creator of the language) that the intended usage for dict(**y) is for creating dictionaries for readability purposes, e.g.:instead ofDespite what Guido says, dict(x, **y) is in line with the dict specification, which btw. works for both Python 2 and 3. The fact that this only works for string keys is a direct consequence of how keyword parameters work and not a short-coming of dict. Nor is using the ** operator in this place an abuse of the mechanism, in fact, ** was designed precisely to pass dictionaries as keywords.Again, it doesn't work for 3 when keys are not strings. The implicit calling contract is that namespaces take ordinary dictionaries, while users must only pass keyword arguments that are strings. All other callables enforced it. dict broke this consistency in Python 2:This inconsistency was bad given other implementations of Python (PyPy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change.I submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints.More comments:dict(x.items() + y.items()) is still the most readable solution for Python 2. Readability counts.My response: merge_two_dicts(x, y) actually seems much clearer to me, if we're actually concerned about readability. And it is not forward compatible, as Python 2 is increasingly deprecated.{**x, **y} does not seem to handle nested dictionaries. the contents of nested keys are simply overwritten, not merged [...] I ended up being burnt by these answers that do not merge recursively and I was surprised no one mentioned it. In my interpretation of the word \"merging\" these answers describe \"updating one dict with another\", and not merging.Yes. I must refer you back to the question, which is asking for a shallow merge of two dictionaries, with the first's values being overwritten by the second's - in a single expression.Assuming two dictionaries of dictionaries, one might recursively merge them in a single function, but you should be careful not to modify the dictionaries from either source, and the surest way to avoid that is to make a copy when assigning values. As keys must be hashable and are usually therefore immutable, it is pointless to copy them:Usage:Coming up with contingencies for other value types is far beyond the scope of this question, so I will point you at my answer to the canonical question on a \"Dictionaries of dictionaries merge\".These approaches are less performant, but they will provide correct behavior.\nThey will be much less performant than copy and update or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they do respect the order of precedence (latter dictionaries have precedence)You can also chain the dictionaries manually inside a dict comprehension:or in Python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced):itertools.chain will chain the iterators over the key-value pairs in the correct order:I'm only going to do the performance analysis of the usages known to behave correctly. (Self-contained so you can copy and paste yourself.)In Python 3.8.1, NixOS:",
                "In your case, you can do:This will, as you want it, put the final dict in z, and make the value for key b be properly overridden by the second (y) dict's value:If you use Python 2, you can even remove the list() calls. To create z:If you use Python version 3.9.0a4 or greater, then you can directly use:",
                "An alternative:",
                "Another, more concise, option:Note: this has become a popular answer, but it is important to point out that if y has any non-string keys, the fact that this works at all is an abuse of a CPython implementation detail, and it does not work in Python 3, or in PyPy, IronPython, or Jython. Also, Guido is not a fan. So I can't recommend this technique for forward-compatible or cross-implementation portable code, which really means it should be avoided entirely.",
                "This probably won't be a popular answer, but you almost certainly do not want to do this.  If you want a copy that's a merge, then use copy (or deepcopy, depending on what you want) and then update.  The two lines of code are much more readable - more Pythonic - than the single line creation with .items() + .items().  Explicit is better than implicit.In addition, when you use .items() (pre Python 3.0), you're creating a new list that contains the items from the dict.  If your dictionaries are large, then that is quite a lot of overhead (two large lists that will be thrown away as soon as the merged dict is created).  update() can work more efficiently, because it can run through the second dict item-by-item.In terms of time:IMO the tiny slowdown between the first two is worth it for the readability.  In addition, keyword arguments for dictionary creation was only added in Python 2.3, whereas copy() and update() will work in older versions.",
                "In a follow-up answer, you asked about the relative performance of these two alternatives:On my machine, at least (a fairly ordinary x86_64 running Python 2.5.2), alternative z2 is not only shorter and simpler but also significantly faster.  You can verify this for yourself using the timeit module that comes with Python.Example 1: identical dictionaries mapping 20 consecutive integers to themselves:z2 wins by a factor of 3.5 or so.  Different dictionaries seem to yield quite different results, but z2 always seems to come out ahead.  (If you get inconsistent results for the same test, try passing in -r with a number larger than the default 3.)Example 2: non-overlapping dictionaries mapping 252 short strings to integers and vice versa:z2 wins by about a factor of 10.  That's a pretty big win in my book!After comparing those two, I wondered if z1's poor performance could be attributed to the overhead of constructing the two item lists, which in turn led me to wonder if this variation might work better:A few quick tests, e.g.lead me to conclude that z3 is somewhat faster than z1, but not nearly as fast as z2.  Definitely not worth all the extra typing.This discussion is still missing something important, which is a performance comparison of these alternatives with the \"obvious\" way of merging two lists: using the update method.  To try to keep things on an equal footing with the expressions, none of which modify x or y, I'm going to make a copy of x instead of modifying it in-place, as follows:A typical result:In other words, z0 and z2 seem to have essentially identical performance.  Do you think this might be a coincidence?  I don't....In fact, I'd go so far as to claim that it's impossible for pure Python code to do any better than this.  And if you can do significantly better in a C extension module, I imagine the Python folks might well be interested in incorporating your code (or a variation on your approach) into the Python core.  Python uses dict in lots of places; optimizing its operations is a big deal.You could also write this asas Tony does, but (not surprisingly) the difference in notation turns out not to have any measurable effect on performance.  Use whichever looks right to you.  Of course, he's absolutely correct to point out that the two-statement version is much easier to understand.",
                "In Python 3.0 and later, you can use collections.ChainMap which groups multiple dicts or other mappings together to create a single, updateable view:Update for Python 3.5 and later: You can use PEP 448 extended dictionary packing and unpacking.  This is fast and easy:Update for Python 3.9 and later:  You can use the PEP 584 union operator:",
                "I wanted something similar, but with the ability to specify how the values on duplicate keys were merged, so I hacked this out (but did not heavily test it).  Obviously this is not a single expression, but it is a single function call.",
                "Demonstration:Outputs:Thanks rednaw for edits.",
                "Python 3.5 (PEP 448) allows a nicer syntax option:Or evenIn Python 3.9 you also use | and |= with the below example from PEP 584",
                "For items with keys in both dictionaries ('b'), you can control which one ends up in the output by putting that one last.",
                "The best version I could think while not using copy would be:It's faster than dict(x.items() + y.items()) but not as fast as n = copy(a); n.update(b), at least on CPython. This version also works in Python 3 if you change iteritems() to items(), which is automatically done by the 2to3 tool.Personally I like this version best because it describes fairly good what I want in a single  functional syntax. The only minor problem is that it doesn't make completely obvious that values from y takes precedence over values from x, but I don't believe it's difficult to figure that out.",
                "While the question has already been answered several times,\nthis simple solution to the problem has not been listed yet.It is as fast as z0 and the evil z2 mentioned above, but easy to understand and change.",
                "Among such shady and dubious answers, this shining example is the one and only good way to merge dicts in Python, endorsed by dictator for life Guido van Rossum himself!  Someone else suggested half of this, but did not put it in a function.gives:",
                "I benchmarked the suggested with perfplot and found that the good oldis the fastest solution together with the good oldandCode to reproduce the plot:",
                "Be Pythonic. Use a comprehension:",
                "If you think lambdas are evil then read no further.\nAs requested, you can write the fast and memory-efficient solution with one expression:As suggested above, using two lines or writing a function is probably a better way to go.",
                "In python3, the items method no longer returns a list, but rather a view, which acts like a set. In this case you'll need to take the set union since concatenating with + won't work:For python3-like behavior in version 2.7, the viewitems method should work in place of items:I prefer this notation anyways since it seems more natural to think of it as a set union operation rather than concatenation (as the title shows).Edit:A couple more points for python 3. First, note that the dict(x, **y) trick won't work in python 3 unless the keys in y are strings.Also, Raymond Hettinger's Chainmap answer is pretty elegant, since it can take an arbitrary number of dicts as arguments, but from the docs it looks like it sequentially looks through a list of all the dicts for each lookup:Lookups search the underlying mappings successively until a key is found.This can slow you down if you have a lot of lookups in your application:So about an order of magnitude slower for lookups. I'm a fan of Chainmap, but looks less practical where there may be many lookups.",
                "Two dictionariesn dictionariessum has bad performance. See https://mathieularose.com/how-not-to-flatten-a-list-of-lists-in-python/",
                "Simple solution using itertools that preserves order (latter dicts have precedence)And it's usage:",
                "Abuse leading to a one-expression solution for Matthew's answer:You said you wanted one expression, so I abused lambda to bind a name, and tuples to override lambda's one-expression limit. Feel free to cringe.You could also do this of course if you don't care about copying it:",
                "If you don't mind mutating x,Simple, readable, performant. You know update() always returns None, which is a false value. So the above expression will always evaluate to x, after updating it.Most mutating methods in the standard library (like .update()) return None by convention, so this kind of pattern will work on those too. However, if you're using a dict subclass or some other method that doesn't follow this convention, then or may return its left operand, which may not be what you want. Instead, you can use a tuple display and index, which works regardless of what the first element evaluates to (although it's not quite as pretty):If you don't have x in a variable yet, you can use lambda to make a local without using an assignment statement. This amounts to using lambda as a let expression, which is a common technique in functional languages, but is maybe unpythonic.Although it's not that different from the following use of the new walrus operator (Python 3.8+ only),especially if you use a default argument:If you do want a copy, PEP 584 style x | y is the most Pythonic on 3.9+. If you must support older versions, PEP 448 style {**x, **y} is easiest for 3.5+. But if that's not available in your (even older) Python version, the let expression pattern works here too.(That is, of course, nearly equivalent to (z := x.copy()).update(y) or z, but if your Python version is new enough for that, then the PEP 448 style will be available.)",
                "Drawing on ideas here and elsewhere I've comprehended a function:Usage (tested in python 3):You could use a lambda instead.",
                "New in Python 3.9: Use the union operator (|) to merge dicts similar to sets:For matching keys, the right dict takes precedence.This also works for |= to modify a dict in-place:",
                "It's so silly that .update returns nothing.\nI just use a simple helper function to solve the problem:Examples:",
                "(For Python\u00a02.7* only; there are simpler solutions for Python\u00a03*.)If you're not averse to importing a standard library module, you can do(The or a bit in the lambda is necessary because dict.update always returns None on success.)",
                "The problem I have with solutions listed to date is that, in the merged dictionary, the value for key \"b\" is 10 but, to my way of thinking, it should be 12.\nIn that light, I present the following:",
                "There will be a new option when Python 3.8 releases (scheduled for 20 October, 2019), thanks to PEP 572: Assignment Expressions. The new assignment expression operator := allows you to assign the result of the copy and still use it to call update, leaving the combined code a single expression, rather than two statements, changing:to:while behaving identically in every way. If you must also return the resulting dict (you asked for an expression returning the dict; the above creates and assigns to newdict, but doesn't return it, so you couldn't use it to pass an argument to a function as is, a la myfunc((newdict := dict1.copy()).update(dict2))), then just add or newdict to the end (since update returns None, which is falsy, it will then evaluate and return newdict as the result of the expression):Important caveat: In general, I'd discourage this approach in favor of:The unpacking approach is clearer (to anyone who knows about generalized unpacking in the first place, which you should), doesn't require a name for the result at all (so it's much more concise when constructing a temporary that is immediately passed to a function or included in a list/tuple literal or the like), and is almost certainly faster as well, being (on CPython) roughly equivalent to:but done at the C layer, using the concrete dict API, so no dynamic method lookup/binding or function call dispatch overhead is involved (where (newdict := dict1.copy()).update(dict2) is unavoidably identical to the original two-liner in behavior, performing the work in discrete steps, with dynamic lookup/binding/invocation of methods.It's also more extensible, as merging three dicts is obvious:where using assignment expressions won't scale like that; the closest you could get would be:or without the temporary tuple of Nones, but with truthiness testing of each None result:either of which is obviously much uglier, and includes further inefficiencies (either a wasted temporary tuple of Nones for comma separation, or pointless truthiness testing of each update's None return for or separation).The only real advantage to the assignment expression approach occurs if:",
                "This should solve your problem.",
                "This can be done with a single dict comprehension:In my view the best answer for the 'single expression' part as no extra functions are needed, and it is short."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I return the response from an asynchronous call?",
                "How do I return the response/result from a function foo that makes an asynchronous request?\nI am trying to return the value from the callback, as well as assigning the result to a local variable ..."
            ],
            "url": "https://stackoverflow.com/questions/14220321",
            "answer": [
                "\u2192 For a more general explanation of asynchronous behaviour with different examples, see Why is my variable unaltered after I modify it inside of a function? - Asynchronous code reference\u2192 If you already understand the problem, skip to the possible solutions below.The A in Ajax stands for asynchronous. That means sending the request (or rather receiving the response) is taken out of the normal execution flow. In your example, $.ajax returns immediately and the next statement, return result;, is executed before the function you passed as success callback was even called.Here is an analogy which hopefully makes the difference between synchronous and asynchronous flow clearer:Imagine you make a phone call to a friend and ask him to look something up for you. Although it might take a while, you wait on the phone and stare into space, until your friend gives you the answer that you needed.The same is happening when you make a function call containing \"normal\" code:Even though findItem might take a long time to execute, any code coming after var item = findItem(); has to wait until the function returns the result.You call your friend again for the same reason. But this time you tell him that you are in a hurry and he should call you back on your mobile phone. You hang up, leave the house, and do whatever you planned to do. Once your friend calls you back, you are dealing with the information he gave to you.That's exactly what's happening when you do an Ajax request.Instead of waiting for the response, the execution continues immediately and the statement after the Ajax call is executed. To get the response eventually, you provide a function to be called once the response was received, a callback (notice something? call back ?). Any statement coming after that call is executed before the callback is called.Embrace the asynchronous nature of JavaScript! While certain asynchronous operations provide synchronous counterparts (so does \"Ajax\"), it's generally discouraged to use them, especially in a browser context.Why is it bad do you ask?JavaScript runs in the UI thread of the browser and any long-running process will lock the UI, making it unresponsive. Additionally, there is an upper limit on the execution time for JavaScript and the browser will ask the user whether to continue the execution or not.All of this results in a really bad user experience. The user won't be able to tell whether everything is working fine or not. Furthermore, the effect will be worse for users with a slow connection.In the following we will look at three different solutions that are all building on top of each other:All three are available in current browsers, and node 7+.The ECMAScript version released in 2017 introduced syntax-level support for asynchronous functions. With the help of async and await, you can write asynchronous in a \"synchronous style\". The code is still asynchronous, but it's easier to read/understand.async/await builds on top of promises: an async function always returns a promise. await \"unwraps\" a promise and either result in the value the promise was resolved with or throws an error if the promise was rejected.Important: You can only use await inside an async function or in a JavaScript module. Top-level await is not supported outside of modules, so you might have to make an async IIFE (Immediately Invoked Function Expression) to start an async context if not using a module.You can read more about async and await on MDN.Here is an example that elaborates the delay function findItem() above:Current browser and node versions support async/await. You can also support older environments by transforming your code to ES5 with the help of regenerator (or tools that use regenerator, such as Babel).A callback is when function 1 is passed to function 2. Function 2 can call function 1 whenever it is ready. In the context of an asynchronous process, the callback will be called whenever the asynchronous process is done. Usually, the result is passed to the callback.In the example of the question, you can make foo accept a callback and use it as success callback. So thisbecomesHere we defined the function \"inline\" but you can pass any function reference:foo itself is defined as follows:callback will refer to the function we pass to foo when we call it and we pass it on to success. I.e. once the Ajax request is successful, $.ajax will call callback and pass the response to the callback (which can be referred to with result, since this is how we defined the callback).You can also process the response before passing it to the callback:It's easier to write code using callbacks than it may seem. After all, JavaScript in the browser is heavily event-driven (DOM events). Receiving the Ajax response is nothing else but an event.\nDifficulties could arise when you have to work with third-party code, but most problems can be solved by just thinking through the application flow.The Promise API is a new feature of ECMAScript 6 (ES2015), but it has good browser support already. There are also many libraries which implement the standard Promises API and provide additional methods to ease the use and composition of asynchronous functions (e.g., bluebird).Promises are containers for future values. When the promise receives the value (it is resolved) or when it is canceled (rejected), it notifies all of its \"listeners\" who want to access this value.The advantage over plain callbacks is that they allow you to decouple your code and they are easier to compose.Here is an example of using a promise:function delay() {\n  // `delay` returns a promise\n  return new Promise(function(resolve, reject) {\n    // Only `delay` is able to resolve or reject the promise\n    setTimeout(function() {\n      resolve(42); // After 3 seconds, resolve the promise with value 42\n    }, 3000);\n  });\n}\n\ndelay()\n  .then(function(v) { // `delay` returns a promise\n    console.log(v); // Log the value once it is resolved\n  })\n  .catch(function(v) {\n    // Or do something else if it is rejected\n    // (it would not happen in this example, since `reject` is not called).\n  });\n.as-console-wrapper { max-height: 100% !important; top: 0; }Applied to our Ajax call we could use promises like this:function ajax(url) {\n  return new Promise(function(resolve, reject) {\n    var xhr = new XMLHttpRequest();\n    xhr.onload = function() {\n      resolve(this.responseText);\n    };\n    xhr.onerror = reject;\n    xhr.open('GET', url);\n    xhr.send();\n  });\n}\n\najax(\"https://jsonplaceholder.typicode.com/todos/1\")\n  .then(function(result) {\n    console.log(result); // Code depending on result\n  })\n  .catch(function() {\n    // An error occurred\n  });\n.as-console-wrapper { max-height: 100% !important; top: 0; }Describing all the advantages that promise offer is beyond the scope of this answer, but if you write new code, you should seriously consider them. They provide a great abstraction and separation of your code.More information about promises: HTML5 rocks - JavaScript Promises.Deferred objects are jQuery's custom implementation of promises (before the Promise API was standardized). They behave almost like promises but expose a slightly different API.Every Ajax method of jQuery already returns a \"deferred object\" (actually a promise of a deferred object) which you can just return from your function:Keep in mind that promises and deferred objects are just containers for a future value, they are not the value itself. For example, suppose you had the following:This code misunderstands the above asynchronous issues. Specifically, $.ajax() doesn't freeze the code while it checks the '/password' page on your server - it sends a request to the server and while it waits, it immediately returns a jQuery Ajax Deferred object, not the response from the server. That means the if statement is going to always get this Deferred object, treat it as true, and proceed as though the user is logged in. Not good.But the fix is easy:As I mentioned, some(!) asynchronous operations have synchronous counterparts. I don't advocate their use, but for completeness' sake, here is how you would perform a synchronous call:If you directly use a XMLHttpRequest object, pass false as third argument to .open.If you use jQuery, you can set the async option to false. Note that this option is deprecated since jQuery 1.8.\nYou can then either still use a success callback or access the responseText property of the jqXHR object:If you use any other jQuery Ajax method, such as $.get, $.getJSON, etc., you have to change it to $.ajax (since you can only pass configuration parameters to $.ajax).Heads up! It is not possible to make a synchronous JSONP request. JSONP by its very nature is always asynchronous (one more reason to not even consider this option).",
                "Your code should be something along the lines of this:Felix Kling did a fine job writing an answer for people using jQuery for AJAX, but I've decided to provide an alternative for people who aren't.(Note, for those using the new fetch API, Angular or promises I've added another answer below)This is a short summary of \"Explanation of the problem\" from the other answer, if you're not sure after reading this, read that.The A in AJAX stands for asynchronous. That means sending the request (or rather receiving the response) is taken out of the normal execution flow. In your example, .send returns immediately and the next statement, return result;, is executed before the function you passed as success callback was even called.This means when you're returning, the listener you've defined did not execute yet, which means the value you're returning has not been defined.Here is a simple analogy:(Fiddle)The value of a returned is undefined since the a=5 part has not executed yet. AJAX acts like this, you're returning the value before the server got the chance to tell your browser what that value is.One possible solution to this problem is to code re-actively , telling your program what to do when the calculation completed.This is called CPS. Basically, we're passing getFive an action to perform when it completes, we're telling our code how to react when an event completes (like our AJAX call, or in this case the timeout).Usage would be:Which should alert \"5\" to the screen. (Fiddle).There are basically two ways how to solve this:As for synchronous AJAX, don't do it! Felix's answer raises some compelling arguments about why it's a bad idea. To sum it up, it'll freeze the user's browser until the server returns the response and create a very bad user experience. Here is another short summary taken from MDN on why:XMLHttpRequest supports both synchronous and asynchronous communications. In general, however, asynchronous requests should be preferred to synchronous requests for performance reasons.In short, synchronous requests block the execution of code... ...this can cause serious issues...If you have to do it, you can pass a flag. Here is how:Let your function accept a callback. In the example code foo can be made to accept a callback. We'll be telling our code how to react when foo completes.So:Becomes:Here we passed an anonymous function, but we could just as easily pass a reference to an existing function, making it look like:For more details on how this sort of callback design is done, check Felix's answer.Now, let's define foo itself to act accordingly(fiddle)We have now made our foo function accept an action to run when the AJAX completes successfully. We can extend this further by checking if the response status is not 200 and acting accordingly (create a fail handler and such). Effectively it is solving our issue.If you're still having a hard time understanding this, read the AJAX getting started guide at MDN.",
                "XMLHttpRequest 2 (first of all, read the answers from Benjamin Gruenbaum and Felix Kling)If you don't use jQuery and want a nice short XMLHttpRequest 2 which works in the modern browsers and also in the mobile browsers, I suggest to use it this way:As you can see:There are two ways to get the response of this Ajax call (three using the XMLHttpRequest var name):The simplest:Or if for some reason you bind() the callback to a class:Example:Or (the above one is better anonymous functions are always a problem):Nothing easier.Now some people will probably say that it's better to use onreadystatechange or the even the XMLHttpRequest variable name. That's wrong.Check out XMLHttpRequest advanced features.It supported all *modern browsers. And I can confirm as I have been using this approach since XMLHttpRequest 2 was created. I never had any type of problem in any browsers I used.onreadystatechange is only useful if you want to get the headers on state 2.Using the XMLHttpRequest variable name is another big error as you need to execute the callback inside the onload/oreadystatechange closures, or else you lost it.Now if you want something more complex using POST and FormData you can easily extend this function:Again ... it's a very short function, but it does GET and POST.Examples of usage:Or pass a full form element (document.getElementsByTagName('form')[0]):Or set some custom values:As you can see, I didn't implement sync... it's a bad thing.Having said that ... why don't we do it the easy way?As mentioned in the comment, the use of error && synchronous does completely break the point of the answer. Which is a nice short way to use Ajax in the proper way?Error handlerIn the above script, you have an error handler which is statically defined, so it does not compromise the function. The error handler can be used for other functions too.But to really get out an error, the only way is to write a wrong URL in which case every browser throws an error.Error handlers are maybe useful if you set custom headers, set the responseType to blob array buffer, or whatever...Even if you pass 'POSTAPAPAP' as the method it won't throw an error.Even if you pass 'fdggdgilfdghfldj' as formdata it won't throw an error.In the first case the error is inside the displayAjax() under this.statusText as Method not Allowed.In the second case, it simply works. You have to check at the server side if you passed the right post data.Cross-domain not allowed throws an error automatically.In the error response, there aren't any error codes.There is only the this.type which is set to error.Why add an error handler if you totally don't have any control over errors?\nMost of the errors are returned inside this in the callback function displayAjax().So: There isn't any need for error checks if you're able to copy and paste the URL properly. ;)PS: As the first test I wrote x('x', displayAjax)..., and it totally got a response...??? So I checked the folder where the HTML is located, and there was a file called 'x.xml'. So even if you forget the extension of your file XMLHttpRequest 2 WILL FIND IT. I LOL'dRead a file synchronousDon't do that.If you want to block the browser for a while load a nice big .txt file synchronous.Now you can doThere is no other way to do this in a non-asynchronous way. (Yeah, with setTimeout loop... but seriously?)Another point is... if you work with APIs or just your own list's files or whatever you always use different functions for each request...Only if you have a page where you load always the same XML/JSON or whatever you need only one function. In that case, modify a little the Ajax function and replace b with your special function.The functions above are for basic use.If you want to extend the function...Yes, you can.I'm using a lot of APIs and one of the first functions I integrate into every HTML page is the first Ajax function in this answer, with GET only...But you can do a lot of stuff with XMLHttpRequest 2:I made a download manager (using ranges on both sides with resume, filereader, and filesystem), various image resizers converters using canvas, populate web SQL databases with base64images and much more...But in these cases you should create a function only for that purpose... sometimes you need a blob, array buffers, you can set headers, override mimetype and there is a lot more...But the question here is how to return an Ajax response... (I added an easy way.)",
                "This means AngularJS, jQuery (with deferred), native XHR's replacement (fetch), Ember.js, Backbone.js's save or any Node.js library that returns promises.Your code should be something along the lines of this:Felix Kling did a fine job writing an answer for people using jQuery with callbacks for Ajax. I have an answer for native XHR. This answer is for generic usage of promises either on the frontend or backend.The JavaScript concurrency model in the browser and on the server with Node.js/io.js is asynchronous and reactive.Whenever you call a method that returns a promise, the then handlers are always executed asynchronously - that is, after the code below them that is not in a .then handler.This means when you're returning data the then handler you've defined did not execute yet. This in turn means that the value you're returning has not been set to the correct value in time.Here is a simple analogy for the issue:function getFive(){\n        var data;\n        setTimeout(function(){ // Set a timer for one second in the future\n           data = 5; // After a second, do this\n        }, 1000);\n        return data;\n    }\n    document.body.innerHTML = getFive(); // `undefined` here and not 5The value of data is undefined since the data = 5 part has not executed yet. It will likely execute in a second, but by that time it is irrelevant to the returned value.Since the operation did not happen yet (Ajax, server call, I/O, and timer) you're returning the value before the request got the chance to tell your code what that value is.One possible solution to this problem is to code re-actively, telling your program what to do when the calculation completed. Promises actively enable this by being temporal (time-sensitive) in nature.A Promise is a value over time. Promises have state. They start as pending with no value and can settle to:A promise can only change states once after which it will always stay at the same state forever. You can attach then handlers to promises to extract their value and handle errors. then handlers allow chaining of calls. Promises are created by using APIs that return them. For example, the more modern Ajax replacement fetch or jQuery's $.get return promises.When we call .then on a promise and return something from it - we get a promise for the processed value. If we return another promise we'll get amazing things, but let's hold our horses.Let's see how we can solve the above issue with promises. First, let's demonstrate our understanding of promise states from above by using the Promise constructor for creating a delay function:Now, after we converted setTimeout to use promises, we can use then to make it count:function delay(ms){ // Takes amount of milliseconds\n  // Returns a new promise\n  return new Promise(function(resolve, reject){\n    setTimeout(function(){ // When the time is up,\n      resolve(); // change the promise to the fulfilled state\n    }, ms);\n  });\n}\n\nfunction getFive(){\n  // We're RETURNING the promise. Remember, a promise is a wrapper over our value\n  return delay(100).then(function(){ // When the promise is ready,\n      return 5; // return the value 5. Promises are all about return values\n  })\n}\n// We _have_ to wrap it like this in the call site, and we can't access the plain value\ngetFive().then(function(five){\n   document.body.innerHTML = five;\n});Basically, instead of returning a value which we can't do because of the concurrency model - we're returning a wrapper for a value that we can unwrap with then. It's like a box you can open with then.This stands the same for your original API call, you can:So this works just as well. We've learned we can't return values from already asynchronous calls, but we can use promises and chain them to perform processing. We now know how to return the response from an asynchronous call.ES6 introduces generators which are functions that can return in the middle and then resume the point they were at. This is typically useful for sequences, for example:Is a function that returns an iterator over the sequence 1,2,3,3,3,3,.... which can be iterated. While this is interesting on its own and opens room for a lot of possibility, there is one particular interesting case.If the sequence we're producing is a sequence of actions rather than numbers - we can pause the function whenever an action is yielded and wait for it before we resume the function. So instead of a sequence of numbers, we need a sequence of future values - that is: promises.This somewhat a tricky, but very powerful trick let\u2019s us write asynchronous code in a synchronous manner. There are several \"runners\" that do this for you. Writing one is a short few lines of code, but it is beyond the scope of this answer. I'll be using Bluebird's Promise.coroutine here, but there are other wrappers like co or Q.async.This method returns a promise itself, which we can consume from other coroutines. For example:In ES7, this is further standardized. There are several proposals right now, but in all of them you can await promise. This is just \"sugar\" (nicer syntax) for the ES6 proposal above by adding the async and await keywords. Making the above example:It still returns a promise just the same :)",
                "You are using Ajax incorrectly. The idea is not to have it return anything, but instead hand off the data to something called a callback function, which handles the data.That is:Returning anything in the submit handler will not do anything. You must instead either hand off the data, or do what you want with it directly inside the success function.",
                "I will answer with a horrible-looking, hand-drawn comic. The second image is the reason why result is undefined in your code example.",
                "The simplest solution is to create a JavaScript function and call it for the Ajax success callback.",
                "People who are using AngularJS, can handle this situation using promises.Here it says,Promises can be used to unnest asynchronous functions and allows one to chain multiple functions together.You can find a nice explanation here also.An example found in documentation mentioned below.In Angular 2 with look at the following example, but its recommended to use observables with Angular 2.You can consume that in this way,See the original post here. But TypeScript does not support native ES6 Promises, if you want to use it, you might need plugin for that.Additionally, here is the promises specification.",
                "Most of the answers here give useful suggestions for when you have a single async operation, but sometimes, this comes up when you need to do an asynchronous operation for each entry in an array or other list-like structure. The temptation is to do this:Example:// WRONG\nvar theArray = [1, 2, 3];\nvar results = [];\ntheArray.forEach(function(entry) {\n    doSomethingAsync(entry, function(result) {\n        results.push(result);\n    });\n});\nconsole.log(\"Results:\", results); // E.g., using them, returning them, etc.\n\nfunction doSomethingAsync(value, callback) {\n    console.log(\"Starting async operation for \" + value);\n    setTimeout(function() {\n        console.log(\"Completing async operation for \" + value);\n        callback(value * 2);\n    }, Math.floor(Math.random() * 200));\n}\n.as-console-wrapper { max-height: 100% !important; }The reason that doesn't work is that the callbacks from doSomethingAsync haven't run yet by the time you're trying to use the results.So, if you have an array (or list of some kind) and want to do async operations for each entry, you have two options: Do the operations in parallel (overlapping), or in series (one after another in sequence).You can start all of them and keep track of how many callbacks you're expecting, and then use the results when you've gotten that many callbacks:Example:var theArray = [1, 2, 3];\nvar results = [];\nvar expecting = theArray.length;\ntheArray.forEach(function(entry, index) {\n    doSomethingAsync(entry, function(result) {\n        results[index] = result;\n        if (--expecting === 0) {\n            // Done!\n            console.log(\"Results:\", JSON.stringify(results)); // E.g., using the results\n        }\n    });\n});\n\nfunction doSomethingAsync(value, callback) {\n    console.log(\"Starting async operation for \" + value);\n    setTimeout(function() {\n        console.log(\"Completing async operation for \" + value);\n        callback(value * 2);\n    }, Math.floor(Math.random() * 200));\n}\n.as-console-wrapper { max-height: 100% !important; }(We could do away with expecting and just use results.length === theArray.length, but that leaves us open to the possibility that theArray is changed while the calls are outstanding...)Notice how we use the index from forEach to save the result in results in the same position as the entry it relates to, even if the results arrive out of order (since async calls don't necessarily complete in the order in which they were started).But what if you need to return those results from a function? As the other answers have pointed out, you can't; you have to have your function accept and call a callback (or return a Promise). Here's a callback version:Example:function doSomethingWith(theArray, callback) {\n    var results = [];\n    var expecting = theArray.length;\n    theArray.forEach(function(entry, index) {\n        doSomethingAsync(entry, function(result) {\n            results[index] = result;\n            if (--expecting === 0) {\n                // Done!\n                callback(results);\n            }\n        });\n    });\n}\ndoSomethingWith([1, 2, 3], function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value, callback) {\n    console.log(\"Starting async operation for \" + value);\n    setTimeout(function() {\n        console.log(\"Completing async operation for \" + value);\n        callback(value * 2);\n    }, Math.floor(Math.random() * 200));\n}\n.as-console-wrapper { max-height: 100% !important; }Or here's a version returning a Promise instead:Of course, if doSomethingAsync passed us errors, we'd use reject to reject the promise when we got an error.)Example:function doSomethingWith(theArray) {\n    return new Promise(function(resolve) {\n        var results = [];\n        var expecting = theArray.length;\n        theArray.forEach(function(entry, index) {\n            doSomethingAsync(entry, function(result) {\n                results[index] = result;\n                if (--expecting === 0) {\n                    // Done!\n                    resolve(results);\n                }\n            });\n        });\n    });\n}\ndoSomethingWith([1, 2, 3]).then(function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value, callback) {\n    console.log(\"Starting async operation for \" + value);\n    setTimeout(function() {\n        console.log(\"Completing async operation for \" + value);\n        callback(value * 2);\n    }, Math.floor(Math.random() * 200));\n}\n.as-console-wrapper { max-height: 100% !important; }(Or alternately, you could make a wrapper for doSomethingAsync that returns a promise, and then do the below...)If doSomethingAsync gives you a Promise, you can use Promise.all:If you know that doSomethingAsync will ignore a second and third argument, you can just pass it directly to map (map calls its callback with three arguments, but most people only use the first most of the time):Example:function doSomethingWith(theArray) {\n    return Promise.all(theArray.map(doSomethingAsync));\n}\ndoSomethingWith([1, 2, 3]).then(function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value) {\n    console.log(\"Starting async operation for \" + value);\n    return new Promise(function(resolve) {\n        setTimeout(function() {\n            console.log(\"Completing async operation for \" + value);\n            resolve(value * 2);\n        }, Math.floor(Math.random() * 200));\n    });\n}\n.as-console-wrapper { max-height: 100% !important; }Note that Promise.all resolves its promise with an array of the results of all of the promises you give it when they are all resolved, or rejects its promise when the first of the promises you give it rejects.Suppose you don't want the operations to be in parallel? If you want to run them one after another, you need to wait for each operation to complete before you start the next. Here's an example of a function that does that and calls a callback with the result:(Since we're doing the work in series, we can just use results.push(result) since we know we won't get results out of order. In the above we could have used results[index] = result;, but in some of the following examples we don't have an index to use.)Example:function doSomethingWith(theArray, callback) {\n    var results = [];\n    doOne(0);\n    function doOne(index) {\n        if (index < theArray.length) {\n            doSomethingAsync(theArray[index], function(result) {\n                results.push(result);\n                doOne(index + 1);\n            });\n        } else {\n            // Done!\n            callback(results);\n        }\n    }\n}\ndoSomethingWith([1, 2, 3], function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value, callback) {\n    console.log(\"Starting async operation for \" + value);\n    setTimeout(function() {\n        console.log(\"Completing async operation for \" + value);\n        callback(value * 2);\n    }, Math.floor(Math.random() * 200));\n}\n.as-console-wrapper { max-height: 100% !important; }(Or, again, build a wrapper for doSomethingAsync that gives you a promise and do the below...)If doSomethingAsync gives you a Promise, if you can use ES2017+ syntax (perhaps with a transpiler like Babel), you can use an async function with for-of and await:Example:async function doSomethingWith(theArray) {\n    const results = [];\n    for (const entry of theArray) {\n        results.push(await doSomethingAsync(entry));\n    }\n    return results;\n}\ndoSomethingWith([1, 2, 3]).then(function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value) {\n    console.log(\"Starting async operation for \" + value);\n    return new Promise(function(resolve) {\n        setTimeout(function() {\n            console.log(\"Completing async operation for \" + value);\n            resolve(value * 2);\n        }, Math.floor(Math.random() * 200));\n    });\n}\n.as-console-wrapper { max-height: 100% !important; }If you can't use ES2017+ syntax (yet), you can use a variation on the \"Promise reduce\" pattern (this is more complex than the usual Promise reduce because we're not passing the result from one into the next, but instead gathering up their results in an array):Example:function doSomethingWith(theArray) {\n    return theArray.reduce(function(p, entry) {\n        return p.then(function(results) {\n            return doSomethingAsync(entry).then(function(result) {\n                results.push(result);\n                return results;\n            });\n        });\n    }, Promise.resolve([]));\n}\ndoSomethingWith([1, 2, 3]).then(function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value) {\n    console.log(\"Starting async operation for \" + value);\n    return new Promise(function(resolve) {\n        setTimeout(function() {\n            console.log(\"Completing async operation for \" + value);\n            resolve(value * 2);\n        }, Math.floor(Math.random() * 200));\n    });\n}\n.as-console-wrapper { max-height: 100% !important; }...which is less cumbersome with ES2015+ arrow functions:Example:function doSomethingWith(theArray) {\n    return theArray.reduce((p, entry) => p.then(results => doSomethingAsync(entry).then(result => {\n        results.push(result);\n        return results;\n    })), Promise.resolve([]));\n}\ndoSomethingWith([1, 2, 3]).then(function(results) {\n    console.log(\"Results:\", JSON.stringify(results));\n});\n\nfunction doSomethingAsync(value) {\n    console.log(\"Starting async operation for \" + value);\n    return new Promise(function(resolve) {\n        setTimeout(function() {\n            console.log(\"Completing async operation for \" + value);\n            resolve(value * 2);\n        }, Math.floor(Math.random() * 200));\n    });\n}\n.as-console-wrapper { max-height: 100% !important; }",
                "Have a look at this example:As you can see getJoke is returning a resolved promise (it is resolved when returning res.data.value). So you wait until the $http.get request is completed and then console.log(res.joke) is executed (as a normal asynchronous flow).This is the plnkr:http://embed.plnkr.co/XlNR7HpCaIhJxskMJfSg/ES6 way (async - await)",
                "This is one of the places which two-way data binding or store concept that's used in many new JavaScript frameworks will work great for you...So if you are using Angular, React, or any other frameworks which do two-way data binding or store concept, this issue is simply fixed for you, so in easy words, your result is undefined at the first stage, so you have got result = undefined before you receive the data, then as soon as you get the result, it will be updated and get assigned to the new value which response of your Ajax call...But how you can do it in pure JavaScript or jQuery for example as you asked in this question?You can use a callback, promise and recently observable to handle it for you. For example, in promises we have some function like success() or then() which will be executed when your data is ready for you. The same with callback or the subscribe function on an observable.For example, in your case which you are using jQuery, you can do something like this:For more information, study promises and observables which are newer ways to do this async stuff.",
                "It's a very common issue we face while struggling with the 'mysteries' of JavaScript. Let me try demystifying this mystery today.Let's start with a simple JavaScript function:That's a simple synchronous function call (where each line of code is 'finished with its job' before the next one in sequence), and the result is same as expected.Now let's add a bit of twist, by introducing a little delay in our function, so that all lines of code are not 'finished' in sequence. Thus, it will emulate the asynchronous behavior of the function:So there you go; that delay just broke the functionality we expected! But what exactly happened? Well, it's actually pretty logical if you look at the code.The function foo(), upon execution, returns nothing (thus returned value is undefined), but it does start a timer, which executes a function after 1 second to return 'wohoo'. But as you can see, the value that's assigned to bar is the immediately returned stuff from foo(), which is nothing, i.e., just undefined.So, how do we tackle this issue?Let's ask our function for a promise.\nPromise is really about what it means: it means that the function guarantees you to provide with any output it gets in future. So let's see it in action for our little problem above:Thus, the summary is - to tackle the asynchronous functions like Ajax-based calls, etc., you can use a promise to resolve the value (which you intend to return). Thus, in short you resolve value instead of returning, in asynchronous functions.Apart from using then/catch to work with promises, there exists one more approach. The idea is to recognize an asynchronous function and then wait for the promises to resolve, before moving to the next line of code. It's still just the promises under the hood, but with a different syntactical approach. To make things clearer, you can find a comparison below:",
                "Another approach to return a value from an asynchronous function, is to pass in an object that will store the result from the asynchronous function.Here is an example of the same:I am using the result object to store the value during the asynchronous operation. This allows the result be available even after the asynchronous job.I use this approach a lot. I would be interested to know how well this approach works where wiring the result back through consecutive modules is involved.",
                "While promises and callbacks work fine in many situations, it is a pain in the rear to express something like:You'd end up going through async1; check if name is undefined or not and call the callback accordingly.While it is okay in small examples it gets annoying when you have a lot of similar cases and error handling involved.Fibers helps in solving the issue.You can checkout the project here.",
                "The following example I have written shows how toThis working example is self-contained. It will define a simple request object that uses the window XMLHttpRequest object to make calls. It will define a simple function to wait for a bunch of promises to be completed.Context. The example is querying the Spotify Web API endpoint in order to search for playlist objects for a given set of query strings:For each item, a new Promise will fire a block - ExecutionBlock, parse the result, schedule a new set of promises based on the result array, that is a list of Spotify user objects and execute the new HTTP call within the ExecutionProfileBlock asynchronously.You can then see a nested Promise structure, that lets you spawn multiple and completely asynchronous nested HTTP calls, and join the results from each subset of calls through Promise.all.NOTE\nRecent Spotify search APIs will require an access token to be specified in the request headers:So, you to run the following example you need to put your access token in the request headers:var spotifyAccessToken = \"YourSpotifyAccessToken\";\r\nvar console = {\r\n    log: function(s) {\r\n        document.getElementById(\"console\").innerHTML += s + \"<br/>\"\r\n    }\r\n}\r\n\r\n// Simple XMLHttpRequest\r\n// based on https://davidwalsh.name/xmlhttprequest\r\nSimpleRequest = {\r\n    call: function(what, response) {\r\n        var request;\r\n        if (window.XMLHttpRequest) { // Mozilla, Safari, ...\r\n            request = new XMLHttpRequest();\r\n        } else if (window.ActiveXObject) { // Internet Explorer\r\n            try {\r\n                request = new ActiveXObject('Msxml2.XMLHTTP');\r\n            }\r\n            catch (e) {\r\n                try {\r\n                  request = new ActiveXObject('Microsoft.XMLHTTP');\r\n                } catch (e) {}\r\n            }\r\n        }\r\n\r\n        // State changes\r\n        request.onreadystatechange = function() {\r\n            if (request.readyState === 4) { // Done\r\n                if (request.status === 200) { // Complete\r\n                    response(request.responseText)\r\n                }\r\n                else\r\n                    response();\r\n            }\r\n        }\r\n        request.open('GET', what, true);\r\n        request.setRequestHeader(\"Authorization\", \"Bearer \" + spotifyAccessToken);\r\n        request.send(null);\r\n    }\r\n}\r\n\r\n//PromiseAll\r\nvar promiseAll = function(items, block, done, fail) {\r\n    var self = this;\r\n    var promises = [],\r\n                   index = 0;\r\n    items.forEach(function(item) {\r\n        promises.push(function(item, i) {\r\n            return new Promise(function(resolve, reject) {\r\n                if (block) {\r\n                    block.apply(this, [item, index, resolve, reject]);\r\n                }\r\n            });\r\n        }(item, ++index))\r\n    });\r\n    Promise.all(promises).then(function AcceptHandler(results) {\r\n        if (done) done(results);\r\n    }, function ErrorHandler(error) {\r\n        if (fail) fail(error);\r\n    });\r\n}; //promiseAll\r\n\r\n// LP: deferred execution block\r\nvar ExecutionBlock = function(item, index, resolve, reject) {\r\n    var url = \"https://api.spotify.com/v1/\"\r\n    url += item;\r\n    console.log( url )\r\n    SimpleRequest.call(url, function(result) {\r\n        if (result) {\r\n\r\n            var profileUrls = JSON.parse(result).playlists.items.map(function(item, index) {\r\n                return item.owner.href;\r\n            })\r\n            resolve(profileUrls);\r\n        }\r\n        else {\r\n            reject(new Error(\"call error\"));\r\n        }\r\n    })\r\n}\r\n\r\narr = [\r\n    \"search?type=playlist&q=%22doom%20metal%22\",\r\n    \"search?type=playlist&q=Adele\"\r\n]\r\n\r\npromiseAll(arr, function(item, index, resolve, reject) {\r\n    console.log(\"Making request [\" + index + \"]\")\r\n    ExecutionBlock(item, index, resolve, reject);\r\n}, function(results) { // Aggregated results\r\n\r\n    console.log(\"All profiles received \" + results.length);\r\n    //console.log(JSON.stringify(results[0], null, 2));\r\n\r\n    ///// promiseall again\r\n\r\n    var ExecutionProfileBlock = function(item, index, resolve, reject) {\r\n        SimpleRequest.call(item, function(result) {\r\n            if (result) {\r\n                var obj = JSON.parse(result);\r\n                resolve({\r\n                    name: obj.display_name,\r\n                    followers: obj.followers.total,\r\n                    url: obj.href\r\n                });\r\n            } //result\r\n        })\r\n    } //ExecutionProfileBlock\r\n\r\n    promiseAll(results[0], function(item, index, resolve, reject) {\r\n        //console.log(\"Making request [\" + index + \"] \" + item)\r\n        ExecutionProfileBlock(item, index, resolve, reject);\r\n    }, function(results) { // aggregated results\r\n        console.log(\"All response received \" + results.length);\r\n        console.log(JSON.stringify(results, null, 2));\r\n    }\r\n\r\n    , function(error) { // Error\r\n        console.log(error);\r\n    })\r\n\r\n    /////\r\n\r\n  },\r\n  function(error) { // Error\r\n      console.log(error);\r\n  });\n<div id=\"console\" />I have extensively discussed this solution here.",
                "The short answer is, you have to implement a callback like this:",
                "JavaScript is single threaded.The browser can be divided into three parts:Event LoopWeb APIEvent QueueThe event loop runs for forever, i.e., kind of an infinite loop. The event queue is where all your functions are pushed on some event (example: click).This is one by one carried out of queue and put into the event loop which executes this function and prepares itself for the next one after the first one is executed. This means execution of one function doesn't start until the function before it in the queue is executed in the event loop.Now let us think we pushed two functions in a queue. One is for getting a data from the server and another utilises that data. We pushed the serverRequest() function in the queue first and then the utiliseData() function. The serverRequest function goes in the event loop and makes a call to server as we never know how much time it will take to get data from server, so this process is expected to take time and so we busy our event loop thus hanging our page.That's where Web API come into the role. It takes this function from the event loop and deals with the server making the event loop free, so that we can execute the next function from the queue.The next function in the queue is utiliseData() which goes in the loop, but because of no data available, it goes to waste and execution of the next function continues until the end of the queue. (This is called Async calling, i.e., we can do something else until we get data.)Let us suppose our serverRequest() function had a return statement in code. When we get back data from the server Web API, it will push it in the queue at the end of queue.As it gets pushed at the end of the queue, we cannot utilise its data as there isn't any function left in our queue to utilise this data. Thus it is not possible to return something from the async call.Thus the solution to this is callback or promise.We give our function (function utilising data returned from the server) to a function calling the server.In my code it is called as:JavaScript.info callback",
                "This is quite simple:Here's a working version of your code:await is supported in all current browsers and Node.js 8",
                "You can use this custom library (written using Promise) to make a remote call.Simple usage example:",
                "Another solution is to execute code via the sequential executor nsynjs.nsynjs will evaluate all promises sequentially, and put the promise result into the data property:function synchronousCode() {\n\n    var getURL = function(url) {\n        return window.fetch(url).data.text().data;\n    };\n    \n    var url = 'https://ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min.js';\n    console.log('received bytes:',getURL(url).length);\n    \n};\n\nnsynjs.run(synchronousCode,{},function(){\n    console.log('synchronousCode done');\n});\n<script src=\"https://rawgit.com/amaksr/nsynjs/master/nsynjs.js\"></script>Step 1. Wrap the function with a callback into the nsynjs-aware wrapper (if it has a promisified version, you can skip this step):Step 2. Put synchronous logic into function:Step 3. Run function in synchronous manner via nsynjs:Nsynjs will evaluate all operators and expressions step-by-step, pausing execution in case if the result of some slow function is not ready.More examples are here.",
                "ECMAScript 6 has 'generators' which allow you to easily program in an asynchronous style.To run the above code you do this:If you need to target browsers that don't support ES6 you can run the code through Babel or closure-compiler to generate ECMAScript 5.The callback ...args are wrapped in an array and destructured when you read them so that the pattern can cope with callbacks that have multiple arguments. For example with node fs:",
                "We find ourselves in a universe which appears to progress along a dimension we call \"time\". We don't really understand what time is, but we have developed abstractions and vocabulary that let us reason and talk about it: \"past\", \"present\", \"future\", \"before\", \"after\".The computer systems we build--more and more--have time as an important dimension. Certain things are set up to happen in the future. Then other things need to happen after those first things eventually occur. This is the basic notion called \"asynchronicity\". In our increasingly networked world, the most common case of asynchronicity is waiting for some remote system to respond to some request.Consider an example. You call the milkman and order some milk. When it comes, you want to put it in your coffee. You can't put the milk in your coffee right now, because it is not here yet. You have to wait for it to come before putting it in your coffee. In other words, the following won't work:Because JavaScript has no way to know that it needs to wait for order_milk to finish before it executes put_in_coffee. In other words, it does not know that order_milk is asynchronous--is something that is not going to result in milk until some future time. JavaScript, and other declarative languages execute one statement after another without waiting.The classic JavaScript approach to this problem, taking advantage of the fact that JavaScript supports functions as first-class objects which can be passed around, is to pass a function as a parameter to the asynchronous request, which it will then invoke when it has completed its task sometime in the future. That is the \"callback\" approach. It looks like this:order_milk kicks off, orders the milk, then, when and only when it arrives, it invokes put_in_coffee.The problem with this callback approach is that it pollutes the normal semantics of a function reporting its result with return; instead, functions must not reports their results by calling a callback given as a parameter. Also, this approach can rapidly become unwieldy when dealing with longer sequences of events. For example, let's say that I want to wait for the milk to be put in the coffee, and then and only then perform a third step, namely drinking the coffee. I end up needing to write something like this:where I am passing to put_in_coffee both the milk to put in it, and also the action (drink_coffee) to execute once the milk has been put in. Such code becomes hard to write, and read, and debug.In this case, we could rewrite the code in the question as:This was the motivation for the notion of a \"promise\", which is a particular type of value which represents a future or asynchronous outcome of some sort. It can represent something that already happened, or that is going to happen in the future, or might never happen at all. Promises have a single method, named then, to which you pass an action to be executed when the outcome the promise represents has been realized.In the case of our milk and coffee, we design order_milk to return a promise for the milk arriving, then specify put_in_coffee as a then action, as follows:One advantage of this is that we can string these together to create sequences of future occurrences (\"chaining\"):Let's apply promises to your particular problem. We will wrap our request logic inside a function, which returns a promise:Actually, all we've done is added a return to the call to $.ajax. This works because jQuery's $.ajax already returns a kind of promise-like thing. (In practice, without getting into details, we would prefer to wrap this call so as for return a real promise, or use some alternative to $.ajax that does so.) Now, if we want to load the file and wait for it to finish and then do something, we can simply sayfor instance,When using promises, we end up passing lots of functions into then, so it's often helpful to use the more compact ES6-style arrow functions:But there's still something vaguely dissatisfying about having to write code one way if synchronous and a quite different way if asynchronous. For synchronous, we writebut if a is asynchronous, with promises we have to writeAbove, we said, \"JavaScript has no way to know that it needs to wait for the first call to finish before it executes the second\". Wouldn't it be nice if there was some way to tell JavaScript that? It turns out that there is--the await keyword, used inside a special type of function called an \"async\" function. This feature is part of the upcoming version of ECMAScript (ES), but it is already available in transpilers such as Babel given the right presets. This allows us to simply writeIn your case, you would be able to write something like",
                "Short answer: Your foo() method returns immediately, while the $ajax() call executes asynchronously after the function returns. The problem is then how or where to store the results retrieved by the async call once it returns.Several solutions have been given in this thread. Perhaps the easiest way is to pass an object to the foo() method, and to store the results in a member of that object after the async call completes.Note that the call to foo() will still return nothing useful. However, the result of the async call will now be stored in result.response.",
                "var App = App || {};\n\nApp = {\n    getDataFromServer: function(){\n\n      var self = this,\n                 deferred = $.Deferred(),\n                 requests = [];\n\n      requests.push($.getJSON('request/ajax/url/1'));\n      requests.push($.getJSON('request/ajax/url/2'));\n\n      $.when.apply(jQuery, requests).done(function(xhrResponse) {\n        return deferred.resolve(xhrResponse.result);\n      });\n      return deferred;\n    },\n\n    init: function(){\n\n        this.getDataFromServer().done(_.bind(function(resp1, resp2) {\n\n           // Do the operations which you wanted to do when you\n           // get a response from Ajax, for example, log response.\n        }, this));\n    }\n};\nApp.init();",
                "As for many others, my encounter with asynchronous calls was puzzling at\nfirst.\nI don't remember the details, but I may have tried something like:let result;\n\n$.ajax({\n  url: 'https://jsonplaceholder.typicode.com/todos/1',\n  success: function (response) {\n    console.log('\\nInside $.ajax:');\n    console.log(response);\n    result = response;\n  }\n});\n\nconsole.log('Finally, the result: ' + result);\n.as-console-wrapper { max-height: 100% !important; top: 0; }\n<script src=\n\"https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js\"></script>Whoops! The output of the line\nconsole.log('Finally, the result: ' + result);\nwhich I thought would be printed last, is actually printed before the\nother output! \u2013 And it doesn't contain the result: it just prints undefined.\n1\nHow come?A helpful insightI distinctly remember my first aha! moment on how to understand asynchronous\ncalls.\nIt was this comment saying:\nyou actually don't want to get the data out of a callback;\nyou want to get your data-needing action into the callback!\n2\nThis is obvious in the example above.\nBut is it still possible to write code after the asynchronous call that\ndeals with the response once it has completed?The answer is yes! \u2013 It is possible.\nOne alternative is the use of a callback function in a continuation-passing\nstyle:\n3const url = 'https://jsonplaceholder.typicode.com/todos/2';\n\nfunction asynchronousCall (callback) {\n  const request = new XMLHttpRequest();\n  request.open('GET', url);\n  request.send();\n  request.onload = function () {\n    if (request.readyState === request.DONE) {\n      console.log('The request is done. Now calling back.');\n      callback(request.responseText);\n    }\n  };\n}\n\nasynchronousCall(function (result) {\n  console.log('This is the start of the callback function. Result:');\n  console.log(result);\n  console.log('The callback function finishes on this line. THE END!');\n});\n\nconsole.log('LAST in the code, but executed FIRST!');\n.as-console-wrapper { max-height: 100% !important; top: 0; }Note how the function asynchronousCall is void. It returns nothing.\nInstead, by calling asynchronousCall with an anonymous callback function\n(asynchronousCall(function (result) {...), this function executes the\ndesired actions on the result, but only after the request has completed \u2013\nwhen the responseText is available.Running the above snippet shows how I will probably not want to write any code\nafter the asyncronous call (such as the line\nLAST in the code, but executed FIRST!).\nWhy? \u2013 Because such code will\nhappen before the asyncronous call delivers any response data.\nDoing so is bound to cause confusion when comparing the code with the output.The .then() construct was introduced in the ECMA-262 6th Edition in June\n2015, and the async/await construct was introduced in the ECMA-262\n8th Edition in June 2017.\nThe code below is still plain JavaScript, replacing the old-school\nXMLHttpRequest with Fetch.\n4fetch('http://api.icndb.com/jokes/random')\n  .then(response => response.json())\n  .then(responseBody => {\n    console.log('.then() - the response body:');\n    console.log(JSON.stringify(responseBody) + '\\n\\n');\n  });\n\nasync function receiveAndAwaitPromise () {\n  const responseBody =\n    (await fetch('http://api.icndb.com/jokes/random')).json();\n  console.log('async/await:');\n  console.log(JSON.stringify(await responseBody) + '\\n\\n');\n}\n\nreceiveAndAwaitPromise();\n.as-console-wrapper { max-height: 100% !important; top: 0; }A word of warning is warranted if you decide to go with the async/await\nconstruct. Note in the above snippet how await is needed in two places.\nIf forgotten in the first place, there will be no output. If forgotten in the\nsecond place, the only output will be the empty object, {}\n(or [object Object] or [object Promise]).\nForgetting the async prefix of the function is maybe the worst of all \u2013 the\noutput will be \"SyntaxError: missing ) in parenthetical\" \u2013 no mentioning of\nthe missing async keyword.Suppose we need to request a whole bunch of URLs.\nI could send one request, wait till it responds, then send the next request,\nwait till it responds, and so on ...\nAargh! \u2013 That could take a loong time. Wouldn't it be better if I could send\nthem all at once, and then wait no longer than it takes for the slowest\nresponse to arrive?As a simplified example, I will use:The JSONs of the two URLs:The goal is to get an array of objects, where each object contains the title\nvalue from the corresponding URL.To make it a little more interesting, I will assume that there is already an\narray of names that I want the array of URL results (the titles) to be\nmerged with:The desired output is a mashup combining namesonly and urls into an\narray of objects:where I have changed the name of title to loremipsum.const namesonly = ['two','three'];\n\nconst urls = ['https://jsonplaceholder.typicode.com/todos/2',\n  'https://jsonplaceholder.typicode.com/todos/3'];\n\nPromise.all(urls.map(url => fetch(url)\n  .then(response => response.json())\n  .then(responseBody => responseBody.title)))\n  .then(titles => {\n    const names = namesonly.map(value => ({ name: value }));\n    console.log('names: ' + JSON.stringify(names));\n    const latins = titles.map(value => ({ loremipsum: value }));\n    console.log('latins:\\n' + JSON.stringify(latins));\n    const result =\n      names.map((item, i) => Object.assign({}, item, latins[i]));\n    console.log('result:\\n' + JSON.stringify(result));\n  });\n.as-console-wrapper { max-height: 100% !important; top: 0; }All the above examples are short and succinctly convey how asynchronous calls\nmay be used on toyish APIs.\nUsing small APIs works well to explain concepts and working code, but the\nexamples might be a bit of dry runs.The next section will show a more realistic example on how APIs may be\ncombined to create a more interesting output.The MusicBrainz API\nhas information about artists and music bands.\nAn example \u2013 a request for the British rock band Coldplay is:\nhttp://musicbrainz.org/ws/2/artist/cc197bad-dc9c-440d-a5b5-d52ba2e14234?&fmt=json&inc=url-rels+release-groups.\nThe JSON response contains \u2013 among other things \u2013 the 25 earliest album titles\nby the band.\nThis information is in the release-groups array.\nThe start of this array, including its first object is:This JSON snippet shows that the first album by Coldplay is Parachutes.\nIt also gives an id, in this case 1dc4c347-a1db-32aa-b14f-bc9cc507b843,\nwhich is a unique identifier of the album.This identifier can be used to make a lookup in the Cover Art Archive API:\nhttp://coverartarchive.org/release-group/1dc4c347-a1db-32aa-b14f-bc9cc507b843.\n7For each album, the JSON response contains some images, one of which is the\nfront cover of the album.\nThe first few lines of the response to the above request:Of interest here is the line\n\"small\": \"http://coverartarchive.org/release/435fc965-9121-461e-b8da-d9b505c9dc9b/4086974851-250.jpg\".\nThat URL is a direct link to the front cover of the Parachutes album.The code to create and visualize the mashupThe overall task is to use Postman to visualize all the album titles and front\ncovers of a music band.\nHow to write code to achieve this has already been described in quite some\ndetail in  an answer to the question\nHow can I visualize an API mashup in Postman? \u2013 Therefore I will avoid\nlengthy discussions here and just present the code and a screenshot of the\nresult:The result and documentationHow to download and run the Postman CollectionRunning the Postman Collection should be straightforward.\nAssuming you are using the desktop version of Postman, do as follows:Download and save\nhttp://henke.atwebpages.com/postman/mbid/MusicBands.pm_coll.json\nin a suitable place on your hard drive.In Postman, Ctrl + O > Upload Files >\nMusicBands.pm_coll.json > Import.\nYou should now see MusicBands among your collections in Postman.Collections > MusicBands > DummyRequest > Send.\n8In the Postman Response Body, click Visualize.You should now be able to scroll 15 albums as indicated by the\nscreenshot above.1 Expressed by the original poster as: they all return\nundefined.\n2 If you think asynchronous calls are confusing, consider having a\nlook at some questions and answers about asynchronous calls to see if that helps.\n3 The name XMLHttpRequest is as misleading as the X in\nAJAX \u2013 these days the data format of Web APIs is ubiquitously JSON, not XML.\n4 Fetch\nreturns a Promise.\nI was surprised to learn that neither XMLHttpRequest nor Fetch are part of\nthe ECMAScript standard.\nThe reason JavaScript can access them here is because the web browser provides\nthem.\nThe Fetch Standard and\nthe XMLHttpRequest Standard are both upheld by\nthe Web Hypertext Application Technology Working Group (WHATWG) that was formed in June 2004.\n5 This section borrows a lot from\nHow can I fetch an array of URLs with Promise.all?.\n6 This section relies heavily on\nHow can I visualize an API mashup in Postman?.\n7 This URL is automatically redirected to:\nhttps://ia800503.us.archive.org/29/items/mbid-435fc965-9121-461e-b8da-d9b505c9dc9b/index.json.\n8 If you get an error,\nSomething went wrong while running your scripts,\ntry hitting Send again.",
                "Use a callback() function inside the foo() success.\nTry it in this way. It is simple and easy to understand.",
                "The most perfect answer to this question is using Promise.There is a problem with using promises!I was using this solution for a while until I figured out there is an error in old browsers:Uncaught ReferenceError: Promise is not definedSo I decided to implement my own Promise class for ES3 to below JavaScript compilers if it's not defined. Just add this code before your main code and then safely use Promise!",
                "Of course there are many approaches like synchronous request, promise, but from my experience I think you should use the callback approach. It's natural to asynchronous behavior of JavaScript.So, your code snippet can be rewritten to be a little different:",
                "The question was:How do I return the response from an asynchronous call?which can be interpreted as:How to make asynchronous code look synchronous?The solution will be to avoid callbacks, and use a combination of Promises and async/await.I would like to give an example for an Ajax request.(Although it can be written in JavaScript, I prefer to write it in Python, and compile it to JavaScript using Transcrypt. It will be clear enough.)Let\u2019s first enable jQuery usage, to have $ available as S:Define a function which returns a Promise, in this case an Ajax call:Use the asynchronous code as if it were synchronous:",
                "Rather than throwing code at you, there are two concepts that are key to understanding how JavaScript handles callbacks and asynchronicity (is that even a word?)There are three things you need to be aware of; The queue; the event loop and the stackIn broad, simplistic terms, the event loop is like the project manager, it is constantly listening for any functions that want to run and communicates between the queue and the stack.Once it receives a message to run something it adds it to the queue. The queue is the list of things that are waiting to execute (like your AJAX request). imagine it like this:When one of these messages is going to execute it pops the message from the queue and creates a stack, the stack is everything JavaScript needs to execute to perform the instruction in the message. So in our example it's being told to call foobarFuncSo anything that foobarFunc needs to execute (in our case anotherFunction) will get pushed onto the stack. executed, and then forgotten about - the event loop will then move onto the next thing in the queue (or listen for messages)The key thing here is the order of execution. That isWhen you make a call using AJAX to an external party or run any asynchronous code (a setTimeout for example), JavaScript is dependant upon a response before it can proceed.The big question is when will it get the response? The answer is we don't know - so the event loop is waiting for that message to say \"hey run me\". If JavaScript just waited around for that message synchronously your app would freeze and it will suck. So JavaScript carries on executing the next item in the queue whilst waiting for the message to get added back to the queue.That's why with asynchronous functionality we use things called callbacks. - A function or handler that, when passed into another function, will be executed at a later date. A promise uses callbacks (functions passed to .then() for example) as a way to reason about this asynchronous behaviour in a more linear way. The promise is a way of saying \"I promise to return something at some point\" and the callback is how we handle that value that is eventually returned. jQuery uses specific callbacks called deffered.done deffered.fail and deffered.always (amongst others). You can see them all hereSo what you need to do is pass a function that is promised to execute at some point with data that is passed to it.Because a callback is not executed immediately but at a later time it's important to pass the reference to the function not it executed. soso most of the time (but not always) you'll pass foo not foo()Hopefully that will make some sense. When you encounter things like this that seem confusing - i highly recommend reading the documentation fully to at least get an understanding of it. It will make you a much better developer."
            ]
        },
        {
            "tag": "",
            "question": [
                "What is the difference between px, dip, dp, and sp?",
                "What is the difference between the units of measure\npx, dip, dp, and sp?"
            ],
            "url": "https://stackoverflow.com/questions/2025282",
            "answer": [
                "From the Android Developer Documentation:px\nPixels - corresponds to actual pixels on the screen.in\nInches - based on the physical size of the screen.\n1 Inch OR 2.54 centimetersmm\n> Millimeters - based on the physical size of the screen.pt\n> Points - 1/72 of an inch based on the physical size of the screen.dp or dip\n> Density-independent Pixels - an abstract unit that is based on the physical density of the screen. These units are relative to a 160\ndpi screen, so one dp is one pixel on a 160 dpi screen. The ratio of dp-to-pixel will change with the screen density, but not necessarily in direct proportion. Note: The compiler accepts both \"dip\" and \"dp\", though \"dp\" is more consistent with \"sp\".sp\n> Scaleable Pixels OR scale-independent pixels - this is like the dp unit, but it is also scaled by the user's font size preference. It is recommended you\nuse this unit when specifying font sizes, so they will be adjusted\nfor both the screen density and the user's preference. Note, the Android documentation is inconsistent on what sp actually stands for, one doc says \"scale-independent pixels\", the other says \"scaleable pixels\".From Understanding Density Independence In Android:More info can be also be found in the Google Design Documentation.",
                "Pretty much everything about this and how to achieve the best support for multiple screens of different sizes and densities is very well documented here:Screen size\nActual physical size, measured as the screen's diagonal.\nFor simplicity, Android groups all actual screen sizes into four\ngeneralized sizes: small, normal, large, and extra-large.Screen density\nThe number of pixels within a physical area of the\nscreen; usually referred to as dpi (dots per inch). For example, a\n\"low\" density screen has fewer pixels within a given physical area,\ncompared to a \"normal\" or \"high\" density screen. For simplicity,\nAndroid groups all actual screen densities into six generalized\ndensities: low, medium, high, extra-high, extra-extra-high, and\nextra-extra-extra-high.OrientationThe orientation of the screen from the user's point of\nview. This is either landscape or portrait, meaning that the screen's\naspect ratio is either wide or tall, respectively. Be aware that not\nonly do different devices operate in different orientations by\ndefault, but the orientation can change at runtime when the user\nrotates the device.Resolution The total number of physical pixels on\na screen. When adding support for multiple screens, applications do\nnot work directly with resolution; applications should be concerned\nonly with screen size and density, as specified by the generalized\nsize and density groups.Density-independent pixel (dp) A virtual\npixel unit that you should use when defining UI layout, to express\nlayout dimensions or position in a density-independent way.\nThe density-independent pixel is equivalent to one physical pixel on a 160\ndpi screen, which is the baseline density assumed by the system for a\n\"medium\" density screen. At runtime, the system transparently handles\nany scaling of the dp units, as necessary, based on the actual density\nof the screen in use. The conversion of dp units to screen pixels is\nsimple:\npx = dp * (dpi / 160).\nFor example, on a 240 dpi screen, 1 dp\nequals 1.5 physical pixels. You should always use dp units when\ndefining your application's UI, to ensure proper display of your UI on\nscreens with different densities.If you are at all serious about developing an Android app for more than one type of device, you should have read the screens support development document at least once. In addition to that, it is always a good thing to know the actual number of active devices that have a particular screen configuration.",
                "I will elaborate more on how exactly does dp convert to px:The other way around: say, you want to add an image to your application and you need it to fill a 100 * 100 dp control. You'll need to create different size images for supported screen sizes:",
                "Moreover you should have a clear understanding of the following concepts:Screen size:Actual physical size, measured as the screen's diagonal. For simplicity, Android groups all actual screen sizes into\nfour generalized sizes: small, normal, large, and extra-large.Screen density:The number of pixels within a physical area of the screen; usually referred to as dpi (dots per inch). For example, a\n\"low\" density screen has fewer pixels within a given physical area,\ncompared to a \"normal\" or \"high\" density screen. For simplicity,\nAndroid groups all actual screen densities into four generalized\ndensities: low, medium, high, and extra high.Orientation:The orientation of the screen from the user's point of view. This is either landscape or portrait, meaning that the\nscreen's aspect ratio is either wide or tall, respectively. Be aware\nthat not only do different devices operate in different orientations\nby default, but the orientation can change at runtime when the user\nrotates the device.Resolution:The total number of physical pixels on a screen. When adding support for multiple screens, applications do not work directly\nwith resolution; applications should be concerned only with screen\nsize and density, as specified by the generalized size and density\ngroups.Density-independent pixel (dp):A virtual pixel unit that you should use when defining UI layout, to express layout dimensions or\nposition in a density-independent way. The density-independent pixel\nis equivalent to one physical pixel on a 160 dpi screen, which is the\nbaseline density assumed by the system for a \"medium\" density screen.\nAt runtime, the system transparently handles any scaling of the dp\nunits, as necessary, based on the actual density of the screen in use.\nThe conversion of dp units to screen pixels is simple: px = dp * (dpi\n/ 160). For example, on a 240 dpi screen, 1 dp equals 1.5 physical\npixels. You should always use dp units when defining your\napplication's UI, to ensure proper display of your UI on screens with\ndifferent densities.Reference: Android developers site",
                "dp is  dip. Use it for everything (margin, padding, etc.).Use sp for {text-size} only.See the difference between px, dp and sp on different screen sizes.Source: Android Programming: The Big Nerd Ranch Guide",
                "px or dot is a pixel on the physical screen.dpi are pixels per inch on the physical screen and represent the density of the display.Android gives alias names to several densitiesdip or dp are density-indenpendant pixels, i.e. they correspond to more or less pixels depending on the physical density.sp or sip is a scale-independant pixel. They are scaled when the Large Text option is turned on in Settings > AccessibilityUse sp for Text size.Use dp for everything else.",
                "I have calculated the formula below to make the conversions dpi to dp and sp",
                "Source 1Source 2Source 3: (data from source 3 is given below)These are dimension values defined in XML. A dimension is specified\nwith a number followed by a unit of measure. For example: 10px, 2in,\n5sp. The following units of measure are supported by Android:dpDensity-independent Pixels - An abstract unit that is based on the\nphysical density of the screen. These units are relative to a 160 dpi\n(dots per inch) screen, on which 1dp is roughly equal to 1px. When\nrunning on a higher density screen, the number of pixels used to draw\n1dp is scaled up by a factor appropriate for the screen's dpi.\nLikewise, when on a lower density screen, the number of pixels used\nfor 1dp is scaled down. The ratio of dp-to-pixel will change with the\nscreen density, but not necessarily in direct proportion. Using dp\nunits (instead of px units) is a simple solution to making the view\ndimensions in your layout resize properly for different screen\ndensities. In other words, it provides consistency for the real-world\nsizes of your UI elements across different devices.spScale-independent Pixels - This is like the dp unit, but it is also\nscaled by the user's font size preference. It is recommended that you use\nthis unit when specifying font sizes, so they will be adjusted for\nboth the screen density and the user's preference.ptPoints - 1/72 of an inch based on the physical size of the screen.pxPixels - Corresponds to actual pixels on the screen. This unit of\nmeasure is not recommended because the actual representation can vary\nacross devices; each device may have a different number of pixels per\ninch and may have more or fewer total pixels available on the screen.mmMillimeters - Based on the physical size of the screen.inInches - Based on the physical size of the screen.Note: A dimension is a simple resource that is referenced using the value provided in the name attribute (not the name of the XML file). As such, you can combine dimension resources with other simple resources in one XML file, under one  element.",
                "Basically the only time where px applies is one px, and that's if you want exactly one pixel on the screen like in the case of a divider:On >160 dpi, you may get 2-3 pixels,On >120 dpi, it rounds to 0.",
                "A virtual pixel unit that you should use when defining UI layout, to express layout dimensions or position in a density-independent way. As described above, the density-independent pixel is equivalent to one physical pixel on a 160 dpi screen, which is the baseline density assumed by the system for a \"medium\" density screen. At runtime, the system transparently handles any scaling of the dp units, as necessary, based on the actual density of the screen in use. The conversion of dp units to screen pixels is\nsimple:px = dp * (dpi / 160).For example, on a 240 dpi screen, 1 dp equals 1.5 physical pixels. You should always use dp units when defining your application's UI, to ensure\nproper display of your UI on screens with different densities.Understanding pixel to dp and vice versa is very essential (especially for giving exact dp values to creative team)It is explained above. Try to avoid in layout files. But there are some cases, where px is required. for example, ListView divider line. px is better here for giving a one-pixel line as a divider for all across screen resolutions.Use sp for font sizes. Then only the font inside the application will change while device fonts size changes (that is, Display -> Fonts on Device). If you want to keep a static sized font inside the app, you can give the font dimension in dp. In such a case, it will never change. Developers may get such a requirement for some specific screens, for that, developers can use dp instead of sp. In all other cases, sp is recommended.",
                "You can see the difference between px and dp from the below picture, and you can also find that the px and dp could not guarantee the same physical sizes on the different screens.",
                "Anything related with the size of text and appearance must use sp or pt. Whereas, anything related to the size of the controls, the layouts, etc. must be used with dp.You can use both dp and dip at its places.",
                "I would only use dp.There is a lot of talk about using \"sp\" for font sizes, and while I appreciate the point, I don't think that it is the right thing to do from a design point of view. You can end up breaking your design if the user has some wonky font size selection, and the user will end up blaming the app, and not their own life choices.Also, if you take an sp-font app on a 160\u00a0dpi tablet, you will find that everything scales up... but your font, which is going to look tiny in comparison. It isn't a good look.While the idea of \"sp\" fonts has a good heart, it is a poor idea. Stick with dp for everything.",
                "sp = scale independent pixeldp = dip = density independent pixelsdpi = dots per inchWe should avoid to use sp.We should use dp to support multiple screens.Android supports different screen resolutionsAn 120 dp ldpi device has 120 pixels in 1 inch size.The same for other densities...We as software engineers should use this conversion formula:pixel = dp * (density / 160)So 240 dpi device's 1 dp will have = 1 * (240/160) = 3/2 = 1.5 pixels.And 480 dpi device's 1 dp will have = 1 * (480/160) = 3 pixels.Using this 1.5 and 3 pixels knowledge, a software engineer can design layouts for different densities.To check screen parameters of any device:",
                "Difference between dp and sp units mentioned as \"user's font size preference\" by the answers copied from official documentation can be seen at run time by changing Settings->Accessibility->Large Text option.Large Text option forces text to become 1.3 times bigger.This might be well of course vendor dependent since it lies in packages/apps/Settings.",
                "dpi -px - pixelpt - pointsin - inch\n - with respect to physical screen size(1 inch = 2.54 cm).mm- milimeter\n - with respect to physical screen size.sp - scale-independent pixel.dip -In standard, dp and sp are used. sp for font size and dp for everything else.Formula for conversion of units:px = dp * ( dpi / 160 );",
                "Please read the answer from the community wiki.\nBelow mentioned is some information to be considered in addition to the above answers. Most Android developers miss this while developing apps, so I am adding these points.sp = scale independent pixeldp = density independent pixelsdpi = density pixelsI have gone through the above answers...not finding them exactly correct.\nsp for text size, dp for layout bounds - standard.\nBut sp for text size will break the layout if used carelessly in most of the devices.sp take the text size of the device, whereas dp take that of device density standard( never change in a device)\nSay 100sp text can occupy 80% of the screen or 100% of the screen depending on the font size set in the deviceYou can use sp for layout bounds also, it will work :)\nNo standard app use sp for whole textUse sp and dp for text size considering UX.Some people use huge FONT size in their phone for more readability, giving them small hardcoded sized text will be a UX issue. Put sp for text where necessary, but make sure it won't break the layout when the user changes his settings.Similarly, if you have a single app supporting all dimensions, adding xxxhdpi assets increases the app size a lot. But now xxxhdpi phones are common so we have to include xxxhdpi assets at least for icons in the sidebar, toolbar, and bottom bar. It's better to move to vector images to have a uniform and better quality images for all screen sizes.Also, note that people use custom fonts on their phones. So lack of a font can cause problems regarding spacing and all. Say text size 12sp for a custom font may take some pixels extra than the default font.Refer to google developer site for screen densities and base density details for android.\nhttps://developer.android.com/training/multiscreen/screendensities",
                "Screen Size in Android is grouped into categories small, medium, large, extra large, double-extra and triple-extra. Screen density is the number of pixels within an area (like an inch) of the screen. Generally, it is measured in dots-per-inch (dpi). Screen density is grouped as low, medium, high, and extra high. Resolution is the total number of pixels on the screen.Formula for Conversion between Unitsdp to px in deviceThe following example may help understand better. The scaling occurs based on bucket sizes of 120(ldpi), 160(mdpi), 240(hdpi), 320(xhdpi), 480(xxhdpi), and 640(xxxhdpi). The Google suggested ratio for designing is 3:4:6:8:12 for ldpi:mdpi:hdpi:xhdpi:xxhdpiA 150px X 150px image will occupy,You may use the following DPI calculator to fix your image sizes and other dimensions when you wish to have a uniform UI design on all Android devices.More Information refer to the following link.http://javapapers.com/android/difference-between-dp-dip-sp-px-in-mm-pt-in-android/",
                "Here's the formula used by Android:px = dp * (dpi / 160)Where dpi is one of the following screen densities. For a list of all possible densities go hereIt defines the \"DENSITY_*\" constants.Taken from here.This will sort out a lot of the confusion when translating between px and dp, if you know your screen dpi.So, let's say you want an image of 60 dp for an hdpi screen then the physical pixel size of 60 dp is:",
                "Normally sp is used for font sizes, while dip is used (also called dp) for others.",
                "I've come across a good article about designing Android apps UI for different screen resolutions, and I'd like to leave it here just for somebody searching in this area. Yes, I know that it's somehow described in Google docs (and mentioned in the posts above), I read that but it was not good for me (yeah, I may be too stupid)). It remained unclear to me how to design layouts capable to handle different screen sizes. I hate the DP concept and so on when I need to implement a \"flexible\" UI layout for different screens. (Hey iOS developers - yes, you're right it's a Storyboard concept).Android has not bad UI concept, but lacks iOS Storyboard features, unfortunately. Designing flexible UI in Android is not an easy thing (at the best).Here goes the article that helped me to understand what to do in Android to make layouts for different screen sizes:JMSTUDIO Blog:- Decide Android App Screen SizeHow to Design UI for Android Apps for Different Screen SizeTo design an app UI for different screen sizes, our initial design has to\nmeet a minimum required space for each screen size. Android defines a\nminimum size (in dp) for each generalized screen type. Here is an\nAndroid screen size guideline.\n\nWhen we get the screen size in dp, it is not enough for us to design\nthe Android app UI. For each screen size, we need to prepare graphics\nand bitmap images for each density. Here is an Android screen density\nguideline.For easy calculation, we can follow the 3:4:6:8 scaling ratio between\nthe four generalized densities. If we create a 36\u00d736 pixel picture for\nldpi device, the rest densities pictures size will be 48\u00d748 for mdpi,\n72\u00d772 for hdpi, and 96\u00d796 for xhdpi.How to Design Android Apps UI in PhotoshopMany designers have problems designing Android app UI in photoshop or another pixel\nbased graphic design tools because of the density-independent unit, dp.\nDesigners don\u2019t know how to map dp to pixel. Google also doesn\u2019t give\na clear Android UI design guide for them, though they give a basic\nformula for dp and pixel translation.As Android\u2019s definition, 1pd equal to 1px under 160 dpi device (mdpi).\nSo we want to design an Android app for xlarge Android devices with\nmdpi density, we can define our UI size in pixel as 960 pixels in width\nand 720px in height; Follow the same mapping rule, we can get\nfollowing Android App screen size UI design guideline:ADDED: If you are interested in \"flexible\" UI too, have a look at this library: An Android SDK that provides a new size unit - sdp (scalable dp). This size unit scales with the screen size (this also mentioned in an answer here, about SDP library)ADDED2 Google has finally understood the usefulness of the iOS Storeboard UI concept, and here goes ConstraintLayout for Android world: Build a Responsive UI with ConstraintLayout",
                "1) dp: (density independent pixels)The number of pixels represented in one unit of dp will increase as the screen resolution increases (when you have more dots/pixels per inch). Conversely on devices with lower resolution, the number of pixels represented in on unit of dp will decrease. Since this is a relative unit, it needs to have a baseline to be compared with. This baseline is a 160 dpi screen. This is the equation: px = dp * (dpi / 160).2) sp: (scale independent pixels)This unit scales according to the screen dpi (similar to dp) as well as the user\u2019s font size preference.3) px: (pixels)Actual pixels or dots on the screen.For more details you can visitAndroid Developer Guide > Dimension\nAndroid Developer Guide > Screens",
                "Screen size in Android is grouped into categories ldpi, mdpi, hdpi, xhdpi, xxhdpi and xxxhdpi. Screen density is the amount of pixels within an area (like inch) of the screen. Generally it is measured in dots-per-inch (dpi).PX(Pixels):DP/DIP(Density pixels / Density independent pixels):dip == dp. In earlier Android versions dip was used and later changed to dp. This is alternative of px.Generally we never use px because it is absolute value. If you use px to set width or height, and if that application is being downloaded into different screen sized devices, then that view will not stretch as per the screen original size.dp is highly recommended to use in place of px. Use dp if you want to mention width and height to grow & shrink dynamically  based on screen sizes.if we give dp/dip, android will automatically calculate the pixel size on the basis of 160 pixel sized screen.SP(Scale independent pixels):scaled based on user\u2019s font size preference. Fonts should use sp.when mentioning the font sizes to fit for various screen sizes, use sp. This is similar to dp.Use sp especially for font sizes to grow & shrink dynamically based on screen sizesAndroid Documentation says:when specifying dimensions, always use either dp or sp units. A dp is\n  a density-independent pixel that corresponds to the physical size of a\n  pixel at 160 dpi. An sp is the same base unit, but is scaled by the\n  user's preferred text size (it\u2019s a scale-independent pixel), so you\n  should use this measurement unit when defining text size",
                "Screen pixel density and resolution vary depending on the platform. Device-independent pixels and scalable pixels are units that provide a flexible way to accommodate a design across platforms.The number of pixels that fit into an inch is referred to as pixel density. High-density screens have more pixels per inch than low-density ones...The number of pixels that fit into an inch is referred to as pixel density. High-density screens have more pixels per inch than low-density ones. As a result, UI elements of the same pixel dimensions appear larger on low-density screens, and smaller on high-density screens.To calculate screen density, you can use this equation:Screen density = Screen width (or height) in pixels / Screen width (or height) in inchesScreen pixel density and resolution vary depending on the platform. Device-independent pixels and scalable pixels are units that provide a flexible way to accommodate a design across platforms.Calculating pixel density\nThe number of pixels that fit into an inch is referred to as pixel density. High-density screens have more pixels per inch than low-density ones...Density independence refers to the uniform display of UI elements on screens with different densities.Density-independent pixels, written as dp (pronounced \u201cdips\u201d), are flexible units that scale to have uniform dimensions on any screen. Material UIs use density-independent pixels to display elements consistently on screens with different densities.Read full text\nhttps://material.io/design/layout/pixel-density.html",
                "The screen of a mobile phone is made up of thousands of tiny dots known as pixels (px). A pixel is the smallest element which goes to make the picture. The more the number of pixels to make a picture or wording, the sharper it becomes and makes the smartphone screen more easily readable.Screen resolution is measured in terms of number of pixels on the screen. Screen resolution is a commonly-used specification when buying a device, but it's actually not that useful when designing for Android because thinking of screens in terms of pixels ignores the notion of physical size, which for a touch device is really really important.Density independent pixel (dp or dip) allow the designer to create assets that appear in a expected way, no matter the resolution or density of target device.A density independent pixel (dp or dip) is equal to one pixel at the baseline density or 160 dpi (dots per inch).1 px/1dp = 160 dpi/160 dpi2 px/1dp = 320 dpi(2x)/160 dpiwhere,dpi is dots per inchSo, at 320 dpi, 1 dp is equal to 2 px.Formulapx/dp = dpi/160dpiDots per inch (dpi) is a measure of the sharpness (that is, the density of illuminated points) on a display screen. The dots per inch for a given picture resolution will differ based on the overall screen size since the same number of pixels are being spread out over a different space.Working with density independent pixels help us to deal with a situation like where you have two devices with same pixel resolution, but differing amount of space. Suppose in a case, a tablet and phone has the same pixel resolution 1280 by 800 pixels (160 dpi) and 800 by 1280 pixels (320 dpi) respectively.Now because a tablet is at baseline density (160 dpi) its physical and density independent pixels sizes are the same, 1280 by 800. The phone on the other hand has a higher pixel density, so it has half as many density independent pixels as physical pixels. So a phone has 400 by 640 density independent pixels. So using a density-independent pixel makes it easier to mentally picture that tablet has much more space than the phone.Similarly, if you have two devices with similar screen size, but different pixel density, say one is 800 by 1280 pixels (320 dpi), and the other is 400 by 640 pixels (160 dpi), we don't need to define totally different layouts for these two devices as we can measure assets in terms of density independent pixel which is same for both devices.800 by 1280 pixels (320dpi)=400 by 640 density independent pixel (dp)400 by 640 pixels (160 dpi)=400 by 640 density independent pixel (dp)Scale independent pixels(sp) is the preferred unit for font size.\nFor accessibility purposes, Android allows users to customize their device's font size. Users that have trouble reading text can increase their device's font size. You can normally find this option in the display setting on your phone or tablet under font size. It's often also available through the accessibility settings.With scale independent pixels, 16 sp is exactly the same as 16 dp when the device's font size is normal or 100%. But when device's font size is large, for example 125%, 16 sp will translate to 20 dp or 1.25 times 16.If you use dp as the unit for font size, then that piece of text has a specific physical size no matter if the user has customize device's font size. Using sp units will make a better experience for people with impaired eyesight.Reference: Udacity, Google",
                "sp: scale independent pixelYou should use it with texts because it is automatically scaled according to the font size that is being used by the user in his device.px: pixel or picture element is the single point on the screen",
                "Pixels(px) \u2013 corresponds to actual pixels on the screen. This is used if you want to give in terms of absolute pixels for width or height.Density-independent Pixels (dp or dip) \u2013 an abstract unit that is based on the physical density of the screen. These units are relative to a 160 dpi screen, so one dp is one pixel on a 160 dpi screen. The ratio of dp-to-pixel will change with the screen density, but not necessarily in direct proportion. Note: The compiler accepts both \u201cdip\u201d and \u201cdp\u201d, though \u201cdp\u201d is more consistent with \u201csp\u201d.Scale-independent Pixels(sp) \u2013 this is like the dp unit, but it is also scaled by the user\u2019s font size preference. It is recommended you use this unit when specifying font sizes, so they will be adjusted for both the screen density and user\u2019s preference.Always use dp and sp only. sp for font sizes and dp for everything else. It will make UI compatible for Android devices with different densities.\nYou can learn more about pixel and dp from\nhttps://www.google.com/design/spec/layout/units-measurements.html#units-measurements-density-independent-pixels-dp-Source URL:- http://www.androidtutorialshub.com/what-is-the-difference-between-px-dp-dip-sp-on-android/",
                "I want to provide an easy way to understand dp. In fact, I think dp is the easiest one to understand. dp is just a physical length unit. It's of the same dimension as mm or inch. It's just convenient for us to write 50dp, 60dp rather than 50/160 inch or 60/160 inch, because one dp is just 1/160 inch whatever the screen size or resolution is.The only problem is that, the android dpi of some screens are not accurate. For example, a screen classified to 160dpi may have 170dpi indeed. So the computation result of dp is fuzzy. It should be approximately the same as 1/160 inch.",
                "SDP - a scalable size unit - basically it is not a unit, but dimension resources for different screen size.Try the sdp library from Intuit. It's very handy to solve unit problems, and you can quickly support multiple screens.Usageandroid:paddingBottom=\"@dimen/_15sdp\" for positive and android:layout_marginTop=\"@dimen/_minus10sdp\"  for negative sdp sdpIt has equivalent value in dp for each size in values-sw<N>dp folders (sw = smallestWidth).AttentionUse it carefully! In most cases you still need to design a different layout for tablets.ExampleYou can use db for text size, but I prefer ssp for text size.For more details, check the library GitHub page.",
                "The ratio of dp-to-pixel will change with the screen density, but not necessarily in direct proportion.Note: The compiler accepts both \"dip\" and \"dp\", though \"dp\" is more consistent with \"sp\".Scale-independent Pixels - this is like the dp unit, but it is also scaled by the user's font size preference."
            ]
        },
        {
            "tag": "",
            "question": [
                "Move the most recent commit(s) to a new branch with Git",
                "How do I move my recent commits on master to a new branch, and reset master to before those commits were made? e.g. From this:\nmaster A - B - C - D - E\n\nTo this:\nnewbranch     C - D - E\n             /\n..."
            ],
            "url": "https://stackoverflow.com/questions/1628563",
            "answer": [
                "If you want to move your commits to an existing branch, it will look like this:You can store uncommitted edits to your stash before doing this, using git stash. Once complete, you can retrieve the stashed uncommitted edits with git stash popWARNING: This method works because you are creating a new branch with the first command: git branch newbranch. If you want to move commits to an existing branch you need to merge your changes into the existing branch before executing git reset --hard HEAD~3 (see Moving to an existing branch above). If you don't merge your changes first, they will be lost.Unless there are other circumstances involved, this can be easily done by branching and rolling back.But do make sure how many commits to go back. Alternatively, you can instead of HEAD~3, simply provide the hash of the commit (or the reference like origin/master) you want to \"revert back to\" on the master (/current) branch, e.g:*1 You will only be \"losing\" commits from the master branch, but don't worry, you'll have those commits in newbranch!Lastly, you may need to force push your latest changes to main repo:WARNING: With Git version 2.0 and later, if you later git rebase the new branch upon the original (master) branch, you may need an explicit --no-fork-point option during the rebase to avoid losing the carried-over commits.  Having branch.autosetuprebase always set makes this more likely.  See John Mellor's answer for details.",
                "For those wondering why it works (as I was at first):You want to go back to C, and move D and E to the new branch.  Here's what it looks like at first:After git branch newBranch:After git reset --hard HEAD~2:Since a branch is just a pointer, master pointed to the last commit.  When you made newBranch, you simply made a new pointer to the last commit.  Then using git reset you moved the master pointer back two commits.  But since you didn't move newBranch, it still points to the commit it originally did.",
                "The method exposed by sykora is the best option in this case. But sometimes is not the easiest and it's not a general method. For a general method use git cherry-pick:To achieve what OP wants, its a 2-step process:ExecuteNote the hashes of (say 3) commits you want on newbranch. Here I shall use:\nC commit: 9aa1233\nD commit: 453ac3d\nE commit: 612ecb3Note: You can use the first seven characters or\n  the whole commit hashgit cherry-pick applies those three commits to newbranch.",
                "Do NOT do this:As the next time you run git rebase (or git pull --rebase) those 3 commits would be silently discarded from newbranch! (see explanation below)Instead do this:Warning: the reflog is enabled by default, but if you've manually disabled it (e.g. by using a \"bare\" git repository), you won't be able to get the 3 commits back after running git reset --keep HEAD~3.An alternative that doesn't rely on the reflog is:(if you prefer you can write @{-1} - the previously checked out branch - instead of oldbranch).Why would git rebase discard the 3 commits after the first example? It's because git rebase with no arguments enables the --fork-point option by default, which uses the local reflog to try to be robust against the upstream branch being force-pushed.Suppose you branched off origin/master when it contained commits M1, M2, M3, then made three commits yourself:but then someone rewrites history by force-pushing origin/master to remove M2:Using your local reflog, git rebase can see that you forked from an earlier incarnation of the origin/master branch, and hence that the M2 and M3 commits are not really part of your topic branch. Hence it reasonably assumes that since M2 was removed from the upstream branch, you no longer want it in your topic branch either once the topic branch is rebased:This behavior makes sense, and is generally the right thing to do when rebasing.So the reason that the following commands fail:is because they leave the reflog in the wrong state. Git sees newbranch as having forked off the upstream branch at a revision that includes the 3 commits, then the reset --hard rewrites the upstream's history to remove the commits, and so next time you run git rebase it discards them like any other commit that has been removed from the upstream.But in this particular case we want those 3 commits to be considered as part of the topic branch. To achieve that, we need to fork off the upstream at the earlier revision that doesn't include the 3 commits. That's what my suggested solutions do, hence they both leave the reflog in the correct state.For more details, see the definition of --fork-point in the git rebase and git merge-base docs.",
                "Yet another way to do this, using just 2 commands. Also keeps your current working tree intact.Old version - before I learned about git branch -fBeing able to push to . is a nice trick to know.",
                "Here's a far simpler solution for commits to the wrong branch. Starting on branch master that has three mistaken commits:You can now use git add and git commit as you normally would. All new commits will be added to newbranch.The OP stated the goal was to \"take master back to before those commits were made\" without losing changes and this solution does that.I do this at least once a week when I accidentally make new commits to master instead of develop. Usually I have only one commit to rollback in which case using git reset HEAD^ on line 1 is a simpler way to rollback just one commit.Don't do this if you pushed master's changes upstreamSomeone else may have pulled those changes. If you are only rewriting your local master there's no impact when it's pushed upstream, but pushing a rewritten history to collaborators can cause headaches.",
                "This doesn't \"move\" them in the technical sense but it has the same effect:",
                "1. Rename master branch to your newbranch (assuming you are on master branch):2. Create master branch from the commit that you wish:e.g. git checkout -b master a34bc22NOTE:\nThe upstream for newbranch would be origin/master.",
                "To do this without rewriting history (i.e. if you've already pushed the commits):Both branches can then be pushed without force!",
                "Had just this situation:I performed:I expected that commit I would be the HEAD, but commit L is it now...To be sure to land on the right spot in the history its easier to work with the hash of the commit",
                "How can I go from thisto this?With two commandsgivingandgiving",
                "If you just need to move all your unpushed commits to a new branch,\nthen you just need to,create a new branch from the current one :git branch new-branch-namepush your new branch: git push origin new-branch-namerevert your old(current) branch to the last pushed/stable state: git reset --hard origin/old-branch-nameSome people also have other upstreams rather than origin, \nthey should use appropriate upstream",
                "TLDRFor meworks best to identify the commit hashes in question.",
                "You can do this is just 3  simple step that i used.1) make new branch where you want to commit you recent update.git branch <branch name>2)  Find  Recent Commit Id for commit on new branch.git log3)  Copy that commit id  note that Most Recent commit list take place on top. so you can find your commit. you also find this via message.git cherry-pick d34bcef232f6c...you can also provide some rang of commit id.git cherry-pick d34bcef...86d2aecNow your job done. If you picked correct id and correct branch then you will success. So before do this be careful. else another problem can occur.Now you can push your codegit push",
                "1) Create a new branch, which moves all your changes to new_branch.2) Then go back to old branch.3) Do git rebase4) Then the opened editor contains last 3 commit information.5) Change pick to drop in all those 3 commits. Then save and close the editor.6) Now last 3 commits are removed from current branch (master). Now push the branch forcefully, with + sign before branch name.",
                "Most of the solutions here count the amount of commits you'd like to go back. I think this is an error prone methodology. Counting would require recounting.You can simply pass the commit hash of the commit you want to be at HEAD or in other words, the commit you'd like to be the last commit via:(Notice see commit hash)To avoid this:",
                "I was surprised that nobody recommended this way:to explain:",
                "Using Emacs' git porcelain Magit, you can do this simply by hitting b s (magit-branch-spinoff). You'll be asked to enter a name for your new branch and once you hit enter, voila.From the Magit documentation:This command creates and checks out a new branch starting at and tracking the current branch. That branch in turn is reset to the last commit it shares with its upstream. If the current branch has no upstream or no unpushed commits, then the new branch is created anyway and the previously current branch is not touched.This is useful to create a feature branch after work has already began on the old branch (likely but not necessarily \"master\").",
                "I got to move 7 commits from one old-branch to a new-branch.After that, both branches were related to the 7 commits I have done. After git checkout new-branch, I was getting fine git log and git status, but, when accessing the old-branch (git checkout old-branch), I'd got the message \"git is behind by 7 commits and can be fast-forwarded\". What worked for me to erase this message was the followind:After that step, the last 7 commits was referenced only for the new-branch and the previous ones were referenced as old-branch and new-branch in the Bitbucket tree.",
                "If you are a UI person like me and you are using Visual Studio. Then you can do the following:\nIn my case, I want to take the latest commit to another branch.So all commit changes will appear in the Git Changes pane.Now, stash your changesFrom \"Git Changes\" double click on your latest Stash.\"Stash details\" pane will be opened. Click on \"Pop\", then resolve conflicts (if exists).",
                "Taking some ideas from other posts, avoiding anything to do with reset, and being ultra paranoid, my solution is:I'm not proud, but I kept my data ;)"
            ]
        },
        {
            "tag": "",
            "question": [
                "What is the difference between POST and PUT in HTTP?",
                "According to RFC 2616, \u00a7 9.5, POST is used to create a resource:\n\nThe POST method is used to request that the origin server accept the entity enclosed in the request as a new subordinate of the ..."
            ],
            "url": "https://stackoverflow.com/questions/630453",
            "answer": [
                "Overall:Both PUT and POST can be used for creating.You have to ask, \"what are you performing the action upon?\", to distinguish what you should be using. Let's assume you're designing an API for asking questions.  If you want to use POST, then you would do that to a list of questions. If you want to use PUT, then you would do that to a particular question.Great, both can be used, so which one should I use in my RESTful design:You do not need to support both PUT and POST.Which you use is up to you.  But just remember to use the right one depending on what object you are referencing in the request.Some considerations:An example:I wrote the following as part of another answer on SO regarding this:POST:Used to modify and update a resourceNote that the following is an error:If the URL is not yet created, you\nshould not be using POST to create it\nwhile specifying the name.  This should\nresult in a 'resource not found' error\nbecause <new_question> does not exist\nyet.  You should PUT the <new_question>\nresource on the server first.You could though do something like\nthis to create a resources using POST:Note that in this case the resource\nname is not specified, the new objects\nURL path would be returned to you.PUT:Used to create a resource, or\noverwrite it.  While you specify the\nresources new URL.For a new resource:To overwrite an existing resource:Additionally, and a bit more concisely, RFC 7231 Section 4.3.4 PUT states (emphasis added),4.3.4.  PUTThe PUT method requests that the state of the target resource be\ncreated or replaced with the state defined by the representation\nenclosed in the request message payload.",
                "You can find assertions on the web that sayNeither is quite right.Better is to choose between PUT and POST based on idempotence of the action.PUT implies putting a resource - completely replacing whatever is available at the given URL with a different thing.  By definition, a PUT is idempotent.  Do it as many times as you like, and the result is the same. x=5 is idempotent.  You can PUT a resource whether it previously exists, or not (eg, to Create, or to Update)!POST updates a resource, adds a subsidiary resource, or causes a change.  A POST is not idempotent, in the way that x++ is not idempotent.By this argument, PUT is for creating when you know the URL of the thing you will create. POST can be used to create when you know the URL of the \"factory\" or manager for the category of things you want to create.so:or:",
                "The relevant specification for PUT and POST is RFC 2616 \u00a79.5ff.POST creates a child resource, so POST to /items creates a resources that lives under the /items resource.\nEg. /items/1. Sending the same post packet twice will create two resources.PUT is for creating or replacing a resource at a URL known by the client.Therefore: PUT is only a candidate for CREATE where the client already knows the url before the resource is created. Eg. /blogs/nigel/entry/when_to_use_post_vs_put as the title is used as the resource keyPUT replaces the resource at the known url if it already exists, so sending the same request twice has no effect. In other words, calls to PUT are idempotent.The RFC reads like this:The fundamental difference between the POST and PUT requests is reflected in the different meaning of the Request-URI. The URI in a POST request identifies the resource that will handle the enclosed entity. That resource might be a data-accepting process, a gateway to some other protocol, or a separate entity that accepts annotations. In contrast, the URI in a PUT request identifies the entity enclosed with the request -- the user agent knows what URI is intended and the server MUST NOT attempt to apply the request to some other resource. If the server desires that the request be applied to a different URI,Note: PUT has mostly been used to update resources (by replacing them in their entireties), but recently there is movement towards using PATCH for updating existing resources, as PUT specifies that it replaces the whole resource. RFC 5789.Update 2018: There is a case that can be made to avoid PUT. See \"REST without PUT\"With \u201cREST without PUT\u201d technique, the idea is that consumers are\nforced to post new 'nounified' request resources. As discussed\nearlier, changing a customer\u2019s mailing address is a POST to a new\n\u201cChangeOfAddress\u201d resource, not a PUT of a \u201cCustomer\u201d resource with a\ndifferent mailing address field value.taken from REST API Design - Resource Modeling by Prakash Subramaniam of ThoughtworksThis forces the API to avoid state transition problems with multiple clients updating a single resource, and matches more nicely with event sourcing and CQRS. When the work is done asynchronously, POSTing the transformation and waiting for it to be applied seems appropriate.",
                "POST means \"create new\" as in \"Here is the input for creating a user, create it for me\".PUT means \"insert, replace if already exists\" as in \"Here is the data for user 5\".You POST to example.com/users since you don't know the URL of the user yet, you want the server to create it.You PUT to example.com/users/id since you want to replace/create a specific user.POSTing twice with the same data means create two identical users with different ids. PUTing twice with the same data creates the user the first and updates him to the same state the second time (no changes). Since you end up with the same state after a PUT no matter how many times you perform it, it is said to be \"equally potent\" every time - idempotent. This is useful for automatically retrying requests. No more 'are you sure you want to resend' when you push the back button on the browser.A general advice is to use POST when you need the server to be in control of URL generation of your resources. Use PUT otherwise.  Prefer PUT  over POST.",
                "Can be performed with both PUT or POST in the following way:Creates THE new resource with newResourceId as the identifier, under the /resources URI, or collection.Creates A new resource under the /resources URI, or collection. Usually the identifier is returned by the server.Can only be performed with PUT in the following way:Updates the resource with existingResourceId as the identifier, under the /resources URI, or collection.When dealing with REST and URI as general, you have generic on the left and specific on the right. The generics are usually called collections and the more specific items can be called resource. Note that a resource can contain a collection.<-- generic -- specific -->When you use POST you are always refering to a collection, so whenever you say:you are posting a new user to the users collection.If you go on and try something like this:it will work, but semantically you are saying that you want to add a resource to the john collection under the users collection.Once you are using PUT you are refering to a resource or single item, possibly inside a collection. So when you say:you are telling to the server update, or create if it doesn't exist, the john resource under the users collection.Let me highlight some important parts of the spec:The POST method is used to request that the origin server accept the entity enclosed in the request as a new subordinate of the resource identified by the Request-URI in the Request-LineHence, creates a new resource on a collection.The PUT method requests that the enclosed entity be stored under the supplied Request-URI. If the Request-URI refers to an already existing resource, the enclosed entity SHOULD be considered as a modified version of the one residing on the origin server. If the Request-URI does not point to an existing resource, and that URI is capable of being defined as a new resource by the requesting user agent, the origin server can create the resource with that URI.\"Hence, create or update based on existence of the resource.",
                "I'd like to add my \"pragmatic\" advice. Use PUT when you know the \"id\" by which the object you are saving can be retrieved. Using PUT won't work too well if you need, say, a database generated id to be returned for you to do future lookups or updates.So: To save an existing user, or one where the client generates the id and it's been verified that the id is unique:Otherwise, use POST to initially create the object, and PUT to update the object:",
                "Both are used for data transmission between client to server, but there are subtle differences between them, which are:Analogy:Social Media/Network Analogy:",
                "Use POST to create, and PUT to update. That's how Ruby on Rails is doing it, anyway.",
                "REST is a very high-level concept. In fact, it doesn't even mention HTTP at all!If you have any doubts about how to implement REST in HTTP, you can always take a look at the Atom Publication Protocol (AtomPub) specification. AtomPub is a standard for writing RESTful webservices with HTTP that was developed by many HTTP and REST luminaries, with some input from Roy Fielding, the inventor of REST and (co-)inventor of HTTP himself.In fact, you might even be able to use AtomPub directly. While it came out of the blogging community, it is in no way restricted to blogging: it is a generic protocol for RESTfully interacting with arbitrary (nested) collections of arbitrary resources via HTTP. If you can represent your application as a nested collection of resources, then you can just use AtomPub and not worry about whether to use PUT or POST, what HTTP Status Codes to return and all those details.This is what AtomPub has to say about resource creation (section 9.2):To add members to a Collection, clients send POST requests to the URI of the Collection.",
                "The decision of whether to use PUT or POST to create a resource on a server with an HTTP + REST API is based on who owns the URL structure. Having the client know, or participate in defining, the URL struct is an unnecessary coupling akin to the undesirable couplings that arose from SOA. Escaping types of couplings is the reason REST is so popular. Therefore, the proper method to use is POST. There are exceptions to this rule and they occur when the client wishes to retain control over the location structure of the resources it deploys. This is rare and likely means something else is wrong.At this point some people will argue that if RESTful-URL's are used, the client does knows the URL of the resource and therefore a PUT is acceptable. After all, this is why canonical, normalized, Ruby on Rails, Django URLs are important, look at the Twitter API \u2026 blah blah blah. Those people need to understand there is no such thing as a Restful-URL and that Roy Fielding himself states that:A REST API must not define fixed resource names or hierarchies (an\nobvious coupling of client and server). Servers must have the freedom\nto control their own namespace. Instead, allow servers to instruct\nclients on how to construct appropriate URIs, such as is done in HTML\nforms and URI templates, by defining those instructions within media\ntypes and link relations. [Failure here implies that clients are\nassuming a resource structure due to out-of band information, such as\na domain-specific standard, which is the data-oriented equivalent to\nRPC's functional coupling].http://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-drivenThe idea of a RESTful-URL is actually a violation of REST as the server is in charge of the URL structure and should be free to decide how to use it to avoid coupling. If this confuses you read about the significance of self discovery on API design.Using POST to create resources comes with a design consideration because POST is not idempotent. This means that repeating a POST several times does not guarantee the same behavior each time. This scares people into using PUT to create resources when they should not. They know it's wrong (POST is for CREATE) but they do it anyway because they don't know how to solve this problem.  This concern is demonstrated in the following situation:Step 6 is where people commonly get confused about what to do. However, there is no reason to create a kludge to solve this issue. Instead, HTTP can be used as specified in RFC 2616 and the server replies:10.4.10 409 ConflictThe request could not be completed due to a conflict with the current\nstate of the resource. This code is only allowed in situations where\nit is expected that the user might be able to resolve the conflict and\nresubmit the request. The response body SHOULD include enoughinformation for the user to recognize the source of the conflict.\nIdeally, the response entity would include enough information for the\nuser or user agent to fix the problem; however, that might not be\npossible and is not required.Conflicts are most likely to occur in response to a PUT request. For\nexample, if versioning were being used and the entity being PUT\nincluded changes to a resource which conflict with those made by an\nearlier (third-party) request, the server might use the 409 response\nto indicate that it can\u2019t complete the request. In this case, the\nresponse entity would likely contain a list of the differences between\nthe two versions in a format defined by the response Content-Type.Replying with a status code of 409 Conflict is the correct recourse because:Update based on release of RFC 7231 to Replace 2616RFC 7231 is designed to replace 2616 and in Section 4.3.3 describes the follow possible response for a POSTIf the result of processing a POST would be equivalent to a\nrepresentation of an existing resource, an origin server MAY redirect\nthe user agent to that resource by sending a 303 (See Other) response\nwith the existing resource's identifier in the Location field.  This\nhas the benefits of providing the user agent a resource identifier\nand transferring the representation via a method more amenable to\nshared caching, though at the cost of an extra request if the user\nagent does not already have the representation cached.It now may be tempting to simply return a 303 in the event that a POST is repeated. However, the opposite is true. Returning a 303 would only make sense if multiple create requests (creating different resources) return the same content. An example would be a \"thank you for submitting your request message\" that the client need not re-download each time. RFC 7231 still maintains in section 4.2.2 that POST is not to be idempotent and continues to maintain that POST should be used for create.For more information about this, read this article.",
                "I like this advice, from RFC 2616's definition of PUT:The fundamental difference between the POST and PUT requests is reflected in the different meaning of the Request-URI. The URI in a POST request identifies the resource that will handle the enclosed entity. That resource might be a data-accepting process, a gateway to some other protocol, or a separate entity that accepts annotations. In contrast, the URI in a PUT request identifies the entity enclosed with the request -- the user agent knows what URI is intended and the server MUST NOT attempt to apply the request to some other resource.This jibes with the other advice here, that PUT is best applied to resources that already have a name, and POST is good for creating a new object under an existing resource (and letting the server name it).I interpret this, and the idempotency requirements on PUT, to mean that:",
                "In short:PUT is idempotent, where the resource state will be the same if the same operation is executed one time or multiple times.POST is non-idempotent, where the resource state may become different if the operation is executed multiple times as compared to executing a single time.PUT You can think of similar to \"UPDATE STUDENT SET address = \"abc\" where id=\"123\";POST You can think of something like \"INSERT INTO STUDENT(name, address) VALUES (\"abc\", \"xyzzz\");Student Id is auto generated.With PUT, if the same query is executed multiple times or one time, the STUDENT table state remains the same.In case of POST, if the same query is executed multiple times then multiple Student records get created in the database and the database state changes on each execution of an \"INSERT\" query.NOTE: PUT needs a resource location (already-resource) on which update needs to happen, whereas POST doesn't require that. Therefore intuitively POST is meant for creation of a new resource, whereas PUT is needed for updating the already existing resource.Some may come up with that updates can be performed with POST. There is no hard rule which one to use for updates or which one to use for create. Again these are conventions, and intuitively I'm inclined with the above mentioned reasoning and follow it.",
                "POST is like posting a letter to a mailbox or posting an email to an email queue.\nPUT is like when you put an object in a cubby hole or a place on a shelf (it has a known address).With POST, you're posting to the address of the QUEUE or COLLECTION. With PUT, you're putting to the address of the ITEM.PUT is idempotent. You can send the request 100 times and it will not matter. POST is not idempotent. If you send the request 100 times, you'll get 100 emails or 100 letters in your postal box.A general rule: if you know the id or name of the item, use PUT. If you want the id or name of the item to be assigned by the receiving party, use POST.",
                "Short Answer:Simple rule of thumb: Use POST to create, use PUT to update.Long Answer:POST:PUT:Longer Answer:To understand it we need to question why PUT was required, what were the problems PUT was trying to solve that POST couldn't.From a REST architecture's point of view there is none that matters. We could have lived without PUT as well. But from a client developer's point of view it made his/her life a lot simpler.Prior to PUT, clients couldn't directly know the URL that the server generated or if all it had generated any or whether the data to be sent to the server is already updated or not. PUT relieved the developer of all these headaches. PUT is idempotent, PUT handles race conditions, and PUT lets the client choose the URL.",
                "New answer (now that I understand REST better):PUT is merely a statement of what content the service should, from now on, use to render representations of the resource identified by the client; POST is a statement of what content the service should, from now on, contain (possibly duplicated) but it's up to the server how to identify that content.PUT x (if x identifies a resource): \"Replace the content of the resource identified by x with my content.\"PUT x (if x does not identify a resource): \"Create a new resource containing my content and use x to identify it.\"POST x: \"Store my content and give me an identifier that I can use to identify a resource (old or new) containing said content (possibly mixed with other content). Said resource should be identical or subordinate to that which x identifies.\" \"y's resource is subordinate to x's resource\" is typically but not necessarily implemented by making y a subpath of x (e.g. x = /foo and y = /foo/bar) and modifying the representation(s) of x's resource to reflect the existence of a new resource, e.g. with a hyperlink to y's resource and some metadata. Only the latter is really essential to good design, as URLs are opaque in REST -- you're supposed to use hypermedia instead of client-side URL construction to traverse the service anyways.In REST, there's no such thing as a resource containing \"content\". I refer as \"content\" to data that the service uses to render representations consistently. It typically consists of some related rows in a database or a file (e.g. an image file). It's up to the service to convert the user's content into something the service can use, e.g. converting a JSON payload into SQL statements.Original answer (might be easier to read):PUT /something (if /something already exists): \"Take whatever you have at /something and replace it with what I give you.\"PUT /something (if /something does not already exist): \"Take what I give you and put it at /something.\"POST /something: \"Take what I give you and put it anywhere you want under /something as long as you give me its URL when you're done.\"",
                "Ruby on Rails 4.0 will use the 'PATCH' method instead of PUT to do partial updates.RFC 5789 says about PATCH (since 1995):A new method is necessary to improve interoperability and prevent\n     errors.  The PUT method is already defined to overwrite a resource\n     with a complete new body, and cannot be reused to do partial changes.\n     Otherwise, proxies and caches, and even clients and servers, may get\n     confused as to the result of the operation.  POST is already used but\n     without broad interoperability (for one, there is no standard way to\n     discover patch format support).  PATCH was mentioned in earlier HTTP\n     specifications, but not completely defined.\"Edge Rails: PATCH is the new primary HTTP method for updates\" explains it.",
                "In addition to differences suggested by others, I want to add one more.In POST method you can send body params in form-dataIn PUT method you have to send body params in x-www-form-urlencodedHeader Content-Type:application/x-www-form-urlencodedAccording to this, you cannot send files or multipart data in the PUT methodEDITThe content type \"application/x-www-form-urlencoded\" is inefficient\n  for sending large quantities of binary data or text containing\n  non-ASCII characters. The content type \"multipart/form-data\" should be\n  used for submitting forms that contain files, non-ASCII data, and\n  binary data.Which means if you have to submitfiles, non-ASCII data, and binary datayou should use POST method",
                "At the risk of restating what has already been said, it seems important to remember that PUT implies that the client controls what the URL is going to end up being, when creating a resource. So part of the choice between PUT and POST is going to be about how much you can trust the client to provide correct, normalized URL that are coherent with whatever your URL scheme is.When you can't fully trust the client to do the right thing, it would be \nmore appropriate to use POST to create a new item and then send the URL back to the client in the response.",
                "In a very simple way I'm taking the example of the Facebook timeline.Case 1: When you post something on your timeline, it's a fresh new entry. So in this case they use the POST method because the POST method is non-idempotent.Case 2: If your friend comment on your post the first time, that also will create a new entry in the database so the POST method used.Case 3: If your friend edits his comment, in this case, they had a comment id, so they will update an existing comment instead of creating a new entry in the database. Therefore for this type of operation use the PUT method because it is idempotent.*In a single line, use POST to add a new entry in the database and PUT to update something in the database.",
                "The most important consideration is reliability. If a POST message gets lost the state of the system is undefined. Automatic recovery is impossible. For PUT messages, the state is undefined only until the first successful retry.For instance, it may not be a good idea to create credit card transactions with POST.If you happen to have auto generated  URI's on your resource you can still use PUT by passing a generated URI (pointing to an empty resource) to the client.Some other considerations:",
                "Readers new to this topic will be struck by the endless discussion about what you should do, and the relative absence of lessons from experience. The fact that REST is \"preferred\" over SOAP is, I suppose, a high-level learning from experience, but goodness we must have progressed from there? It's 2016. Roy's dissertation was in 2000. What have we developed? Was it fun? Was it easy to integrate with? To support? Will it handle the rise of smartphones and flaky mobile connections?According to ME, real-life networks are unreliable. Requests timeout. Connections are reset. Networks go down for hours or days at a time. Trains go into tunnels with mobile users aboard. For any given request (as occasionally acknowledged in all this discussion) the request can fall in the water on its way, or the response can fall in the water on its way back. In these conditions, issuing PUT, POST and DELETE requests directly against substantive resources has always struck me as a little brutal and naive.HTTP does nothing to ensure reliable completion of the request-response, and that's just fine because this is properly the job of network-aware applications. Developing such an application, you can jump through hoops to use PUT instead of POST, then more hoops to give a certain kind of error on the server if you detect duplicate requests. Back at the client, you then have to jump through hoops to interpret these errors, refetch, revalidate and repost.Or you can do this: consider your unsafe requests as ephemeral single-user resources (let's call them actions). Clients request a new \"action\" on a substantive resource with an empty POST to the resource. POST will be used only for this. Once safely in possession of the URI of the freshly minted action, the client PUTs the unsafe request to the action URI, not the target resource. Resolving the action and updating the \"real\" resource is properly the job of your API, and is here decoupled from the unreliable network.The server does the business, returns the response and stores it against the agreed action URI. If anything goes wrong, the client repeats the request (natural behaviour!), and if the server has already seen it, it repeats the stored response and does nothing else.You will quickly spot the similarity with promises: we create and return the placeholder for the result before doing anything. Also like a promise, an action can succeed or fail one time, but its result can be fetched repeatedly.Best of all, we give sending and receiving applications a chance to link the uniquely identified action to uniqueness in their respective environments. And we can start to demand, and enforce!, responsible behaviour from clients: repeat your requests as much as you like, but don't go generating a new action until you're in possession of a definitive result from the existing one.As such, numerous thorny problems go away. Repeated insert requests won't create duplicates, and we don't create the real resource until we're in possession of the data. (database columns can stay not-nullable). Repeated update requests won't hit incompatible states and won't overwrite subsequent changes. Clients can (re)fetch and seamlessy process the original confirmation for whatever reason (client crashed, response went missing, etc.).Successive delete requests can see and process the original confirmation, without hitting a 404 error. If things take longer than expected, we can respond provisionally, and we have a place where the client can check back for the definitive result. The nicest part of this pattern is its Kung-Fu (Panda) property. We take a weakness, the propensity for clients to repeat a request any time they don't understand the response, and turn it into a strength :-)Before telling me this is not RESTful, please consider the numerous ways in which REST principles are respected. Clients don't construct URLs. The API stays discoverable, albeit with a little change in semantics. HTTP verbs are used appropriately. If you think this is a huge change to implement, I can tell you from experience that it's not.If you think you'll have huge amounts of data to store, let's talk volumes: a typical update confirmation is a fraction of a kilobyte. HTTP currently gives you a minute or two to respond definitively. Even if you only store actions for a week, clients have ample chance to catch up. If you have very high volumes, you may want a dedicated acid-compliant key value store, or an in-memory solution.",
                "There seems to always be some confusion as to when to use the HTTP POST versus the HTTP PUT method for REST services. Most developers will try to associate CRUD operations directly to HTTP methods. I will argue that this is not correct and one can not simply associate the CRUD concepts to the HTTP methods. That is:It is true that the R(etrieve) and D(elete) of the CRUD operations can be mapped directly to the HTTP methods GET and DELETE respectively. However, the confusion lies in the C(reate) and U(update) operations. In some cases, one can use the PUT for a create while in other cases a POST will be required. The ambiguity lies in the definition of an HTTP PUT method versus an HTTP POST method.According to the HTTP 1.1 specifications the GET, HEAD, DELETE, and PUT methods must be idempotent, and the POST method is not idempotent. That is to say that an operation is idempotent if it can be performed on a resource once or many times and always return the same state of that resource. Whereas a non idempotent operation can return a modified state of the resource from one request to another. Hence, in a non idempotent operation, there is no guarantee that one will receive the same state of a resource.Based on the above idempotent definition, my take on using the HTTP PUT method versus using the HTTP POST method for REST services is:\nUse the HTTP PUT method when:In both cases, these operations can be performed multiple times with the same results. That is the resource will not be changed by requesting the operation more than once. Hence, a true idempotent operation.\nUse the HTTP POST method when:ConclusionDo not directly correlate and map CRUD operations to HTTP methods for REST services. The use of an HTTP PUT method versus an HTTP POST method should be based on the idempotent aspect of that operation. That is, if the operation is idempotent, then use the HTTP PUT method. If the operation is non idempotent, then use the HTTP POST method.",
                "the origin server can create the resource with that URISo you use POST and probably, but not necessary PUT for resource creation. You don't have to support both. For me POST is perfectly enough. So it is a design decision.As your quote mentioned, you use PUT for creation of there is no resource assigned to an IRI, and you want to create a resource anyway. For example, PUT /users/123/password usually replaces the old password with a new one, but you can use it to create a password if it does not exist already (for example, by freshly registered users or by restoring banned users).",
                "I'm going to land with the following:PUT refers to a resource, identified by the URI. In this case, you are updating it. It is the part of the three verbs referring to resources -- delete and get being the other two.POST is basically a free form message, with its meaning being defined 'out of band'. If the message can be interpreted as adding a resource to a directory, that would be OK, but basically you need to understand the message you are sending (posting) to know what will happen with the resource.Because PUT and GET and DELETE refer to a resource, they are also by definition idempotent.POST can perform the other three functions, but then the semantics of the request will be lost on the intermediaries such as caches and proxies. This also applies to providing security on the resource, since a post's URI doesn't necessarily indicate the resource it is applying to (it can though).A PUT doesn't need to be a create; the service could error if the resource isn't already created, but otherwise update it. Or vice versa -- it may create the resource, but not allow updates. The only thing required about PUT is that it points to a specific resource, and its payload is the representation of that resource. A successful PUT means (barring interference) that a GET would retrieve the same resource.Edit: One more thing -- a PUT can create, but if it does then the ID has to be a natural ID -- AKA an email address. That way when you PUT twice, the second put is an update of the first. This makes it idempotent.If the ID is generated (a new employee ID, for example), then the second PUT with the same URL would create a new record, which violates the idempotent rule. In this case the verb would be POST, and the message (not resource) would be to create a resource using the values defined in this message.",
                "Here's a simple rule:PUT to a URL should be used to update or create the resource that can be located at that URL.POST to a URL should be used to update or create a resource which is located at some other (\"subordinate\") URL, or is not locatable via HTTP.",
                "The semantics are supposed be different, in that \"PUT\", like \"GET\" is supposed to be idempotent -- meaning, you can the same exact PUT request multiple times and the result will be as if you executed it only once.I will describe the conventions which I think are most widely used and are most useful:When you PUT a resource at a particular URL what happens is that it should get saved at that URL, or something along those lines.When you POST to a resource at a particular URL, often you are posting a related piece of information to that URL. This implies that the resource at the URL already exists.For example, when you want to create a new stream, you can PUT it to some URL. But when you want to POST a message to an existing stream, you POST to its URL.As for modifying the properties of the stream, you can do that with either PUT or POST. Basically, only use \"PUT\" when the operation is idempotent - otherwise use POST.Note, however, that not all modern browsers support HTTP verbs other than GET or POST.",
                "Most of the time, you will use them like this:For example:In both cases, the request body contains the data for the resource to be created or updated. It should be obvious from the route names that POST is not idempotent (if you call it 3 times it will create 3 objects), but PUT is idempotent (if you call it 3 times the result is the same). PUT is often used for \"upsert\" operation (create or update), but you can always return a 404 error if you only want to use it to modify.Note that POST \"creates\" a new element in the collection, and PUT \"replaces\" an element at a given URL, but it is a very common practice to use PUT for partial modifications, that is, use it only to update existing resources and only modify the included fields in the body (ignoring the other fields). This is technically incorrect, if you want to be REST-purist, PUT should replace the whole resource and you should use PATCH for the partial update. I personally don't care much as far as the behavior is clear and consistent across all your API endpoints.Remember, REST is a set of conventions and guidelines to keep your API simple. If you end up with a complicated work-around just to check the \"RESTfull\" box then you are defeating the purpose ;)",
                "To me, the key of understanding the difference was to understand who defines the ID of the resource:Example (with some address service)There are many great answers with great details below, but that helped me to get to the point.",
                "If you are familiar with database operations,\nthere areI use PUT for Merge and update like operations and use POST for Insertions.",
                "While there is probably an agnostic way to describe these, it does seem to be conflicting with various statements from answers to websites.Let's be very clear and direct here. If you are a .NET developer working with Web API, the facts are (from the Microsoft API documentation),\nhttp://www.asp.net/web-api/overview/creating-web-apis/creating-a-web-api-that-supports-crud-operations:Sure you \"can\" use \"POST\" to update, but just follow the conventions laid out for you with your given framework. In my case it is .NET / Web API, so PUT is for UPDATE there is no debate.I hope this helps any Microsoft developers that read all comments with Amazon and Sun/Java website links."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I include a JavaScript file in another JavaScript file?",
                "How do I include a JavaScript file inside another JavaScript file, similar to @import in CSS?"
            ],
            "url": "https://stackoverflow.com/questions/950087",
            "answer": [
                "The old versions of JavaScript had no import, include, or require, so many different approaches to this problem have been developed.But since 2015 (ES6), JavaScript has had the ES6 modules standard to import modules in Node.js, which is also supported by most modern browsers.For compatibility with older browsers, build tools like Webpack and Rollup and/or transpilation tools like Babel can be used.ECMAScript (ES6) modules have been supported in Node.js since v8.5, with the --experimental-modules flag, and since at least Node.js v13.8.0 without the flag. To enable \"ESM\" (vs. Node.js's previous CommonJS-style module system [\"CJS\"]) you either use \"type\": \"module\" in package.json or give the files the extension .mjs. (Similarly, modules written with Node.js's previous CJS module can be named .cjs if your default is ESM.)Using package.json:Then module.js:Then main.js:Using .mjs, you'd have module.mjs:Then main.mjs:Browsers have had support for loading ECMAScript modules directly (no tools like Webpack required) since Safari 10.1, Chrome 61, Firefox 60, and Edge 16. Check the current support at caniuse. There is no need to use Node.js' .mjs extension; browsers completely ignore file extensions on modules/scripts.Read more at https://jakearchibald.com/2017/es-modules-in-browsers/Dynamic imports let the script load other scripts as needed:Read more at https://developers.google.com/web/updates/2017/11/dynamic-importThe older CJS module style, still widely used in Node.js, is the module.exports/require system.There are other ways for JavaScript to include external JavaScript contents in browsers that do not require preprocessing.You could load an additional script with an AJAX call and then use eval to run it. This is the most straightforward way, but it is limited to your domain because of the JavaScript sandbox security model. Using eval also opens the door to bugs, hacks and security issues.Like Dynamic Imports you can load one or many scripts with a fetch call using promises to control order of execution for script dependencies using the Fetch Inject library:The jQuery library provides loading functionality in one line:You could add a script tag with the script URL into the HTML. To avoid the overhead of jQuery, this is an ideal solution.The script can even reside on a different server. Furthermore, the browser evaluates the code. The <script> tag can be injected into either the web page <head>, or inserted just before the closing </body> tag.Here is an example of how this could work:This function will add a new <script> tag to the end of the head section of the page, where the src attribute is set to the URL which is given to the function as the first parameter.Both of these solutions are discussed and illustrated in JavaScript Madness: Dynamic Script Loading.Now, there is a big issue you must know about. Doing that implies that you remotely load the code. Modern web browsers will load the file and keep executing your current script because they load everything asynchronously to improve performance. (This applies to both the jQuery method and the manual dynamic script loading method.)It means that if you use these tricks directly, you won't be able to use your newly loaded code the next line after you asked it to be loaded, because it will be still loading.For example: my_lovely_script.js contains MySuperObject:Then you reload the page hitting F5. And it works! Confusing...So what to do about it ?Well, you can use the hack the author suggests in the link I gave you. In summary, for people in a hurry, he uses an event to run a callback function when the script is loaded. So you can put all the code using the remote library in the callback function. For example:Then you write the code you want to use AFTER the script is loaded in a lambda function:Then you run all that:Note that the script may execute after the DOM has loaded, or before, depending on the browser and whether you included the line script.async = false;. There's a great article on Javascript loading in general which discusses this.As mentioned at the top of this answer, many developers use build/transpilation tool(s) like Parcel, Webpack, or Babel in their projects, allowing them to use upcoming JavaScript syntax, provide backward compatibility for older browsers, combine files, minify, perform code splitting etc.",
                "If anyone is looking for something more advanced, try out RequireJS. You'll get added benefits such as dependency management, better concurrency, and avoid duplication (that is, retrieving a script more than once).You can write your JavaScript files in \"modules\" and then reference them as dependencies in other scripts. Or you can use RequireJS as a simple \"go get this script\" solution.Example:Define dependencies as modules:some-dependency.jsimplementation.js is your \"main\" JavaScript file that depends on some-dependency.jsExcerpt from the GitHub README:RequireJS loads plain JavaScript files as well as more defined\n  modules. It is optimized for in-browser use, including in a Web\n  Worker, but it can be used in other JavaScript environments, like\n  Rhino and Node. It implements the Asynchronous Module API.RequireJS uses plain script tags to load modules/files, so it should\n  allow for easy debugging. It can be used simply to load existing\n  JavaScript files, so you can add it to your existing project without\n  having to re-write your JavaScript files....",
                "There actually is a way to load a JavaScript file not asynchronously, so you could use the functions included in your newly loaded file right after loading it, and I think it works in all browsers.You need to use jQuery.append() on the <head> element of your page, that is:However, this method also has a problem: if an error happens in the imported JavaScript file, Firebug (and also Firefox Error Console and Chrome Developer Tools as well) will report its place incorrectly, which is a big problem if you use Firebug to track JavaScript errors down a lot (I do). Firebug simply doesn't know about the newly loaded file for some reason, so if an error occurs in that file, it reports that it occurred in your main HTML file, and you will have trouble finding out the real reason for the error.But if that is not a problem for you, then this method should work.I have actually written a jQuery plugin called $.import_js() which uses this method:So all you would need to do to import JavaScript is:I also made a simple test for this at Example.It includes a main.js file in the main HTML and then the script in main.js uses $.import_js() to import an additional file called included.js, which defines this function:And right after including included.js, the hello() function is called, and you get the alert.(This answer is in response to e-satis' comment).",
                "Another way, that in my opinion is much cleaner, is to make a synchronous Ajax request instead of using a <script> tag. Which is also how Node.js handles includes.Here's an example using jQuery:You can then use it in your code as you'd usually use an include:And be able to call a function from the required script in the next line:",
                "It is possible to dynamically generate a JavaScript tag and append it to HTML document from inside other JavaScript code. This will load targeted JavaScript file.",
                "There is a good news for you. Very soon you will be able to load JavaScript code easily. It will become a standard way of importing modules of JavaScript code and will be part of core JavaScript itself.You simply have to write import cond from 'cond.js'; to load a macro named cond from a file cond.js.So you don't have to rely upon any JavaScript framework nor do you have to explicitly make Ajax calls.Refer to:Static module resolutionModule loaders",
                "Statement import is in ECMAScript 6.Syntax",
                "Maybe you can use this function that I found on this page How do I include a JavaScript file in a JavaScript file?:",
                "Here is a synchronous version without jQuery:Note that to get this working cross-domain, the server will need to set allow-origin header in its response.",
                "I just wrote this JavaScript code (using Prototype for DOM manipulation):Usage:Gist: http://gist.github.com/284442.",
                "If you want it in pure JavaScript, you can use document.write.If you use the jQuery library, you can use the $.getScript method.",
                "Here's the generalized version of how Facebook does it for their ubiquitous Like button:<script>\r\n  var firstScript = document.getElementsByTagName('script')[0],\r\n      js = document.createElement('script');\r\n  js.src = 'https://cdnjs.cloudflare.com/ajax/libs/Snowstorm/20131208/snowstorm-min.js';\r\n  js.onload = function () {\r\n    // do stuff with your dynamically loaded script\r\n    snowStorm.snowColor = '#99ccff';\r\n  };\r\n  firstScript.parentNode.insertBefore(js, firstScript);\r\n</script>If it works for Facebook, it will work for you.The reason why we look for the first script element instead of head or body is because some browsers don't create one if missing, but we're guaranteed to have a script element - this one. Read more at http://www.jspatterns.com/the-ridiculous-case-of-adding-a-script-element/.",
                "You can also assemble your scripts using PHP:File main.js.php:",
                "Most of solutions shown here imply dynamical loading. I was searching instead for a compiler which assemble all the depended files into a single output file. The same as Less/Sass preprocessors deal with the CSS @import at-rule. Since I didn't find anything decent of this sort, I wrote a simple tool solving the issue.So here is the compiler, https://github.com/dsheiko/jsic, which replaces $import(\"file-path\") with the requested file content securely. Here is the corresponding Grunt plugin: https://github.com/dsheiko/grunt-jsic.On the jQuery master branch, they simply concatenate atomic source files into a single one starting with intro.js and ending with outtro.js. That doesn't suits me as it provides no flexibility on the source code design. Check out how it works with jsic:src/main.jssrc/Form/Input/Tel.jsNow we can run the compiler:And get the combined filebuild/main.js",
                "If your intention to load the JavaScript file is using the functions from the imported/included file, you can also define a global object and set the functions as object items. For instance:You just need to be careful when you are including scripts in an HTML file. The order should be as in below:",
                "This should do:",
                "Or rather than including at run time, use a script to concatenate prior to upload.I use Sprockets (I don't know if there are others). You build your JavaScript code in separate files and include comments that are processed by the Sprockets engine as includes. For development you can include files sequentially, then for production to merge them...See also:",
                "I had a simple issue, but I was baffled by responses to this question.I had to use a variable (myVar1) defined in one JavaScript file (myvariables.js) in another JavaScript file (main.js).For this I did as below:Loaded the JavaScript code in the HTML file, in the correct order, myvariables.js first, then main.js:File: myvariables.jsFile: main.jsAs you saw, I had use a variable in one JavaScript file in another JavaScript file, but I didn't need to include one in another. I just needed to ensure that the first JavaScript file loaded before the second JavaScript file, and, the first JavaScript file's variables are accessible in the second JavaScript file, automatically.This saved my day. I hope this helps.",
                "In a modern language with the check if script has already been loaded, it would be:Usage (async/await):orUsage (Promise):",
                "The @import syntax for achieving CSS-like JavaScript importing is possible using a tool such as Mixture via their special .mix file type (see here). I assume the application does this via one of above-mentioned methods.From the Mixture documentation on .mix files:Mix files are simply .js or .css files with .mix. in the file name. A\nmix file simply     extends the functionality of a normal style or\nscript file and allows you to import and combine.Here's an example .mix file that combines multiple .js files into one:Mixture outputs this as scripts-global.js and also as a minified version (scripts-global.min.js).Note: I'm not in any way affiliated with Mixture, other than using it as a front-end development tool. I came across this question upon seeing a .mix JavaScript file in action (in one of the Mixture boilerplates) and being a bit confused by it (\"you can do this?\" I thought to myself). Then I realized that it was an application-specific file type (somewhat disappointing, agreed). Nevertheless, figured the knowledge might be helpful for others.Note: Mixture was discontinued on 2016/07/26 (after being open sourced on 2015/04/12).",
                "In case you are using Web Workers and want to include additional scripts in the scope of the worker, the other answers provided about adding scripts to the head tag, etc. will not work for you.Fortunately, Web Workers have their own importScripts function which is a global function in the scope of the Web Worker, native to the browser itself as it is part of the specification.Alternatively, as the second highest voted answer to your question highlights, RequireJS can also handle including scripts inside a Web Worker (likely calling importScripts itself, but with a few other useful features).",
                "Yes, use type=\"module\" in a script tag (support):And in a script.js file include another file like this:In 'module.js' you must export the function/class that you will import:A working example is here.",
                "Although these answers are great, there is a simple \"solution\" that has been around since script loading existed, and it will cover 99.999% of most people's use cases. Just include the script you need before the script that requires it. For most projects it does not take long to determine which scripts are needed and in what order.If script2 requires script1, this really is the absolute easiest way to do something like this. I'm very surprised no-one has brought this up, as it's the most obvious and simplest answer that will apply in nearly every single case.",
                "My usual method is:It works great and uses no page-reloads for me. I've tried the AJAX method (one of the other answers) but it doesn't seem to work as nicely for me.Here's an explanation of how the code works for those that are curious: essentially, it creates a new script tag (after the first one) of the URL. It sets it to asynchronous mode so it doesn't block the rest of the code, but calls a callback when the readyState (the state of the content to be loaded) changes to 'loaded'.",
                "I wrote a simple module that automates the job of importing/including module scripts in JavaScript. For detailed explanation of the code, refer to the blog post JavaScript require / import / include modules.",
                "This script will add a JavaScript file to the top of any other <script> tag:",
                "Keep it nice, short, simple, and maintainable! :]This code is simply a short functional example that could require additional feature functionality for full support on any (or given) platform.",
                "I came to this question because I was looking for a simple way to maintain a collection of useful JavaScript plugins. After seeing some of the solutions here, I came up with this:Set up a file called \"plugins.js\" (or extensions.js or whatever you want). Keep your plugin files together with that one master file.plugins.js will have an array called pluginNames[] that we will iterate over each(),\nthen append a <script> tag to the head for each pluginBUT:Even though all of the plugins get dropped into the head tag the way they ought to, they don't always get run by the browser when you click into the page or refresh.I've found it's more reliable to just write the script tags in a PHP include. You only have to write it once and that's just as much work as calling the plugin using JavaScript.",
                "There are several ways to implement modules in JavaScript. Here are the two most popular ones:Browsers do not support this moduling system yet, so in order for you to use this syntax you must use a bundler like Webpack. Using a bundler is better anyway because this can combine all of your different files into a single (or a couple of related) files. This will serve the files from the server to the client faster because each HTTP request has some associated overhead accompanied with it. Thus by reducing the overall HTTP request we improve the performance. Here is an example of ES6 modules:This moduling system is used in Node.js. You basically add your exports to an object which is called module.exports. You then can access this object via a require('modulePath'). Important here is to realize that these modules are being cached, so if you require() a certain module twice it will return the already created module."
            ]
        },
        {
            "tag": "",
            "question": [
                "What is the difference between \"let\" and \"var\"?",
                "ECMAScript 6 introduced the let statement.\nI've heard that it's described as a local variable, but I'm still not quite sure how it behaves differently than the var keyword.\nWhat are the differences? ..."
            ],
            "url": "https://stackoverflow.com/questions/762011",
            "answer": [
                "The main difference is scoping rules. Variables declared by var keyword are scoped to the immediate function body (hence the function scope) while let variables are scoped to the immediate enclosing block denoted by { } (hence the block scope).function run() {\n  var foo = \"Foo\";\n  let bar = \"Bar\";\n\n  console.log(foo, bar); // Foo Bar\n\n  {\n    var moo = \"Mooo\"\n    let baz = \"Bazz\";\n    console.log(moo, baz); // Mooo Bazz\n  }\n\n  console.log(moo); // Mooo\n  console.log(baz); // ReferenceError\n}\n\nrun();The reason why let keyword was introduced to the language was function scope is confusing and was one of the main sources of bugs in JavaScript.Take a look at this example from another Stack Overflow question:var funcs = [];\n// let's create 3 functions\nfor (var i = 0; i < 3; i++) {\n  // and store them in funcs\n  funcs[i] = function() {\n    // each should log its value.\n    console.log(\"My value: \" + i);\n  };\n}\nfor (var j = 0; j < 3; j++) {\n  // and now let's run each one to see\n  funcs[j]();\n}My value: 3 was output to console each time funcs[j](); was invoked since anonymous functions were bound to the same variable.People had to create immediately invoked functions to capture correct values from the loops but that was also hairy.While variables declared with var keyword are hoisted (initialized with undefined before the code is run) which means they are accessible in their enclosing scope even before they are declared:function run() {\n  console.log(foo); // undefined\n  var foo = \"Foo\";\n  console.log(foo); // Foo\n}\n\nrun();let variables are not initialized until their definition is evaluated. Accessing them before the initialization results in a ReferenceError. The variable is said to be in \"temporal dead zone\" from the start of the block until the initialization is processed.function checkHoisting() {\n  console.log(foo); // ReferenceError\n  let foo = \"Foo\";\n  console.log(foo); // Foo\n}\n\ncheckHoisting();At the top level, let, unlike var, does not create a property on the global object:var foo = \"Foo\";  // globally scoped\nlet bar = \"Bar\"; // not allowed to be globally scoped\n\nconsole.log(window.foo); // Foo\nconsole.log(window.bar); // undefinedIn strict mode, var will let you re-declare the same variable in the same scope while let raises a SyntaxError.'use strict';\nvar foo = \"foo1\";\nvar foo = \"foo2\"; // No problem, 'foo1' is replaced with 'foo2'.\n\nlet bar = \"bar1\"; \nlet bar = \"bar2\"; // SyntaxError: Identifier 'bar' has already been declared",
                "let can also be used to avoid problems with closures. It binds fresh value rather than keeping an old reference as shown in examples below.for(var i=1; i<6; i++) {\r\n  $(\"#div\" + i).click(function () { console.log(i); });\r\n}\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\r\n<p>Clicking on each number will log to console:</p> \r\n<div id=\"div1\">1</div>\r\n<div id=\"div2\">2</div>\r\n<div id=\"div3\">3</div>\r\n<div id=\"div4\">4</div>\r\n<div id=\"div5\">5</div>Code above demonstrates a classic JavaScript closure problem. Reference to the i variable is being stored in the click handler closure, rather than the actual value of i.Every single click handler will refer to the same object because there\u2019s only one counter object which holds 6 so you get six on each click.A general workaround is to wrap this in an anonymous function and pass i as an argument. Such issues can also be avoided now by using let instead var as shown in the code below.(Tested in Chrome and Firefox 50)for(let i=1; i<6; i++) {\r\n  $(\"#div\" + i).click(function () { console.log(i); });\r\n}\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js\"></script>\r\n<p>Clicking on each number will log to console:</p> \r\n<div id=\"div1\">1</div>\r\n<div id=\"div2\">2</div>\r\n<div id=\"div3\">3</div>\r\n<div id=\"div4\">4</div>\r\n<div id=\"div5\">5</div>",
                "To understand the difference, consider the following code:Here, we can see that our variable j is only known in the first for loop, but not before and after. Yet, our variable i is known in the entire function.Also, consider that block scoped variables are not known before they are declared because they are not hoisted. You're also not allowed to redeclare the same block scoped variable within the same block. This makes block scoped variables less error prone than globally or functionally scoped variables, which are hoisted and which do not produce any errors in case of multiple declarations.Some people would argue that in the future we'll ONLY use let statements and that var statements will become obsolete. JavaScript guru Kyle Simpson wrote a very elaborate article on why he believes that won't be the case.Today, however, that is definitely not the case. In fact, we need actually to ask ourselves whether it's safe to use the let statement. The answer to that question depends on your environment:If you're writing server-side JavaScript code (Node.js), you can safely use the let statement.If you're writing client-side JavaScript code and use a browser based transpiler (like Traceur or babel-standalone), you can safely use the let statement, however your code is likely to be anything but optimal with respect to performance.If you're writing client-side JavaScript code and use a Node based transpiler (like the traceur shell script or Babel), you can safely use the let statement. And, because your browser will only know about the transpiled code, performance drawbacks should be limited.If you're writing client-side JavaScript code and don't use a transpiler, you need to consider browser support.There are still some browsers that don't support let at all :For an up-to-date overview of which browsers support the let statement at the time of your reading this answer, see this Can I Use page.(*) Globally and functionally scoped variables can be initialized and used before they are declared because JavaScript variables are hoisted. This means that declarations are always moved to the top of the scope.(**) Block scoped variables are not hoisted",
                "Here's an explanation of the let keyword with some examples.let works very much like var. The main difference is that the scope of a var variable is the entire enclosing functionThis table on Wikipedia shows which browsers support Javascript 1.7.Note that only Mozilla and Chrome browsers support it. IE, Safari, and potentially others don't.",
                "Variables declared using the let keyword are block-scoped, which means that they are available only in the block in which they were declared.At the top level, variables declared using let don't create properties on the global object.Inside a function (but outside of a block), let has the same scope as var.Variables declared using let inside a block can't be accessed outside that block.Variables declared with let in loops can be referenced only inside that loop.If you use let instead of var in a loop, with each iteration you get a new variable. That means that you can safely use a closure inside a loop.Because of the temporal dead zone, variables declared using let can't be accessed before they are declared. Attempting to do so throws an error.You can't declare the same variable multiple times using let. You also can't declare a variable using let with the same identifier as another variable which was declared using var.const is quite similar to let\u2014it's block-scoped and has TDZ. There are, however, two things which are different.Variable declared using const can't be re-assigned.Note that it doesn't mean that the value is immutable. Its properties still can be changed.If you want to have an immutable object, you should use Object.freeze().You always must specify a value when declaring a variable using const.",
                "The accepted answer is missing a point:",
                "\u26a1\ufe0f Sandbox to play around \u2193",
                "The main difference is the scope difference, while let can be only available inside the scope it's declared, like in for loop, var can be accessed outside the loop for example. From the documentation in MDN (examples also from MDN):let allows you to declare variables that are limited in scope to the block, statement, or expression on which it is used. This is unlike the var keyword, which defines a variable globally, or locally to an entire function regardless of block scope.Variables declared by let have as their scope the block in which they are defined, as well as in any contained sub-blocks. In this way, let works very much like var. The main difference is that the scope of a var variable is the entire enclosing function:At the top level of programs and functions, let, unlike var, does not create a property on the global object. For example:When used inside a block, let limits the variable's scope to that block. Note the difference between var whose scope is inside the function where it is declared.Also don't forget it's ECMA6 feature, so it's not fully supported yet, so it's better always transpiles it to ECMA5 using Babel etc... for more info about visit babel website",
                "Here is an example for the difference between the two (support just started for chrome):As you can see the var j variable is still having a value outside of the for loop scope (Block Scope), but the let i variable is undefined outside of the for loop scope.\"use strict\";\r\nconsole.log(\"var:\");\r\nfor (var j = 0; j < 2; j++) {\r\n  console.log(j);\r\n}\r\n\r\nconsole.log(j);\r\n\r\nconsole.log(\"let:\");\r\nfor (let i = 0; i < 2; i++) {\r\n  console.log(i);\r\n}\r\n\r\nconsole.log(i);",
                "There are some subtle differences \u2014 let scoping behaves more like variable scoping does in more or less any other languages.e.g. It scopes to the enclosing block, They don't exist before they're declared, etc.However it's worth noting that let is only a part of newer Javascript implementations and has varying degrees of browser support.",
                "Variable Not Hoistinglet will not hoist to the entire scope of the block they appear in. By contrast, var could hoist as below.Actually, Per @Bergi, Both var and let are hoisted.Garbage CollectionBlock scope of let is useful relates to closures and garbage collection to reclaim memory. Consider,The click handler callback does not need the hugeData variable at all. Theoretically, after process(..) runs, the huge data structure hugeData could be garbage collected. However, it's possible that some JS engine will still have to keep this huge structure, since the click function has a closure over the entire scope.However, the block scope can make this huge data structure to garbage collected.let loopslet in the loop can re-binds it to each iteration of the loop, making sure to re-assign it the value from the end of the previous loop iteration. Consider,However, replace var with letBecause let create a new lexical environment with those names for a) the initialiser expression b) each iteration (previosly to evaluating the increment expression), more details are here.",
                "The difference is in the scope of the variables declared with each.In practice, there are a number of useful consequences of the difference in scope:The restrictions imposed by let reduce the visibility of the variables and increase the likelihood that unexpected name collisions will be found early.  This makes it easier to track and reason about variables, including their reachability(helping with reclaiming unused memory).Consequently, let variables are less likely to cause problems when used in large programs or when independently-developed frameworks are combined in new and unexpected ways.var may still be useful if you are sure you want the single-binding effect when using a closure in a loop (#5) or for declaring externally-visible global variables in your code (#4).  Use of var for exports may be supplanted if export migrates out of transpiler space and into the core language.1. No use outside nearest enclosing block:\nThis block of code will throw a reference error because the second use of x occurs outside of the block where it is declared with let:In contrast, the same example with var works.2. No use before declaration:\nThis block of code will throw a ReferenceError before the code can be run because x is used before it is declared:In contrast, the same example with var parses and runs without throwing any exceptions.3. No redeclaration:\nThe following code demonstrates that a variable declared with let may not be redeclared later:4. Globals not attached to window:5. Easy use with closures:\nVariables declared with var do not work well with closures inside loops.  Here is a simple loop that outputs the sequence of values that the variable i has at different points in time:Specifically, this outputs:In JavaScript we often use variables at a significantly later time than when they are created.  When we demonstrate this by delaying the output with a closure passed to setTimeout:... the output remains unchanged as long as we stick with let.  In contrast, if we had used var i instead:... the loop unexpectedly outputs \"i is 5\" five times:",
                "Here's an example to add on to what others have already written. Suppose you want to make an array of functions, adderFunctions, where each function takes a single Number argument and returns the sum of the argument and the function's index in the array. Trying to generate adderFunctions with a loop using the var keyword won't work the way someone might na\u00efvely expect:The process above doesn't generate the desired array of functions because i's scope extends beyond the iteration of the for block in which each function was created. Instead, at the end of the loop, the i in each function's closure refers to i's value at the end of the loop (1000) for every anonymous function in adderFunctions. This isn't what we wanted at all: we now have an array of 1000 different functions in memory with exactly the same behavior. And if we subsequently update the value of i, the mutation will affect all the adderFunctions.However, we can try again using the let keyword:This time, i is rebound on each iteration of the for loop. Each function now keeps the value of i at the time of the function's creation, and adderFunctions behaves as expected.Now, image mixing the two behaviors and you'll probably see why it's not recommended to mix the newer let and const with the older var in the same script. Doing so can result is some spectacularly confusing code.Don't let this happen to you. Use a linter.NOTE: This is a teaching example intended to demonstrate the var/let behavior in loops and with function closures that would also be easy to understand. This would be a terrible way to add numbers. But the general technique of capturing data in anonymous function closures might be encountered in the real world in other contexts. YMMV.",
                "May the following two functions show the difference:",
                "ES6 introduced two new keyword(let and const) alternate to var.When you need a block level deceleration you can go with let and const instead of var.The below table summarize the difference between var, let and const",
                "The main difference between var and let is that variables declared with var are function scoped. Whereas functions declared with let are block scoped. For example:variables with var:When the first function testVar gets called the variable foo, declared with var, is still accessible outside the if statement. This variable foo would be available everywhere within the scope of the testVar function.variables with let:When the second function testLet gets called the variable bar, declared with let, is only accessible inside the if statement. Because variables declared with let are block scoped (where a block is the code between curly brackets e.g if{} , for{}, function{}).Another difference between var and let is variables with declared with let don't get hoisted. An example is the best way to illustrate this behavior:variables with let don't get hoisted:variables with var do get hoisted:A variable declared with let in the global scope (which is code that is not in a function) doesn't get added as a property on the global window object. For example (this code is in global scope):When should let be used over var?Use let over var whenever you can because it is simply scoped more specific. This reduces potential naming conflicts which can occur when dealing with a large number of variables. var can be used when you want a global variable explicitly to be on the window object (always consider carefully if this is really necessary).",
                "let is interesting, because it allows us to do something like this:Which results in counting [0, 7].WhereasOnly counts [0, 1].",
                "It also appears that, at least in Visual Studio 2015, TypeScript 1.5, \"var\" allows multiple declarations of the same variable name in a block, and \"let\" doesn't.This won't generate a compile error:This will:",
                "This explanation was taken from an article I wrote at Medium:Hoisting is a JavaScript mechanism where variables and function\ndeclarations are moved to the top of their scope by the parser which\nreads the source code into an intermediate representation before the\nactual code execution starts by the JavaScript interpreter. So, it actually\ndoesn\u2019t matter where variables or functions are declared, they will be\nmoved to the top of their scope regardless of whether their scope is\nglobal or local. This means thatis actually interpreted toSo, as we saw just now, var variables are being hoisted to the top\nof their scope and are being initialized with the value of undefined\nwhich means that we can actually assign their value before actually\ndeclaring them in the code like so:Regarding function declarations, we can invoke them before actually declaring them like so:Function expressions, on the other hand, are not hoisted, so we\u2019ll get the following error:ES6 introduced JavaScript developers the let and const keywords. While let and const are block-scoped and not function\nscoped as var it shouldn\u2019t make a difference while discussing their\nhoisting behavior. We\u2019ll start from the end, JavaScript hoists let\nand const.As we can see above, let doesn\u2019t allow us to use undeclared\nvariables, hence the interpreter explicitly output a reference error\nindicating that the hi variable cannot be accessed before\ninitialization. The same error will occur if we change the above let\nto constSo, bottom line, the JavaScript parser searches for variable\ndeclarations and functions and hoists them to the top of their scope\nbefore code execution and assign values to them in the memory so in\ncase the interpreter will encounter them while executing the code he\nwill recognize them and will be able to execute the code with their\nassigned values. Variables declared with let or const remain\nuninitialized at the beginning of execution while that variables\ndeclared with var are being initialized with a value of undefined.I added this visual illustration to help understanding of how are the hoisted\nvariables and function are being saved in the memory",
                "var is global scope (hoist-able) variable.let and const is block scope.test.js{\r\n    let l = 'let';\r\n    const c = 'const';\r\n    var v = 'var';\r\n    v2 = 'var 2';\r\n}\r\n\r\nconsole.log(v, this.v);\r\nconsole.log(v2, this.v2);\r\nconsole.log(l); // ReferenceError: l is not defined\r\nconsole.log(c); // ReferenceError: c is not defined",
                "varIn this code sample, variable i is declared using var. Therefore, it has a function scope. It means you can access i from only inside the function x. You can't read it from outside the function xfunction x(){\n  var i = 100;\n  console.log(i); // 100\n}\n \nconsole.log(i); // Error. You can't do this\n\nx();In this sample, you can see i is declared inside a if block. But it's declared using var. Therefore, it gets function scope. It means still you can access variable i inside function x. Because var always get scoped to functions. Even though variable i is declared inside if block, because of it's using var it get scoped to parent function x.function x(){\n  if(true){\n    var i = 100;\n  }\n  console.log(i); \n}\n\nx();Now variable i is declared inside the function y. Therefore, i scoped to function y. You can access i inside function y. But not from outside function y.function x(){\n  function y(){\n    var i = 100;\n    console.log(i);\n  }\n  \n  y();\n}\n\nx();function x(){\n  function y(){\n    var i = 100;\n  }\n  console.log(i); // ERROR\n}\n\nx();let, constlet and const has block scope.const and let behave same. But the difference is, when you assign value to const you can't re-assign. But you can re-assign values with let.In this example, variable i is declared inside an if block. So it can be only accessed from inside that if block. We can't access it from outside that if block. (here const work same as let)if(true){\n  let i = 100;\n  console.log(i); // Output: 100\n}\n\nconsole.log(i); // Errorfunction x(){\n  if(true){\n    let i = 100;\n    console.log(i); // Output: 100\n  }\n  console.log(i); // Error\n}\n\nx();Another difference with (let, const) vs var is you can access var defined variable before declaring it. It will give you undefined. But if you do that with let or const defined variable it will give you an error.console.log(x);\nvar x = 100;console.log(x); // ERROR\nlet x = 100;",
                "If I read the specs right then let thankfully can also be leveraged to avoid self invoking functions used to simulate private only members - a popular design pattern that decreases code readability, complicates debugging, that adds no real code protection or other benefit - except maybe satisfying someone's desire for semantics, so stop using it. /rantSee 'Emulating private interfaces'",
                "When Using letThe let keyword attaches the variable declaration to the scope of whatever block (commonly a { .. } pair) it's contained in. In other words,let implicitly hijacks any block's scope for its variable declaration.let variables cannot be accessed in the window object because they cannot be globally accessed.When Using varvar and variables in ES5 has scopes in functions meaning the variables are valid within the function and not outside the function itself.var variables can be accessed in the window object because they cannot be globally accessed.If you want to know more continue reading belowone of the most famous interview questions on scope also can suffice the exact use of let and var as below;When using letThis is because when using let, for every loop iteration the variable is scoped and has its own copy.When using varThis is because when using var, for every loop iteration the variable is scoped and has shared copy.",
                "Some hacks with let:1.2.3.",
                "let vs var. It's all about scope.var variables are global and can be accessed basically everywhere, while let variables are not global and only exist until a closing parenthesis kills them.See my example below, and note how the lion (let) variable acts differently in the two console.logs; it becomes out of scope in the 2nd console.log.",
                "I just came across one use case that I had to use var over let to introduce new variable. Here's a case:I want to create a new variable with dynamic variable names.The above code doesn't work because eval introduces a new block of code. The declaration using var will declare a variable outside of this block of code since var declares a variable in the function scope.let, on the other hand, declares a variable in a block scope. So, a variable will only be visible in eval block.",
                "The below shows how 'let' and 'var' are different in the scope:The gfoo, defined by let initially is in the global scope, and when we declare gfoo again inside the if clause its scope changed and when a new value is assigned to the variable inside that scope it does not affect the global scope.Whereas hfoo, defined by var is initially in the global scope, but again when we declare it inside the if clause, it considers the global scope hfoo, although var has been used again to declare it. And when we re-assign its value we see that the global scope hfoo is also affected. This is the primary difference.",
                "let is a part of es6. These functions will explain the difference in easy way.",
                "As mentioned above:The difference is scoping. var is scoped to the nearest function\n  block and let is scoped to the nearest enclosing block, which\n  can be smaller than a function block. Both are global if outside any\n  block.Lets see an example:Example1:In my both examples I have a function myfunc. myfunc contains a variable myvar equals to 10. \nIn my first example  I check   if myvar equals to 10 (myvar==10) . If yes, I agian declare  a variable  myvar (now I have two myvar variables)using var keyword and assign it a new value (20). In next line I  print its value on my console.  After the conditional block I again print the value of myvar on my console. If you look at the output of myfunc,   myvar has value equals to 20.Example2:\nIn my second example  instead of using var keyword in my conditional block I declare myvar using let keyword . Now when I call myfunc  I get two different outputs: myvar=20 and myvar=10.So the difference is very simple i.e its scope.",
                "As I am currently trying to get an in depth understanding of JavaScript I will share my brief research which contains some of the great pieces already discussed plus some other details in a different perspective.Understanding the difference between var and let can be easier if we understand the difference between function and block scope.Let's consider the following cases:when timer() gets called an ExecutionContext is created which will contain both the VariableEnvironment and all the LexicalEnvironments corresponding to each iteration.And a simpler exampleFunction ScopeBlock Scope"
            ]
        },
        {
            "tag": "",
            "question": [
                "How to disable text selection highlighting",
                "For anchors that act like buttons (for example, the buttons on the sidebar of this Stack\u00a0Overflow page titled Questions, Tags, and Users) or tabs, is there a CSS standard way to disable the ..."
            ],
            "url": "https://stackoverflow.com/questions/826782",
            "answer": [
                "UPDATE January, 2017:According to Can I use, the user-select + -webkit-user-select for Safari is enough to achieve desired behavior in all major browsers.These are all of the available correct CSS variations:.noselect {\n  -webkit-touch-callout: none; /* iOS Safari */\n    -webkit-user-select: none; /* Safari */\n     -khtml-user-select: none; /* Konqueror HTML */\n       -moz-user-select: none; /* Old versions of Firefox */\n        -ms-user-select: none; /* Internet Explorer/Edge */\n            user-select: none; /* Non-prefixed version, currently\n                                  supported by Chrome, Edge, Opera and Firefox */\n}\n<p>\n  Selectable text.\n</p>\n<p class=\"noselect\">\n  Unselectable text.\n</p>Note that user-select is in standardization process (currently in a W3C working draft). It is not guaranteed to work everywhere and there might be differences in implementation among browsers. Also, browsers can drop support for it in the future.More information can be found in Mozilla Developer Network documentation.The values of this attribute are none, text, toggle, element, elements, all and inherit.",
                "In most browsers, this can be achieved using proprietary variations on the CSS user-select property, originally proposed and then abandoned in CSS\u00a03 and now proposed in CSS UI Level 4:For Internet Explorer < 10 and Opera < 15, you will need to use the unselectable attribute of the element you wish to be unselectable. You can set this using an attribute in HTML:Sadly this property isn't inherited, meaning you have to put an attribute in the start tag of every element inside the <div>. If this is a problem, you could instead use JavaScript to do this recursively for an element's descendants:Update 30 April 2014: This tree traversal needs to be rerun whenever a new element is added to the tree, but it seems from a comment by @Han that it is possible to avoid this by adding a mousedown event handler that sets unselectable on the target of the event. See http://jsbin.com/yagekiji/1 for details.This still doesn't cover all possibilities. While it is impossible to initiate selections in unselectable elements, in some browsers (Internet\u00a0Explorer and Firefox, for example) it's still impossible to prevent selections that start before and end after the unselectable element without making the whole document unselectable.",
                "Until CSS 3's user-select property becomes available, Gecko-based browsers support the -moz-user-select property you already found. WebKit and Blink-based browsers support the -webkit-user-select property.This of course is not supported in browsers that do not use the Gecko rendering engine.There is no \"standards\" compliant quick-and-easy way to do it; using JavaScript is an option.The real question is, why do you want users to not be able to highlight and presumably copy and paste certain elements? I have not come across a single time that I wanted to not let users highlight a certain portion of my website. Several of my friends, after spending many hours reading and writing code will use the highlight feature as a way to remember where on the page they were, or providing a marker so that their eyes know where to look next.The only place I could see this being useful is if you have buttons for forms that should not be copy and pasted if a user copy and pasted the website.",
                "A JavaScript solution for Internet\u00a0Explorer is:",
                "If you want to disable text selection on everything except on <p> elements, you can do this in CSS (watch out for the -moz-none which allows override in sub-elements, which is allowed in other browsers with none):",
                "In the solutions in previous answers selection is stopped, but the user still thinks you can select text because the cursor still changes. To keep it static, you'll have to set your CSS cursor:.noselect {\r\n    cursor: default;\r\n    -webkit-touch-callout: none;\r\n    -webkit-user-select: none;\r\n    -khtml-user-select: none;\r\n    -moz-user-select: none;\r\n    -ms-user-select: none;\r\n    user-select: none;\r\n}\n<p>\r\n  Selectable text.\r\n</p>\r\n<p class=\"noselect\">\r\n  Unselectable text.\r\n</p>This will make your text totally flat, like it would be in a desktop application.",
                "You can do so in Firefox and Safari (Chrome also?)",
                "Workaround for WebKit:I found it in a CardFlip example.",
                "I like the hybrid CSS + jQuery solution.To make all elements inside <div class=\"draggable\"></div> unselectable, use this CSS:And then, if you're using jQuery, add this inside a $(document).ready() block:I figure you still want any input elements to be interactable, hence the :not() pseudo-selector. You could use '*' instead if you don't care.Caveat: Internet\u00a0Explorer\u00a09 may not need this extra jQuery piece, so you may want to add a version check in there.",
                ".hidden:after {\r\n    content: attr(data-txt);\r\n}\n<p class=\"hidden\" data-txt=\"Some text you don't want to be selected\"></p>It's not the best way, though.",
                "You can use CSS or JavaScript for that.The JavaScript way is supported in older browsers, like old versions of Internet\u00a0Explorer as well, but if it's not your case, use the CSS way then:HTML/JavaScript:<html onselectstart='return false;'>\r\n  <body>\r\n    <h1>This is the Heading!</h1>\r\n    <p>And I'm the text, I won't be selected if you select me.</p>\r\n  </body>\r\n</html>HTML/CSS:.not-selectable {\r\n  -webkit-touch-callout: none;\r\n  -webkit-user-select: none;\r\n  -khtml-user-select: none;\r\n  -moz-user-select: none;\r\n  -ms-user-select: none;\r\n  user-select: none;\r\n}\n<body class=\"not-selectable\">\r\n  <h1>This is the Heading!</h1>\r\n  <p>And I'm the text, I won't be selected if you select me.</p>\r\n</body>",
                "For Internet Explorer in addition, you need to add pseudo class focus (.ClassName:focus) and outline-style: none.",
                "Try to insert these rows into the CSS and call the \"disHighlight\" at class property:",
                "A Quick Hack UpdateIf you use the value none for all the CSS user-select properties (including browser prefixes of it), there is a problem which can be still occurred by this.As CSS-Tricks says, the problem is:WebKit still allows the text to be copied, if you select elements around it.You can also use the below one to enforce that an entire element gets selected which means if you click on an element, all the text wrapped in that element will get selected. For this all you have to do is changing the value none to all.",
                "You can do this with a mixin:In an HTML tag:Try it in this CodePen.If you are using an autoprefixer you can remove other prefixes.Browser compatibility here.",
                "For those who have trouble achieving the same in the Android browser with the touch event, use:",
                "If you are using Less and Bootstrap you could write:",
                "Aside from the Mozilla-only property, no, there is no way to disable text selection with just standard CSS (as of now).If you notice, Stack Overflow doesn't disable text selection for their navigation buttons, and I would recommend against doing so in most cases, since it modifies normal selection behavior and makes it conflict with a user's expectations.",
                "This works in some browsers:Simply add your desired elements/ids in front of the selectors separated by commas without spaces, like so:The other answers are better; this should probably be seen as a last resort/catchall.",
                "Suppose there are two divs like this:.second {\r\n  cursor: default;\r\n  user-select: none;\r\n  -webkit-user-select: none;\r\n  /* Chrome/Safari/Opera */\r\n  -moz-user-select: none;\r\n  /* Firefox */\r\n  -ms-user-select: none;\r\n  /* Internet Explorer/Edge */\r\n  -webkit-touch-callout: none;\r\n  /* iOS Safari */\r\n}\n<div class=\"first\">\r\n  This is my first div\r\n</div>\r\n\r\n<div class=\"second\">\r\n  This is my second div\r\n</div>Set cursor to default so that it will give a unselectable feel to the user.Prefix need to be used to support it in all browsers. Without a prefix this may not work in all the answers.",
                "This will be useful if color selection is also not needed:...all other browser fixes. It will work in Internet\u00a0Explorer\u00a09 or later.",
                "Add this to the first div in which you want to disable the selection for text:",
                "NOTE:The correct answer is correct in that it prevents you from being able to select the text. However, it does not prevent you from being able to copy the text, as I'll show with the next couple of screenshots (as of 7th Nov 2014).As you can see, we were unable to select the numbers, but we were able to copy them.Tested on: Ubuntu, Google Chrome 38.0.2125.111.",
                "It is easily done with:Alternatively:Let's say you have a <h1 id=\"example\">Hello, World!</h1>. You will have to remove the innerHTML of that h1, in this case Hello, World. Then you will have to go to CSS and do this:Now it simply thinks it is a block-element, and not text.",
                "To get the result I needed, I found I had to use both ::selection and user-select",
                "This is not CSS, but it is worth a mention:jQuery UI Disable Selection:",
                "Check my solution without JavaScript:jsFiddleli:hover {\r\n    background-color: silver;\r\n}\r\n#id1:before {\r\n    content: \"File\";\r\n}\r\n#id2:before {\r\n    content: \"Edit\";\r\n}\r\n#id3:before {\r\n    content: \"View\";\r\n}\n<ul>\r\n    <li><a id=\"id1\" href=\"www.w1.com\"></a>\r\n    <li><a id=\"id2\" href=\"www.w2.com\"></a>\r\n    <li><a id=\"id3\" href=\"www.w3.com\"></a>\r\n</ul>Popup menu with my technique applied: http://jsfiddle.net/y4Lac/2/",
                "Though this pseudo-element was in drafts of CSS Selectors Level 3, it was removed during the Candidate Recommendation phase, as it appeared that its behavior was under-specified, especially with nested elements, and interoperability wasn't achieved.It's being discussed in How ::selection works on nested elements.Despite it is being implemented in browsers, you can make an illusion of text not being selected by using the same color and background color on selection as of the tab design (in your case).Disallowing users to select the text will raise usability issues.",
                "I have learned from the CSS-Tricks website.And this also:"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I discard unstaged changes in Git?",
                "How do I discard changes in my working copy that are not in the index?"
            ],
            "url": "https://stackoverflow.com/questions/52704",
            "answer": [
                "For all unstaged files in current working directory use:For a specific file use:That together with git switch replaces the overloaded git checkout (see here), and thus removes the argument disambiguation.If a file has both staged and unstaged changes, only the unstaged changes shown in git diff are reverted. Changes shown in git diff --staged stay intact.Before Git 2.23For all unstaged files in current working directory:For a specific file:-- here to remove ambiguity (this is known as  argument disambiguation).",
                "Another quicker way is:You don't need to include --include-untracked if you don't want to be thorough about it.After that, you can drop that stash with a git stash drop command if you like.",
                "It seems like the complete solution is:WARNING: while it won't delete ignored files mentioned directly in .gitignore, git clean -df may delete ignored files residing in folders.git clean removes all untracked files and git checkout clears all unstaged changes.",
                "This checks out the current index for the current directory, throwing away all changes in files from the current directory downwards.or this which checks out all files from the index, overwriting working tree files.",
                "Cleans the working tree by recursively removing files that are not under version control, starting from the current directory.-d: Remove untracked directories in addition to untracked files-f: Force (might be not necessary depending on  clean.requireForce setting)Run git help clean to see the manual",
                "You can now discard unstaged changes in one tracked file with:and in all tracked files in the current directory (recursively) with:If you run the latter from the root of the repository, it will discard unstaged changes in all tracked files in the project.",
                "My favorite isThat lets you selectively revert chunks.See also:",
                "Since no answer suggests the exact option combination that I use, here it is:This is the online help text for the used git clean options:-dRemove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository, it is not removed by default. Use -f option twice if you really want to remove such a directory.-xDon\u2019t use the standard ignore rules read from .gitignore (per directory) and $GIT_DIR/info/exclude, but do still use the ignore rules given with -e options. This allows removing all untracked files, including build products. This can be used (possibly in conjunction with git reset) to create a pristine working directory to test a clean build.-nDon\u2019t actually remove anything, just show what would be done.-fIf the Git configuration variable clean.requireForce is not set to false, Git clean will refuse to delete files or directories unless given -f, -n, or -i. Git will refuse to delete directories within the .git subdirectory or file, unless a second -f is given.",
                "If you merely wish to remove changes to existing files, use checkout (documented here).If you want to remove files added since your last commit, use clean (documented here):If you wish to move changes to a holding space for later access, use stash (documented here):",
                "The easiest way to do this is by using this command:This command is used to discard changes in working directory -https://git-scm.com/docs/git-checkoutIn git command, stashing of untracked files is achieved by using:http://git-scm.com/docs/git-stash",
                "I really found this article helpful for explaining when to use what command: http://www.szakmeister.net/blog/2011/oct/12/reverting-changes-git/There are a couple different cases:If you haven't staged the file, then you use git checkout.  Checkout \"updates files in the working tree to match the version in the index\".  If the files have not been staged (aka added to the index)... this command will essentially revert the files to what your last commit was.git checkout -- foo.txtIf you have staged the file, then use git reset.  Reset changes the index to match a commit.git reset -- foo.txtI suspect that using git stash is a popular choice since it's a little less dangerous.  You can always go back to it if you accidently blow too much away when using git reset.  Reset is recursive by default.Take a look at the article above for further advice.",
                "If you aren't interested in keeping the unstaged changes (especially if the staged changes are new files), I found this handy:",
                "As you type git status, \n(use \"git checkout -- ...\" to discard changes in working directory)\nis shown.e.g. git checkout -- .",
                "You can use git stash - if something goes wrong, you can still revert from the stash.\nSimilar to some other answer here, but this one also removes all unstaged files and also all unstaged deletes:if you check that everything is OK, throw the stash away:The answer from Bilal Maqsood with git clean also worked for me, but with the stash I have more control - if I do sth accidentally, I can still get my changes backUPDATEI think there is 1 more change (don't know why this worked for me before):git add . -A instead of git add .without the -A the removed files will not be staged",
                "git checkout -fman git-checkout:-f, --forceWhen switching branches, proceed even if the index or the working tree differs from HEAD. This is used to throw away local changes.When checking out paths from the index, do not fail upon unmerged entries; instead, unmerged entries are ignored.",
                "Instead of discarding changes, I reset my remote to the origin. Note - this method is to completely restore your folder to that of the repo.So I do this to make sure they don't sit there when I git reset (later - excludes gitignores on the Origin/branchname)NOTE: If you want to keep files not yet tracked, but not in GITIGNORE you may wish to skip this step, as it will Wipe these untracked files not found on your remote repository (thanks @XtrmJosh).Then IThen I reset to originThat will put it back to square one. Just like RE-Cloning the branch, WHILE keeping all my gitignored files locally and in place.Updated per user comment below:\nVariation to reset the to whatever current branch the user is on.",
                "Tried all the solutions above but still couldn't get rid of new, unstaged files.Use git clean -f to remove those new files - with caution though! Note the force option.",
                "To do a permanent discard:\ngit reset --hardTo save changes for later:\ngit stash",
                "Just use:Done. Easy.If you really care about your stash stack then you can follow with git stash drop. But at that point you're better off using (from Mariusz Nowak):Nonetheless, I like git stash -u the best because it \"discards\" all tracked and untracked changes in just one command. Yet git checkout -- . only discards tracked changes,\nand git clean -df only discards untracked changes... and typing both commands is far too much work :)",
                "simply sayIt will remove all your local changes. You also can use later by sayingor \n    git stash pop",
                "you have a very simple git command git checkout .",
                "This works even in directories that are; outside of normal git permissions.Happened to me recently",
                "No matter what state your repo is in you can always reset to any previous commit:This will discard all changes which were made after that commit.",
                "In my opinion,should do the trick. As per Git documentation on git cleangit-clean - Remove untracked files from the working treeDescriptionCleans the working tree by recursively removing files that\n  are not under version control, starting from the current directory.Normally, only files unknown to Git are removed, but if the -x option\n  is specified, ignored files are also removed. This can, for example,\n  be useful to remove all build products.If any optional ... arguments are given, only those paths are\n  affected.Options-d Remove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository, it is\n  not removed by default. Use -f option twice if you really want to\n  remove such a directory.-f\n  --force If the Git configuration variable clean.requireForce is not set to false, git clean will refuse to run unless given -f, -n or -i.",
                "Another way to get rid of new files that is more specific than git clean -df (it will allow you to get rid of some files not necessarily all), is to add the new files to the index first, then stash, then drop the stash.This technique is useful when, for some reason, you can't easily delete all of the untracked files by some ordinary mechanism (like rm).",
                "What follows is really only a solution if you are working with a fork of a repository where you regularly synchronize (e.g. pull request) with another repo. Short answer: delete fork and refork, but read the warnings on github.I had a similar problem, perhaps not identical, and I'm sad to say my solution is not ideal, but it is ultimately effective.I would often have git status messages like this (involving at least 2/4 files):A keen eye will note that these files have dopplegangers that are a single letter in case off. Somehow, and I have no idea what led me down this path to start with (as I was not working with these files myself from the upstream repo), I had switched these files. Try the many solutions listed on this page (and other pages) did not seem to help.I was able to fix the problem by deleting my forked repository and all local repositories, and reforking. This alone was not enough; upstream had to rename the files in question to new filenames. As long as you don't have any uncommited work, no wikis, and no issues that diverge from the upstream repository, you should be just fine. Upstream may not be very happy with you, to say the least. As for my problem, it is undoubtedly a user error as I'm not that proficient with git, but the fact that it is far from easy to fix points to an issue with git as well.",
                "I had a weird situation where a file is always unstaged, this helps me to resolve.git rm .gitattributes\n  git add -A\n  git reset --hard",
                "When you want to transfer a stash to someone else:[edit] as commented, it \u00eds possible to name stashes. Well, use this if you want to share your stash ;)",
                "You could create your own alias which describes how to do it in a descriptive way.I use the next alias to discard changes.Then you can use it as next to discard all changes:Or just a file:Otherwise, if you want to discard all changes and also the untracked files, I use a mix of checkout and clean:So the use is simple as next:Now is available in the next Github repo which contains a lot of aliases:"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I get the directory where a Bash script is located from within the script itself?",
                "How do I get the path of the directory in which a Bash script is located, inside that script?\nI want to use a Bash script as a launcher for another application. I want to change the working directory ..."
            ],
            "url": "https://stackoverflow.com/questions/59895",
            "answer": [
                "is a useful one-liner which will give you the full directory name of the script no matter where it is being called from.It will work as long as the last component of the path used to find the script is not a symlink (directory links are OK).  If you also want to resolve any links to the script itself, you need a multi-line solution:This last one will work with any combination of aliases, source, bash -c, symlinks, etc.Beware: if you cd to a different directory before running this snippet, the result may be incorrect!Also, watch out for $CDPATH gotchas, and stderr output side effects if the user has smartly overridden cd to redirect output to stderr instead (including escape sequences, such as when calling update_terminal_cwd >&2 on Mac). Adding >/dev/null 2>&1 at the end of your cd command will take care of both possibilities.To understand how it works, try running this more verbose form:And it will print something like:",
                "Use dirname \"$0\":Using pwd alone will not work if you are not running the script from the directory it is contained in.",
                "The dirname command is the most basic, simply parsing the path up to the filename off of the $0 (script name) variable:But, as matt b pointed out, the path returned is different depending on how the script is called. pwd doesn't do the job because that only tells you what the current directory is, not what directory the script resides in. Additionally, if a symbolic link to a script is executed, you're going to get a (probably relative) path to where the link resides, not the actual script.Some others have mentioned the readlink command, but at its simplest, you can use:readlink will resolve the script path to an absolute path from the root of the filesystem. So, any paths containing single or double dots, tildes and/or symbolic links will be resolved to a full path.Here's a script demonstrating each of these, whatdir.sh:Running this script in my home dir, using a relative path:Again, but using the full path to the script:Now changing directories:And finally using a symbolic link to execute the script:There is however one case where this doesn't work, when the script is sourced (instead of executed) in bash:",
                "It works for all versions, includingAlternatively, if the Bash script itself is a relative symlink you want to follow it and return the full path of the linked-to script:SCRIPT_PATH is given in full path, no matter how it is called.Just make sure you locate this at start of the script.",
                "You can use $BASH_SOURCE:Note that you need to use #!/bin/bash and not #!/bin/sh since it's a Bash extension.",
                "Short answer:or (preferably):",
                "Here is an easy-to-remember script:",
                "This should do it:This works with symlinks and spaces in path.Please see the man pages for dirname and realpath.Please add a comment on how to support MacOS. I'm sorry I can verify it.",
                "pwd can be used to find the current working directory, and dirname to find the directory of a particular file (command that was run, is $0, so dirname $0 should give you the directory of the current script).However, dirname gives precisely the directory portion of the filename, which more likely than not is going to be relative to the current working directory. If your script needs to change directory for some reason, then the output from dirname becomes meaningless.I suggest the following:This way, you get an absolute, rather than a relative directory.Since the script will be run in a separate Bash instance, there isn't any need to restore the working directory afterwards, but if you do want to change back in your script for some reason, you can easily assign the value of pwd to a variable before you change directory, for future use.Although justsolves the specific scenario in the question, I find having the absolute path to more more useful generally.",
                "I don't think this is as easy as others have made it out to be.  pwd doesn't work, as the current directory is not necessarily the directory with the script.  $0 doesn't always have the information either.  Consider the following three ways to invoke a script:In the first and third ways $0 doesn't have the full path information.  In the second and third, pwd does not work.  The only way to get the directory in the third way would be to run through the path and find the file with the correct match.  Basically the code would have to redo what the OS does.One way to do what you are asking would be to just hardcode the data in the /usr/share directory, and reference it by its full path.  Data shoudn't be in the /usr/bin directory anyway, so this is probably the thing to do.",
                "This gets the current working directory on Mac\u00a0OS\u00a0X\u00a0v10.6.6 (Snow\u00a0Leopard):",
                "This is Linux specific, but you could use:",
                "Here is a POSIX compliant one-liner:",
                "The shortest and most elegant way to do this is:This would work on all platforms and is super clean.More details can be found in \"Which directory is that bash script in?\".",
                "...even when the called script is called from within another bash function or script, or when nested sourcing is being used!For many cases, all you need to acquire is the full path to the script you just called. This can be easily accomplished using realpath. Note that realpath is part of GNU coreutils. If you don't have it already installed (it comes default on Ubuntu), you can install it with sudo apt update && sudo apt install coreutils.get_script_path.sh (for the latest version of this script, see get_script_path.sh in my eRCaGuy_hello_world repo):IMPORTANT note on nested source calls: if \"${BASH_SOURCE[-1]}\" above doesn't give you quite what you want, try using \"${BASH_SOURCE[0]}\" instead. The first (0) index gives you the first entry in the array, and the last (-1) index gives you the last last entry in the array. Depending on what it is you're after, you may actually want the first entry. I discovered this to be the case when I sourced ~/.bashrc with . ~/.bashrc, which sourced ~/.bash_aliases with . ~/.bash_aliases, and I wanted the realpath (with expanded symlinks) to the ~/.bash_aliases file, NOT to the ~/.bashrc file. Since these are nested source calls, using \"${BASH_SOURCE[0]}\" gave me what I wanted: the expanded path to ~/.bash_aliases! Using \"${BASH_SOURCE[-1]}\", however, gave me what I did not want: the expanded path to ~/.bashrc.Example command and output:If you use \"$0\" in the script instead of \"${BASH_SOURCE[-1]}\", you'll get the same output as above when running the script, but this undesired output instead when sourcing the script:And, apparently if you use \"$BASH_SOURCE\" instead of \"${BASH_SOURCE[-1]}\", it will not work if the script is called from within another bash function. So, using \"${BASH_SOURCE[-1]}\" is therefore the best way to do it, as it solves both of these problems! See the references below.Difference between realpath and realpath -s:Note that realpath also successfully walks down symbolic links to determine and point to their targets rather than pointing to the symbolic link. If you do NOT want this behavior (sometimes I don't), then add -s to the realpath command above, making that line look like this instead:This way, symbolic links are NOT expanded. Rather, they are left as-is, as symbolic links in the full path.The code above is now part of my eRCaGuy_hello_world repo in this file here: bash/get_script_path.sh. Reference and run this file for full examples both with and withOUT symlinks in the paths. See the bottom of the file for example output in both cases.BASH_SOURCEAn array variable whose members are the source filenames where the corresponding shell function names in the FUNCNAME array variable are defined. The shell function ${FUNCNAME[$i]} is defined in the file ${BASH_SOURCE[$i]} and called from ${BASH_SOURCE[$i+1]}.",
                "Here is the simple, correct way:Explanation:${BASH_SOURCE[0]} - the full path to the script. The value of this will be correct even when the script is being sourced, e.g. source <(echo 'echo $0') prints bash, while replacing it with ${BASH_SOURCE[0]} will print the full path of the script. (Of course, this assumes you're OK taking a dependency on Bash.)readlink -f - Recursively resolves any symlinks in the specified path. This is a GNU extension, and not available on (for example) BSD systems. If you're running a Mac, you can use Homebrew to install GNU coreutils and supplant this with greadlink -f.And of course dirname gets the parent directory of the path.",
                "I tried all of these and none worked. One was very close, but it had a tiny bug that broke it badly; they forgot to wrap the path in quotation marks.Also a lot of people assume you're running the script from a shell, so they forget when you open a new script it defaults to your home.Try this directory on for size:This gets it right regardless how or where you run it:So to make it actually useful, here's how to change to the directory of the running script:",
                "This is a slight revision to the solution e-satis and 3bcdnlklvc04a pointed out in their answer:This should still work in all the cases they listed.This will prevent popd after a failed pushd. Thanks to konsolebox.",
                "I would use something like this:",
                "For systems having GNU coreutils readlink (for example, Linux):There's no need to use BASH_SOURCE when $0 contains the script filename.",
                "Try using:",
                "$_ is worth mentioning as an alternative to $0.  If you're running a script from Bash, the accepted answer can be shortened to:Note that this has to be the first statement in your script.",
                "These are short ways to get script information:Folders and files:Using these commands:And I got this output:Also see: https://pastebin.com/J8KjxrPF",
                "This works in Bash 3.2:If you have a ~/bin directory in your $PATH, you have  A inside this directory. It sources the script ~/bin/lib/B. You know where the included script is relative to the original one, in the lib subdirectory, but not where it is relative to the user's current directory.This is solved by the following (inside A):It doesn't matter where the user is or how he/she calls the script. This will always work.",
                "I've compared many of the answers given, and came up with some more compact solutions. These seem to handle all of the crazy edge cases that arise from your favorite combination of:If you're running from Linux, it seems that using the proc handle is the best solution to locate the fully resolved source of the currently running script (in an interactive session, the link points to the respective /dev/pts/X):This has a small bit of ugliness to it, but the fix is compact and easy to understand. We aren't using bash primitives only, but I'm okay with that because readlink simplifies the task considerably. The echo X adds an X to the end of the variable string so that any trailing whitespace in the filename doesn't get eaten, and the parameter substitution ${VAR%X} at the end of the line gets rid of the X. Because readlink adds a newline of its own (which would normally be eaten in the command substitution if not for our previous trickery), we have to get rid of that, too. This is most easily accomplished using the $'' quoting scheme, which lets us use escape sequences such as \\n to represent newlines (this is also how you can easily make deviously named directories and files).The above should cover your needs for locating the currently running script on Linux, but if you don't have the proc filesystem at your disposal, or if you're trying to locate the fully resolved path of some other file, then maybe you'll find the below code helpful. It's only a slight modification from the above one-liner. If you're playing around with strange directory/filenames, checking the output with both ls and readlink is informative, as ls will output \"simplified\" paths, substituting ? for things like newlines.",
                "I believe I've got this one. I'm late to the party, but I think some will appreciate it being here if they come across this thread. The comments should explain:",
                "Try the following cross-compatible solution:As the commands such as realpath or readlink could be not available (depending on the operating system).Note: In Bash, it's recommended to use ${BASH_SOURCE[0]} instead of $0, otherwise path can break when sourcing the file (source/.).Alternatively you can try the following function in Bash:This function takes one argument. If argument has already absolute path, print it as it is, otherwise print $PWD variable + filename argument (without ./ prefix).Related:"
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I execute a program or call a system command?",
                "How do I call an external command within Python as if I had typed it in a shell or command prompt?"
            ],
            "url": "https://stackoverflow.com/questions/89228",
            "answer": [
                "Use the subprocess module in the standard library:The advantage of subprocess.run over os.system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...).Even the documentation for os.system recommends using subprocess instead:The subprocess module provides more powerful facilities for spawning new processes and retrieving their results; using that module is preferable to using this function. See the Replacing Older Functions with the subprocess Module section in the subprocess documentation for some helpful recipes.On Python 3.4 and earlier, use subprocess.call instead of .run:",
                "Here is a summary of ways to call external programs, including their advantages and disadvantages:os.system passes the command and arguments to your system's shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example:However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, et cetera. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.os.popen will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don't need to worry about escaping anything. Example:subprocess.Popen. This is intended as a replacement for os.popen, but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you'd say:instead ofbut it is nice to have all of the options there in one unified class instead of 4 different popen functions. See the documentation.subprocess.call. This is basically just like the Popen class and takes all of the same arguments, but it simply waits until the command completes and gives you the return code. For example:subprocess.run. Python 3.5+ only. Similar to the above but even more flexible and returns a CompletedProcess object when the command finishes executing.os.fork, os.exec, os.spawn are similar to their C language counterparts, but I don't recommend using them directly.The subprocess module should probably be what you use.Finally, please be aware that for all methods where you pass the final command to be executed by the shell as a string and you are responsible for escaping it. There are serious security implications if any part of the string that you pass can not be fully trusted. For example, if a user is entering some/any part of the string. If you are unsure, only use these methods with constants. To give you a hint of the implications consider this code:and imagine that the user enters something \"my mama didnt love me && rm -rf /\" which could erase the whole filesystem.",
                "Typical implementation:You are free to do what you want with the stdout data in the pipe.  In fact, you can simply omit those parameters (stdout= and stderr=) and it'll behave like os.system().",
                "Some hints on detaching the child process from the calling one (starting the child process in background).Suppose you want to start a long task from a CGI script. That is, the child process should live longer than the CGI script execution process.The classical example from the subprocess module documentation is:The idea here is that you do not want to wait in the line 'call subprocess' until the longtask.py is finished. But it is not clear what happens after the line 'some more code here' from the example.My target platform was FreeBSD, but the development was on Windows, so I faced the problem on Windows first.On Windows (Windows\u00a0XP), the parent process will not finish until the longtask.py has finished its work. It is not what you want in a CGI script. The problem is not specific to Python; in the PHP community the problems are the same.The solution is to pass DETACHED_PROCESS Process Creation Flag to the underlying CreateProcess function in Windows API.\nIf you happen to have installed pywin32, you can import the flag from the win32process module, otherwise you should define it yourself:/* UPD 2015.10.27 @eryksun in a comment below notes, that the semantically correct flag is CREATE_NEW_CONSOLE (0x00000010) */On FreeBSD we have another problem: when the parent process is finished, it finishes the child processes as well. And that is not what you want in a CGI script either. Some experiments showed that the problem seemed to be in sharing sys.stdout. And the working solution was the following:I have not checked the code on other platforms and do not know the reasons of the behaviour on FreeBSD. If anyone knows, please share your ideas. Googling on starting background processes in Python does not shed any light yet.",
                "Note that this is dangerous, since the command isn't cleaned. I leave it up to you to google for the relevant documentation on the 'os' and 'sys' modules. There are a bunch of functions (exec* and spawn*) that will do similar things.",
                "I'd recommend using the subprocess module instead of os.system because it does shell escaping for you and is therefore much safer.",
                "If you want to return the results of the command, you can use os.popen. However, this is deprecated since version 2.6 in favor of the subprocess module, which other answers have covered well.",
                "There are lots of different libraries which allow you to call external commands with Python. For each library I've given a description and shown an example of calling an external command. The command I used as the example is ls -l (list all files). If you want to find out more about any of the libraries I've listed and linked the documentation for each of them.Hopefully this will help you make a decision on which library to use :)Subprocess allows you to call external commands and connect them to their input/output/error pipes (stdin, stdout, and stderr). Subprocess is the default choice for running commands, but sometimes other modules are better.os is used for \"operating system dependent functionality\". It can also be used to call external commands with os.system and os.popen (Note: There is also a subprocess.popen). os will always run the shell and is a simple alternative for people who don't need to, or don't know how to use subprocess.run.sh is a subprocess interface which lets you call programs as if they were functions. This is useful if you want to run a command multiple times.plumbum is a library for \"script-like\" Python programs. You can call programs like functions as in sh. Plumbum is useful if you want to run a pipeline without the shell.pexpect lets you spawn child applications, control them and find patterns in their output. This is a better alternative to subprocess for commands that expect a tty on Unix.fabric is a Python 2.5 and 2.7 library. It allows you to execute local and remote shell commands. Fabric is simple alternative for running commands in a secure shell (SSH)envoy is known as \"subprocess for humans\". It is used as a convenience wrapper around the subprocess module.commands contains wrapper functions for os.popen, but it has been removed from Python 3 since subprocess is a better alternative.",
                "Use the subprocess module (Python 3):It is the recommended standard way. However, more complicated tasks (pipes, output, input, etc.) can be tedious to construct and write.Note on Python version: If you are still using Python 2, subprocess.call works in a similar way.ProTip: shlex.split can help you to parse the command for run, call, and other subprocess functions in case you don't want (or you can't!) provide them in form of lists:If you do not mind external dependencies, use plumbum:It is the best subprocess wrapper. It's cross-platform, i.e. it works on both Windows and Unix-like systems. Install by pip install plumbum.Another popular library is sh:However, sh dropped Windows support, so it's not as awesome as it used to be. Install by pip install sh.",
                "I always use fabric for this things like:But this seem to be a good tool: sh (Python subprocess interface).Look at an example:",
                "Check the \"pexpect\" Python library, too.It allows for interactive controlling of external programs/commands, even ssh, ftp, telnet, etc. You can just type something like:",
                "If you need the output from the command you are calling,\nthen you can use subprocess.check_output (Python 2.7+).Also note the shell parameter.If shell is True, the specified command will be executed through the shell. This can be useful if you are using Python primarily for the enhanced control flow it offers over most system shells and still want convenient access to other shell features such as shell pipes, filename wildcards, environment variable expansion, and expansion of ~ to a user\u2019s home directory. However, note that Python itself offers implementations of many shell-like features (in particular, glob, fnmatch, os.walk(), os.path.expandvars(), os.path.expanduser(), and shutil).",
                "subprocess.run is the recommended approach as of Python 3.5 if your code does not need to maintain compatibility with earlier Python versions. It's more consistent and offers similar ease-of-use as Envoy. (Piping isn't as straightforward though. See this question for how.)Here's some examples from the documentation.Run a process:Raise on failed run:Capture output:I recommend trying Envoy. It's a wrapper for subprocess, which in turn aims to replace the older modules and functions. Envoy is subprocess for humans.Example usage from the README:Pipe stuff around too:",
                "This is how I run my commands. This code has everything you need pretty much",
                "Simple, use subprocess.run, which returns a CompletedProcess object:(run wants a list of lexically parsed shell arguments - this is what you'd type in a shell, separated by spaces, but not where the spaces are quoted, so use a specialized function, split, to split up what you would literally type into your shell)As of Python 3.5, the documentation recommends subprocess.run:The recommended approach to invoking subprocesses is to use the run() function for all use cases it can handle. For more advanced use cases, the underlying Popen interface can be used directly.Here's an example of the simplest possible usage - and it does exactly as asked:run waits for the command to successfully finish, then returns a CompletedProcess object. It may instead raise TimeoutExpired (if you give it a timeout= argument) or CalledProcessError (if it fails and you pass check=True).As you might infer from the above example, stdout and stderr both get piped to your own stdout and stderr by default.We can inspect the returned object and see the command that was given and the returncode:If you want to capture the output, you can pass subprocess.PIPE to the appropriate stderr or stdout:And those respective attributes return bytes.One might easily move from manually providing a command string (like the question suggests) to providing a string built programmatically. Don't build strings programmatically. This is a potential security issue. It's better to assume you don't trust the input.Note, only args should be passed positionally.Here's the actual signature in the source and as shown by help(run):The popenargs and kwargs are given to the Popen constructor. input can be a string of bytes (or unicode, if specify encoding or universal_newlines=True) that will be piped to the subprocess's stdin.The documentation describes timeout= and check=True better than I could:The timeout argument is passed to Popen.communicate(). If the timeout\nexpires, the child process will be killed and waited for. The\nTimeoutExpired exception will be re-raised after the child process has\nterminated.If check is true, and the process exits with a non-zero exit code, a\nCalledProcessError exception will be raised. Attributes of that\nexception hold the arguments, the exit code, and stdout and stderr if\nthey were captured.and this example for check=True is better than one I could come up with:Here's an expanded signature, as given in the documentation:Note that this indicates that only the args list should be passed positionally. So pass the remaining arguments as keyword arguments.When use Popen instead? I would struggle to find use-case based on the arguments alone. Direct usage of Popen would, however, give you access to its methods, including poll, 'send_signal', 'terminate', and 'wait'.Here's the Popen signature as given in the source. I think this is the most precise encapsulation of the information (as opposed to help(Popen)):But more informative is the Popen documentation:Execute a child program in a new process. On POSIX, the class uses\nos.execvp()-like behavior to execute the child program. On Windows,\nthe class uses the Windows CreateProcess() function. The arguments to\nPopen are as follows.Understanding the remaining documentation on Popen will be left as an exercise for the reader.",
                "Use subprocess....or for a very simple command:",
                "As of Python 3.7.0 released on June 27th 2018 (https://docs.python.org/3/whatsnew/3.7.html), you can achieve your desired result in the most powerful while equally simple way. This answer intends to show you the essential summary of various options in a short manner. For in-depth answers, please see the other ones.The big advantage of os.system(...) was its simplicity. subprocess is better and still easy to use, especially as of Python 3.5.Note: This is the exact answer to your question - running a commandlike in a shellIf possible, remove the shell overhead and run the command directly (requires a list).Pass program arguments in a list. Don't include \\\"-escaping for arguments containing spaces.The following code speaks for itself:result.stdout is all normal program output excluding errors. Read result.stderr to get them.capture_output=True - turns capturing on. Otherwise result.stderr and result.stdout would be None. Available from Python 3.7.text=True - a convenience argument added in Python 3.7 which converts the received binary data to Python strings you can easily work with.DoIf you just want to check if the program succeeded (returncode == 0) and otherwise throw an Exception, there is a more convenient function:But it's Python, so there's an even more convenient argument check which does the same thing automatically for you:You might want to have all program output inside stdout, even errors. To accomplish this, runresult.stderr will then be None and result.stdout will contain everything.shell=False expects a list of arguments. You might however, split an argument string on your own using shlex.That's it.Chances are high you just started using Python when you come across this question. Let's look at some common problems.FileNotFoundError: [Errno 2] No such file or directory: 'ls -a': 'ls -a'You're running a subprocess without shell=True . Either use a list ([\"ls\", \"-a\"]) or set shell=True.TypeError: [...] NoneType [...]Check that you've set capture_output=True.TypeError: a bytes-like object is required, not [...]You always receive byte results from your program. If you want to work with it like a normal string, set text=True.subprocess.CalledProcessError: Command '[...]' returned non-zero exit status 1.Your command didn't run successfully. You could disable returncode checking or check your actual program's validity.TypeError: init() got an unexpected keyword argument [...]You're likely using a version of Python older than 3.7.0; update it to the most recent one available. Otherwise there are other answers in this Stack Overflow post showing you older alternative solutions.",
                "os.system is OK, but kind of dated.  It's also not very secure.  Instead, try subprocess.  subprocess does not call sh directly and is therefore more secure than os.system.Get more information here.",
                "There is also Plumbum",
                "Use:os - This module provides a portable way of using operating system-dependent functionality.For the more os functions, here is the documentation.",
                "It can be this simple:",
                "There is another difference here which is not mentioned previously.subprocess.Popen executes the <command> as a subprocess. In my case, I need to execute file <a> which needs to communicate with another program, <b>.I tried subprocess, and execution was successful. However <b> could not communicate with <a>.\nEverything is normal when I run both from the terminal.One more: \n(NOTE: kwrite behaves different from other applications. If you try the below with Firefox, the results will not be the same.)If you try os.system(\"kwrite\"), program flow freezes until the user closes kwrite. To overcome that I tried instead os.system(konsole -e kwrite). This time program continued to flow, but kwrite became the subprocess of the console.Anyone runs the kwrite not being a subprocess (i.e. in the system monitor it must appear at the leftmost edge of the tree).",
                "os.system does not allow you to store results, so if you want to store results in some list or something, a subprocess.call works.",
                "subprocess.check_call is convenient if you don't want to test return values. It throws an exception on any error.",
                "I tend to use subprocess together with shlex (to handle escaping of quoted strings):",
                "I wrote a library for this, shell.py.It's basically a wrapper for popen and shlex for now. It also supports piping commands, so you can chain commands easier in Python. So you can do things like:",
                "In Windows you can just import the subprocess module and run external commands by calling subprocess.Popen(), subprocess.Popen().communicate() and subprocess.Popen().wait() as below:Output:",
                "Under Linux, in case you would like to call an external command that will execute independently (will keep running after the Python script terminates), you can use a simple queue as task spooler or the at command.An example with task spooler:Notes about task spooler (ts):You could set the number of concurrent processes to be run (\"slots\") with:ts -S <number-of-slots>Installing ts doesn't requires admin privileges. You can download and compile it from source with a simple make, add it to your path and you're done.",
                "Invoke is a Python (2.7 and 3.4+) task execution tool and library. It provides a clean, high-level API for running shell commands:",
                "You can use Popen, and then you can check the procedure's status:Check out subprocess.Popen."
            ]
        },
        {
            "tag": "",
            "question": [
                "How do I change the URI (URL) for a remote Git repository?",
                "I have a repo (origin) on a USB key that I cloned on my hard drive (local). I moved \"origin\" to a NAS and successfully tested cloning it from here.\nI would like to know if I can change the ..."
            ],
            "url": "https://stackoverflow.com/questions/2432764",
            "answer": [
                "You canSee git help remote. You also can edit .git/config and change the URLs there.You're not in any danger of losing history unless you do something very silly (and if you're worried, just make a copy of your repo, since your repo is your history.)",
                "Changing a remote's URL",
                "git remote set-url {name} {url}",
                "Change Host for a Git Origin Serverfrom: http://pseudofish.com/blog/2010/06/28/change-host-for-a-git-origin-server/Hopefully this isn\u2019t something you need to do. The server that I\u2019ve been using to collaborate on a few git projects with had the domain name expire. This meant finding a way of migrating the local repositories to get back in sync.Update: Thanks to @mawolf for pointing out there is an easy way with recent git versions (post Feb, 2010):See the man page for details.If you\u2019re on an older version, then try this:As a caveat, this works only as it is the same server, just with different names.Assuming that the new hostname is newhost.com, and the old one was oldhost.com, the change is quite simple.Edit the .git/config file in your working directory. You should see something like:Change oldhost.com to newhost.com, save the file and you\u2019re done.From my limited testing (git pull origin; git push origin; gitx) everything seems in order. And yes, I know it is bad form to mess with git internals.",
                "This is very easy and simple; just follow these instructions.",
                "Open Terminal.Ist Step:- Change the current working directory to your local project.2nd Step:- List your existing remotes in order to get the name of the remote you want to change.git remote -vChange your remote's URL from HTTPS to SSH with the git remote set-url command.3rd Step:-  git remote set-url origin git@github.com:USERNAME/REPOSITORY.git4th Step:- Now Verify that the remote URL has changed.git remote -v\nVerify new remote URL",
                "(alternatively, open .git/config, look for [remote \"origin\"], and edit the url = line.You can check it worked by examining the remotes:Next time you push, you'll have to specify the new upstream branch, e.g.:See also: GitHub: Changing a remote's URL",
                "As seen here,",
                "First you need to type this command to view existing remotesgit remote -vThen second you need to type this command to Change the 'origin' remote's URLgit remote set-url origin <paste your GitHub URL>",
                "Write the below command from your repo terminal:Refer this link for more details about changing the url in the remote.",
                "To check git remote connection:Now, set the local repository to remote git:Now to make it upstream or push use following code:git push --set-upstream origin master -f",
                "Navigate to the project root of the local repository and check for existing remotes:If your repository is using SSH you will see something like:And if your repository is using HTTPS you will see something like:Changing the URL is done with git remote set-url. Depending on the output of git remote -v, you can change the URL in the following manner:In case of SSH, you can change the URL from REPOSITORY.git to NEW_REPOSITORY.git like:And in case of HTTPS, you can change the URL from REPOSITORY.git to NEW_REPOSITORY.git like:NOTE: If you've changed your GitHub username, you can follow the same process as above to update the change in the username associated with your repository. You would only have to update the USERNAME in the git remote set-url command.",
                "if you cloned your local will automatically consist,remote URL where it gets  cloned.you can check  it using git remote -vif you want to made change in it,here,origin - your branchif you want to overwrite existing branch you can still use it.. it will override your existing ... it will do,for you...",
                "Troubleshooting :You may encounter these errors when trying to changing a remote.\nNo such remote '[name]'This error means that the remote you tried to change doesn't exist:git remote set-url sofake https://github.com/octocat/Spoon-Knife\nfatal: No such remote 'sofake'Check that you've correctly typed the remote name.Reference : https://help.github.com/articles/changing-a-remote-s-url/",
                "I worked:",
                "In the Git Bash, enter the command:git remote set-url origin https://NewRepoLink.gitEnter the CredentialsDone",
                "You have a lot of ways to do that:ConsoleJust be sure that you've opened it in a place where a repository is.ConfigIt is placed in .git/config (same folder as repository)TortoiseGitThen just edit URL.SourceTreeClick on the \"Settings\" button on the toolbar to open the Repository Settings window.Click \"Add\" to add a remote repository path to the repository. A \"Remote details\" window will open.Enter a name for the remote path.Enter the URL/Path for the remote repositoryEnter the username for the hosting service for the remote repository.Click 'OK' to add the remote path.Back on the Repository Settings window, click 'OK'. The new remote path should be added on the repository now.If you need to edit an already added remote path, just click the 'Edit' button. You should be directed to the \"Remote details\" window where you can edit the details (URL/Path/Host Type) of the remote path.To remove a remote repository path, click the 'Remove' buttonref. Support",
                "For me, the accepted answer worked only in the case of fetch but not pull. I did the following to make it work for push as well.So to update the fetch URL:To update the pull URL:",
                "Change remote git URI to git@github.com rather than https://github.comExample:The benefit is that you may do git push automatically when you use ssh-agent :Put a script file $HOME/.ssh/agent to let it runs ssh-add using expect as below:",
                "To change the remote upstream:\ngit remote set-url origin <url>To add more upstreams:\ngit remote add newplace <url>So you can choose where to work\ngit push origin <branch> or git push newplace <branch>",
                "You can change the url by editing the config file.\nGo to your project root:Then edit the url field and set your new url. \nSave the changes. You can verify the changes by using the command.",
                "An alternative approach is to rename the 'old' origin (in the example below I name it simply old-origin) and adding a new one. This might be the desired approach if you still want to be able to push to the old origin every now and then:And in case you need to push your local state to the new origin:",
                "If you're using TortoiseGit then follow the below steps:Your branch and all your local commits will remain intact and you can keep working as you were before.",
                "Removing a remoteUse the git remote rm command to remove a remote URL from your repository.",
                "If you would like to set the username and password as well in the origin url, you can follow the below steps.Exporting the password in a variable would avoid issues with special characters.Steps:",
                "check your privilegein my case i need to check  my usernamei have two or three repository with seperate credentials.problem is my permission i have two private git server and repositoriesthis second account is admin of that new repo and first one is my default user account and i should grant permission to first",
                "For those who want to make this change from Visual Studio 2019Open Team Explorer (Ctrl+M)Home -> SettingsGit -> Repository SettingsRemotes -> Edit",
                "If your repository is private thenReference"
            ]
        },
        {
            "tag": "",
            "question": [
                "Which equals operator (== vs ===) should be used in JavaScript comparisons?",
                "I'm using JSLint to go through JavaScript, and it's returning many suggestions to replace == (two equals signs) with === (three equals signs) when doing things like comparing idSele_UNVEHtype.value...."
            ],
            "url": "https://stackoverflow.com/questions/359494",
            "answer": [
                "The strict equality operator (===) behaves identically to the abstract equality operator (==) except no type conversion is done, and the types must be the same to be considered equal.Reference: Javascript Tutorial: Comparison OperatorsThe == operator will compare for equality after doing any necessary type conversions.  The === operator will not do the conversion, so if two values are not the same type === will simply return false. Both are equally quick.To quote Douglas Crockford's excellent JavaScript: The Good Parts,JavaScript has two sets of equality operators: === and !==, and their evil twins == and !=.  The good ones work the way you would expect.  If the two operands are of the same type and have the same value, then === produces true and !== produces false.  The evil twins do the right thing when the operands are of the same type, but if they are of different types, they attempt to coerce the values.  the rules by which they do that are complicated and unmemorable.  These are some of the interesting cases:The lack of transitivity is alarming.  My advice is to never use the evil twins.  Instead, always use === and !==.  All of the comparisons just shown produce false with the === operator.A good point was brought up by @Casebash in the comments and in @Phillipe Laybaert's answer concerning objects.  For objects, == and === act consistently with one another (except in a special case).The special case is when you compare a primitive with an object that evaluates to the same primitive, due to its toString or valueOf method. For example, consider the comparison of a string primitive with a string object created using the String constructor.Here the == operator is checking the values of the two objects and returning true, but the === is seeing that they're not the same type and returning false.  Which one is correct?  That really depends on what you're trying to compare.  My advice is to bypass the question entirely and just don't use the String constructor to create string objects from string literals.Reference\nhttp://www.ecma-international.org/ecma-262/5.1/#sec-11.9.3",
                "This is because the equality operator == does type coercion, meaning that the interpreter implicitly tries to convert the values before comparing.On the other hand, the identity operator === does not do type coercion, and thus does not convert the values when comparing.",
                "Here's an interesting visualisation of the equality comparison between == and ===.Source: https://github.com/dorey/JavaScript-Equality-Table (demo, unified demo)When using === for JavaScript equality testing, everything is as is.\nNothing gets converted before being evaluated.When using == for JavaScript equality testing, some funky conversions take place.Always use ===, unless you fully understand the funky conversions that take place with ==.",
                "In the answers here, I didn't read anything about what equal means. Some will say that === means equal and of the same type, but that's not really true. It actually means that both operands reference the same object, or in case of value types, have the same value.So, let's take the following code:The same here:Or even:This behavior is not always obvious. There's more to the story than being equal and being of the same type.The rule is:For value types (numbers):\na === b returns true if a and b have the same value and are of the same typeFor reference types:\na === b returns true if a and b reference the exact same objectFor strings:\na === b returns true if a and b are both strings and contain the exact same charactersStrings are not value types, but in Javascript they behave like value types, so they will be \"equal\" when the characters in the string are the same and when they are of the same length (as explained in the third rule)Now it becomes interesting:But how about this?:I thought strings behave like value types? Well, it depends who you ask... In this case a and b are not the same type. a is of type Object, while b is of type string. Just remember that creating a string object using the String constructor creates something of type Object that behaves as a string most of the time.",
                "Let me add this counsel:If in doubt, read the specification!ECMA-262 is the specification for a scripting language of which JavaScript is a dialect. Of course in practice it matters more how the most important browsers behave than an esoteric definition of how something is supposed to be handled. But it is helpful to understand why new String(\"a\") !== \"a\".Please let me explain how to read the specification to clarify this question. I see that in this very old topic nobody had an answer for the very strange effect. So, if you can read a specification, this will help you in your profession tremendously. It is an acquired skill. So, let's continue.Searching the PDF file for === brings me to page 56 of the specification: 11.9.4. The Strict Equals Operator ( === ), and after wading through the specificationalese I find:11.9.6 The Strict Equality Comparison Algorithm\nThe comparison x === y, where x and y are values, produces true or false. Such a comparison is performed as follows:\n\u00a0\u00a01. If Type(x) is different from Type(y), return false.\n\u00a0\u00a02. If Type(x) is Undefined, return true.\n\u00a0\u00a03. If Type(x) is Null, return true.\n\u00a0\u00a04. If Type(x) is not Number, go to step 11.\n\u00a0\u00a05. If x is NaN, return false.\n\u00a0\u00a06. If y is NaN, return false.\n\u00a0\u00a07. If x is the same number value as y, return true.\n\u00a0\u00a08. If x is +0 and y is \u22120, return true.\n\u00a0\u00a09. If x is \u22120 and y is +0, return true.\n\u00a0\u00a010. Return false.\n\u00a0\u00a011. If Type(x) is String, then return true if x and y are exactly the same sequence of characters (same length and same characters in corresponding positions); otherwise, return false.\n\u00a0\u00a012. If Type(x) is Boolean, return true if x and y are both true or both false; otherwise, return false.\n\u00a0\u00a013. Return true if x and y refer to the same object or if they refer to objects joined to each other (see 13.1.2). Otherwise, return false.Interesting is step 11. Yes, strings are treated as value types. But this does not explain why new String(\"a\") !== \"a\". Do we have a browser not conforming to ECMA-262?Not so fast!Let's check the types of the operands. Try it out for yourself by wrapping them in typeof(). I find that new String(\"a\") is an object, and step 1 is used: return false if the types are different.If you wonder why new String(\"a\") does not return a string, how about some exercise reading a specification? Have fun!Aidiakapi wrote this in a comment below:From the specification11.2.2 The new Operator:If Type(constructor) is not Object, throw a TypeError exception.With other words, if String wouldn't be of type Object it couldn't be used with the new operator.new always returns an Object, even for String constructors, too. And alas! The value semantics for strings (see step 11) is lost.And this finally means: new String(\"a\") !== \"a\".",
                "I tested this in Firefox with Firebug using code like this:console.time(\"testEquality\");\nvar n = 0;\nwhile (true) {\n  n++;\n  if (n == 100000)\n    break;\n}\nconsole.timeEnd(\"testEquality\");andconsole.time(\"testTypeEquality\");\nvar n = 0;\nwhile (true) {\n  n++;\n  if (n === 100000)\n    break;\n}\nconsole.timeEnd(\"testTypeEquality\");My results (tested five times each and averaged):So I'd say that the miniscule difference (this is over 100000 iterations, remember) is negligible. Performance isn't a reason to do ===. Type safety (well, as safe as you're going to get in JavaScript), and code quality is.",
                "In PHP and JavaScript, it is a strict equality operator. Which means, it will compare both type and values.",
                "In JavaScript it means of the same value and type.For example,but",
                "Why == is so unpredictable?What do you get when you compare an empty string \"\" with the number zero 0?trueYep, that's right according to == an empty string and the number zero are the same time.And it doesn't end there, here's another one:Things get really weird with arrays.Then weirder with stringsIt get's worse:When is equal not equal?Let me say that again:And this is just the crazy stuff you get with primitives.It's a whole new level of crazy when you use == with objects.At this point your probably wondering...Why does this happen?Well it's because unlike \"triple equals\" (===) which just checks if two values are the same.== does a whole bunch of other stuff.It has special handling for functions, special handling for nulls, undefined, strings, you name it.It get's pretty wacky.In fact, if you tried to write a function that does what == does it would look something like this:So what does this mean?It means == is complicated.Because it's complicated it's hard to know what's going to happen when you use it.Which means you could end up with bugs.So the moral of the story is...Make your life less complicated.Use === instead of ==.The End.",
                "The === operator is called a strict comparison operator, it does differ from the == operator.Lets take 2 vars a and b.For \"a == b\" to evaluate to true a and b need to be the same value.In the case of \"a === b\" a and b must be the same value and also the same type for it to evaluate to true.Take the following exampleIn summary; using the == operator might evaluate to true in situations where you do not want it to so using the === operator would be safer.In the 90% usage scenario it won't matter which one you use, but it is handy to know the difference when you get some unexpected behaviour one day.",
                "Many times an untyped check would be handy because you do not care if the value is either undefined, null, 0  or \"\"",
                "Javascript execution flow diagram for strict equality / Comparison '==='Javascript execution flow diagram for non strict equality / comparison '=='",
                "JavaScript === vs == .",
                "It means equality without type coercion\ntype coercion means JavaScript do not automatically convert any other data types to string data types",
                "In a typical script there will be no performance difference. More important may be the fact that thousand \"===\" is 1\u00a0KB heavier than thousand \"==\" :) JavaScript profilers can tell you if there is a performance difference in your case.But personally I would do what JSLint suggests. This recommendation is there not because of performance issues, but because type coercion means ('\\t\\r\\n' == 0) is true.",
                "The equal comparison operator == is confusing and should be avoided.If you HAVE TO live with it, then remember the following 3 things:EQUAL OPERATOR TRUTH TABLE IN JAVASCRIPT** STRANGE: note that any two values on the first column are not equal in that sense.**",
                "There is unlikely to be any performance difference between the two operations in your usage. There is no type-conversion to be done because both parameters are already the same type. Both operations will have a type comparison followed by a value comparison.",
                "Yes! It does matter.=== operator in javascript checks value as well as type where as == operator just checks the value (does type conversion if required).You can easily test it. Paste following code in an HTML file and open it in browserYou will get 'false' in alert. Now modify the onPageLoad() method to alert(x == 5); you will get true.",
                "Simply== means comparison between operands with type coercionand=== means comparison between operands without type coercion.Type coercion in JavaScript means automatically converting data types to other data types.For example:",
                "As a rule of thumb, I would generally use === instead of == (and !== instead of !=).Reasons are explained in in the answers above and also Douglas Crockford is pretty clear about it (JavaScript: The Good Parts).However there is one single exception:\n== null is an efficient way to check for 'is null or undefined':For example jQuery 1.9.1 uses this pattern 43 times, and  the JSHint syntax checker even provides the eqnull relaxing option for this reason.From the jQuery style guide:Strict equality checks (===) should be used in favor of ==. The only\nexception is when checking for undefined and null by way of null.EDIT 2021-03:Nowadays most browsers\nsupport the Nullish coalescing operator (??)\nand the Logical nullish assignment (??=), which allows a more concise way to\nassign a default value if a variable is null or undefined, for example:can be written as any of these forms",
                "It's a strict check test.It's a good thing especially if you're checking between 0 and false and null.For example, if you have:Then:All returns true and you may not want this. Let's suppose you have a function that can return the 0th index of an array or false on failure. If you check with \"==\" false, you can get a confusing result.So with the same thing as above, but a strict test:",
                "=== operator  checks the values as well as the types of the variables for equality.== operator just checks the value of the variables for equality.",
                "JSLint sometimes gives you unrealistic reasons to modify stuff. === has exactly the same performance as == if the types are already the same.It is faster only when the types are not the same, in which case it does not try to convert types but directly returns a false.So, IMHO, JSLint maybe used to write new code, but useless over-optimizing should be avoided at all costs.Meaning, there is no reason to change == to === in a check like if (a == 'test') when you know it for a fact that a can only be a String.Modifying a lot of code that way wastes developers' and reviewers' time and achieves nothing.",
                "A simple example is",
                "The top 2 answers both mentioned == means equality and === means identity. Unfortunately, this statement is incorrect.If both operands of == are objects, then they are compared to see if they are the same object. If both operands point to the same object, then the equal operator returns true. Otherwise,\nthe two are not equal.In the code above, both == and === get false because a and b are not the same objects.That's to say: if both operands of == are objects, == behaves same as ===, which also means identity. The essential difference of this two operators is about type conversion. == has conversion before it checks equality, but === does not.",
                "The problem is that you might easily get into trouble since JavaScript have a lot of implicit conversions meaning...Which pretty soon becomes a problem. The best sample of why implicit conversion is \"evil\" can be taken from this code in MFC / C++ which actually will compile due to an implicit conversion from CString to HANDLE which is a pointer typedef type...Which obviously during runtime does very undefined things...Google for implicit conversions in C++ and STL to get some of the arguments against it...",
                "From the core javascript reference=== Returns true if the operands are strictly equal (see above)\n  with no type conversion.",
                "Equality comparison:Operator ==Returns true, when both operands are equal. The operands are converted to the same type before being compared.Equality and type comparison:Operator ===Returns true if both operands are equal and of the same type. It's generally \nbetter and safer if you compare this way, because there's no behind-the-scenes type conversions.",
                "Here is a handy comparison table that shows the conversions that happen and the differences between == and ===.As the conclusion states:\"Use three equals unless you fully understand the conversions that take\n  place for two-equals.\"http://dorey.github.io/JavaScript-Equality-Table/",
                "null and undefined are nothingness, that is,Here a and b do not have values. Whereas, 0, false and '' are all values. One thing common beween all these are that they are all falsy values, which means they all satisfy falsy conditions.So, the 0, false and '' together form a sub-group. And on other hand, null & undefined form the second sub-group. Check the comparisons in the below image. null and undefined would equal. The other three would equal to each other. But, they all are treated as falsy conditions in JavaScript.This is same as any object (like {}, arrays, etc.), non-empty string & Boolean true are all truthy conditions. But, they are all not equal."
            ]
        },
        {
            "tag": "",
            "question": [
                "What is the maximum length of a URL in different browsers?",
                "What is the maximum length of a URL for each browser?\nIs a maximum URL length part of the HTTP specification?"
            ],
            "url": "https://stackoverflow.com/questions/417142",
            "answer": [
                "If you keep URLs under 2000 characters, they'll work in virtually any combination of client and server software.If you are targeting particular browsers, see below for more details on specific limits.RFC 2616 (Hypertext Transfer Protocol HTTP/1.1) section 3.2.1 saysThe HTTP protocol does not place\nany a priori limit on the length of\na URI. Servers MUST be able to handle\nthe URI of any resource they    serve,\nand SHOULD be able to handle URIs of\nunbounded length if they    provide\nGET-based forms that could generate\nsuch URIs. A server    SHOULD return\n414 (Request-URI Too Long) status if a\nURI is longer    than the server can\nhandle (see section 10.4.15).That RFC has been obsoleted by RFC7230 which is a refresh of the HTTP/1.1 specification. It contains similar language, but also goes on to suggest this:Various ad hoc limitations on request-line length are found in\npractice. It is RECOMMENDED that all HTTP senders and recipients\nsupport, at a minimum, request-line lengths of 8000 octets.That's what the standards say. For the reality, there was an article on boutell.com (link goes to Internet Archive backup) that discussed what individual browser and server implementations will support. The executive summary is:Extremely long URLs are usually a\nmistake. URLs over 2,000 characters\nwill not work in the most popular web\nbrowsers. Don't use them if you intend\nyour site to work for the majority of\nInternet users.(Note: this is a quote from an article written in 2006, but in 2015 IE's declining usage means that longer URLs do work for the majority. However, IE still has the limitation...)IE8's maximum URL length is 2083 chars, and it seems IE9 has a similar limit.I've tested IE10 and the address bar will only accept 2083 chars. You can click a URL which is longer than this, but the address bar will still only show 2083 characters of this link.There's a nice writeup on the IE Internals blog which goes into some of the background to this.There are mixed reports IE11 supports longer URLs - see comments below. Given some people report issues, the general advice still stands.Be aware that the sitemaps protocol, which allows a site to inform search engines about available pages, has a limit of 2048 characters in a URL. If you intend to use sitemaps, a limit has been decided for you! (see Calin-Andrei Burloiu's answer below)There's also some research from 2010 into the maximum URL length that search engines will crawl and index. They found the limit was 2047 chars, which appears allied to the sitemap protocol spec. However, they also found the Google SERP tool wouldn't cope with URLs longer than 1855 chars.CDNs also impose limits on URI length, and will return a 414 Too long request when these limits are reached, for example:(credit to timrs2998 for providing that info in the comments)I tested the following against an Apache 2.4 server configured with a very large LimitRequestLine and LimitRequestFieldSize.See also this answer from Matas Vaitkevicius below.This is a popular question, and as the original research is ~14 years old I'll try to keep it up to date: As of Jan 2021, the advice still stands. Even though IE11 may possibly accept longer URLs, the ubiquity of older IE installations plus the search engine limitations mean staying under 2000 chars is the best general policy.",
                "The longest URLs I came across are data URLsExample image URL from Google image results (11747 characters)",
                "I wrote this test that keeps on adding 'a' to parameter until the browser failsC# part:View:PART 1On Chrome I got:It then blew up with:HTTP Error 404.15 - Not Found The request filtering module is\n  configured to deny a request where the query string is too long.Same on Internet\u00a0Explorer\u00a08 and FirefoxPART 2I went easy mode and added additional limits to IISExpress applicationhost.config and web.config setting maxQueryStringLength=\"32768\".after 7744 characters.PART 3Addedwhich didn't help at all. I finally decided to use fiddler to remove the referrer from header.Which did nicely.Chrome: got to 15613 characters. (I guess it's a 16K limit for IIS)And it failed again with:Firefox:Internet Explorer 8 failed with iexplore.exe crashing.After 2505Android EmulatorInternet Explorer 11Internet Explorer 10Internet Explorer 9",
                "WWW FAQs: What is the maximum length of a URL? has its own answer based on empirical testing and research. The short answer is that going over 2048 characters makes Internet\u00a0Explorer unhappy and thus this is the limit you should use. See the page for a long answer.",
                "On Apple platforms (iOS/macOS/tvOS/watchOS), the limit may be a 2 GB long URL scheme, as seen by this comment in the source code of Swift:On iOS, I've tested and confirmed that even a 300+ MB long URL is accepted. You can try such a long URL like this in Objective-C:And catch if it succeed with:",
                "There is really no universal maximum URL length. The max length is determined only by what the client browser chooses to support, which varies widely. The 2,083 limit is only present in Internet Explorer (all versions up to 7.0). The max length in Firefox and Safari seems to be unlimited, although instability occurs with URLs reaching around 65,000 characters.\nOpera seems to have no max URL length whatsoever, and doesn't suffer instability at extremely long lengths.",
                "The URI RFC (of which URLs are a subset) doesn't define a maximum length, however, it does recommend that the hostname part of the URI (if applicable) not exceed 255 characters in length:URI producers should use names that\nconform to the DNS syntax, even when\nuse of DNS is not immediately\napparent, and should limit these names\nto no more than 255 characters in\nlength.As noted in other posts though, some browsers have a practical limitation on the length of a URL.",
                "The HTTP 1.1 specification says:URIs in HTTP can be represented in\n  absolute form or relative to some\n  known base URI [11], depending upon\n  the context of their use. The two\n  forms are differentiated by the fact\n  that absolute URIs always begin\n  with a scheme name followed by a\n  colon. For definitive information on\n  URL syntax and semantics, see \"Uniform\n  Resource Identifiers (URI):    Generic\n  Syntax and Semantics,\" RFC 2396 [42]\n  (which replaces RFCs    1738 [4] and\n  RFC 1808 [11]). This specification\n  adopts the    definitions of\n  \"URI-reference\", \"absoluteURI\",\n  \"relativeURI\", \"port\",\n  \"host\",\"abs_path\", \"rel_path\", and\n  \"authority\" from that\n  specification.The HTTP protocol does not place\n  any a priori limit on the length of\n  a URI. Servers MUST be able to handle\n  the URI of any resource they    serve,\n  and SHOULD be able to handle URIs of\n  unbounded length if they    provide\n  GET-based forms that could generate\n  such URIs.* A server    SHOULD return\n  414 (Request-URI Too Long) status if a\n  URI is longer    than the server can\n  handle (see section 10.4.15).Note: Servers ought to be cautious about depending on URI\n  lengths\n        above 255 bytes, because some older client or proxy\n        implementations might not properly support these lengths.As mentioned by @Brian, the HTTP clients (e.g. browsers) may have their own limits, and HTTP servers will have different limits.",
                "Microsoft Support says \"Maximum URL length is 2,083 characters in Internet Explorer\".IE has problems with URLs longer than that. Firefox seems to work fine with >4k chars.",
                "In URL as UI Jakob Nielsen recommends:the social interface to the Web relies on email when users want to recommend Web pages to each other, and email is the second-most common way users get to new sites (search engines being the most common): make sure that all URLs on your site are less than 78 characters long so that they will not wrap across a line feed.This is not the maximum but I'd consider this a practical maximum if you want your URL to be shared.",
                "Sitemaps protocol, which is a way for webmasters to inform search engines about pages on their sites (also used by Google in Webmaster Tools), supports URLs with less than 2048 characters. So if you are planning to use this feature for Search Engine Optimization, take this into account.",
                "ASP.NET 2 and SQL Server reporting services 2005 have a limit of 2028. I found this out the hard way, where my dynamic URL generator would not pass over some parameters to a report beyond that point. This was under Internet\u00a0Explorer\u00a08.",
                "Why is the Internet\u00a0Explorer limit only 2K while IIS has a limit of 16K? I don't think it makes sense.So I want to start an experiment about Ajax request URL size limits.I have set my Tomcat HTTP connector's maxHttpHeaderSize=\"1048576\". And prepared a very long URL.Then I send a request with the long URL like the following:jQuery reports done. Tomcat reports the URL requested is 1048015 bytes. It was tested with Chrome 50 and Internet\u00a0Explorer\u00a011.So web browsers won't truncate or limit your URL intentionally when sending Ajax requests.",
                "Limit request line directive sets the maximum length of a URL. By default, it is set to 8190, which gives you a lot of room. However other servers and some browses, limit the length more.Because all parameters are passed on the URL line, items that were in password of hidden fields will also be displayed in the URL of course. Neither mobile should be used for real security measures and should be considered cosmetic security at best.",
                "It seems that Chrome at least has raised this limit. I pasted 20,000 characters into the bookmarklet and it took it.",
                "I have experience with SharePoint 2007, 2010 and there is a limit of the length URL you can create from the server side in this case SharePoint, so it depends mostly on, 1) the client (browser, version, and OS) and 2) the server technology, IIS, Apache, etc.",
                "According to the HTTP spec, there is no limit to a URL's length. Keep your URLs under 2048 characters; this will ensure the URLs work in all clients & server configurations. Also, search engines like URLs to remain under approximately 2000 characters."
            ]
        },
        {
            "tag": "",
            "question": [
                "Loop over an array in JavaScript",
                "How can I loop through all the entries in an array using JavaScript?"
            ],
            "url": "https://stackoverflow.com/questions/9329446",
            "answer": [
                "TL;DRYour best bets are usuallySome quick \"don't\"s:But there's lots more to explore, read on...JavaScript has powerful semantics for looping through arrays and array-like objects. I've split the answer into two parts: Options for genuine arrays, and options for things that are just array-like, such as the arguments object, other iterable objects (ES2015+), DOM collections, and so on.Okay, let's look at our options:You have five options (two supported basically forever, another added by ECMAScript\u00a05 [\"ES5\"], and two more added in ECMAScript\u00a02015 (\"ES2015\", aka \"ES6\"):(You can see those old specs here: ES5, ES2015, but both have been superceded; the current editor's draft is always here.)Details:ES2015 added iterators and iterables to JavaScript. Arrays are iterable (so are strings, Maps, and Sets, as well as DOM collections and lists, as you'll see later). Iterable objects provide iterators for their values. The new for-of statement loops through the values returned by an iterator:const a = [\"a\", \"b\", \"c\"];\nfor (const element of a) { // You can use `let` instead of `const` if you like\n    console.log(element);\n}\n// a\n// b\n// cIt doesn't get simpler than that! Under the covers, that gets an iterator from the array and loops through the values the iterator returns. The iterator provided by arrays provides the values of the array elements, in order beginning to end.Notice how element is scoped to each loop iteration; trying to use element after the end of the loop would fail because it doesn't exist outside the loop body.In theory, a for-of loop involves several function calls (one to get the iterator, then one to get each value from it). Even when that's true, it's nothing to worry about, function calls are very cheap in modern JavaScript engines (it bothered me for forEach [below] until I looked into it; details). But additionally, JavaScript engines optimize those calls away (in performance-critical code) when dealing with native iterators for things like arrays.for-of is entirely async-friendly. If you need the work in a loop body to be done in series (not in parallel), an await in the loop body will wait for the promise to settle before continuing. Here's a silly example:function delay(ms) {\n    return new Promise(resolve => {\n        setTimeout(resolve, ms);\n    });\n}\n\nasync function showSlowly(messages) {\n    for (const message of messages) {\n        await delay(400);\n        console.log(message);\n    }\n}\n\nshowSlowly([\n    \"So\", \"long\", \"and\", \"thanks\", \"for\", \"all\", \"the\", \"fish!\"\n]);\n// `.catch` omitted because we know it never rejectsNote how the words appear with a delay before each one.It's a matter of coding style, but for-of is the first thing I reach for when looping through anything iterable.In any even vaguely-modern environment (so, not IE8) where you have access to the Array features added by ES5, you can use forEach (spec | MDN) if you're only dealing with synchronous code (or you don't need to wait for an asynchronous process to finish during the loop):const a = [\"a\", \"b\", \"c\"];\na.forEach((element) => {\n    console.log(element);\n});forEach accepts a callback function and, optionally, a value to use as this when calling that callback (not used above). The callback is called for each element in the array, in order, skipping non-existent elements in sparse arrays. Although I only used one parameter above, the callback is called with three arguments: The element for that iteration, the index of that element, and a reference to the array you're iterating over (in case your function doesn't already have it handy).Like for-of, forEach has the advantage that you don't have to declare indexing and value variables in the containing scope; in this case, they're supplied as arguments to the iteration function, and so nicely scoped to just that iteration.Unlike for-of, forEach has the disadvantage that it doesn't understand async functions and await. If you use an async function as the callback, forEach does not wait for that function's promise to settle before continuing. Here's the async example from for-of using forEach instead\u00a0\u2014 notice how there's an initial delay, but then all the text appears right away instead of waiting:function delay(ms) {\n    return new Promise(resolve => {\n        setTimeout(resolve, ms);\n    });\n}\n\nasync function showSlowly(messages) {\n    // INCORRECT, doesn't wait before continuing,\n    // doesn't handle promise rejections\n    messages.forEach(async message => {\n        await delay(400);\n        console.log(message);\n    });\n}\n\nshowSlowly([\n    \"So\", \"long\", \"and\", \"thanks\", \"for\", \"all\", \"the\", \"fish!\"\n]);\n// `.catch` omitted because we know it never rejectsforEach is the \"loop through them all\" function, but ES5 defined several other useful \"work your way through the array and do things\" functions, including:As with forEach, if you use an async function as your callback, none of those waits for the function's promise to settle. That means:Sometimes the old ways are the best:const a = [\"a\", \"b\", \"c\"];\nfor (let index = 0; index < a.length; ++index) {\n    const element = a[index];\n    console.log(element);\n}If the length of the array won't change during the loop, and it's in highly performance-sensitive code, a slightly more complicated version grabbing the length up front might be a tiny bit faster:const a = [\"a\", \"b\", \"c\"];\nfor (let index = 0, len = a.length; index < len; ++index) {\n    const element = a[index];\n    console.log(element);\n}And/or counting backward:const a = [\"a\", \"b\", \"c\"];\nfor (let index = a.length - 1; index >= 0; --index) {\n    const element = a[index];\n    console.log(element);\n}But with modern JavaScript engines, it's rare you need to eke out that last bit of juice.Before ES2015, the loop variable had to exist in the containing scope, because var only has function-level scope, not block-level scope. But as you saw in the examples above, you can use let within the for to scope the variables to just the loop. And when you do that, the index variable is recreated for each loop iteration, meaning closures created in the loop body keep a reference to the index for that specific iteration, which solves the old \"closures in loops\" problem:// (The `NodeList` from `querySelectorAll` is array-like)\nconst divs = document.querySelectorAll(\"div\");\nfor (let index = 0; index < divs.length; ++index) {\n    divs[index].addEventListener('click', e => {\n        console.log(\"Index is: \" + index);\n    });\n}\n<div>zero</div>\n<div>one</div>\n<div>two</div>\n<div>three</div>\n<div>four</div>In the above, you get \"Index is: 0\" if you click the first and \"Index is: 4\" if you click the last. This does not work if you use var instead of let (you'd always see \"Index is: 5\").Like for-of, for loops work well in async functions. Here's the earlier example using a for loop:function delay(ms) {\n    return new Promise(resolve => {\n        setTimeout(resolve, ms);\n    });\n}\n\nasync function showSlowly(messages) {\n    for (let i = 0; i < messages.length; ++i) {\n        const message = messages[i];\n        await delay(400);\n        console.log(message);\n    }\n}\n\nshowSlowly([\n    \"So\", \"long\", \"and\", \"thanks\", \"for\", \"all\", \"the\", \"fish!\"\n]);\n// `.catch` omitted because we know it never rejectsfor-in isn't for looping through arrays, it's for looping through the names of an object's properties. It does often seem to work for looping through arrays as a by-product of the fact that arrays are objects, but it doesn't just loop through the array indexes, it loops through all enumerable properties of the object (including inherited ones). (It also used to be that the order wasn't specified; it is now [details in this other answer], but even though the order is specified now, the rules are complex, there are exceptions, and relying on the order is not best practice.)The only real use cases for for-in on an array are:Looking only at that first example: You can use for-in to visit those sparse array elements if you use appropriate safeguards:// `a` is a sparse array\nconst a = [];\na[0] = \"a\";\na[10] = \"b\";\na[10000] = \"c\";\nfor (const name in a) {\n    if (Object.hasOwn(a, name) &&       // These checks are\n        /^0$|^[1-9]\\d*$/.test(name) &&  // explained\n        name <= 4294967294              // below\n       ) {\n        const element = a[name];\n        console.log(a[name]);\n    }\n}Note the three checks:That the object has its own property by that name (not one it inherits from its prototype; this check is also often written as a.hasOwnProperty(name) but ES2022 adds Object.hasOwn which can be more reliable), andThat the name is all decimal digits (e.g., normal string form, not scientific notation), andThat the name's value when coerced to a number is <= 2^32 - 2 (which is 4,294,967,294). Where does that number come from? It's part of the definition of an array index in the specification. Other numbers (non-integers, negative numbers, numbers greater than 2^32 - 2) are not array indexes. The reason it's 2^32 - 2 is that that makes the greatest index value one lower than 2^32 - 1, which is the maximum value an array's length can have. (E.g., an array's length fits in a 32-bit unsigned integer.)...although with that said, most code only does the hasOwnProperty check.You wouldn't do that in inline code, of course. You'd write a utility function. Perhaps:// Utility function for antiquated environments without `forEach`\nconst hasOwn = Object.prototype.hasOwnProperty.call.bind(Object.prototype.hasOwnProperty);\nconst rexNum = /^0$|^[1-9]\\d*$/;\nfunction sparseEach(array, callback, thisArg) {\n    for (const name in array) {\n        const index = +name;\n        if (hasOwn(a, name) &&\n            rexNum.test(name) &&\n            index <= 4294967294\n           ) {\n            callback.call(thisArg, array[name], index, array);\n        }\n    }\n}\n\nconst a = [];\na[5] = \"five\";\na[10] = \"ten\";\na[100000] = \"one hundred thousand\";\na.b = \"bee\";\n\nsparseEach(a, (value, index) => {\n    console.log(\"Value at \" + index + \" is \" + value);\n});Like for, for-in works well in asynchronous functions if the work within it needs to be done in series.function delay(ms) {\n    return new Promise(resolve => {\n        setTimeout(resolve, ms);\n    });\n}\n\nasync function showSlowly(messages) {\n    for (const name in messages) {\n        if (messages.hasOwnProperty(name)) { // Almost always this is the only check people do\n            const message = messages[name];\n            await delay(400);\n            console.log(message);\n        }\n    }\n}\n\nshowSlowly([\n    \"So\", \"long\", \"and\", \"thanks\", \"for\", \"all\", \"the\", \"fish!\"\n]);\n// `.catch` omitted because we know it never rejectsfor-of uses an iterator implicitly, doing all the scut work for you. Sometimes, you might want to use an iterator explicitly. It looks like this:const a = [\"a\", \"b\", \"c\"];\nconst it = a.values(); // Or `const it = a[Symbol.iterator]();` if you like\nlet entry;\nwhile (!(entry = it.next()).done) {\n    const element = entry.value;\n    console.log(element);\n}An iterator is an object matching the Iterator definition in the specification. Its next method returns a new result object each time you call it. The result object has a property, done, telling us whether it's done, and a property value with the value for that iteration. (done is optional if it would be false, value is optional if it would be undefined.)What you get for value varies depending on the iterator. On arrays, the default iterator provides the value of each array element (\"a\", \"b\", and \"c\" in the example earlier). Arrays also have three other methods that return iterators:Since iterator objects don't advance until you call next, they work well in async function loops. Here's the earlier for-of example using the iterator explicitly:function delay(ms) {\n    return new Promise(resolve => {\n        setTimeout(resolve, ms);\n    });\n}\n\nasync function showSlowly(messages) {\n    const it = messages.values()\n    while (!(entry = it.next()).done) {\n        await delay(400);\n        const element = entry.value;\n        console.log(element);\n    }\n}\n\nshowSlowly([\n    \"So\", \"long\", \"and\", \"thanks\", \"for\", \"all\", \"the\", \"fish!\"\n]);\n// `.catch` omitted because we know it never rejectsAside from true arrays, there are also array-like objects that have a length property and properties with all-digits names: NodeList instances, HTMLCollection instances, the arguments object, etc. How do we loop through their contents?At least some, and possibly most or even all, of the array approaches above apply equally well to array-like objects:Use for-of (use an iterator implicitly) (ES2015+)for-of uses the iterator provided by the object (if any). That includes host-provided objects (like DOM collections and lists). For instance, HTMLCollection instances from getElementsByXYZ methods and NodeLists instances from querySelectorAll both support iteration. (This is defined quite subtly by the HTML and DOM specifications. Basically, any object with length and indexed access is automatically iterable. It doesn't have to be marked iterable; that is used only for collections that, in addition to being iterable, support forEach, values, keys, and entries methods. NodeList does; HTMLCollection doesn't, but both are iterable.)Here's an example of looping through div elements:const divs = document.querySelectorAll(\"div\");\nfor (const div of divs) {\n    div.textContent = Math.random();\n}\n<div>zero</div>\n<div>one</div>\n<div>two</div>\n<div>three</div>\n<div>four</div>Use forEach and related (ES5+)The various functions on Array.prototype are \"intentionally generic\" and can be used on array-like objects via Function#call (spec | MDN) or Function#apply (spec | MDN). (If you have to deal with IE8 or earlier [ouch], see the \"Caveat for host-provided objects\" at the end of this answer, but it's not an issue with vaguely-modern browsers.)Suppose you wanted to use forEach on a Node's childNodes collection (which, being an HTMLCollection, doesn't have forEach natively). You'd do this:(Note, though, that you could just use for-of on node.childNodes.)If you're going to do that a lot, you might want to grab a copy of the function reference into a variable for reuse, e.g.:Use a simple for loopPerhaps obviously, a simple for loop works for array-like objects.Use an iterator explicitly (ES2015+)See #1.You may be able to get away with for-in (with safeguards), but with all of these more appropriate options, there's no reason to try.Other times, you may want to convert an array-like object into a true array. Doing that is surprisingly easy:Use Array.fromArray.from (spec) | (MDN) (ES2015+, but easily polyfilled) creates an array from an array-like object, optionally passing the entries through a mapping function first. So:...takes the NodeList from querySelectorAll and makes an array from it.The mapping function is handy if you were going to map the contents in some way. For instance, if you wanted to get an array of the tag names of the elements with a given class:Use spread syntax (...)It's also possible to use ES2015's spread syntax. Like for-of, this uses the iterator provided by the object (see #1 in the previous section):So for instance, if we want to convert a NodeList into a true array, with spread syntax this becomes quite succinct:Use the slice method of arraysWe can use the slice method of arrays, which like the other methods mentioned above is \"intentionally generic\" and so can be used with array-like objects, like this:So for instance, if we want to convert a NodeList into a true array, we could do this:(If you still have to handle IE8 [ouch], will fail; IE8 didn't let you use host-provided objects as this like that.)If you use Array.prototype functions with host-provided array-like objects (for example, DOM collections and such provided by the browser rather than the JavaScript engine), obsolete browsers like IE8 didn't necessarily handle that way, so if you have to support them, be sure to test in your target environments. But it's not an issue with vaguely-modern browsers. (For non-browser environments, naturally it'll depend on the environment.)",
                "Note: This answer is hopelessly out-of-date. For a more modern approach, look at the methods available on an array. Methods of interest might be:The standard way to iterate an array in JavaScript is a vanilla for-loop:Note, however, that this approach is only good if you have a dense array, and each index is occupied by an element. If the array is sparse, then you can run into performance problems with this approach, since you will iterate over a lot of indices that do not really exist in the array. In this case, a for .. in-loop might be a better idea. However, you must use the appropriate safeguards to ensure that only the desired properties of the array (that is, the array elements) are acted upon, since the for..in-loop will also be enumerated in legacy browsers, or if the additional properties are defined as enumerable.In ECMAScript 5 there will be a forEach method on the array prototype, but it is not supported in legacy browsers. So to be able to use it consistently you must either have an environment that supports it (for example, Node.js for server side JavaScript), or use a \"Polyfill\". The Polyfill for this functionality is, however, trivial and since it makes the code easier to read, it is a good polyfill to include.",
                "If you\u2019re using the jQuery library, you can use jQuery.each:EDIT :As per question, user want code in javascript instead of jquery so the edit is",
                "I think the reverse for loop deserves a mention here:Some developers use the reverse for loop by default, unless there is a good reason to loop forwards.Although the performance gains are usually insignificant, it sort of screams:\"Just do this to every item in the list, I don't care about the order!\"However in practice that is not actually a reliable indication of intent, since it is indistinguishable from those occasions when you do care about the order, and really do need to loop in reverse.  So in fact another construct would be needed to accurately express the \"don't care\" intent, something currently unavailable in most languages, including ECMAScript, but which could be called, for example, forEachUnordered().If order doesn't matter, and efficiency is a concern (in the innermost loop of a game or animation engine), then it may be acceptable to use the reverse for loop as your go-to pattern.  Just remember that seeing a reverse for loop in existing code does not necessarily mean that the order irrelevant!In general for higher level code where clarity and safety are greater concerns, I previously recommended using Array::forEach as your default pattern for looping (although these days I prefer to use for..of).  Reasons to prefer forEach over a reverse loop are:Then when you do see the reverse for loop in your code, that is a hint that it is reversed for a good reason (perhaps one of the reasons described above).  And seeing a traditional forward for loop may indicate that shifting can take place.(If the discussion of intent makes no sense to you, then you and your code may benefit from watching Crockford's lecture on Programming Style & Your Brain.)There is a debate about whether for..of or forEach() are preferable:For maximum browser support, for..of requires a polyfill for iterators, making your app slightly slower to execute and slightly larger to download.For that reason (and to encourage use of map and filter), some front-end style guides ban for..of completely!But the above concerns is not applicable to Node.js applications, where for..of is now well supported.And furthermore await does not work inside forEach().  Using for..of is the clearest pattern in this case.Personally, I tend to use whatever looks easiest to read, unless performance or minification has become a major concern.  So these days I prefer to use for..of instead of forEach(), but I will always use map or filter or find or some when applicable. \n (For the sake of my colleagues, I rarely use reduce.)You will notice that i-- is the middle clause (where we usually see a comparison) and the last clause is empty (where we usually see i++).  That means that i-- is also used as the condition for continuation.  Crucially, it is executed and checked before each iteration.How can it start at array.length without exploding?Because i-- runs before each iteration, on the first iteration we will actually be accessing the item at array.length - 1 which avoids any issues with Array-out-of-bounds undefined items.Why doesn't it stop iterating before index 0?The loop will stop iterating when the condition i-- evaluates to a falsey value (when it yields 0).The trick is that unlike --i, the trailing i-- operator decrements i but yields the value before the decrement.  Your console can demonstrate this:> var i = 5; [i, i--, i];[5, 5, 4]So on the final iteration, i was previously 1 and the i-- expression changes it to 0 but actually yields 1 (truthy), and so the condition passes.  On the next iteration i-- changes i to -1 but yields 0 (falsey), causing execution to immediately drop out of the bottom of the loop.In the traditional forwards for loop, i++ and ++i are interchangeable (as Douglas Crockford points out).  However in the reverse for loop, because our decrement is also our condition expression, we must stick with i-- if we want to process the item at index 0.Some people like to draw a little arrow in the reverse for loop, and end with a wink:Credits go to WYL for showing me the benefits and horrors of the reverse for loop.",
                "Some C-style languages use foreach to loop through enumerations. In JavaScript this is done with the for..in loop structure:There is a catch. for..in will loop through each of the object's enumerable members, and the members on its prototype. To avoid reading values that are inherited through the object's prototype, simply check if the property belongs to the object:Additionally, ECMAScript 5 has added a forEach method to Array.prototype which can be used to enumerate over an array using a calback (the polyfill is in the docs so you can still use it for older browsers):It's important to note that Array.prototype.forEach doesn't break when the callback returns false. jQuery and Underscore.js provide their own variations on each to provide loops that can be short-circuited.",
                "\ud83d\udc49\ud83c\udffd \u00a0 for...of\ud83d\udc49\ud83c\udffd \u00a0 forEach\ud83d\udc49\ud83c\udffd \u00a0 map*Different from the two above, map() creates a new array and expects you to return something after each iteration.\ud83d\uded1\u00a0 Important: As map() is meant to return a value at each iteration, it is an ideal method for transforming elements in arrays:On the other hand, for...of and forEach( ) don't need to return anything and that's why we typically use them to perform logic tasks that manipulate stuff outside.So to speak, you're going to find if () statements, side effects, and logging activities in these two.\ud83d\udc4c\ud83c\udffe\u00a0 TIP: you can also have the index (as well as the whole array) in each iteration in your .map() or .forEach() functions.Just pass additional arguments to them:",
                "If you want to loop over an array, use the standard three-part for loop.You can get some performance optimisations by caching myArray.length or iterating over it backwards.",
                "If you don't mind emptying the array:x will contain the last value of y and it will be removed from the array. You can also use shift() which will give and remove the first item from y.",
                "A forEach implementation (see in jsFiddle):",
                "I know this is an old post, and there are so many great answers already. For a little more completeness I figured I'd throw in another one using AngularJS. Of course, this only applies if you're using Angular, obviously, nonetheless I'd like to put it anyway.angular.forEach takes 2 arguments and an optional third argument. The first argument is the object (array) to iterate over, the second argument is the iterator function, and the optional third argument is the object context (basically referred to inside the loop as 'this'.There are different ways to use the forEach loop of angular. The simplest and probably most used isAnother way that is useful for copying items from one array to another isThough, you don't have to do that, you can simply do the following and it's equivalent to the previous example:Now there are pros and cons of using the angular.forEach function as opposed to the built in vanilla-flavored for loop.ProsConsider the following 2 nested loops, which do exactly the same thing. Let's say that we have 2 arrays of objects and each object contains an array of results, each of which has a Value property that's a string (or whatever). And let's say we need to iterate over each of the results and if they're equal then perform some action:Granted this is a very simple hypothetical example, but I've written triple embedded for loops using the second approach and it was very hard to read, and write for that matter.ConsI'm sure there's various other pros and cons as well, and please feel free to add any that you see fit. I feel that, bottom line, if you need efficiency, stick with just the native for loop for your looping needs. But, if your datasets are smaller and a some efficiency is okay to give up in exchange for readability and writability, then by all means throw an angular.forEach in that bad boy.",
                "As of ECMAScript\u00a06:list = [0, 1, 2, 3]\r\nfor (let obj of list) {\r\n    console.log(obj)\r\n}Where of avoids the oddities associated with in and makes it work like the for loop of any other language, and let binds i within the loop as opposed to within the function.The braces ({}) can be omitted when there is only one command (e.g. in the example above).",
                "Probably the for(i = 0; i < array.length; i++) loop is not the best choice. Why? If you have this:The method will call from array[0] to array[2]. First, this will first reference variables you don't even have, second you would not have the variables in the array, and third this will make the code bolder. Look here, it's what I use:And if you want it to be a function, you can do this:If you want to break, a little more logic:Example:It returns:",
                "There are three implementations of foreach in jQuery as follows.",
                "An easy solution now would be to use the underscore.js library. It's providing many useful tools, such as each and will automatically delegate the job to the native forEach if available.A CodePen example of how it works is:",
                "There isn't any for each loop in native JavaScript. You can either use libraries to get this functionality (I recommend Underscore.js), use a simple for in loop.However, note that there may be reasons to use an even simpler for loop (see Stack Overflow question Why is using \u201cfor\u2026in\u201d with array iteration such a bad idea?)",
                "ECMAScript\u00a05 (the version on JavaScript) to work with Arrays:forEach - Iterates through every item in the array and do whatever you need with each item.In case, more interested on operation on array using some inbuilt feature.map - It creates a new array with the result of the callback function. This method is good to be used when you need to format the elements of your array.reduce - As the name says, it reduces the array to a single value by calling the given function passing in the current element and the result of the previous execution.every - Returns true or false if all the elements in the array pass the test in the callback function.filter - Very similar to every except that filter returns an array with the elements that return true to the given function.",
                "There are a few ways to loop through an array in JavaScript, as below:for - it's the most common one. Full block of code for loopingvar languages = [\"Java\", \"JavaScript\", \"C#\", \"Python\"];\r\nvar i, len, text;\r\nfor (i = 0, len = languages.length, text = \"\"; i < len; i++) {\r\n    text += languages[i] + \"<br>\";\r\n}\r\ndocument.getElementById(\"example\").innerHTML = text;\n<p id=\"example\"></p>while - loop while a condition is through. It seems to be the fastest loopvar text = \"\";\r\nvar i = 0;\r\nwhile (i < 10) {\r\n    text +=  i + \") something<br>\";\r\n    i++;\r\n}\r\ndocument.getElementById(\"example\").innerHTML = text;\n<p id=\"example\"></p>do/while - also loop through a block of code while the condition is true, will run at least one timevar text = \"\"\r\nvar i = 0;\r\n\r\ndo {\r\n    text += i + \") something <br>\";\r\n    i++;\r\n}\r\nwhile (i < 10);\r\n\r\ndocument.getElementById(\"example\").innerHTML = text;\n<p id=\"example\"></p>Functional loops - forEach, map, filter, also reduce (they loop through the function, but they are used if you need to do something with your array, etc.// For example, in this case we loop through the number and double them up using the map function\r\nvar numbers = [65, 44, 12, 4];\r\ndocument.getElementById(\"example\").innerHTML = numbers.map(function(num){return num * 2});\n<p id=\"example\"></p>For more information and examples about functional programming on arrays, look at the blog post Functional programming in JavaScript: map, filter and reduce.",
                "This is an iterator for NON-sparse list where the index starts at 0, which is the typical scenario when dealing with document.getElementsByTagName or document.querySelectorAll)Examples of usage:Example #1Example #2Each p tag gets class=\"blue\"Example #3Every other p tag gets class=\"red\">Example #4And finally the first 20 blue p tags are changed to greenCaution when using string as function: the function is created out-of-context and ought to be used only where you are certain of variable scoping.  Otherwise, better to pass functions where scoping is more intuitive.",
                "There's no inbuilt ability to break in forEach. To interrupt execution use the Array#some like below:This works because some returns true as soon as any of the callbacks, executed in array order, returns true, short-circuiting the execution of the rest. \nOriginal Answer\nsee Array prototype for some",
                "I also would like to add this as a composition of a reverse loop and an answer above for someone that would like this syntax too.Pros:The benefit for this: You have the reference already in the first like that won't need to be declared later with another line. It is handy when looping trough the object array.Cons:This will break whenever the reference is false - falsey (undefined, etc.). It can be used as an advantage though. However, it would make it a little bit harder to read. And also depending on the browser it can be \"not\" optimized to work faster than the original one.",
                "jQuery way using $.map:",
                "Using loops with ECMAScript\u00a06  destructuring and the spread operatorDestructuring and using of the spread operator have proven quite useful for newcomers to ECMAScript\u00a06 as being more human-readable/aesthetic, although some JavaScript veterans might consider it messy. Juniors or some other people might find it useful.The following examples will use the for...of statement and the .forEach method.Examples 6, 7, and 8 can be used with any functional loops like .map, .filter, .reduce, .sort, .every, .some. For more information about these methods, check out the Array Object.Example 1: Normal for...of loop - no tricks here.let arrSimple = ['a', 'b', 'c'];\n\nfor (let letter of arrSimple) {\n  console.log(letter);\n}Example 2: Split words to characterslet arrFruits = ['apple', 'orange', 'banana'];\n\nfor (let [firstLetter, ...restOfTheWord] of arrFruits) {\n  // Create a shallow copy using the spread operator\n  let [lastLetter] = [...restOfTheWord].reverse();\n  console.log(firstLetter, lastLetter, restOfTheWord);\n}Example 3: Looping with a key and value// let arrSimple = ['a', 'b', 'c'];\n\n// Instead of keeping an index in `i` as per example `for(let i = 0 ; i<arrSimple.length;i++)`\n// this example will use a multi-dimensional array of the following format type:\n// `arrWithIndex: [number, string][]`\n\nlet arrWithIndex = [\n  [0, 'a'],\n  [1, 'b'],\n  [2, 'c'],\n];\n\n// Same thing can be achieved using `.map` method\n// let arrWithIndex = arrSimple.map((i, idx) => [idx, i]);\n\n// Same thing can be achieved using `Object.entries`\n// NOTE: `Object.entries` method doesn't work on Internet Explorer  unless it's polyfilled\n// let arrWithIndex = Object.entries(arrSimple);\n\nfor (let [key, value] of arrWithIndex) {\n  console.log(key, value);\n}Example 4: Get object properties inlinelet arrWithObjects = [{\n    name: 'Jon',\n    age: 32\n  },\n  {\n    name: 'Elise',\n    age: 33\n  }\n];\n\nfor (let { name, age: aliasForAge } of arrWithObjects) {\n  console.log(name, aliasForAge);\n}Example 5: Get deep object properties of what you needlet arrWithObjectsWithArr = [{\n    name: 'Jon',\n    age: 32,\n    tags: ['driver', 'chef', 'jogger']\n  },\n  {\n    name: 'Elise',\n    age: 33,\n    tags: ['best chef', 'singer', 'dancer']\n  }\n];\n\nfor (let { name, tags: [firstItemFromTags, ...restOfTags] } of arrWithObjectsWithArr) {\n  console.log(name, firstItemFromTags, restOfTags);\n}Example 6: Is Example 3 used with .forEachlet arrWithIndex = [\n  [0, 'a'],\n  [1, 'b'],\n  [2, 'c'],\n];\n\n// Not to be confused here, `forEachIndex` is the real index\n// `mappedIndex` was created by \"another user\", so you can't really trust it\n\narrWithIndex.forEach(([mappedIndex, item], forEachIndex) => {\n  console.log(forEachIndex, mappedIndex, item);\n});Example 7: Is Example 4 used with .forEachlet arrWithObjects = [{\n    name: 'Jon',\n    age: 32\n  },\n  {\n    name: 'Elise',\n    age: 33\n  }\n];\n// NOTE: Destructuring objects while using shorthand functions\n// are required to be surrounded by parentheses\narrWithObjects.forEach( ({ name, age: aliasForAge }) => {\n  console.log(name, aliasForAge)\n});Example 8: Is Example 5 used with .forEachlet arrWithObjectsWithArr = [{\n    name: 'Jon',\n    age: 32,\n    tags: ['driver', 'chef', 'jogger']\n  },\n  {\n    name: 'Elise',\n    age: 33,\n    tags: ['best chef', 'singer', 'dancer']\n  }\n];\n\narrWithObjectsWithArr.forEach(({\n  name,\n  tags: [firstItemFromTags, ...restOfTags]\n}) => {\n  console.log(name, firstItemFromTags, restOfTags);\n});",
                "When iterating over an array, we often want to accomplish one of the following goals:We want to iterate over the array and create a new array:Array.prototype.mapWe want to iterate over the array and don't create a new array:Array.prototype.forEach \nfor..of loopIn JavaScript, there are many ways of accomplishing both of these goals. However, some are more convenient than others. Below you can find some commonly used methods (the most convenient IMO) to accomplish array iteration in JavaScript.map() is a function located on Array.prototype which can transform every element of an array and then returns a new array. map() takes as an argument a callback function and works in the following manner:let arr = [1, 2, 3, 4, 5];\r\n\r\nlet newArr = arr.map((element, index, array) => {\r\n  return element * 2;\r\n})\r\n\r\nconsole.log(arr);\r\nconsole.log(newArr);The callback which we have passed into map() as an argument gets executed for every element. Then an array gets returned which has the same length as the original array. In this new array element is transformed by the callback function passed in as an argument to map().The distinct difference between map and another loop mechanism like forEach and a for..of loop is that map returns a new array and leaves the old array intact (except if you explicitly manipulate it with thinks like splice).Also, note that the map function's callback provides the index number of the current iteration as a second argument. Furthermore, does the third argument provide the array on which map was called? Sometimes these properties can be very useful.forEach is a function which is located on Array.prototype which takes a callback function as an argument. It then executes this callback function for every element in the array. In contrast to the map() function, the forEach function returns nothing (undefined). For example:let arr = [1, 2, 3, 4, 5];\r\n\r\narr.forEach((element, index, array) => {\r\n\r\n  console.log(element * 2);\r\n\r\n  if (index === 4) {\r\n    console.log(array)\r\n  }\r\n  // index, and oldArray are provided as 2nd and 3th argument by the callback\r\n\r\n})\r\n\r\nconsole.log(arr);Just like the map function, the forEach callback provides the index number of the current iteration as a second argument. Also, does the third argument provide the array on which forEach was called?The for..of loop loops through every element of an array (or any other iterable object). It works in the following manner:let arr = [1, 2, 3, 4, 5];\r\n\r\nfor(let element of arr) {\r\n  console.log(element * 2);\r\n}In the above example, element stands for an array element and arr is the array which we want to loop. Note that the name element is arbitrary, and we could have picked any other name like 'el' or something more declarative when this is applicable.Don't confuse the for..in loop with the for..of loop. for..in will loop through all enumerable properties of the array whereas the for..of loop will only loop through the array elements. For example:let arr = [1, 2, 3, 4, 5];\r\n\r\narr.foo = 'foo';\r\n\r\nfor(let element of arr) {\r\n  console.log(element);\r\n}\r\n\r\nfor(let element in arr) {\r\n  console.log(element);\r\n}",
                "Today (2019-12-18) I perform test on my macOS v10.13.6 (High Sierra), on Chrome v 79.0, Safari v13.0.4 and Firefox v71.0 (64 bit) - conclusions about optimisation (and micro-optimisation which usually is not worth to introduce it to code because the benefit is small, but code complexity grows).It looks like the traditional for i (Aa) is a good choice to write fast code on all browsers.The other solutions, like for-of (Ad), all in group C.... are usually 2 - 10 (and more) times slower than Aa, but for small arrays it is ok to use it - for the sake of increase code clarity.The loops with array length cached in n (Ab, Bb, Be) are sometimes faster, sometimes not. Probably compilers automatically detect this situation and introduce caching. The speed differences between the cached and no-cached versions (Aa, Ba, Bd) are about ~1%, so it looks like introduce n is a micro-optimisation.The i-- like solutions where the loop starts from the last array element (Ac, Bc) are usually ~30% slower than forward solutions - probably the reason is the way of CPU memory cache working - forward memory reading is more optimal for CPU caching). Is recommended to NOT USE such solutions.In tests we calculate the sum of array elements. I perform a test for small arrays (10 elements) and big arrays (1M elements) and divide them into three groups:let arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\r\n//let arr = Array.from(Array(1000000), (x, i) => i%10);\r\n\r\nfunction Aa(a, s=0) {\r\n  for(let i=0; i<a.length; i++) {\r\n    s += a[i];\r\n  }\r\n  console.log('Aa=', s);\r\n}\r\n\r\nfunction Ab(a, s=0) {\r\n  let n = a.length;\r\n  for(let i=0; i<n; i++) {\r\n    s += a[i];\r\n  }\r\n  console.log('Ab=', s);\r\n}\r\n\r\nfunction Ac(a, s=0) {\r\n  for(let i=a.length; i--;) {\r\n    s += a[i];\r\n  }\r\n  console.log('Ac=', s);\r\n}\r\n\r\nfunction Ad(a, s=0) {\r\n  for(let x of a) {\r\n    s += x;\r\n  }\r\n  console.log('Ad=', s);\r\n}\r\n\r\nfunction Ae(a, s=0) {\r\n  for(let i in a) if (a.hasOwnProperty(i)) {\r\n    s += a[i];\r\n  }\r\n  console.log('Ae=', s);\r\n}\r\n\r\nfunction Ba(a, s=0) {\r\n  let i = -1;\r\n  while(++i < a.length) {\r\n    s+= a[i];\r\n  }\r\n  console.log('Ba=', s);\r\n}\r\n\r\nfunction Bb(a, s=0) {\r\n  let i = -1;\r\n  let n = a.length;\r\n  while(++i < n) {\r\n    s+= a[i];\r\n  }\r\n  console.log('Bb=', s);\r\n}\r\n\r\nfunction Bc(a, s=0) {\r\n  let i = a.length;\r\n  while(i--) {\r\n    s += a[i];\r\n  }\r\n  console.log('Bc=', s);\r\n}\r\n\r\nfunction Bd(a, s=0) {\r\n  let i = 0;\r\n  do {\r\n    s+= a[i]\r\n  } while (++i < a.length);\r\n  console.log('Bd=', s);\r\n}\r\n\r\nfunction Be(a, s=0) {\r\n  let i = 0;\r\n  let n = a.length;\r\n  do {\r\n    s += a[i]\r\n  } while (++i < n);\r\n  console.log('Be=', s);\r\n}\r\n\r\nfunction Bf(a, s=0) {\r\n  const it = a.values(); \r\n  let e;\r\n  while (!(e = it.next()).done) { \r\n    s+= e.value; \r\n  }\r\n  console.log('Bf=', s);\r\n}\r\n\r\nfunction Ca(a, s=0) {\r\n  a.map(x => { s+=x });\r\n  console.log('Ca=', s);\r\n}\r\n\r\nfunction Cb(a, s=0) {\r\n  a.forEach(x => { s+=x });\r\n  console.log('Cb=', s);\r\n}\r\n\r\nfunction Cc(a, s=0) {\r\n  a.every(x => (s += x, 1));\r\n  console.log('Cc=', s);\r\n}\r\n\r\nfunction Cd(a, s=0) {\r\n  a.filter(x => { s+=x });\r\n  console.log('Cd=',s);\r\n}\r\n\r\nfunction Ce(a, s=0) {\r\n  a.reduce((z, c) => { s+=c }, 0);\r\n  console.log('Ce=', s);\r\n}\r\n\r\nfunction Cf(a, s=0) {\r\n  a.reduceRight((z, c) => { s += c }, 0);\r\n  console.log('Cf=', s);\r\n}\r\n\r\nfunction Cg(a, s=0) {\r\n  a.some(x => { s += x } );\r\n  console.log('Cg=', s);\r\n}\r\n\r\nfunction Ch(a, s=0) {\r\n  Array.from(a, x=> s += x);\r\n  console.log('Cc=', s);\r\n}\r\n\r\n\r\nAa(arr);\r\nAb(arr);\r\nAc(arr);\r\nAd(arr);\r\nAe(arr);\r\n\r\nBa(arr);\r\nBb(arr);\r\nBc(arr);\r\nBd(arr);\r\nBe(arr);\r\nBf(arr);\r\n\r\nCa(arr);\r\nCb(arr);\r\nCc(arr);\r\nCd(arr);\r\nCe(arr);\r\nCf(arr);\r\nCg(arr);\r\nCh(arr);\n<p style=\"color: red\">This snippets only PRESENTS code used for benchmark - it not perform test itself</p>Cross browser resultsResults for all tested browsersbrowsers**Array with 10 elementsResults for Chrome. You can perform the test on your machine here.Array with 1,000,000 elementsResults for Chrome. You can perform the test on your machine here",
                "A way closest to your idea would be to use Array.forEach() which accepts a closure function which will be executed for each element of the array.Another viable way would be to use Array.map() which works in the same way, but it also takes all values that you return and returns them in a new array (essentially mapping each element to a new one), like this:",
                "As per the new updated feature ECMAScript 6 (ES6) and ECMAScript 2015, you can use the following options with loops:for loopsfor...in loopsArray.forEach()for...of loopswhile loopsdo...while loops",
                "As one can see in the table above, for...of should be used wherever it fits. Since it supports async functions, skips non-numeric properties and prevents messing up the loop by accidentally modifying the loop index.See for...of reference for more examples, link to specification and difference between for...of and for...in. Or maybe check this tutorial for some explanation on how they differ.",
                "The lambda syntax doesn't usually work in Internet\u00a0Explorer\u00a010  or below.I usually use theIf you are a jQuery fan and already have a jQuery file running, you should reverse the positions of the index and value parameters",
                "You can call forEach like this:forEach will iterate over the array you provide and for each iteration it will have element which holds the value of that iteration. If you need index you can get the current index by passing the i as the second parameter in the callback function for forEach.Foreach is basically a High Order Function, Which takes another function as its parameter.Output:You can also iterate over an array like this:",
                "If you want to use forEach(), it will look like -If you want to use for(), it will look like -"
            ]
        },
        {
            "tag": "",
            "question": [
                "The definitive guide to form-based website authentication [closed]",
                "Moderator note:\nThis question is not a good fit for our question and answer format with the topicality rules which currently apply for Stack Overflow. We normally use a \"historical lock\" for ..."
            ],
            "url": "https://stackoverflow.com/questions/549",
            "answer": [
                "We'll assume you already know how to build a login+password HTML form which POSTs the values to a script on the server side for authentication. The sections below will deal with patterns for sound practical auth, and how to avoid the most common security pitfalls.To HTTPS or not to HTTPS?Unless the connection is already secure (that is, tunneled through HTTPS using SSL/TLS), your login form values will be sent in cleartext, which allows anyone eavesdropping on the line between browser and web server will be able to read logins as they pass through. This type of wiretapping is done routinely by governments, but in general, we won't address 'owned' wires other than to say this: Just use HTTPS.In essence, the only practical way to protect against wiretapping/packet sniffing during login is by using HTTPS or another certificate-based encryption scheme (for example, TLS) or a proven & tested challenge-response scheme (for example, the Diffie-Hellman-based SRP). Any other method can be easily circumvented by an eavesdropping attacker.Of course, if you are willing to get a little bit impractical, you could also employ some form of two-factor authentication scheme (e.g. the Google Authenticator app, a physical 'cold war style' codebook, or an RSA key generator dongle). If applied correctly, this could work even with an unsecured connection, but it's hard to imagine that a dev would be willing to implement two-factor auth but not SSL.(Do not) Roll-your-own JavaScript encryption/hashingGiven the perceived (though now avoidable) cost and technical difficulty of setting up an SSL certificate on your website, some developers are tempted to roll their own in-browser hashing or encryption schemes in order to avoid passing cleartext logins over an unsecured wire.While this is a noble thought, it is essentially useless (and can be a security flaw) unless it is combined with one of the above - that is, either securing the line with strong encryption or using a tried-and-tested challenge-response mechanism (if you don't know what that is, just know that it is one of the most difficult to prove, most difficult to design, and most difficult to implement concepts in digital security).While it is true that hashing the password can be effective against password disclosure, it is vulnerable to replay attacks, Man-In-The-Middle attacks / hijackings (if an attacker can inject a few bytes into your unsecured HTML page before it reaches your browser, they can simply comment out the hashing in the JavaScript), or brute-force attacks (since you are handing the attacker both username, salt and hashed password).CAPTCHAS against humanityCAPTCHA is meant to thwart one specific category of attack: automated dictionary/brute force trial-and-error with no human operator. There is no doubt that this is a real threat, however, there are ways of dealing with it seamlessly that don't require a CAPTCHA, specifically properly designed server-side login throttling schemes - we'll discuss those later.Know that CAPTCHA implementations are not created alike; they often aren't human-solvable, most of them are actually ineffective against bots, all of them are ineffective against cheap third-world labor (according to OWASP, the current sweatshop rate is $12 per 500 tests), and some implementations may be technically illegal in some countries (see OWASP Authentication Cheat Sheet). If you must use a CAPTCHA, use Google's reCAPTCHA, since it is OCR-hard by definition (since it uses already OCR-misclassified book scans) and tries very hard to be user-friendly.Personally, I tend to find CAPTCHAS annoying, and use them only as a last resort when a user has failed to log in a number of times and throttling delays are maxed out. This will happen rarely enough to be acceptable, and it strengthens the system as a whole.Storing Passwords / Verifying loginsThis may finally be common knowledge after all the highly-publicized hacks and user data leaks we've seen in recent years, but it has to be said: Do not store passwords in cleartext in your database. User databases are routinely hacked, leaked or gleaned through SQL injection, and if you are storing raw, plaintext passwords, that is instant game over for your login security.So if you can't store the password, how do you check that the login+password combination POSTed from the login form is correct? The answer is hashing using a key derivation function. Whenever a new user is created or a password is changed, you take the password and run it through a KDF, such as Argon2, bcrypt, scrypt or PBKDF2, turning the cleartext password (\"correcthorsebatterystaple\") into a long, random-looking string, which is a lot safer to store in your database. To verify a login, you run the same hash function on the entered password, this time passing in the salt and compare the resulting hash string to the value stored in your database. Argon2, bcrypt and scrypt store the salt with the hash already. Check out this article on sec.stackexchange for more detailed information.The reason a salt is used is that hashing in itself is not sufficient -- you'll want to add a so-called 'salt' to protect the hash against rainbow tables. A salt effectively prevents two passwords that exactly match from being stored as the same hash value, preventing the whole database being scanned in one run if an attacker is executing a password guessing attack.A cryptographic hash should not be used for password storage because user-selected passwords are not strong enough (i.e. do not usually contain enough entropy) and a password guessing attack could be completed in a relatively short time by an attacker with access to the hashes. This is why KDFs are used - these effectively \"stretch the key\", which means that every password guess an attacker makes causes multiple repetitions of the hash algorithm, for example 10,000 times, which causes the attacker to guess the password 10,000 times slower.Session data - \"You are logged in as Spiderman69\"Once the server has verified the login and password against your user database and found a match, the system needs a way to remember that the browser has been authenticated. This fact should only ever be stored server side in the session data.If you are unfamiliar with session data, here's how it works: A single randomly-generated string is stored in an expiring cookie and used to reference a collection of data - the session data - which is stored on the server. If you are using an MVC framework, this is undoubtedly handled already.If at all possible, make sure the session cookie has the secure and HTTP Only flags set when sent to the browser. The HttpOnly flag provides some protection against the cookie being read through XSS attack. The secure flag ensures that the cookie is only sent back via HTTPS, and therefore protects against network sniffing attacks. The value of the cookie should not be predictable. Where a cookie referencing a non-existent session is presented, its value should be replaced immediately to prevent session fixation.Session state can also be maintained on the client side. This is achieved by using techniques like JWT (JSON Web Token).Persistent Login Cookies (\"remember me\" functionality) are a danger zone; on the one hand, they are entirely as safe as conventional logins when users understand how to handle them; and on the other hand, they are an enormous security risk in the hands of careless users, who may use them on public computers and forget to log out, and who may not know what browser cookies are or how to delete them.Personally, I like persistent logins for the websites I visit on a regular basis, but I know how to handle them safely. If you are positive that your users know the same, you can use persistent logins with a clean conscience. If not - well, then you may subscribe to the philosophy that users who are careless with their login credentials brought it upon themselves if they get hacked. It's not like we go to our user's houses and tear off all those facepalm-inducing Post-It notes with passwords they have lined up on the edge of their monitors, either.Of course, some systems can't afford to have any accounts hacked; for such systems, there is no way you can justify having persistent logins.If you DO decide to implement persistent login cookies, this is how you do it:First, take some time to read Paragon Initiative's article on the subject. You'll need to get a bunch of elements right, and the article does a great job of explaining each.And just to reiterate one of the most common pitfalls, DO NOT STORE THE PERSISTENT LOGIN COOKIE (TOKEN) IN YOUR DATABASE, ONLY A HASH OF IT! The login token is Password Equivalent, so if an attacker got their hands on your database, they could use the tokens to log in to any account, just as if they were cleartext login-password combinations. Therefore, use hashing (according to https://security.stackexchange.com/a/63438/5002 a weak hash will do just fine for this purpose) when storing persistent login tokens.Don't implement 'secret questions'. The 'secret questions' feature is a security anti-pattern. Read the paper from link number 4 from the MUST-READ list. You can ask Sarah Palin about that one, after her Yahoo! email account got hacked during a previous presidential campaign because the answer to her security question was... \"Wasilla High School\"!Even with user-specified questions, it is highly likely that most users will choose either:A 'standard' secret question like mother's maiden name or favorite petA simple piece of trivia that anyone could lift from their blog, LinkedIn profile, or similarAny question that is easier to answer than guessing their password. Which, for any decent password, is every question you can imagineIn conclusion, security questions are inherently insecure in virtually all their forms and variations, and should not be employed in an authentication scheme for any reason.The true reason why security questions even exist in the wild is that they conveniently save the cost of a few support calls from users who can't access their email to get to a reactivation code. This at the expense of security and Sarah Palin's reputation. Worth it? Probably not.I already mentioned why you should never use security questions for handling forgotten/lost user passwords; it also goes without saying that you should never e-mail users their actual passwords. There are at least two more all-too-common pitfalls to avoid in this field:Don't reset a forgotten password to an autogenerated strong password - such passwords are notoriously hard to remember, which means the user must either change it or write it down - say, on a bright yellow Post-It on the edge of their monitor. Instead of setting a new password, just let users pick a new one right away - which is what they want to do anyway. (An exception to this might be if the users are universally using a password manager to store/manage passwords that would normally be impossible to remember without writing it down).Always hash the lost password code/token in the database. AGAIN, this code is another example of a Password Equivalent, so it MUST be hashed in case an attacker got their hands on your database. When a lost password code is requested, send the plaintext code to the user's email address, then hash it, save the hash in your database -- and throw away the original. Just like a password or a persistent login token.A final note: always make sure your interface for entering the 'lost password code' is at least as secure as your login form itself, or an attacker will simply use this to gain access instead. Making sure you generate very long 'lost password codes' (for example, 16 case-sensitive alphanumeric characters) is a good start, but consider adding the same throttling scheme that you do for the login form itself.First, you'll want to read this small article for a reality check: The 500 most common passwordsOkay, so maybe the list isn't the canonical list of most common passwords on any system anywhere ever, but it's a good indication of how poorly people will choose their passwords when there is no enforced policy in place. Plus, the list looks frighteningly close to home when you compare it to publicly available analyses of recently stolen passwords.So: With no minimum password strength requirements, 2% of users use one of the top 20 most common passwords. Meaning: if an attacker gets just 20 attempts, 1 in 50 accounts on your website will be crackable.Thwarting this requires calculating the entropy of a password and then applying a threshold.  The National Institute of Standards and Technology (NIST) Special Publication 800-63 has a set of very good suggestions.  That, when combined with a dictionary and keyboard layout analysis (for example, 'qwertyuiop' is a bad password), can reject 99% of all poorly selected passwords at a level of 18 bits of entropy.  Simply calculating password strength and showing a visual strength meter to a user is good, but insufficient.  Unless it is enforced, a lot of users will most likely ignore it.And for a refreshing take on user-friendliness of high-entropy passwords, Randall Munroe's Password Strength xkcd is highly recommended.Utilize Troy Hunt's Have I Been Pwned API to check users passwords against passwords compromised in public data breaches.First, have a look at the numbers: Password Recovery Speeds - How long will your password stand upIf you don't have the time to look through the tables in that link, here's the list of them:It takes virtually no time to crack a weak password, even if you're cracking it with an abacusIt takes virtually no time to crack an alphanumeric 9-character password if it is case insensitiveIt takes virtually no time to crack an intricate, symbols-and-letters-and-numbers, upper-and-lowercase password if it is less than 8 characters long (a desktop PC can search the entire keyspace up to 7 characters in a matter of days or even hours)It would, however, take an inordinate amount of time to crack even a 6-character password, if you were limited to one attempt per second!So what can we learn from these numbers? Well, lots, but we can focus on the most important part: the fact that preventing large numbers of rapid-fire successive login attempts (ie. the brute force attack) really isn't that difficult. But preventing it right isn't as easy as it seems.Generally speaking, you have three choices that are all effective against brute-force attacks (and dictionary attacks, but since you are already employing a strong passwords policy, they shouldn't be an issue):Present a CAPTCHA after N failed attempts (annoying as hell and often ineffective -- but I'm repeating myself here)Locking accounts and requiring email verification after N failed attempts (this is a DoS attack waiting to happen)And finally, login throttling: that is, setting a time delay between attempts after N failed attempts (yes, DoS attacks are still possible, but at least they are far less likely and a lot more complicated to pull off).Best practice #1: A short time delay that increases with the number of failed attempts, like:DoS attacking this scheme would be very impractical, since the resulting lockout time is slightly larger than the sum of the previous lockout times.To clarify: The delay is not a delay before returning the response to the browser. It is more like a timeout or refractory period during which login attempts to a specific account or from a specific IP address will not be accepted or evaluated at all. That is, correct credentials will not return in a successful login, and incorrect credentials will not trigger a delay increase.Best practice #2: A medium length time delay that goes into effect after N failed attempts, like:DoS attacking this scheme would be quite impractical, but certainly doable. Also, it might be relevant to note that such a long delay can be very annoying for a legitimate user. Forgetful users will dislike you.Best practice #3: Combining the two approaches - either a fixed, short time delay that goes into effect after N failed attempts, like:Or, an increasing delay with a fixed upper bound, like:This final scheme was taken from the OWASP best-practices suggestions (link 1 from the MUST-READ list) and should be considered best practice, even if it is admittedly on the restrictive side.As a rule of thumb, however, I would say: the stronger your password policy is, the less you have to bug users with delays. If you require strong (case-sensitive alphanumerics + required numbers and symbols) 9+ character passwords, you could give the users 2-4 non-delayed password attempts before activating the throttling.DoS attacking this final login throttling scheme would be very impractical. And as a final touch, always allow persistent (cookie) logins (and/or a CAPTCHA-verified login form) to pass through, so legitimate users won't even be delayed while the attack is in progress. That way, the very impractical DoS attack becomes an extremely impractical attack.Additionally, it makes sense to do more aggressive throttling on admin accounts, since those are the most attractive entry pointsJust as an aside, more advanced attackers will try to circumvent login throttling by 'spreading their activities':Distributing the attempts on a botnet to prevent IP address flaggingRather than picking one user and trying the 50.000 most common passwords (which they can't, because of our throttling), they will pick THE most common password and try it against 50.000 users instead. That way, not only do they get around maximum-attempts measures like CAPTCHAs and login throttling, their chance of success increases as well, since the number 1 most common password is far more likely than number 49.995Spacing the login requests for each user account, say, 30 seconds apart, to sneak under the radarHere, the best practice would be logging the number of failed logins, system-wide, and using a running average of your site's bad-login frequency as the basis for an upper limit that you then impose on all users.Too abstract? Let me rephrase:Say your site has had an average of 120 bad logins per day over the past 3 months. Using that (running average), your system might set the global limit to 3 times that -- ie. 360 failed attempts over a 24 hour period. Then, if the total number of failed attempts across all accounts exceeds that number within one day (or even better, monitor the rate of acceleration and trigger on a calculated threshold), it activates system-wide login throttling - meaning short delays for ALL users (still, with the exception of cookie logins and/or backup CAPTCHA logins).I also posted a question with more details and a really good discussion of how to avoid tricky pitfals in fending off distributed brute force attacksCredentials can be compromised, whether by exploits, passwords being written down and lost, laptops with keys being stolen, or users entering logins into phishing sites.  Logins can be further protected with two-factor authentication, which uses out-of-band factors such as single-use codes received from a phone call, SMS message, app, or dongle. Several providers offer two-factor authentication services.Authentication can be completely delegated to a single-sign-on service, where another provider handles collecting credentials. This pushes the problem to a trusted third party. Google and Twitter both provide standards-based SSO services, while Facebook provides a similar proprietary solution.",
                "The only practical way to send credentials 100% securely is by using SSL. Using JavaScript to hash the password is not safe. Common pitfalls for client-side password hashing:There's another secure method called SRP, but it's patented (although it is freely licensed) and there are few good implementations available.Don't ever store passwords as plaintext in the database. Not even if you don't care about the security of your own site. Assume that some of your users will reuse the password of their online bank account. So, store the hashed password, and throw away the original. And make sure the password doesn't show up in access logs or application logs. OWASP recommends the use of Argon2 as your first choice for new applications. If this is not available, PBKDF2 or scrypt should be used instead. And finally if none of the above are available, use bcrypt.Hashes by themselves are also insecure. For instance, identical passwords mean identical hashes--this makes hash lookup tables an effective way of cracking lots of passwords at once. Instead, store the salted hash. A salt is a string appended to the password prior to hashing - use a different (random) salt per user. The salt is a public value, so you can store them with the hash in the database. See here for more on this.This means that you can't send the user their forgotten passwords (because you only have the hash). Don't reset the user's password unless you have authenticated the user (users must prove that they are able to read emails sent to the stored (and validated) email address.)Security questions are insecure - avoid using them. Why? Anything a security question does, a password does better. Read PART III: Using Secret Questions in @Jens Roland answer here in this wiki.After the user logs in, the server sends the user a session cookie. The server can retrieve the username or id from the cookie, but nobody else can generate such a cookie (TODO explain mechanisms).Cookies can be hijacked: they are only as secure as the rest of the client's machine and other communications. They can be read from disk, sniffed in network traffic, lifted by a cross-site scripting attack, phished from a poisoned DNS so the client sends their cookies to the wrong servers. Don't send persistent cookies. Cookies should expire at the end of the client session (browser close or leaving your domain).If you want to autologin your users, you can set a persistent cookie, but it should be distinct from a full-session cookie. You can set an additional flag that the user has auto-logged in, and needs to log in for real for sensitive operations. This is popular with shopping sites that want to provide you with a seamless, personalized shopping experience but still protect your financial details. For example, when you return to visit Amazon, they show you a page that looks like you're logged in, but when you go to place an order (or change your shipping address, credit card etc.), they ask you to confirm your password.Financial websites such as banks and credit cards, on the other hand, only have sensitive data and should not allow auto-login or a low-security mode.",
                "First, a strong caveat that this answer is not the best fit for this exact question. It should definitely not be the top answer!I will go ahead and mention Mozilla\u2019s proposed BrowserID (or perhaps more precisely, the Verified Email Protocol) in the spirit of finding an upgrade path to better approaches to authentication in the future.I\u2019ll summarize it this way:This is not strictly \u201cform-based authentication for websites\u201d. But it is an effort to transition from the current norm of form-based authentication to something more secure: browser-supported authentication.",
                "I just thought I'd share this solution that I found to be working just fine.I call it the Dummy Field (though I haven't invented this so don't credit me). Others know this as a honey pot.In short: you just have to insert this into your <form> and check for it to be empty at when validating:The trick is to fool a bot into thinking it has to insert data into a required field, that's why I named the input \"email\". If you already have a field called email that you're using you should try naming the dummy field something else like \"company\", \"phone\" or \"emailaddress\". Just pick something you know you don't need and what sounds like something people would normally find logical to fill in into a web form. Now hide the input field using CSS or JavaScript/jQuery - whatever fits you best - just don't set the input type to hidden or else the bot won't fall for it.When you are validating the form (either client or server side) check if your dummy field has been filled to determine if it was sent by a human or a bot.Example:In case of a human:\nThe user will not see the dummy field (in my case named \"email\") and will not attempt to fill it. So the value of the dummy field should still be empty when the form has been sent.In case of a bot: The bot will see a field whose type is text and a name email (or whatever it is you called it) and will logically attempt to fill it with appropriate data. It doesn't care if you styled the input form with some fancy CSS, web-developers do it all the time. Whatever the value in the dummy field is, we don't care as long as it's larger than 0 characters.I used this method on a guestbook in combination with CAPTCHA, and I haven't seen a single spam post since. I had used a CAPTCHA-only solution before, but eventually, it resulted in about five spam posts every hour. Adding the dummy field in the form has stopped (at least until now) all the spam from appearing.I believe this can also be used just fine with a login/authentication form.Warning: Of course this method is not 100% foolproof. Bots can be programmed to ignore input fields with the style display:none applied to it. You also have to think about people who use some form of auto-completion (like most browsers have built-in!) to auto-fill all form fields for them. They might just as well pick up a dummy field.You can also vary this up a little by leaving the dummy field visible but outside the boundaries of the screen, but this is totally up to you.Be creative!",
                "I do not think the above answer is \"wrong\" but there are large areas of authentication that are not touched upon (or rather the emphasis is on \"how to implement cookie sessions\", not on \"what options are available and what are the trade-offs\".My suggested edits/answers areDo NOT try to implement your own login form or database storage of passwords, unless \nthe data being stored is valueless at account creation and self-generated (that is, web 2.0 style like Facebook, Flickr, etc.)This avoids any need to have \"sessions\" or cookies as the browser itself will re-encrypt the communication each time. It is the most \"lightweight\" development approach.However, I do not recommend this, except for public, low-value services. This is an issue with some of the other answers above - do not try an re-implement server-side authentication mechanisms - this problem has been solved and is supported by most major browsers. Do not use cookies. Do not store anything in your own hand-rolled database. Just ask, per request, if the request is authenticated. Everything else should be supported by configuration and third-party trusted software.So ...First, we are confusing the initial creation of an account (with a password) with the re-checking of the password subsequently. If I am Flickr and creating your site for the first time, the new user has access to zero value (blank web space). I truly do not care if the person creating the account is lying about their name. If I am creating an account of the hospital intranet/extranet, the value lies in all the medical records, and so I do care about the identity (*) of the account creator.This is the very very hard part. The only decent solution is a web of trust. For example, you join the hospital as a doctor. You create a web page hosted somewhere with your photo, your passport number, and a public key, and hash them all with the private key. You then visit the hospital and the system administrator looks at your passport, sees if the photo matches you, and then hashes the web page/photo hash with the hospital private key. From now on we can securely exchange keys and tokens. As can anyone who trusts the hospital (there is the secret sauce BTW). The system administrator can also give you an RSA dongle or other two-factor authentication.But this is a lot of a hassle, and not very web 2.0. However, it is the only secure way to create new accounts that have access to valuable information that is not self-created.Kerberos and SPNEGO - single sign-on mechanisms with a trusted third party - basically the user verifies against a trusted third party. (NB this is not in any way the not to be trusted OAuth)SRP - sort of clever password authentication without a trusted third party. But here we are getting into the realms of \"it's safer to use two-factor authentication, even if that's costlier\"SSL client side - give the clients a public key certificate (support in all major browsers - but raises questions over client machine security).In the end, it's a tradeoff - what is the cost of a security breach vs the cost of implementing more secure approaches. One day, we may see a proper PKI widely accepted and so no more own rolled authentication forms and databases. One day...",
                "When hashing, don't use fast hash algorithms such as MD5 (many hardware implementations exist).  Use something like SHA-512.  For passwords, slower hashes are better.The faster you can create hashes, the faster any brute force checker can work. Slower hashes will therefore slow down brute forcing. A slow hash algorithm will make brute forcing impractical for longer passwords (8 digits +)",
                "My favourite rule in regards to authentication systems: use passphrases, not passwords. Easy to remember, hard to crack.\nMore info: Coding Horror: Passwords vs. Pass Phrases",
                "I'd like to add one suggestion I've used, based on defense in depth. You don't need to have the same auth&auth system for admins as regular users. You can have a separate login form on a separate url executing separate code for requests that will grant high privileges. This one can make choices that would be a total pain to regular users. One such that I've used is to actually scramble the login URL for admin access and email the admin the new URL. Stops any brute force attack right away as your new URL can be arbitrarily difficult (very long random string) but your admin user's only inconvenience is following a link in their email. The attacker no longer knows where to even POST to.",
                "I dont't know whether it was best to answer this as an answer or as a comment. I opted for the first option.Regarding the poing PART IV: Forgotten Password Functionality in the first answer, I would make a point about Timing Attacks.In the Remember your password forms, an attacker could potentially check a full list of emails and detect which are registered to the system (see link below).Regarding the Forgotten Password Form, I would add that it is a good idea to equal times between successful and unsucessful queries with some delay function.https://crypto.stanford.edu/~dabo/papers/webtiming.pdf",
                "I would like to add one very important comment: -Many corporations deploy \"internal use only\" websites which are, effectively, \"corporate applications\" that happen to have been implemented through URLs. These URLs can (supposedly ...) only be resolved within \"the company's internal network.\" (Which network magically includes all VPN-connected 'road warriors.')When a user is dutifully-connected to the aforesaid network, their identity (\"authentication\") is [already ...] \"conclusively known,\" as is their permission (\"authorization\") to do certain things ... such as ... \"to access this website.\"This \"authentication + authorization\" service can be provided by several different technologies, such as LDAP (Microsoft OpenDirectory), or Kerberos.From your point-of-view, you simply know this: that anyone who legitimately winds-up at your website must be accompanied by [an environment-variable magically containing ...] a \"token.\" (i.e. The absence of such a token must be immediate grounds for 404 Not Found.)The token's value makes no sense to you, but, should the need arise, \"appropriate means exist\" by which your website can \"[authoritatively] ask someone who knows (LDAP... etc.)\" about any and every(!) question that you may have. In other words, you do not avail yourself of any \"home-grown logic.\" Instead, you inquire of The Authority and implicitly trust its verdict.Uh huh ... it's quite a mental-switch from the \"wild-and-wooly Internet.\"",
                "Use OpenID Connect or User-Managed Access.As nothing is more efficient than not doing it at all."
            ]
        },
        {
            "tag": "python",
            "question": [
                "What does the \"yield\" keyword do?",
                "What is the use of the yield keyword in Python? What does it do?\nFor example, I'm trying to understand this code1:\ndef _get_child_candidates(self, distance, min_dist, max_dist):\n    if self._leftchild ..."
            ],
            "url": "https://stackoverflow.com/questions/231767",
            "answer": [
                "To understand what yield does, you must understand what generators are. And before you can understand generators, you must understand iterables.When you create a list, you can read its items one by one. Reading its items one by one is called iteration:mylist is an iterable. When you use a list comprehension, you create a list, and so an iterable:Everything you can use \"for... in...\" on is an iterable; lists, strings, files...These iterables are handy because you can read them as much as you wish, but you store all the values in memory and this is not always what you want when you have a lot of values.Generators are iterators, a kind of iterable you can only iterate over once. Generators do not store all the values in memory, they generate the values on the fly:It is just the same except you used () instead of []. BUT, you cannot perform for i in mygenerator a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end calculating 4, one by one.yield is a keyword that is used like return, except the function will return a generator.Here it's a useless example, but it's handy when you know your function will return a huge set of values that you will only need to read once.To master yield, you must understand that when you call the function, the code you have written in the function body does not run. The function only returns the generator object, this is a bit tricky.Then, your code will continue from where it left off each time for uses the generator.Now the hard part:The first time the for calls the generator object created from your function, it will run the code in your function from the beginning until it hits yield, then it'll return the first value of the loop. Then, each subsequent call will run another iteration of the loop you have written in the function and return the next value. This will continue until the generator is considered empty, which happens when the function runs without hitting yield. That can be because the loop has come to an end, or because you no longer satisfy an \"if/else\".Generator:Caller:This code contains several smart parts:The loop iterates on a list, but the list expands while the loop is being iterated. It's a concise way to go through all these nested data even if it's a bit dangerous since you can end up with an infinite loop. In this case, candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) exhausts all the values of the generator, but while keeps creating new generator objects which will produce different values from the previous ones since it's not applied on the same node.The extend() method is a list object method that expects an iterable and adds its values to the list.Usually, we pass a list to it:But in your code, it gets a generator, which is good because:And it works because Python does not care if the argument of a method is a list or not. Python expects iterables so it will work with strings, lists, tuples, and generators! This is called duck typing and is one of the reasons why Python is so cool. But this is another story, for another question...You can stop here, or read a little bit to see an advanced use of a generator:Note: For Python 3, useprint(corner_street_atm.__next__()) or print(next(corner_street_atm))It can be useful for various things like controlling access to a resource.The itertools module contains special functions to manipulate iterables. Ever wish to duplicate a generator?\nChain two generators? Group values in a nested list with a one-liner? Map / Zip without creating another list?Then just import itertools.An example? Let's see the possible orders of arrival for a four-horse race:Iteration is a process implying iterables (implementing the __iter__() method) and iterators (implementing the __next__() method).\nIterables are any objects you can get an iterator from. Iterators are objects that let you iterate on iterables.There is more about it in this article about how for loops work.",
                "When you see a function with yield statements, apply this easy trick to understand what will happen:This trick may give you an idea of the logic behind the function, but what actually happens with yield is significantly different than what happens in the list-based approach. In many cases, the yield approach will be a lot more memory efficient and faster too. In other cases, this trick will get you stuck in an infinite loop, even though the original function works just fine. Read on to learn more...First, the iterator protocol - when you writePython performs the following two steps:Gets an iterator for mylist:Call iter(mylist) -> this returns an object with a next() method (or __next__() in Python 3).[This is the step most people forget to tell you about]Uses the iterator to loop over items:Keep calling the next() method on the iterator returned from step 1. The return value from next() is assigned to x and the loop body is executed. If an exception StopIteration is raised from within next(), it means there are no more values in the iterator and the loop is exited.The truth is Python performs the above two steps anytime it wants to loop over the contents of an object - so it could be a for loop, but it could also be code like otherlist.extend(mylist) (where otherlist is a Python list).Here mylist is an iterable because it implements the iterator protocol. In a user-defined class, you can implement the __iter__() method to make instances of your class iterable. This method should return an iterator. An iterator is an object with a next() method. It is possible to implement both __iter__() and next() on the same class, and have __iter__() return self. This will work for simple cases, but not when you want two iterators looping over the same object at the same time.So that's the iterator protocol, many objects implement this protocol:Note that a for loop doesn't know what kind of object it's dealing with - it just follows the iterator protocol, and is happy to get item after item as it calls next(). Built-in lists return their items one by one, dictionaries return the keys one by one, files return the lines one by one, etc. And generators return... well that's where yield comes in:Instead of yield statements, if you had three return statements in f123() only the first would get executed, and the function would exit. But f123() is no ordinary function. When f123() is called, it does not return any of the values in the yield statements! It returns a generator object. Also, the function does not really exit - it goes into a suspended state. When the for loop tries to loop over the generator object, the function resumes from its suspended state at the very next line after the yield it previously returned from, executes the next line of code, in this case, a yield statement, and returns that as the next item. This happens until the function exits, at which point the generator raises StopIteration, and the loop exits.So the generator object is sort of like an adapter - at one end it exhibits the iterator protocol, by exposing __iter__() and next() methods to keep the for loop happy. At the other end, however, it runs the function just enough to get the next value out of it, and puts it back in suspended mode.Usually, you can write code that doesn't use generators but implements the same logic. One option is to use the temporary list 'trick' I mentioned before. That will not work in all cases, for e.g. if you have infinite loops, or it may make inefficient use of memory when you have a really long list. The other approach is to implement a new iterable class SomethingIter that keeps the state in instance members and performs the next logical step in its next() (or __next__() in Python 3) method. Depending on the logic, the code inside the next() method may end up looking very complex and prone to bugs. Here generators provide a clean and easy solution.",
                "Think of it this way:An iterator is just a fancy sounding term for an object that has a next() method.  So a yield-ed function ends up being something like this:Original version:This is basically what the Python interpreter does with the above code:For more insight as to what's happening behind the scenes, the for loop can be rewritten to this:Does that make more sense or just confuse you more?  :)I should note that this is an oversimplification for illustrative purposes. :)",
                "The yield keyword is reduced to two simple facts:In a nutshell: Most commonly, a generator is a lazy, incrementally-pending list, and yield statements allow you to use function notation to program the list values the generator should incrementally spit out. Furthermore, advanced usage lets you use generators as coroutines (see below).Basically, whenever the yield statement is encountered, the function pauses and saves its state, then emits \"the next return value in the 'list'\" according to the python iterator protocol (to some syntactic construct like a for-loop that repeatedly calls next() and catches a StopIteration exception, etc.). You might have encountered generators with generator expressions; generator functions are more powerful because you can pass arguments back into the paused generator function, using them to implement coroutines. More on that later.Let's define a function makeRange that's just like Python's range. Calling makeRange(n) RETURNS A GENERATOR:To force the generator to immediately return its pending values, you can pass it into list() (just like you could any iterable):The above example can be thought of as merely creating a list which you append to and return:There is one major difference, though; see the last section.An iterable is the last part of a list comprehension, and all generators are iterable, so they're often used like so:To get a better feel for generators, you can play around with the itertools module (be sure to use chain.from_iterable rather than chain when warranted). For example, you might even use generators to implement infinitely-long lazy lists like itertools.count(). You could implement your own def enumerate(iterable): zip(count(), iterable), or alternatively do so with the yield keyword in a while-loop.Please note: generators can actually be used for many more things, such as implementing coroutines or non-deterministic programming or other elegant things. However, the \"lazy lists\" viewpoint I present here is the most common use you will find.This is how the \"Python iteration protocol\" works. That is, what is going on when you do list(makeRange(5)). This is what I describe earlier as a \"lazy, incremental list\".The built-in function next() just calls the objects .__next__() function, which is a part of the \"iteration protocol\" and is found on all iterators. You can manually use the next() function (and other parts of the iteration protocol) to implement fancy things, usually at the expense of readability, so try to avoid doing that...Coroutine example:A coroutine (generators which generally accept input via the yield keyword e.g. nextInput = yield nextOutput, as a form of two-way communication) is basically a computation which is allowed to pause itself and request input (e.g. to what it should do next). When the coroutine pauses itself (when the running coroutine eventually hits a yield keyword), the computation is paused and control is inverted (yielded) back to the 'calling' function (the frame which requested the next value of the computation). The paused generator/coroutine remains paused until another invoking function (possibly a different function/context) requests the next value to unpause it (usually passing input data to direct the paused logic interior to the coroutine's code).You can think of python coroutines as lazy incrementally-pending lists, where the next element doesn't just depend on the previous computation, but also on input you may opt to inject during the generation process.Normally, most people would not care about the following distinctions and probably want to stop reading here.In Python-speak, an iterable is any object which \"understands the concept of a for-loop\" like a list [1,2,3], and an iterator is a specific instance of the requested for-loop like [1,2,3].__iter__(). A generator is exactly the same as any iterator, except for the way it was written (with function syntax).When you request an iterator from a list, it creates a new iterator. However, when you request an iterator from an iterator (which you would rarely do), it just gives you a copy of itself.Thus, in the unlikely event that you are failing to do something like this...... then remember that a generator is an iterator; that is, it is one-time-use. If you want to reuse it, you should call myRange(...) again. If you need to use the result twice, convert the result to a list and store it in a variable x = list(myRange(5)). Those who absolutely need to clone a generator (for example, who are doing terrifyingly hackish metaprogramming) can use itertools.tee (still works in Python 3) if absolutely necessary, since the copyable iterator Python PEP standards proposal has been deferred.",
                "What does the yield keyword do in Python?yield is only legal inside of a function definition, and the inclusion of yield in a function definition makes it return a generator.The idea for generators comes from other languages (see footnote 1) with varying implementations. In Python's Generators, the execution of the code is frozen at the point of the yield. When the generator is called (methods are discussed below) execution resumes and then freezes at the next yield.yield provides an\neasy way of implementing the iterator protocol, defined by the following two methods:\n__iter__ and __next__.  Both of those methods\nmake an object an iterator that you could type-check with the Iterator Abstract Base\nClass from the collections module.Let's do some introspection:The generator type is a sub-type of iterator:And if necessary, we can type-check like this:A feature of an Iterator is that once exhausted, you can't reuse or reset it:You'll have to make another if you want to use its functionality again (see footnote 2):One can yield data programmatically, for example:The above simple generator is also equivalent to the below - as of Python 3.3 you can use yield from:However, yield from also allows for delegation to subgenerators,\nwhich will be explained in the following section on cooperative delegation with sub-coroutines.yield forms an expression that allows data to be sent into the generator (see footnote 3)Here is an example, take note of the received variable, which will point to the data that is sent to the generator:First, we must queue up the generator with the builtin function, next. It will\ncall the appropriate next or __next__ method, depending on the version of\nPython you are using:And now we can send data into the generator. (Sending None is\nthe same as calling next.) :Now, recall that yield from is available in Python 3. This allows us to delegate coroutines to a subcoroutine:And now we can delegate functionality to a sub-generator and it can be used\nby a generator just as above:Now simulate adding another 1,000 to the account plus the return on the account (60.0):You can read more about the precise semantics of yield from in PEP 380.The close method raises GeneratorExit at the point the function\nexecution was frozen. This will also be called by __del__ so you\ncan put any cleanup code where you handle the GeneratorExit:You can also throw an exception which can be handled in the generator\nor propagated back to the user:Raises:I believe I have covered all aspects of the following question:What does the yield keyword do in Python?It turns out that yield does a lot. I'm sure I could add even more\nthorough examples to this. If you want more or have some constructive criticism, let me know by commenting\nbelow.The top/accepted answer is a very incomplete answer.The grammar currently allows any expression in a list comprehension.Since yield is an expression, it has been touted by some as interesting to use it in comprehensions or generator expression - in spite of citing no particularly good use-case.The CPython core developers are discussing deprecating its allowance.\nHere's a relevant post from the mailing list:On 30 January 2017 at 19:05, Brett Cannon  wrote:On Sun, 29 Jan 2017 at 16:39 Craig Rodrigues  wrote:I'm OK with either approach.  Leaving things the way they are in Python 3\nis no good, IMHO.My vote is it be a SyntaxError since you're not getting what you expect from\nthe syntax.I'd agree that's a sensible place for us to end up, as any code\nrelying on the current behaviour is really too clever to be\nmaintainable.In terms of getting there, we'll likely want:Cheers, Nick.--  Nick Coghlan   |   ncoghlan at gmail.com   |   Brisbane, AustraliaFurther, there is an outstanding issue (10544) which seems to be pointing in the direction of this never being a good idea (PyPy, a Python implementation written in Python, is already raising syntax warnings.)Bottom line, until the developers of CPython tell us otherwise: Don't put yield in a generator expression or comprehension.In Python 3:In a generator function, the return statement indicates that the generator is done and will cause StopIteration to be raised. The returned value (if any) is used as an argument to construct StopIteration and becomes the StopIteration.value attribute.Historical note, in Python 2:\n\"In a generator function, the return statement is not allowed to include an expression_list. In that context, a bare return indicates that the generator is done and will cause StopIteration to be raised.\"\nAn expression_list is basically any number of expressions separated by commas - essentially, in Python 2, you can stop the generator with return, but you can't return a value.The languages CLU, Sather, and Icon were referenced in the proposal\nto introduce the concept of generators to Python. The general idea is\nthat a function can maintain internal state and yield intermediate\ndata points on demand by the user. This promised to be superior in performance\nto other approaches, including Python threading, which isn't even available on some systems.This means, for example, that range objects aren't Iterators, even though they are iterable, because they can be reused. Like lists, their __iter__ methods return iterator objects.yield was originally introduced as a statement, meaning that it\ncould only appear at the beginning of a line in a code block.\nNow yield creates a yield expression.\nhttps://docs.python.org/2/reference/simple_stmts.html#grammar-token-yield_stmt\nThis change was proposed to allow a user to send data into the generator just as\none might receive it. To send data, one must be able to assign it to something, and\nfor that, a statement just won't work.",
                "yield is just like return - it returns whatever you tell it to (as a generator). The difference is that the next time you call the generator, execution starts from the last call to the yield statement. Unlike return, the stack frame is not cleaned up when a yield occurs, however control is transferred back to the caller, so its state will resume the next time the function is called.In the case of your code, the function get_child_candidates is acting like an iterator so that when you extend your list, it adds one element at a time to the new list.list.extend calls an iterator until it's exhausted. In the case of the code sample you posted, it would be much clearer to just return a tuple and append that to the list.",
                "There's one extra thing to mention: a function that yields doesn't actually have to terminate. I've written code like this:Then I can use it in other code like this:It really helps simplify some problems, and makes some things easier to work with.",
                "For those who prefer a minimal working example, meditate on this interactive Python session:",
                "TL;DRWhenever you find yourself building a list from scratch, yield each piece instead.This was my first \"aha\" moment with yield.yield is a sugary way to saybuild a series of stuffSame behavior:Different behavior:Yield is single-pass: you can only iterate through once. When a function has a yield in it we call it a generator function. And an iterator is what it returns. Those terms are revealing. We lose the convenience of a container, but gain the power of a series that's computed as needed, and arbitrarily long.Yield is lazy, it puts off computation. A function with a yield in it doesn't actually execute at all when you call it. It returns an iterator object that remembers where it left off. Each time you call next() on the iterator (this happens in a for-loop) execution inches forward to the next yield. return raises StopIteration and ends the series (this is the natural end of a for-loop).Yield is versatile. Data doesn't have to be stored all together, it can be made available one at a time. It can be infinite.If you need multiple passes and the series isn't too long, just call list() on it:Brilliant choice of the word yield because both meanings apply:yield \u2014 produce or provide (as in agriculture)...provide the next data in the series.yield \u2014 give way or relinquish (as in political power)...relinquish CPU execution until the iterator advances.",
                "Yield gives you a generator.As you can see, in the first case foo holds the entire list in memory at once. It's not a big deal for a list with 5 elements, but what if you want a list of 5 million? Not only is this a huge memory eater, it also costs a lot of time to build at the time that the function is called.In the second case, bar just gives you a generator. A generator is an iterable--which means you can use it in a for loop, etc, but each value can only be accessed once. All the values are also not stored in memory at the same time; the generator object \"remembers\" where it was in the looping the last time you called it--this way, if you're using an iterable to (say) count to 50 billion, you don't have to count to 50 billion all at once and store the 50 billion numbers to count through.Again, this is a pretty contrived example, you probably would use itertools if you really wanted to count to 50 billion. :)This is the most simple use case of generators. As you said, it can be used to write efficient permutations, using yield to push things up through the call stack instead of using some sort of stack variable. Generators can also be used for specialized tree traversal, and all manner of other things.",
                "It's returning a generator. I'm not particularly familiar with Python, but I believe it's the same kind of thing as C#'s iterator blocks if you're familiar with those.The key idea is that the compiler/interpreter/whatever does some trickery so that as far as the caller is concerned, they can keep calling next() and it will keep returning values - as if the generator method was paused. Now obviously you can't really \"pause\" a method, so the compiler builds a state machine for you to remember where you currently are and what the local variables etc look like. This is much easier than writing an iterator yourself.",
                "There is one type of answer that I don't feel has been given yet, among the many great answers that describe how to use generators. Here is the programming language theory answer:The yield statement in Python returns a generator. A generator in Python is a function that returns continuations (and specifically a type of coroutine, but continuations represent the more general mechanism to understand what is going on).Continuations in programming languages theory are a much more fundamental kind of computation, but they are not often used, because they are extremely hard to reason about and also very difficult to implement. But the idea of what a continuation is, is straightforward: it is the state of a computation that has not yet finished. In this state, the current values of variables, the operations that have yet to be performed, and so on, are saved. Then at some point later in the program the continuation can be invoked, such that the program's variables are reset to that state and the operations that were saved are carried out.Continuations, in this more general form, can be implemented in two ways. In the call/cc way, the program's stack is literally saved and then when the continuation is invoked, the stack is restored.In continuation passing style (CPS), continuations are just normal functions (only in languages where functions are first class) which the programmer explicitly manages and passes around to subroutines. In this style, program state is represented by closures (and the variables that happen to be encoded in them) rather than variables that reside somewhere on the stack. Functions that manage control flow accept continuation as arguments (in some variations of CPS, functions may accept multiple continuations) and manipulate control flow by invoking them by simply calling them and returning afterwards. A very simple example of continuation passing style is as follows:In this (very simplistic) example, the programmer saves the operation of actually writing the file into a continuation (which can potentially be a very complex operation with many details to write out), and then passes that continuation (i.e, as a first-class closure) to another operator which does some more processing, and then calls it if necessary. (I use this design pattern a lot in actual GUI programming, either because it saves me lines of code or, more importantly, to manage control flow after GUI events trigger.)The rest of this post will, without loss of generality, conceptualize continuations as CPS, because it is a hell of a lot easier to understand and read.Now let's talk about generators in Python. Generators are a specific subtype of continuation. Whereas continuations are able in general to save the state of a computation (i.e., the program's call stack), generators are only able to save the state of iteration over an iterator. Although, this definition is slightly misleading for certain use cases of generators. For instance:This is clearly a reasonable iterable whose behavior is well defined -- each time the generator iterates over it, it returns 4 (and does so forever). But it isn't probably the prototypical type of iterable that comes to mind when thinking of iterators (i.e., for x in collection: do_something(x)). This example illustrates the power of generators: if anything is an iterator, a generator can save the state of its iteration.To reiterate: Continuations can save the state of a program's stack and generators can save the state of iteration. This means that continuations are more a lot powerful than generators, but also that generators are a lot, lot easier. They are easier for the language designer to implement, and they are easier for the programmer to use (if you have some time to burn, try to read and understand this page about continuations and call/cc).But you could easily implement (and conceptualize) generators as a simple, specific case of continuation passing style:Whenever yield is called, it tells the function to return a continuation.  When the function is called again, it starts from wherever it left off. So, in pseudo-pseudocode (i.e., not pseudocode, but not code) the generator's next method is basically as follows:where the yield keyword is actually syntactic sugar for the real generator function, basically something like:Remember that this is just pseudocode and the actual implementation of generators in Python is more complex. But as an exercise to understand what is going on, try to use continuation passing style to implement generator objects without use of the yield keyword.",
                "Here is an example in plain language. I will provide a correspondence between high-level human concepts to low-level Python concepts.I want to operate on a sequence of numbers, but I don't want to bother my self with the creation of that sequence, I want only to focus on the operation I want to do. So, I do the following:This is what a generator does (a function that contains a yield); it starts executing on the first next(), pauses whenever it does a yield, and when asked for the next() value it continues from the point it was last. It fits perfectly by design with the iterator protocol of Python, which describes how to sequentially request values.The most famous user of the iterator protocol is the for command in Python. So, whenever you do a:it doesn't matter if sequence is a list, a string, a dictionary or a generator object like described above; the result is the same: you read items off a sequence one by one.Note that defining a function which contains a yield keyword is not the only way to create a generator; it's just the easiest way to create one.For more accurate information, read about iterator types, the yield statement and generators in the Python documentation.",
                "While a lot of answers show why you'd use a yield to create a generator, there are more uses for yield.  It's quite easy to make a coroutine, which enables the passing of information between two blocks of code.  I won't repeat any of the fine examples that have already been given about using yield to create a generator.To help understand what a yield does in the following code, you can use your finger to trace the cycle through any code that has a yield.  Every time your finger hits the yield, you have to wait for a next or a send to be entered.  When a next is called, you trace through the code until you hit the yield\u2026 the code on the right of the yield is evaluated and returned to the caller\u2026 then you wait.  When next is called again, you perform another loop through the code.  However, you'll note that in a coroutine, yield can also be used with a send\u2026 which will send a value from the caller into the yielding function. If a send is given, then yield receives the value sent, and spits it out the left hand side\u2026 then the trace through the code progresses until you hit the yield again (returning the value at the end, as if next was called).For example:",
                "There is another yield use and meaning (since Python 3.3):From PEP 380 -- Syntax for Delegating to a Subgenerator:A syntax is proposed for a generator to delegate part of its operations to another generator. This allows a section of code containing 'yield' to be factored out and placed in another generator. Additionally, the subgenerator is allowed to return with a value, and the value is made available to the delegating generator.The new syntax also opens up some opportunities for optimisation when one generator re-yields values produced by another.Moreover this will introduce (since Python 3.5):to avoid coroutines being confused with a regular generator (today yield is used in both).",
                "All great answers, however a bit difficult for newbies.I assume you have learned the return statement.As an analogy, return and yield are twins. return means 'return and stop' whereas 'yield` means 'return, but continue'Run it:See, you get only a single number rather than a list of them. return never allows you prevail happily, just implements once and quit.Replace return with yield:Now, you win to get all the numbers.Comparing to return which runs once and stops, yield runs times you planed.\nYou can interpret return as return one of them, and yield as return all of them. This is called iterable.It's the core about yield.The difference between a list return outputs and the object yield output is:You will always get [0, 1, 2] from a list object but only could retrieve them from 'the object yield output' once. So, it has a new name generator object as displayed in Out[11]: <generator object num_list at 0x10327c990>.In conclusion, as a metaphor to grok it:",
                "From a programming viewpoint, the iterators are implemented as thunks.To implement iterators, generators, and thread pools for concurrent execution, etc. as thunks, one uses messages sent to a closure object, which has a dispatcher, and the dispatcher answers to \"messages\".\"next\" is a message sent to a closure, created by the \"iter\" call.There are lots of ways to implement this computation. I used mutation, but it is possible to do this kind of computation without mutation, by returning the current value and the next yielder (making it referential transparent).  Racket uses a sequence of transformations of the initial program in some intermediary languages, one of such rewriting making the yield operator to be transformed in some language with simpler operators.Here is a demonstration of how yield could be rewritten, which uses the structure of R6RS, but the semantics is identical to Python's. It's the same model of computation, and only a change in syntax is required to rewrite it using yield of Python.",
                "Here are some Python examples of how to actually implement generators as if Python did not provide syntactic sugar for them:As a Python generator:Using lexical closures instead of generatorsUsing object closures instead of generators (because ClosuresAndObjectsAreEquivalent)",
                "I was going to post \"read page 19 of Beazley's 'Python: Essential Reference' for a quick description of generators\", but so many others have posted good descriptions already.Also, note that yield can be used in coroutines as the dual of their use in generator functions.  Although it isn't the same use as your code snippet, (yield) can be used as an expression in a function.  When a caller sends a value to the method using the send() method, then the coroutine will execute until the next (yield) statement is encountered.Generators and coroutines are a cool way to set up data-flow type applications.  I thought it would be worthwhile knowing about the other use of the yield statement in functions.",
                "Here is a simple example:Output:I am not a Python developer, but it looks to me yield holds the position of program flow and the next loop start from \"yield\" position. It seems like it is waiting at that position, and just before that, returning a value outside, and next time continues to work.It seems to be an interesting and nice ability :D",
                "Here is a mental image of what yield does.I like to think of a thread as having a stack (even when it's not implemented that way).When a normal function is called, it puts its local variables on the stack, does some computation, then clears the stack and returns. The values of its local variables are never seen again.With a yield function, when its code begins to run (i.e. after the function is called, returning a generator object, whose next() method is then invoked), it similarly puts its local variables onto the stack and computes for a while. But then, when it hits the yield statement, before clearing its part of the stack and returning, it takes a snapshot of its local variables and stores them in the generator object. It also writes down the place where it's currently up to in its code (i.e. the particular yield statement).So it's a kind of a frozen function that the generator is hanging onto.When next() is called subsequently, it retrieves the function's belongings onto the stack and re-animates it. The function continues to compute from where it left off, oblivious to the fact that it had just spent an eternity in cold storage.Compare the following examples:When we call the second function, it behaves very differently to the first. The yield statement might be unreachable, but if it's present anywhere, it changes the nature of what we're dealing with.Calling yielderFunction() doesn't run its code, but makes a generator out of the code. (Maybe it's a good idea to name such things with the yielder prefix for readability.)The gi_code and gi_frame fields are where the frozen state is stored. Exploring them with dir(..), we can confirm that our mental model above is credible.",
                "Imagine that you have created a remarkable machine that is capable of generating thousands and thousands of lightbulbs per day. The machine generates these lightbulbs in boxes with a unique serial number. You don't have enough space to store all of these lightbulbs at the same time, so you would like to adjust it to generate lightbulbs on-demand.Python generators don't differ much from this concept. Imagine that you have a function called barcode_generator that generates unique serial numbers for the boxes. Obviously, you can have a huge number of such barcodes returned by the function, subject to the hardware (RAM) limitations. A wiser, and space efficient, option is to generate those serial numbers on-demand.Machine's code:Note the next(barcode) bit.As you can see, we have a self-contained \u201cfunction\u201d to generate the next unique serial number each time. This function returns a generator! As you can see, we are not calling the function each time we need a new serial number, but instead we are using next() given the generator to obtain the next serial number.To be more precise, this generator is a lazy iterator! An iterator is an object that helps us traverse a sequence of objects. It's called lazy because it does not load all the items of the sequence in memory until they are needed. The use of next in the previous example is the explicit way to obtain the next item from the iterator. The implicit way is using for loops:This will print barcodes infinitely, yet you will not run out of memory.In other words, a generator looks like a function but behaves like an iterator.Finally, real-world applications? They are usually useful when you work with big sequences. Imagine reading a huge file from disk with billions of records. Reading the entire file in memory, before you can work with its content, will probably be infeasible (i.e., you will run out of memory).",
                "An easy example to understand what it is: yieldThe output is:",
                "Like every answer suggests, yield is used for creating a sequence generator. It's used for generating some sequence dynamically. For example, while reading a file line by line on a network, you can use the yield function as follows:You can use it in your code as follows:Execution Control Transfer gotchaThe execution control will be transferred from getNextLines() to the for loop when yield is executed. Thus, every time getNextLines() is invoked, execution begins from the point where it was paused last time.Thus in short, a function with the following codewill print",
                "(My below answer only speaks from the perspective of using Python generator, not the underlying implementation of generator mechanism, which involves some tricks of stack and heap manipulation.)When yield is used instead of a return in a python function, that function is turned into something special called generator function. That function will return an object of generator type. The yield keyword is a flag to notify the python compiler to treat such function specially. Normal functions will terminate once some value is returned from it. But with the help of the compiler, the generator function can be thought of as resumable. That is, the execution context will be restored and the execution will continue from last run. Until you explicitly call return, which will raise a StopIteration exception (which is also part of the iterator protocol), or reach the end of the function. I found a lot of references about generator but this one from the functional programming perspective is the most digestable.(Now I want to talk about the rationale behind generator, and the iterator based on my own understanding. I hope this can help you grasp the essential motivation of iterator and generator. Such concept shows up in other languages as well such as C#.)As I understand, when we want to process a bunch of data, we usually first store the data somewhere and then process it one by one. But this naive approach is problematic. If the data volume is huge, it's expensive to store them as a whole beforehand. So instead of storing the data itself directly, why not store some kind of metadata indirectly, i.e. the logic how the data is computed.There are 2 approaches to wrap such metadata.Either way, an iterator is created, i.e. some object that can give you the data you want. The OO approach may be a bit complex. Anyway, which one to use is up to you.",
                "In summary, the yield statement transforms your function into a factory that produces a special object called a generator which wraps around the body of your original function. When the generator is iterated, it executes your function  until it reaches the next yield then suspends execution and evaluates to the value passed to yield. It repeats this process on each iteration until the path of execution exits the function. For instance,simply outputsThe power comes from using the generator with a loop that calculates a sequence, the generator executes the loop stopping each time to 'yield' the next result of the calculation, in this way it calculates a list on the fly, the benefit being the memory saved for especially large calculationsSay you wanted to create a your own range function that produces an iterable range of numbers, you could do it like so,and use it like this;But this is inefficient becauseLuckily Guido and his team were generous enough to develop generators so we could just do this;Now upon each iteration a function on the generator called next() executes the function until it either reaches a 'yield' statement in which it stops and  'yields' the value or reaches the end of the function. In this case on the first call, next() executes up to the yield statement and yield 'n', on the next call it will execute the  increment statement, jump back to the 'while', evaluate it, and if true, it will stop and yield 'n' again, it will continue that way until the while condition returns false and the generator jumps to the end of the function.",
                "Yield is an objectA return in a function will return a single value.If you want a function to return a huge set of values, use yield.More importantly, yield is a barrier.like barrier in the CUDA language, it will not transfer control until it gets\n  completed.That is, it will run the code in your function from the beginning until it hits yield. Then, it\u2019ll return the first value of the loop.Then, every other call will run the loop you have written in the function one more time, returning the next value until there isn't any value to return.",
                "Many people use return rather than yield, but in some cases yield can be more efficient and easier to work with.Here is an example which yield is definitely best for:return (in function)yield (in function)Calling functionsBoth functions do the same thing, but yield uses three lines instead of five and has one less variable to worry about.This is the result from the code:As you can see both functions do the same thing. The only difference is return_dates() gives a list and yield_dates() gives a generator.A real life example would be something like reading a file line by line or if you just want to make a generator.",
                "The yield keyword simply collects returning results. Think of yield like return +=",
                "yield is like a return element for a function. The difference is, that the yield element turns a function into a generator. A generator behaves just like a function until something is 'yielded'. The generator stops until it is next called, and continues from exactly the same point as it started. You can get a sequence of all the 'yielded' values in one, by calling list(generator())."
            ]
        },
        {
            "tag": "python",
            "question": [
                "What does if __name__ == \"__main__\": do?",
                "What does this do, and why should one include the if statement?\nif __name__ == \"__main__\":\n    print(\"Hello, World!\")\r\nIf you are trying to close a question where someone should be ..."
            ],
            "url": "https://stackoverflow.com/questions/419163",
            "answer": [
                "It's boilerplate code that protects users from accidentally invoking the script when they didn't intend to. Here are some common problems when the guard is omitted from a script:If you import the guardless script in another script (e.g. import my_script_without_a_name_eq_main_guard), then the latter script will trigger the former to run at import time and using the second script's command line arguments. This is almost always a mistake.If you have a custom class in the guardless script and save it to a pickle file, then unpickling it in another script will trigger an import of the guardless script, with the same problems outlined in the previous bullet.To better understand why and how this matters, we need to take a step back to understand how Python initializes scripts and how this interacts with its module import mechanism.Whenever the Python interpreter reads a source file, it does two things:it sets a few special variables like __name__, and thenit executes all of the code found in the file.Let's see how this works and how it relates to your question about the __name__ checks we always see in Python scripts.Let's use a slightly different code sample to explore how imports and scripts work.  Suppose the following is in a file called foo.py.When the Python interpreter reads a source file, it first defines a few special variables. In this case, we care about the __name__ variable.When Your Module Is the Main ProgramIf you are running your module (the source file) as the main program, e.g.the interpreter will assign the hard-coded string \"__main__\" to the __name__ variable, i.e.When Your Module Is Imported By AnotherOn the other hand, suppose some other module is the main program and it imports your module. This means there's a statement like this in the main program, or in some other module the main program imports:The interpreter will search for your foo.py file (along with searching for a few other variants), and prior to executing that module, it will assign the name \"foo\" from the import statement to the __name__ variable, i.e.After the special variables are set up, the interpreter executes all the code in the module, one statement at a time. You may want to open another window on the side with the code sample so you can follow along with this explanation.AlwaysIt prints the string \"before import\" (without quotes).It loads the math module and assigns it to a variable called math. This is equivalent to replacing import math with the following (note that __import__ is a low-level function in Python that takes a string and triggers the actual import):It prints the string \"before function_a\".It executes the def block, creating a function object, then assigning that function object to a variable called function_a.It prints the string \"before function_b\".It executes the second def block, creating another function object, then assigning it to a variable called function_b.It prints the string \"before __name__ guard\".Only When Your Module Is the Main ProgramOnly When Your Module Is Imported by AnotherAlwaysSummaryIn summary, here's what'd be printed in the two cases:You might naturally wonder why anybody would want this.  Well, sometimes you want to write a .py file that can be both used by other programs and/or modules as a module, and can also be run as the main program itself.  Examples:Your module is a library, but you want to have a script mode where it runs some unit tests or a demo.Your module is only used as a main program, but it has some unit tests, and the testing framework works by importing .py files like your script and running special test functions. You don't want it to try running the script just because it's importing the module.Your module is mostly used as a main program, but it also provides a programmer-friendly API for advanced users.Beyond those examples, it's elegant that running a script in Python is just setting up a few magic variables and importing the script. \"Running\" the script is a side effect of importing the script's module.Question: Can I have multiple __name__ checking blocks?  Answer: it's strange to do so, but the language won't stop you.Suppose the following is in foo2.py.  What happens if you say python foo2.py on the command-line? Why?",
                "When your script is run by passing it as a command to the Python interpreter,all of the code that is at indentation level 0 gets executed.  Functions and classes that are defined are, well, defined, but none of their code gets run.  Unlike other languages, there's no main() function that gets run automatically - the main() function is implicitly all the code at the top level.In this case, the top-level code is an if block.  __name__ is a built-in variable which evaluates to the name of the current module.  However, if a module is being run directly (as in myscript.py above), then __name__ instead is set to the string \"__main__\".  Thus, you can test whether your script is being run directly or being imported by something else by testingIf your script is being imported into another module, its various function and class definitions will be imported and its top-level code will be executed, but the code in the then-body of the if clause above won't get run as the condition is not met. As a basic example, consider the following two scripts:Now, if you invoke the interpreter asThe output will beIf you run two.py instead:You getThus, when module one gets loaded, its __name__ equals \"one\" instead of \"__main__\".",
                "Create the following two files:Now run each file individually.Running python a.py:When a.py is executed, it imports the module b. This causes all the code inside b to run. Python sets globals()['__name__'] in the b module to the module's name, b.Running python b.py:When only the file b.py is executed, Python sets globals()['__name__'] in this file to \"__main__\". Therefore, the if statement evaluates to True this time.",
                "To outline the basics:The global variable, __name__, in the module that is the entry point to your program, is '__main__'. Otherwise, it's the name you import the module by.So, code under the if block will only run if the module is the entry point to your program.It allows the code in the module to be importable by other modules, without executing the code block beneath on import.Why do we need this?Say you're writing a Python script designed to be used as a module:You could test the module by adding this call of the function to the bottom:and running it (on a command prompt) with something like:However, if you want to import the module to another script:On import, the do_important function would be called, so you'd probably comment out your function call, do_important(), at the bottom.And then you'll have to remember whether or not you've commented out your test function call. And this extra complexity would mean you're likely to forget, making your development process more troublesome.The __name__ variable points to the namespace wherever the Python interpreter happens to be at the moment.Inside an imported module, it's the name of that module.But inside the primary module (or an interactive Python session, i.e. the interpreter's Read, Eval, Print Loop, or REPL) you are running everything from its \"__main__\".So if you check before executing:With the above, your code will only execute when you're running it as the primary module (or intentionally call it from another script).There's a Pythonic way to improve on this, though.What if we want to run this business process from outside the module?If we put the code we want to exercise as we develop and test in a function like this and then do our check for '__main__' immediately after:We now have a final function for the end of our module that will run if we run the module as the primary module.It will allow the module and its functions and classes to be imported into other scripts without running the main function, and will also allow the module (and its functions and classes) to be called when running from a different '__main__' module, i.e.This idiom can also be found in the Python documentation in an explanation of the __main__ module. That text states:This module represents the (otherwise anonymous) scope in which the\n  interpreter\u2019s main program executes \u2014 commands read either from\n  standard input, from a script file, or from an interactive prompt. It\n  is this environment in which the idiomatic \u201cconditional script\u201d stanza\n  causes a script to run:",
                "if __name__ == \"__main__\" is the part that runs when the script is run from (say) the command line using a command like python myscript.py.",
                "__name__ is a global variable (in Python, global actually means on the module level) that exists in all namespaces. It is typically the module's name (as a str type).As the only special case, however, in whatever Python process you run, as in mycode.py:the otherwise anonymous global namespace is assigned the value of '__main__' to its __name__.Thus, including the final lineswill cause your script's uniquely defined main function to run.Another benefit of using this construct: you can also import your code as a module in another script and then run the main function if and when your program decides:",
                "There are lots of different takes here on the mechanics of the code in question, the \"How\", but for me none of it made sense until I understood the \"Why\". This should be especially helpful for new programmers.Take file \"ab.py\":And a second file \"xy.py\":What is this code actually doing?When you execute xy.py, you import ab. The import statement runs the module immediately on import, so ab's operations get executed before the remainder of xy's. Once finished with ab, it continues with xy.The interpreter keeps track of which scripts are running with __name__. When you run a script - no matter what you've named it - the interpreter calls it \"__main__\", making it the master or 'home' script that gets returned to after running an external script.Any other script that's called from this \"__main__\" script is assigned its filename as its __name__ (e.g., __name__ == \"ab.py\"). Hence, the line if __name__ == \"__main__\": is the interpreter's test to determine if it's interpreting/parsing the 'home' script that was initially executed, or if it's temporarily peeking into another (external) script. This gives the programmer flexibility to have the script behave differently if it's executed directly vs. called externally.Let's step through the above code to understand what's happening, focusing first on the unindented lines and the order they appear in the scripts. Remember that function - or def - blocks don't do anything by themselves until they're called. What the interpreter might say if mumbled to itself:The bottom two lines mean: \"If this is the \"__main__\" or 'home' script, execute the function called main()\". That's why you'll see a def main(): block up top, which contains the main flow of the script's functionality.Why implement this?Remember what I said earlier about import statements? When you import a module it doesn't just 'recognize' it and wait for further instructions - it actually runs all the executable operations contained within the script. So, putting the meat of your script into the main() function effectively quarantines it, putting it in isolation so that it won't immediately run when imported by another script.Again, there will be exceptions, but common practice is that main() doesn't usually get called externally. So you may be wondering one more thing: if we're not calling main(), why are we calling the script at all? It's because many people structure their scripts with standalone functions that are built to be run independent of the rest of the code in the file. They're then later called somewhere else in the body of the script. Which brings me to this:But the code works without itYes, that's right. These separate functions can be called from an in-line script that's not contained inside a main() function. If you're accustomed (as I am, in my early learning stages of programming) to building in-line scripts that do exactly what you need, and you'll try to figure it out again if you ever need that operation again ... well, you're not used to this kind of internal structure to your code, because it's more complicated to build and it's not as intuitive to read.But that's a script that probably can't have its functions called externally, because if it did it would immediately start calculating and assigning variables. And chances are if you're trying to re-use a function, your new script is related closely enough to the old one that there will be conflicting variables.In splitting out independent functions, you gain the ability to re-use your previous work by calling them into another script. For example, \"example.py\" might import \"xy.py\" and call x(), making use of the 'x' function from \"xy.py\". (Maybe it's capitalizing the third word of a given text string; creating a NumPy array from a list of numbers and squaring them; or detrending a 3D surface. The possibilities are limitless.)(As an aside, this question contains an answer by @kindall that finally helped me to understand - the why, not the how. Unfortunately it's been marked as a duplicate of this one, which I think is a mistake.)",
                "The code under if __name__ == '__main__': will only be executed if the module is invoked as a script.As an example, consider the following module my_test_module.py:First possibility: Import my_test_module.py in another moduleNow if you invoke main.py:Note that only the top-level print() statement in my_test_module is executed.Second possibility: Invoke my_test_module.py as a scriptNow if you run my_test_module.py as a Python script, both print() statements will be executed:For a more comprehensive explanation, you can read What does if __name__ == '__main__' do in Python.",
                "When there are certain statements in our module (M.py) we want to be executed when it'll be running as main (not imported), we can place those statements (test-cases, print statements) under this if block.As by default (when module running as main, not imported) the __name__ variable is set to \"__main__\", and when it'll be imported the __name__ variable will get a different value, most probably the name of the module ('M').\nThis is helpful in running different variants of a modules together, and separating their specific input & output statements and also if there are any test-cases.In short, use this 'if __name__ == \"main\" ' block to prevent (certain) code from being run when the module is imported.",
                "Put simply, __name__ is a variable defined for each script that defines whether the script is being run as the main module or it is being run as an imported module.So if we have two scripts;andThe output from executing script1 isAnd the output from executing script2 is:As you can see, __name__ tells us which code is the 'main' module.\nThis is great, because you can just write code and not have to worry about structural issues like in C/C++, where, if a file does not implement a 'main' function then it cannot be compiled as an executable and if it does, it cannot then be used as a library.Say you write a Python script that does something great and you implement a boatload of functions that are useful for other purposes. If I want to use them I can just import your script and use them without executing your program (given that your code only executes within the  if __name__ == \"__main__\": context). Whereas in C/C++ you would have to portion out those pieces into a separate module that then includes the file. Picture the situation below;The arrows are import links. For three modules each trying to include the previous modules code there are six files (nine, counting the implementation files) and five links. This makes it difficult to include other code into a C project unless it is compiled specifically as a library. Now picture it for Python:You write a module, and if someone wants to use your code they just import it and the __name__ variable can help to separate the executable portion of the program from the library part.",
                "To be short, you need to know several points:import a action actually runs all that can be run in a.py, meaning each line in a.pyBecause of point 1, you may not want everything to be run in a.py when importing itTo solve the problem in point 2, Python allows you to use a condition check__name__ is an implicit variable in all .py modules:The important thing that Python is special at is point 4! The rest is just basic logic.I've been reading so much throughout the answers on this page. I would say, if you know the thing, for sure you will understand those answers, otherwise, you are still confused.",
                "Let's look at the answer in a more abstract way:Suppose we have this code in x.py:Blocks A and B are run when we are running x.py.But just block A (and not B) is run when we are running another module, y.py for example, in which x.py is imported and the code is run from there (like when a function in x.py is called from y.py).",
                "When you run Python interactively the local __name__ variable is assigned a value of __main__. Likewise, when you execute a Python module from the command line, rather than importing it into another module, its __name__ attribute is assigned a value of __main__, rather than the actual name of the module. In this way, modules can look at their own __name__ value to determine for themselves how they are being used, whether as support for another program or as the main application executed from the command line. Thus, the following idiom is quite common in Python modules:",
                "Consider:It checks if the __name__ attribute of the Python script is \"__main__\". In other words, if the program itself is executed, the attribute will be __main__, so the program will be executed (in this case the main() function).However, if your Python script is used by a module, any code outside of the if statement will be executed, so if __name__ == \"__main__\" is used just to check if the program is used as a module or not, and therefore decides whether to run the code.",
                "Before explaining anything about if __name__ == '__main__' it is important to understand what __name__ is and what it does.__name__ is a DunderAlias - can be thought of as a global variable (accessible from modules) and works in a similar way to global.It is a string (global as mentioned above) as indicated by type(__name__) (yielding <class 'str'>), and is an inbuilt standard for both Python 3 and Python 2 versions.It can not only be used in scripts but can also be found in both the interpreter and modules/packages.test_file.py:Resulting in __main__somefile.py:test_file.py:Resulting in somefileNotice that when used in a package or module, __name__ takes the name of the file.  The path of the actual module or package path is not given, but has its own DunderAlias __file__, that allows for this.You should see that, where __name__, where it is the main file (or program) will always return __main__, and if it is a module/package, or anything that is running off some other Python script, will return the name of the file where it has originated from.Being a variable means that it's value can be overwritten (\"can\" does not mean \"should\"), overwriting the value of __name__ will result in a lack of readability.  So do not do it, for any reason.  If you need a variable define a new variable.It is always assumed that the value of __name__ to be __main__ or the name of the file.  Once again changing this default value will cause more confusion that it will do good, causing problems further down the line.It is considered good practice in general to include the if __name__ == '__main__' in scripts.Now we know the behaviour of __name__ things become clearer:An if is a flow control statement that contains the block of code will execute if the value given is true. We have seen that __name__ can take either\n__main__ or the file name it has been imported from.This means that if __name__ is equal to __main__ then the file must be the main file and must actually be running (or it is the interpreter), not a module or package imported into the script.If indeed __name__ does take the value of __main__ then whatever is in that block of code will execute.This tells us that if the file running is the main file (or you are running from the interpreter directly) then that condition must execute.  If it is a package then it should not, and the value will not be __main__.__name__ can also be used in modules to define the name of a moduleIt is also possible to do other, less common but useful things with __name__, some I will show here:You can also use it to provide runnable help functions/utilities on packages and modules without the elaborate use of libraries.It also allows modules to be run from the command line as main scripts, which can be also very useful.",
                "I think it's best to break the answer in depth and in simple words:__name__: Every module in Python has a special attribute called __name__.\nIt is a built-in variable that returns the name of the module.__main__: Like other programming languages, Python too has an execution entry point, i.e., main. '__main__' is the name of the scope in which top-level code executes. Basically you have two ways of using a Python module: Run it directly as a script, or import it. When a module is run as a script, its __name__ is set to __main__.Thus, the value of the __name__ attribute is set to __main__ when the module is run as the main program. Otherwise the value of __name__  is set to contain the name of the module.",
                "It is a special for when a Python file is called from the command line. This is typically used to call a \"main()\" function or execute other appropriate startup code, like commandline arguments handling for instance.It could be written in several ways. Another is:I am not saying you should use this in production code, but it serves to illustrate that there is nothing \"magical\" about if __name__ == '__main__'.It just a convention for invoking a main function in Python files.",
                "There are a number of variables that the system (Python interpreter) provides for source files (modules).  You can get their values anytime you want, so, let us focus on the __name__ variable/attribute:When Python loads a source code file, it executes all of the code found in it. (Note that it doesn't call all of the methods and functions defined in the file, but it does define them.)Before the interpreter executes the source code file though, it defines a few special variables for that file; __name__ is one of those special variables that Python automatically defines for each source code file.If Python is loading this source code file as the main program (i.e. the file you run), then it sets the special __name__ variable for this file to have a value \"__main__\".If this is being imported from another module, __name__ will be set to that module's name.So, in your example in part:means that the code block:will be executed only when you run the module directly; the code block will not execute if another module is calling/importing it because the value of __name__ will not equal to \"main\" in that particular instance.Hope this helps out.",
                "if __name__ == \"__main__\": is basically the top-level script environment, and it specifies the interpreter that ('I have the highest priority to be executed first').'__main__' is the name of the scope in which top-level code executes. A module\u2019s __name__ is set equal to '__main__' when read from standard input, a script, or from an interactive prompt.",
                "Consider:The output for the above is __main__.The above statement is true and prints \"direct method\". Suppose if they imported this class in another class it doesn't print \"direct method\" because, while importing, it will set __name__ equal to \"first model name\".",
                "In simple words:The code you see under if __name__ == \"__main__\": will only get called upon when your Python file is executed as python example1.pyHowever, if you wish to import your Python file example1.py as a module to work with another Python file, say example2.py, the code under if __name__ == \"__main__\": will not run or take any effect.",
                "You can make the file usable as a script as well as an importable module.fibo.py (a module named fibo)Reference: https://docs.python.org/3.5/tutorial/modules.html",
                "The reason foris primarily to avoid the import lock problems that would arise from having code directly imported. You want main() to run if your file was directly invoked (that's the __name__ == \"__main__\" case), but if your code was imported then the importer has to enter your code from the true main module to avoid import lock problems.A side-effect is that you automatically sign on to a methodology that supports multiple entry points. You can run your program using main() as the entry point, but you don't have to. While setup.py expects main(), other tools use alternate entry points. For example, to run your file as a gunicorn process, you define an app() function instead of a main(). Just as with setup.py, gunicorn imports your code so you don't want it do do anything while it's being imported (because of the import lock issue).",
                "If you are a beginner, probably the only answer you need right now is that this code is unnecessary for a simple script. It is only useful if you want to be able to import your script (or unpickle etc; see the other answers here for some other non-beginner scenarios).In slightly different words, the if __name__ guard is a mechanism for hiding code from other code. If you don't have a specific reason to hide something, don't: If you don't need to hide some code from import, don't put it behind this guard, and if you do, hide as little as possible.In slightly more detail, let's say you have a simple script fib.py (adapted from this answer):Now, if you simply run python fib.py it works fine. But __name__ will always be \"__main__\" in this scenario, so the condition is actually unnecessary. The script could be simplified to justNow, you can't import fib with the new version, but if you didn't plan to do that in the first place, this version is actually better, because it's simpler and clearer.If you do want to be able to import fib, the first version is useless, too, because the useful code is in a section which will not run when you import this file (in which case __name__ will not be \"__main__\"). The proper design in that case would be to refactor the code so that the useful parts are in a function you can run when you want to after you have imported it.Now, if you import fib, the call to main() will not be executed; but when you run python fib.py, it will.Actually, a better design still would be to isolate the reusable part (the actual calculation) from the user-visible input/output:Now, you can from fib import fibn and call the fibn() function from the code which performs this import.(I called the function fibn() just to make it clearer what is what in this example. In real life, you might call it fib() and do from fib import fib.)Similarly, you could import and call the main function if you wanted to reuse it.Returning to the code in the question, I would similarly move the code from the if into a function as well, so that callers can invoke that function if they want to.This changes the scope of the lock variable; if the surrounding code needs access to it, you will need to make it global (or, perhaps, better, refactor main to return lock, and have the caller capture the value in a local variable of its own).(Unlike in languages like C, the name main has no specific meaning to Python; but it's a common convention to use it as the name of the thing which will be run. You still have to actually explicitly call it, like main(), unlike in C.)",
                "Every module in Python has an attribute called __name__. The value of __name__  attribute is  __main__ when the module is run directly, like python my_module.py. Otherwise (like when you say import my_module) the value of __name__  is the name of the module.Small example to explain in short.We can execute this directly asOutputNow suppose we call the above script from another script:When you execute this,OutputSo, the above is self-explanatory that when you call test from another script, if loop __name__ in test.py will not execute.",
                "This answer is for Java programmers learning Python.\nEvery Java file typically contains one public class. You can use that class in two ways:Call the class from other files. You just have to import it in the calling program.Run the class stand alone, for testing purposes.For the latter case, the class should contain a public static void main() method. In Python this purpose is served by the globally defined label '__main__'.",
                "If this .py file are imported by other .py files, the code under the if statement will not be executed.If this .py are run by python this_py.py under shell, or double clicked in Windows. the code under the if statement will be executed.It is usually written for testing.",
                "We see if __name__ == '__main__': quite often.It checks if a module is being imported or not.In other words, the code within the if block will be executed only when the code runs directly. Here directly means not imported.Let's see what it does using a simple code that prints the name of the module:If we run the code directly via python test.py, the module name is __main__:",
                "If the Python interpreter is running a particular module then the __name__ global variable will have the value \"__main__\":When you run this script, it prints:If you import this file, say A to file B, and execute the file B then if __name__ == \"__main__\" in file A becomes False, so it prints:",
                "All the answers have pretty much explained the functionality. But I will provide one example of its usage which might help clearing out the concept further.Assume that you have two Python files, a.py and b.py. Now, a.py imports b.py. We run the a.py file, where the import b.py code is executed first. Before the rest of the a.py code runs, the code in the file b.py must run completely.In the b.py code, there is some code that is exclusive to that file b.py and we don't want any other file (other than the b.py file), that has imported the b.py file, to run it.So that is what this line of code checks. If it is the main file (i.e., b.py) running the code, which in this case it is not (a.py is the main file running), then only the code gets executed."
            ]
        },
        {
            "tag": "python",
            "question": [
                "Does Python have a ternary conditional operator?",
                "Is there a ternary conditional operator in Python?"
            ],
            "url": "https://stackoverflow.com/questions/394809",
            "answer": [
                "Yes, it was added in version 2.5. The expression syntax is:First condition is evaluated, then exactly one of either a or b is evaluated and returned based on the Boolean value of condition. If condition evaluates to True, then a is evaluated and returned but b is ignored, or else when b is evaluated and returned but a is ignored.This allows short-circuiting because when condition is true only a is evaluated and b is not evaluated at all, but when condition is false only b is evaluated and a is not evaluated at all.For example:Note that conditionals are an expression, not a statement. This means you can't use statements such as pass, or assignments with = (or \"augmented\" assignments like +=), within a conditional expression:(In 3.8 and above, the := \"walrus\" operator allows simple assignment of values as an expression, which is then compatible with this syntax. But please don't write code like that; it will quickly become very difficult to understand.)Similarly, because it is an expression, the else part is mandatory:You can, however, use conditional expressions to assign a variable like so:Or for example to return a value:Think of the conditional expression as switching between two values. We can use it when we are in a 'one value or another' situation, where we will do the same thing with the result, regardless of whether the condition is met. We use the expression to compute the value, and then do something with it. If you need to do something different depending on the condition, then use a normal if statement instead.Keep in mind that it's frowned upon by some Pythonistas for several reasons:If you're having trouble remembering the order, then remember that when read aloud, you (almost) say what you mean. For example, x = 4 if b > 8 else 9 is read aloud as x will be 4 if b is greater than 8 otherwise 9.Official documentation:",
                "You can index into a tuple:test needs to return True or False.\nIt might be safer to always implement it as:or you can use the built-in bool() to assure a Boolean value:",
                "For versions prior to 2.5, there's the trick:It can give wrong results when on_true has a false Boolean value.1Although it does have the benefit of evaluating expressions left to right, which is clearer in my opinion.1. Is there an equivalent of C\u2019s \u201d?:\u201d ternary operator?",
                "<expression 1> if <condition> else <expression 2>",
                "From the documentation:Conditional expressions (sometimes called a \u201cternary operator\u201d) have the lowest priority of all Python operations.The expression x if C else y first evaluates the condition, C (not x); if C is true, x is evaluated and its value is returned; otherwise, y is evaluated and its value is returned.See PEP 308 for more details about conditional expressions.New since version 2.5.",
                "An operator for a conditional expression in Python was added in 2006 as part of Python Enhancement Proposal 308. Its form differ from common ?: operator and it's:which is equivalent to:Here is an example:Another syntax which can be used (compatible with versions before 2.5):where operands are lazily evaluated.Another way is by indexing a tuple (which isn't consistent with the conditional operator of most other languages):or explicitly constructed dictionary:Another (less reliable), but simpler method is to use and and or operators:however this won't work if x would be False.A possible workaround is to make x and y lists or tuples as in the following:or:If you're working with dictionaries, instead of using a ternary conditional, you can take advantage of get(key, default), for example:Source: ?: in Python at Wikipedia",
                "Unfortunately, thesolution doesn't have short-circuit behaviour; thus both falseValue and trueValue are evaluated regardless of the condition. This could be suboptimal or even buggy (i.e. both trueValue and falseValue could be methods and have side effects).One solution to this would be(execution delayed until the winner is known ;)), but it introduces inconsistency between callable and non-callable objects. In addition, it doesn't solve the case when using properties.And so the story goes - choosing between three mentioned solutions is a trade-off between having the short-circuit feature, using at least Python 2.5 (IMHO, not a problem anymore) and not being prone to \"trueValue-evaluates-to-false\" errors.",
                "Here I just try to show some important differences in the ternary operator between a couple of programming languages.",
                "For Python 2.5 and newer there is a specific syntax:In older Pythons a ternary operator is not implemented but it's possible to simulate it.Though, there is a potential problem, which if cond evaluates to True and on_true evaluates to False then on_false is returned instead of on_true. If you want this behavior the method is OK, otherwise use this:which can be wrapped by:and used this way:It is compatible with all Python versions.",
                "You might often findbut this leads to a problem when on_true == 0Where you would expect this result for a normal ternary operator:",
                "Yes. From the grammar file:The part of interest is:So, a ternary conditional operation is of the form:expression3 will be lazily evaluated (that is, evaluated only if expression2 is false in a boolean context). And because of the recursive definition, you can chain them indefinitely (though it may considered bad style.)Note that every if must be followed with an else. People learning list comprehensions and generator expressions may find this to be a difficult lesson to learn - the following will not work, as Python expects a third expression for an else:which raises a SyntaxError: invalid syntax.\nSo the above is either an incomplete piece of logic (perhaps the user expects a no-op in the false condition) or what may be intended is to use expression2 as a filter - notes that the following is legal Python:expression2 works as a filter for the list comprehension, and is not a ternary conditional operator.You may find it somewhat painful to write the following:expression1 will have to be evaluated twice with the above usage. It can limit redundancy if it is simply a local variable. However, a common and performant Pythonic idiom for this use-case is to use or's shortcutting behavior:which is equivalent in semantics. Note that some style-guides may limit this usage on the grounds of clarity - it does pack a lot of meaning into very little syntax.",
                "One of the alternatives to Python's conditional expressionis the following:which has the following nice extension:The shortest alternative remainswhich works because issubclass(bool, int).Careful, though: the alternative tois notbutThis works fine as long as no and yes are to be called with exactly the same parameters. If they are not, like inor inthen a similar alternative either does not exist (1) or is hardly viable (2). (In rare cases, depending on the context, something likecould make sense.)Thanks to Radek Roj\u00edk for his comment",
                "As already answered, yes, there is a ternary operator in Python:In many cases <expression 1> is also used as Boolean evaluated <condition>. Then you can use short-circuit evaluation.One big pro of short-circuit evaluation is the possibility of chaining more than two expressions:When working with functions it is more different in detail:PS: Of course, a short-circuit evaluation is not a ternary operator, but often the ternary is used in cases where the short circuit would be enough. It has a better readability and can be chained.",
                "Simulating the Python ternary operator.For exampleOutput:",
                "Just memorize this pyramid if you have trouble remembering:",
                "The ternary conditional operator simply allows testing a condition in a single line replacing the multiline if-else making the code compact.[on_true] if [expression] else [on_false]Above approach can be written as:",
                "Vinko Vrsalovic's answer is good enough. There is only one more thing:Note that conditionals are an expression, not a statement. This means you can't use assignment statements or pass or other statements within a conditional expressionAfter the walrus operator was introduced in Python 3.8, something changed.gives a = 3 and b is not defined,gives a is not defined and b = 5, andgives c = 5, a is not defined and b = 5.Even if this may be ugly, assignments can be done inside conditional expressions after Python 3.8. Anyway, it is still better to use normal if statement instead in this case.",
                "More a tip than an answer (I don't need to repeat the obvious for the hundredth time), but I sometimes use it as a one-liner shortcut in such constructs:, becomes:Some (many :) may frown upon it as unpythonic (even, Ruby-ish :), but I personally find it more natural - i.e., how you'd express it normally, plus a bit more visually appealing in large blocks of code.",
                "You can do this:Example:This would print \"odd\" if the number is odd or \"even\" if the number is even.The result: If condition is true, exp_1 is executed, else exp_2 is executed.Note: 0, None, False, emptylist, and emptyString evaluates as False.And any data other than 0 evaluates to True.If the condition [condition] becomes \"True\", then expression_1 will be evaluated, but not expression_2.If we \"and\" something with 0 (zero), the result will always to be false. So in the below statement,The expression exp won't be evaluated at all since \"and\" with 0 will always evaluate to zero and there is no need to evaluate the expression. This is how the compiler itself works, in all languages.Inthe expression exp won't be evaluated at all since \"or\" with 1 will always be 1. So it won't bother to evaluate the expression exp since the result will be 1 anyway (compiler optimization methods).But in case ofThe second expression exp2 won't be evaluated since True and exp1 would be True when exp1 isn't false.Similarly inThe expression exp1 won't be evaluated since False is equivalent to writing 0 and doing \"and\" with 0 would be 0 itself, but after exp1 since \"or\" is used, it will evaluate the expression exp2 after \"or\".Note:- This kind of branching using \"or\" and \"and\" can only be used when the expression_1 doesn't have a Truth value of False (or 0 or None or emptylist [ ] or emptystring ' '.) since if expression_1 becomes False, then the expression_2 will be evaluated because of the presence \"or\" between exp_1 and exp_2.In case you still want to make it work for all the cases regardless of what exp_1 and exp_2 truth values are, do this:",
                "Many programming languages derived from C usually have the following syntax of the ternary conditional operator:At first, the Python's benevolent dictator for life (I mean Guido van Rossum, of course) rejected it (as non-Pythonic style), since it's quite hard to understand for people not used to C language. Also, the colon sign : already has many uses in Python. After PEP 308 was approved, Python finally received its own shortcut conditional expression (what we use now):So, firstly it evaluates the condition. If it returns True, expression1 will be evaluated to give the result, otherwise expression2 will be evaluated. Due to lazy evaluation mechanics \u2013 only one expression will be executed.Here are some examples (conditions will be evaluated from left to right):Ternary operators can be chained in series:The following one is the same as previous one:",
                "Yes, Python have a ternary operator, here is the syntax and an example code to demonstrate the same :)",
                "Other answers correctly talk about the Python ternary operator. I would like to complement by mentioning a scenario for which the ternary operator is often used, but for which there is a better idiom. This is the scenario of using a default value.Suppose we want to use option_value with a default value if it is not set:or, if option_value is never set to a falsy value (0, \"\", etc.), simplyHowever, in this case an ever better solution is simply to write",
                "The syntax for the ternary operator in Python is:[on_true] if [expression] else [on_false]Using that syntax, here is how we would rewrite the code above using Python\u2019s ternary operator:It's still pretty clear, but much shorter. Note that the expression could be any type of expression, including a function call, that returns a value that evaluates to True or False.",
                "Python has a ternary form for assignments; however there may be even a shorter form that people should be aware of.It's very common to need to assign to a variable one value or another depending on a condition.^ This is the long form for doing such assignments.Below is the ternary form. But this isn't the most succinct way - see the last example.With Python, you can simply use or for alternative assignments.The above works since li1 is None and the interpreter treats that as False in logic expressions. The interpreter then moves on and evaluates the second expression, which is not None and it's not an empty list - so it gets assigned to a.This also works with empty lists. For instance, if you want to assign a whichever list has items.Knowing this, you can simply such assignments whenever you encounter them. This also works with strings and other iterables. You could assign a whichever string isn't empty.I always liked the C ternary syntax, but Python takes it a step further!I understand that some may say this isn't a good stylistic choice, because it relies on mechanics that aren't immediately apparent to all developers. I personally disagree with that viewpoint. Python is a syntax-rich language with lots of idiomatic tricks that aren't immediately apparent to the dabbler. But the more you learn and understand the mechanics of the underlying system, the more you appreciate it.",
                "Pythonic way of doing the things:But there always exists a different way of doing a ternary condition too:",
                "There are multiple ways. The simplest one is to use the condition inside the \"print\" method.You can useWhich is equivalent to:In this way, more than two statements are also possible to print. For example:can be written as:",
                "The if else-if version can be written as:",
                "Yes, it has, but it's different from C-syntax-like programming languages (which is condition ? value_if_true : value_if_falseIn Python, it goes like this: value_if_true if condition else value_if_falseExample: even_or_odd = \"even\" if x % 2 == 0 else \"odd\"",
                "A neat way to chain multiple operators:",
                "I find the default Python syntax val = a if cond else b cumbersome, so sometimes I do this:Of course, it has the downside of always evaluating both sides (a and b), but the syntax is way clearer to me."
            ]
        },
        {
            "tag": "python",
            "question": [
                "What are metaclasses in Python?",
                "What are metaclasses? What are they used for?"
            ],
            "url": "https://stackoverflow.com/questions/100003",
            "answer": [
                "Before understanding metaclasses, you need to master classes in Python. And Python has a very peculiar idea of what classes are, borrowed from the Smalltalk language.In most languages, classes are just pieces of code that describe how to produce an object. That's kinda true in Python too:But classes are more than that in Python. Classes are objects too.Yes, objects.As soon as you use the keyword class, Python executes it and creates\nan object. The instructioncreates in memory an object with the name ObjectCreator.This object (the class) is itself capable of creating objects (the instances),\nand this is why it's a class.But still, it's an object, and therefore:e.g.:Since classes are objects, you can create them on the fly, like any object.First, you can create a class in a function using class:But it's not so dynamic, since you still have to write the whole class yourself.Since classes are objects, they must be generated by something.When you use the class keyword, Python creates this object automatically. But as\nwith most things in Python, it gives you a way to do it manually.Remember the function type? The good old function that lets you know what\ntype an object is:Well, type has also a completely different ability: it can create classes on the fly. type can take the description of a class as parameters,\nand return a class.(I  know, it's silly that the same function can have two completely different uses according to the parameters you pass to it. It's an issue due to backward\ncompatibility in Python)type works this way:Where:e.g.:can be created manually this way:You'll notice that we use MyShinyClass as the name of the class\nand as the variable to hold the class reference. They can be different,\nbut there is no reason to complicate things.type accepts a dictionary to define the attributes of the class. So:Can be translated to:And used as a normal class:And of course, you can inherit from it, so:would be:Eventually, you'll want to add methods to your class. Just define a function\nwith the proper signature and assign it as an attribute.And you can add even more methods after you dynamically create the class, just like adding methods to a normally created class object.You see where we are going: in Python, classes are objects, and you can create a class on the fly, dynamically.This is what Python does when you use the keyword class, and it does so by using a metaclass.Metaclasses are the 'stuff' that creates classes.You define classes in order to create objects, right?But we learned that Python classes are objects.Well, metaclasses are what create these objects. They are the classes' classes,\nyou can picture them this way:You've seen that type lets you do something like this:It's because the function type is in fact a metaclass. type is the\nmetaclass Python uses to create all classes behind the scenes.Now you wonder \"why the heck is it written in lowercase, and not Type?\"Well, I guess it's a matter of consistency with str, the class that creates\nstrings objects, and int the class that creates integer objects. type is\njust the class that creates class objects.You see that by checking the __class__ attribute.Everything, and I mean everything, is an object in Python. That includes integers,\nstrings, functions and classes. All of them are objects. And all of them have\nbeen created from a class:Now, what is the __class__ of any __class__ ?So, a metaclass is just the stuff that creates class objects.You can call it a 'class factory' if you wish.type is the built-in metaclass Python uses, but of course, you can create your\nown metaclass.In Python 2, you can add a __metaclass__ attribute when you write a class (see next section for the Python 3 syntax):If you do so, Python will use the metaclass to create the class Foo.Careful, it's tricky.You write class Foo(object) first, but the class object Foo is not created\nin memory yet.Python will look for __metaclass__ in the class definition. If it finds it,\nit will use it to create the object class Foo. If it doesn't, it will use\ntype to create the class.Read that several times.When you do:Python does the following:Is there a __metaclass__ attribute in Foo?If yes, create in-memory a class object (I said a class object, stay with me here), with the name Foo by using what is in __metaclass__.If Python can't find __metaclass__, it will look for a __metaclass__ at the MODULE level, and try to do the same (but only for classes that don't inherit anything, basically old-style classes).Then if it can't find any __metaclass__ at all, it will use the Bar's (the first parent) own metaclass (which might be the default type) to create the class object.Be careful here that the __metaclass__ attribute will not be inherited, the metaclass of the parent (Bar.__class__) will be. If Bar used a __metaclass__ attribute that created Bar with type() (and not type.__new__()), the subclasses will not inherit that behavior.Now the big question is, what can you put in __metaclass__?The answer is something that can create a class.And what can create a class? type, or anything that subclasses or uses it.The syntax to set the metaclass has been changed in Python 3:i.e. the __metaclass__ attribute is no longer used, in favor of a keyword argument in the list of base classes.The behavior of metaclasses however stays largely the same.One thing added to metaclasses in Python 3 is that you can also pass attributes as keyword-arguments into a metaclass, like so:Read the section below for how Python handles this.The main purpose of a metaclass is to change the class automatically,\nwhen it's created.You usually do this for APIs, where you want to create classes matching the\ncurrent context.Imagine a stupid example, where you decide that all classes in your module\nshould have their attributes written in uppercase. There are several ways to\ndo this, but one way is to set __metaclass__ at the module level.This way, all classes of this module will be created using this metaclass,\nand we just have to tell the metaclass to turn all attributes to uppercase.Luckily, __metaclass__ can actually be any callable, it doesn't need to be a\nformal class (I know, something with 'class' in its name doesn't need to be\na class, go figure... but it's helpful).So we will start with a simple example, by using a function.Let's check:Now, let's do exactly the same, but using a real class for a metaclass:Let's rewrite the above, but with shorter and more realistic variable names now that we know what they mean:You may have noticed the extra argument cls. There is\nnothing special about it: __new__ always receives the class it's defined in, as the first parameter. Just like you have self for ordinary methods which receive the instance as the first parameter, or the defining class for class methods.But this is not proper OOP. We are calling type directly and we aren't overriding or calling the parent's __new__. Let's do that instead:We can make it even cleaner by using super, which will ease inheritance (because yes, you can have metaclasses, inheriting from metaclasses, inheriting from type):Oh, and in Python 3 if you do this call with keyword arguments, like this:It translates to this in the metaclass to use it:That's it. There is really nothing more about metaclasses.The reason behind the complexity of the code using metaclasses is not because\nof metaclasses, it's because you usually use metaclasses to do twisted stuff\nrelying on introspection, manipulating inheritance, vars such as __dict__, etc.Indeed, metaclasses are especially useful to do black magic, and therefore\ncomplicated stuff. But by themselves, they are simple:Since __metaclass__ can accept any callable, why would you use a class\nsince it's obviously more complicated?There are several reasons to do so:Now the big question. Why would you use some obscure error-prone feature?Well, usually you don't:Metaclasses are deeper magic that\n99% of users should never worry about it.\nIf you wonder whether you need them,\nyou don't (the people who actually\nneed them know with certainty that\nthey need them, and don't need an\nexplanation about why).Python Guru Tim PetersThe main use case for a metaclass is creating an API. A typical example of this is the Django ORM. It allows you to define something like this:But if you do this:It won't return an IntegerField object. It will return an int, and can even take it directly from the database.This is possible because models.Model defines __metaclass__ and\nit uses some magic that will turn the Person you just defined with simple statements\ninto a complex hook to a database field.Django makes something complex look simple by exposing a simple API\nand using metaclasses, recreating code from this API to do the real job\nbehind the scenes.First, you know that classes are objects that can create instances.Well, in fact, classes are themselves instances. Of metaclasses.Everything is an object in Python, and they are all either instance of classes\nor instances of metaclasses.Except for type.type is actually its own metaclass. This is not something you could\nreproduce in pure Python, and is done by cheating a little bit at the implementation\nlevel.Secondly, metaclasses are complicated. You may not want to use them for\nvery simple class alterations. You can change classes by using two different techniques:99% of the time you need class alteration, you are better off using these.But 98% of the time, you don't need class alteration at all.",
                "A metaclass is the class of a class. A class defines how an instance of the class (i.e. an object) behaves while a metaclass defines how a class behaves. A class is an instance of a metaclass.While in Python you can use arbitrary callables for metaclasses (like Jerub shows), the better approach is to make it an actual class itself. type is the usual metaclass in Python. type is itself a class, and it is its own type. You won't be able to recreate something like type purely in Python, but Python cheats a little. To create your own metaclass in Python you really just want to subclass type.A metaclass is most commonly used as a class-factory. When you create an object by calling the class, Python creates a new class (when it executes the 'class' statement) by calling the metaclass. Combined with the normal __init__ and __new__ methods, metaclasses therefore allow you to do 'extra things' when creating a class, like registering the new class with some registry or replace the class with something else entirely.When the class statement is executed, Python first executes the body of the class statement as a normal block of code. The resulting namespace (a dict) holds the attributes of the class-to-be. The metaclass is determined by looking at the baseclasses of the class-to-be (metaclasses are inherited), at the __metaclass__ attribute of the class-to-be (if any) or the __metaclass__ global variable. The metaclass is then called with the name, bases and attributes of the class to instantiate it.However, metaclasses actually define the type of a class, not just a factory for it, so you can do much more with them. You can, for instance, define normal methods on the metaclass. These metaclass-methods are like classmethods in that they can be called on the class without an instance, but they are also not like classmethods in that they cannot be called on an instance of the class. type.__subclasses__() is an example of a method on the type metaclass. You can also define the normal 'magic' methods, like __add__, __iter__ and __getattr__, to implement or change how the class behaves.Here's an aggregated example of the bits and pieces:",
                "Note, this answer is for Python 2.x as it was written in 2008, metaclasses are slightly different in 3.x.Metaclasses are the secret sauce that make 'class' work. The default metaclass for a new style object is called 'type'.Metaclasses take 3 args. 'name', 'bases' and 'dict'Here is where the secret starts. Look for where name, bases and the dict come from in this example class definition.Lets define a metaclass that will demonstrate how 'class:' calls it.And now, an example that actually means something, this will automatically make the variables in the list \"attributes\" set on the class, and set to None.Note that the magic behaviour that Initialised gains by having the metaclass init_attributes is not passed onto a subclass of Initialised.Here is an even more concrete example, showing how you can subclass 'type' to make a metaclass that performs an action when the class is created. This is quite tricky:",
                "Others have explained how metaclasses work and how they fit into the Python type system. Here's an example of what they can be used for. In a testing framework I wrote, I wanted to keep track of the order in which classes were defined, so that I could later instantiate them in this order. I found it easiest to do this using a metaclass.Anything that's a subclass of MyType then gets a class attribute _order that records the order in which the classes were defined.",
                "One use for metaclasses is adding new properties and methods to an instance automatically.For example, if you look at Django models, their definition looks a bit confusing. It looks as if you are only defining class properties:However, at runtime the Person objects are filled with all sorts of useful methods. See the source for some amazing metaclassery.",
                "I think the ONLamp introduction to metaclass programming is well written and gives a really good introduction to the topic despite being several years old already.http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html (archived at https://web.archive.org/web/20080206005253/http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html)In short: A class is a blueprint for the creation of an instance, a metaclass is a blueprint for the creation of a class. It can be easily seen that in Python classes need to be first-class objects too to enable this behavior.I've never written one myself, but I think one of the nicest uses of metaclasses can be seen in the Django framework. The model classes use a metaclass approach to enable a declarative style of writing new models or form classes. While the metaclass is creating the class, all members get the possibility to customize the class itself.The thing that's left to say is: If you don't know what metaclasses are, the probability that you will not need them is 99%.",
                "TLDR: A metaclass instantiates and defines behavior for a class just like a class instantiates and defines behavior for an instance.Pseudocode:The above should look familiar. Well, where does Class come from? It's an instance of a metaclass (also pseudocode):In real code, we can pass the default metaclass, type, everything we need to instantiate a class and we get a class:A class is to an instance as a metaclass is to a class.When we instantiate an object, we get an instance:Likewise, when we define a class explicitly with the default metaclass, type, we instantiate it:Put another way, a class is an instance of a metaclass:Put a third way, a metaclass is a class's class.When you write a class definition and Python executes it, it uses a metaclass to instantiate the class object (which will, in turn, be used to instantiate instances of that class).Just as we can use class definitions to change how custom object instances behave, we can use a metaclass class definition to change the way a class object behaves.What can they be used for? From the docs:The potential uses for metaclasses are boundless. Some ideas that have been explored include logging, interface checking, automatic delegation, automatic property creation, proxies, frameworks, and automatic resource locking/synchronization.Nevertheless, it is usually encouraged for users to avoid using metaclasses unless absolutely necessary.When you write a class definition, for example, like this,You instantiate a class object.It is the same as functionally calling type with the appropriate arguments and assigning the result to a variable of that name:Note, some things automatically get added to the __dict__, i.e., the namespace:The metaclass of the object we created, in both cases, is type.(A side-note on the contents of the class __dict__: __module__ is there because classes must know where they are defined, and  __dict__ and __weakref__ are there because we don't define __slots__ - if we define __slots__ we'll save a bit of space in the instances, as we can disallow __dict__ and __weakref__ by excluding them. For example:... but I digress.)Here's the default __repr__ of classes:One of the most valuable things we can do by default in writing a Python object is to provide it with a good __repr__. When we call help(repr) we learn that there's a good test for a __repr__ that also requires a test for equality - obj == eval(repr(obj)). The following simple implementation of __repr__ and __eq__ for class instances of our type class provides us with a demonstration that may improve on the default __repr__ of classes:So now when we create an object with this metaclass, the __repr__ echoed on the command line provides a much less ugly sight than the default:With a nice __repr__ defined for the class instance, we have a stronger ability to debug our code. However, much further checking with eval(repr(Class)) is unlikely (as functions would be rather impossible to eval from their default __repr__'s).If, for example, we want to know in what order a class's methods are created in, we could provide an ordered dict as the namespace of the class. We would do this with __prepare__ which returns the namespace dict for the class if it is implemented in Python 3:And usage:And now we have a record of the order in which these methods (and other class attributes) were created:Note, this example was adapted from the documentation - the new enum in the standard library does this.So what we did was instantiate a metaclass by creating a class. We can also treat the metaclass as we would any other class. It has a method resolution order:And it has approximately the correct repr (which we can no longer eval unless we can find a way to represent our functions.):",
                "Python 3 updateThere are (at this point) two key methods in a metaclass:__prepare__ lets you supply a custom mapping (such as an OrderedDict) to be used as the namespace while the class is being created.  You must return an instance of whatever namespace you choose.  If you don't implement __prepare__ a normal dict is used.__new__ is responsible for the actual creation/modification of the final class.A bare-bones, do-nothing-extra metaclass would like:A simple example:Say you want some simple validation code to run on your attributes -- like it must always be an int or a str.  Without a metaclass, your class would look something like:As you can see, you have to repeat the name of the attribute twice.  This makes typos possible along with irritating bugs.A simple metaclass can address that problem:This is what the metaclass would look like (not using __prepare__ since it is not needed):A sample run of:produces:Note:  This example is simple enough it could have also been accomplished with a class decorator, but presumably an actual metaclass would be doing much more.The 'ValidateType' class for reference:",
                "If you've done Python programming for more than a few months you'll eventually stumble upon code that looks like this:The latter is possible when you implement the __call__() magic method on the class.The __call__() method is invoked when an instance of a class is used as a callable. But as we've seen from previous answers a class itself is an instance of a metaclass, so when we use the class as a callable (i.e. when we create an instance of it) we're actually calling its metaclass' __call__() method. At this point most Python programmers are a bit confused because they've been told that when creating an instance like this instance = SomeClass() you're calling its __init__() method. Some who've dug a bit deeper know that before __init__() there's __new__(). Well, today another layer of truth is being revealed, before __new__() there's the metaclass' __call__().Let's study the method call chain from specifically the perspective of creating an instance of a class.This is a metaclass that logs exactly the moment before an instance is created and the moment it's about to return it.This is a class that uses that metaclassAnd now let's create an instance of Class_1Observe that the code above doesn't actually do anything more than logging the tasks. Each method delegates the actual work to its parent's implementation, thus keeping the default behavior. Since type is Meta_1's parent class (type being the default parent metaclass) and considering the ordering sequence of the output above, we now have a clue as to what would be the pseudo implementation of type.__call__():We can see that the metaclass' __call__() method is the one that's called first. It then delegates creation of the instance to the class's __new__() method and initialization to the instance's __init__(). It's also the one that ultimately returns the instance.From the above it stems that the metaclass' __call__() is also given the opportunity to decide whether or not a call to Class_1.__new__() or Class_1.__init__() will eventually be made. Over the course of its execution it could actually return an object that hasn't been touched by either of these methods. Take for example this approach to the singleton pattern:Let's observe what happens when repeatedly trying to create an object of type Class_2",
                "A metaclass is a class that tells how (some) other class should be created.This is a case where I saw metaclass as a solution to my problem:\nI had a really complicated problem, that probably could have been solved differently, but I chose to solve it using a metaclass.  Because of the complexity, it is one of the few modules I have written where the comments in the module surpass the amount of code that has been written.  Here it is...",
                "The type(obj) function gets you the type of an object.The type() of a class is its metaclass.To use a metaclass:type is its own metaclass. The class of a class is a metaclass-- the body of a class is the arguments passed to the metaclass that is used to construct the class.Here you can read about how to use metaclasses to customize class construction.",
                "type is actually a metaclass -- a class that creates another classes.\nMost metaclass are the subclasses of type. The metaclass receives the new class as its first argument and provide access to class object with details as mentioned below:Note:Notice that the class was not instantiated at any time; the simple act of creating the class triggered execution of the metaclass.",
                "Python classes are themselves objects - as in instance - of their meta-class.The default metaclass, which is applied when when you determine classes as:meta class are used to apply some rule to an entire set of classes. For example, suppose you're building an ORM to access a database, and you want records from each table to be of a class mapped to that table (based on fields, business rules, etc..,), a possible use of metaclass is for instance, connection pool logic, which is share by all classes of record from all tables. Another use is logic to to support foreign keys, which involves multiple classes of records.when you define metaclass, you subclass type, and can overrided the following magic methods to insert your logic.anyhow, those two are the most commonly used hooks. metaclassing is powerful, and above is nowhere near and exhaustive list of uses for metaclassing.",
                "The type() function can return the type of an object or create a new type,for example, we can create a Hi class with the type() function and do not  need to use this way with class Hi(object):In addition to using type() to create classes dynamically, you can control creation behavior of class and use metaclass.According to the Python object model, the class is the object, so the class must be an instance of another certain class.\nBy default, a Python class is instance of the type class. That is, type is metaclass of most of the built-in classes and metaclass of user-defined classes.Magic will take effect when we passed keyword arguments in metaclass, it indicates the Python interpreter to create the CustomList through ListMetaclass. new (), at this point, we can modify the class definition, for example, and add a new method and then return the revised definition.",
                "In addition to the published answers I can say that a metaclass defines the behaviour for a class. So, you can explicitly set your metaclass. Whenever Python gets a keyword class then it starts searching for the metaclass. If it's not found \u2013 the default metaclass type is used to create the class's object. Using the __metaclass__ attribute, you can set metaclass of your class:It'll produce the output like this:And, of course, you can create your own metaclass to define the behaviour of any class that are created using your class.For doing that, your default metaclass type class must be inherited as this is the main metaclass:The output will be:",
                "Note that in python 3.6 a new dunder method __init_subclass__(cls, **kwargs) was introduced to replace a lot of common use cases for metaclasses. Is is called when a subclass of the defining class is created. See python docs.",
                "Here's another example of what it can be used for:The metaclass is powerful, there are many things (such as monkey magic) you can do with it, but be careful this may only be known to you.",
                "The top answer is correct.But readers may be coming here searching answers about similarly named inner classes. They are present in popular libraries, such as Django and WTForms.As DavidW points out in the comments beneath this answer, these are library-specific features and are not to be confused with the advanced, unrelated Python language feature with a similar name.Rather, these are namespaces within classes' dicts. They are constructed using inner classes for sake of readability.In this example special field, abstract is visibly separate from fields of Author model.Another example is from the documentation for WTForms:This syntax does not get special treatment in the python programming language. Meta is not a keyword here, and does not trigger metaclass behavior. Rather, third-party library code in packages like Django and WTForms reads this property in the constructors of certain classes, and elsewhere.The presence of these declarations modifies the behavior of the classes that have these declarations. For example, WTForms reads self.Meta.csrf to determine if the form needs a csrf field.",
                "In object-oriented programming, a metaclass is a class whose instances are classes. Just as an ordinary class defines the behavior of certain objects, a metaclass defines the behavior of certain class and their instances\nThe term metaclass simply means something used to create classes. In other words, it is the class of a class. The metaclass is used to create the class so like the object being an instance of a class, a class is an instance of a metaclass. In python classes are also considered objects.",
                "A class, in Python, is an object, and just like any other object, it is an instance of \"something\". This \"something\" is what is termed as a Metaclass. This metaclass is a special type of class that creates other class's objects. Hence, metaclass is responsible for making new classes. This allows the programmer to customize the way classes are generated.To create a metaclass, overriding of new() and init() methods is usually done. new() can be overridden to change the way objects are created, while init() can be overridden to change the way of initializing the object. Metaclass can be created by a number of ways. One of the ways is to use type() function. type() function, when called with 3 parameters, creates a metaclass. The parameters are :-Another way of creating a metaclass comprises of 'metaclass' keyword. Define the metaclass as a simple class. In the parameters of inherited class, pass metaclass=metaclass_nameMetaclass can be specifically used in the following situations :-",
                "I saw an interesting use case for metaclasses in a package called classutilities. It checks if all class variables are in upper case format (it is convenient to have unified logic for configuration classes), and checks if there are no instance level methods in class.\nAnother interesting example for metaclases was deactivation of unittests based on complex conditions (checking values of multiple environmental variables).",
                "In Python, a metaclass is a subclass of a subclass that determines how a subclass behaves. A class is an instance of another metaclass. In Python, a class specifies how the class's instance will behave.Since metaclasses are in charge of class generation, you can\u00a0write your own custom metaclasses to change how classes are created by performing additional actions or injecting code. Custom metaclasses aren't always important, but they can be.",
                "look this:In other words, when an object was not created (type of object), we looking MetaClass."
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I check whether a file exists without exceptions?",
                "How do I check whether a file exists or not, without using the try statement?"
            ],
            "url": "https://stackoverflow.com/questions/82831",
            "answer": [
                "If the reason you're checking is so you can do something like if file_exists: open_it(), it's safer to use a try around the attempt to open it. Checking and then opening risks the file being deleted or moved or something between when you check and when you try to open it.If you're not planning to open the file immediately, you can use os.path.isfileReturn True if path is an existing regular file. This follows symbolic links, so both islink() and isfile() can be true for the same path.if you need to be sure it's a file.Starting with Python 3.4, the pathlib module offers an object-oriented approach (backported to pathlib2 in Python 2.7):To check a directory, do:To check whether a Path object exists independently of whether is it a file or directory, use exists():You can also use resolve(strict=True) in a try block:",
                "Use os.path.exists to check both files and directories:Use os.path.isfile to check only files (note: follows symbolic links):",
                "Unlike isfile(), exists() will return True for directories. So depending on if you want only plain files or also directories, you'll use isfile() or exists(). Here is some simple REPL output:",
                "Use os.path.isfile() with os.access():",
                "Although almost every possible way has been listed in (at least one of) the existing answers (e.g. Python 3.4 specific stuff was added), I'll try to group everything together.Note: every piece of Python standard library code that I'm going to post, belongs to version 3.5.3.Problem statement:Check file (arguable: also folder (\"special\" file) ?) existenceDon't use try / except / else / finally blocksPossible solutions:Also check other function family members like os.path.isfile, os.path.isdir, os.path.lexists for slightly different behaviors:Return True if path refers to an existing path or an open file descriptor. Returns False for broken symbolic links. On some platforms, this function may return False if permission is not granted to execute os.stat() on the requested file, even if the path physically exists.All good, but if following the import tree:os.path - posixpath.py (ntpath.py)genericpath.py - line ~20+it's just a try / except block around [Python.Docs]: os.stat(path, *, dir_fd=None, follow_symlinks=True). So, your code is try / except free, but lower in the framestack there's (at least) one such block. This also applies to other functions (including os.path.isfile).It's a fancier (and more [Wiktionary]: Pythonic) way of handling paths, butUnder the hood, it does exactly the same thing (pathlib.py - line ~1330):Either:Create one:And its usage - I'll replicate the os.path.isfile behavior (note that this is just for demonstrating purposes, do not attempt to write such code for production):Use [Python.Docs]: contextlib.suppress(*exceptions) - which was specifically designed for selectively suppressing exceptionsBut, they seem to be wrappers over try / except / else / finally blocks, as [Python.Docs]: Compound statements - The with statement states:This allows common try...except...finally usage patterns to be encapsulated for convenient reuse.Search the results for matching item(s):[Python.Docs]: os.listdir(path='.') (or [Python.Docs]: os.scandir(path='.') on Python v3.5+, backport: [PyPI]: scandir)Under the hood, both use:Nix: [Man7]: OPENDIR(3) / [Man7]: READDIR(3) / [Man7]: CLOSEDIR(3)Win: [MS.Learn]: FindFirstFileW function (fileapi.h) / [MS.Learn]: FindNextFileW function (fileapi.h) / [MS.Learn]: FindClose function (fileapi.h)via [GitHub]: python/cpython - (main) cpython/Modules/posixmodule.cUsing scandir() instead of listdir() can significantly increase the performance of code that also needs file type or file attribute information, because os.DirEntry objects expose this information if the operating system provides it when scanning a directory. All os.DirEntry methods may perform a system call, but is_dir() and is_file() usually only require a system call for symbolic links; os.DirEntry.stat() always requires a system call on Unix, but only requires one for symbolic links on Windows.[Python.Docs]: os.walk(top, topdown=True, onerror=None, followlinks=False)[Python.Docs]: glob.iglob(pathname, *, root_dir=None, dir_fd=None, recursive=False, include_hidden=False) (or its predecessor: glob.glob)Since these iterate over folders, (in most of the cases) they are inefficient for our problem (there are exceptions, like non wildcarded globbing - as @ShadowRanger pointed out), so I'm not going to insist on them. Not to mention that in some cases, filename processing might be required.Its behavior is close to os.path.exists (actually it's wider, mainly because of the 2nd argument).User permissions might restrict the file \"visibility\" as the doc states:... test if the invoking user has the specified access to path. mode should be F_OK to test the existence of path...Security considerations:Using access() to check if a user is authorized to e.g. open a file before actually doing so using open() creates a security hole, because the user might exploit the short time interval between checking and opening the file to manipulate it.Since I also work in C, I use this method as well because under the hood, it calls native APIs (again, via \"${PYTHON_SRC_DIR}/Modules/posixmodule.c\"), but it also opens a gate for possible user errors, and it's not as Pythonic as other variants. So, don't use it unless you know what you're doing:Nix: [Man7]: ACCESS(2)Warning: Using these calls to check if a user is authorized to, for example, open a file before actually doing so using open(2) creates a security hole, because the user might exploit the short time interval between checking and opening the file to manipulate it. For this reason, the use of this system call should be avoided.Win: [MS.Learn]: GetFileAttributesW function (fileapi.h)As seen, this approach is highly discouraged (especially on Nix).Note: calling native APIs is also possible via [Python.Docs]: ctypes - A foreign function library for Python, but in most cases it's more complicated. Before working with CTypes, check [SO]: C function called from Python via ctypes returns incorrect value (@CristiFati's answer) out.(Win specific): since vcruntime###.dll (msvcr###.dll for older VStudio versions - I'm going to refer to it as UCRT) exports a [MS.Learn]: _access, _waccess function family as well, here's an example (note that the recommended [Python.Docs]: msvcrt - Useful routines from the MS VC++ runtime doesn't export them):Notes:Although it's not a good practice, I'm using os.F_OK in the call, but that's just for clarity (its value is 0)I'm using _waccess so that the same code works on Python 3 and Python 2 (in spite of [Wikipedia]: Unicode related differences between them - [SO]: Passing utf-16 string to a Windows function (@CristiFati's answer))Although this targets a very specific area, it was not mentioned in any of the previous answersThe Linux (Ubuntu ([Wikipedia]: Ubuntu version history) 16 x86_64 (pc064)) counterpart as well:Notes:Instead hardcoding libc.so (LibC)'s path (\"/lib/x86_64-linux-gnu/libc.so.6\") which may (and most likely, will) vary across systems, None (or the empty string) can be passed to CDLL constructor (ctypes.CDLL(None).access(b\"/tmp\", os.F_OK)). According to [Man7]: DLOPEN(3):If filename is NULL, then the returned handle is for the main\nprogram.  When given to dlsym(3), this handle causes a search for a\nsymbol in the main program, followed by all shared objects loaded at\nprogram startup, and then all shared objects loaded by dlopen() with\nthe flag RTLD_GLOBAL.Main (current) program (python) is linked against LibC, so its symbols (including access) will be loadedThis has to be handled with care, since functions like main, Py_Main and (all the) others are available; calling them could have disastrous effects (on the current program)This doesn't also apply to Windows (but that's not such a big deal, since UCRT is located in \"%SystemRoot%\\System32\" which is in %PATH% by default). I wanted to take things further and replicate this behavior on Windows (and submit a patch), but as it turns out, [MS.Learn]: GetProcAddress function (libloaderapi.h) only \"sees\" exported symbols, so unless someone declares the functions in the main executable as __declspec(dllexport) (why on Earth the common person would do that?), the main program is loadable, but it is pretty much unusableMost likely, will rely on one of the ways above (maybe with slight customizations). One example would be (again, Win specific) [GitHub]: mhammond/pywin32 - Python for Windows (pywin32) Extensions, which is a Python wrapper over WinAPIs.But, since this is more like a workaround, I'm stopping here.I consider this a (lame) workaround (gainarie): use Python as a wrapper to execute shell commands:Win:Nix ([Wikipedia]: Unix-like) - Ubuntu:Do use try / except / else / finally blocks, because they can prevent you running into a series of nasty problemsA possible counterexample that I can think of, is performance: such blocks are costly, so try not to place them in code that it's supposed to run hundreds of thousands times per second (but since (in most cases) it involves disk access, it won't be the case)",
                "Python 3.4+ has an object-oriented path module: pathlib.  Using this new module, you can check whether a file exists like this:You can (and usually should) still use a try/except block when opening files:The pathlib module has lots of cool stuff in it: convenient globbing, checking file's owner, easier path joining, etc.  It's worth checking out.  If you're on an older Python (version 2.6 or later), you can still install pathlib with pip:Then import it as follows:",
                "This is the simplest way to check if a file exists. Just because the file existed when you checked doesn't guarantee that it will be there when you need to open it.",
                "Now available since Python 3.4, import and instantiate a Path object with the file name, and check the is_file method (note that this returns True for symlinks pointing to regular files as well):If you're on Python 2, you can backport the pathlib module from pypi, pathlib2, or otherwise check isfile from the os.path module:Now the above is probably the best pragmatic direct answer here, but there's the possibility of a race condition (depending on what you're trying to accomplish), and the fact that the underlying implementation uses a try, but Python uses try everywhere in its implementation.Because Python uses try everywhere, there's really no reason to avoid an implementation that uses it.But the rest of this answer attempts to consider these caveats.Available since Python 3.4, use the new Path object in pathlib. Note that .exists is not quite right, because directories are not files (except in the unix sense that everything is a file).So we need to use is_file:Here's the help on is_file:So let's get a file that we know is a file:By default, NamedTemporaryFile deletes the file when closed (and will automatically close when no more references exist to it).If you dig into the implementation, though, you'll see that is_file uses try:We like try because it avoids race conditions. With try, you simply attempt to read your file, expecting it to be there, and if not, you catch the exception and perform whatever fallback behavior makes sense.If you want to check that a file exists before you attempt to read it, and you might be deleting it and then you might be using multiple threads or processes, or another program knows about that file and could delete it - you risk the chance of a race condition if you check it exists, because you are then racing to open it before its condition (its existence) changes.Race conditions are very hard to debug because there's a very small window in which they can cause your program to fail.But if this is your motivation, you can get the value of a try statement by using the suppress context manager.Python 3.4 gives us the suppress context manager (previously the ignore context manager), which does semantically exactly the same thing in fewer lines, while also (at least superficially) meeting the original ask to avoid a try statement:Usage:For earlier Pythons, you could roll your own suppress, but without a try will be more verbose than with. I do believe this actually is the only answer that doesn't use try at any level in the Python that can be applied to prior to Python 3.4 because it uses a context manager instead:Perhaps easier with a try:isfilefrom the docs:os.path.isfile(path)Return True if path is an existing regular file. This follows symbolic\n  links, so both islink() and isfile() can be true for the same path.But if you examine the source of this function, you'll see it actually does use a try statement:All it's doing is using the given path to see if it can get stats on it,  catching OSError and then checking if it's a file if it didn't raise the exception.If you intend to do something with the file, I would suggest directly attempting it with a try-except to avoid a race condition:os.accessAvailable for Unix and Windows is os.access, but to use you must pass flags, and it does not differentiate between files and directories. This is more used to test if the real invoking user has access in an elevated privilege environment:It also suffers from the same race condition problems as isfile. From the docs:Note:\n  Using access() to check if a user is authorized to e.g. open a file\n  before actually doing so using open() creates a security hole, because\n  the user might exploit the short time interval between checking and\n  opening the file to manipulate it. It\u2019s preferable to use EAFP\n  techniques. For example:is better written as:Avoid using os.access. It is a low level function that has more opportunities for user error than the higher level objects and functions discussed above.Another answer says this about os.access:Personally, I prefer this one because under the hood, it calls native APIs (via \"${PYTHON_SRC_DIR}/Modules/posixmodule.c\"), but it also opens a gate for possible user errors, and it's not as Pythonic as other variants:This answer says it prefers a non-Pythonic, error-prone method, with no justification. It seems to encourage users to use low-level APIs without understanding them.It also creates a context manager which, by unconditionally returning True, allows all Exceptions (including KeyboardInterrupt and SystemExit!) to pass silently, which is a good way to hide bugs.This seems to encourage users to adopt poor practices.",
                "Prefer the try statement. It's considered better style and avoids race conditions.Don't take my word for it. There's plenty of support for this theory. Here's a couple:",
                "Use:Importing os makes it easier to navigate and perform standard actions with your operating system.For reference, also see How do I check whether a file exists without exceptions?.If you need high-level operations, use shutil.",
                "Testing for files and folders with os.path.isfile(), os.path.isdir() and os.path.exists()Assuming that the \"path\" is a valid path, this table shows what is returned by each function for files and folders:You can also test if a file is a certain type of file using os.path.splitext() to get the extension (if you don't already know it)",
                "TL;DR \nThe answer is: use the pathlib modulePathlib is probably the most modern and convenient way for almost all of the file operations. For the existence of a file or a folder a single line of code is enough. If file is not exists, it will not throw any exception.The pathlib module was introduced in Python 3.4, so you need to have Python 3.4+. This library makes your life much easier while working with files and folders, and it is pretty to use. Here is more documentation about it: pathlib \u2014 Object-oriented filesystem paths.BTW, if you are going to reuse the path, then it is better to assign it to a variable.So it will become:",
                "In 2016 the best way is still using os.path.isfile:Or in Python 3 you can use pathlib:",
                "It doesn't seem like there's a meaningful functional difference between try/except and isfile(), so you should use which one makes sense.If you want to read a file, if it exists, doBut if you just wanted to rename a file if it exists, and therefore don't need to open it, doIf you want to write to a file, if it doesn't exist, doIf you need file locking, that's a different matter.",
                "You could try this (safer):The ouput would be:([Errno 2] No such file or directory:\n  'whatever.txt')Then, depending on the result, your program can just keep running from there or you can code to stop it if you want.",
                "Date: 2017-12-04Every possible solution has been listed in other answers.An intuitive and arguable way to check if a file exists is the following:I made an exhaustive cheat sheet for your reference:",
                "Although I always recommend using try and except statements, here are a few possibilities for you (my personal favourite is using os.access):Try opening the file:Opening the file will always verify the existence of the file. You can make a function just like so:If it's False, it will stop execution with an unhanded IOError\nor OSError in later versions of Python. To catch the exception,\nyou have to use a try except clause. Of course, you can always\nuse a try except` statement like so (thanks to hsandt\nfor making me think):Use os.path.exists(path):This will check the existence of what you specify. However, it checks for files and directories so beware about how you use it.Use os.access(path, mode):This will check whether you have access to the file. It will check for permissions. Based on the os.py documentation, typing in os.F_OK, it will check the existence of the path. However, using this will create a security hole, as someone can attack your file using the time between checking the permissions and opening the file. You should instead go directly to opening the file instead of checking its permissions. (EAFP vs LBYP). If you're not going to open the file afterwards, and only checking its existence, then you can use this.Anyway, here:I should also mention that there are two ways that you will not be able to verify the existence of a file. Either the issue will be permission denied or no such file or directory. If you catch an IOError, set the IOError as e (like my first option), and then type in print(e.args) so that you can hopefully determine your issue. I hope it helps! :)",
                "If the file is for opening you could use one of the following techniques:Note: This finds either a file or a directory with the given name.",
                "Additionally, os.access():Being R_OK, W_OK, and X_OK the flags to test for permissions (doc).",
                "Raising exceptions is considered to be an acceptable, and Pythonic,\napproach for flow control in your program. Consider handling missing\nfiles with IOErrors. In this situation, an IOError exception will be\nraised if the file exists but the user does not have read permissions.Source: Using Python: How To Check If A File Exists",
                "If you imported NumPy already for other purposes then there is no need to import other libraries like pathlib, os, paths, etc.This will return true or false based on its existence.",
                "You can follow these three ways:Note 1: The os.path.isfile used only for filesNote 2: The os.path.exists is used for both files and directories",
                "You can write Brian's suggestion without the try:.suppress is part of Python 3.4. In older releases you can quickly write your own suppress:",
                "Adding one more slight variation which isn't exactly reflected in the other answers.This will handle the case of the file_path being None or empty string.Adding a variant based on suggestion from ShahbazAdding a variant based on suggestion from Peter Wood",
                "I'm the author of a package that's been around for about 10 years, and it has a function that addresses this question directly. Basically, if you are on a non-Windows system, it uses Popen to access find.  However, if you are on Windows, it replicates find with an efficient filesystem walker.The code itself does not use a try block\u2026 except in determining the operating system and thus steering you to the \"Unix\"-style find or the hand-buillt find. Timing tests showed that the try was faster in determining the OS, so I did use one there (but nowhere else).And the doc\u2026The implementation, if you care to look, is here:\nhttps://github.com/uqfoundation/pox/blob/89f90fb308f285ca7a62eabe2c38acb87e89dad9/pox/shutils.py#L190",
                "Here's a one-line Python command for the Linux command line environment. I find this very handy since I'm not such a hot Bash guy.",
                "You can use the \"OS\" library of Python:",
                "How do I check whether a file exists, without using the try statement?In 2016, this is still arguably the easiest way to check if both a file exists and if it is a file:isfile is actually just a helper method that internally uses os.stat and stat.S_ISREG(mode) underneath. This os.stat is a lower-level method that will provide you with detailed information about files, directories, sockets, buffers, and more. More about os.stat hereNote: However, this approach will not lock the file in any way and therefore your code can become vulnerable to \"time of check to time of use\" (TOCTTOU) bugs.So raising exceptions is considered to be an acceptable, and Pythonic, approach for flow control in your program. And one should consider handling missing files with IOErrors, rather than if statements (just an advice)."
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I merge two dictionaries in a single expression?",
                "I want to merge two dictionaries into a new dictionary.\nx = {'a': 1, 'b': 2}\ny = {'b': 3, 'c': 4}\nz = merge(x, y)\n\n>>> z\n{'a': 1, 'b': 3, 'c': 4}\n\nWhenever a key k is present in both ..."
            ],
            "url": "https://stackoverflow.com/questions/38987",
            "answer": [
                "For dictionaries x and y, their shallowly-merged dictionary z takes values from y, replacing those from x.In Python 3.9.0 or greater (released 17 October 2020, PEP-584, discussed here):In Python 3.5 or greater:In Python 2, (or 3.4 or lower) write a function:and now:Say you have two dictionaries and you want to merge them into a new dictionary without altering the original dictionaries:The desired result is to get a new dictionary (z) with the values merged, and the second dictionary's values overwriting those from the first.A new syntax for this, proposed in PEP 448 and available as of Python 3.5, isAnd it is indeed a single expression.Note that we can merge in with literal notation as well:and now:It is now showing as implemented in the release schedule for 3.5, PEP 478, and it has now made its way into the What's New in Python 3.5 document.However, since many organizations are still on Python 2, you may wish to do this in a backward-compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process:In both approaches, y will come second and its values will replace x's values, thus b will point to 3 in our final result.If you are not yet on Python 3.5 or need to write backward-compatible code, and you want this in a single expression, the most performant while the correct approach is to put it in a function:and then you have a single expression:You can also make a function to merge an arbitrary number of dictionaries, from zero to a very large number:This function will work in Python 2 and 3 for all dictionaries. e.g. given dictionaries a to g:and key-value pairs in g will take precedence over dictionaries a to f, and so on.Don't use what you see in the formerly accepted answer:In Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict. In Python 3, this will fail because you're adding two dict_items objects together, not two lists -and you would have to explicitly create them as lists, e.g. z = dict(list(x.items()) + list(y.items())). This is a waste of resources and computation power.Similarly, taking the union of items() in Python 3 (viewitems() in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable, since sets are semantically unordered, the behavior is undefined in regards to precedence. So don't do this:This example demonstrates what happens when values are unhashable:Here's an example where y should have precedence, but instead the value from x is retained due to the arbitrary order of sets:Another hack you should not use:This uses the dict constructor and is very fast and memory-efficient (even slightly more so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic.Here's an example of the usage being remediated in django.Dictionaries are intended to take hashable keys (e.g. frozensets or tuples), but this method fails in Python 3 when keys are not strings.From the mailing list, Guido van Rossum, the creator of the language, wrote:I am fine with\ndeclaring dict({}, **{1:3}) illegal, since after all it is abuse of\nthe ** mechanism.andApparently dict(x, **y) is going around as \"cool hack\" for \"call\nx.update(y) and return x\". Personally, I find it more despicable than\ncool.It is my understanding (as well as the understanding of the creator of the language) that the intended usage for dict(**y) is for creating dictionaries for readability purposes, e.g.:instead ofDespite what Guido says, dict(x, **y) is in line with the dict specification, which btw. works for both Python 2 and 3. The fact that this only works for string keys is a direct consequence of how keyword parameters work and not a short-coming of dict. Nor is using the ** operator in this place an abuse of the mechanism, in fact, ** was designed precisely to pass dictionaries as keywords.Again, it doesn't work for 3 when keys are not strings. The implicit calling contract is that namespaces take ordinary dictionaries, while users must only pass keyword arguments that are strings. All other callables enforced it. dict broke this consistency in Python 2:This inconsistency was bad given other implementations of Python (PyPy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change.I submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints.More comments:dict(x.items() + y.items()) is still the most readable solution for Python 2. Readability counts.My response: merge_two_dicts(x, y) actually seems much clearer to me, if we're actually concerned about readability. And it is not forward compatible, as Python 2 is increasingly deprecated.{**x, **y} does not seem to handle nested dictionaries. the contents of nested keys are simply overwritten, not merged [...] I ended up being burnt by these answers that do not merge recursively and I was surprised no one mentioned it. In my interpretation of the word \"merging\" these answers describe \"updating one dict with another\", and not merging.Yes. I must refer you back to the question, which is asking for a shallow merge of two dictionaries, with the first's values being overwritten by the second's - in a single expression.Assuming two dictionaries of dictionaries, one might recursively merge them in a single function, but you should be careful not to modify the dictionaries from either source, and the surest way to avoid that is to make a copy when assigning values. As keys must be hashable and are usually therefore immutable, it is pointless to copy them:Usage:Coming up with contingencies for other value types is far beyond the scope of this question, so I will point you at my answer to the canonical question on a \"Dictionaries of dictionaries merge\".These approaches are less performant, but they will provide correct behavior.\nThey will be much less performant than copy and update or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they do respect the order of precedence (latter dictionaries have precedence)You can also chain the dictionaries manually inside a dict comprehension:or in Python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced):itertools.chain will chain the iterators over the key-value pairs in the correct order:I'm only going to do the performance analysis of the usages known to behave correctly. (Self-contained so you can copy and paste yourself.)In Python 3.8.1, NixOS:",
                "In your case, you can do:This will, as you want it, put the final dict in z, and make the value for key b be properly overridden by the second (y) dict's value:If you use Python 2, you can even remove the list() calls. To create z:If you use Python version 3.9.0a4 or greater, then you can directly use:",
                "An alternative:",
                "Another, more concise, option:Note: this has become a popular answer, but it is important to point out that if y has any non-string keys, the fact that this works at all is an abuse of a CPython implementation detail, and it does not work in Python 3, or in PyPy, IronPython, or Jython. Also, Guido is not a fan. So I can't recommend this technique for forward-compatible or cross-implementation portable code, which really means it should be avoided entirely.",
                "This probably won't be a popular answer, but you almost certainly do not want to do this.  If you want a copy that's a merge, then use copy (or deepcopy, depending on what you want) and then update.  The two lines of code are much more readable - more Pythonic - than the single line creation with .items() + .items().  Explicit is better than implicit.In addition, when you use .items() (pre Python 3.0), you're creating a new list that contains the items from the dict.  If your dictionaries are large, then that is quite a lot of overhead (two large lists that will be thrown away as soon as the merged dict is created).  update() can work more efficiently, because it can run through the second dict item-by-item.In terms of time:IMO the tiny slowdown between the first two is worth it for the readability.  In addition, keyword arguments for dictionary creation was only added in Python 2.3, whereas copy() and update() will work in older versions.",
                "In a follow-up answer, you asked about the relative performance of these two alternatives:On my machine, at least (a fairly ordinary x86_64 running Python 2.5.2), alternative z2 is not only shorter and simpler but also significantly faster.  You can verify this for yourself using the timeit module that comes with Python.Example 1: identical dictionaries mapping 20 consecutive integers to themselves:z2 wins by a factor of 3.5 or so.  Different dictionaries seem to yield quite different results, but z2 always seems to come out ahead.  (If you get inconsistent results for the same test, try passing in -r with a number larger than the default 3.)Example 2: non-overlapping dictionaries mapping 252 short strings to integers and vice versa:z2 wins by about a factor of 10.  That's a pretty big win in my book!After comparing those two, I wondered if z1's poor performance could be attributed to the overhead of constructing the two item lists, which in turn led me to wonder if this variation might work better:A few quick tests, e.g.lead me to conclude that z3 is somewhat faster than z1, but not nearly as fast as z2.  Definitely not worth all the extra typing.This discussion is still missing something important, which is a performance comparison of these alternatives with the \"obvious\" way of merging two lists: using the update method.  To try to keep things on an equal footing with the expressions, none of which modify x or y, I'm going to make a copy of x instead of modifying it in-place, as follows:A typical result:In other words, z0 and z2 seem to have essentially identical performance.  Do you think this might be a coincidence?  I don't....In fact, I'd go so far as to claim that it's impossible for pure Python code to do any better than this.  And if you can do significantly better in a C extension module, I imagine the Python folks might well be interested in incorporating your code (or a variation on your approach) into the Python core.  Python uses dict in lots of places; optimizing its operations is a big deal.You could also write this asas Tony does, but (not surprisingly) the difference in notation turns out not to have any measurable effect on performance.  Use whichever looks right to you.  Of course, he's absolutely correct to point out that the two-statement version is much easier to understand.",
                "In Python 3.0 and later, you can use collections.ChainMap which groups multiple dicts or other mappings together to create a single, updateable view:Update for Python 3.5 and later: You can use PEP 448 extended dictionary packing and unpacking.  This is fast and easy:Update for Python 3.9 and later:  You can use the PEP 584 union operator:",
                "I wanted something similar, but with the ability to specify how the values on duplicate keys were merged, so I hacked this out (but did not heavily test it).  Obviously this is not a single expression, but it is a single function call.",
                "Demonstration:Outputs:Thanks rednaw for edits.",
                "Python 3.5 (PEP 448) allows a nicer syntax option:Or evenIn Python 3.9 you also use | and |= with the below example from PEP 584",
                "For items with keys in both dictionaries ('b'), you can control which one ends up in the output by putting that one last.",
                "The best version I could think while not using copy would be:It's faster than dict(x.items() + y.items()) but not as fast as n = copy(a); n.update(b), at least on CPython. This version also works in Python 3 if you change iteritems() to items(), which is automatically done by the 2to3 tool.Personally I like this version best because it describes fairly good what I want in a single  functional syntax. The only minor problem is that it doesn't make completely obvious that values from y takes precedence over values from x, but I don't believe it's difficult to figure that out.",
                "While the question has already been answered several times,\nthis simple solution to the problem has not been listed yet.It is as fast as z0 and the evil z2 mentioned above, but easy to understand and change.",
                "Among such shady and dubious answers, this shining example is the one and only good way to merge dicts in Python, endorsed by dictator for life Guido van Rossum himself!  Someone else suggested half of this, but did not put it in a function.gives:",
                "I benchmarked the suggested with perfplot and found that the good oldis the fastest solution together with the good oldandCode to reproduce the plot:",
                "Be Pythonic. Use a comprehension:",
                "If you think lambdas are evil then read no further.\nAs requested, you can write the fast and memory-efficient solution with one expression:As suggested above, using two lines or writing a function is probably a better way to go.",
                "In python3, the items method no longer returns a list, but rather a view, which acts like a set. In this case you'll need to take the set union since concatenating with + won't work:For python3-like behavior in version 2.7, the viewitems method should work in place of items:I prefer this notation anyways since it seems more natural to think of it as a set union operation rather than concatenation (as the title shows).Edit:A couple more points for python 3. First, note that the dict(x, **y) trick won't work in python 3 unless the keys in y are strings.Also, Raymond Hettinger's Chainmap answer is pretty elegant, since it can take an arbitrary number of dicts as arguments, but from the docs it looks like it sequentially looks through a list of all the dicts for each lookup:Lookups search the underlying mappings successively until a key is found.This can slow you down if you have a lot of lookups in your application:So about an order of magnitude slower for lookups. I'm a fan of Chainmap, but looks less practical where there may be many lookups.",
                "Two dictionariesn dictionariessum has bad performance. See https://mathieularose.com/how-not-to-flatten-a-list-of-lists-in-python/",
                "Simple solution using itertools that preserves order (latter dicts have precedence)And it's usage:",
                "Abuse leading to a one-expression solution for Matthew's answer:You said you wanted one expression, so I abused lambda to bind a name, and tuples to override lambda's one-expression limit. Feel free to cringe.You could also do this of course if you don't care about copying it:",
                "If you don't mind mutating x,Simple, readable, performant. You know update() always returns None, which is a false value. So the above expression will always evaluate to x, after updating it.Most mutating methods in the standard library (like .update()) return None by convention, so this kind of pattern will work on those too. However, if you're using a dict subclass or some other method that doesn't follow this convention, then or may return its left operand, which may not be what you want. Instead, you can use a tuple display and index, which works regardless of what the first element evaluates to (although it's not quite as pretty):If you don't have x in a variable yet, you can use lambda to make a local without using an assignment statement. This amounts to using lambda as a let expression, which is a common technique in functional languages, but is maybe unpythonic.Although it's not that different from the following use of the new walrus operator (Python 3.8+ only),especially if you use a default argument:If you do want a copy, PEP 584 style x | y is the most Pythonic on 3.9+. If you must support older versions, PEP 448 style {**x, **y} is easiest for 3.5+. But if that's not available in your (even older) Python version, the let expression pattern works here too.(That is, of course, nearly equivalent to (z := x.copy()).update(y) or z, but if your Python version is new enough for that, then the PEP 448 style will be available.)",
                "Drawing on ideas here and elsewhere I've comprehended a function:Usage (tested in python 3):You could use a lambda instead.",
                "New in Python 3.9: Use the union operator (|) to merge dicts similar to sets:For matching keys, the right dict takes precedence.This also works for |= to modify a dict in-place:",
                "It's so silly that .update returns nothing.\nI just use a simple helper function to solve the problem:Examples:",
                "(For Python\u00a02.7* only; there are simpler solutions for Python\u00a03*.)If you're not averse to importing a standard library module, you can do(The or a bit in the lambda is necessary because dict.update always returns None on success.)",
                "The problem I have with solutions listed to date is that, in the merged dictionary, the value for key \"b\" is 10 but, to my way of thinking, it should be 12.\nIn that light, I present the following:",
                "There will be a new option when Python 3.8 releases (scheduled for 20 October, 2019), thanks to PEP 572: Assignment Expressions. The new assignment expression operator := allows you to assign the result of the copy and still use it to call update, leaving the combined code a single expression, rather than two statements, changing:to:while behaving identically in every way. If you must also return the resulting dict (you asked for an expression returning the dict; the above creates and assigns to newdict, but doesn't return it, so you couldn't use it to pass an argument to a function as is, a la myfunc((newdict := dict1.copy()).update(dict2))), then just add or newdict to the end (since update returns None, which is falsy, it will then evaluate and return newdict as the result of the expression):Important caveat: In general, I'd discourage this approach in favor of:The unpacking approach is clearer (to anyone who knows about generalized unpacking in the first place, which you should), doesn't require a name for the result at all (so it's much more concise when constructing a temporary that is immediately passed to a function or included in a list/tuple literal or the like), and is almost certainly faster as well, being (on CPython) roughly equivalent to:but done at the C layer, using the concrete dict API, so no dynamic method lookup/binding or function call dispatch overhead is involved (where (newdict := dict1.copy()).update(dict2) is unavoidably identical to the original two-liner in behavior, performing the work in discrete steps, with dynamic lookup/binding/invocation of methods.It's also more extensible, as merging three dicts is obvious:where using assignment expressions won't scale like that; the closest you could get would be:or without the temporary tuple of Nones, but with truthiness testing of each None result:either of which is obviously much uglier, and includes further inefficiencies (either a wasted temporary tuple of Nones for comma separation, or pointless truthiness testing of each update's None return for or separation).The only real advantage to the assignment expression approach occurs if:",
                "This should solve your problem.",
                "This can be done with a single dict comprehension:In my view the best answer for the 'single expression' part as no extra functions are needed, and it is short."
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I execute a program or call a system command?",
                "How do I call an external command within Python as if I had typed it in a shell or command prompt?"
            ],
            "url": "https://stackoverflow.com/questions/89228",
            "answer": [
                "Use the subprocess module in the standard library:The advantage of subprocess.run over os.system is that it is more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc...).Even the documentation for os.system recommends using subprocess instead:The subprocess module provides more powerful facilities for spawning new processes and retrieving their results; using that module is preferable to using this function. See the Replacing Older Functions with the subprocess Module section in the subprocess documentation for some helpful recipes.On Python 3.4 and earlier, use subprocess.call instead of .run:",
                "Here is a summary of ways to call external programs, including their advantages and disadvantages:os.system passes the command and arguments to your system's shell. This is nice because you can actually run multiple commands at once in this manner and set up pipes and input/output redirection. For example:However, while this is convenient, you have to manually handle the escaping of shell characters such as spaces, et cetera. On the other hand, this also lets you run commands which are simply shell commands and not actually external programs.os.popen will do the same thing as os.system except that it gives you a file-like object that you can use to access standard input/output for that process. There are 3 other variants of popen that all handle the i/o slightly differently. If you pass everything as a string, then your command is passed to the shell; if you pass them as a list then you don't need to worry about escaping anything. Example:subprocess.Popen. This is intended as a replacement for os.popen, but has the downside of being slightly more complicated by virtue of being so comprehensive. For example, you'd say:instead ofbut it is nice to have all of the options there in one unified class instead of 4 different popen functions. See the documentation.subprocess.call. This is basically just like the Popen class and takes all of the same arguments, but it simply waits until the command completes and gives you the return code. For example:subprocess.run. Python 3.5+ only. Similar to the above but even more flexible and returns a CompletedProcess object when the command finishes executing.os.fork, os.exec, os.spawn are similar to their C language counterparts, but I don't recommend using them directly.The subprocess module should probably be what you use.Finally, please be aware that for all methods where you pass the final command to be executed by the shell as a string and you are responsible for escaping it. There are serious security implications if any part of the string that you pass can not be fully trusted. For example, if a user is entering some/any part of the string. If you are unsure, only use these methods with constants. To give you a hint of the implications consider this code:and imagine that the user enters something \"my mama didnt love me && rm -rf /\" which could erase the whole filesystem.",
                "Typical implementation:You are free to do what you want with the stdout data in the pipe.  In fact, you can simply omit those parameters (stdout= and stderr=) and it'll behave like os.system().",
                "Some hints on detaching the child process from the calling one (starting the child process in background).Suppose you want to start a long task from a CGI script. That is, the child process should live longer than the CGI script execution process.The classical example from the subprocess module documentation is:The idea here is that you do not want to wait in the line 'call subprocess' until the longtask.py is finished. But it is not clear what happens after the line 'some more code here' from the example.My target platform was FreeBSD, but the development was on Windows, so I faced the problem on Windows first.On Windows (Windows\u00a0XP), the parent process will not finish until the longtask.py has finished its work. It is not what you want in a CGI script. The problem is not specific to Python; in the PHP community the problems are the same.The solution is to pass DETACHED_PROCESS Process Creation Flag to the underlying CreateProcess function in Windows API.\nIf you happen to have installed pywin32, you can import the flag from the win32process module, otherwise you should define it yourself:/* UPD 2015.10.27 @eryksun in a comment below notes, that the semantically correct flag is CREATE_NEW_CONSOLE (0x00000010) */On FreeBSD we have another problem: when the parent process is finished, it finishes the child processes as well. And that is not what you want in a CGI script either. Some experiments showed that the problem seemed to be in sharing sys.stdout. And the working solution was the following:I have not checked the code on other platforms and do not know the reasons of the behaviour on FreeBSD. If anyone knows, please share your ideas. Googling on starting background processes in Python does not shed any light yet.",
                "Note that this is dangerous, since the command isn't cleaned. I leave it up to you to google for the relevant documentation on the 'os' and 'sys' modules. There are a bunch of functions (exec* and spawn*) that will do similar things.",
                "I'd recommend using the subprocess module instead of os.system because it does shell escaping for you and is therefore much safer.",
                "If you want to return the results of the command, you can use os.popen. However, this is deprecated since version 2.6 in favor of the subprocess module, which other answers have covered well.",
                "There are lots of different libraries which allow you to call external commands with Python. For each library I've given a description and shown an example of calling an external command. The command I used as the example is ls -l (list all files). If you want to find out more about any of the libraries I've listed and linked the documentation for each of them.Hopefully this will help you make a decision on which library to use :)Subprocess allows you to call external commands and connect them to their input/output/error pipes (stdin, stdout, and stderr). Subprocess is the default choice for running commands, but sometimes other modules are better.os is used for \"operating system dependent functionality\". It can also be used to call external commands with os.system and os.popen (Note: There is also a subprocess.popen). os will always run the shell and is a simple alternative for people who don't need to, or don't know how to use subprocess.run.sh is a subprocess interface which lets you call programs as if they were functions. This is useful if you want to run a command multiple times.plumbum is a library for \"script-like\" Python programs. You can call programs like functions as in sh. Plumbum is useful if you want to run a pipeline without the shell.pexpect lets you spawn child applications, control them and find patterns in their output. This is a better alternative to subprocess for commands that expect a tty on Unix.fabric is a Python 2.5 and 2.7 library. It allows you to execute local and remote shell commands. Fabric is simple alternative for running commands in a secure shell (SSH)envoy is known as \"subprocess for humans\". It is used as a convenience wrapper around the subprocess module.commands contains wrapper functions for os.popen, but it has been removed from Python 3 since subprocess is a better alternative.",
                "Use the subprocess module (Python 3):It is the recommended standard way. However, more complicated tasks (pipes, output, input, etc.) can be tedious to construct and write.Note on Python version: If you are still using Python 2, subprocess.call works in a similar way.ProTip: shlex.split can help you to parse the command for run, call, and other subprocess functions in case you don't want (or you can't!) provide them in form of lists:If you do not mind external dependencies, use plumbum:It is the best subprocess wrapper. It's cross-platform, i.e. it works on both Windows and Unix-like systems. Install by pip install plumbum.Another popular library is sh:However, sh dropped Windows support, so it's not as awesome as it used to be. Install by pip install sh.",
                "I always use fabric for this things like:But this seem to be a good tool: sh (Python subprocess interface).Look at an example:",
                "Check the \"pexpect\" Python library, too.It allows for interactive controlling of external programs/commands, even ssh, ftp, telnet, etc. You can just type something like:",
                "If you need the output from the command you are calling,\nthen you can use subprocess.check_output (Python 2.7+).Also note the shell parameter.If shell is True, the specified command will be executed through the shell. This can be useful if you are using Python primarily for the enhanced control flow it offers over most system shells and still want convenient access to other shell features such as shell pipes, filename wildcards, environment variable expansion, and expansion of ~ to a user\u2019s home directory. However, note that Python itself offers implementations of many shell-like features (in particular, glob, fnmatch, os.walk(), os.path.expandvars(), os.path.expanduser(), and shutil).",
                "subprocess.run is the recommended approach as of Python 3.5 if your code does not need to maintain compatibility with earlier Python versions. It's more consistent and offers similar ease-of-use as Envoy. (Piping isn't as straightforward though. See this question for how.)Here's some examples from the documentation.Run a process:Raise on failed run:Capture output:I recommend trying Envoy. It's a wrapper for subprocess, which in turn aims to replace the older modules and functions. Envoy is subprocess for humans.Example usage from the README:Pipe stuff around too:",
                "This is how I run my commands. This code has everything you need pretty much",
                "Simple, use subprocess.run, which returns a CompletedProcess object:(run wants a list of lexically parsed shell arguments - this is what you'd type in a shell, separated by spaces, but not where the spaces are quoted, so use a specialized function, split, to split up what you would literally type into your shell)As of Python 3.5, the documentation recommends subprocess.run:The recommended approach to invoking subprocesses is to use the run() function for all use cases it can handle. For more advanced use cases, the underlying Popen interface can be used directly.Here's an example of the simplest possible usage - and it does exactly as asked:run waits for the command to successfully finish, then returns a CompletedProcess object. It may instead raise TimeoutExpired (if you give it a timeout= argument) or CalledProcessError (if it fails and you pass check=True).As you might infer from the above example, stdout and stderr both get piped to your own stdout and stderr by default.We can inspect the returned object and see the command that was given and the returncode:If you want to capture the output, you can pass subprocess.PIPE to the appropriate stderr or stdout:And those respective attributes return bytes.One might easily move from manually providing a command string (like the question suggests) to providing a string built programmatically. Don't build strings programmatically. This is a potential security issue. It's better to assume you don't trust the input.Note, only args should be passed positionally.Here's the actual signature in the source and as shown by help(run):The popenargs and kwargs are given to the Popen constructor. input can be a string of bytes (or unicode, if specify encoding or universal_newlines=True) that will be piped to the subprocess's stdin.The documentation describes timeout= and check=True better than I could:The timeout argument is passed to Popen.communicate(). If the timeout\nexpires, the child process will be killed and waited for. The\nTimeoutExpired exception will be re-raised after the child process has\nterminated.If check is true, and the process exits with a non-zero exit code, a\nCalledProcessError exception will be raised. Attributes of that\nexception hold the arguments, the exit code, and stdout and stderr if\nthey were captured.and this example for check=True is better than one I could come up with:Here's an expanded signature, as given in the documentation:Note that this indicates that only the args list should be passed positionally. So pass the remaining arguments as keyword arguments.When use Popen instead? I would struggle to find use-case based on the arguments alone. Direct usage of Popen would, however, give you access to its methods, including poll, 'send_signal', 'terminate', and 'wait'.Here's the Popen signature as given in the source. I think this is the most precise encapsulation of the information (as opposed to help(Popen)):But more informative is the Popen documentation:Execute a child program in a new process. On POSIX, the class uses\nos.execvp()-like behavior to execute the child program. On Windows,\nthe class uses the Windows CreateProcess() function. The arguments to\nPopen are as follows.Understanding the remaining documentation on Popen will be left as an exercise for the reader.",
                "Use subprocess....or for a very simple command:",
                "As of Python 3.7.0 released on June 27th 2018 (https://docs.python.org/3/whatsnew/3.7.html), you can achieve your desired result in the most powerful while equally simple way. This answer intends to show you the essential summary of various options in a short manner. For in-depth answers, please see the other ones.The big advantage of os.system(...) was its simplicity. subprocess is better and still easy to use, especially as of Python 3.5.Note: This is the exact answer to your question - running a commandlike in a shellIf possible, remove the shell overhead and run the command directly (requires a list).Pass program arguments in a list. Don't include \\\"-escaping for arguments containing spaces.The following code speaks for itself:result.stdout is all normal program output excluding errors. Read result.stderr to get them.capture_output=True - turns capturing on. Otherwise result.stderr and result.stdout would be None. Available from Python 3.7.text=True - a convenience argument added in Python 3.7 which converts the received binary data to Python strings you can easily work with.DoIf you just want to check if the program succeeded (returncode == 0) and otherwise throw an Exception, there is a more convenient function:But it's Python, so there's an even more convenient argument check which does the same thing automatically for you:You might want to have all program output inside stdout, even errors. To accomplish this, runresult.stderr will then be None and result.stdout will contain everything.shell=False expects a list of arguments. You might however, split an argument string on your own using shlex.That's it.Chances are high you just started using Python when you come across this question. Let's look at some common problems.FileNotFoundError: [Errno 2] No such file or directory: 'ls -a': 'ls -a'You're running a subprocess without shell=True . Either use a list ([\"ls\", \"-a\"]) or set shell=True.TypeError: [...] NoneType [...]Check that you've set capture_output=True.TypeError: a bytes-like object is required, not [...]You always receive byte results from your program. If you want to work with it like a normal string, set text=True.subprocess.CalledProcessError: Command '[...]' returned non-zero exit status 1.Your command didn't run successfully. You could disable returncode checking or check your actual program's validity.TypeError: init() got an unexpected keyword argument [...]You're likely using a version of Python older than 3.7.0; update it to the most recent one available. Otherwise there are other answers in this Stack Overflow post showing you older alternative solutions.",
                "os.system is OK, but kind of dated.  It's also not very secure.  Instead, try subprocess.  subprocess does not call sh directly and is therefore more secure than os.system.Get more information here.",
                "There is also Plumbum",
                "Use:os - This module provides a portable way of using operating system-dependent functionality.For the more os functions, here is the documentation.",
                "It can be this simple:",
                "There is another difference here which is not mentioned previously.subprocess.Popen executes the <command> as a subprocess. In my case, I need to execute file <a> which needs to communicate with another program, <b>.I tried subprocess, and execution was successful. However <b> could not communicate with <a>.\nEverything is normal when I run both from the terminal.One more: \n(NOTE: kwrite behaves different from other applications. If you try the below with Firefox, the results will not be the same.)If you try os.system(\"kwrite\"), program flow freezes until the user closes kwrite. To overcome that I tried instead os.system(konsole -e kwrite). This time program continued to flow, but kwrite became the subprocess of the console.Anyone runs the kwrite not being a subprocess (i.e. in the system monitor it must appear at the leftmost edge of the tree).",
                "os.system does not allow you to store results, so if you want to store results in some list or something, a subprocess.call works.",
                "subprocess.check_call is convenient if you don't want to test return values. It throws an exception on any error.",
                "I tend to use subprocess together with shlex (to handle escaping of quoted strings):",
                "I wrote a library for this, shell.py.It's basically a wrapper for popen and shlex for now. It also supports piping commands, so you can chain commands easier in Python. So you can do things like:",
                "In Windows you can just import the subprocess module and run external commands by calling subprocess.Popen(), subprocess.Popen().communicate() and subprocess.Popen().wait() as below:Output:",
                "Under Linux, in case you would like to call an external command that will execute independently (will keep running after the Python script terminates), you can use a simple queue as task spooler or the at command.An example with task spooler:Notes about task spooler (ts):You could set the number of concurrent processes to be run (\"slots\") with:ts -S <number-of-slots>Installing ts doesn't requires admin privileges. You can download and compile it from source with a simple make, add it to your path and you're done.",
                "Invoke is a Python (2.7 and 3.4+) task execution tool and library. It provides a clean, high-level API for running shell commands:",
                "You can use Popen, and then you can check the procedure's status:Check out subprocess.Popen."
            ]
        },
        {
            "tag": "python",
            "question": [
                "How can I safely create a nested directory?",
                "I am writing a file using Python. How do I check:\n\nif the parent file directory exists\nif it does not - create the directory"
            ],
            "url": "https://stackoverflow.com/questions/273192",
            "answer": [
                "On Python \u2265 3.5, use pathlib.Path.mkdir:For older versions of Python, I see two answers with good qualities, each with a small flaw, so I will give my take on it:Try os.path.exists, and consider os.makedirs for the creation.As noted in comments and elsewhere, there's a race condition \u2013 if the directory is created between the os.path.exists and the os.makedirs calls, the os.makedirs will fail with an OSError. Unfortunately, blanket-catching OSError and continuing is not foolproof, as it will ignore a failure to create the directory due to other factors, such as insufficient permissions, full disk, etc.One option would be to trap the OSError and examine the embedded error code (see Is there a cross-platform way of getting information from Python\u2019s OSError):Alternatively, there could be a second os.path.exists, but suppose another created the directory after the first check, then removed it before the second one \u2013 we could still be fooled.Depending on the application, the danger of concurrent operations may be more or less than the danger posed by other factors such as file permissions. The developer would have to know more about the particular application being developed and its expected environment before choosing an implementation.Modern versions of Python improve this code quite a bit, both by exposing FileExistsError (in 3.3+)......and by allowing a keyword argument to os.makedirs called exist_ok (in 3.2+).",
                "pathlib.Path.mkdir as used above recursively creates the directory and does not raise an exception if the directory already exists. If you don't need or want the parents to be created, skip the parents argument.Using pathlib:If you can, install the current pathlib backport named pathlib2. Do not install the older unmaintained backport named pathlib. Next, refer to the Python 3.5+ section above and use it the same.If using Python 3.4, even though it comes with pathlib, it is missing the useful exist_ok option. The backport is intended to offer a newer and superior implementation of mkdir which includes this missing option.Using os:os.makedirs as used above recursively creates the directory and does not raise an exception if the directory already exists. It has the optional exist_ok argument only if using Python 3.2+, with a default value of False. This argument does not exist in Python 2.x up to 2.7. As such, there is no need for manual exception handling as with Python 2.7.Using pathlib:If you can, install the current pathlib backport named pathlib2. Do not install the older unmaintained backport named pathlib. Next, refer to the Python 3.5+ section above and use it the same.Using os:While a naive solution may first use os.path.isdir followed by os.makedirs, the solution above reverses the order of the two operations. In doing so, it prevents a common race condition having to do with a duplicated attempt at creating the directory, and also disambiguates files from directories.Note that capturing the exception and using errno is of limited usefulness because OSError: [Errno 17] File exists, i.e. errno.EEXIST, is raised for both files and directories. It is more reliable simply to check if the directory exists.mkpath creates the nested directory, and does nothing if the directory already exists. This works in both Python 2 and 3.Per Bug 10948, a severe limitation of this alternative is that it works only once per python process for a given path. In other words, if you use it to create a directory, then delete the directory from inside or outside Python, then use mkpath again to recreate the same directory, mkpath will simply silently use its invalid cached info of having previously created the directory, and will not actually make the directory again. In contrast, os.makedirs doesn't rely on any such cache. This limitation may be okay for some applications.With regard to the directory's mode, please refer to the documentation if you care about it.",
                "Using try except and the right error code from errno module gets rid of the race condition and is cross-platform:In other words, we try to create the directories, but if they already exist we ignore the error. On the other hand, any other error gets reported. For example, if you create dir 'a' beforehand and remove all permissions from it, you will get an OSError raised with errno.EACCES (Permission denied, error 13).",
                "Starting from Python 3.5, pathlib.Path.mkdir has an exist_ok flag:This recursively creates the directory and does not raise an exception if the directory already exists.(just as os.makedirs got an exist_ok flag starting from python 3.2 e.g os.makedirs(path, exist_ok=True))Note: when i posted this answer none of the other answers mentioned exist_ok...",
                "I would personally recommend that you use os.path.isdir() to test instead of os.path.exists().If you have:And a foolish user input:... You're going to end up with a directory named filename.etc when you pass that argument to os.makedirs() if you test with os.path.exists().",
                "Check os.makedirs:  (It makes sure the complete path exists.)\n To handle the fact the directory might exist, catch OSError.\n(If exist_ok is False (the default), an OSError is raised if the target directory already exists.)",
                "Try the os.path.exists function",
                "You give a particular file at a certain path and you pull the directory from the file path. Then after making sure you have the directory, you attempt to open a file for reading. To comment on this code:We want to avoid overwriting the builtin function, dir. Also, filepath or perhaps fullfilepath is probably a better semantic name than filename so this would be better written:Your end goal is to open this file, you initially state, for writing, but you're essentially approaching this goal (based on your code) like this, which opens the file for reading:Why would you make a directory for a file that you expect to be there and be able to read?Just attempt to open the file.If the directory or file isn't there, you'll get an IOError with an associated error number: errno.ENOENT will point to the correct error number regardless of your platform. You can catch it if you want, for example:This is probably what you're wanting.In this case, we probably aren't facing any race conditions. So just do as you were, but note that for writing, you need to open with the w mode (or a to append). It's also a Python best practice to use the context manager for opening files.However, say we have several Python processes that attempt to put all their data into the same directory. Then we may have contention over creation of the directory. In that case it's best to wrap the makedirs call in a try-except block.",
                "I have put the following down. It's not totally foolproof though.Now as I say, this is not really foolproof, because we have the possiblity of failing to create the directory, and another process creating it during that period.",
                "Check if a directory exists and create it if necessary?The direct answer to this is, assuming a simple situation where you don't expect other users or processes to be messing with your directory:or if making the directory is subject to race conditions (i.e. if after checking the path exists, something else may have already made it) do this:But perhaps an even better approach is to sidestep the resource contention issue, by using temporary directories via tempfile:Here's the essentials from the online doc:There's a new Path object (as of 3.4) with lots of methods one would want to use with paths - one of which is mkdir.(For context, I'm tracking my weekly rep with a script. Here's the relevant parts of code from the script that allow me to avoid hitting Stack Overflow more than once a day for the same data.)First the relevant imports:We don't have to deal with os.path.join now - just join path parts with a /:Then I idempotently ensure the directory exists - the exist_ok argument shows up in Python 3.5:Here's the relevant part of the documentation:If exist_ok is true, FileExistsError exceptions will be ignored (same behavior as the POSIX mkdir -p command), but only if the last path component is not an existing non-directory file.Here's a little more of the script - in my case, I'm not subject to a race condition, I only have one process that expects the directory (or contained files) to be there, and I don't have anything trying to remove the directory.Path objects have to be coerced to str before other APIs that expect str paths can use them.Perhaps Pandas should be updated to accept instances of the abstract base class, os.PathLike.",
                "Best way to do this in python",
                "In Python 3.4 you can also use the brand new pathlib module:",
                "fastest safest way to do it is:\nit will create if not exists and skip if exists:",
                "For a one-liner solution, you can use IPython.utils.path.ensure_dir_exists():From the documentation: Ensure that a directory exists. If it doesn\u2019t exist, try to create it and protect against a race condition if another process is doing the same.IPython is an extension package, not part of the standard library.",
                "In Python3, os.makedirs supports setting exist_ok. The default setting is False, which means an OSError will be raised if the target directory already exists. By setting exist_ok to True, OSError (directory exists) will be ignored and the directory will not be created.In Python2, os.makedirs doesn't support setting exist_ok. You can use the approach in heikki-toivonen's answer:",
                "The relevant Python documentation suggests the use of the EAFP coding style (Easier to Ask for Forgiveness than Permission). This means that the codeis better than the alternativeThe documentation suggests this exactly because of the race condition discussed in this question. In addition, as others mention here, there is a performance advantage in querying once instead of twice the OS. Finally, the argument placed forward, potentially, in favour of the second code in some cases --when the developer knows the environment the application is running-- can only be advocated in the special case that the program has set up a private environment for itself (and other instances of the same program).Even in that case, this is a bad practice and can lead to long useless debugging. For example, the fact we set the permissions for a directory should not leave us with the impression permissions are set appropriately for our purposes. A parent directory could be mounted with other permissions. In general, a program should always work correctly and the programmer should not expect one specific environment.",
                "I found this Q/A after I was puzzled by some of the failures and errors I was getting while working with directories in Python. I am working in Python 3 (v.3.5 in an Anaconda virtual environment on an Arch Linux x86_64 system).Consider this directory structure:Here are my experiments/notes, which provides clarification:Conclusion: in my opinion, \"Method 2\" is more robust.[1] How can I safely create a nested directory?[2] https://docs.python.org/3/library/os.html#os.makedirs",
                "You can use mkpathNote that it will create the ancestor directories as well.It works for Python 2 and 3.",
                "In case you're writing a file to a variable path, you can use this on the file's path to make sure that the parent directories are created.Works even if path_to_file is file.ext (zero directories deep).See pathlib.PurePath.parent and pathlib.Path.mkdir.",
                "Why not use subprocess module if running on a machine that supports command \nmkdir with -p option ? \nWorks on python 2.7 and python 3.6Should do the trick on most systems.In situations where portability doesn't matter (ex, using docker) the solution is a clean 2 lines. You also don't have to add logic to check if directories exist or not. Finally, it is safe to re-run without any side effectsIf you need error handling:",
                "You have to set the full path before creating the directory:This works for me and hopefully, it will works for you as well",
                "I saw Heikki Toivonen and A-B-B's answers and thought of this variation.",
                "I use os.path.exists(), here is a Python 3 script that can be used to check if a directory exists, create one if it does not exist, and delete it if it does exist (if desired).It prompts users for input of the directory and can be easily modified.",
                "Use this command check and create dir",
                "Call the function create_dir() at the entry point of your program/project.",
                "If you consider the following:means a directory (path) exists AND is a directory. So for me this way does what I need. So I can make sure it is folder (not a file) and exists.",
                "You can use os.listdir for this:",
                "This may not exactly answer the question. But I guess your real intention is to create a file and its parent directories, given its content all in 1 command.You can do that with fastcore extension to pathlib: path.mk_write(data)See more in fastcore documentation"
            ]
        },
        {
            "tag": "python",
            "question": [
                "Accessing the index in 'for' loops",
                "How do I access the index while iterating over a sequence with a for loop?\nxs = [8, 23, 45]\n\nfor x in xs:\n    print(\"item #{} = {}\".format(index, x))\n\nDesired output:\nitem #1 = 8\nitem #2 = ..."
            ],
            "url": "https://stackoverflow.com/questions/522563",
            "answer": [
                "Use the built-in function enumerate():It is non-pythonic to manually index via for i in range(len(xs)): x = xs[i] or manually manage an additional state variable.Check out PEP 279 for more.",
                "Use enumerate to get the index with the element as you iterate:And note that Python's indexes start at zero, so you would get 0 to 4 with the above. If you want the count, 1 to 5, do this:What you are asking for is the Pythonic equivalent of the following, which is the algorithm most programmers of lower-level languages would use:Or in languages that do not have a for-each loop:or sometimes more commonly (but unidiomatically) found in Python:Python's enumerate function reduces the visual clutter by hiding the accounting for the indexes, and encapsulating the iterable into another iterable (an enumerate object) that yields a two-item tuple of the index and the item that the original iterable would provide. That looks like this:This code sample is fairly well the canonical example of the difference between code that is idiomatic of Python and code that is not. Idiomatic code is sophisticated (but not complicated) Python, written in the way that it was intended to be used. Idiomatic code is expected by the designers of the language, which means that usually this code is not just more readable, but also more efficient.Even if you don't need indexes as you go, but you need a count of the iterations (sometimes desirable) you can start with 1 and the final number will be your count.The count seems to be more what you intend to ask for (as opposed to index) when you said you wanted from 1 to 5.To break these examples down, say we have a list of items that we want to iterate over with an index:Now we pass this iterable to enumerate, creating an enumerate object:We can pull the first item out of this iterable that we would get in a loop with the next function:And we see we get a tuple of 0, the first index, and 'a', the first item:we can use what is referred to as \"sequence unpacking\" to extract the elements from this two-tuple:and when we inspect index, we find it refers to the first index, 0, and item refers to the first item, 'a'.So do this:",
                "It's pretty simple to start it from 1 other than 0:",
                "Here's how you can access the indices and array's elements using for-in loops.Result:Result:Result:Result:Result:Result:Result:Result:Result:",
                "As is the norm in Python, there are several ways to do this. In all examples assume: lst = [1, 2, 3, 4, 5]This is also the safest option in my opinion because the chance of going into infinite recursion has been eliminated. Both the item and its index are held in variables and there is no need to write any further code to access the item.As explained before, there are other ways to do this that have not been explained here and they may even apply more in other situations. For example, using itertools.chain with for. It handles nested loops better than the other examples.",
                "Old fashioned way:List comprehension:",
                "The fastest way to access indexes of list within loop in Python 3.7 is to use the enumerate method for small, medium and huge lists.Please see different approaches which can be used to iterate over list and access index value and their performance metrics (which I suppose would be useful for you) in code samples below:See performance metrics for each method below:As the result, using enumerate method is the fastest method for iteration when the index needed.Adding some useful links below:What is the difference between range and xrange functions in Python 2.X?What is faster for loop using enumerate or for loop using xrange in Python?range(len(list)) or enumerate(list)?",
                "You can use enumerate and embed expressions inside string literals to obtain the solution.This is a simple way:",
                "First of all, the indexes will be from 0 to 4. Programming languages start counting from 0; don't forget that or you will come across an index-out-of-bounds exception. All you need in the for loop is a variable counting from 0 to 4 like so:Keep in mind that I wrote 0 to 5 because the loop stops one number before the maximum. :)To get the value of an index, use",
                "You can do it with this code:Use this code if you need to reset the index value at the end of the loop:",
                "According to this discussion: object's list indexLoop counter iterationThe current idiom for looping over the indices makes use of the built-in range function:Looping over both elements and indices can be achieved either by the old idiom or by using the new zip built-in function:orvia PEP 212 \u2013 Loop Counter Iteration.",
                "In your question, you write \"how do I access the loop index, from 1 to 5 in this case?\"However, the index for a list runs from zero.  So, then we need to know if what you actually want is the index and item for each item in a list, or whether you really want numbers starting from 1.  Fortunately, in Python, it is easy to do either or both.First, to clarify, the enumerate function iteratively returns the index and corresponding item for each item in a list.The output for the above is then,Notice that the index runs from 0. This kind of indexing is common among modern programming languages including Python and C.If you want your loop to span a part of the list, you can use the standard Python syntax for a part of the list. For example, to loop from the second item in a list up to but not including the last item, you could useNote that once again, the output index runs from 0,That brings us to the start=n switch for enumerate().  This simply offsets the index, you can equivalently simply add a number to the index inside the loop.for which the output is",
                "If I were to iterate nums = [1, 2, 3, 4, 5] I would doOr get the length as l = len(nums)",
                "If there is no duplicate value in the list:",
                "You can also try this:The output is",
                "You can use the index method:It is highlighted in a comment that this method doesn\u2019t work if there are duplicates in ints. The method below should work for any values in ints:Or alternativelyif you want to get both the index and the value in ints as a list of tuples.It uses the method of enumerate in the selected answer to this question, but with list comprehension, making it faster with less code.",
                "A simple answer using a while loop:Output:",
                "You can simply use a variable such as count to count the number of elements in the list:",
                "To print a tuple of (index, value) in a list comprehension using a for loop:Output:",
                "In addition to all the excellent answers above, here is a solution to this problem when working with pandas Series objects. In many cases, pandas Series have custom/unique indices (for example, unique identifier strings) that can't be accessed with the enumerate() function.Output:We can see below that enumerate() doesn't give us the desired result:Output:We can access the indices of a pandas Series in a for loop using .items():Output:",
                "One-liner lovers:Explaination:Points to take:Thanks. Keep me in your prayers.",
                "You can use range(len(some_list)) and then lookup the index like thisOr use the Python\u2019s built-in enumerate function which allows you to loop over a list and retrieve the index and the value of each item in the list",
                "It can be achieved with the following code:Here, range(1, len(xs)+1); If you expect the output to start from 1 instead of 0, you need to start the range from 1 and add 1 to the total length estimated since python starts indexing the number from 0 by default.",
                "A loop with a \"counter\" variable set as an initialiser that will be a parameter, in formatting the string, as the item number.The for loop accesses the \"listos\" variable which is the list. As we access the list by \"i\", \"i\" is formatted as the item price (or whatever it is).Output:",
                "This serves the purpose well enough:"
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I make a flat list out of a list of lists?",
                "I have a list of lists like [[1, 2, 3], [4, 5, 6], [7], [8, 9]]. How can I flatten it to get [1, 2, 3, 4, 5, 6, 7, 8, 9]?\n\nIf your list of lists comes from a nested list comprehension, the problem can ..."
            ],
            "url": "https://stackoverflow.com/questions/952914",
            "answer": [
                "Given a list of lists l,which means:is faster than the shortcuts posted so far. (l is the list to flatten.)Here is the corresponding function:As evidence, you can use the timeit module in the standard library:Explanation: the shortcuts based on + (including the implied use in sum) are, of necessity, O(L**2) when there are L sublists -- as the intermediate result list keeps getting longer, at each step a new intermediate result list object gets allocated, and all the items in the previous intermediate result must be copied over (as well as a few new ones added at the end). So, for simplicity and without actual loss of generality, say you have L sublists of I items each: the first I items are copied back and forth L-1 times, the second I items L-2 times, and so on; total number of copies is I times the sum of x for x from 1 to L excluded, i.e., I * (L**2)/2.The list comprehension just generates one list, once, and copies each item over (from its original place of residence to the result list) also exactly once.",
                "You can use itertools.chain():Or you can use itertools.chain.from_iterable() which doesn't require unpacking the list with the * operator:This approach is arguably more readable than [item for sublist in l for item in sublist] and appears to be faster too:",
                "Note from the author: This is very inefficient. But fun, because monoids are awesome.sum sums the elements of the iterable xss, and uses the second argument as the initial value [] for the sum. (The default initial value is 0, which is not a list.)Because you are summing nested lists, you actually get [1,3]+[2,4] as a result of sum([[1,3],[2,4]],[]), which is equal to [1,3,2,4].Note that only works on lists of lists. For lists of lists of lists, you'll need another solution.",
                "I tested most suggested solutions with perfplot (a pet project of mine, essentially a wrapper around timeit), and foundto be the fastest solution, both when many small lists and few long lists are concatenated. (operator.iadd is equally fast.)A simpler and also acceptable variant isIf the number of sublists is large, this performs a little worse than the above suggestion.Code to reproduce the plot:",
                "Using functools.reduce, which adds an accumulated list xs to the next list ys:Output:A faster way using operator.concat:Output:",
                "Here is a general approach that applies to numbers, strings, nested lists and mixed containers.  This can flatten both simple and complicated containers (see also Demo).CodeNotes:DemoReference",
                "To flatten a data-structure that is deeply nested, use iteration_utilities.deepflatten1:It's a generator so you need to cast the result to a list or explicitly iterate over it.To flatten only one level and if each of the items is itself iterable you can also use iteration_utilities.flatten which itself is just a thin wrapper around itertools.chain.from_iterable:Just to add some timings (based on Nico Schl\u00f6mer's answer that didn't include the function presented in this answer):It's a log-log plot to accommodate for the huge range of values spanned. For qualitative reasoning: Lower is better.The results show that if the iterable contains only a few inner iterables then sum will be fastest, however for long iterables only the itertools.chain.from_iterable, iteration_utilities.deepflatten or the nested comprehension have reasonable performance with itertools.chain.from_iterable being the fastest (as already noticed by Nico Schl\u00f6mer).1 Disclaimer: I'm the author of that library",
                "The following seems simplest to me:",
                "Consider installing the more_itertools package.It ships with an implementation for flatten (source, from the itertools recipes):Note: as mentioned in the docs, flatten requires a list of lists.  See below on flattening more irregular inputs.As of version 2.4, you can flatten more complicated, nested iterables with more_itertools.collapse (source, contributed by  abarnet).",
                "The reason your function didn't work is because the extend extends an array in-place and doesn't return it. You can still return x from lambda, using something like this:Note: extend is more efficient than + on lists.",
                "matplotlib.cbook.flatten() will work for nested lists even if they nest more deeply than the example.Result:This is 18x faster than underscore._.flatten:",
                "According your list [[1, 2, 3], [4, 5, 6], [7], [8, 9]] which is 1 list level, we can simply use sum(list,[]) without using any librariesTo extend the advantage of this method when there is a tuple or number existing inside. Simply adding a mapping function for each element by map to the listIn here, there is a clear explanation of the drawback in terms of memory for this approach. In short, it recursively creates list objects, which should be avoided :(",
                "One can also use NumPy's flat:It only works when sublists have identical dimensions.",
                "You can use the list extend method. It shows to be the fastest:Performance:Output:",
                "There are several answers with the same recursive appending scheme as below, but none makes use of try, which makes the solution more robust and Pythonic.Usage: this is a generator, and you typically want to enclose it in an iterable builder like list() or tuple() or use it in a for loop.Advantages of this solution are:N.B.: Since all iterables are flattened, strings are decomposed into sequences of single characters. If you don't like/want such behavior, you can use the following version which filters out from flattening iterables like strings and bytes:",
                "Note: Below applies to Python 3.3+ because it uses yield_from.  six is also a third-party package, though it is stable.  Alternately, you could use sys.version.In the case of obj = [[1, 2,], [3, 4], [5, 6]], all of the solutions here are good, including list comprehension and itertools.chain.from_iterable.However, consider this slightly more complex case:There are several problems here:You can remedy this as follows:Here, you check that the sub-element (1) is iterable with Iterable, an ABC from itertools, but also want to ensure that (2) the element is not \"string-like.\"",
                "If you are willing to give up a tiny amount of speed for a cleaner look, then you could use numpy.concatenate().tolist() or numpy.concatenate().ravel().tolist():You can find out more here in the documentation, numpy.concatenate and numpy.ravel.",
                "I wanted a solution which can deal with multiple nesting ([[1], [[[2]], [3]]], [1, 2, 3] for example), but would also not be recursive (I had a big level of recursion and I got a recursion error.This is what I came up with:and tests:",
                "This may not be the most efficient way, but I thought to put a one-liner (actually a two-liner). Both versions will work on arbitrary hierarchy nested lists, and exploits language features (Python\u00a03.5) and recursion.The output isThis works in a depth first manner. The recursion goes down until it finds a non-list element, then extends the local variable flist and then rolls back it to the parent. Whenever flist is returned, it is extended to the parent's flist in the list comprehension. Therefore, at the root, a flat list is returned.The above one creates several local lists and returns them which are used to extend the parent's list. I think the way around for this may be creating a gloabl flist, like below.The output is againAlthough I am not sure at this time about the efficiency.",
                "Not a one-liner, but seeing all the answers here, I guess this long list missed some pattern matching, so here it is :)The two methods are probably not efficient, but anyway, it's easy to read (to me at least; perhaps I'm spoiled by functional programming):The second version considers lists of lists of lists... whatever the nesting:",
                "Another unusual approach that works for hetero- and homogeneous lists of integers:",
                "A non-recursive function to flatten lists of lists of any depth:",
                "If you want to unnest everything and keep a distinct list of elements, you could use this as well.",
                "If you have a numpy array a:produces:np.flatten also accepts other parameters:More details about parameters are available here.",
                "For a list containing multiple list here a recursive solution that work for me and that i hope is correct:Output:",
                "I would suggest using generators with yield statement and yield from.\nHere's an example:",
                "If I want to add something to the great previous answers, here is my recursive flatten function which can flatten not only nested lists, but also any given container or any generally any object which can throw out items. This does also work for any depth of nesting and it is a lazy iterator which yields the items as requested:This way, you can exclude types you don't want to be flattened, like str or what else.The idea is if an object can pass the iter() it's ready to yield items. So the iterable can have even generator expressions as an item.Someone could argue: Why did you write this that generic when the OP didn't ask for it? OK, you're right. I just felt like this might help someone (like it did for myself).Test cases:Output:",
                "Simplest Way to do in python without any libraryThis function will work for even multidimensional list alsousing recursion we can achieve any combination of list inside list, we can flatten it without using any library.",
                "Considering the list has just integers:"
            ]
        },
        {
            "tag": "python",
            "question": [
                "Difference between @staticmethod and @classmethod",
                "What is the difference between a function decorated with @staticmethod and one decorated with @classmethod?"
            ],
            "url": "https://stackoverflow.com/questions/136097",
            "answer": [
                "Maybe a bit of example code will help: Notice the difference in the call signatures of foo, class_foo and static_foo:Below is the usual way an object instance calls a method. The object instance, a, is implicitly passed as the first argument.With classmethods, the class of the object instance is implicitly passed as the first argument instead of self.You can also call class_foo using the class. In fact, if you define something to be\na classmethod, it is probably because you intend to call it from the class rather than from a class instance. A.foo(1) would have raised a TypeError, but A.class_foo(1) works just fine:One use people have found for class methods is to create inheritable alternative constructors.With staticmethods, neither self (the object instance) nor  cls (the class) is implicitly passed as the first argument. They behave like plain functions except that you can call them from an instance or the class:Staticmethods are used to group functions which have some logical connection with a class to the class.foo is just a function, but when you call a.foo you don't just get the function,\nyou get a \"partially applied\" version of the function with the object instance a bound as the first argument to the function. foo expects 2 arguments, while a.foo only expects 1 argument.a is bound to foo. That is what is meant by the term \"bound\" below:With a.class_foo, a is not bound to class_foo, rather the class A is bound to class_foo.Here, with a staticmethod, even though it is a method, a.static_foo just returns\na good 'ole function with no arguments bound. static_foo expects 1 argument, and\na.static_foo expects 1 argument too.And of course the same thing happens when you call static_foo with the class A instead.",
                "A staticmethod is a method that knows nothing about the class or instance it was called on. It just gets the arguments that were passed, no implicit first argument. It is basically useless in Python -- you can just use a module function instead of a staticmethod.A classmethod, on the other hand, is a method that gets passed the class it was called on, or the class of the instance it was called on, as first argument. This is useful when you want the method to be a factory for the class: since it gets the actual class it was called on as first argument, you can always instantiate the right class, even when subclasses are involved. Observe for instance how dict.fromkeys(), a classmethod, returns an instance of the subclass when called on a subclass:",
                "Basically @classmethod makes a method whose first argument is the class it's called from (rather than the class instance), @staticmethod does not have any implicit arguments.",
                "To decide whether to use @staticmethod or @classmethod you have to look inside your method. If your method accesses other variables/methods in your class then use @classmethod. On the other hand, if your method does not touches any other parts of the class then use @staticmethod.",
                "Official python docs:@classmethodA class method receives the class as\n  implicit first argument, just like an\n  instance method receives the instance.\n  To declare a class method, use this\n  idiom:The @classmethod form is a function\n  decorator \u2013 see the description of\n  function definitions in Function\n  definitions for details.It can be called either on the class\n  (such as C.f()) or on an instance\n  (such as C().f()). The instance is\n  ignored except for its class. If a\n  class method is called for a derived\n  class, the derived class object is\n  passed as the implied first argument.Class methods are different than C++\n  or Java static methods. If you want\n  those, see staticmethod() in this\n  section.@staticmethodA static method does not receive an\n  implicit first argument. To declare a\n  static method, use this idiom:The @staticmethod form is a function\n  decorator \u2013 see the description of\n  function definitions in Function\n  definitions for details.It can be called either on the class\n  (such as C.f()) or on an instance\n  (such as C().f()). The instance is\n  ignored except for its class.Static methods in Python are similar\n  to those found in Java or C++. For a\n  more advanced concept, see\n  classmethod() in this section.",
                "Here is a short article on this question@staticmethod function is nothing more than a function defined inside a class. It is callable without instantiating the class first. It\u2019s definition is immutable via inheritance.@classmethod function also callable without instantiating the class, but its definition follows Sub class, not Parent class, via inheritance. That\u2019s because the first argument for @classmethod function must always be cls (class).",
                "You may have seen Python code like this pseudocode, which demonstrates the signatures of the various method types and provides a docstring to explain each:First I'll explain a_normal_instance_method. This is precisely called an \"instance method\". When an instance method is used, it is used as a partial function (as opposed to a total function, defined for all values when viewed in source code) that is, when used, the first of the arguments is predefined as the instance of the object, with all of its given attributes. It has the instance of the object bound to it, and it must be called from an instance of the object. Typically, it will access various attributes of the instance.For example, this is an instance of a string:if we use the instance method, join on this string, to join another iterable,\nit quite obviously is a function of the instance, in addition to being a function of the iterable list, ['a', 'b', 'c']:Instance methods can be bound via a dotted lookup for use later.For example, this binds the str.join method to the ':' instance:And later we can use this as a function that already has the first argument bound to it. In this way, it works like a partial function on the instance:The static method does not take the instance as an argument.It is very similar to a module level function.However, a module level function must live in the module and be specially imported to other places where it is used.If it is attached to the object, however, it will follow the object conveniently through importing and inheritance as well.An example of a static method is str.maketrans, moved from the string module in Python 3.  It makes a translation table suitable for consumption by str.translate. It does seem rather silly when used from an instance of a string, as demonstrated below, but importing the function from the string module is rather clumsy, and it's nice to be able to call it from the class, as in str.maketransIn python 2, you have to import this function from the increasingly less useful string module:A class method is a similar to an instance method in that it takes an implicit first argument, but instead of taking the instance, it takes the class. Frequently these are used as alternative constructors for better semantic usage and it will support inheritance.The most canonical example of a builtin classmethod is dict.fromkeys. It is used as an alternative constructor of dict, (well suited for when you know what your keys are and want a default value for them.)When we subclass dict, we can use the same constructor, which creates an instance of the subclass.See the pandas source code for other similar examples of alternative constructors, and see also the official Python documentation on classmethod and staticmethod.",
                "I started learning programming language with C++ and then Java and then Python and so this question bothered me a lot as well, until I understood the simple usage of each.Class Method: Python unlike Java and C++ doesn't have constructor overloading.  And so to achieve this you could use classmethod. Following example will explain thisLet's consider we have a Person class which takes two arguments first_name and last_name and creates the instance of Person.Now, if the requirement comes where you need to create a class using a single name only, just a first_name, you can't do something like this in Python.This will give you an error when you will try to create an object (instance).However, you could achieve the same thing using @classmethod as mentioned belowStatic Method: This is rather simple, it's not bound to instance or class and you can simply call that using class name.So let's say in above example you need a validation that first_name should not exceed 20 characters, you can simply do this.and you could simply call using class name",
                "Only the first argument differs:In more detail...The \"standard\" method, as in every object oriented language. When an object's method is called, it is automatically given an extra argument self as its first argument. That is, methodmust be called with 2 arguments. self is automatically passed, and it is the object itself. Similar to the this that magically appears in eg. java/c++, only in python it is shown explicitly.actually, the first argument does not have to be called self, but it's the standard convention, so keep itWhen the method is decoratedthe automatically provided argument is not self, but the class of self.When the method is decoratedthe method is not given any automatic argument at all. It is only given the parameters that it is called with.",
                "I think a better question is \"When would you use @classmethod vs @staticmethod?\"@classmethod allows you easy access to private members that are associated to the class definition. this is a great way to do singletons, or factory classes that control the number of instances of the created objects exist.@staticmethod provides marginal performance gains, but I have yet to see a productive use of a static method within a class that couldn't be achieved as a standalone function outside the class.",
                "Static Methods:Benefits of Static Methods:More convenient to import versus module-level functions since each method does not have to be specially importedClass Methods:These are created with classmethod in-built function.",
                "@decorators were added in python 2.4 If you're using python < 2.4 you can use the classmethod() and staticmethod() function.For example, if you want to create a factory method (A function returning an instance of a different implementation of a class depending on what argument it gets) you can do something like:Also observe that this is a good example for using a classmethod and a static method,\nThe static method clearly belongs to the class, since it uses the class Cluster internally.\nThe classmethod only needs information about the class, and no instance of the object.Another benefit of making the _is_cluster_for method a classmethod is so a subclass can decide to change it's implementation, maybe because it is pretty generic and can handle more than one type of cluster, so just checking the name of the class would not be enough.",
                "Let me tell the similarity between a method decorated with @classmethod vs @staticmethod first.Similarity: Both of them can be called on the Class itself, rather than just the instance of the class. So, both of them in a sense are Class's methods.Difference: A classmethod will receive the class itself as the first argument, while a staticmethod does not.So a static method is, in a sense, not bound to the Class itself and is just hanging in there just because it may have a related functionality.",
                "@staticmethod just disables the default function as method descriptor.  classmethod wraps your function in a container callable that passes a reference to the owning class as first argument:As a matter of fact, classmethod has a runtime overhead but makes it possible to access the owning class.  Alternatively I recommend using a metaclass and putting the class methods on that metaclass:",
                "The definitive guide on how to use static, class or abstract methods in Python is one good link for this topic, and summary it as following.@staticmethod function is nothing more than a function defined inside a class. It is callable without instantiating the class first. It\u2019s definition is immutable via inheritance.@classmethod function also callable without instantiating the class, but its definition follows Sub class, not Parent class, via inheritance, can be overridden by subclass. That\u2019s because the first argument for @classmethod function must always be cls (class).",
                "Another consideration with respect to staticmethod vs classmethod comes up with inheritance.  Say you have the following class:And you then want to override bar() in a child class:This works, but note that now the bar() implementation in the child class (Foo2) can no longer take advantage of anything specific to that class.  For example, say Foo2 had a method called magic() that you want to use in the Foo2 implementation of bar():The workaround here would be to call Foo2.magic() in bar(), but then you're repeating yourself (if the name of Foo2 changes, you'll have to remember to update that bar() method).To me, this is a slight violation of the open/closed principle, since a decision made in Foo is impacting your ability to refactor common code in a derived class (ie it's less open to extension).  If bar() were a classmethod we'd be fine:Gives: In Foo2 MAGICAlso: historical note: Guido Van Rossum (Python's creator) once referred to staticmethod's as \"an accident\": https://mail.python.org/pipermail/python-ideas/2012-May/014969.htmlwe all know how limited static methods are. (They're basically an accident -- back in the Python 2.2 days when I was inventing new-style classes and descriptors, I meant to implement class methods but at first I didn't understand them and accidentally implemented static methods first. Then it was too late to remove them and only provide class methods.Also: https://mail.python.org/pipermail/python-ideas/2016-July/041189.htmlHonestly, staticmethod was something of a mistake -- I was trying to do something like Java class methods but once it was released I found what was really needed was classmethod. But it was too late to get rid of staticmethod.",
                "I will try to explain the basic difference using an example.1 - we can directly call static and classmethods without initializing2- Static method cannot call self method but can call other static and classmethod3- Static method belong to class and will not use object at all.4- Class method are not bound to an object but to a class.",
                "Python comes with several built-in decorators. The big three are:First let's note that any function of a class can be called with instance of this class (after we initialized this class).@classmethod is the way to call function not only as an instance of a class but also directly by the class itself as its first argument.@staticmethod is a way of putting a function into a class (because it logically belongs there), while indicating that it does not require access to the class (so we don't need to use self in function definition).Let's consider the following class:Let's see how it works:Here you can see some use cases for those methods.Bonus: you can read about @property decorator here",
                "The difference occurs when there is inheritance.Suppose that there are two classes-- Parent and Child. If one wants to use @staticmethod, print_name method should be written twice because the name of the class should be written in the print line.However, for @classmethod, it is not required to write print_name method twice.",
                "Instance Method:+ Can modify object instance state+ Can modify class stateClass Method:- Can't modify object instance state+ Can modify class stateStatic Method:- Can't modify object instance state- Can't modify class stateoutput:The instance method we actually had access to the object instance , right so this was an instance off a my class object whereas with the class method we have access to the class itself. But not to any of the objects,  because the class method doesn't really care about an object existing. However you can both call a class method and static method on an object instance. This is going to work it doesn't really make a difference, so again when you call static method here it's going to work and it's going to know which method you want to call.The Static methods are used to do some utility tasks, and class methods are used for factory methods. The factory methods can return class objects for different use cases.And finally, a short example for better understanding:",
                "@classmethod : can be used to create a shared global access to all the instances created of that class..... like updating a record by multiple users....\nI particulary found it use ful when creating singletons as well..:)@static method:  has nothing to do with the class or instance being associated with ...but for readability can use static method",
                "My contribution demonstrates the difference amongst @classmethod, @staticmethod, and instance methods, including how an instance can indirectly call a @staticmethod. But instead of indirectly calling a @staticmethod from an instance, making it private may be more \"pythonic.\" Getting something from a private method isn't demonstrated here but it's basically the same concept.",
                "A class method receives the class as implicit first argument, just like an instance method receives the instance. It is a method which is bound to the class and not the object of the class.It has access to the state of the class as it takes a class parameter that points to the class and not the object instance. It can modify a class state that would apply across all the instances of the class. For example it can modify a class variable that will be applicable to all the instances.On the other hand, a static method does not receive an implicit first argument, compared to class methods or instance methods. And can\u2019t access or modify class state. It only belongs to the class because from design point of view that is the correct way. But in terms of functionality is not bound, at runtime, to the class.as a guideline, use static methods as utilities, use class methods for example as factory . Or maybe to define a singleton. And use instance methods to model the state and behavior of instances.Hope I was clear !",
                "You might want to consider the difference between:andThis has changed between python2 and python3:python2:python3:So using  @staticmethod for methods only called directly from the class has become optional in python3. If you want to call them from both class and instance, you still need to use the @staticmethod decorator.The other cases have been well covered by unutbus answer.",
                "Class methods, as the name suggests, are used to make changes to classes and not the objects. To make changes to classes, they will modify the class attributes(not object attributes), since that is how you update classes.\nThis is the reason that class methods take the class(conventionally denoted by 'cls') as the first argument.Static methods on the other hand, are used to perform functionalities that are not bound to the class i.e. they will not read or write class variables. Hence, static methods do not take classes as arguments. They are used so that classes can perform functionalities that are not directly related to the purpose of the class.",
                "I think giving a purely Python version of staticmethod and classmethod would help to understand the difference between them at language level (Refers to Descriptor Howto Guide).Both of them are non-data descriptors (It would be easier to understand them if you are familiar with descriptors first).",
                "Analyze @staticmethod literally providing different insights.A normal method of a class is an implicit dynamic method which takes the instance as first argument.\nIn contrast, a staticmethod does not take the instance as first argument, so is called 'static'.A staticmethod is indeed such a normal function the same as those outside a class definition.\nIt is luckily grouped into the class just in order to stand closer where it is applied, or you might scroll around to find it.",
                "One pretty important practical difference occurs when subclassing. If you don't mind, I'll hijack @unutbu's example:In class_foo, the method knows which class it is called on:In static_foo, there is no way to determine whether it is called on A or B:Note that this doesn't mean you can't use other methods in a staticmethod, you just have to reference the class directly, which means subclasses' staticmethods will still reference the parent class:",
                "tldr;A staticmethod is essentially a function bound to a class (and consequently its instances)A classmethod is essentially an inheritable staticmethod.For details, see the excellent answers by others.",
                "First let's start with an example code that we'll use to understand both concepts:Class methodA class method accepts the class itself as an implicit argument and -optionally- any other arguments specified in the definition. It\u2019s important to understand that a class method, does not have access to object instances (like instance methods do). Therefore, class methods cannot be used to alter the state of an instantiated object but instead, they are capable of changing the class state which is shared amongst all the instances of that class.\nClass methods are typically useful when we need to access the class itself \u2014 for example, when we want to create a factory method, that is a method that creates instances of the class. In other words, class methods can serve as alternative constructors.In our example code, an instance of Employee can be constructed by providing three arguments; first_name , last_name and salary.Now let\u2019s assume that there\u2019s a chance that the name of an Employee can be provided in a single field in which the first and last names are separated by a whitespace. In this case, we could possibly use our class method called employee_from_full_name that accepts three arguments in total. The first one, is the class itself, which is an implicit argument which means that it won\u2019t be provided when calling the method \u2014 Python will automatically do this for us:Note that it is also possible to call employee_from_full_name from object instances although in this context it doesn\u2019t make a lot of sense:Another reason why we might want to create a class method, is when we need to change the state of the class. In our example, the class variable NO_OF_EMPLOYEES keeps track of the number of employees currently working for the company. This method is called every time a new instance of Employee is created and it updates the count accordingly:Static methodsOn the other hand, in static methods neither the instance (i.e. self) nor the class itself (i.e. cls) is passed as an implicit argument. This means that such methods, are not capable of accessing the class itself or its instances.\nNow one could argue that static methods are not useful in the context of classes as they can also be placed in helper modules instead of adding them as members of the class. In object oriented programming, it is important to structure your classes into logical chunks and thus, static methods are quite useful when we need to add a method under a class simply because it logically belongs to the class.\nIn our example, the static method named get_employee_legal_obligations_txt simply returns a string that contains the legal obligations of every single employee of a company. This function, does not interact with the class itself nor with any instance. It could have been placed into a different helper module however, it is only relevant to this class and therefore we have to place it under the Employee class.A static method can be access directly from the class itselfor from an instance of the class:References"
            ]
        },
        {
            "tag": "python",
            "question": [
                "Understanding slicing",
                "I need a good explanation (references are a plus) on Python slicing."
            ],
            "url": "https://stackoverflow.com/questions/509211",
            "answer": [
                "The syntax is:There is also the step value, which can be used with any of the above:The key point to remember is that the :stop value represents the first value that is not in the selected slice. So, the difference between stop and start is the number of elements selected (if step is 1, the default).The other feature is that start or stop may be a negative number, which means it counts from the end of the array instead of the beginning. So:Similarly, step may be a negative number:Python is kind to the programmer if there are fewer items than you ask for. For example, if you ask for a[:-2] and a only contains one element, you get an empty list instead of an error. Sometimes you would prefer the error, so you have to be aware that this may happen.A slice object can represent a slicing operation, i.e.:is equivalent to:Slice objects also behave slightly differently depending on the number of arguments, similarly to range(), i.e. both slice(stop) and slice(start, stop[, step]) are supported.\nTo skip specifying a given argument, one might use None, so that e.g. a[start:] is equivalent to a[slice(start, None)] or a[::-1] is equivalent to a[slice(None, None, -1)].While the :-based notation is very helpful for simple slicing, the explicit use of slice() objects simplifies the programmatic generation of slicing.",
                "The Python tutorial talks about it (scroll down a bit until you get to the part about slicing).The ASCII art diagram is helpful too for remembering how slices work:One way to remember how slices work is to think of the indices as pointing between characters, with the left edge of the first character numbered 0. Then the right edge of the last character of a string of n characters has index n.",
                "Enumerating the possibilities allowed by the grammar for the sequence x:Of course, if (high-low)%stride != 0, then the end point will be a little lower than high-1.If stride is negative, the ordering is changed a bit since we're counting down:Extended slicing (with commas and ellipses) are mostly used only by special data structures (like NumPy); the basic sequences don't support them.",
                "The answers above don't discuss slice assignment. To understand slice assignment, it's helpful to add another concept to the ASCII art:One heuristic is, for a slice from zero to n, think: \"zero is the beginning, start at the beginning and take n items in a list\".Another heuristic is, \"for any slice, replace the start by zero, apply the previous heuristic to get the end of the list, then count the first number back up to chop items off the beginning\"The first rule of slice assignment is that since slicing returns a list, slice assignment requires a list (or other iterable):The second rule of slice assignment, which you can also see above, is that whatever portion of the list is returned by slice indexing, that's the same portion that is changed by slice assignment:The third rule of slice assignment is, the assigned list (iterable) doesn't have to have the same length; the indexed slice is simply sliced out and replaced en masse by whatever is being assigned:The trickiest part to get used to is assignment to empty slices. Using heuristic 1 and 2 it's easy to get your head around indexing an empty slice:And then once you've seen that, slice assignment to the empty slice makes sense too:Note that, since we are not changing the second number of the slice (4), the inserted items always stack right up against the 'o', even when we're assigning to the empty slice. So the position for the empty slice assignment is the logical extension of the positions for the non-empty slice assignments.Backing up a little bit, what happens when you keep going with our procession of counting up the slice beginning?With slicing, once you're done, you're done; it doesn't start slicing backwards. In Python you don't get negative strides unless you explicitly ask for them by using a negative number.There are some weird consequences to the \"once you're done, you're done\" rule:In fact, compared to indexing, Python slicing is bizarrely error-proof:This can come in handy sometimes, but it can also lead to somewhat strange behavior:Depending on your application, that might... or might not... be what you were hoping for there!Below is the text of my original answer. It has been useful to many people, so I didn't want to delete it.This may also clarify the difference between slicing and indexing.",
                "In short, the colons (:) in subscript notation (subscriptable[subscriptarg]) make slice notation, which has the optional arguments start, stop, and step:Python slicing is a computationally fast way to methodically access parts of your data. In my opinion, to be even an intermediate Python programmer, it's one aspect of the language that it is necessary to be familiar with.To begin with, let's define a few terms:start: the beginning index of the slice, it will include the element at this index unless it is the same as stop, defaults to 0, i.e. the first index. If it's negative, it means to start n items from the end.stop: the ending index of the slice, it does not include the element at this index, defaults to length of the sequence being sliced, that is, up to and including the end.step: the amount by which the index increases, defaults to 1. If it's negative, you're slicing over the iterable in reverse.You can make any of these positive or negative numbers. The meaning of the positive numbers is straightforward, but for negative numbers, just like indexes in Python, you count backwards from the end for the start and stop, and for the step, you simply decrement your index. This example is from the documentation's tutorial, but I've modified it slightly to indicate which item in a sequence each index references:To use slice notation with a sequence that supports it, you must include at least one colon in the square brackets that follow the sequence (which actually implement the __getitem__ method of the sequence, according to the Python data model.)Slice notation works like this:And recall that there are defaults for start, stop, and step, so to access the defaults, simply leave out the argument.Slice notation to get the last nine elements from a list (or any other sequence that supports it, like a string) would look like this:When I see this, I read the part in the brackets as \"9th from the end, to the end.\" (Actually, I abbreviate it mentally as \"-9, on\")The full notation isand to substitute the defaults (actually when step is negative, stop's default is -len(my_list) - 1, so None for stop really just means it goes to whichever end step takes it to):The colon, :,  is what tells Python you're giving it a slice and not a regular index. That's why the idiomatic way of making a shallow copy of lists in Python 2 isAnd clearing them is with:(Python 3 gets a list.copy and list.clear method.)By default, when the step argument is empty (or None), it is assigned to +1.But you can pass in a negative integer, and the list (or most other standard sliceables) will be sliced from the end to the beginning.Thus a negative slice will change the defaults for start and stop!I like to encourage users to read the source as well as the documentation. The source code for slice objects and this logic is found here. First we determine if step is negative:If so, the lower bound is -1  meaning we slice all the way up to and including the beginning, and the upper bound is the length minus 1, meaning we start at the end. (Note that the semantics of this -1 is different from a -1 that users may pass indexes in Python indicating the last item.)Otherwise step is positive, and the lower bound will be zero and the upper bound (which we go up to but not including) the length of the sliced list.Then, we may need to apply the defaults for start and stop\u2014the default then for start is calculated as the upper bound when step is negative:and stop, the lower bound:You may find it useful to separate forming the slice from passing it to the list.__getitem__ method (that's what the square brackets do). Even if you're not new to it, it keeps your code more readable so that others that may have to read your code can more readily understand what you're doing.However, you can't just assign some integers separated by colons to a variable. You need to use the slice object:The second argument, None, is required, so that the first argument is interpreted as the start argument otherwise it would be the stop argument.You can then pass the slice object to your sequence:It's interesting that ranges also take slices:Since slices of Python lists create new objects in memory, another important function to be aware of is itertools.islice. Typically you'll want to iterate over a slice, not just have it created statically in memory. islice is perfect for this. A caveat, it doesn't support negative arguments to start, stop, or step, so if that's an issue you may need to calculate indices or reverse the iterable in advance.and now:The fact that list slices make a copy is a feature of lists themselves. If you're slicing advanced objects like a Pandas DataFrame, it may return a view on the original, and not a copy.",
                "And a couple of things that weren't immediately obvious to me when I first saw the slicing syntax:Easy way to reverse sequences!And if you wanted, for some reason, every second item in the reversed sequence:",
                "In Python 2.7Slicing in PythonUnderstanding index assignment is very important.When you say [a:b:c], you are saying depending on the sign of c (forward or backward), start at a and end at b (excluding element at bth index). Use the indexing rule above and remember you will only find elements in this range:But this range continues in both directions infinitely:For example:If your choice of a, b, and c allows overlap with the range above as you traverse using rules for a,b,c above you will either get a list with elements (touched during traversal) or you will get an empty list.One last thing: if a and b are equal, then also you get an empty list:",
                "Found this great table at http://wiki.python.org/moin/MovingToPythonFromOtherLanguages",
                "After using it a bit I realise that the simplest description is that it is exactly the same as the arguments in a for loop...Any of them are optional:Then the negative indexing just needs you to add the length of the string to the negative indices to understand it.This works for me anyway...",
                "I find it easier to remember how it works, and then I can figure out any specific start/stop/step combination.It's instructive to understand range() first:Begin from start, increment by step, do not reach stop.  Very simple.The thing to remember about negative step is that stop is always the excluded end, whether it's higher or lower. If you want same slice in opposite order, it's much cleaner to do the reversal separately: e.g. 'abcde'[1:-2][::-1] slices off one char from left, two from right, then reverses. (See also reversed().)Sequence slicing is same, except it first normalizes negative indexes, and it can never go outside the sequence:TODO: The code below had a bug with \"never go outside the sequence\" when abs(step)>1; I think I patched it to be correct, but it's hard to understand.Don't worry about the is None details - just remember that omitting start and/or stop always does the right thing to give you the whole sequence.Normalizing negative indexes first allows start and/or stop to be counted from the end independently: 'abcde'[1:-2] == 'abcde'[1:3] == 'bc' despite range(1,-2) == [].\nThe normalization is sometimes thought of as \"modulo the length\", but note it adds the length just once: e.g. 'abcde'[-53:42] is just the whole string.",
                "I use the \"an index points between elements\" method of thinking about it myself, but one way of describing it which sometimes helps others get it is this:X is the index of the first element you want.\nY is the index of the first element you don't want.",
                "I hope this will help you to model the list in Python.Reference: http://wiki.python.org/moin/MovingToPythonFromOtherLanguages",
                "This is how I teach slices to newbies:Understanding the difference between indexing and slicing:Wiki Python has this amazing picture which clearly distinguishes indexing and slicing.It is a list with six elements in it. To understand slicing better, consider that list as a set of six boxes placed together. Each box has an alphabet in it.Indexing is like dealing with the contents of box. You can check contents of any box. But you can't check the contents of multiple boxes at once. You can even replace the contents of the box. But you can't place two balls in one box or replace two balls at a time.Slicing is like dealing with boxes themselves. You can pick up the first box and place it on another table. To pick up the box, all you need to know is the position of beginning and ending of the box.You can even pick up the first three boxes or the last two boxes or all boxes between 1 and 4. So, you can pick any set of boxes if you know the beginning and ending. These positions are called start and stop positions.The interesting thing is that you can replace multiple boxes at once. Also you can place multiple boxes wherever you like.Slicing With Step:Till now you have picked boxes continuously. But sometimes you need to pick up discretely. For example, you can pick up every second box. You can even pick up every third box from the end. This value is called step size. This represents the gap between your successive pickups. The step size should be positive if You are picking boxes from the beginning to end and vice versa.How Python Figures Out Missing Parameters:When slicing, if you leave out any parameter, Python tries to figure it out automatically.If you check the source code of CPython, you will find a function called PySlice_GetIndicesEx() which figures out indices to a slice for any given parameters. Here is the logical equivalent code in Python.This function takes a Python object and optional parameters for slicing and returns the start, stop, step, and slice length for the requested slice.This is the intelligence that is present behind slices. Since Python has an built-in function called slice, you can pass some parameters and check how smartly it calculates missing parameters.Note: This post was originally written in my blog, The Intelligence Behind Python Slices.",
                "Python slicing notation:The notation extends to (numpy) matrices and multidimensional arrays.  For example, to slice entire columns you can use:Slices hold references, not copies, of the array elements.  If you want to make a separate copy an array, you can use deepcopy().",
                "You can also use slice assignment to remove one or more elements from a list:",
                "This is just for some extra info...\nConsider the list belowFew other tricks for reversing the list:",
                "To make it simple, remember slice has only one form\uff1aand here is how it works:Another import thing: all start,end, step can be omitted! And if they are omitted, their default value will be used: 0,len(s),1 accordingly.So possible variations are:NOTE: If start >= end (considering only when step>0), Python will return a empty slice [].The above part explains the core features on how slice works, and it will work on most occasions. However, there can be pitfalls you should watch out, and this part explains them.The very first thing that confuses Python learners is that an index can be negative!\nDon't panic: a negative index means count backwards.For example:Making things more confusing is that step can be negative too!A negative step means iterate the array backwards: from the end to start, with the end index included, and the start index excluded from the result.NOTE: when step is negative, the default value for start is len(s) (while end does not equal to 0, because s[::-1] contains s[0]). For example:Be surprised: slice does not raise an IndexError when the index is out of range!If the index is out of range, Python will try its best to set the index to 0 or len(s) according to the situation. For example:Let's finish this answer with examples, explaining everything we have discussed:",
                "As a general rule, writing code with a lot of hardcoded index values leads to a readability\nand maintenance mess. For example, if you come back to the code a year later, you\u2019ll\nlook at it and wonder what you were thinking when you wrote it. The solution shown\nis simply a way of more clearly stating what your code is actually doing.\nIn general, the built-in slice() creates a slice object that can be used anywhere a slice\nis allowed. For example:If you have a slice instance s, you can get more information about it by looking at its\ns.start, s.stop, and s.step attributes, respectively. For example:",
                "The previous answers don't discuss multi-dimensional array slicing which is possible using the famous NumPy package:Slicing can also be applied to multi-dimensional arrays.The \":2\" before the comma operates on the first dimension and the \"0:3:2\" after the comma operates on the second dimension.",
                "I- Convert upper bound  and lower bound into common signs.II- Then check if the step size is a positive or a negative value.(i) If the step size is a positive value, upper bound should be greater than lower bound, otherwise empty string is printed. For example:The output:However if we run the following code:It will return an empty string.(ii) If the step size if a negative value, upper bound should be lesser than lower bound, otherwise empty string will be printed. For example:The output:But if we run the following code:The output will be an empty string.Thus in the code:In the first str2=str[l-1:0:-1], the upper bound is lesser than the lower bound, thus dcb is printed.However in str2=str[l-1:-1:-1], the upper bound is not less than the lower bound (upon converting lower bound into negative value which is -1: since index of last element is -1 as well as 3).",
                "In my opinion, you will understand and memorize better the Python string slicing notation if you look at it the following way (read on).Let's work with the following string ...For those who don't know, you can create any substring from azString using the notation azString[x:y]Coming from other programming languages, that's when the common sense gets compromised. What are x and y?I had to sit down and run several scenarios in my quest for a memorization technique that will help me remember what x and y are and help me slice strings properly at the first attempt.My conclusion is that x and y should be seen as the boundary indexes that are surrounding the strings that we want to extra. So we should see the expression as azString[index1, index2] or even more clearer as azString[index_of_first_character, index_after_the_last_character].Here is an example visualization of that ...So all you have to do is setting index1 and index2 to the values that will surround the desired substring. For instance, to get the substring \"cdefgh\", you can use azString[2:8], because the index on the left side of \"c\" is 2 and the one on the right size of \"h\" is 8.Remember that we are setting the boundaries. And those boundaries are the positions where you could place some brackets that will be wrapped around the substring like this ...a b [ c d e f g h ] i jThat trick works all the time and is easy to memorize.",
                "I personally think about it like a for loop:Also, note that negative values for start and end are relative to the end of the list and computed in the example above by given_index + a.shape[0].",
                "You can run this script and experiment with it, below is some samples that I got from the script.When using a negative step, notice that the answer is shifted to the right by 1.",
                "My brain seems happy to accept that lst[start:end] contains the start-th item. I might even say that it is a 'natural assumption'.But occasionally a doubt creeps in and my brain asks for reassurance that it does not contain the end-th element.In these moments I rely on this simple theorem:This pretty property tells me that lst[start:end] does not contain the end-th item because it is in lst[end:].Note that this theorem is true for any n at all. For example, you can check thatreturns True.",
                "In Python, the most basic form for slicing is the following:where l is some collection, start is an inclusive index, and end is an exclusive index.When slicing from the start, you can omit the zero index, and when slicing to the end, you can omit the final index since it is redundant, so do not be verbose:Negative integers are useful when doing offsets relative to the end of a collection:It is possible to provide indices that are out of bounds when slicing such as:Keep in mind that the result of slicing a collection is a whole new collection. In addition, when using slice notation in assignments, the length of the slice assignments do not need to be the same. The values before and after the assigned slice will be kept, and the collection will shrink or grow to contain the new values:If you omit the start and end index, you will make a copy of the collection:If the start and end indexes are omitted when performing an assignment operation, the entire content of the collection will be replaced with a copy of what is referenced:Besides basic slicing, it is also possible to apply the following notation:where l is a collection, start is an inclusive index, end is an exclusive index, and step is a stride that can be used to take every nth item in l.Using step provides a useful trick to reverse a collection in Python:It is also possible to use negative integers for step as the following example:However, using a negative value for step could become very confusing. Moreover, in order to be Pythonic, you should avoid using start, end, and step in a single slice. In case this is required, consider doing this in two assignments (one to slice, and the other to stride).",
                "I want to add one Hello, World! example that explains the basics of slices for the very beginners. It helped me a lot.Let's have a list with six values ['P', 'Y', 'T', 'H', 'O', 'N']:Now the simplest slices of that list are its sublists. The notation is [<index>:<index>] and the key is to read it like this:Now if you make a slice [2:5] of the list above, this will happen:You made a cut before the element with index 2 and another cut before the element with index 5. So the result will be a slice between those two cuts, a list ['T', 'H', 'O'].",
                "Most of the previous answers clears up questions about slice notation.The extended indexing syntax used for slicing is aList[start:stop:step], and basic examples are::More slicing examples: 15 Extended Slices",
                "The below is the example of an index of a string:Slicing example: [start:end:step]Below is the example usage:",
                "If you feel negative indices in slicing is confusing, here's a very easy way to think about it: just replace the negative index with len - index. So for example, replace -3 with len(list) - 3.The best way to illustrate what slicing does internally is just show it in code that implements this operation:",
                "I don't think that the Python tutorial diagram (cited in various other answers) is good as this suggestion works for positive stride, but does not for a negative stride.This is the diagram:From the diagram, I expect a[-4,-6,-1] to be yP but it is ty.What always work is to think in characters or slots and use indexing as a half-open interval -- right-open if positive stride, left-open if negative stride.This way, I can think of a[-4:-6:-1] as a(-6,-4] in interval terminology."
            ]
        },
        {
            "tag": "python",
            "question": [
                "Finding the index of an item in a list",
                "Given a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", how do I get its index 1?"
            ],
            "url": "https://stackoverflow.com/questions/176918",
            "answer": [
                "The simplest case is handled by the built-in .index method of the list:Return zero-based index in the list of the first item whose value is equal to x. Raises a ValueError if there is no such item.The optional arguments start and end are interpreted as in the slice notation and are used to limit the search to a particular subsequence of the list. The returned index is computed relative to the beginning of the full sequence rather than the start argument.Thus, we can do:An index call checks every element of the list in order, until it finds a match. If the list is long, and if there is no guarantee that the value will be near the beginning, this can slow down the code.This problem can only be completely avoided by using a different data structure. However, if the element is known to be within a certain part of the list, the start and end parameters can be used to narrow the search.For example:The second call is orders of magnitude faster, because it only has to search through 10 elements, rather than all 1 million.A call to index searches through the list in order until it finds a match, and stops there. If there could be more than one occurrence of the value, and all indices are needed, index cannot solve the problem:Instead, use a list comprehension or generator expression to do the search, with enumerate to get indices:The list comprehension and generator expression techniques still work if there is only one match, and are more generalizable.As noted in the documentation above, using .index will raise an exception if the searched-for value is not in the list:If this is a concern, either explicitly check first using item in my_list, or handle the exception with try/except as appropriate.The explicit check is simple and readable, but it must iterate the list a second time. See What is the EAFP principle in Python? for more guidance on this choice.",
                "The majority of answers explain how to find a single index, but their methods do not return multiple indexes if the item is in the list multiple times. Use enumerate():The index() function only returns the first occurrence, while enumerate() returns all occurrences.As a list comprehension:Here's also another small solution with itertools.count() (which is pretty much the same approach as enumerate):This is more efficient for larger lists than using enumerate():",
                "To get all indexes:",
                "index() returns the first index of value!|  index(...)\n   |      L.index(value, [start, [stop]]) -> integer -- return first index of value",
                "A problem will arise if the element is not in the list. This function handles the issue:",
                "You have to set a condition to check if the element you're searching is in the list",
                "If you want all indexes, then you can use NumPy:It is clear, readable solution.",
                "All of the proposed functions here reproduce inherent language behavior but obscure what's going on.Why write a function with exception handling if the language provides the methods to do what you want itself?",
                "For a list [\"foo\", \"bar\", \"baz\"] and an item in the list \"bar\", what's the cleanest way to get its index (1) in Python?Well, sure, there's the index method, which returns the index of the first occurrence:There are a couple of issues with this method:If the value could be missing, you need to catch the ValueError.You can do so with a reusable definition like this:And use it like this:And the downside of this is that you will probably have a check for if the returned value is or is not None:If you could have more occurrences, you'll not get complete information with list.index:You might enumerate into a list comprehension the indexes:If you have no occurrences, you can check for that with boolean check of the result, or just do nothing if you loop over the results:If you have pandas, you can easily get this information with a Series object:A comparison check will return a series of booleans:Pass that series of booleans to the series via subscript notation, and you get just the matching members:If you want just the indexes, the index attribute returns a series of integers:And if you want them in a list or tuple, just pass them to the constructor:Yes, you could use a list comprehension with enumerate too, but that's just not as elegant, in my opinion - you're doing tests for equality in Python, instead of letting builtin code written in C handle it:The XY problem is asking about your attempted solution rather than your actual problem.Why do you think you need the index given an element in a list?If you already know the value, why do you care where it is in a list?If the value isn't there, catching the ValueError is rather verbose - and I prefer to avoid that.I'm usually iterating over the list anyways, so I'll usually keep a pointer to any interesting information, getting the index with enumerate.If you're munging data, you should probably be using pandas - which has far more elegant tools than the pure Python workarounds I've shown.I do not recall needing list.index, myself. However, I have looked through the Python standard library, and I see some excellent uses for it.There are many, many uses for it in idlelib, for GUI and text parsing.The keyword module uses it to find comment markers in the module to automatically regenerate the list of keywords in it via metaprogramming.In Lib/mailbox.py it seems to be using it like an ordered mapping:andIn Lib/http/cookiejar.py, seems to be used to get the next month:In Lib/tarfile.py similar to distutils to get a slice up to an item:In Lib/pickletools.py:What these usages seem to have in common is that they seem to operate on lists of constrained sizes (important because of O(n) lookup time for list.index), and they're mostly used in parsing (and UI in the case of Idle).While there are use-cases for it, they are fairly uncommon. If you find yourself looking for this answer, ask yourself if what you're doing is the most direct usage of the tools provided by the language for your use-case.",
                "With enumerate(alist) you can store the first element (n) that is the index of the list when the element x is equal to what you look for.This function takes the item and the list as arguments and return the position of the item in the list, like we saw before.OutputOutput:",
                "You can apply this for any member of the list to get their index",
                "All indexes with the zip function:",
                "Simply you can go with",
                "Another option",
                "... like confirming the existence of the item before getting the index.  The nice thing about this approach is the function always returns a list of indices -- even if it is an empty list.  It works with strings as well.When pasted into an interactive python window:After another year of heads-down python development, I'm a bit embarrassed by my original answer, so to set the record straight, one can certainly use the above code; however, the much more idiomatic way to get the same behavior would be to use list comprehension, along with the enumerate() function.Something like this:Which, when pasted into an interactive python window yields:And now, after reviewing this question and all the answers, I realize that this is exactly what FMc suggested in his earlier answer.  At the time I originally answered this question, I didn't even see that answer, because I didn't understand it.  I hope that my somewhat more verbose example will aid understanding.If the single line of code above still doesn't make sense to you, I highly recommend you Google 'python list comprehension' and take a few minutes to familiarize yourself.  It's just one of the many powerful features that make it a joy to use Python to develop code.",
                "My friend, I have made the easiest code to solve your question. While you were receiving gigantic lines of codes, I am here to cater you a two line code which is all due to the help of index() function in python.Output:I Hope I have given you the best and the simplest answer which might help you greatly.",
                "A variant on the answer from FMc and user7177 will give a dict that can return all indices for any entry:You could also use this as a one liner to get all indices for a single entry. There are no guarantees for efficiency, though I did use set(a) to reduce the number of times the lambda is called.",
                "Finding index of item x in list L:",
                "This solution is not as powerful as others, but if you're a beginner and only know about forloops it's still possible to find the first index of an item while avoiding the ValueError:",
                "There is a chance that that value may not be present so to avoid this ValueError, we can check if that actually exists in the list .",
                "List comprehension would be the best option to acquire a compact implementation in finding the index of an item in a list.",
                "It just uses the python function array.index() and with a simple Try / Except it returns the position of the record if it is found in the list and return -1 if it is not found in the list (like on JavaScript with the function indexOf()).In this case \"mango\" is not present in the list fruits so the pos variable is -1, if I had searched for \"cherry\" the pos variable would be 2.",
                "There is a more functional answer to this.More generic form:",
                "Python index() method throws an error if the item was not found. So instead you can make it similar to the indexOf() function of JavaScript which returns -1 if the item was not found:",
                "This accounts for if the string is not in the list too, if it isn't in the list then location = -1",
                "If you are going to find an index once then using \"index\" method is fine. However, if you are going to search your data more than once then I recommend using bisect module. Keep in mind that using bisect module data must be sorted. So you sort data once and then you can use bisect.\nUsing bisect module on my machine is about 20 times faster than using index method.Here is an example of code using Python 3.8 and above syntax:Output:",
                "Since Python lists are zero-based, we can use the zip built-in function as follows:where \"haystack\" is the list in question and \"needle\" is the item to look for.(Note: Here we are iterating using i to get the indexes, but if we need rather to focus on the items we can switch to j.)",
                "It is mentioned in numerous answers that the built-in method of list.index(item) method is an O(n) algorithm. It is fine if you need to perform this once. But if you need to access the indices of elements a number of times, it makes more sense to first create a dictionary (O(n)) of item-index pairs, and then access the index at O(1) every time you need it.If you are sure that the items in your list are never repeated, you can easily:If you may have duplicate elements, and need to return all of their indices:"
            ]
        },
        {
            "tag": "python",
            "question": [
                "Iterating over dictionaries using 'for' loops",
                "d = {'x': 1, 'y': 2, 'z': 3}\n\nfor key in d:\n    print(key, 'corresponds to', d[key])\n\nHow does Python recognize that it needs only to read the key from the dictionary? Is key a special keyword, or is ..."
            ],
            "url": "https://stackoverflow.com/questions/3294889",
            "answer": [
                "key is just a variable name.will simply loop over the keys in the dictionary, rather than the keys and values.  To loop over both key and value you can use the following:For Python 3.x:For Python 2.x:To test for yourself, change the word key to poop.In Python 3.x, iteritems() was replaced with simply items(), which returns a set-like view backed by the dict, like iteritems() but even better. \nThis is also available in 2.7 as viewitems().The operation items() will work for both 2 and 3, but in 2 it will return a list of the dictionary's (key, value) pairs, which will not reflect changes to the dict that happen after the items() call. If you want the 2.x behavior in 3.x, you can call list(d.items()).",
                "It's not that key is a special word, but that dictionaries implement the iterator protocol.  You could do this in your class, e.g. see this question for how to build class iterators.In the case of dictionaries, it's implemented at the C level.  The details are available in PEP 234.  In particular, the section titled \"Dictionary Iterators\":Dictionaries implement a tp_iter slot that returns an efficient\n  iterator that iterates over the keys of the dictionary. [...] This \n  means that we can writewhich is equivalent to, but much faster thanas long as the restriction on modifications to the dictionary\n  (either by the loop or by another thread) are not violated.Add methods to dictionaries that return different kinds of\n  iterators explicitly:This means that for x in dict is shorthand for for x in\n   dict.iterkeys().In Python 3, dict.iterkeys(), dict.itervalues() and dict.iteritems() are no longer supported. Use dict.keys(), dict.values() and dict.items() instead.",
                "Iterating over a dict iterates through its keys in no particular order, as you can see here:(This is no longer the case in Python 3.6, but note that it's not guaranteed behaviour yet.)For your example, it is a better idea to use dict.items():This gives you a list of tuples. When you loop over them like this, each tuple is unpacked into k and v automatically:Using k and v as variable names when looping over a dict is quite common if the body of the loop is only a few lines. For more complicated loops it may be a good idea to use more descriptive names:It's a good idea to get into the habit of using format strings:",
                "key is simply a variable.For Python2.X:... or better,For Python3.X:",
                "When you iterate through dictionaries using the for .. in ..-syntax, it always iterates over the keys (the values are accessible using dictionary[key]).To iterate over key-value pairs, use the following:",
                "This is a very common looping idiom. in is an operator. For when to use for key in dict and when it must be for key in dict.keys() see David Goodger's Idiomatic Python article (archived copy).",
                "I have a use case where I have to iterate through the dict to get the key, value pair, also the index indicating where I am. This is how I do it:Note that the parentheses around the key, value are important, without them, you'd get an ValueError \"not enough values to unpack\".",
                "How does Python recognize that it needs only to read the key from the\n  dictionary? Is key a special word in Python? Or is it simply a\n  variable?It's not just for loops. The important word here is \"iterating\".A dictionary is a mapping of keys to values:Any time we iterate over it, we iterate over the keys. The variable name key is only intended to be descriptive - and it is quite apt for the purpose.This happens in a list comprehension:It happens when we pass the dictionary to list (or any other collection type object):The way Python iterates is, in a context where it needs to, it calls the __iter__ method of the object (in this case the dictionary) which returns an iterator (in this case, a keyiterator object):We shouldn't use these special methods ourselves, instead, use the respective builtin function to call it, iter:Iterators have a __next__ method - but we call it with the builtin function, next:When an iterator is exhausted, it raises StopIteration. This is how Python knows to exit a for loop, or a list comprehension, or a generator expression, or any other iterative context. Once an iterator raises StopIteration it will always raise it - if you want to iterate again, you need a new one.We've seen dicts iterating in many contexts. What we've seen is that any time we iterate over a dict, we get the keys. Back to the original example:If we change the variable name, we still get the keys. Let's try it:If we want to iterate over the values, we need to use the .values method of dicts, or for both together, .items:In the example given, it would be more efficient to iterate over the items like this:But for academic purposes, the question's example is just fine.",
                "For Iterating through dictionaries, The below code can be used.",
                "You can check the implementation of CPython's dicttype on GitHub. This is the signature of method that implements the dict iterator:CPython dictobject.c",
                "To iterate over keys, it is slower but better to use my_dict.keys(). If you tried to do something like this:it would create a runtime error because you are changing the keys while the program is running. If you are absolutely set on reducing time, use the for key in my_dict way, but you have been warned.",
                "If you are looking for a clear and visual example:Result:",
                "This will print the output in sorted order by values in ascending order.Output:",
                "Let's get straight to the point. If the word key is just a variable, as you have mentioned then the main thing to note is that when you run a 'FOR LOOP' over a dictionary it runs through only the 'keys' and ignores the 'values'.rather try this:but if you use a function like:in the above case 'keys' is just not a variable, its a function.",
                "A dictionary in Python is a collection of key-value pairs. Each key is connected to a value, and you can use a key to access the value associated with that key. A key's value can be a number, a string, a list, or even another dictionary. In this case, threat each \"key-value pair\" as a separate row in the table: d is your table with two columns. the key is the first column, key[value] is your second column. Your for loop is a standard way to iterate over a table."
            ]
        },
        {
            "tag": "python",
            "question": [
                "Using global variables in a function",
                "How do I create or use a global variable inside a function?\nHow do I use a global variable that was defined in one function inside other functions?\n\nFailing to use the global keyword where appropriate ..."
            ],
            "url": "https://stackoverflow.com/questions/423379",
            "answer": [
                "You can use a global variable within other functions by declaring it as global within each function that assigns a value to it:Since it's unclear whether globvar = 1 is creating a local variable or changing a global variable, Python defaults to creating a local variable, and makes you explicitly choose the other behavior with the global keyword.See other answers if you want to share a global variable across modules.",
                "If I'm understanding your situation correctly, what you're seeing is the result of how Python handles local (function) and global (module) namespaces.Say you've got a module like this:You might expecting this to print 42, but instead it prints 5.  As has already been mentioned, if you add a 'global' declaration to func1(), then func2() will print 42.What's going on here is that Python assumes that any name that is assigned to, anywhere within a function, is local to that function unless explicitly told otherwise.  If it is only reading from a name, and the name doesn't exist locally, it will try to look up the name in any containing scopes (e.g. the module's global scope).When you assign 42 to the name _my_global, therefore, Python creates a local variable that shadows the global variable of the same name.  That local goes out of scope and is garbage-collected when func1() returns; meanwhile, func2() can never see anything other than the (unmodified) global name.  Note that this namespace decision happens at compile time, not at runtime -- if you were to read the value of _my_global inside func1() before you assign to it, you'd get an UnboundLocalError, because Python has already decided that it must be a local variable but it has not had any value associated with it yet.  But by using the 'global' statement, you tell Python that it should look elsewhere for the name instead of assigning to it locally.(I believe that this behavior originated largely through an optimization of local namespaces -- without this behavior,  Python's VM would need to perform at least three name lookups each time a new name is assigned to inside a function (to ensure that the name didn't already exist at module/builtin level), which would significantly slow down a very common operation.)",
                "You may want to explore the notion of namespaces. In Python, the module is the natural place for global data:Each module has its own private symbol table, which is used as the global symbol table by all functions defined in the module. Thus, the author of a module can use global variables in the module without worrying about accidental clashes with a user\u2019s global variables. On the other hand, if you know what you are doing you can touch a module\u2019s global variables with the same notation used to refer to its functions, modname.itemname.A specific use of global-in-a-module is described here - How do I share global variables across modules?, and for completeness the contents are shared here:The canonical way to share information across modules within a single program is to create a special configuration module (often called config or cfg). Just import the configuration module in all modules of your application; the module then becomes available as a global name. Because there is only one instance of each module, any changes made to the module object get reflected everywhere. For example:File: config.pyFile: mod.pyFile: main.py",
                "Python uses a simple heuristic to decide which scope it should load a variable from, between local and global.  If a variable name appears on the left hand side of an assignment, but is not declared global, it is assumed to be local.  If it does not appear on the left hand side of an assignment, it is assumed to be global.See how baz, which appears on the left side of an assignment in foo(), is the only LOAD_FAST variable.",
                "If you want to refer to a global variable in a function, you can use the global keyword to declare which variables are global. You don't have to use it in all cases (as someone here incorrectly claims) - if the name referenced in an expression cannot be found in local scope or scopes in the functions in which this function is defined, it is looked up among global variables.However, if you assign to a new variable not declared as global in the function, it is implicitly declared as local, and it can overshadow any existing global variable with the same name.Also, global variables are useful, contrary to some OOP zealots who claim otherwise - especially for smaller scripts, where OOP is overkill.",
                "We can create a global with the following function:Writing a function does not actually run its code. So we call the create_global_variable function:You can just use it, so long as you don't expect to change which object it points to:For example,and now we can use the global variable:To point the global variable at a different object, you are required to use the global keyword again:Note that after writing this function, the code actually changing it has still not run:So after calling the function:we can see that the global variable has been changed. The global_variable name now points to 'Bar':Note that \"global\" in Python is not truly global - it's only global to the module level. So it is only available to functions written in the modules in which it is global. Functions remember the module in which they are written, so when they are exported into other modules, they still look in the module in which they were created to find global variables.If you create a local variable with the same name, it will overshadow a global variable:But using that misnamed local variable does not change the global variable:Note that you should avoid using the local variables with the same names as globals unless you know precisely what you are doing and have a very good reason to do so. I have not yet encountered such a reason.A follow on comment asks:what to do if I want to create a global variable inside a function inside a class and want to use that variable inside another function inside another class?Here I demonstrate we get the same behavior in methods as we do in regular functions:And now:But I would suggest instead of using global variables you use class attributes, to avoid cluttering the module namespace. Also note we don't use self arguments here - these could be class methods (handy if mutating the class attribute from the usual cls argument) or static methods (no self or cls).",
                "In addition to already existing answers and to make this more confusing:In Python, variables that are only referenced inside a function are\n  implicitly global. If a variable is assigned a new value anywhere\n  within the function\u2019s body, it\u2019s assumed to be a local. If a variable\n  is ever assigned a new value inside the function, the variable is\n  implicitly local, and you need to explicitly declare it as \u2018global\u2019.Though a bit surprising at first, a moment\u2019s consideration explains\n  this. On one hand, requiring global for assigned variables provides a\n  bar against unintended side-effects. On the other hand, if global was\n  required for all global references, you\u2019d be using global all the\n  time. You\u2019d have to declare as global every reference to a built-in\n  function or to a component of an imported module. This clutter would\n  defeat the usefulness of the global declaration for identifying\n  side-effects.Source: What are the rules for local and global variables in Python?.",
                "With parallel execution, global variables can cause unexpected results if you don't understand what is happening. Here is an example of using a global variable within multiprocessing. We can clearly see that each process works with its own copy of the variable:Output:",
                "As it turns out the answer is always simple.Here is a small sample module with a simple way to show it in a main definition:Here is how to show it in a main definition:This simple code works just like that, and it will execute. I hope it helps.",
                "What you are saying is to use the method like this:But the better way is to use the global variable like this:Both give the same output.",
                "You need to reference the global variable in every function you want to use.As follows:",
                "Try this:",
                "You're not actually storing the global in a local variable, just creating a local reference to the same object that your original global reference refers to. Remember that pretty much everything in Python is a name referring to an object, and nothing gets copied in usual operation.If you didn't have to explicitly specify when an identifier was to refer to a predefined global, then you'd presumably have to explicitly specify when an identifier is a new local variable instead (for example, with something like the 'var' command seen in JavaScript). Since local variables are more common than global variables in any serious and non-trivial system, Python's system makes more sense in most cases.You could have a language which attempted to guess, using a global variable if it existed or creating a local variable if it didn't. However, that would be very error-prone. For example, importing another module could inadvertently introduce a global variable by that name, changing the behaviour of your program.",
                "In case you have a local variable with the same name, you might want to use the globals() function.",
                "Following on and as an add on, use a file to contain all global variables all declared locally and then import as:File initval.py:File getstocks.py:",
                "Writing to explicit elements of a global array does not apparently need the global declaration, though writing to it \"wholesale\" does have that requirement:",
                "I'm adding this as I haven't seen it in any of the other answers and it might be useful for someone struggling with something similar. The globals() function returns a mutable global symbol dictionary where you can \"magically\" make data available for the rest of your code. \nFor example:andWill just let you dump/load variables out of and into the global namespace. Super convenient, no muss, no fuss. Pretty sure it's Python 3 only.",
                "Reference the class namespace where you want the change to show up.In this example, runner is using max from the file config. I want my test to change the value of max when runner is using it.main/config.pymain/runner.pytests/runner_test.py",
                "Explanation:global_var is a global variable and all functions and classes can access that variable.The func_1() accessed that global variable using the keyword global which points to the variable which is written in the global scope. If I didn't write the global keyword the variable global_var inside func_1 is considered a local variable that is only usable inside the function. Then inside func_1, I have incremented that global variable by 1.The same happened in func_2().After calling func_1 and func_2, you'll see the global_var is changed",
                "Globals in connection with multiprocessing on different platforms/envrionments \nas Windows/Mac OS on the one side and Linux on the other are troublesome.I will show you this with a simple example pointing out a problem which I run into some time ago.If you want to understand, why things are different on Windows/MacOs and Linux you \nneed to know that, the default mechanism to start a new process on ...They are different in Memory allocation an initialisation ... (but I don't go into this\nhere).Let's have a look at the problem/example ...If you run this on Windows (And I suppose on MacOS too), you get the following output ...If you run this on Linux, you get the following instead.",
                "There are 2 ways to declare a variable as global:1. assign variable inside functions and use global line2. assign variable outside functions:Now we can use these declared global variables in the other functions:Note 1:If you want to change a global variable inside another function like update_variables() you should use global line in that function before assigning the variable:Note 2:There is a exception for note 1 for list and dictionary variables while not using global line inside a function:",
                "Though this has been answered, I am giving solution again as I prefer single line\nThis is if you wish to create global variable within function",
                "Like this code:Key:If you declare a variable outside the strings, it become global.If you declare a variable inside the strings, it become local.If you want to declare a global variable inside the strings, use the keyword global before the variable you want to declare:and then you have 100 in the document.",
                "Here we are comparing global variable Initialized that 0, so while loop condition got trueFunction will get called.Loop will be infinite",
                "if you want to access global var you just add global keyword inside your function\nex:\nglobal_var = 'yeah'"
            ]
        },
        {
            "tag": "python",
            "question": [
                "How to iterate over rows in a DataFrame in Pandas",
                "I have a pandas dataframe, df:\n   c1   c2\n0  10  100\n1  11  110\n2  12  120\n\nHow do I iterate over the rows of this dataframe? For every row, I want to be able to access its elements (values in cells) ..."
            ],
            "url": "https://stackoverflow.com/questions/16476924",
            "answer": [
                "DataFrame.iterrows is a generator which yields both the index and row (as a Series):",
                "Iteration in Pandas is an anti-pattern and is something you should only do when you have exhausted every other option. You should not use any function with \"iter\" in its name for more than a few thousand rows or you will have to get used to a lot of waiting.Do you want to print a DataFrame? Use DataFrame.to_string().Do you want to compute something? In that case, search for methods in this order (list modified from here):iterrows and itertuples (both receiving many votes in answers to this question) should be used in very rare circumstances, such as generating row objects/nametuples for sequential processing, which is really the only thing these functions are useful for.Appeal to AuthorityThe documentation page on iteration has a huge red warning box that says:Iterating through pandas objects is generally slow. In many cases, iterating manually over the rows is not needed [...].* It's actually a little more complicated than \"don't\". df.iterrows() is the correct answer to this question, but \"vectorize your ops\" is the better one. I will concede that there are circumstances where iteration cannot be avoided (for example, some operations where the result depends on the value computed for the previous row). However, it takes some familiarity with the library to know when. If you're not sure whether you need an iterative solution, you probably don't. PS: To know more about my rationale for writing this answer, skip to the very bottom.A good number of basic operations and computations are \"vectorised\" by pandas (either through NumPy, or through Cythonized functions). This includes arithmetic, comparisons, (most) reductions, reshaping (such as pivoting), joins, and groupby operations. Look through the documentation on Essential Basic Functionality to find a suitable vectorised method for your problem.If none exists, feel free to write your own using custom Cython extensions.List comprehensions should be your next port of call if 1) there is no vectorized solution available, 2) performance is important, but not important enough to go through the hassle of cythonizing your code, and 3) you're trying to perform elementwise transformation on your code. There is a good amount of evidence to suggest that list comprehensions are sufficiently fast (and even sometimes faster) for many common Pandas tasks.The formula is simple,If you can encapsulate your business logic into a function, you can use a list comprehension that calls it. You can make arbitrarily complex things work through the simplicity and speed of raw Python code.CaveatsList comprehensions assume that your data is easy to work with - what that means is your data types are consistent and you don't have NaNs, but this cannot always be guaranteed.*Your mileage may vary for the reasons outlined in the Caveats section above.Let's demonstrate the difference with a simple example of adding two pandas columns A + B. This is a vectorizable operation, so it will be easy to contrast the performance of the methods discussed above.Benchmarking code, for your reference. The line at the bottom measures a function written in numpandas, a style of Pandas that mixes heavily with NumPy to squeeze out maximum performance. Writing numpandas code should be avoided unless you know what you're doing. Stick to the API where you can (i.e., prefer vec over vec_numpy).I should mention, however, that it isn't always this cut and dry. Sometimes the answer to \"what is the best method for an operation\" is \"it depends on your data\". My advice is to test out different approaches on your data before settling on one.Most of the analyses performed on the various alternatives to the iter family has been through the lens of performance. However, in most situations you will typically be working on a reasonably sized dataset (nothing beyond a few thousand or 100K rows) and performance will come second to simplicity/readability of the solution.Here is my personal preference when selecting a method to use for a problem.For the novice:Vectorization (when possible); apply(); List Comprehensions; itertuples()/iteritems(); iterrows(); CythonFor the more experienced:Vectorization (when possible); apply(); List Comprehensions; Cython; itertuples()/iteritems(); iterrows()Vectorization prevails as the most idiomatic method for any problem that can be vectorized. Always seek to vectorize! When in doubt, consult the docs, or look on Stack Overflow for an existing question on your particular task.I do tend to go on about how bad apply is in a lot of my posts, but I do concede it is easier for a beginner to wrap their head around what it's doing. Additionally, there are quite a few use cases for apply has explained in this post of mine.Cython ranks lower down on the list because it takes more time and effort to pull off correctly. You will usually never need to write code with pandas that demands this level of performance that even a list comprehension cannot satisfy.* As with any personal opinion, please take with heaps of salt!10 Minutes to pandas, and Essential Basic Functionality - Useful links that introduce you to Pandas and its library of vectorized*/cythonized functions.Enhancing Performance - A primer from the documentation on enhancing standard Pandas operationsAre for-loops in pandas really bad? When should I care? - a detailed write-up by me on list comprehensions and their suitability for various operations (mainly ones involving non-numeric data)When should I (not) want to use pandas apply() in my code? - apply is slow (but not as slow as the iter* family. There are, however, situations where one can (or should) consider apply as a serious alternative, especially in some GroupBy operations).* Pandas string methods are \"vectorized\" in the sense that they are specified on the series but operate on each element. The underlying mechanisms are still iterative, because string operations are inherently hard to vectorize.A common trend I notice from new users is to ask questions of the form \"How can I iterate over my df to do X?\". Showing code that calls iterrows() while doing something inside a for loop. Here is why. A new user to the library who has not been introduced to the concept of vectorization will likely envision the code that solves their problem as iterating over their data to do something. Not knowing how to iterate over a DataFrame, the first thing they do is Google it and end up here, at this question. They then see the accepted answer telling them how to, and they close their eyes and run this code without ever first questioning if iteration is the right thing to do.The aim of this answer is to help new users understand that iteration is not necessarily the solution to every problem, and that better, faster and more idiomatic solutions could exist, and that it is worth investing time in exploring them. I'm not trying to start a war of iteration vs. vectorization, but I want new users to be informed when developing solutions to their problems with this library.",
                "First consider if you really need to iterate over rows in a DataFrame. See this answer for alternatives.If you still need to iterate over rows, you can use methods below. Note some  important caveats which are not mentioned in any of the other answers.DataFrame.iterrows()DataFrame.itertuples()itertuples() is supposed to be faster than iterrows()But be aware, according to the docs (pandas 0.24.2 at the moment):Because iterrows returns a Series for each row, it does not preserve dtypes across the rows (dtypes are preserved across columns for DataFrames). To preserve dtypes while iterating over the rows, it is better to use itertuples() which returns namedtuples of the values and which is generally much faster than iterrows()You should never modify something you are iterating over. This is not guaranteed to work in all cases. Depending on the data types, the iterator returns a copy and not a view, and writing to it will have no effect.Use DataFrame.apply() instead:The column names will be renamed to positional names if they are invalid Python identifiers, repeated, or start with an underscore. With a large number of columns (>255), regular tuples are returned.See pandas docs on iteration for more details.",
                "You should use df.iterrows(). Though iterating row-by-row is not especially efficient since Series objects have to be created.",
                "While iterrows() is a good option, sometimes itertuples() can be much faster:",
                "You can use the df.iloc function as follows:",
                "You can also use df.apply() to iterate over rows and access multiple columns for a function.docs: DataFrame.apply()",
                "If you really have to iterate a Pandas dataframe, you will probably want to avoid using iterrows(). There are different methods and the usual iterrows() is far from being the best. itertuples() can be 100 times faster.In short:Generate a random dataframe with a million rows and 4 columns:1) The usual iterrows() is convenient, but damn slow:2) The default itertuples() is already much faster, but it doesn't work with column names such as My Col-Name is very Strange (you should avoid this method if your columns are repeated or if a column name cannot be simply converted to a Python variable name).:3) The default itertuples() using name=None is even faster but not really convenient as you have to define a variable per column.4) Finally, the named itertuples() is slower than the previous point, but you do not have to define a variable per column and it works with column names such as My Col-Name is very Strange.Output:This article is a very interesting comparison between iterrows and itertuples",
                "I was looking for How to iterate on rows and columns and ended here so:",
                "We have multiple options to do the same, and lots of folks have shared their answers.I found the below two methods easy and efficient to do:Example:Note: itertuples() is supposed to be faster than iterrows()",
                "You can write your own iterator that implements namedtupleThis is directly comparable to pd.DataFrame.itertuples.  I'm aiming at performing the same task with more efficiency.For the given dataframe with my function:Or with pd.DataFrame.itertuples:A comprehensive test\nWe test making all columns available and subsetting the columns.",
                "To loop all rows in a dataframe you can use:",
                "Update: cs95 has updated his answer to include plain numpy vectorization. You can simply refer to his answer.cs95 shows that Pandas vectorization far outperforms other Pandas methods for computing stuff with dataframes.I wanted to add that if you first convert the dataframe to a NumPy array and then use vectorization, it's even faster than Pandas dataframe vectorization, (and that includes the time to turn it back into a dataframe series).If you add the following functions to cs95's benchmark code, this becomes pretty evident:",
                "Sometimes a useful pattern is:Which results in:",
                "To loop all rows in a dataframe and use values of each row conveniently, namedtuples can be converted to ndarrays. For example:Iterating over the rows:results in:Please note that if index=True, the index is added as the first element of the tuple, which may be undesirable for some applications.",
                "In short",
                "There is a way to iterate throw rows while getting a DataFrame in return, and not a Series. I don't see anyone mentioning that you can pass index as a list for the row to be returned as a DataFrame:Note the usage of double brackets. This returns a DataFrame with a single row.",
                "For both viewing and modifying values, I would use iterrows(). In a for loop and by using tuple unpacking (see the example: i, row), I use the row for only viewing the value and use i with the loc method when I want to modify values. As stated in previous answers, here you should not modify something you are iterating over.Here the row in the loop is a copy of that row, and not a view of it. Therefore, you should NOT write something like row['A'] = 'New_Value', it will not modify the DataFrame. However, you can use i and loc and specify the DataFrame to do the work.",
                "There are so many ways to iterate over the rows in Pandas dataframe. One very simple and intuitive way is:",
                "The easiest way, use the apply function",
                "As many answers here correctly point out, your default plan in Pandas should be to write vectorized code (with its implicit loops) rather than attempting an explicit loop yourself.  But the question remains whether you should ever write loops in Pandas, and if so what's the best way to loop in those situations.I believe there is at least one general situation where loops are appropriate: when you need to calculate some function that depends on values in other rows in a somewhat complex manner.  In this case, the looping code is often simpler, more readable, and less error prone than vectorized code.The looping code might even be faster too, as you'll see below, so loops might make sense in cases where speed is of utmost importance. But really, those are just going to be subsets of cases where you probably should have been working in numpy/numba (rather than Pandas) to begin with, because optimized numpy/numba will almost always be faster than Pandas.Let's show this with an example.  Suppose you want to take a cumulative sum of a column, but reset it whenever some other column equals zero:This is a good example where you could certainly write one line of Pandas to achieve this, although it's not especially readable, especially if you aren't fairly experienced with Pandas already:That's going to be fast enough for most situations, although you could also write faster code by avoiding the groupby, but it will likely be even less readable.Alternatively, what if we write this as a loop?  You could do something like the following with NumPy:Admittedly, there's a bit of overhead there required to convert DataFrame columns to NumPy arrays, but the core piece of code is just one line of code that you could read even if you didn't know anything about Pandas or NumPy:And this code is actually faster than the vectorized code.  In some quick tests with 100,000 rows, the above is about 10x faster than the groupby approach.  Note that one key to the speed there is numba, which is optional.  Without the \"@nb.jit\" line, the looping code is actually about 10x slower than the groupby approach.Clearly this example is simple enough that you would likely prefer the one line of pandas to writing a loop with its associated overhead.  However, there are more complex versions of this problem for which the readability or speed of the NumPy/numba loop approach likely makes sense.",
                "You can also do NumPy indexing for even greater speed ups. It's not really iterating but works much better than iteration for certain applications.You may also want to cast it to an array. These indexes/selections are supposed to act like NumPy arrays already, but I ran into issues and needed to cast",
                "df.iterrows() returns tuple(a, b) where a is the index and b is the row.",
                "Probably the most elegant solution (but certainly not the most efficient):Note that:Still, I think this option should be included here, as a straightforward solution to a (one should think) trivial problem.",
                "This example uses iloc to isolate each digit in the data frame.",
                "Disclaimer: Although here are so many answers which recommend not using an iterative (loop) approach (and I mostly agree), I would still see it as a reasonable approach for the following situation:Let's say you have a large dataframe which contains incomplete user data. Now you have to extend this data with additional columns, for example, the user's age and gender.Both values have to be fetched from a backend API. I'm assuming the API doesn't provide a \"batch\" endpoint (which would accept multiple user IDs at once). Otherwise, you should rather call the API only once.The costs (waiting time) for the network request surpass the iteration of the dataframe by far. We're talking about network round trip times of hundreds of milliseconds compared to the negligibly small gains in using alternative approaches to iterations.So in this case, I would absolutely prefer using an iterative approach. Although the network request is expensive, it is guaranteed being triggered only once for each row in the dataframe. Here is an example using DataFrame.iterrows:",
                "Some libraries (e.g. a Java interop library that I use) require values to be passed in a row at a time, for example, if streaming data. To replicate the streaming nature, I 'stream' my dataframe values one by one, I wrote the below, which comes in handy from time to time.Which can be used:And preserves the values/ name mapping for the rows being iterated. Obviously, is a lot slower than using apply and Cython as indicated above, but is necessary in some circumstances.",
                "As the accepted answer states, the fastest way to apply a function over rows is to use a vectorized function, the so-called NumPy ufuncs (universal functions).But what should you do when the function you want to apply isn't already implemented in NumPy?Well, using the vectorize decorator from numba, you can easily create ufuncs directly in Python like this:The documentation for this function is here: Creating NumPy universal functions",
                "Along with the great answers in this post I am going to propose Divide and Conquer approach, I am not writing this answer to abolish the other great answers but to fulfill them with another approach which was working efficiently for me. It has two steps of splitting and merging the pandas dataframe:PROS of Divide and Conquer:CONS of Divide and Conquer:===================    Divide and Conquer Approach    =================Step 1: Splitting/SlicingIn this step, we are going to divide the iteration over the entire dataframe. Think that you are going to read a CSV file into pandas df then iterate over it. In may case I have 5,000,000 records and I am going to split it into 100,000 records.NOTE: I need to reiterate as other runtime analysis explained in the other solutions in this page, \"number of records\" has exponential proportion of \"runtime\" on search on the df. Based on the benchmark on my data here are the results:Step 2: MergingThis is going to be an easy step, just merge all the written CSV files into one dataframe and write it into a bigger CSV file.Here is the sample code:Reference:Efficient way of iteration over datafreameConcatenate CSV files into one Pandas Dataframe"
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I get the current time?",
                "How do I get the current time?"
            ],
            "url": "https://stackoverflow.com/questions/415511",
            "answer": [
                "Use datetime:For just the clock time without the date:To save typing, you can import the datetime object from the datetime module:Then remove the prefix datetime. from all of the above.",
                "Use time.strftime():",
                "Example output: '2013-09-18 11:16:32'See list of strftime directives.",
                "Similar to Harley's answer, but use the str() function for a quick-n-dirty, slightly more human readable format:",
                "The time module provides functions that tell us the time in \"seconds since the epoch\" as well as other utilities.This is the format you should get timestamps in for saving in databases. It is a simple floating-point number that can be converted to an integer. It is also good for arithmetic in seconds, as it represents the number of seconds since Jan 1, 1970, 00:00:00, and it is memory light relative to the other representations of time we'll be looking at next:This timestamp does not account for leap-seconds, so it's not linear - leap seconds are ignored. So while it is not equivalent to the international UTC standard, it is close, and therefore quite good for most cases of record-keeping.This is not ideal for human scheduling, however. If you have a future event you wish to take place at a certain point in time, you'll want to store that time with a string that can be parsed into a datetime object or a serialized datetime object (these will be described later).You can also represent the current time in the way preferred by your operating system (which means it can change when you change your system preferences, so don't rely on this to be standard across all systems, as I've seen others expect). This is typically user friendly, but doesn't typically result in strings one can sort chronologically:You can hydrate timestamps into human readable form with ctime as well:This conversion is also not good for record-keeping (except in text that will only be parsed by humans - and with improved Optical Character Recognition and Artificial Intelligence, I think the number of these cases will diminish).The datetime module is also quite useful here:The datetime.now is a class method that returns the current time. It uses the time.localtime without the timezone info (if not given, otherwise see timezone aware below). It has a representation (which would allow you to recreate an equivalent object) echoed on the shell, but when printed (or coerced to a str), it is in human readable (and nearly ISO) format, and the lexicographic sort is equivalent to the chronological sort:You can get a datetime object in UTC time, a global standard, by doing this:UTC is a time standard that is nearly equivalent to the GMT timezone. (While GMT and UTC do not change for Daylight Savings Time, their users may switch to other timezones, like British Summer Time, during the Summer.)However, none of the datetime objects we've created so far can be easily converted to various timezones. We can solve that problem with the pytz module:Equivalently, in Python 3 we have the timezone class with a utc timezone instance attached, which also makes the object timezone aware (but to convert to another timezone without the handy pytz module is left as an exercise to the reader):And we see we can easily convert to timezones from the original UTC object.You can also make a naive datetime object aware with the pytz timezone localize method, or by replacing the tzinfo attribute (with replace, this is done blindly), but these are more last resorts than best practices:The pytz module allows us to make our datetime objects timezone aware and convert the times to the hundreds of timezones available in the pytz module.One could ostensibly serialize this object for UTC time and store that in a database, but it would require far more memory and be more prone to error than simply storing the Unix Epoch time, which I demonstrated first.The other ways of viewing times are much more error-prone, especially when dealing with data that may come from different time zones. You want there to be no confusion as to which timezone a string or serialized datetime object was intended for.If you're displaying the time with Python for the user, ctime works nicely, not in a table (it doesn't typically sort well), but perhaps in a clock. However, I personally recommend, when dealing with time in Python, either using Unix time, or a timezone aware UTC datetime object.",
                "DoThere is some difference for Unix and Windows platforms.",
                "That outputs the current GMT in the specified format. There is also a localtime() method.This page has more details.",
                "The previous answers are all good suggestions, but I find it easiest to use ctime():This gives a nicely formatted string representation of the current local time.",
                "The quickest way is:",
                "If you need current time as a time object:",
                "You can use the time module:The use of the capital Y gives the full year, and using y would give 06/02/15.You could also use the following code to give a more lengthy time:",
                ".isoformat() is in the documentation, but not yet here\n(this is mighty similar to @Ray Vega's answer):",
                "Why not ask the U.S. Naval Observatory, the official timekeeper of the United States Navy?If you live in the D.C. area (like me) the latency might not be too bad...",
                "Using pandas to get the current time, kind of overkilling the problem at hand:Output:",
                "if you are using numpy already then directly you can use numpy.datetime64() \nfunction.for only date:or, if you are using pandas already then you can use pandas.to_datetime() functionor,",
                "This is what I ended up going with:Also, this table is a necessary reference for choosing the appropriate format codes to get the date formatted just the way you want it (from Python \"datetime\" documentation here).",
                "datetime.now() returns the current time as a naive datetime object that represents time in the local timezone. That value may be ambiguous e.g., during DST transitions (\"fall back\"). To avoid ambiguity either UTC timezone should be used:Or a timezone-aware object that has the corresponding timezone info attached (Python 3.2+):",
                "Do dir(date) or any variables including the package. You can get all the attributes and methods associated with the variable.",
                "This question doesn't need a new answer just for the sake of it ... a shiny new-ish toy/module, however, is enough justification.  That being the Pendulum library, which appears to do the sort of things which arrow attempted, except without the inherent flaws and bugs which beset arrow.For instance, the answer to the original question:There's a lot of standards which need addressing, including multiple RFCs and ISOs, to worry about.  Ever get them mixed up; not to worry, take a little look into dir(pendulum.constants) There's a bit more than RFC and ISO formats there, though.When we say local, though what do we mean?  Well I mean:Presumably most of the rest of you mean somewhere else.And on it goes.  Long story short: Pendulum attempts to do for date and time what requests did for HTTP.  It's worth consideration, particularly for both its ease of use and extensive documentation.",
                "By default, now() function returns output in the YYYY-MM-DD HH:MM:SS:MS format. Use the below sample script to get the current date and time in a Python script and print results on the screen. Create file getDateTime1.py with the below content.The output looks like below:",
                "Try the arrow module from http://crsmithdev.com/arrow/:Or the UTC version:To change its output, add .format():For a specific timezone:An hour ago:Or if you want the gist.",
                "Current time of a timezone",
                "To get exactly 3 decimal points for milliseconds 11:34:23.751 run this:More context:I want to get the time with milliseconds. A simple way to get them:But I want only milliseconds, right? The shortest way to get them:Add or remove zeroes from the last multiplication to adjust number of decimal points, or just:",
                "If you just want the current timestamp in ms (for example, to measure execution time), you can also use the \"timeit\" module:",
                "You can use this function to get the time (unfortunately it doesn't say AM or PM):To get the hours, minutes, seconds and milliseconds to merge later, you can use these functions:Hour:Minute:Second:Millisecond:",
                "You can  try the followingor",
                "Because no one has mentioned it yet, and this is something I ran into recently... a pytz timezone's fromutc() method combined with datetime's utcnow() is the best way I've found to get a useful current time (and date) in any timezone.If all you want is the time, you can then get that with local_time.time().",
                "Method1: Getting Current Date and Time from system datetimeThe datetime module supplies classes for manipulating dates and times.CodeOutput will be likeMethod2: Getting Current Date and Time if Network is availableurllib package helps us to handle the url's that means webpages. Here we collects data from the webpage http://just-the-time.appspot.com/ and parses dateime from the webpage using the package dateparser.CodeOutput will be likeMethod3: Getting Current Date and Time from Local Time of the MachinePython's time module provides a function for getting local time from the number of seconds elapsed since the epoch called localtime(). ctime() function takes seconds passed since epoch as an argument and returns a string representing local time.CodeOutput will be like"
            ]
        },
        {
            "tag": "python",
            "question": [
                "Catch multiple exceptions in one line (except block)",
                "I know that I can do:\n\ntry:\n    # do something that may fail\nexcept:\n    # do this if ANYTHING goes wrong\r\nI can also do this:\n\ntry:\n    # do something that may fail\nexcept IDontLikeYouException:\n    #..."
            ],
            "url": "https://stackoverflow.com/questions/6470428",
            "answer": [
                "From Python Documentation:An except clause may name multiple exceptions as a parenthesized tuple, for exampleOr, for Python 2 only:Separating the exception from the variable with a comma will still work in Python 2.6 and 2.7, but is now deprecated and does not work in Python 3; now you should be using as.",
                "Do this:The parentheses are required due to older syntax that used the commas to assign the error object to a name. The as keyword is used for the assignment. You can use any name for the error object, I prefer error personally.To do this in a manner currently and forward compatible with Python, you need to separate the Exceptions with commas and wrap them with parentheses to differentiate from earlier syntax that assigned the exception instance to a variable name by following the Exception type to be caught with a comma.Here's an example of simple usage:I'm specifying only these exceptions to avoid hiding bugs, which if I encounter I expect the full stack trace from.This is documented here: https://docs.python.org/tutorial/errors.htmlYou can assign the exception to a variable, (e is common, but you might prefer a more verbose variable if you have long exception handling or your IDE only highlights selections larger than that, as mine does.) The instance has an args attribute. Here is an example:Note that in Python 3, the err object falls out of scope when the except block is concluded.You may see code that assigns the error with a comma. This usage, the only form available in Python 2.5 and earlier, is deprecated, and if you wish your code to be forward compatible in Python 3, you should update the syntax to use the new form:If you see the comma name assignment in your codebase, and you're using Python 2.5 or higher, switch to the new way of doing it so your code remains compatible when you upgrade.The accepted answer is really 4 lines of code, minimum:The try, except, pass lines can be handled in a single line with the suppress context manager, available in Python 3.4:So when you want to pass on certain exceptions, use suppress.",
                "From Python documentation -> 8.3 Handling Exceptions:A try statement may have more than one except clause, to specify\n  handlers for different exceptions. At most one handler will be\n  executed. Handlers only handle exceptions that occur in the\n  corresponding try clause, not in other handlers of the same try\n  statement. An except clause may name multiple exceptions as a\n  parenthesized tuple, for example:Note that the parentheses around this tuple are required, because\n  except ValueError, e: was the syntax used for what is normally\n  written as except ValueError as e: in modern Python (described\n  below). The old syntax is still supported for backwards compatibility.\n  This means except RuntimeError, TypeError is not equivalent to\n  except (RuntimeError, TypeError): but to except RuntimeError as\nTypeError: which is not what you want.",
                "If you frequently use a large number of exceptions, you can pre-define a tuple, so you don't have to re-type them many times.NOTES:If you, also, need to catch other exceptions than those in the\npre-defined tuple, you will need to define another except block.If you just cannot tolerate a global variable, define it in main()\nand pass it around where needed...",
                "One of the way to do this is..and another way is to create method which performs task executed by except block and call it through all of the except block that you write..I know that second one is not the best way to do this, but i'm just showing number of ways to do this thing.",
                "As of Python 3.11 you can take advantage of the except* clause that is used to handle multiple exceptions.PEP-654 introduced a new standard exception type called ExceptionGroup that corresponds to a group of exceptions that are being propagated together. The ExceptionGroup can be handled using a new except* syntax. The * symbol indicates that multiple exceptions can be handled by each except* clause.For example, you can handle multiple exceptionsFor more details see PEP-654."
            ]
        },
        {
            "tag": "python",
            "question": [
                "Does Python have a string 'contains' substring method?",
                "I'm looking for a string.contains or string.indexof method in Python.\n\nI want to do:\n\nif not somestring.contains(\"blah\"):\n   continue"
            ],
            "url": "https://stackoverflow.com/questions/3437059",
            "answer": [
                "Use the in operator:",
                "If it's just a substring search you can use string.find(\"substring\").You do have to be a little careful with find, index, and in though, as they are substring searches. In other words, this:It would print Found 'is' in the string. Similarly, if \"is\" in s: would evaluate to True. This may or may not be what you want.",
                "99% of use cases will be covered using the keyword, in, which returns True or False:For the use case of getting the index, use str.find (which returns -1 on failure, and has optional positional arguments):or str.index (like find but raises ValueError on failure):Use the in comparison operator becauseThe opposite (complement), which the original question asked for, is not in:This is semantically the same as not 'foo' in '**foo**' but it's much more readable and explicitly provided for in the language as a readability improvement.The \"contains\" method implements the behavior for in. This example,returns True. You could also call this function from the instance of the superstring:But don't. Methods that start with underscores are considered semantically non-public. The only reason to use this is when implementing or extending the in and not in functionality (e.g. if subclassing str):and now:Don't use the following string methods to test for \"contains\":Other languages may have no methods to directly test for substrings, and so you would have to use these types of methods, but with Python, it is much more efficient to use the in comparison operator.Also, these are not drop-in replacements for in. You may have to handle the exception or -1 cases, and if they return 0 (because they found the substring at the beginning) the boolean interpretation is False instead of True.If you really mean not any_string.startswith(substring) then say it.We can compare various ways of accomplishing the same goal.And now we see that using in is much faster than the others.\nLess time to do an equivalent operation is better:This is a fine follow-on question.Let's disassemble functions with the methods of interest:so we see that the .__contains__ method has to be separately looked up and then called from the Python virtual machine - this should adequately explain the difference.",
                "if needle in haystack: is the normal use, as @Michael says -- it relies on the in operator, more readable and faster than a method call.If you truly need a method instead of an operator (e.g. to do some weird key= for a very peculiar sort...?), that would be 'haystack'.__contains__.  But since your example is for use in an if, I guess you don't really mean what you say;-).  It's not good form (nor readable, nor efficient) to use special methods directly -- they're meant to be used, instead, through the operators and builtins that delegate to them.",
                "Here are a few useful examples that speak for themselves concerning the in method:Caveat. Lists are iterables, and the in method acts on iterables, not just strings.If you want to compare strings in a more fuzzy way to measure how \"alike\" they are, consider using the Levenshtein packageHere's an answer that shows how it works.",
                "If you are happy with \"blah\" in somestring but want it to be a function/method call, you can probably do thisAll operators in Python can be more or less found in the operator module including in.",
                "So apparently there is nothing similar for vector-wise comparison. An obvious Python way to do so would be:",
                "You can use y.count().It will return the integer value of the number of times a sub string appears in a string.For example:",
                "Here is your answer:For checking if it is false:OR:",
                "You can use regular expressions to get the occurrences:"
            ]
        },
        {
            "tag": "python",
            "question": [
                "What is the difference between __str__ and __repr__?",
                "What is the difference between __str__ and __repr__ in Python?"
            ],
            "url": "https://stackoverflow.com/questions/1436703",
            "answer": [
                "Alex summarized well but, surprisingly, was too succinct.First, let me reiterate the main points in Alex\u2019s post:Default implementation is uselessThis is mostly a surprise because Python\u2019s defaults tend to be fairly useful. However, in this case, having a default for __repr__ which would act like:would have been too dangerous (for example, too easy to get into infinite recursion if objects reference each other). So Python cops out. Note that there is one default which is true: if __repr__ is defined, and __str__ is not, the object will behave as though __str__=__repr__.This means, in simple terms: almost every object you implement should have a functional __repr__ that\u2019s usable for understanding the object. Implementing __str__ is optional: do that if you need a \u201cpretty print\u201d functionality (for example, used by a report generator).The goal of __repr__ is to be unambiguousLet me come right out and say it \u2014 I do not believe in debuggers. I don\u2019t really know how to use any debugger, and have never used one seriously. Furthermore, I believe that the big fault in debuggers is their basic nature \u2014 most failures I debug happened a long long time ago, in a galaxy far far away. This means that I do believe, with religious fervor, in logging. Logging is the lifeblood of any decent fire-and-forget server system. Python makes it easy to log: with maybe some project specific wrappers, all you need is aBut you have to do the last step \u2014 make sure every object you implement has a useful repr, so code like that can just work. This is why the \u201ceval\u201d thing comes up: if you have enough information so eval(repr(c))==c, that means you know everything there is to know about c. If that\u2019s easy enough, at least in a fuzzy way, do it. If not, make sure you have enough information about c anyway. I usually use an eval-like format: \"MyClass(this=%r,that=%r)\" % (self.this,self.that). It does not mean that you can actually construct MyClass, or that those are the right constructor arguments \u2014 but it is a useful form to express \u201cthis is everything you need to know about this instance\u201d.Note: I used %r above, not %s. You always want to use repr() [or %r formatting character, equivalently] inside __repr__ implementation, or you\u2019re defeating the goal of repr. You want to be able to differentiate MyClass(3) and MyClass(\"3\").The goal of __str__ is to be readableSpecifically, it is not intended to be unambiguous \u2014 notice that str(3)==str(\"3\"). Likewise, if you implement an IP abstraction, having the str of it look like 192.168.1.1 is just fine. When implementing a date/time abstraction, the str can be \"2010/4/12 15:35:22\", etc. The goal is to represent it in a way that a user, not a programmer, would want to read it. Chop off useless digits, pretend to be some other class \u2014 as long is it supports readability, it is an improvement.Container\u2019s __str__ uses contained objects\u2019 __repr__This seems surprising, doesn\u2019t it? It is a little, but how readable would it be if it used their __str__?Not very. Specifically, the strings in a container would find it way too easy to disturb its string representation. In the face of ambiguity, remember, Python resists the temptation to guess. If you want the above behavior when you\u2019re printing a list, just(you can probably also figure out what to do about dictionaries.SummaryImplement __repr__ for any class you implement. This should be second nature. Implement __str__ if you think it would be useful to have a string version which errs on the side of readability.",
                "My rule of thumb:  __repr__ is for developers, __str__ is for customers.",
                "Unless you specifically act to ensure otherwise, most classes don't have helpful results for either:As you see -- no difference, and no info beyond the class and object's id.  If you only override one of the two...:as you see, if you override __repr__, that's ALSO used for __str__, but not vice versa.Other crucial tidbits to know: __str__ on a built-on container uses the __repr__, NOT the __str__, for the items it contains. And, despite the words on the subject found in typical docs, hardly anybody bothers making the __repr__ of objects be a string that eval may use to build an equal object (it's just too hard, AND not knowing how the relevant module was actually imported makes it actually flat out impossible).So, my advice: focus on making __str__ reasonably human-readable, and __repr__ as unambiguous as you possibly can, even if that interferes with the fuzzy unattainable goal of making __repr__'s returned value acceptable as input to __eval__!",
                "__repr__: representation of python object usually eval will convert it back to that object__str__: is whatever you think is that object in text forme.g.",
                "In short, the goal of __repr__ is to be unambiguous and __str__ is to be\n  readable.Here is a good example:Read this documentation for repr:repr(object)Return a string containing a printable representation of an object. This is the same value yielded by conversions (reverse\n  quotes). It is sometimes useful to be able to access this operation as\n  an ordinary function. For many types, this function makes an attempt\n  to return a string that would yield an object with the same value when\n  passed to eval(), otherwise the representation is a string enclosed in\n  angle brackets that contains the name of the type of the object\n  together with additional information often including the name and\n  address of the object. A class can control what this function returns\n  for its instances by defining a __repr__() method.Here is the documentation for str:str(object='')Return a string containing a nicely printable\n  representation of an object. For strings, this returns the string\n  itself. The difference with repr(object) is that str(object) does not\n  always attempt to return a string that is acceptable to eval(); its\n  goal is to return a printable string. If no argument is given, returns\n  the empty string, ''.",
                "__str__ (read as \"dunder (double-underscore) string\") and __repr__ (read as \"dunder-repper\" (for \"representation\")) are both special methods that return strings based on the state of the object.__repr__ provides backup behavior if __str__ is missing.So one should first write a __repr__ that allows you to reinstantiate an equivalent object from the string it returns e.g. using eval or by typing it in character-for-character in a Python shell.At any time later, one can write a __str__ for a user-readable string representation of the instance, when one believes it to be necessary.If you print an object, or pass it to format, str.format, or str, then if a __str__ method is defined, that method will be called, otherwise, __repr__ will be used.The __repr__ method is called by the builtin function repr and is what is echoed on your python shell when it evaluates an expression that returns an object.Since it provides a backup for __str__, if you can only write one, start with __repr__Here's the builtin help on repr:That is, for most objects, if you type in what is printed by repr, you should be able to create an equivalent object. But this is not the default implementation.The default object __repr__ is (C Python source) something like:That means by default you'll print the module the object is from, the class name, and the hexadecimal representation of its location in memory - for example:This information isn't very useful, but there's no way to derive how one might accurately create a canonical representation of any given instance, and it's better than nothing, at least telling us how we might uniquely identify it in memory.Let's look at how useful it can be, using the Python shell and datetime objects. First we need to import the datetime module:If we call datetime.now in the shell, we'll see everything we need to recreate an equivalent datetime object. This is created by the datetime __repr__:If we print a datetime object, we see a nice human readable (in fact, ISO) format. This is implemented by datetime's __str__:It is a simple matter to recreate the object we lost because we didn't assign it to a variable by copying and pasting from the __repr__ output, and then printing it, and we get it in the same human readable output as the other object:#How do I implement them?As you're developing, you'll want to be able to reproduce objects in the same state, if possible. This, for example, is how the datetime object defines __repr__ (Python source). It is fairly complex, because of all of the attributes needed to reproduce such an object:If you want your object to have a more human readable representation, you can implement __str__ next. Here's how the datetime object (Python source) implements __str__, which it easily does because it already has a function to display it in ISO format:This is a critique of another answer here that suggests setting __repr__ = __str__.Setting __repr__ = __str__ is silly - __repr__ is a fallback for __str__ and a __repr__, written for developers usage in debugging, should be written before you write a __str__.You need a __str__ only when you need a textual representation of the object.Define __repr__ for objects you write so you and other developers have a reproducible example when using it as you develop. Define __str__ when you need a human readable string representation of it.",
                "On page 358 of the book Python scripting for computational science by Hans Petter Langtangen, it clearly states thatSo, I prefer to understand them asfrom the user's point of view\nalthough this is a misunderstanding I made when learning python.A small but good example is also given on the same page as follows:",
                "Apart from all the answers given, I would like to add few points :-1) __repr__() is invoked when you simply write object's name on interactive python console and press enter.2) __str__() is invoked when you use object with print statement.3) In case, if __str__ is missing, then print and any function using str() invokes __repr__() of object.4) __str__() of containers, when invoked will execute __repr__() method of its contained elements.5) str() called within __str__() could potentially recurse without a base case, and error on maximum recursion depth.6) __repr__() can call repr() which will attempt to avoid infinite recursion automatically, replacing an already represented object with ....",
                "(2020 entry)Q: What's the difference between __str__() and __repr__()?TL;DR:LONGThis question has been around a long time, and there are a variety of answers of which most are correct (not to mention from several Python community legends[!]). However when it comes down to the nitty-gritty, this question is analogous to asking the difference between the str() and repr() built-in functions. I'm going to describe the differences in my own words (which means I may be \"borrowing\" liberally from Core Python Programming so pls forgive me).Both str() and repr() have the same basic job: their goal is to return a string representation of a Python object. What kind of string representation is what differentiates them.For example, let's assign a string to x and an int to y, and simply showing human-readable string versions of each:Can we take what is inside the quotes in both cases and enter them verbatim into the Python interpreter? Let's give it a try:Clearly you can for an int but not necessarily for a str. Similarly, while I can pass '123' to eval(), that doesn't work for 'foo':So this tells you the Python shell just eval()s what you give it. Got it? Now, let's repr() both expressions and see what we get. More specifically, take its output and dump those out in the interpreter (there's a point to this which we'll address afterwards):Wow, they both work? That's because 'foo', while a printable string representation of that string, it's not evaluatable, but \"'foo'\" is. 123 is a valid Python int called by either str() or repr(). What happens when we call eval() with these?It works because 123 and 'foo' are valid Python objects. Another key takeaway is that while sometimes both return the same thing (the same string representation), that's not always the case. (And yes, yes, I can go create a variable foo where the eval() works, but that's not the point.)More factoids about both pairs",
                "To put it simply:__str__ is used in to show a string representation of your object to be read easily by others.__repr__ is used to show a string representation of the object.Let's say I want to create a Fraction class where the string representation of a fraction is '(1/2)' and the object (Fraction class) is to be represented as 'Fraction (1,2)'So we can create a simple Fraction class:",
                "From an (An Unofficial) Python Reference Wiki (archive copy) by effbot:__str__ \"computes the \"informal\" string representation of an object. This differs from __repr__ in that it does not have to be a valid Python expression: a more convenient or concise representation may be used instead.\"",
                "In all honesty, eval(repr(obj)) is never used. If you find yourself using it, you should stop, because eval is dangerous, and strings are a very inefficient way to serialize your objects (use pickle instead).Therefore, I would recommend setting __repr__ = __str__. The reason is that str(list) calls repr on the elements (I consider this to be one of the biggest design flaws of Python that was not addressed by Python 3). An actual repr will probably not be very helpful as the output of print([your, objects]).To qualify this, in my experience, the most useful use case of the repr function is to put a string inside another string (using string formatting). This way, you don't have to worry about escaping quotes or anything. But note that there is no eval happening here.",
                "str - Creates a new string object from the given object.repr - Returns the canonical string representation of the object.The differences:str():repr():",
                "One aspect that is missing in other answers. It's true that in general the pattern is:Unfortunately, this differentiation is flawed, because the Python REPL and also IPython use __repr__ for printing objects in a REPL console (see related questions for Python and IPython). Thus, projects which are targeted for interactive console work (e.g., Numpy or Pandas) have started to ignore above rules and provide a human-readable __repr__ implementation instead.",
                "From the book Fluent Python:A basic requirement for a Python object is to provide usable \n       string   representations of itself, one used for debugging and\n       logging, another for presentation to end users. That is why the\n       special methods __repr__ and __str__ exist in the data model.",
                "__str__ can be invoked on an object by calling str(obj) and should return a human readable string.__repr__ can be invoked on an object by calling repr(obj) and should return internal object (object fields/attributes)This example may help:",
                "You can get some insight from this code:",
                "Excellent answers already cover the difference between __str__ and __repr__, which for me boils down to the former being readable even by an end user, and the latter being as useful as possible to developers. Given that, I find that the default implementation of __repr__ often fails to achieve this goal because it omits information useful to developers.For this reason, if I have a simple enough __str__, I generally just try to get the best of both worlds with something like:",
                "When print() is called on the result of decimal.Decimal(23) / decimal.Decimal(\"1.05\") the raw number is printed; this output is in string form which can be achieved with __str__(). If we simply enter the expression we get a decimal.Decimal output \u2014 this output is in representational form which can be achieved with __repr__(). All Python objects have two output forms. String form is designed to be human-readable. The representational form is designed to produce output that if fed to a Python interpreter would (when possible) reproduce the represented object.",
                "One important thing to keep in mind is that container's __str__ uses contained objects' __repr__.Python favors unambiguity over readability, the __str__ call of a tuple calls the contained objects' __repr__, the \"formal\" representation of an object. Although the formal representation is harder to read than an informal one, it is unambiguous and more robust against bugs.",
                "In a nutshell:",
                "Understand __str__ and __repr__ intuitively and permanently distinguish them at all.__str__ return the string disguised body of a given object for readable of eyes\n__repr__ return the real flesh body of a given object (return itself) for unambiguity to identify.See it in an exampleAs to __repr__We can do arithmetic operation on __repr__ results conveniently.if apply the operation on __str__Returns nothing but error.Another example.Hope this help you build concrete grounds to explore more answers.",
                "Source: https://www.journaldev.com/22460/python-str-repr-functions",
                "__repr__ is used everywhere, except by print and str methods (when a __str__is defined !)",
                "Every object inherits __repr__  from the base class that all objects created.if you call repr(p) you will get this as default:But if you call str(p) you will get the same output. it is because when __str__ does not exist, Python calls __repr__Let's implement our own __str__print(p) and str(p)will returnlet's add __str__()if we call print(p) and str(p), it will call __str__() so it will returnrepr(p) will returnrepr called\n\"Person(name='ali, age=self.age')\"Let's omit __repr__ and just implement __str__.print(p) will look for the __str__ and will return:NOTE= if we had __repr__ and __str__ defined, f'name is {p}' would call __str__",
                "Programmers with prior experience in languages with a toString method tend to implement __str__ and not __repr__.\nIf you only implement one of these special methods in Python, choose __repr__.From Fluent Python book, by Ramalho, Luciano.",
                "Basically __str__ or str() is used for creating output that is human-readable are must be for end-users.\nOn the other hand, repr() or __repr__ mainly returns canonical string representation of objects which serve the purpose of debugging and development helps the programmers.",
                "repr() used when we debug or log.It is used for developers to understand code.\none the other hand str() user for non developer like(QA) or user."
            ]
        },
        {
            "tag": "python",
            "question": [
                "Convert bytes to a string",
                "I captured the standard output of an external program into a bytes object:\n>>> from subprocess import *\n>>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]\n>>..."
            ],
            "url": "https://stackoverflow.com/questions/606191",
            "answer": [
                "Decode the bytes object to produce a string:The above example assumes that the bytes object is in UTF-8, because it is a common encoding. However, you should use the encoding your data is actually in!",
                "Decode the byte string and turn it in to a character (Unicode) string.Python 3:orPython 2:or",
                "This joins together a list of bytes into a string:",
                "If you don't know the encoding, then to read binary input into string in Python 3 and Python 2 compatible way, use the ancient MS-DOS CP437 encoding:Because encoding is unknown, expect non-English symbols to translate to characters of cp437 (English characters are not translated, because they match in most single byte encodings and UTF-8).Decoding arbitrary binary input to UTF-8 is unsafe, because you may get this:The same applies to latin-1, which was popular (the default?) for Python 2. See the missing points in Codepage Layout - it is where Python chokes with infamous ordinal not in range.UPDATE 20150604: There are rumors that Python 3 has the surrogateescape error strategy for encoding stuff into binary data without data loss and crashes, but it needs conversion tests, [binary] -> [str] -> [binary], to validate both performance and reliability.UPDATE 20170116: Thanks to comment by Nearoo - there is also a possibility to slash escape all unknown bytes with backslashreplace error handler. That works only for Python 3, so even with this workaround you will still get inconsistent output from different Python versions:See Python\u2019s Unicode Support for details.UPDATE 20170119: I decided to implement slash escaping decode that works for both Python\u00a02 and Python\u00a03. It should be slower than the cp437 solution, but it should produce identical results on every Python version.",
                "In Python 3, the default encoding is \"utf-8\", so you can directly use:which is equivalent toOn the other hand, in Python 2, encoding defaults to the default string encoding. Thus, you should use:where encoding is the encoding you want.Note: support for keyword arguments was added in Python\u00a02.7.",
                "I think you actually want this:Aaron's answer was correct, except that you need to know which encoding to use. And I believe that Windows uses 'windows-1252'. It will only matter if you have some unusual (non-ASCII) characters in your content, but then it will make a difference.By the way, the fact that it does matter is the reason that Python moved to using two different types for binary and text data: it can't convert magically between them, because it doesn't know the encoding unless you tell it! The only way YOU would know is to read the Windows documentation (or read it here).",
                "Since this question is actually asking about subprocess output, you have more direct approaches available. The most modern would be using subprocess.check_output and passing text=True (Python 3.7+) to automatically decode stdout using the system default coding:For Python 3.6, Popen accepts an encoding keyword:The general answer to the question in the title, if you're not dealing with subprocess output, is to decode bytes to text:With no argument, sys.getdefaultencoding() will be used.  If your data is not sys.getdefaultencoding(), then you must specify the encoding explicitly in the decode call:",
                "Set universal_newlines to True, i.e.",
                "To interpret a byte sequence as a text, you have to know the\ncorresponding character encoding:Example:ls command may produce output that can't be interpreted as text. File names\non Unix may be any sequence of bytes except slash b'/' and zero\nb'\\0':Trying to decode such byte soup using utf-8 encoding raises UnicodeDecodeError.It can be worse. The decoding may fail silently and produce mojibake\nif you use a wrong incompatible encoding:The data is corrupted but your program remains unaware that a failure\nhas occurred.In general, what character encoding to use is not embedded in the byte sequence itself. You have to communicate this info out-of-band. Some outcomes are more likely than others and therefore chardet module exists that can guess the character encoding. A single Python script may use multiple character encodings in different places.ls output can be converted to a Python string using os.fsdecode()\nfunction that succeeds even for undecodable\nfilenames (it uses\nsys.getfilesystemencoding() and surrogateescape error handler on\nUnix):To get the original bytes, you could use os.fsencode().If you pass universal_newlines=True parameter then subprocess uses\nlocale.getpreferredencoding(False) to decode bytes e.g., it can be\ncp1252 on Windows.To decode the byte stream on-the-fly,\nio.TextIOWrapper()\ncould be used: example.Different commands may use different character encodings for their\noutput e.g., dir internal command (cmd) may use cp437. To decode its\noutput, you could pass the encoding explicitly (Python 3.6+):The filenames may differ from os.listdir() (which uses Windows\nUnicode API) e.g., '\\xb6' can be substituted with '\\x14'\u2014Python's\ncp437 codec maps b'\\x14' to control character U+0014 instead of\nU+00B6 (\u00b6). To support filenames with arbitrary Unicode characters, see  Decode PowerShell output possibly containing non-ASCII Unicode characters into a Python string",
                "While @Aaron Maenpaa's answer just works, a user recently asked:Is there any more simply way? 'fhand.read().decode(\"ASCII\")' [...] It's so long!You can use:decode() has a standard argument:codecs.decode(obj, encoding='utf-8', errors='strict')",
                "If you should get the following by trying decode():AttributeError: 'str' object has no attribute 'decode'You can also specify the encoding type straight in a cast:",
                "ororor",
                "If you have had this error:utf-8 codec can't decode byte 0x8a,then it is better to use the following code to convert bytes to a string:",
                "For Python 3, this is a much safer and Pythonic approach to convert from byte to string:Output:",
                "When working with data from Windows systems (with \\r\\n line endings), my answer isWhy? Try this with a multiline Input.txt:All your line endings will be doubled (to \\r\\r\\n), leading to extra empty lines. Python's text-read functions usually normalize line endings so that strings use only \\n. If you receive binary data from a Windows system, Python does not have a chance to do that. Thus,will replicate your original file.",
                "We can decode the bytes object to produce a string using bytes.decode(encoding='utf-8', errors='strict').\nFor documentation see bytes.decode.Python 3 example:Output:Note: In Python 3, by default the encoding type is UTF-8. So, <byte_string>.decode(\"utf-8\") can be also written as <byte_string>.decode()",
                "For your specific case of \"run a shell command and get its output as text instead of bytes\", on Python 3.7, you should use subprocess.run and pass in text=True (as well as capture_output=True to capture the output)text used to be called universal_newlines, and was changed (well, aliased) in Python 3.7. If you want to support Python versions before 3.7, pass in universal_newlines=True instead of text=True",
                "From sys \u2014 System-specific parameters and functions:To write or read binary data from/to the standard streams, use the underlying binary buffer. For example, to write bytes to stdout, use sys.stdout.buffer.write(b'abc').",
                "Try this:",
                "Decode with .decode(). This will decode the string. Pass in 'utf-8') as the value in the inside.",
                "If you want to convert any bytes, not just string converted to bytes:This is not very efficient, however. It will turn a 2 MB picture into 9 MB.",
                "Try using this one; this function will ignore all the non-character sets (like UTF-8) binaries and return a clean string. It is tested for Python\u00a03.6 and above.Here, the function will take the binary and decode it (converts binary data to characters using the Python predefined character set and the ignore argument ignores all non-character set data from your binary and finally returns your desired string value.If you are not sure about the encoding, use sys.getdefaultencoding() to get the default encoding of your device."
            ]
        },
        {
            "tag": "python",
            "question": [
                "How to copy files",
                "How do I copy a file in Python?"
            ],
            "url": "https://stackoverflow.com/questions/123198",
            "answer": [
                "shutil has many methods you can use. One of which is:Another shutil method to look at is shutil.copy2(). It's similar but preserves more metadata (e.g. time stamps).If you use os.path operations, use copy rather than copyfile. copyfile will only accept strings.",
                "copy2(src,dst) is often more useful than copyfile(src,dst) because:Here is a short example:",
                "In Python, you can copy the files usingshutil.copyfile  signatureshutil.copy  signatureshutil.copy2  signatureshutil.copyfileobj  signatureos.popen  signatureos.system  signaturesubprocess.call  signaturesubprocess.check_output  signature",
                "You can use one of the copy functions from the shutil package:Example:",
                "Copying a file is a relatively straightforward operation as shown by the examples below, but you should instead use the shutil stdlib module for that.If you want to copy by filename you could do something like this:",
                "Use the shutil module.Copy the contents of the file named src to a file named dst. The destination location must be writable; otherwise, an IOError exception will be raised. If dst already exists, it will be replaced. Special files such as character or block devices and pipes cannot be copied with this function. src and dst are path names given as strings.Take a look at filesys for all the file and directory handling functions available in standard Python modules.",
                "Directory and File copy example, from Tim Golden's Python Stuff:",
                "For small files and using only Python built-ins, you can use the following one-liner:This is not optimal way for applications where the file is too large or when memory is critical, thus Swati's answer should be preferred.",
                "Firstly, I made an exhaustive cheat sheet of the shutil methods for your reference.Secondly, explaining methods of copy in examples:shutil.copyfileobj(fsrc, fdst[, length]) manipulate opened objectsshutil.copyfile(src, dst, *, follow_symlinks=True)  Copy and renameshutil.copy()  Copy without preseving the metadatashutil.copy2()  Copy with preserving the metadatashutil.copytree()Recursively copy an entire directory tree rooted at src, returning the destination directory.",
                "shutil module offers some high-level operations on files. It supports file copying and removal.Refer to the table below for your use case.",
                "As of Python 3.5 you can do the following for small files (ie: text files, small jpegs):write_bytes will overwrite whatever was at the destination's location",
                "You could use os.system('cp nameoffilegeneratedbyprogram /otherdirectory/').Or as I did it,where rawfile is the name that I had generated inside the program.This is a Linux-only solution.",
                "Use subprocess.call to copy the file",
                "For large files, I read the file line by line and read each line into an array. Then, once the array reached a certain size, append it to a new file.",
                "UseOpen the source file in read mode, and write to the destination file in write mode.",
                "In case you've come this far down. The answer is that you need the entire path and file name",
                "Here is a simple way to do it, without any module. It's similar to this answer, but has the benefit to also work if it's a big file that doesn't fit in RAM:Since we're writing a new file, it does not preserve the modification time, etc.\nWe can then use os.utime for this if needed.",
                "Similar to the accepted answer, the following code block might come in handy if you also want to make sure to create any (non-existent) folders in the path to the destination.As the accepted answers notes, these lines will overwrite any file which exists at the destination path, so sometimes it might be useful to also add: if not path.exists(destination_path): before this code block.",
                "There are two best ways to copy file in Python.Code Example:There are other methods available also other than copyfile, like copy, copy2, etc, but copyfile is best in terms of performance,Code Example:Another method is by the use of a subprocess, but it is not preferable as it\u2019s one of the call methods and is not secure.",
                "You can use system.For Unix-like systems:",
                "You can use os.link to create a hard link to a file:This is not an independent clone, but if you plan to only read (not modify) the new file and its content must remain the same as the original, this will work well. It also has a benefit that if you want to check whether the copy already exists, you can compare the hard links (with os.stat) instead of their content.In Linux, the command cp with keyscreates a hard link. Therefore a hard link may be considered a copy. Sometimes a person would need exactly this behaviour (access to file content from a different place), and not need a separate copy.",
                "Here is an answer utilizing \"shutil.copyfileobj\" and it is highly efficient. I used it in a tool I created some time ago. I didn't write this originally, but I tweaked it a little bit.",
                "Python provides in-built functions for easily copying files using the operating system shell utilities.The Following command is used to copy a file:The following command is used to copy a file with metadata information:",
                "shutil.copy(src, dst, *, follow_symlinks=True)"
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I list all files of a directory?",
                "How can I list all files of a directory in Python and add them to a list?"
            ],
            "url": "https://stackoverflow.com/questions/3207219",
            "answer": [
                "os.listdir() returns everything inside a directory -- including both files and directories.os.path's isfile() can be used to only list files:Alternatively, os.walk() yields two lists for each directory it visits -- one for files and one for dirs. If you only want the top directory you can break the first time it yields:or, shorter:",
                "I prefer using the glob module, as it does pattern matching and expansion.It does pattern matching intuitivelyIt will return a list with the queried files and directories:Note that glob ignores files and directories that begin with a dot ., as those are considered hidden files and directories, unless the pattern is something like .*.Use glob.escape to escape strings that are not meant to be patterns:",
                "list in the current directoryWith listdir in os module you get the files and the folders in the current dirLooking in a directorywith glob you can specify a type of file to list like thisorget the full path of only files in the current directoryGetting the full path name with os.path.abspathYou get the full path in returnWalk: going through sub directoriesos.walk returns the root, the directories list and the files list, that is why I unpacked them in r, d, f in the for loop; it, then, looks for other files and directories in the subfolders of the root and so on until there are no subfolders.To go up in the directory treeGet files of a particular subdirectory with os.listdir()os.walk('.') - current directorynext(os.walk('.')) and os.path.join('dir', 'file')next... walkos.walkos.listdir() - get only txt filesUsing glob to get the full path of the filesUsing os.path.isfile to avoid directories in the listUsing pathlib from Python 3.4With list comprehension:Use glob method in pathlib.Path()Get all and only files with os.walk: checks only in the third element returned, i.e. the list of the filesGet only files with next in a directory: returns only the file in the root folderGet only directories with next and walk in a directory, because in the [1] element there are the folders onlyGet all the subdir names with walkos.scandir() from Python 3.5 and greater",
                "will return a list of all files and directories in \"somedirectory\".",
                "A one-line solution to get only list of files (no subdirectories):or absolute pathnames:",
                "Getting Full File Paths From a Directory and All Its Subdirectoriesprint full_file_paths which will print the list:If you'd like, you can open and read the contents, or focus only on files with the extension \".dat\" like in the code below:/Users/johnny/Desktop/TEST/SUBFOLDER/file3.dat",
                "Since version 3.4 there are builtin iterators for this which are a lot more efficient than os.listdir():pathlib: New in version 3.4.According to PEP 428, the aim of the pathlib library is to provide a simple hierarchy of classes to handle filesystem paths and the common operations users do over them.os.scandir(): New in version 3.5.Note that os.walk() uses os.scandir() instead of os.listdir() from version 3.5, and its speed got increased by 2-20 times according to PEP 471.Let me also recommend reading ShadowRanger's comment below.",
                "Although there's a clear differentiation between file and directory terms in the question text, some may argue that directories are actually special filesThe statement: \"all files of a directory\" can be interpreted in two ways:All direct (or level 1) descendants onlyAll descendants in the whole directory tree (including the ones in sub-directories)When the question was asked, I imagine that Python 2, was the LTS version, however the code samples will be run by Python 3(.5) (I'll keep them as Python 2 compliant as possible; also, any code belonging to Python that I'm going to post, is from v3.5.4 - unless otherwise specified).\nThat has consequences related to another keyword in the question: \"add them into a list\":In pre Python 2.2 versions, sequences (iterables) were mostly represented by lists (tuples, sets, ...)In Python 2.2, the concept of generator ([Python.Wiki]: Generators) - courtesy of [Python.Docs]: Simple statements - The yield statement) - was introduced. As time passed, generator counterparts started to appear for functions that returned / worked with listsIn Python 3, generator is the default behaviorNot sure if returning a list is still mandatory (or a generator would do as well), but passing a generator to the list constructor, will create a list out of it (and also consume it). The example below illustrates the differences on [Python.Docs]: Built-in functions - map(function, iterable, *iterables)The examples will be based on a directory called root_dir with the following structure (this example is for Win, but I'm using the same tree on Nix as well). Note that I'll be reusing the console:Return a list containing the names of the entries in the directory given by path. The list is in arbitrary order, and does not include the special entries '.' and '..' ...A more elaborate example (code_os_listdir.py):Notes:There are two implementations:One that uses generators (of course here it seems useless, since I immediately convert the result to a list)The classic one (function names ending in _old)Recursion is used (to get into subdirectories)For each implementation there are two functions:One that starts with an underscore (_): \"private\" (should not be called directly) - that does all the workThe public one (wrapper over previous): it just strips off the initial path (if required) from the returned entries. It's an ugly implementation, but it's the only idea that I could come with at this pointIn terms of performance, generators are generally a little bit faster (considering both creation and  iteration times), but I didn't test them in recursive functions, and also I am iterating inside the function over inner generators - don't know how performance friendly is thatPlay with the arguments to get different resultsOutput:In Python 3.5+ only, backport: [PyPI]: scandir:Return an iterator of os.DirEntry objects corresponding to the entries in the directory given by path. The entries are yielded in arbitrary order, and the special entries '.' and '..' are not included.Using scandir() instead of listdir() can significantly increase the performance of code that also needs file type or file attribute information, because os.DirEntry objects expose this information if the operating system provides it when scanning a directory. All os.DirEntry methods may perform a system call, but is_dir() and is_file() usually only require a system call for symbolic links; os.DirEntry.stat() always requires a system call on Unix but only requires one for symbolic links on Windows.Notes:Similar to os.listdirBut it's also more flexible (and offers more functionality), more Pythonic (and in some cases, faster)Generate the file names in a directory tree by walking the tree either top-down or bottom-up. For each directory in the tree rooted at directory top (including top itself), it yields a 3-tuple (dirpath, dirnames, filenames).Notes:Under the scenes, it uses os.scandir (os.listdir on older (Python) versions)It does the heavy lifting by recurring in subfoldersOr glob.iglob:Return a possibly-empty list of path names that match pathname, which must be a string containing a path specification. pathname can be either absolute (like /usr/src/Python-1.5/Makefile) or relative (like ../../Tools/*/*.gif), and can contain shell-style wildcards. Broken symlinks are included in the results (as in the shell)....Changed in version 3.5: Support for recursive globs using \u201c**\u201d.Notes:Uses os.listdirFor large trees (especially if recursive is on), iglob is preferredAllows advanced filtering based on name (due to the wildcard)Python 3.4+, backport: [PyPI]: pathlib2.Notes:This is one way of achieving our goalIt's the OOP style of handling pathsOffers lots of functionalitiesPython 2 onlyBut, according to [GitHub]: python/cpython - (2.7) cpython/Lib/dircache.py, it's just a (thin) wrapper over os.listdir with cachingPOSIX specific:[Man7]: OPENDIR(3)[Man7]: READDIR(3)[Man7]: CLOSEDIR(3)Available via [Python.Docs]: ctypes - A foreign function library for Python:ctypes is a foreign function library for Python. It provides C compatible data types, and allows calling functions in DLLs or shared libraries. It can be used to wrap these libraries in pure Python.Not directly related, but check [SO]: C function called from Python via ctypes returns incorrect value (@CristiFati's answer) out before working with CTypes.code_ctypes.py:Notes:It loads the three functions from LibC (libc.so - loaded in the current process) and calls them (for more details check [SO]: How do I check whether a file exists without exceptions? (@CristiFati's answer) - last notes from item #4.). That would place this approach very close to the Python / C edgeNixDirent64 is the CTypes representation of struct dirent64 from [Man7]: dirent.h(0P) (so are the DT_ constants) from my Ubuntu OS. On other flavors / versions, the structure definition might differ, and if so, the CTypes alias should be updated, otherwise it will yield Undefined BehaviorIt returns data in the os.walk's format. I didn't bother to make it recursive, but starting from the existing code, that would be a fairly trivial taskEverything is doable on Win as well, the data (libraries, functions, structs, constants, ...) differOutput:Win specific:Retrieves a list of matching filenames, using the Windows Unicode API. An interface to the API FindFirstFileW/FindNextFileW/Find close functions.Notes:Most likely, will rely on one (or more) of the above (maybe with slight customizations).Code is meant to be portable (except places that target a specific area - which are marked) or cross:OS (Nix, Win, )Python version (2, 3, )Multiple path styles (absolute, relatives) were used across the above variants, to illustrate the fact that the \"tools\" used are flexible in this directionos.listdir and os.scandir use opendir / readdir / closedir ([MS.Learn]: FindFirstFileW function (fileapi.h) / [MS.Learn]: FindNextFileW function (fileapi.h) / [MS.Learn]: FindClose function (fileapi.h)) (via [GitHub]: python/cpython - (main) cpython/Modules/posixmodule.c)win32file.FindFilesW uses those (Win specific) functions as well (via [GitHub]: mhammond/pywin32 - (main) pywin32/win32/src/win32file.i)_get_dir_content (from point #1.) can be implemented using any of these approaches (some will require more work and some less)Nota Bene! Since recursion is used, I must mention that I did some tests on my laptop (Win 10 pc064), totally unrelated to this problem, and when the recursion level was reaching values somewhere in the (990 .. 1000) range (recursionlimit - 1000 (default)), I got StackOverflow :). If the directory tree exceeds that limit (I am not an FS expert, so I don't know if that is even possible), that could be a problem.\nI must also mention that I didn't try to increase recursionlimit, but in theory there will always be the possibility for failure, if the dir depth is larger than the highest possible recursionlimit (on that machine).\nCheck [SO]: _csv.Error: field larger than field limit (131072) (@CristiFati's answer) for more details on the topicCode samples are for demonstrative purposes only. That means that I didn't take into account error handling (I don't think there's any try / except / else / finally block), so the code is not robust (the reason is: to keep it as simple and short as possible). For production, error handling should be added as wellEverything is done using another technologyThat technology is invoked from PythonThe most famous flavor that I know is what I call the SysAdmin approach:Use Python (or any programming language for that matter) in order to execute Shell commands (and parse their outputs)Some consider this a neat hackI consider it more like a lame workaround (gainarie), as the action per se is performed from Shell (Cmd in this case), and thus doesn't have anything to do with PythonFiltering (grep / findstr) or output formatting could be done on both sides, but I'm not going to insist on it. Also, I deliberately used os.system instead of [Python.Docs]: subprocess - Subprocess management routines (run, check_output, ...)In general, this approach is to be avoided, since if some command output format slightly differs between OS versions / flavors, the parsing code should be adapted as well - not to mention differences between locales.",
                "I really liked adamk's answer, suggesting that you use glob(), from the module of the same name. This allows you to have pattern matching with *s.But as other people pointed out in the comments, glob() can get tripped up over inconsistent slash directions. To help with that, I suggest you use the join() and expanduser() functions in the os.path module, and perhaps the getcwd() function in the os module, as well.As examples:The above is terrible - the path has been hardcoded and will only ever work on Windows between the drive name and the \\s being hardcoded into the path.The above works better, but it relies on the folder name Users which is often found on Windows and not so often found on other OSs. It also relies on the user having a specific name, admin.This works perfectly across all platforms.Another great example that works perfectly across platforms and does something a bit different:Hope these examples help you see the power of a few of the functions you can find in the standard Python library modules.",
                "If you are looking for a Python implementation of find, this is a recipe I use rather frequently:So I made a PyPI package out of it and there is also a GitHub repository. I hope that someone finds it potentially useful for this code.",
                "For greater results, you can use listdir() method of the os module along with a generator (a generator is a powerful iterator that keeps its state, remember?). The following code works fine with both versions: Python 2 and Python 3.Here's a code:The listdir() method returns the list of entries for the given directory. The method os.path.isfile() returns True if the given entry is a file. And the yield operator quits the func but keeps its current state, and it returns only the name of the entry detected as a file. All the above allows us to loop over the generator function.",
                "Returning a list of absolute filepaths, does not recurse into subdirectories",
                "A wise teacher told me once that:When there are several established ways to do something, none of them is good for all cases.I will thus add a solution for a subset of the problem: quite often, we only want to check whether a file matches a start string and an end string, without going into subdirectories. We would thus like a function that returns a list of filenames, like:If you care to first declare two functions, this can be done:This solution could be easily generalized with regular expressions (and you might want to add a pattern argument, if you do not want your patterns to always stick to the start or end of the filename).",
                "Here I use a recursive structure.",
                "Using generators",
                "Another very readable variant for Python 3.4+ is using pathlib.Path.glob:It is simple to make more specific, e.g. only look for Python source files which are not symbolic links, also in all subdirectories:",
                "For Python 2:Then do",
                "Here's my general-purpose function for this.  It returns a list of file paths rather than filenames since I found that to be more useful.  It has a few optional arguments that make it versatile.  For instance, I often use it with arguments like pattern='*.txt' or subfolders=True.",
                "I will provide a sample one liner where sourcepath and file type can be provided as input. The code returns a list of filenames with csv extension. Use . in case all files needs to be returned. This will also recursively scans the subdirectories.[y for x in os.walk(sourcePath) for y in glob(os.path.join(x[0], '*.csv'))]Modify file extensions and source path as needed.",
                "dircache is  \"Deprecated since version 2.6: The dircache module has been removed in Python 3.0.\""
            ]
        },
        {
            "tag": "python",
            "question": [
                "What is __init__.py for?",
                "What is __init__.py for in a Python source directory?"
            ],
            "url": "https://stackoverflow.com/questions/448271",
            "answer": [
                "It used to be a required part of a package (old, pre-3.3 \"regular package\", not newer 3.3+ \"namespace package\").Here's the documentation.Python defines two types of packages, regular packages and namespace packages. Regular packages are traditional packages as they existed in Python 3.2 and earlier. A regular package is typically implemented as a directory containing an __init__.py file. When a regular package is imported, this __init__.py file is implicitly executed, and the objects it defines are bound to names in the package\u2019s namespace. The __init__.py file can contain the same Python code that any other module can contain, and Python will add some additional attributes to the module when it is imported.But just click the link, it contains an example, more information, and an explanation of namespace packages, the kind of packages without __init__.py.",
                "Files named __init__.py are used to mark directories on disk as Python package directories.\nIf you have the filesand mydir is on your path, you can import the code in module.py asorIf you remove the __init__.py file, Python will no longer look for submodules inside that directory, so attempts to import the module will fail.The __init__.py file is usually empty, but can be used to export selected portions of the package under more convenient name, hold convenience functions, etc.\nGiven the example above, the contents of the init module can be accessed asbased on this",
                "In addition to labeling a directory as a Python package and defining __all__, __init__.py allows you to define any variable at the package level. Doing so is often convenient if a package defines something that will be imported frequently, in an API-like fashion. This pattern promotes adherence to the Pythonic \"flat is better than nested\" philosophy.Here is an example from one of my projects, in which I frequently import a sessionmaker called Session to interact with my database. I wrote a \"database\" package with a few modules:My __init__.py contains the following code:Since I define Session here, I can start a new session using the syntax below. This code would be the same executed from inside or outside of the \"database\" package directory.Of course, this is a small convenience -- the alternative would be to define Session in a new file like \"create_session.py\" in my database package, and start new sessions using:There is a pretty interesting reddit thread covering appropriate uses of __init__.py here:http://www.reddit.com/r/Python/comments/1bbbwk/whats_your_opinion_on_what_to_include_in_init_py/The majority opinion seems to be that __init__.py files should be very thin to avoid violating the \"explicit is better than implicit\" philosophy.",
                "There are 2 main reasons for __init__.pyFor convenience: the other users will not need to know your functions' exact location in your package hierarchy (documentation).then others can call add() bywithout knowing file1's inside functions, likeIf you want something to be initialized; for example, logging (which should be put in the top level):",
                "The __init__.py file makes Python treat directories containing it as modules.Furthermore, this is the first file to be loaded in a module, so you can use it to execute code that you want to run each time a module is loaded, or specify the submodules to be exported.",
                "Since Python 3.3, __init__.py is no longer required to define directories as importable Python packages.Check PEP 420: Implicit Namespace Packages:Native support for package directories that don\u2019t require __init__.py marker files and can automatically span multiple path segments (inspired by various third party approaches to namespace packages, as described in PEP 420)Here's the test:references:\nhttps://docs.python.org/3/whatsnew/3.3.html#pep-420-implicit-namespace-packages\nhttps://www.python.org/dev/peps/pep-0420/\nIs __init__.py not required for packages in Python 3?",
                "Although Python works without an __init__.py file you should still include one.It specifies that the directory should be treated as a package, so therefore include it (even if it is empty).There is also a case where you may actually use an __init__.py file:Imagine you had the following file structure:And methods.py contained this:To use foo() you would need one of the following:Maybe there you need (or want) to keep methods.py inside main_methods (runtimes/dependencies for example) but you only want to import main_methods.If you changed the name of methods.py to __init__.py then you could use foo() by just importing main_methods:This works because __init__.py is treated as part of the package.Some Python packages actually do this.  An example is with JSON, where running import json is actually importing __init__.py from the json package (see the package file structure here):Source code: Lib/json/__init__.py",
                "In Python the definition of package is very simple. Like Java the hierarchical structure and the directory structure are the same. But you have to have __init__.py in a package. I will explain the __init__.py file with the example below:__init__.py can be empty, as long as it exists. It indicates that the directory should be regarded as a package. Of course, __init__.py can also set the appropriate content.If we add a function in module_n1:After running:Then we followed the hierarchy package and called module_n1 the function. We can use __init__.py in subPackage_b like this:After running:Hence using * importing, module package is subject to __init__.py content.",
                "__init__.py will treat the directory it is in as a loadable module.For people who prefer reading code, I put Two-Bit Alchemist's comment here.",
                "It facilitates importing other python files. When you placed this file in a directory (say stuff)containing other py files, then you can do something like import stuff.other.Without this __init__.py inside the directory stuff, you couldn't import other.py, because Python doesn't know where the source code for stuff is and unable to recognize it as a package.",
                "An __init__.py file makes imports easy. When an __init__.py is present within a package, function a() can be imported from file b.py like so:Without it, however, you can't import directly. You have to amend the system path:",
                "One thing __init__.py allows is converting a module to a package without breaking the API or creating extraneous nested namespaces or private modules*. This helps when I want to extend a namespace.If I have a file util.py containingthen users will access foo withIf I then want to add utility functions for database interaction, and I want them to have their own namespace under util, I'll need a new directory**, and to keep API compatibility (so that from util import foo still works), I'll call it util/. I could move util.py into util/ like so,and in util/__init__.py dobut this is redundant. Instead of having a util/util.py file, we can just put the util.py contents in __init__.py and the user can nowI think this nicely highlights how a util package's __init__.py acts in a similar way to a util module* this is hinted at in the other answers, but I want to highlight it here\n** short of employing import gymnastics. Note it won't work to create a new package with the same name as the file, see this",
                "If you're using Python 2 and want to load siblings of your file you can simply add the parent folder of your file to your system paths of the session. It will behave about the same as if your current file was an init file.After that regular imports relative to the file's directory will work just fine. E.g.Generally you want to use a proper init.py file instead though, but when dealing with legacy code you might be stuck with f.ex. a library hard-coded to load a particular file and nothing but. For those cases this is an alternative.",
                "init.py : It is a python file found in a package directory, it is invoked when the package or a module in the package is imported. You can use this to execute package initialization code, i.e. whenever the package is imported the python statements are executed first before the other modules in this folder gets executed. It is similar to main function of c or java program but this exists in the python package module(folder) rather than in the core python file.\nalso it has access to global variables defined in this init.py file as when the module is imported into python file.for eg.\nI have a init.py file in a folder called pymodlib, this file contains the following statements:print(f'Invoking init.py for {name}')\npystructures = ['for_loop', 'while__loop', 'ifCondition']when I import this package \"pymodlib\" in the my solution module or notebook or python console:\nthis two statements gets executed while importing.\nSo in the log or console you would see the following output:import pymodlib\nInvoking init.py for pymodlibin the next statement of python console: I can access the global variable:pymodlib.pystructures\nit gives the following output:['for_loop', 'while__loop', 'ifCondition']Now from python3.3 onwards the use of this file has been optional to make folder a python module. So you skip from including it in the python module folder."
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I sort a dictionary by value?",
                "I have a dictionary of values read from two fields in a database: a string field and a numeric field. The string field is unique, so that is the key of the dictionary.\n\nI can sort on the keys, but how ..."
            ],
            "url": "https://stackoverflow.com/questions/613183",
            "answer": [
                "Dicts preserve insertion order in Python 3.7+. Same in CPython 3.6, but it's an implementation detail.orIt is not possible to sort a dictionary, only to get a representation of a dictionary that is sorted. Dictionaries are inherently orderless, but other types, such as lists and tuples, are not. So you need an ordered data type to represent sorted values, which will be a list\u2014probably a list of tuples.For instance,sorted_x will be a list of tuples sorted by the second element in each tuple. dict(sorted_x) == x.And for those wishing to sort on keys instead of values:In Python3 since unpacking is not allowed we can useIf you want the output as a dict, you can use collections.OrderedDict:",
                "Well, it is actually possible to do a \"sort by dictionary values\". Recently I had to do that in a Code Golf (Stack Overflow question Code golf: Word frequency chart). Abridged, the problem was of the kind: given a text, count how often each word is encountered and display a list of the top words, sorted by decreasing frequency.If you construct a dictionary with the words as keys and the number of occurrences of each word as value, simplified here as:then you can get a list of the words, ordered by frequency of use with sorted(d, key=d.get) - the sort iterates over the dictionary keys, using the number of word occurrences as a sort key .I am writing this detailed explanation to illustrate what people often mean by \"I can easily sort a dictionary by key, but how do I sort by value\" - and I think the original post was trying to address such an issue. And the solution is to do sort of list of the keys, based on the values, as shown above.",
                "You could use:This will sort the dictionary by the values of each entry within the dictionary from smallest to largest.To sort it in descending order just add reverse=True:Input:Output:",
                "Dicts can't be sorted, but you can build a sorted list from them.A sorted list of dict values:A list of (key, value) pairs, sorted by value:",
                "In recent Python 2.7, we have the new OrderedDict type, which remembers the order in which the items were added.To make a new ordered dictionary from the original, sorting by the values:The OrderedDict behaves like a normal dict:",
                "Whilst I found the accepted answer useful, I was also surprised that it hasn't been updated to reference OrderedDict from the standard library collections module as a viable, modern alternative - designed to solve exactly this type of problem.The official OrderedDict documentation offers a very similar example too, but using a lambda for the sort function:",
                "Pretty much the same as Hank Gay's answer:Or optimized slightly as suggested by John Fouhy:",
                "Good news, so the OP's original use case of mapping pairs retrieved from a database with unique string ids as keys and numeric values as values into a built-in Python v3.6+ dict, should now respect the insert order.If say the resulting two column table expressions from a database query like:would be stored in two Python tuples, k_seq and v_seq (aligned by numerical index and with the same length of course), then:Allow to output later as:yielding in this case (for the new Python 3.6+ built-in dict!):in the same ordering per value of v.Where in the Python 3.5 install on my machine it currently yields:As proposed in 2012 by Raymond Hettinger (cf. mail on python-dev with subject \"More compact dictionaries with faster iteration\") and now (in 2016) announced in a mail by Victor Stinner to python-dev with subject \"Python 3.6 dict becomes compact and gets a private version; and keywords become ordered\" due to the fix/implementation of issue 27350 \"Compact and ordered dict\" in Python 3.6 we will now be able, to use a built-in dict to maintain insert order!!Hopefully this will lead to a thin layer OrderedDict implementation as a first step. As @JimFasarakis-Hilliard indicated, some see use cases for the OrderedDict type also in the future. I think the Python community at large will carefully inspect, if this will stand the test of time, and what the next steps will be.Time to rethink our coding habits to not miss the possibilities opened by stable ordering of:The first because it eases dispatch in the implementation of functions and methods in some cases.The second as it encourages to more easily use dicts as intermediate storage in processing pipelines.Raymond Hettinger kindly provided documentation explaining \"The Tech Behind Python 3.6 Dictionaries\" - from his San Francisco Python Meetup Group presentation 2016-DEC-08.And maybe quite some Stack Overflow high decorated question and answer pages will receive variants of this information and many high quality answers will require a per version update too.As @ajcr rightfully notes: \"The order-preserving aspect of this new implementation is considered an implementation detail and should not be relied upon.\" (from the whatsnew36) not nit picking, but the citation was cut a bit pessimistic ;-). It continues as \" (this may change in the future, but it is desired to have this new dict implementation in the language for a few releases before changing the language spec to mandate order-preserving semantics for all current and future Python implementations; this also helps preserve backwards-compatibility with older versions of the language where random iteration order is still in effect, e.g. Python 3.5).\"So as in some human languages (e.g. German), usage shapes the language, and the will now has been declared ... in whatsnew36.In a mail to the python-dev list, Guido van Rossum declared:Make it so. \"Dict keeps insertion order\" is the ruling. Thanks!So, the version 3.6 CPython side-effect of dict insertion ordering is now becoming part of the language spec (and not anymore only an implementation detail). That mail thread also surfaced some distinguishing design goals for collections.OrderedDict as reminded by Raymond Hettinger during discussion.",
                "It can often be very handy to use namedtuple. For example, you have a dictionary of 'name' as keys and 'score' as values and you want to sort on 'score':sorting with lowest score first:sorting with highest score first:Now you can get the name and score of, let's say the second-best player (index=1) very Pythonically like this:",
                "I had the same problem, and I solved it like this:(People who answer \"It is not possible to sort a dict\" did not read the question! In fact, \"I can sort on the keys, but how can I sort based on the values?\" clearly means that he wants a list of the keys sorted according to the value of their values.)Please notice that the order is not well defined (keys with the same value will be in an arbitrary order in the output list).",
                "If values are numeric you may also use Counter from collections.",
                "In Python 2.7, simply do:copy-paste from : http://docs.python.org/dev/library/collections.html#ordereddict-examples-and-recipesEnjoy ;-)",
                "Starting from Python 3.6, dict objects are now ordered by insertion order. It's officially in the specifications of Python 3.7.Before that, you had to use OrderedDict.Python 3.7 documentation says:Changed in version 3.7: Dictionary order is guaranteed to be insertion\norder. This behavior was implementation detail of CPython from 3.6.",
                "This is the code:Here are the results:OriginalRoflRank",
                "Try the following approach. Let us define a dictionary called mydict with the following data:If one wanted to sort the dictionary by keys, one could do something like:This should return the following output:On the other hand, if one wanted to sort a dictionary by value (as is asked in the question), one could do the following:The result of this command (sorting the dictionary by value) should return the following:",
                "You can create an \"inverted index\", alsoNow your inverse has the values; each value has a list of applicable keys.",
                "You can use the collections.Counter. Note, this will work for both numeric and non-numeric values.",
                "The collections solution mentioned in another answer is absolutely superb, because you retain a connection between the key and value which in the case of dictionaries is extremely important.I don't agree with the number one choice presented in another answer, because it throws away the keys.I used the solution mentioned above (code shown below) and retained access to both keys and values and in my case the ordering was on the values, but the importance was the ordering of the keys after ordering the values.",
                "You can use a skip dict which is a dictionary that's permanently sorted by value.If you use keys(), values() or items() then you'll iterate in sorted order by value.It's implemented using the skip list datastructure.",
                "You can also use a custom function that can be passed to parameter key.",
                "Of course, remember, you need to use OrderedDict because regular Python dictionaries don't keep the original order.If you do not have Python 2.7 or higher, the best you can do is iterate over the values in a generator function. (There is an OrderedDict for 2.4 and 2.6  here, buta) I don't know about how well it worksandb) You have to download and install it of course. If you do not have administrative access, then I'm afraid the option's out.)You can also print out every valuePlease remember to remove the parentheses after print if not using Python 3.0 or above",
                "Here is a solution using zip on d.values() and d.keys().  A few lines down this link (on Dictionary view objects) is:This allows the creation of (value, key) pairs using zip(): pairs = zip(d.values(), d.keys()).So we can do the following:",
                "As pointed out by Dilettant, Python 3.6 will now keep the order! I thought I'd share a function I wrote that eases the sorting of an iterable (tuple, list, dict). In the latter case, you can sort either on keys or values, and it can take numeric comparison into account. Only for >= 3.6!When you try using sorted on an iterable that holds e.g. strings as well as ints, sorted() will fail. Of course you can force string comparison with str(). However, in some cases you want to do actual numeric comparison where 12 is smaller than 20 (which is not the case in string comparison). So I came up with the following. When you want explicit numeric comparison you can use the flag num_as_num which will try to do explicit numeric sorting by trying to convert all values to floats. If that succeeds, it will do numeric sorting, otherwise it'll resort to string comparison.Comments for improvement welcome.",
                "I just learned a relevant skill from Python for Everybody.You may use a temporary list to help you to sort the dictionary:If you want to sort the list in descending order, simply change the original sorting line to:Using list comprehension, the one-liner would be:Sample Output:",
                "Use ValueSortedDict from dicts:",
                "Iterate through a dict and sort it by its values in descending order:",
                "If your values are integers, and you use Python 2.7 or newer, you can use collections.Counter instead of dict. The most_common method will give you all items, sorted by the value.",
                "This works in 3.1.x:",
                "For the sake of completeness, I am posting a solution using heapq. Note, this method will work for both numeric and non-numeric values"
            ]
        },
        {
            "tag": "python",
            "question": [
                "How can I add new keys to a dictionary?",
                "How do I add a key to an existing dictionary? It doesn't have an .add() method."
            ],
            "url": "https://stackoverflow.com/questions/1024847",
            "answer": [
                "You create a new key/value pair on a dictionary by assigning a value to that keyIf the key doesn't exist, it's added and points to that value. If it exists, the current value it points to is overwritten.",
                "I feel like consolidating info about Python dictionaries:The update operator |= now works for dictionaries:This uses a new feature called dictionary unpacking.The merge operator | now works for dictionaries:",
                "To add multiple keys simultaneously, use dict.update():For adding a single key, the accepted answer has less computational overhead.",
                "Yes it is possible, and it does have a method that implements this, but you don't want to use it directly.To demonstrate how and how not to use it, let's create an empty dict with the dict literal, {}:To update this dict with a single new key and value, you can use the subscript notation (see Mappings here) that provides for item assignment:my_dict is now:We can also update the dict with multiple values efficiently as well using the update method.  We may be unnecessarily creating an extra dict here, so we hope our dict has already been created and came from or was used for another purpose:my_dict is now:Another efficient way of doing this with the update method is with keyword arguments, but since they have to be legitimate python words, you can't have spaces or special symbols or start the name with a number, but many consider this a more readable way to create keys for a dict, and here we certainly avoid creating an extra unnecessary dict:and my_dict is now:So now we have covered three Pythonic ways of updating a dict.There's another way of updating a dict that you shouldn't use, which uses the __setitem__ method. Here's an example of how one might use the __setitem__ method to add a key-value pair to a dict, and a demonstration of the poor performance of using it:So we see that using the subscript notation is actually much faster than using __setitem__. Doing the Pythonic thing, that is, using the language in the way it was intended to be used, usually is both more readable and computationally efficient.",
                "If you want to add a dictionary within a dictionary you can do it this way.Example: Add a new entry to your dictionary & sub dictionaryOutput:NOTE: Python requires that you first add a subbefore adding entries.",
                "The conventional syntax is d[key] = value, but if your keyboard is missing the square bracket keys you could also do:In fact, defining __getitem__ and __setitem__ methods is how you can make your own class support the  square bracket syntax. See Dive Into Python, Classes That Act Like Dictionaries.",
                "You can create one:Gives:",
                "This popular question addresses functional methods of merging dictionaries a and b.Here are some of the more straightforward methods (tested in Python 3)...Note: The first method above only works if the keys in b are strings.To add or modify a single element, the b dictionary would contain only that one element...This is equivalent to...",
                "Let's pretend you want to live in the immutable world and do not want to modify the original but want to create a new dict that is the result of adding a new key to the original.In Python 3.5+ you can do:The Python 2 equivalent is:After either of these:params is still equal to {'a': 1, 'b': 2}andnew_params is equal to {'a': 1, 'b': 2, 'c': 3}There will be times when you don't want to modify the original (you only want the result of adding to the original). I find this a refreshing alternative to the following:orReference: What does `**` mean in the expression `dict(d1, **d2)`?",
                "There is also the strangely named, oddly behaved, and yet still handy dict.setdefault().Thisbasically just does this:E.g.,",
                "This question has already been answered ad nauseam, but since my\ncomment\ngained a lot of traction, here it is as an answer:If you are here trying to figure out how to add a key and return a new dictionary (without modifying the existing one), you can do this using the techniques belowNote that with this approach, your key will need to follow the rules of valid identifier names in Python.",
                "If you're not joining two dictionaries, but adding new key-value pairs to a dictionary, then using the subscript notation seems like the best way.However, if you'd like to add, for example, thousands of new key-value pairs, you should consider using the update() method.",
                "Here's another way that I didn't see here:You can use the dictionary constructor and implicit expansion to reconstruct a dictionary. Moreover, interestingly, this method can be used to control the positional order during dictionary construction (post Python 3.6). In fact, insertion order is guaranteed for Python 3.7 and above!The above is using dictionary comprehension.",
                "First to check whether the key already exists:Then you can add the new key and value.",
                "Add a dictionary (key,value) class.",
                "I think it would also be useful to point out Python's collections module that consists of many useful dictionary subclasses and wrappers that simplify the addition and modification of data types in a dictionary, specifically defaultdict:dict subclass that calls a factory function to supply missing valuesThis is particularly useful if you are working with dictionaries that always consist of the same data types or structures, for example a dictionary of lists.If the key does not yet exist, defaultdict assigns the value given (in our case 10) as the initial value to the dictionary (often used inside loops). This operation therefore does two things: it adds a new key to a dictionary (as per question), and assigns the value if the key doesn't yet exist. With the standard dictionary, this would have raised an error as the += operation is trying to access a value that doesn't yet exist:Without the use of defaultdict, the amount of code to add a new element would be much greater and perhaps looks something like:defaultdict can also be used with complex data types such as list and set:Adding an element automatically initialises the list.",
                "dico[\"new key\"] = \"value\""
            ]
        },
        {
            "tag": "python",
            "question": [
                "\"Least Astonishment\" and the Mutable Default Argument",
                "Anyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:\ndef foo(a=[]):\n    a.append(5)\n    return a\n\nPython novices would expect this function called with ..."
            ],
            "url": "https://stackoverflow.com/questions/1132941",
            "answer": [
                "Actually, this is not a design flaw, and it is not because of internals or performance. It comes simply from the fact that functions in Python are first-class objects, and not only a piece of code.As soon as you think of it this way, then it completely makes sense: a function is an object being evaluated on its definition; default parameters are kind of \"member data\" and therefore their state may change from one call to the other - exactly as in any other object.In any case, the effbot (Fredrik Lundh) has a very nice explanation of the reasons for this behavior in Default Parameter Values in Python.\nI found it very clear, and I really suggest reading it for a better knowledge of how function objects work.",
                "Suppose you have the following codeWhen I see the declaration of eat, the least astonishing thing is to think that if the first parameter is not given, that it will be equal to the tuple (\"apples\", \"bananas\", \"loganberries\")However, suppose later on in the code, I do something likethen if default parameters were bound at function execution rather than function declaration, I would be astonished (in a very bad way) to discover that fruits had been changed. This would be more astonishing IMO than discovering that your foo function above was mutating the list.The real problem lies with mutable variables, and all languages have this problem to some extent. Here's a question: suppose in Java I have the following code:Now, does my map use the value of the StringBuffer key when it was placed into the map, or does it store the key by reference? Either way, someone is astonished; either the person who tried to get the object out of the Map using a value identical to the one they put it in with, or the person who can't seem to retrieve their object even though the key they're using is literally the same object that was used to put it into the map (this is actually why Python doesn't allow its mutable built-in data types to be used as dictionary keys).Your example is a good one of a case where Python newcomers will be surprised and bitten. But I'd argue that if we \"fixed\" this, then that would only create a different situation where they'd be bitten instead, and that one would be even less intuitive. Moreover, this is always the case when dealing with mutable variables; you always run into cases where someone could intuitively expect one or the opposite behavior depending on what code they're writing.I personally like Python's current approach: default function arguments are evaluated when the function is defined and that object is always the default. I suppose they could special-case using an empty list, but that kind of special casing would cause even more astonishment, not to mention be backwards incompatible.",
                "The relevant part of the documentation:Default parameter values are evaluated from left to right when the function definition is executed. This means that the expression is evaluated once, when the function is defined, and that the same \u201cpre-computed\u201d value is used for each call. This is especially important to understand when a default parameter is a mutable object, such as a list or a dictionary: if the function modifies the object (e.g. by appending an item to a list), the default value is in effect modified. This is generally not what was intended. A way around this is to use None as the default, and explicitly test for it in the body of the function, e.g.:",
                "I know nothing about the Python interpreter inner workings (and I'm not an expert in compilers and interpreters either) so don't blame me if I propose anything unsensible or impossible.Provided that python objects are mutable I think that this should be taken into account when designing the default arguments stuff.\nWhen you instantiate a list:you expect to get a new list referenced by a.Why should the a=[] ininstantiate a new list on function definition and not on invocation?\nIt's just like you're asking \"if the user doesn't provide the argument then instantiate a new list and use it as if it was produced by the caller\".\nI think this is ambiguous instead:user, do you want a to default to the datetime corresponding to when you're defining or executing x?\nIn this case, as in the previous one, I'll keep the same behaviour as if the default argument \"assignment\" was the first instruction of the function (datetime.now() called on function invocation).\nOn the other hand, if the user wanted the definition-time mapping he could write:I know, I know: that's a closure. Alternatively Python might provide a keyword to force definition-time binding:",
                "Well, the reason is quite simply that bindings are done when code is executed, and the function definition is executed, well... when the functions is defined.Compare this:This code suffers from the exact same unexpected happenstance. bananas is a class attribute, and hence, when you add things to it, it's added to all instances of that class. The reason is exactly the same.It's just \"How It Works\", and making it work differently in the function case would probably be complicated, and in the class case likely impossible, or at least slow down object instantiation a lot, as you would have to keep the class code around and execute it when objects are created.Yes, it is unexpected. But once the penny drops, it fits in perfectly with how Python works in general. In fact, it's a good teaching aid, and once you understand why this happens, you'll grok python much better.That said it should feature prominently in any good Python tutorial. Because as you mention, everyone runs into this problem sooner or later.",
                "I'm really surprised no one has performed the insightful introspection offered by Python (2 and 3 apply) on callables.Given a simple little function func defined as:When Python encounters it, the first thing it will do is compile it in order to create a code object for this function. While this compilation step is done, Python evaluates* and then stores the default arguments (an empty list [] here) in the function object itself. As the top answer mentioned: the list a can now be considered a member of the function func.So, let's do some introspection, a before and after to examine how the list gets expanded inside the function object. I'm using Python 3.x for this, for Python 2 the same applies (use __defaults__ or func_defaults in Python 2; yes, two names for the same thing).After Python executes this definition it will take any default parameters specified (a = [] here) and cram them in the __defaults__ attribute for the function object (relevant section: Callables):O.k, so an empty list as the single entry in __defaults__, just as expected.Let's now execute this function:Now, let's see those __defaults__ again:Astonished? The value inside the object changes! Consecutive calls to the function will now simply append to that embedded list object:So, there you have it, the reason why this 'flaw' happens, is because default arguments are part of the function object. There's nothing weird going on here, it's all just a bit surprising.The common solution to combat this is to use None as the default and then initialize in the function body:Since the function body is executed anew each time, you always get a fresh new empty list if no argument was passed for a.To further verify that the list in __defaults__ is the same as that used in the function func you can just change your function to return the id of the list a used inside the function body. Then, compare it to the list in __defaults__ (position [0] in __defaults__) and you'll see how these are indeed refering to the same list instance:All with the power of introspection!* To verify that Python evaluates the default arguments during compilation of the function, try executing the following:as you'll notice, input() is called before the process of building the function and binding it to the name bar is made.",
                "I used to think that creating the objects at runtime would be the better approach.  I'm less certain now, since you do lose some useful features, though it may be worth it regardless simply to prevent newbie confusion.  The disadvantages of doing so are:1. PerformanceIf call-time evaluation is used, then the expensive function is called every time your function is used without an argument.  You'd either pay an expensive price on each call, or need to manually cache the value externally, polluting your namespace and adding verbosity.2. Forcing bound parametersA useful trick is to bind parameters of a lambda to the current binding of a variable when the lambda is created.  For example:This returns a list of functions that return 0,1,2,3... respectively.  If the behaviour is changed, they will instead bind i to the call-time value of i, so you would get a list of functions that all returned 9.The only way to implement this otherwise would be to create a further closure with the i bound, ie:3. IntrospectionConsider the code:We can get information about the arguments and defaults using the inspect module, whichThis information is very useful for things like document generation, metaprogramming, decorators etc.Now, suppose the behaviour of defaults could be changed so that this is the equivalent of:However, we've lost the ability to introspect, and see what the default arguments are.  Because the objects haven't been constructed, we can't ever get hold of them without actually calling the function.  The best we could do is to store off the source code and return that as a string.",
                "Simplicity: The behavior is simple in the following sense:\nMost people fall into this trap only once, not several times.Consistency: Python always passes objects, not names.\nThe default parameter is, obviously, part of the function\nheading (not the function body). It therefore ought to be evaluated\nat module load time (and only at module load time, unless nested), not\nat function call time.Usefulness: As Frederik Lundh points out in his explanation\nof \"Default Parameter Values in Python\", the\ncurrent behavior can be quite useful for advanced programming.\n(Use sparingly.)Sufficient documentation: In the most basic Python documentation,\nthe tutorial, the issue is loudly announced as\nan \"Important warning\" in the first subsection of Section\n\"More on Defining Functions\".\nThe warning even uses boldface,\nwhich is rarely applied outside of headings.\nRTFM: Read the fine manual.Meta-learning: Falling into the trap is actually a very\nhelpful moment (at least if you are a reflective learner),\nbecause you will subsequently better understand the point\n\"Consistency\" above and that will\nteach you a great deal about Python.",
                "This behavior is easy explained by:So:",
                "1)  The so-called problem of \"Mutable Default Argument\" is in general a special example demonstrating that:\n\"All functions with this problem suffer also from similar side effect problem on the actual parameter,\"\nThat is against the rules of functional programming, usually undesiderable and should be fixed both together.Example:Solution:  a copy\nAn absolutely safe solution is to copy or deepcopy the input object first and then to do whatever with the copy.Many builtin mutable types have a copy method like some_dict.copy() or some_set.copy() or can be copied easy like somelist[:] or list(some_list). Every object can be also copied by copy.copy(any_object) or more thorough by copy.deepcopy() (the latter useful if the mutable object is composed from mutable objects). Some objects are fundamentally based on side effects like \"file\" object and can not be meaningfully reproduced by copy. copyingExample problem for a similar SO questionIt shouldn't be neither saved in any public attribute of an instance returned by this function. (Assuming that private attributes of instance should not be modified from outside of this class or subclasses by convention. i.e. _var1 is a private attribute )Conclusion:\nInput parameters objects shouldn't be modified in place (mutated) nor they should not be binded into an object returned by the function. (If we prefere programming without side effects which is strongly recommended. see Wiki about \"side effect\" (The first two paragraphs are relevent in this context.)\n.)2)\nOnly if the side effect on the actual parameter is required but unwanted on the default parameter then the useful solution is def ...(var1=None): if var1 is None: var1 = [] More..3) In some cases is the mutable behavior of default parameters useful.",
                "What you're asking is why this:isn't internally equivalent to this:except for the case of explicitly calling func(None, None), which we'll ignore.In other words, instead of evaluating default parameters, why not store each of them, and evaluate them when the function is called?One answer is probably right there--it would effectively turn every function with default parameters into a closure.  Even if it's all hidden away in the interpreter and not a full-blown closure, the data's got to be stored somewhere.  It'd be slower and use more memory.",
                "This actually has nothing to do with default values, other than that it often comes up as an unexpected behaviour when you write functions with mutable default values.No default values in sight in this code, but you get exactly the same problem.The problem is that foo is modifying a mutable variable passed in from the caller, when the caller doesn't expect this. Code like this would be fine if the function was called something like append_5; then the caller would be calling the function in order to modify the value they pass in, and the behaviour would be expected. But such a function would be very unlikely to take a default argument, and probably wouldn't return the list (since the caller already has a reference to that list; the one it just passed in).Your original foo, with a default argument, shouldn't be modifying a whether it was explicitly passed in or got the default value. Your code should leave mutable arguments alone unless it is clear from the context/name/documentation that the arguments are supposed to be modified. Using mutable values passed in as arguments as local temporaries is an extremely bad idea, whether we're in Python or not and whether there are default arguments involved or not.If you need to destructively manipulate a local temporary in the course of computing something, and you need to start your manipulation from an argument value, you need to make a copy.",
                "Default arguments get evaluated at the time the function is compiled into a function object. When used by the function, multiple times by that function, they are and remain the same object.When they are mutable, when mutated (for example, by adding an element to it) they remain mutated on consecutive calls.They stay mutated because they are the same object each time.Since the list is bound to the function when the function object is compiled and instantiated, this:is almost exactly equivalent to this:Here's a demonstration - you can verify that they are the same object each time they are referenced byexample.pyand running it with python example.py:This order of execution is frequently confusing to new users of Python. If you understand the Python execution model, then it becomes quite expected.But this is why the usual instruction to new users is to create their default arguments like this instead:This uses the None singleton as a sentinel object to tell the function whether or not we've gotten an argument other than the default. If we get no argument, then we actually want to use a new empty list, [], as the default.As the tutorial section on control flow says:If you don\u2019t want the default to be shared between subsequent calls,\n  you can write the function like this instead:",
                "The shortest answer would probably be \"definition is execution\", therefore the whole argument makes no strict sense. As a more contrived example, you may cite this:Hopefully it's enough to show that not executing the default argument expressions at the execution time of the def statement isn't easy or doesn't make sense, or both.I agree it's a gotcha when you try to use default constructors, though.",
                "Already busy topic, but from what I read here, the following helped me realizing how it's working internally:",
                "It's a performance optimization.  As a result of this functionality, which of these two function calls do you think is faster?I'll give you a hint.  Here's the disassembly (see http://docs.python.org/library/dis.html):I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs ?)As you can see, there is a performance benefit when using immutable default arguments.  This can make a difference if it's a frequently called function or the default argument takes a long time to construct.  Also, bear in mind that Python isn't C.  In C you have constants that are pretty much free.  In Python you don't have this benefit.",
                "This behavior is not surprising if you take the following into consideration:The role of (2) has been covered extensively in this thread. (1) is likely the astonishment causing factor, as this behavior is not \"intuitive\" when coming from other languages.(1) is described in the Python tutorial on classes. In an attempt to assign a value to a read-only class attribute:...all variables found outside of the innermost scope are\nread-only (an attempt to write to such a variable will simply create a\nnew local variable in the innermost scope, leaving the identically\nnamed outer variable unchanged).Look back to the original example and consider the above points:Here foo is an object and a is an attribute of foo (available at foo.func_defs[0]). Since a is a list, a is mutable and is thus a read-write attribute of foo. It is initialized to the empty list as specified by the signature when the function is instantiated, and is available for reading and writing as long as the function object exists.Calling foo without overriding a default uses that default's value from foo.func_defs. In this case, foo.func_defs[0] is used for a within function object's code scope. Changes to a change foo.func_defs[0], which is part of the foo object and persists between execution of the code in foo.Now, compare this to the example from the documentation on emulating the default argument behavior of other languages, such that the function signature defaults are used every time the function is executed:Taking (1) and (2) into account, one can see why this accomplishes the desired behavior:",
                "A simple workaround using None",
                "It may be true that:it is entirely consistent to hold to both of the features above and still make another point:The other answers, or at least some of them either make points 1 and 2 but not 3, or make point 3 and downplay points 1 and 2. But all three are true.It may be true that switching horses in midstream here would be asking for significant breakage, and that there could be more problems created by changing Python to intuitively handle Stefano's opening snippet. And it may be true that someone who knew Python internals well could explain a minefield of consequences. However,The existing behavior is not Pythonic, and Python is successful because very little about the language violates the principle of least astonishment anywhere near this badly. It is a real problem, whether or not it would be wise to uproot it. It is a design flaw. If you understand the language much better by trying to trace out the behavior, I can say that C++ does all of this and more; you learn a lot by navigating, for instance, subtle pointer errors. But this is not Pythonic: people who care about Python enough to persevere in the face of this behavior are people who are drawn to the language because Python has far fewer surprises than other language. Dabblers and the curious become Pythonistas when they are astonished at how little time it takes to get something working--not because of a design fl--I mean, hidden logic puzzle--that cuts against the intuitions of programmers who are drawn to Python because it Just Works.",
                "I am going to demonstrate an alternative structure to pass a default list value to a function (it works equally well with dictionaries).As others have extensively commented, the list parameter is bound to the function when it is defined as opposed to when it is executed.  Because lists and dictionaries are mutable, any alteration to this parameter will affect other calls to this function.  As a result, subsequent calls to the function will receive this shared list which may have been altered by any other calls to the function.  Worse yet, two parameters are using this function's shared parameter at the same time oblivious to the changes made by the other.Wrong Method (probably...):You can verify that they are one and the same object by using id:Per Brett Slatkin's \"Effective Python: 59 Specific Ways to Write Better Python\", Item 20: Use None and Docstrings to specify dynamic default arguments (p. 48)The convention for achieving the desired result in Python is to\n  provide a default value of None and to document the actual behaviour\n  in the docstring.This implementation ensures that each call to the function either receives the default list or else the list passed to the function.Preferred Method:There may be legitimate use cases for the 'Wrong Method' whereby the programmer intended the default list parameter to be shared, but this is more likely the exception than the rule.",
                "The solutions here are:The second option is nice because users of the function can pass in a callable, which may be already existing (such as a type)",
                "You can get round this by replacing the object (and therefore the tie with the scope):Ugly, but it works.",
                "When we do this:... we assign the argument a to an unnamed list, if the caller does not pass the value of a.To make things simpler for this discussion, let's temporarily give the unnamed list a name. How about pavlo ?At any time, if the caller doesn't tell us what a is, we reuse pavlo.If pavlo is mutable (modifiable), and foo ends up modifying it, an effect we notice the next time foo is called without specifying a.So this is what you see (Remember, pavlo is initialized to []):Now, pavlo is [5].Calling foo() again modifies pavlo again:Specifying a when calling foo() ensures pavlo is not touched.So, pavlo is still [5, 5].",
                "I sometimes exploit this behavior as an alternative to the following pattern:If singleton is only used by use_singleton, I like the following pattern as a replacement:I've used this for instantiating client classes that access external resources, and also for creating dicts or lists for memoization.Since I don't think this pattern is well known, I do put a short comment in to guard against future misunderstandings.",
                "Every other answer explains why this is actually a nice and desired behavior, or why you shouldn't be needing this anyway. Mine is for those stubborn ones who want to exercise their right to bend the language to their will, not the other way around.We will \"fix\" this behavior with a decorator that will copy the default value instead of reusing the same instance for each positional argument left at its default value.Now let's redefine our function using this decorator:This is particularly neat for functions that take multiple arguments. Compare:withIt's important to note that the above solution breaks if you try to use keyword args, like so:The decorator could be adjusted to allow for that, but we leave this as an exercise for the reader ;)",
                "This \"bug\" gave me a lot of overtime work hours! But I'm beginning to see a potential use of it (but I would have liked it to be at the execution time, still)I'm gonna give you what I see as a useful example.prints the following",
                "This is not a design flaw. Anyone who trips over this is doing something wrong.There are 3 cases I see where you might run into this problem:The example in the question could fall into category 1 or 3. It's odd that it both modifies the passed list and returns it; you should pick one or the other.",
                "Just change the function to be:",
                "TLDR: Define-time defaults are consistent and strictly more expressive.Defining a function affects two scopes: the defining scope containing the function, and the execution  scope contained by the function. While it is pretty clear how blocks map to scopes, the question is where def <name>(<args=defaults>): belongs to:The def name part must evaluate in the defining scope - we want name to be available there, after all. Evaluating the function only inside itself would make it inaccessible.Since parameter is a constant name, we can \"evaluate\" it at the same time as def name. This also has the advantage it produces the function with a known signature as name(parameter=...):, instead of a bare name(...):.Now, when to evaluate default?Consistency already says \"at definition\": everything else of def <name>(<args=defaults>): is best evaluated at definition as well. Delaying parts of it would be the astonishing choice.The two choices are not equivalent, either: If default is evaluated at definition time, it can still affect execution time. If default is evaluated at execution time, it cannot affect definition time. Choosing \"at definition\" allows expressing both cases, while choosing \"at execution\" can express only one:",
                "I think the answer to this question lies in how python pass data to parameter (pass by value or by reference), not mutability or how python handle the \"def\" statement.A brief introduction. First, there are two type of data types in python, one is simple elementary data type, like numbers, and another data type is objects. Second, when passing data to parameters, python pass elementary data type by value, i.e., make a local copy of the value to a local variable, but pass object by reference, i.e., pointers to the object.Admitting the above two points, let's explain what happened to the python code. It's only because of passing by reference for objects, but has nothing to do with mutable/immutable, or arguably the fact that \"def\" statement is executed only once when it is defined.[] is an object, so python pass the reference of [] to a, i.e., a is only a pointer to [] which lies in memory as an object. There is only one copy of [] with, however, many references to it. For the first foo(), the list [] is changed to 1 by append method. But Note that there is only one copy of the list object and this object now becomes 1. When running the second foo(), what effbot webpage says (items is not evaluated any more) is wrong. a is evaluated to be the list object, although now the content of the object is 1. This is the effect of passing by reference! The result of foo(3) can be easily derived in the same way.To further validate my answer, let's take a look at two additional codes.====== No. 2 ========[] is an object, so is None (the former is mutable while the latter is immutable. But the mutability has nothing to do with the question). None is somewhere in the space but we know it's there and there is only one copy of None there. So every time foo is invoked, items is evaluated (as opposed to some answer that it is only evaluated once) to be None, to be clear, the reference (or the address) of None. Then in the foo, item is changed to [], i.e., points to another object which has a different address.====== No. 3 =======The invocation of foo(1) make items point to a list object [] with an address, say, 11111111. the content of the list is changed to 1 in the foo function in the sequel, but the address is not changed, still 11111111. Then foo(2,[]) is coming. Although the [] in foo(2,[]) has the same content as the default parameter [] when calling foo(1), their address are different! Since we provide the parameter explicitly, items has to take the address of this new [], say 2222222, and return it after making some change. Now foo(3) is executed. since only x is provided, items has to take its default value again. What's the default value? It is set when defining the foo function: the list object located in 11111111. So the items is evaluated to be the address 11111111 having an element 1. The list located at 2222222 also contains one element 2, but it is not pointed by items any more. Consequently, An append of 3 will make items [1,3].From the above explanations, we can see that the effbot webpage recommended in the accepted answer failed to give a relevant answer to this question. What is more, I think a point in the effbot webpage is wrong. I think the code regarding the UI.Button is correct:Each button can hold a distinct callback function which will display different value of i. I can provide an example to show this:If we execute x[7]() we'll get 7 as expected, and x[9]() will gives 9, another value of i."
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I concatenate two lists in Python?",
                "How do I concatenate two lists in Python?\n\nExample:\n\nlistone = [1, 2, 3]\nlisttwo = [4, 5, 6]\r\nExpected outcome:\n\n>>> joinedlist\n[1, 2, 3, 4, 5, 6]"
            ],
            "url": "https://stackoverflow.com/questions/1720421",
            "answer": [
                "Use the + operator to combine the lists:Output:",
                "Python >= 3.5 alternative: [*l1, *l2]Another alternative has been introduced via the acceptance of PEP 448 which deserves mentioning.The PEP, titled Additional Unpacking Generalizations, generally reduced some syntactic restrictions when using the starred * expression in Python; with it, joining two lists (applies to any iterable) can now also be done with:This functionality was defined for Python 3.5, but it hasn't been backported to previous versions in the 3.x family. In unsupported versions a SyntaxError is going to be raised.As with the other approaches, this too creates as shallow copy of the elements in the corresponding lists.The upside to this approach is that you really don't need lists in order to perform it; anything that is iterable will do. As stated in the PEP:This is also useful as a more readable way of summing iterables into a\nlist, such as my_list + list(my_tuple) + list(my_range) which is now\nequivalent to just [*my_list, *my_tuple, *my_range].So while addition with + would raise a TypeError due to type mismatch:The following won't:because it will first unpack the contents of the iterables and then simply create a list from the contents.",
                "It's also possible to create a generator that simply iterates over the items in both lists using itertools.chain(). This allows you to chain lists (or any iterable) together for processing without copying the items to a new list:",
                "You could also use the list.extend() method in order to add a list to the end of another one:If you want to keep the original list intact, you can create a new list object, and extend both lists to it:",
                "As of 3.9, these are the most popular stdlib methods for concatenating two (or more) lists in Python.FootnotesThis is a slick solution because of its succinctness. But sum performs concatenation in a pairwise fashion, which means this is a\nquadratic operation as memory has to be allocated for each step. DO\nNOT USE if your lists are large.See chain\nand\nchain.from_iterable\nfrom the docs. You will need to from itertools import chain first.\nConcatenation is linear in memory, so this is the best in terms of\nperformance and version compatibility. chain.from_iterable was introduced in 2.6.This method uses Additional Unpacking Generalizations (PEP 448), but cannot\ngeneralize to N lists unless you manually unpack each one yourself.a += b and a.extend(b) are more or less equivalent for all practical purposes. += when called on a list will internally call\nlist.__iadd__, which extends the first list by the second.2-List Concatenation1There's not much difference between these methods but that makes sense given they all have the same order of complexity (linear). There's no particular reason to prefer one over the other except as a matter of style.N-List ConcatenationPlots have been generated using the perfplot module. Code, for your reference.1. The iadd (+=) and extend methods operate in-place, so a copy has to be generated each time before testing. To keep things fair, all methods have a pre-copy step for the left-hand list which can be ignored.DO NOT USE THE DUNDER METHOD list.__add__ directly in any way, shape or form. In fact, stay clear of dunder methods, and use the operators and operator functions like they were designed for. Python has careful semantics baked into these which are more complicated than just calling the dunder directly. Here is an example. So, to summarise, a.__add__(b) => BAD; a + b => GOOD.Some answers here offer reduce(operator.add, [a, b]) for pairwise concatenation -- this is the same as sum([a, b], []) only more wordy.Any method that uses set will drop duplicates and lose ordering. Use with caution.for i in b: a.append(i) is more wordy, and slower than a.extend(b), which is single function call and more idiomatic. append is slower because of the semantics with which memory is allocated and grown for lists. See here for a similar discussion.heapq.merge will work, but its use case is for merging sorted lists in linear time. Using it in any other situation is an anti-pattern.yielding list elements from a function is an acceptable method, but chain does this faster and better (it has a code path in C, so it is fast).operator.add(a, b) is an acceptable functional equivalent to a + b. It's use cases are mainly for dynamic method dispatch. Otherwise, prefer a + b which is shorter and more readable, in my opinion. YMMV.",
                "You can use sets to obtain merged list of unique values",
                "This is quite simple, and I think it was even shown in the tutorial:",
                "This question directly asks about joining two lists. However it's pretty high in search even when you are looking for a way of joining many lists (including the case when you joining zero lists).I think the best option is to use list comprehensions:You can create generators as well:Old AnswerConsider this more generic approach:Will output:Note, this also works correctly when a is [] or [[1,2,3]].However, this can be done more efficiently with itertools:If you don't need a list, but just an iterable, omit list().UpdateAlternative suggested by Patrick Collins in the comments could also work for you:",
                "You could simply use the + or += operator as follows:Or:Also, if you want the values in the merged list to be unique you can do:",
                "It's worth noting that the itertools.chain function accepts variable number of arguments:If an iterable (tuple, list, generator, etc.) is the input, the from_iterable class method may be used:",
                "For cases with a low number of lists you can simply add the lists together or use in-place unpacking (available in Python-3.5+):As a more general way for cases with more number of lists you can use chain.from_iterable()1 function from itertools module. Also, based on this answer this function is the best; or at least a very good way for flatting a nested list as well.",
                "With Python 3.3+ you can use yield from:Or, if you want to support an arbitrary number of iterators:",
                "If you want to merge the two lists in sorted form, you can use the merge function from the heapq library.",
                "If you can't use the plus operator (+),  you can use the operator import:Alternatively, you could also use the __add__ dunder function:",
                "If you need to merge two ordered lists with complicated sorting rules, you might have to roll it yourself like in the following code (using a simple sorting rule for readability :-) ).",
                "If you are using NumPy, you can concatenate two arrays of compatible dimensions with this command:",
                "Use a simple list comprehension:It has all the advantages of the newest approach of using Additional Unpacking Generalizations - i.e. you can concatenate an arbitrary number of different iterables (for example, lists, tuples, ranges, and generators) that way - and it's not limited to Python 3.5 or later.",
                "Another way:",
                "The above code does not preserve order and removes duplicates from each list (but not from the concatenated list).",
                "As already pointed out by many, itertools.chain() is the way to go if one needs to apply exactly the same treatment to both lists. In my case, I had a label and a flag which were different from one list to the other, so I needed something slightly more complex. As it turns out, behind the scenes itertools.chain() simply does the following:(see https://docs.python.org/2/library/itertools.html), so I took inspiration from here and wrote something along these lines:The main points to understand here are that lists are just a special case of iterable, which are objects like any other; and that for ... in loops in python can work with tuple variables, so it is simple to loop on multiple variables at the same time.",
                "You could use the append() method defined on list objects:",
                "In the above code, the \"+\" operator is used to concatenate the two lists into a single list.",
                "I recommend three methods to concatenate the list, but the first method is most recommended,In the second method, I assign newlist to a copy of the listone, because I don't want to change listone.This is not a good way to concatenate lists because we are using a for loop to concatenate the lists. So time complexity is much higher than with the other two methods.",
                "The most common method used to concatenate lists are the plus operator and the built-in method append, for example:For most of the cases, this will work, but the append function will not extend a list if one was added. Because that is not expected, you can use another method called extend. It should work with structures:",
                "A really concise way to combine a list of lists iswhich gives us",
                "So there are two easy ways.Example:Example:Thus we see that out of two of most popular methods, extend is efficient.",
                "You could also just use sum.This works for any length and any element type of list:The reason I add [], is because the start argument is set to 0 by default, so it loops through the list and adds to start, but 0 + [1, 2, 3] would give an error, so if we set the start to []. It would add to [], and [] + [1, 2, 3] would work as expected.",
                "I assume you want one of the two methods:Keep duplicate elementsIt is very easy. Just concatenate like a string:Next, if you want to eliminate duplicate elements",
                "The solutions provided are for a single list. In case there are lists within a list and the merging of corresponding lists is required, the \"+\" operation through a for loop does the work.Output: [[1, 2, 3, 0, 1, 2], [4, 5, 6, 7, 8, 9]]",
                "All the possible ways to join lists that I could findOutput"
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I select rows from a DataFrame based on column values?",
                "How can I select rows from a DataFrame based on values in some column in Pandas?\nIn SQL, I would use:\nSELECT *\nFROM table\nWHERE column_name = some_value"
            ],
            "url": "https://stackoverflow.com/questions/17071871",
            "answer": [
                "To select rows whose column value equals a scalar, some_value, use ==:To select rows whose column value is in an iterable, some_values, use isin:Combine multiple conditions with &:Note the parentheses. Due to Python's operator precedence rules, & binds more tightly than <= and >=. Thus, the parentheses in the last example are necessary. Without the parenthesesis parsed aswhich results in a Truth value of a Series is ambiguous error.To select rows whose column value does not equal some_value, use !=:isin returns a boolean Series, so to select rows whose value is not in some_values, negate the boolean Series using ~:For example,yieldsIf you have multiple values you want to include, put them in a\nlist (or more generally, any iterable) and use isin:yieldsNote, however, that if you wish to do this many times, it is more efficient to\nmake an index first, and then use df.loc:yieldsor, to include multiple values from the index use df.index.isin:yields",
                "There are several ways to select rows from a Pandas dataframe:Below I show you examples of each, with advice when to use certain techniques. Assume our criterion is column 'A' == 'foo'(Note on performance: For each base type, we can keep things simple by using the Pandas API or we can venture outside the API, usually into NumPy, and speed things up.)SetupThe first thing we'll need is to identify a condition that will act as our criterion for selecting rows. We'll start with the OP's case column_name == some_value, and include some other common use cases.Borrowing from @unutbu:... Boolean indexing requires finding the true value of each row's 'A' column being equal to 'foo', then using those truth values to identify which rows to keep.  Typically, we'd name this series, an array of truth values, mask.  We'll do so here as well.We can then use this mask to slice or index the data frameThis is one of the simplest ways to accomplish this task and if performance or intuitiveness isn't an issue, this should be your chosen method.  However, if performance is a concern, then you might want to consider an alternative way of creating the mask.Positional indexing (df.iloc[...]) has its use cases, but this isn't one of them.  In order to identify where to slice, we first need to perform the same boolean analysis we did above.  This leaves us performing one extra step to accomplish the same task.Label indexing can be very handy, but in this case, we are again doing more work for no benefitpd.DataFrame.query is a very elegant/intuitive way to perform this task, but is often slower. However, if you pay attention to the timings below, for large data, the query is very efficient. More so than the standard approach and of similar magnitude as my best suggestion.My preference is to use the Boolean maskActual improvements can be made by modifying how we create our Boolean mask.mask alternative 1\nUse the underlying NumPy array and forgo the overhead of creating another pd.SeriesI'll show more complete time tests at the end, but just take a look at the performance gains we get using the sample data frame.  First, we look at the difference in creating the maskEvaluating the mask with the NumPy array is ~ 30 times faster.  This is partly due to NumPy evaluation often being faster. It is also partly due to the lack of overhead necessary to build an index and a corresponding pd.Series object.Next, we'll look at the timing for slicing with one mask versus the other.The performance gains aren't as pronounced.  We'll see if this holds up over more robust testing.mask alternative 2\nWe could have reconstructed the data frame as well.  There is a big caveat when reconstructing a dataframe\u2014you must take care of the dtypes when doing so!Instead of df[mask] we will do thisIf the data frame is of mixed type, which our example is, then when we get df.values the resulting array is of dtype object and consequently, all columns of the new data frame will be of dtype object.  Thus requiring the astype(df.dtypes) and killing any potential performance gains.However, if the data frame is not of mixed type, this is a very useful way to do it.GivenVersusWe cut the time in half.mask alternative 3@unutbu also shows us how to use pd.Series.isin to account for each element of df['A'] being in a set of values.  This evaluates to the same thing if our set of values is a set of one value, namely 'foo'.  But it also generalizes to include larger sets of values if needed.  Turns out, this is still pretty fast even though it is a more general solution.  The only real loss is in intuitiveness for those not familiar with the concept.However, as before, we can utilize NumPy to improve performance while sacrificing virtually nothing. We'll use np.in1dTimingI'll include other concepts mentioned in other posts as well for reference.Code BelowEach column in this table represents a different length data frame over which we test each function. Each column shows relative time taken, with the fastest function given a base index of 1.0.You'll notice that the fastest times seem to be shared between mask_with_values and mask_with_in1d.FunctionsTestingSpecial TimingLooking at the special case when we have a single non-object dtype for the entire data frame.Code BelowTurns out, reconstruction isn't worth it past a few hundred rows.FunctionsTesting",
                "The Pandas equivalent toisMultiple conditions:orIn the above code it is the line df[df.foo == 222] that gives the rows based on the column value, 222 in this case.Multiple conditions are also possible:But at that point I would recommend using the query function, since it's less verbose and yields the same result:",
                "I find the syntax of the previous answers to be redundant and difficult to remember. Pandas introduced the query() method in v0.13 and I much prefer it. For your question, you could do df.query('col == val').Reproduced from The query() Method (Experimental):You can also access variables in the environment by prepending an @.",
                "Since pandas >= 0.25.0 we can use the query method to filter dataframes with pandas methods and even column names which have spaces. Normally the spaces in column names would give an error, but now we can solve that using a backtick (`) - see GitHub:Using .query with method str.endswith:OutputAlso we can use local variables by prefixing it with an @ in our query:Output",
                "For selecting only specific columns out of multiple columns for a given value in Pandas:Options loc:or query:",
                "In newer versions of Pandas, inspired by the documentation (Viewing data):Combine multiple conditions by putting the clause in parentheses, (), and combining them with & and | (and/or). Like this:Other filters",
                "Faster results can be achieved using numpy.where.For example, with unubtu's setup -Timing comparisons:",
                "Here is a simple example",
                "To add: You can also do df.groupby('column_name').get_group('column_desired_value').reset_index() to make a new data frame with specified column having a particular value. E.g.,Running this gives:",
                "You can also use .apply:It actually works row-wise (i.e., applies the function to each row).The output isThe results is the same as using as mentioned by @unutbu",
                "If you want to make query to your dataframe repeatedly and speed is important to you, the best thing is to convert your dataframe to dictionary and then by doing this you can make query thousands of times faster.After make my_dict dictionary you can go through:If you have duplicated values in column_name you can't make a dictionary. but you can use:",
                "With DuckDB we can query pandas DataFrames with SQL statements, in a highly performant way.Since the question is How do I select rows from a DataFrame based on column values?, and the example in the question is a SQL query, this answer looks logical in this topic.Example:",
                "If the column name used to filter your dataframe comes from a local variable, f-strings may be useful. For example,In fact, f-strings can be used for the query variable as well (except for datetime):The pandas documentation recommends installing numexpr to speed up numeric calculation when using query(). Use pip install numexpr (or conda, sudo etc. depending on your environment) to install it.For larger dataframes (where performance actually matters), df.query() with numexpr engine performs much faster than df[mask]. In particular, it performs better for the following cases.Logical and/or comparison operators on columns of stringsIf a column of strings are compared to some other string(s) and matching rows are to be selected, even for a single comparison operation, query() performs faster than df[mask]. For example, for a dataframe with 80k rows, it's 30% faster1 and for a dataframe with 800k rows, it's 60% faster.2This gap increases as the number of operations increases (if 4 comparisons are chained df.query() is 2-2.3 times faster than df[mask])1,2 and/or the dataframe length increases.2Multiple operations on numeric columnsIf multiple arithmetic, logical or comparison operations need to be computed to create a boolean mask to filter df, query() performs faster. For example, for a frame with 80k rows, it's 20% faster1 and for a frame with 800k rows, it's 2 times faster.2This gap in performance increases as the number of operations increases and/or the dataframe length increases.2The following plot shows how the methods perform as the dataframe length increases.3Numexpr currently supports only logical (&, |, ~), comparison (==, >, <, >=, <=, !=) and basic arithmetic operators (+, -, *, /, **, %).For example, it doesn't support integer division (//). However, calling the equivalent pandas method (floordiv()) works.1 Benchmark code using a frame with 80k rows2 Benchmark code using a frame with 800k rows3: Code used to produce the performance graphs of the two methods for strings and numbers.",
                "You can use loc (square brackets) with a function:Output:orOutput:The advantage of this method is that you can chain selection with previous operations. For example:vsOutput:",
                "Great answers. Only, when the size of the dataframe approaches million rows, many of the methods tend to take ages when using df[df['col']==val]. I wanted to have all possible values of \"another_column\" that correspond to specific values in \"some_column\" (in this case in a dictionary). This worked and fast."
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I check if a list is empty?",
                "For example, if passed the following:\n\na = []\r\nHow do I check to see if a is empty?"
            ],
            "url": "https://stackoverflow.com/questions/53513",
            "answer": [
                "Using the implicit booleanness of the empty list is quite Pythonic.",
                "The Pythonic way to do it is from the PEP 8 style guide.For sequences, (strings, lists, tuples), use the fact that empty sequences are false:",
                "I prefer it explicitly:This way it's 100% clear that li is a sequence (list) and we want to test its size. My problem with if not li: ... is that it gives the false impression that li is a boolean variable.",
                "This is the first google hit for \"python test empty array\" and similar queries, and other people are generalizing the question beyond just lists, so here's a caveat for a different type of sequence that a lot of people use.You need to be careful with NumPy arrays, because other methods that work fine for lists or other standard containers fail for NumPy arrays.  I explain why below, but in short, the preferred method is to use size.The \"pythonic\" way fails with NumPy arrays because NumPy tries to cast the array to an array of bools, and if x tries to evaluate all of those bools at once for some kind of aggregate truth value.  But this doesn't make any sense, so you get a ValueError:But at least the case above tells you that it failed.  If you happen to have a NumPy array with exactly one element, the if statement will \"work\", in the sense that you don't get an error.  However, if that one element happens to be 0 (or 0.0, or False, ...), the if statement will incorrectly result in False:But clearly x exists and is not empty!  This result is not what you wanted.For example,returns 1, even though the array has zero elements.As explained in the SciPy FAQ, the correct method in all cases where you know you have a NumPy array is to use if x.size:If you're not sure whether it might be a list, a NumPy array, or something else, you could combine this approach with the answer @dubiousjim gives to make sure the right test is used for each type.  Not very \"pythonic\", but it turns out that NumPy intentionally broke pythonicity in at least this sense.If you need to do more than just check if the input is empty, and you're using other NumPy features like indexing or math operations, it's probably more efficient (and certainly more common) to force the input to be a NumPy array.  There are a few nice functions for doing this quickly \u2014\u00a0most importantly numpy.asarray.  This takes your input, does nothing if it's already an array, or wraps your input into an array if it's a list, tuple, etc., and optionally converts it to your chosen dtype.  So it's very quick whenever it can be, and it ensures that you just get to assume the input is a NumPy array.  We usually even just use the same name, as the conversion to an array won't make it back outside of the current scope:This will make the x.size check work in all cases I see on this page.",
                "For example, if passed the following:How do I check to see if a is empty?Place the list in a boolean context (for example, with an if or while statement). It will test False if it is empty, and True otherwise. For example:PEP 8, the official Python style guide for Python code in Python's standard library, asserts:For sequences, (strings, lists, tuples), use the fact that empty sequences are false.We should expect that standard library code should be as performant and correct as possible. But why is that the case, and why do we need this guidance?I frequently see code like this from experienced programmers new to Python:And users of lazy languages may be tempted to do this:These are correct in their respective other languages. And this is even semantically correct in Python.But we consider it un-Pythonic because Python supports these semantics directly in the list object's interface via boolean coercion.From the docs (and note specifically the inclusion of the empty list, []):By default, an object is considered true unless its class defines\n  either a __bool__() method that returns False or a __len__() method\n  that returns zero, when called with the object. Here are most of the built-in objects considered false:And the datamodel documentation:object.__bool__(self)Called to implement truth value testing and the built-in operation bool(); should return False or True. When this method is not defined,\n  __len__() is called, if it is defined, and the object is considered true if its result is nonzero. If a class defines neither __len__()\n  nor __bool__(), all its instances are considered true.andobject.__len__(self)Called to implement the built-in function len(). Should return the length of the object, an integer >= 0. Also, an object that doesn\u2019t define a __bool__() method and whose __len__() method returns zero is considered to be false in a Boolean context.So instead of this:or this:Do this:Does it pay off? (Note that less time to perform an equivalent operation is better:)For scale, here's the cost of calling the function and constructing and returning an empty list, which you might subtract from the costs of the emptiness checks used above:We see that either checking for length with the builtin function len compared to 0 or checking against an empty list is much less performant than using the builtin syntax of the language as documented.Why?For the len(a) == 0 check:First Python has to check the globals to see if len is shadowed.Then it must call the function, load 0, and do the equality comparison in Python (instead of with C):And for the [] == [] it has to build an unnecessary list and then, again, do the comparison operation in Python's virtual machine (as opposed to C)The \"Pythonic\" way is a much simpler and faster check since the length of the list is cached in the object instance header:PyVarObjectThis is an extension of PyObject that adds the ob_size field. This is only used for objects that have some notion of length. This type does not often appear in the Python/C API. It corresponds to the fields defined by the expansion of the PyObject_VAR_HEAD macro.From the c source in Include/listobject.h:I would point out that this is also true for the non-empty case though its pretty ugly as with l=[] then %timeit len(l) != 0 90.6 ns \u00b1 8.3 ns, %timeit l != [] 55.6 ns \u00b1 3.09, %timeit not not l 38.5 ns \u00b1 0.372. But there is no way anyone is going to enjoy not not l despite triple the speed. It looks ridiculous. But the speed wins out\n  I suppose the problem is testing with timeit since just if l: is sufficient but surprisingly %timeit bool(l) yields 101 ns \u00b1 2.64 ns. Interesting there is no way to coerce to bool without this penalty. %timeit l is useless since no conversion would occur.IPython magic, %timeit, is not entirely useless here:We can see there's a bit of linear cost for each additional not here. We want to see the costs, ceteris paribus, that is, all else equal - where all else is minimized as far as possible:Now let's look at the case for an unempty list:What we can see here is that it makes little difference whether you pass in an actual bool to the condition check or the list itself, and if anything, giving the list, as is, is faster.Python is written in C; it uses its logic at the C level. Anything you write in Python will be slower. And it will likely be orders of magnitude slower unless you're using the mechanisms built into Python directly.",
                "An empty list is itself considered false in true value testing (see python documentation):To Daren Thomas's answer:EDIT: Another point against testing\nthe empty list as False: What about\npolymorphism? You shouldn't depend on\na list being a list. It should just\nquack like a duck - how are you going\nto get your duckCollection to quack\n''False'' when it has no elements?Your duckCollection should implement __nonzero__ or __len__ so the if a: will work without problems.",
                "Patrick's (accepted) answer is right: if not a: is the right way to do it. Harley Holcombe's answer is right that this is in the PEP 8 style guide. But what none of the answers explain is why it's a good idea to follow the idiom\u2014even if you personally find it's not explicit enough or confusing to Ruby users or whatever.Python code, and the Python community, has very strong idioms. Following those idioms makes your code easier to read for anyone experienced in Python. And when you violate those idioms, that's a strong signal.It's true that if not a: doesn't distinguish empty lists from None, or numeric 0, or empty tuples, or empty user-created collection types, or empty user-created not-quite-collection types, or single-element NumPy array acting as scalars with falsey values, etc. And sometimes it's important to be explicit about that. And in that case, you know what you want to be explicit about, so you can test for exactly that. For example, if not a and a is not None: means \"anything falsey except None\", while if len(a) != 0: means \"only empty sequences\u2014and anything besides a sequence is an error here\", and so on. Besides testing for exactly what you want to test, this also signals to the reader that this test is important.But when you don't have anything to be explicit about, anything other than if not a: is misleading the reader. You're signaling something as important when it isn't. (You may also be making the code less flexible, or slower, or whatever, but that's all less important.) And if you habitually mislead the reader like this, then when you do need to make a distinction, it's going to pass unnoticed because you've been \"crying wolf\" all over your code.",
                "No one seems to have addressed questioning your need to test the list in the first place.  Because you provided no additional context, I can imagine that you may not need to do this check in the first place, but are unfamiliar with list processing in Python.I would argue that the most Pythonic way is to not check at all, but rather to just process the list.  That way it will do the right thing whether empty or full.This has the benefit of handling any contents of a, while not requiring a specific check for emptiness.  If a is empty, the dependent block will not execute and the interpreter will fall through to the next line.If you do actually need to check the array for emptiness:is sufficient.",
                "len() is an O(1) operation for Python lists, strings, dicts, and sets. Python internally keeps track of the number of elements in these containers.JavaScript has a similar notion of truthy/falsy.",
                "I had written:which was voted -1. I'm not sure if that's because readers objected to the strategy or thought the answer wasn't helpful as presented. I'll pretend it was the latter, since---whatever counts as \"pythonic\"---this is the correct strategy. Unless you've already ruled out, or are prepared to handle cases where a is, for example, False, you need a test more restrictive than just if not a:. You could use something like this:the first test is in response to @Mike's answer, above. The third line could also be replaced with:if you only want to accept instances of particular types (and their subtypes), or with:You can get away without the explicit type check, but only if the surrounding context already assures you that a is a value of the types you're prepared to handle, or if you're sure that types you're not prepared to handle are going to raise errors (e.g., a TypeError if you call len on a value for which it's undefined) that you're prepared to handle. In general, the \"pythonic\" conventions seem to go this last way. Squeeze it like a duck and let it raise a DuckError if it doesn't know how to quack. You still have to think about what type assumptions you're making, though, and whether the cases you're not prepared to handle properly really are going to error out in the right places. The Numpy arrays are a good example where just blindly relying on len or the boolean typecast may not do precisely what you're expecting.",
                "From documentation on truth value testing:All values other than what is listed here are considered TrueAs can be seen, empty list [] is falsy, so doing what would be done to a boolean value sounds most efficient:",
                "I prefer the following:",
                "Here are a few ways you can check if a list is empty:1) The pretty simple pythonic way:In Python, empty containers such as lists,tuples,sets,dicts,variables etc are seen as False. One could simply treat the list as a predicate (returning a Boolean value). And  a True value would indicate that it's non-empty.2) A much explicit way: using the len() to find the length and check if it equals to 0:3) Or comparing it to an anonymous empty list:4) Another yet silly way to do is using exception and iter():",
                "Method 1 (preferred):Method 2:Method 3:",
                "You can even try using bool() like this. Although it is less readable surely it's a concise way to perform this.I love this way for the checking list is empty or not.Very handy and useful.",
                "It is sometimes good to test for None and for emptiness separately as those are two different states. The code above produces the following output:Although it's worth nothing that None is falsy. So if you don't want to separate test for None-ness, you don't have to do that.produces expected",
                "To check whether a list is empty or not you can use two following ways. But remember, we should avoid the way of explicitly checking for a type of sequence (it's a less Pythonic way):The second way is a more Pythonic one. This method is an implicit way of checking and much more preferable than the previous one.",
                "Many answers have been given, and a lot of them are pretty good. I just wanted to add that the checkwill also pass for None and other types of empty structures. If you truly want to check for an empty list, you can do this:",
                "If you want to check if a list is empty:If you want to check whether all the values in list is empty. However it will be True for an empty list:If you want to use both cases together:Now you can use:",
                "a little more practical:and the shortest version:",
                "We could use a simple if else:",
                "Being inspired by dubiousjim's solution, I propose to use an additional general check of whether is it something iterable:Note: a string is considered to be iterable\u2014add and not isinstance(a,(str,unicode)) if you want the empty string to be excludedTest:",
                "Simply use is_empty() or make function like:-It can be used for any data_structure like a list,tuples, dictionary and many more. By these, you can call it many times using just is_empty(any_structure).",
                "Simple way is checking the length is equal zero.",
                "From python3 onwards you can useto check if the list is emptyEDIT : This works with python2.7 too..I am not sure why there are so many complicated answers.\nIt's pretty clear and straightforward",
                "The truth value of an empty list is False whereas for a non-empty list it is True.",
                "What brought me here is a special use-case: I actually wanted a function to tell me if a list is empty or not. I wanted to avoid writing my own function or using a lambda-expression here (because it seemed like it should be simple enough):And, of course, there is a very natural way to do it:Of course, do not use bool in if (i.e., if bool(L):) because it's implied. But, for the cases when \"is not empty\" is explicitly needed as a function, bool is the best choice."
            ]
        },
        {
            "tag": "python",
            "question": [
                "What does ** (double star/asterisk) and * (star/asterisk) do for parameters?",
                "What do *args and **kwargs mean?\ndef foo(x, y, *args):\ndef bar(x, y, **kwargs):"
            ],
            "url": "https://stackoverflow.com/questions/36901",
            "answer": [
                "The *args and **kwargs is a common idiom to allow arbitrary number of arguments to functions as described in the section more on defining functions in the Python documentation.The *args will give you all function parameters as a tuple:The **kwargs will give you all\nkeyword arguments except for those corresponding to a formal parameter as a dictionary.Both idioms can be mixed with normal arguments to allow a set of fixed and some variable arguments:It is also possible to use this the other way around:Another usage of the *l idiom is to unpack argument lists when calling a function.In Python 3 it is possible to use *l on the left side of an assignment (Extended Iterable Unpacking), though it gives a list instead of a tuple in this context:Also Python 3 adds new semantic (refer PEP 3102):For example the following works in python 3 but not python 2:Such function accepts only 3 positional arguments, and everything after * can only be passed as keyword arguments.",
                "It's also worth noting that you can use * and ** when calling functions as well. This is a shortcut that allows you to pass multiple arguments to a function directly using either a list/tuple or a dictionary. For example, if you have the following function:You can do things like:Note: The keys in mydict have to be named exactly like the parameters of function foo. Otherwise it will throw a TypeError:",
                "The single * means that there can be any number of extra positional arguments. foo() can be invoked like foo(1,2,3,4,5). In the body of foo() param2 is a sequence containing 2-5.The double ** means there can be any number of extra named parameters. bar() can be invoked like bar(1, a=2, b=3). In the body of bar() param2 is a dictionary containing {'a':2, 'b':3 }With the following code:the output is",
                "They allow for functions to be defined to accept and for users to pass any number of arguments, positional (*) and keyword (**).*args allows for any number of optional positional arguments (parameters), which will be assigned to a tuple named args.**kwargs allows for any number of optional keyword arguments (parameters), which will be in a dict named kwargs.You can (and should) choose any appropriate name, but if the intention is for the arguments to be of non-specific semantics, args and kwargs are standard names.You can also use *args and **kwargs to pass in parameters from lists (or any iterable) and dicts (or any mapping), respectively.The function recieving the parameters does not have to know that they are being expanded.For example, Python 2's xrange does not explicitly expect *args, but since it takes 3 integers as arguments:As another example, we can use dict expansion in str.format:You can have keyword only arguments after the *args - for example, here, kwarg2 must be given as a keyword argument - not positionally:Usage:Also, * can be used by itself  to indicate that keyword only arguments follow, without allowing for unlimited positional arguments.Here, kwarg2 again must be an explicitly named, keyword argument:And we can no longer accept unlimited positional arguments because we don't have *args*:Again, more simply, here we require kwarg to be given by name, not positionally:In this example, we see that if we try to pass kwarg positionally, we get an error:We must explicitly pass the kwarg parameter as a keyword argument.*args (typically said \"star-args\") and **kwargs (stars can be implied by saying \"kwargs\", but be explicit with \"double-star kwargs\") are common idioms of Python for using the * and ** notation. These specific variable names aren't required (e.g. you could use *foos and **bars), but a departure from convention is likely to enrage your fellow Python coders.We typically use these when we don't know what our function is going to receive or how many arguments we may be passing, and sometimes even when naming every variable separately would get very messy and redundant (but this is a case where usually explicit is better than implicit).Example 1The following function describes how they can be used, and demonstrates behavior. Note the named b argument will be consumed by the second positional argument before :We can check the online help for the function's signature, with help(foo), which tells usLet's call this function with foo(1, 2, 3, 4, e=5, f=6, g=7)which prints:Example 2We can also call it using another function, into which we just provide a:bar(100) prints:Example 3: practical usage in decoratorsOK, so maybe we're not seeing the utility yet. So imagine you have several functions with redundant code before and/or after the differentiating code. The following named functions are just pseudo-code for illustrative purposes.We might be able to handle this differently, but we can certainly extract the redundancy with a decorator, and so our below example demonstrates how *args and **kwargs can be very useful:And now every wrapped function can be written much more succinctly, as we've factored out the redundancy:And by factoring out our code, which *args and **kwargs allows us to do, we reduce lines of code, improve readability and maintainability, and have sole canonical locations for the logic in our program. If we need to change any part of this structure, we have one place in which to make each change.",
                "Let us first understand what are positional arguments and keyword arguments.\nBelow is an example of function definition with Positional arguments.So this is a function definition with positional arguments.\nYou can call it with keyword/named arguments as well:Now let us study an example of function definition with keyword arguments:You can call this function with positional arguments as well:So we now know function definitions with positional as well as keyword arguments.Now let us study the '*' operator and '**' operator.Please note these operators can be used in 2 areas:a) function callb) function definitionThe use of '*' operator and '**' operator in function call.Let us get straight to an example and then discuss it.So rememberwhen the '*' or '**' operator is used in a function call -'*' operator unpacks data structure such as a list or tuple  into arguments needed by function definition.'**' operator unpacks a dictionary into arguments needed by function definition.Now let us study the '*' operator use in function definition.\nExample:In function definition the '*' operator packs the received arguments into a tuple.Now let us see an example of '**' used in function definition:In function definition The '**' operator packs the received arguments into a dictionary.So remember:In a function call the '*' unpacks data structure of tuple or list into positional or keyword arguments to be received by function definition.In a function call the '**' unpacks data structure of dictionary into positional or keyword arguments to be received by function definition.In a function definition the '*' packs positional arguments into a tuple.In a function definition the '**' packs keyword arguments into a dictionary.",
                "This table is handy for using * and ** in function construction and function call:This really just serves to summarize Lorin Hochstein's answer but I find it helpful.Relatedly: uses for the star/splat operators have been expanded in Python 3",
                "* and ** have special usage in the function argument list. *\nimplies that the argument is a list and ** implies that the argument\nis a dictionary. This allows functions to take arbitrary number of\narguments",
                "TL;DRBelow are 6 different use cases for * and ** in python programming:BONUS: From python 3.8 onward, one can use / in function definition to enforce  positional only parameters. In the following example, parameters a and b are positional-only, while c or d can be positional or keyword, and e or f are required to be keywords:BONUS 2: THIS ANSWER to the same question also brings a new perspective, where it shares what does * and ** means in a function call, functions signature, for loops, etc.",
                "Let us show this by defining a function that takes two normal variables x, y, and can accept more arguments as myArgs, and can accept even more arguments as myKW. Later, we will show how to feed y using myArgDict.",
                "From the Python documentation:If there are more positional arguments than there are formal parameter slots, a TypeError exception is raised, unless a formal parameter using the syntax \"*identifier\" is present; in this case, that formal parameter receives a tuple containing the excess positional arguments (or an empty tuple if there were no excess positional arguments).If any keyword argument does not correspond to a formal parameter name, a TypeError exception is raised, unless a formal parameter using the syntax \"**identifier\" is present; in this case, that formal parameter receives a dictionary containing the excess keyword arguments (using the keywords as keys and the argument values as corresponding values), or a (new) empty dictionary if there were no excess keyword arguments.",
                "* means receive variable arguments as tuple** means receive variable arguments as dictionaryUsed like the following:1) single *Output:2) Now **Output:",
                "In Python 3.5, you can also use this syntax in list, dict, tuple, and set displays (also sometimes called literals). See PEP 488: Additional Unpacking Generalizations.It also allows multiple iterables to be unpacked in a single function call.(Thanks to mgilson for the PEP link.)",
                "It packs arguments passed to the function into list and dict respectively inside the function body. When you define a function signature like this:it can be called with any number of arguments and keyword arguments. The non-keyword arguments get packed into a list called args inside the function body and the keyword arguments get packed into a dict called kwds inside the function body.now inside the function body, when the function is called, there are two local variables, args which is a list having value [\"this\", \"is a list of\", \"non-keyword\", \"arguments\"] and kwds which is a dict having value {\"keyword\" : \"ligma\", \"options\" : [1,2,3]}This also works in reverse, i.e. from the caller side. for example if you have a function defined as:you can call it with by unpacking iterables or mappings you have in the calling scope:",
                "I want to give an example which others haven't  mentioned* can also unpack a generatorAn example from Python3 Documentunzip_x will be (1, 2, 3), unzip_y will be (4, 5, 6)The zip() receives multiple iretable args, and return a generator.",
                "Building on nickd's answer...Output:Basically, any number of positional arguments can use *args and any named arguments (or kwargs aka keyword arguments) can use **kwargs.",
                "In addition to function calls, *args and **kwargs are useful in class hierarchies and also avoid having to write __init__ method in Python. Similar usage can seen in frameworks like Django code.For example,A subclass can then beThe subclass then be instantiated asAlso, a subclass with a new attribute which makes sense only to that subclass instance can call the Base class __init__ to offload the attributes setting.\nThis is done through *args and **kwargs. kwargs mainly used so that code is readable using named arguments. For example,which can be instatiated asThe complete code is here",
                "Given a function that has 3 items as argumentImagine this toy with a bag of a triangle, a circle and a rectangle item. That bag does not directly fit. You need to unpack the bag to take those 3 items and now they fit. The Python * operator does this unpack process.",
                "*args and **kwargs: allow you to pass a variable number of arguments to a function.*args: is used to send a non-keyworded variable length argument list to the function:Will produce:**kwargs***kwargs allows you to pass keyworded variable length of arguments to a function. You should use **kwargs if you want to handle named arguments in a function.Will produce:",
                "A good example of using both in a function is:",
                "This example would help you remember *args, **kwargs and even super and inheritance in Python at once.",
                "In addition to the answers in this thread, here is another detail that was not mentioned elsewhere. This expands on the answer by Brad SolomonUnpacking with ** is also useful when using python str.format.This is somewhat similar to what you can do with python f-strings f-string but with the added overhead of declaring a dict to hold the variables (f-string does not require a dict).",
                "*args ( or *any ) means every parametersNOTICE : you can don't pass parameters to *argsThe *args is in type tuplefor access to elements don't use of *The **kwd**kwd or **any\nThis is a dict type",
                "For example, the syntax for implementing varargs in Java as follows:",
                "*args and **kwargs are just some way to input unlimited characters to functions, like:",
                "*args is the special parameter which can take 0 or more (positional) arguments as a tuple.**kwargs is the special parameter which can take 0 or more (keyword) arguments as a dictionary.*In Python, there are 2 kinds of arguments positional argument and keyword argument:For example, *args can take 0 or more arguments as a tuple as shown below:Output:And, when printing *args, 4 numbers are printed without parentheses and commas:Output:And, args has tuple type:Output:But, *args has no type:Output(Error):TypeError: type() takes 1 or 3 argumentsAnd, normal parameters can be put before *args as shown below:Output:But, **kwargs cannot be put before *args as shown below:Output(Error):SyntaxError: invalid syntaxAnd, normal parameters cannot be put after *args as shown below:Output(Error):TypeError: test() missing 2 required keyword-only arguments: 'num1' and 'num2'But, if normal parameters have default values, they can be put after *args as shown below:Output:And also, **kwargs can be put after *args as shown below:Output:For example, **kwargs can take 0 or more arguments as a dictionary as shown below:Output:And, when printing *kwargs, 2 keys are printed:Output:And, kwargs has dict type:Output:But, *kwargs and **kwargs have no type:Output(Error):TypeError: type() takes 1 or 3 argumentsAnd, normal parameters can be put before **kwargs as shown below:Output:And also, *args can be put before **kwargs as shown below:Output:And, normal parameters and *args cannot be put after **kwargs as shown below:Output(Error):SyntaxError: invalid syntaxActually, you can use other names for *args and **kwargs as shown below. *args and **kwargs are used conventionally:Output:"
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I pass a variable by reference?",
                "Are parameters passed by reference or by value? How do I pass by reference so that the code below outputs 'Changed' instead of 'Original'?\nclass PassByReference:\n    def __init__(self):\n        self...."
            ],
            "url": "https://stackoverflow.com/questions/986006",
            "answer": [
                "Arguments are passed by assignment. The rationale behind this is twofold:So:If you pass a mutable object into a method, the method gets a reference to that same object and you can mutate it to your heart's delight, but if you rebind the reference in the method, the outer scope will know nothing about it, and after you're done, the outer reference will still point at the original object.If you pass an immutable object to a method, you still can't rebind the outer reference, and you can't even mutate the object.To make it even more clear, let's have some examples.Let's try to modify the list that was passed to a method:Output:Since the parameter passed in is a reference to outer_list, not a copy of it, we can use the mutating list methods to change it and have the changes reflected in the outer scope.Now let's see what happens when we try to change the reference that was passed in as a parameter:Output:Since the the_list parameter was passed by value, assigning a new list to it had no effect that the code outside the method could see. The the_list was a copy of the outer_list reference, and we had the_list point to a new list, but there was no way to change where outer_list pointed.It's immutable, so there's nothing we can do to change the contents of the stringNow, let's try to change the referenceOutput:Again, since the the_string parameter was passed by value, assigning a new string to it had no effect that the code outside the method could see. The the_string was a copy of the outer_string reference, and we had the_string point to a new string, but there was no way to change where outer_string pointed.I hope this clears things up a little.EDIT: It's been noted that this doesn't answer the question that @David originally asked, \"Is there something I can do to pass the variable by actual reference?\". Let's work on that.As @Andrea's answer shows, you could return the new value. This doesn't change the way things are passed in, but does let you get the information you want back out:If you really wanted to avoid using a return value, you could create a class to hold your value and pass it into the function or use an existing class, like a list:Although this seems a little cumbersome.",
                "The problem comes from a misunderstanding of what variables are in Python. If you're used to most traditional languages, you have a mental model of what happens in the following sequence:You believe that a is a memory location that stores the value 1, then is updated to store the value 2. That's not how things work in Python. Rather, a starts as a reference to an object with the value 1, then gets reassigned as a reference to an object with the value 2. Those two objects may continue to coexist even though a doesn't refer to the first one anymore; in fact they may be shared by any number of other references within the program.When you call a function with a parameter, a new reference is created that refers to the object passed in. This is separate from the reference that was used in the function call, so there's no way to update that reference and make it refer to a new object. In your example:self.variable is a reference to the string object 'Original'. When you call Change you create a second reference var to the object. Inside the function you reassign the reference var to a different string object 'Changed', but the reference self.variable is separate and does not change.The only way around this is to pass a mutable object. Because both references refer to the same object, any changes to the object are reflected in both places.",
                "I found the other answers rather long and complicated, so I created this simple diagram to explain the way Python treats variables and parameters.",
                "It is neither pass-by-value or pass-by-reference - it is call-by-object. See this, by Fredrik Lundh:http://effbot.org/zone/call-by-object.htmHere is a significant quote:\"...variables [names] are not objects; they cannot be denoted by other variables or referred to by objects.\"In your example, when the Change method is called--a namespace is created for it; and var becomes a name, within that namespace, for the string object 'Original'. That object then has a name in two namespaces. Next, var = 'Changed' binds var to a new string object, and thus the method's namespace forgets about 'Original'. Finally, that namespace is forgotten, and the string 'Changed' along with it.",
                "Think of stuff being passed by assignment instead of by reference/by value. That way, it is always clear, what is happening as long as you understand what happens during the normal assignment.So, when passing a list to a function/method, the list is assigned to the parameter name. Appending to the list will result in the list being modified. Reassigning the list inside the function will not change the original list, since:Since immutable types cannot be modified, they seem like being passed by value - passing an int into a function means assigning the int to the function's parameter. You can only ever reassign that, but it won't change the original variables value.",
                "The key to understanding parameter passing is to stop thinking about \"variables\". There are names and objects in Python and together they\nappear like variables, but it is useful to always distinguish the three.That is all there is to it. Mutability is irrelevant to this question.Example:This binds the name a to an object of type integer that holds the value 1.This binds the name b to the same object that the name x is currently bound to.\nAfterward, the name b has nothing to do with the name x anymore.See sections 3.1 and 4.2 in the Python 3 language reference.In the code shown in the question, the statement self.Change(self.variable) binds the name var (in the scope of function Change) to the object that holds the value 'Original' and the assignment var = 'Changed' (in the body of function Change) assigns that same name again: to some other object (that happens to hold a string as well but could have been something else entirely).So if the thing you want to change is a mutable object, there is no problem, as everything is effectively passed by reference.If it is an immutable object (e.g. a bool, number, string), the way to go is to wrap it in a mutable object.\nThe quick-and-dirty solution for this is a one-element list (instead of self.variable, pass [self.variable] and in the function modify var[0]).\nThe more pythonic approach would be to introduce a trivial, one-attribute class. The function receives an instance of the class and manipulates the attribute.",
                "Effbot (aka Fredrik Lundh) has described Python's variable passing style as call-by-object:  http://effbot.org/zone/call-by-object.htmObjects are allocated on the heap and pointers to them can be passed around anywhere.When you make an assignment such as x = 1000, a dictionary entry is created that maps the string \"x\" in the current namespace to a pointer to the integer object containing one thousand.When you update \"x\" with x = 2000, a new integer object is created and the dictionary is updated to point at the new object.  The old one thousand object is unchanged (and may or may not be alive depending on whether anything else refers to the object).When you do a new assignment such as y = x, a new dictionary entry \"y\" is created that points to the same object as the entry for \"x\".Objects like strings and integers are immutable.  This simply means that there are no methods that can change the object after it has been created.  For example, once the integer object one-thousand is created, it will never change.  Math is done by creating new integer objects.Objects like lists are mutable.  This means that the contents of the object can be changed by anything pointing to the object.  For example, x = []; y = x; x.append(10); print y will print [10].  The empty list was created.  Both \"x\" and \"y\" point to the same list.  The append method mutates (updates) the list object (like adding a record to a database) and the result is visible to both \"x\" and \"y\" (just as a database update would be visible to every connection to that database).Hope that clarifies the issue for you.",
                "Technically, Python always uses pass by reference values. I am going to repeat my other answer to support my statement.Python always uses pass-by-reference values. There isn't any exception. Any variable assignment means copying the reference value. No exception. Any variable is the name bound to the reference value. Always.You can think about a reference value as the address of the target object. The address is automatically dereferenced when used. This way, working with the reference value, it seems you work directly with the target object. But there always is a reference in between, one step more to jump to the target.Here is the example that proves that Python uses passing by reference:If the argument was passed by value, the outer lst could not be modified. The green are the target objects (the black is the value stored inside, the red is the object type), the yellow is the memory with the reference value inside -- drawn as the arrow. The blue solid arrow is the reference value that was passed to the function (via the dashed blue arrow path). The ugly dark yellow is the internal dictionary. (It actually could be drawn also as a green ellipse. The colour and the shape only says it is internal.)You can use the id() built-in function to learn what the reference value is (that is, the address of the target object).In compiled languages, a variable is a memory space that is able to capture the value of the type. In Python, a variable is a name (captured internally as a string) bound to the reference variable that holds the reference value to the target object. The name of the variable is the key in the internal dictionary, the value part of that dictionary item stores the reference value to the target.Reference values are hidden in Python. There isn't any explicit user type for storing the reference value. However, you can use a list element (or element in any other suitable container type) as the reference variable, because all containers do store the elements also as references to the target objects. In other words, elements are actually not contained inside the container -- only the references to elements are.",
                "A simple trick I normally use is to just wrap it in a list:(Yeah I know this can be inconvenient, but sometimes it is simple enough to do this.)",
                "(edit - Blair has updated his enormously popular answer so that it is now accurate)I think it is important to note that the current post with the most votes (by Blair Conrad), while being correct with respect to its result, is misleading and is borderline incorrect based on its definitions.  While there are many languages (like C) that allow the user to either pass by reference or pass by value, Python is not one of them.David Cournapeau's answer points to the real answer and explains why the behavior in Blair Conrad's post seems to be correct while the definitions are not.To the extent that Python is pass by value, all languages are pass by value since some piece of data (be it a \"value\" or a \"reference\") must be sent. However, that does not mean that Python is pass by value in the sense that a C programmer would think of it.If you want the behavior, Blair Conrad's answer is fine.  But if you want to know the nuts and bolts of why Python is neither pass by value or pass by reference, read David Cournapeau's answer.",
                "You got some really good answers here.",
                "Python\u2019s pass-by-assignment scheme isn\u2019t quite the same as C++\u2019s reference parameters option, but it turns out to be very similar to the argument-passing model of the C language (and others) in practice:",
                "In this case the variable titled var in the method Change is assigned a reference to self.variable, and you immediately assign a string to var. It's no longer pointing to self.variable. The following code snippet shows what would happen if you modify the data structure pointed to by var and self.variable, in this case a list:I'm sure someone else could clarify this further.",
                "A lot of insights in answers here, but i think an additional point is not clearly mentioned here explicitly.   Quoting from python documentation https://docs.python.org/2/faq/programming.html#what-are-the-rules-for-local-and-global-variables-in-python\"In Python, variables that are only referenced inside a function are implicitly global. If a variable is assigned a new value anywhere within the function\u2019s body, it\u2019s assumed to be a local. If a variable is ever assigned a new value inside the function, the variable is implicitly local, and you need to explicitly declare it as \u2018global\u2019.\nThough a bit surprising at first, a moment\u2019s consideration explains this. On one hand, requiring global for assigned variables provides a bar against unintended side-effects. On the other hand, if global was required for all global references, you\u2019d be using global all the time. You\u2019d have to declare as global every reference to a built-in function or to a component of an imported module. This clutter would defeat the usefulness of the global declaration for identifying side-effects.\"Even when passing a mutable object to a function this still applies. And to me clearly explains the reason for the difference in behavior between assigning to the object and operating on the object in the function.gives:The assignment to an global variable that is not declared global therefore creates a new local object and breaks the link to the original object.",
                "As you can state you need to have a mutable object, but let me suggest you to check over the global variables as they can help you or even solve this kind of issue!http://docs.python.org/3/faq/programming.html#what-are-the-rules-for-local-and-global-variables-in-pythonexample:",
                "Here is the simple (I hope) explanation of the concept pass by object used in Python.\nWhenever you pass an object to the function, the object itself is passed (object in Python is actually what you'd call a value in other programming languages) not the reference to this object. In other words, when you call:The actual object - [0, 1] (which would be called a value in other programming languages) is being passed. So in fact the function change_me will try to do something like:which obviously will not change the object passed to the function. If the function looked like this:Then the call would result in:which obviously will change the object. This answer explains it well.",
                "Aside from all the great explanations on how this stuff works in Python, I don't see a simple suggestion for the problem. As you seem to do create objects and instances, the pythonic way of handling instance variables and changing them is the following:In instance methods, you normally refer to self to access instance attributes. It is normal to set instance attributes in __init__ and read or change them in instance methods. That is also why you pass self als the first argument to def Change.Another solution would be to create a static method like this:",
                "I used the following method to quickly convert a couple of Fortran codes to Python.  True, it's not pass by reference as the original question was posed, but is a simple work around in some cases.",
                "There is a little trick to pass an object by reference, even though the language doesn't make it possible. It works in Java too, it's the list with one item. ;-)It's an ugly hack, but it works. ;-P",
                "given the way python handles values and references to them, the only way you can reference an arbitrary instance attribute is by name:in real code you would, of course, add error checking on the dict lookup.",
                "Since it seems to be nowhere mentioned an approach to simulate references as known from e.g. C++ is to use an \"update\" function and pass that instead of the actual variable (or rather, \"name\"):This is mostly useful for \"out-only references\" or in a situation with multiple threads / processes (by making the update function thread / multiprocessing safe).Obviously the above does not allow reading the value, only updating it.",
                "Since your example happens to be object-oriented, you could make the following change to achieve a similar result:",
                "Since dictionaries are passed by reference, you can use a dict variable to store any referenced values inside it.",
                "While pass by reference is nothing that fits well into python and should be rarely used there are some workarounds that actually can work to get the object currently assigned to a local variable or even reassign a local variable from inside of a called function.The basic idea is to have a function that can do that access and can be passed as object into other functions or stored in a class.One way is to use global (for global variables) or nonlocal (for local variables in a function) in a wrapper function.The same idea works for reading and deleting a variable.For just reading there is even a shorter way of just using lambda: x which returns a callable that when called returns the current value of x. This is somewhat like \"call by name\" used in languages in the distant past.Passing 3 wrappers to access a variable is a bit unwieldy so those can be wrapped into a class that has a proxy attribute:Pythons \"reflection\" support makes it possible to get a object that is capable of reassigning a name/variable in a given scope without defining functions explicitly in that scope:Here the ByRef class wraps a dictionary access. So attribute access to wrapped is translated to a item access in the passed dictionary. By passing the result of the builtin locals and the name of a local variable this ends up accessing a local variable. The python documentation as of 3.5 advises that changing the dictionary might not work but it seems to work for me.",
                "You can merely use an empty class as an instance to store reference objects because internally object attributes are stored in an instance dictionary. See the example.",
                "Pass-By-Reference in Python is quite different from the concept of pass by reference in C++/Java.",
                "I am new to Python, started yesterday (though I have been programming for 45 years).I came here because I was writing a function where I wanted to have two so called out-parameters. If it would have been only one out-parameter, I wouldn't get hung up right now on checking how reference/value works in Python. I would just have used the return value of the function instead. But since I needed two such out-parameters I felt I needed to sort it out.In this post I am going to show how I solved my situation. Perhaps others coming here can find it valuable, even though it is not exactly an answer to the topic question. Experienced Python programmers of course already know about the solution I used, but it was new to me.From the answers here I could quickly see that Python works a bit like Javascript in this regard, and that you need to use workarounds if you want the reference functionality.But then I found something neat in Python that I don't think I have seen in other languages before, namely that you can return more than one value from a function, in a simple comma separated way, like this:and that you can handle that on the calling side similarly, like thisThat was good enough for me and I was satisfied. No need to use some workaround.In other languages you can of course also return many values, but then usually in the from of an object, and you need to adjust the calling side accordingly.The Python way of doing it was nice and simple.If you want to mimic by reference even more, you could do as follows:which gives this result",
                "alternatively you could use ctypes witch would look something like thisas a is a c int and not a python integer and apperently passed by reference. however you have to be carefull as strange things could happen and is therefor not advised",
                "Most likely not the most reliable method but this works, keep in mind that you are overloading the built-in str function which is typically something you don't want to do:",
                "What about dataclasses? Also, it allows you to apply type restriction (aka \"type hint\").I agree with folks that in most cases you'd better consider not to use it.And yet, when we're talking about contexts it's worth to know that way.You can design explicit context class though. When prototyping I prefer dataclasses, just because it's easy to serialize them back and forth.Cheers!"
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I clone a list so that it doesn't change unexpectedly after assignment?",
                "While using new_list = my_list, any modifications to new_list changes my_list every time. Why is this, and how can I clone or copy the list to prevent it?"
            ],
            "url": "https://stackoverflow.com/questions/2612802",
            "answer": [
                "new_list = my_list doesn't actually create a second list. The assignment just copies the reference to the list, not the actual list, so both new_list and my_list refer to the same list after the assignment.To actually copy the list, you have several options:You can use the builtin list.copy() method (available since Python 3.3):You can slice it:Alex Martelli's opinion (at least back in 2007) about this is, that it is a weird syntax and it does not make sense to use it ever. ;) (In his opinion, the next one is more readable).You can use the built in list() constructor:You can use generic copy.copy():This is a little slower than list() because it has to find out the datatype of old_list first.If you need to copy the elements of the list as well, use generic copy.deepcopy():Obviously the slowest and most memory-needing method, but sometimes unavoidable. This operates recursively; it will handle any number of levels of nested lists (or other containers).Example:Result:",
                "Felix already provided an excellent answer, but I thought I'd do a speed comparison of the various methods:So the fastest is list slicing. But be aware that copy.copy(), list[:] and list(list), unlike copy.deepcopy() and the python version don't copy any lists, dictionaries and class instances in the list, so if the originals change, they will change in the copied list too and vice versa.(Here's the script if anyone's interested or wants to raise any issues:)",
                "I've been told that Python 3.3+ adds the list.copy() method, which should be as fast as slicing:",
                "In Python 3, a shallow copy can be made with:In Python 2 and 3, you can get a shallow copy with a full slice of the original:There are two semantic ways to copy a list. A shallow copy creates a new list of the same objects, a deep copy creates a new list containing new equivalent objects.A shallow copy only copies the list itself, which is a container of references to the objects in the list. If the objects contained themselves are mutable and one is changed, the change will be reflected in both lists.There are different ways to do this in Python 2 and 3. The Python 2 ways will also work in Python 3.In Python 2, the idiomatic way of making a shallow copy of a list is with a complete slice of the original:You can also accomplish the same thing by passing the list through the list constructor,but using the constructor is less efficient:In Python 3, lists get the list.copy method:In Python 3.5:Using new_list = my_list then modifies new_list every time my_list changes. Why is this?my_list is just a name that points to the actual list in memory. When you say new_list = my_list you're not making a copy, you're just adding another name that points at that original list in memory. We can have similar issues when we make copies of lists.The list is just an array of pointers to the contents, so a shallow copy just copies the pointers, and so you have two different lists, but they have the same contents. To make copies of the contents, you need a deep copy.To make a deep copy of a list, in Python 2 or 3, use deepcopy in the copy module:To demonstrate how this allows us to make new sub-lists:And so we see that the deep copied list is an entirely different list from the original. You could roll your own function - but don't. You're likely to create bugs you otherwise wouldn't have by using the standard library's deepcopy function.You may see this used as a way to deepcopy, but don't do it:In 64 bit Python 2.7:on 64 bit Python 3.5:",
                "Let's start from the beginning and explore this question.So let's suppose you have two lists:And we have to copy both lists, now starting from the first list:So first let's try by setting the variable copy to our original list, list_1:Now if you are thinking copy copied the list_1, then you are wrong. The id function can show us if two variables can point to the same object. Let's try this:The output is:Both variables are the exact same argument. Are you surprised?So as we know, Python doesn't store anything in a variable, Variables are just referencing to the object and object store the value. Here object is a list but we created two references to that same object by two different variable names. This means that both variables are pointing to the same object, just with different names.When you do copy = list_1, it is actually doing:Here in the image list_1 and copy are two variable names, but the object is same for both variable which is list.So if you try to modify copied list then it will modify the original list too because the list is only one there, you will modify that list no matter you do from the copied list or from the original list:Output:So it modified the original list:Now let's move onto a Pythonic method for copying lists.This method fixes the first issue we had:So as we can see our both list having different id and it means that both variables are pointing to different objects. So what actually going on here is:Now let's try to modify the list and let's see if we still face the previous problem:The output is:As you can see, it only modified the copied list. That means it worked.Do you think we're done? No. Let's try to copy our nested list.list_2 should reference to another object which is copy of list_2. Let's check:We get the output:Now we can assume both lists are pointing different object, so now let's try to modify it and let's see it is giving what we want:This gives us the output:This may seem a little bit confusing, because the same method we previously used worked. Let's try to understand this.When you do:You're only copying the outer list, not the inside list. We can use the id function once again to check this.The output is:When we do copy_2 = list_2[:], this happens:It creates the copy of list, but only outer list copy, not the nested list copy. The nested list is same for both variable, so if you try to modify the nested list then it will modify the original list too as the nested list object is same for both lists.What is the solution? The solution is the deepcopy function.Let's check this:Both outer lists have different IDs. Let's try this on the inner nested lists.The output is:As you can see both IDs are different, meaning we can assume that both nested lists are pointing different object now.This means when you do deep = deepcopy(list_2) what actually happens:Both nested lists are pointing different object and they have separate copy of nested list now.Now let's try to modify the nested list and see if it solved the previous issue or not:It outputs:As you can see, it didn't modify the original nested list, it only modified the copied list.",
                "There are many answers already that tell you how to make a proper copy, but none of them say why your original 'copy' failed.Python doesn't store values in variables; it binds names to objects. Your original assignment took the object referred to by my_list and bound it to new_list as well. No matter which name you use there is still only one list, so changes made when referring to it as my_list will persist when referring to it as new_list. Each of the other answers to this question give you different ways of creating a new object to bind to new_list.Each element of a list acts like a name, in that each element binds non-exclusively to an object. A shallow copy creates a new list whose elements bind to the same objects as before.To take your list copy one step further, copy each object that your list refers to, and bind those element copies to a new list.This is not yet a deep copy, because each element of a list may refer to other objects, just like the list is bound to its elements. To recursively copy every element in the list, and then each other object referred to by each element, and so on: perform a deep copy.See the documentation for more information about corner cases in copying.",
                "Use thing[:]",
                "Here are the timing results using Python 3.6.8. Keep in mind these times are relative to one another, not absolute.I stuck to only doing shallow copies, and also added some new methods that weren't possible in Python\u00a02, such as list.copy() (the Python\u00a03 slice equivalent) and two forms of list unpacking (*new_list, = list and new_list = [*list]):We can see the Python 2 winner still does well, but doesn't edge out Python 3 list.copy() by much, especially considering the superior readability of the latter.The dark horse is the unpacking and repacking method (b = [*a]), which is ~25% faster than raw slicing, and more than twice as fast as the other unpacking method (*b, = a).b = a * 1 also does surprisingly well.Note that these methods do not output equivalent results for any input other than lists. They all work for sliceable objects, a few work for any iterable, but only copy.copy() works for more general Python objects.Here is the testing code for interested parties (Template from here):",
                "Python's idiom for doing this is newList = oldList[:]",
                "All of the other contributors gave great answers, which work when you have a single dimension (leveled) list, however of the methods mentioned so far, only copy.deepcopy() works to clone/copy a list and not have it point to the nested list objects when you are working with multidimensional, nested lists (list of lists). While Felix Kling refers to it in his answer, there is a little bit more to the issue and possibly a workaround using built-ins that might prove a faster alternative to deepcopy.While new_list = old_list[:], copy.copy(old_list)' and for Py3k old_list.copy() work for single-leveled lists, they revert to pointing at the list objects nested within the old_list and the new_list, and changes to one of the list objects are perpetuated in the other.As was pointed out by both Aaron Hall and PM 2Ring using eval() is not only a bad idea, it is also much slower than copy.deepcopy().This means that for multidimensional lists, the only option is copy.deepcopy(). With that being said, it really isn't an option as the performance goes way south when you try to use it on a moderately sized multidimensional array.  I tried to timeit using a 42x42 array, not unheard of or even that large for bioinformatics applications, and I gave up on waiting for a response and just started typing my edit to this post.It would seem that the only real option then is to initialize multiple lists and work on them independently. If anyone has any other suggestions, for how to handle multidimensional list copying, it would be appreciated.As others have stated, there  are significant performance issues using the copy module and copy.deepcopy for multidimensional lists.",
                "It surprises me that this hasn't been mentioned yet, so for the sake of completeness...You can perform list unpacking with the \"splat operator\": *, which will also copy elements of your list.The obvious downside to this method is that it is only available in Python 3.5+.Timing wise though, this appears to perform better than other common methods.",
                "new_list = my_listTry to understand this. Let's say that my_list is in the heap memory at location X, i.e., my_list is pointing to the X. Now by assigning new_list = my_list you're letting new_list point to the X. This is known as a shallow copy.Now if you assign new_list = my_list[:], you're simply copying each object of my_list to new_list. This is known as a deep copy.The other ways you can do this are:",
                "A very simple approach independent of python version was missing in already-given answers which you can use most of the time (at least I do):However, if my_list contains other containers (for example, nested lists) you must use deepcopy as others suggested in the answers above from the copy library. For example:.Bonus: If you don't want to copy elements use (AKA shallow copy):Let's understand difference between solution #1 and solution #2As you can see, solution #1 worked perfectly when we were not using the nested lists. Let's check what will happen when we apply solution #1 to nested lists.",
                "I wanted to post something a bit different than some of the other answers. Even though this is most likely not the most understandable, or fastest option, it provides a bit of an inside view of how deep copy works, as well as being another alternative option for deep copying. It doesn't really matter if my function has bugs, since the point of this is to show a way to copy objects like the question answers, but also to use this as a point to explain how deepcopy works at its core.At the core of any deep copy function is way to make a shallow copy. How? Simple. Any deep copy function only duplicates the containers of immutable objects. When you deepcopy a nested list, you are only duplicating the outer lists, not the mutable objects inside of the lists. You are only duplicating the containers. The same works for classes, too. When you deepcopy a class, you deepcopy all of its mutable attributes. So, how? How come you only have to copy the containers, like lists, dicts, tuples, iters, classes, and class instances?It's simple. A mutable object can't really be duplicated. It can never be changed, so it is only a single value. That means you never have to duplicate strings, numbers, bools, or any of those. But how would you duplicate the containers? Simple. You make just initialize a new container with all of the values. Deepcopy relies on recursion. It duplicates all the containers, even ones with containers inside of them, until no containers are left. A container is an immutable object.Once you know that, completely duplicating an object without any references is pretty easy. Here's a function for deepcopying basic data-types (wouldn't work for custom classes but you could always add that)Python's own built-in deepcopy is based around that example. The only difference is it supports other types, and also supports user-classes by duplicating the attributes into a new duplicate class, and also blocks infinite-recursion with a reference to an object it's already seen using a memo list or dictionary. And that's really it for making deep copies. At its core, making a deep copy is just making shallow copies. I hope this answer adds something to the question.EXAMPLESSay you have this list: [1, 2, 3]. The immutable numbers cannot be duplicated, but the other layer can. You can duplicate it using a list comprehension: [x for x in [1, 2, 3]]Now, imagine you have this list: [[1, 2], [3, 4], [5, 6]]. This time, you want to make a function, which uses recursion to deep copy all layers of the list. Instead of the previous list comprehension:It uses a new one for lists:And deepcopy_list looks like this:Then now you have a function which can deepcopy any list of strs, bools, floast, ints and even lists to infinitely many layers using recursion. And there you have it, deepcopying.TLDR: Deepcopy uses recursion to duplicate objects, and merely returns the same immutable objects as before, as immutable objects cannot be duplicated. However, it deepcopies the most inner layers of mutable objects until it reaches the outermost mutable layer of an object.",
                "Note that there are some cases where if you have defined your own custom class and you want to keep the attributes then you should use copy.copy() or copy.deepcopy() rather than the alternatives, for example in Python 3:Outputs:",
                "Remember that in Python when you do:List2 isn't storing the actual list, but a reference to list1. So when you do anything to list1, list2 changes as well. use the copy module (not default, download on pip) to make an original copy of the list(copy.copy() for simple lists, copy.deepcopy() for nested ones). This makes a copy that doesn't change with the first list.",
                "A slight practical perspective to look into memory through id and gc.",
                "There is another way of copying a list that was not listed until now: adding an empty list: l2 = l + [].I tested it with Python 3.8:It is not the best answer, but it works.",
                "The deepcopy option is the only method that works for me:leads to output of:",
                "This is because, the line new_list = my_list assigns a new reference to the variable my_list which is new_list\nThis is similar to the C code given below,You should use the copy module to create a new list by",
                "The method to use depends on the contents of the list being copied. If the list contains nested dicts than deepcopy is the only method that works, otherwise most of the methods listed in the answers (slice, loop [for], copy, extend, combine, or unpack) will work and execute in similar time (except for loop and deepcopy, which preformed the worst).",
                "I often see code that tries to modify a copy of the list in some iterative fashion. To construct a trivial example, suppose we had non-working (because x should not be modified) code like:Naturally people will ask how to make y be a copy of x, rather than a name for the same list, so that the for loop will do the right thing.But this is the wrong approach. Functionally, what we really want to do is make a new list that is based on the original.We don't need to make a copy first to do that, and we typically shouldn't.The natural tool for this is a list comprehension. This way, we write the logic that tells us how the elements in the desired result, relate to the original elements. It's simple, elegant and expressive; and we avoid the need for workarounds to modify the y copy in a for loop (since assigning to the iteration variable doesn't affect the list - for the same reason that we wanted the copy in the first place!).For the above example, it looks like:List comprehensions are quite powerful; we can also use them to filter out elements by a rule with an if clause, and we can chain for and if clauses (it works like the corresponding imperative code, with the same clauses in the same order; only the value that will ultimately end up in the result list, is moved to the front instead of being in the \"innermost\" part). If the plan was to iterate over the original while modifying the copy to avoid problems, there is generally a much more pleasant way to do that with a filtering list comprehension.Suppose instead that we had something likeRather than making y a separate copy first in order to delete the part we don't want, we can build a list by putting together the parts that we do want. Thus:Handling insertion, replacement etc. by slicing is left as an exercise. Just reason out which subsequences you want the result to contain. A special case of this is making a reversed copy - assuming we need a new list at all (rather than just to iterate in reverse), we can directly create it by slicing, rather than cloning and then using .reverse.These approaches - like the list comprehension - also have the advantage that they create the desired result as an expression, rather than by procedurally modifying an existing object in-place (and returning None). This is more convenient for writing code in a \"fluent\" style.",
                "Short and simple explanations of each copy mode:A shallow copy constructs a new compound object and then (to the extent possible) inserts references into it to the objects found in the original - creating a shallow copy:A deep copy constructs a new compound object and then, recursively, inserts copies into it of the objects found in the original - creating a deep copy:list() works fine for deep copy of simple lists, like:But, for complex lists like......use deepcopy():"
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I make a time delay? [duplicate]",
                "How do I put a time delay in a Python script?"
            ],
            "url": "https://stackoverflow.com/questions/510348",
            "answer": [
                "This delays for 2.5 seconds:Here is another example where something is run approximately once a minute:",
                "Use sleep() from the time module. It can take a float argument for sub-second resolution.",
                "In a single thread I suggest the sleep function:This function actually suspends the processing of the thread in which it is called by the operating system, allowing other threads and processes to execute while it sleeps.Use it for that purpose, or simply to delay a function from executing. For example:\"hooray!\" is printed 3 seconds after I hit Enter.Again, sleep suspends your thread - it uses next to zero processing power.To demonstrate, create a script like this (I first attempted this in an interactive Python 3.5 shell, but sub-processes can't find the party_later function for some reason):Example output from this script:You can trigger a function to be called at a later time in a separate thread with the Timer threading object:The blank line illustrates that the function printed to my standard output, and I had to hit Enter to ensure I was on a prompt.The upside of this method is that while the Timer thread was waiting, I was able to do other things, in this case, hitting Enter one time - before the function executed (see the first empty prompt).There isn't a respective object in the multiprocessing library. You can create one, but it probably doesn't exist for a reason. A sub-thread makes a lot more sense for a simple timer than a whole new subprocess.",
                "Delays can be also implemented by using the following methods.The first method:The second method to delay would be using the implicit wait method:The third method is more useful when you have to wait until a particular action is completed or until an element is found:",
                "There are five methods which I know: time.sleep(), pygame.time.wait(), matplotlib's pyplot.pause(), .after(), and asyncio.sleep().time.sleep() example (do not use if using tkinter):pygame.time.wait() example (not recommended if you are not using the pygame window, but you could exit the window instantly):matplotlib's function pyplot.pause() example (not recommended if you are not using the graph, but you could exit the graph instantly):The .after() method (best with Tkinter):Finally, the asyncio.sleep() method (has to be in an async loop):",
                "A bit of fun with a sleepy generator.The question is about time delay. It can be fixed time, but in some cases we might need a delay measured since last time. Here is one possible solution:The situation can be, we want to do something as regularly as possible and we do not want to bother with all the last_time, next_time stuff all around our code.The following code (sleepy.py) defines a buzzergen generator:And running it we see:We can also use it directly in a loop:And running it we might see:As we see, this buzzer is not too rigid and allow us to catch up with regular sleepy intervals even if we oversleep and get out of regular schedule.",
                "The Tkinter library in the Python standard library is an interactive tool which you can import. Basically, you can create buttons and boxes and popups and stuff that appear as windows which you manipulate with code.If you use Tkinter, do not use time.sleep(), because it will muck up your program. This happened to me. Instead, use root.after() and replace the values for however many seconds, with a milliseconds. For example, time.sleep(1) is equivalent to root.after(1000) in Tkinter.Otherwise, time.sleep(), which many answers have pointed out, which is the way to go.",
                "Delays are done with the time library, specifically the time.sleep() function.To just make it wait for a second:This works because by doing:You extract the sleep function only from the time library, which means you can just call it with:Rather than having to type outWhich is awkwardly long to type.With this method, you wouldn't get access to the other features of the time library and you can't have a variable called sleep. But you could create a variable called time.Doing from [library] import [function] (, [function2]) is great if you just want certain parts of a module.You could equally do it as:and you would have access to the other features of the time library like time.clock() as long as you type time.[function](), but you couldn't create the variable time because it would overwrite the import. A solution to this to dowhich would allow you to reference the time library as t, allowing you to do:This works on any library.",
                "Use time.sleep or Event().wait like this:Use threading.Timer like this:Outputs:",
                "Notice in recent Python versions (Python\u00a03.4 or higher) you can use asyncio.sleep. It's related to asynchronous programming and asyncio. Check out next example:We may think it will \"sleep\" for 2 seconds for first method and then 3 seconds in the second method, a total of 5 seconds running time of this code. But it will print:It is recommended to read asyncio official documentation for more details.",
                "While everyone else has suggested the de facto time module, I thought I'd share a different method using matplotlib's pyplot function, pause.Typically this is used to prevent the plot from disappearing as soon as it is plotted or to make crude animations.This would save you an import if you already have matplotlib imported.",
                "This is an easy example of a time delay:Another, in Tkinter:",
                "You also can try this:Now the shell will not crash or not react."
            ]
        },
        {
            "tag": "python",
            "question": [
                "How can I delete a file or folder in Python?",
                "How can I delete a file or folder?"
            ],
            "url": "https://stackoverflow.com/questions/6996603",
            "answer": [
                "os.remove() removes a file.os.rmdir() removes an empty directory.shutil.rmtree() deletes a directory and all its contents.Path objects from the Python 3.4+ pathlib module also expose these instance methods:pathlib.Path.unlink() removes a file or symbolic link.pathlib.Path.rmdir() removes an empty directory.",
                "ororpathlib Library for Python version >= 3.4Unlink method used to remove the file or the symbolik link.First, check if the file or folder exists and then delete it. You can achieve this in two ways:EXAMPLE for os.path.isfileExample for shutil.rmtree()",
                "Use(See complete documentation on shutil) and/orand(Complete documentation on os.)",
                "Here is a robust function that uses both os.remove and shutil.rmtree:",
                "You can use the built-in pathlib module (requires Python 3.4+, but there are backports for older versions on PyPI: pathlib, pathlib2).To remove a file there is the unlink method:Or the rmdir method to remove an empty folder:",
                "There are multiple ways to Delete a File in Python but the best ways are the following:To delete all files inside a particular directory, you simply have to use the * symbol as the pattern string.\n#Importing os and glob modules\nimport os, glob\n#Loop Through the folder projects all files and deleting them one by one\nfor file in glob.glob(\"pythonpool/*\"):\nos.remove(file)\nprint(\"Deleted \" + str(file))os.unlink() is an alias or another name of os.remove() . As in the Unix OS remove is also known as unlink.\nNote: All the functionalities and syntax is the same of os.unlink() and os.remove(). Both of them are used to delete the Python file path.\nBoth are methods in the os module in Python\u2019s standard libraries which performs the deletion function.Pathlib module provides different ways to interact with your files. Rmdir is one of the path functions which allows you to delete an empty folder. Firstly, you need to select the Path() for the directory, and then calling rmdir() method will check the folder size. If it\u2019s empty, it\u2019ll delete it.This is a good way to deleting empty folders without any fear of losing actual data.",
                "For Python 3, to remove the file and directory individually, use the unlink and rmdir Path object methods respectively:Note that you can also use relative paths with Path objects, and you can check your current working directory with Path.cwd.For removing individual files and directories in Python 2, see the section so labeled below.To remove a directory with contents, use shutil.rmtree, and note that this is available in Python 2 and 3:New in Python 3.4 is the Path object.Let's use one to create a directory and file to demonstrate usage. Note that we use the / to join the parts of the path, this works around issues between operating systems and issues from using backslashes on Windows (where you'd need to either double up your backslashes like \\\\ or use raw strings, like r\"foo\\bar\"):and now:Now let's delete them. First the file:We can use globbing to remove multiple files - first let's create a few files for this:Then just iterate over the glob pattern:Now, demonstrating removing the directory:What if we want to remove a directory  and everything in it? \nFor this use-case, use shutil.rmtreeLet's recreate our directory and file:and note that rmdir fails unless it's empty, which is why rmtree is so convenient:Now, import rmtree and pass the directory to the funtion:and we can see the whole thing has been removed:If you're on Python 2, there's a backport of the pathlib module called pathlib2, which can be installed with pip:And then you can alias the library to pathlibOr just directly import the Path object (as demonstrated here):If that's too much, you can remove files with os.remove or os.unlinkorand you can remove directories with os.rmdir:Note that there is also a os.removedirs - it only removes empty directories recursively, but it may suit your use-case.",
                "shutil.rmtree is the asynchronous function, \nso if you want to check when it complete, you can use while...loop",
                "This is my function for deleting dirs. The \"path\" requires the full pathname.",
                "orBoth functions are semantically same. This functions removes (deletes) the file path. If path is not a file and it is directory, then exception is raised.orIn order to remove whole directory trees, shutil.rmtree() can be used. os.rmdir only works when the directory is empty and exists.It remove every empty parent directory with self until parent which has some contentex. os.removedirs('abc/xyz/pqr') will remove the directories by order 'abc/xyz/pqr', 'abc/xyz' and 'abc' if they are empty.For more info check official doc: os.unlink , os.remove, os.rmdir , shutil.rmtree, os.removedirs",
                "To remove all files in folderTo remove all folders in a directory",
                "To avoid the TOCTOU issue highlighted by \u00c9ric Araujo's comment, you can catch an exception to call the correct method:Since shutil.rmtree() will only remove directories and os.remove() or os.unlink() will only remove files.",
                "My personal preference is to work with pathlib objects - it offers a more pythonic and less error-prone way to interact with the filesystem, especially if You develop cross-platform code.In that case, You might use pathlib3x - it offers a backport of the latest (at the date of writing this answer Python 3.10.a0) Python pathlib for Python 3.6 or newer, and a few additional functions like \"copy\", \"copy2\", \"copytree\", \"rmtree\" etc ...It also wraps shutil.rmtree:you can find it on github or PyPiDisclaimer: I'm the author of the pathlib3x library.",
                "I recommend using subprocess if writing a beautiful and readable code is your cup of tea:And if you are not a software engineer, then maybe consider using Jupyter; you can simply type bash commands:Traditionally, you use shutil:"
            ]
        },
        {
            "tag": "python",
            "question": [
                "What is the difference between Python's list methods append and extend?",
                "What's the difference between the list methods append() and extend()?"
            ],
            "url": "https://stackoverflow.com/questions/252703",
            "answer": [
                "append appends a specified object at the end of the list:extend extends the list by appending elements from the specified iterable:",
                "append adds an element to a list. extend concatenates the first list with another list/iterable.",
                "The list.append method appends an object to the end of the list.Whatever the object is, whether a number, a string, another list, or something else, it gets added onto the end of my_list as a single entry on the list.So keep in mind that a list is an object. If you append another list onto a list, the first list will be a single object at the end of the list (which may not be what you want):The list.extend method extends a list by appending elements from an iterable:So with extend, each element of the iterable gets appended onto the list. For example:Keep in mind that a string is an iterable, so if you extend a list with a string, you'll append each character as you iterate over the string (which may not be what you want):Both + and += operators are defined for list. They are semantically similar to extend.my_list + another_list creates a third list in memory, so you can return the result of it, but it requires that the second iterable be a list.my_list += another_list modifies the list in-place (it is the in-place operator, and lists are mutable objects, as we've seen) so it does not create a new list. It also works like extend, in that the second iterable can be any kind of iterable.Don't get confused - my_list = my_list + another_list is not equivalent to += - it gives you a brand new list assigned to my_list.Append has (amortized) constant time complexity, O(1).Extend has time complexity, O(k).Iterating through the multiple calls to append adds to the complexity, making it equivalent to that of extend, and since extend's iteration is implemented in C, it will always be faster if you intend to append successive items from an iterable onto a list.Regarding \"amortized\" - from the list object implementation source:This means that we get the benefits of a larger than needed memory reallocation up front, but we may pay for it on the next marginal reallocation with an even larger one. Total time for all appends is linear at O(n), and that time allocated per append, becomes O(1).You may wonder what is more performant, since append can be used to achieve the same outcome as extend. The following functions do the same thing:So let's time them:A commenter said:Perfect answer, I just miss the timing of comparing adding only one elementDo the semantically correct thing. If you want to append all elements in an iterable, use extend. If you're just adding one element, use append.Ok, so let's create an experiment to see how this works out in time:And we see that going out of our way to create an iterable just to use extend is a (minor) waste of time:We learn from this that there's nothing gained from using extend when we have only one element to append.Also, these timings are not that important. I am just showing them to make the point that, in Python, doing the semantically correct thing is doing things the Right Way\u2122.It's conceivable that you might test timings on two comparable operations and get an ambiguous or inverse result. Just focus on doing the semantically correct thing.We see that extend is semantically clearer, and that it can run much faster than append, when you intend to append each element in an iterable to a list.If you only have a single element (not in an iterable) to add to the list, use append.",
                "append appends a single element. extend appends a list of elements.Note that if you pass a list to append, it still adds one element:",
                "With append you can append a single element that will extend the list:If you want to extend more than one element you should use extend, because you can only append one elment or one list of element:So that you get a nested listInstead with extend, you can extend a single element like thisOr, differently, from append, extend more elements in one time without nesting the list into the original one (that's the reason of the name extend)Both append and extend can add one element to the end of the list, though append is simpler.If you use append for more than one element, you have to pass a list of elements as arguments and you will obtain a NESTED list!With extend, instead, you pass a list as an argument, but you will obtain a list with the new element that is not nested in the old one.So, with more elements, you will use extend to get a list with more items.\nHowever, appending a list will not add more elements to the list, but one element that is a nested list as you can clearly see in the output of the code.",
                "The following two snippets are semantically equivalent:andThe latter may be faster as the loop is implemented in C.",
                "The append() method adds a single item to the end of the list.The extend() method takes one argument, a list, and appends each of the items of the argument to the original list. (Lists are implemented as classes. \u201cCreating\u201d a list is really instantiating a class. As such, a list has methods that operate on it.)From Dive Into Python.",
                "You can use \"+\" for returning extend, instead of extending in place.Similarly += for in place behavior, but with slight differences from append & extend. One of the biggest differences of += from append and extend is when it is used in function scopes, see this blog post.",
                "append(object) updates the list by adding the object to the list.extend(list) concatenates the two lists essentially.",
                "This is the equivalent of append and extend using the + operator:",
                "extend() can be used with an iterator argument. Here is an example. You wish to make a list out of a list of lists this way:Fromyou wantYou may use itertools.chain.from_iterable() to do so. This method's output is an iterator. Its implementation is equivalent toBack to our example, we can doand get the wanted list.Here is how equivalently extend() can be used with an iterator argument:",
                "append(): It is basically used in Python to add one element.Example 1:Example 2:extend(): Where extend(), is used to merge two lists or insert multiple elements in one list.Example 1:Example 2:",
                "An interesting point that has been hinted, but not explained, is that extend is faster than append. For any loop that has append inside should be considered to be replaced by list.extend(processed_elements).Bear in mind that apprending new elements might result in the realloaction of the whole list to a better location in memory. If this is done several times because we are appending 1 element at a time, overall performance suffers. In this sense, list.extend is analogous to \"\".join(stringlist).",
                "Append adds the entire data at once. The whole data will be added to the newly created index. On the other hand, extend, as it name suggests, extends the current array.For exampleWith append we get:While on extend we get:",
                "An English dictionary defines the words append and extend as:append: add (something) to the end of a written document. \nextend: make larger. Enlarge or expandWith that knowledge, now let's understand1) The difference between append and extendappend:extend:2) Similarity between append and extendExample",
                "I hope I can make a useful supplement to this question. If your list stores a specific type object, for example Info, here is a situation that extend method is not suitable: In a for loop and and generating an Info object every time and using extend to store it into your list, it will fail. The exception is like below:TypeError: 'Info' object is not iterableBut if you use the append method, the result is OK. Because every time using the extend method, it will always treat it as a list or any other collection type, iterate it, and place it after the previous list. A specific object can not be iterated, obviously.",
                "To distinguish them intuitivelyIt's like l1 reproduce a body inside her body(nested).It's like that two separated individuals get married and construct an united family.Besides I make an exhaustive cheatsheet of all list's methods for your reference.",
                "extend(L) extends the list by appending all the items in the given list L.",
                "append \"extends\" the list (in place) by only one item, the single object passed (as argument).extend \"extends\" the list (in place) by as many items as the object passed (as argument) contains.This may be slightly confusing for str objects.produces:",
                "Append and extend are one of the extensibility mechanisms in python.Append: Adds an element to the end of the list.To add a new element to the list, we can use append method in the following way.The default location that the new element will be added is always in the (length+1) position.Insert: The insert method was used to overcome the limitations of append. With insert, we can explicitly define the exact position we want our new element to be inserted at.Method descriptor of insert(index, object). It takes two arguments, first being the index we want to insert our element and second the element itself.Extend: This is very useful when we want to join two or more lists into a single list. Without extend, if we want to join two lists, the resulting object will contain a list of lists.If we try to access the element at pos 2, we get a list ([3]), instead of the element. To join two lists, we'll have to use append.To join multiple lists"
            ]
        },
        {
            "tag": "python",
            "question": [
                "Understanding Python super() with __init__() methods [duplicate]",
                "Why is super() used?\nIs there a difference between using Base.__init__ and super().__init__?\nclass Base(object):\n    def __init__(self):\n        print \"Base created\"\n        \nclass ChildA(..."
            ],
            "url": "https://stackoverflow.com/questions/576169",
            "answer": [
                "super() lets you avoid referring to the base class explicitly, which can be nice. But the main advantage comes with multiple inheritance, where all sorts of fun stuff can happen. See the standard docs on super if you haven't already.Note that the syntax changed in Python 3.0: you can just say super().__init__() instead of super(ChildB, self).__init__() which IMO is quite a bit nicer. The standard docs also refer to a guide to using super() which is quite explanatory.",
                "The reason we use super is so that child classes that may be using cooperative multiple inheritance will call the correct next parent class function in the Method Resolution Order (MRO).In Python 3, we can call it like this:In Python 2, we were required to call super like this with the defining class's name and self, but we'll avoid this from now on because it's redundant, slower (due to the name lookups), and more verbose (so update your Python if you haven't already!):Without super, you are limited in your ability to use multiple inheritance because you hard-wire the next parent's call:I further explain below.The primary difference in this code is that in ChildB you get a layer of indirection in the __init__ with super, which uses the class in which it is defined to determine the next class's __init__ to look up in the MRO.I illustrate this difference in an answer at the canonical question, How to use 'super' in Python?, which demonstrates dependency injection and cooperative multiple inheritance.Here's code that's actually closely equivalent to super (how it's implemented in C, minus some checking and fallback behavior, and translated to Python):Written a little more like native Python:If we didn't have the super object, we'd have to write this manual code everywhere (or recreate it!) to ensure that we call the proper next method in the Method Resolution Order!How does super do this in Python 3 without being told explicitly which class and instance from the method it was called from?It gets the calling stack frame, and finds the class (implicitly stored as a local free variable, __class__, making the calling function a closure over the class) and the first argument to that function, which should be the instance or class that informs it which Method Resolution Order (MRO) to use.Since it requires that first argument for the MRO, using super with static methods is impossible as they do not have access to the MRO of the class from which they are called.super() lets you avoid referring to the base class explicitly, which can be nice. . But the main advantage comes with multiple inheritance, where all sorts of fun stuff can happen. See the standard docs on super if you haven't already.It's rather hand-wavey and doesn't tell us much, but the point of super is not to avoid writing the parent class. The point is to ensure that the next method in line in the method resolution order (MRO) is called. This becomes important in multiple inheritance.I'll explain here.And let's create a dependency that we want to be called after the Child:Now remember, ChildB uses super, ChildA does not:And UserA does not call the UserDependency method:But UserB does in-fact call UserDependency because ChildB invokes super:In no circumstance should you do the following, which another answer suggests, as you'll definitely get errors when you subclass ChildB:(That answer is not clever or particularly interesting, but in spite of direct criticism in the comments and over 17 downvotes, the answerer persisted in suggesting it until a kind editor fixed his problem.)Explanation: Using self.__class__ as a substitute for the class name in super() will lead to recursion. super lets us look up the next parent in the MRO (see the first section of this answer) for child classes. If you tell super we're in the child instance's method, it will then lookup the next method in line (probably this one) resulting in recursion, probably causing a logical failure (in the answerer's example, it does) or a RuntimeError when the recursion depth is exceeded.Python 3's new super() calling method with no arguments fortunately allows us to sidestep this issue.",
                "It's been noted that in Python 3.0+ you can useto make your call, which is concise and does not require you to reference the parent OR class names explicitly, which can be handy. I just want to add that for Python 2.7 or under, some people implement a name-insensitive behaviour by writing self.__class__ instead of the class name, i.e.HOWEVER, this breaks calls to super for any classes that inherit from your class, where self.__class__ could return a child class. For example:Here I have a class Square, which is a sub-class of Rectangle. Say I don't want to write a separate constructor for Square because the constructor for Rectangle is good enough, but for whatever reason I want to implement a Square so I can reimplement some other method.When I create a Square using mSquare = Square('a', 10,10), Python calls the constructor for Rectangle because I haven't given Square its own constructor. However, in the constructor for Rectangle, the call super(self.__class__,self) is going to return the superclass of mSquare, so it calls the constructor for Rectangle again. This is how the infinite loop happens, as was mentioned by @S_C. In this case, when I run super(...).__init__() I am calling the constructor for Rectangle but since I give it no arguments, I will get an error.",
                "Super has no side effectsworks as expectedgets into infinite recursion.",
                "Just a heads up... with Python 2.7, and I believe ever since super() was introduced in version 2.2, you can only call super() if one of the parents inherit from a class that eventually inherits object (new-style classes).Personally, as for python 2.7 code, I'm going to continue using BaseClassName.__init__(self, args) until I actually get the advantage of using super().",
                "There isn't, really. super() looks at the next class in the MRO (method resolution order, accessed with cls.__mro__) to call the methods. Just calling the base __init__ calls the base __init__. As it happens, the MRO has exactly one item-- the base. So you're really doing the exact same thing, but in a nicer way with super() (particularly if you get into multiple inheritance later).",
                "The main difference is that ChildA.__init__ will unconditionally call Base.__init__ whereas ChildB.__init__ will call __init__ in whatever class happens to be ChildB ancestor in self's line of ancestors\n(which may differ from what you expect).If you add a ClassC that uses multiple inheritance:then Base is no longer the parent of ChildB for ChildC instances. Now super(ChildB, self) will point to Mixin if self is a ChildC instance.You have inserted Mixin in between ChildB and Base. And you can take advantage of it with super()So if you are designed your classes so that they can be used in a Cooperative Multiple Inheritance scenario, you use super because you don't really know who is going to be the ancestor at runtime.The super considered super post and pycon 2015 accompanying video explain this pretty well."
            ]
        },
        {
            "tag": "python",
            "question": [
                "How to make function decorators and chain them together?",
                "How do I make two decorators in Python that would do the following?\n@make_bold\n@make_italic\ndef say():\n   return \"Hello\"\n\nCalling say() should return:\n\"<b><i>Hello</i>&..."
            ],
            "url": "https://stackoverflow.com/questions/739654",
            "answer": [
                "If you are not into long explanations, see Paolo Bergantino\u2019s answer.To understand decorators, you must first understand that functions are objects in Python. This has important consequences. Let\u2019s see why with a simple example :Keep this in mind. We\u2019ll circle back to it shortly.Another interesting property of Python functions is they can be defined inside another function!Okay, still here? Now the fun part...You\u2019ve seen that functions are objects. Therefore, functions:That means that a function can return another function.There\u2019s more!If you can return a function, you can pass one as a parameter:Well, you just have everything needed to understand decorators. You see, decorators are \u201cwrappers\u201d, which means that they let you execute code before and after the function they decorate without modifying the function itself.How you\u2019d do it manually:Now, you probably want that every time you call a_stand_alone_function, a_stand_alone_function_decorated is called instead. That\u2019s easy, just overwrite a_stand_alone_function with the function returned by my_shiny_new_decorator:The previous example, using the decorator syntax:Yes, that\u2019s all, it\u2019s that simple. @decorator is just a shortcut to:Decorators are just a pythonic variant of the decorator design pattern. There are several classic design patterns embedded in Python to ease development (like iterators).Of course, you can accumulate decorators:Using the Python decorator syntax:The order you set the decorators MATTERS:As a conclusion, you can easily see how to answer the question:You can now just leave happy, or burn your brain a little bit more and see advanced uses of decorators.One nifty thing about Python is that methods and functions are really the same.  The only difference is that methods expect that their first argument is a reference to the current object (self).That means you can build a decorator for methods the same way! Just remember to take self into consideration:If you\u2019re making general-purpose decorator--one you\u2019ll apply to any function or method, no matter its arguments--then just use *args, **kwargs:Great, now what would you say about passing arguments to the decorator itself?This can get somewhat twisted, since a decorator must accept a function as an argument. Therefore, you cannot pass the decorated function\u2019s arguments directly to the decorator.Before rushing to the solution, let\u2019s write a little reminder:It\u2019s exactly the same. \"my_decorator\" is called. So when you @my_decorator, you are telling Python to call the function 'labelled by the variable \"my_decorator\"'.This is important! The label you give can point directly to the decorator\u2014or not.Let\u2019s get evil. \u263aNo surprise here.Let\u2019s do EXACTLY the same thing, but skip all the pesky intermediate variables:Let\u2019s make it even shorter:Hey, did you see that? We used a function call with the \"@\" syntax! :-)So, back to decorators with arguments. If we can use functions to generate the decorator on the fly, we can pass arguments to that function, right?Here it is: a decorator with arguments. Arguments can be set as variable:As you can see, you can pass arguments to the decorator like any function using this trick. You can even use *args, **kwargs if you wish. But remember decorators are called only once. Just when Python imports the script. You can't dynamically set the arguments afterwards. When you do \"import x\", the function is already decorated, so you can't\nchange anything.Okay, as a bonus, I'll give you a snippet to make any decorator accept generically any argument. After all, in order to accept arguments, we created our decorator using another function.We wrapped the decorator.Anything else we saw recently that wrapped function?Oh yes, decorators!Let\u2019s have some fun and write a decorator for the decorators:It can be used as follows:I know, the last time you had this feeling, it was after listening a guy saying: \"before understanding recursion, you must first understand recursion\". But now, don't you feel good about mastering this?The functools module was introduced in Python 2.5. It includes the function functools.wraps(), which copies the name, module, and docstring of the decorated function to its wrapper.(Fun fact: functools.wraps() is a decorator! \u263a)Now the big question: What can I use decorators for?Seem cool and powerful, but a practical example would be great. Well, there are 1000 possibilities. Classic uses are extending a function behavior from an external lib (you can't modify it), or for debugging (you don't want to modify it because it\u2019s temporary).You can use them to extend several functions in a DRY\u2019s way, like so:Of course the good thing with decorators is that you can use them right away on almost anything without rewriting. DRY, I said:Python itself provides several decorators: property, staticmethod, etc.This really is a large playground.",
                "Check out the documentation to see how decorators work. Here is what you asked for:",
                "Alternatively, you could write a factory function which return a decorator which wraps the return value of the decorated function in a tag passed to the factory function. For example:This enables you to write:orPersonally I would have written the decorator somewhat differently:which would yield:Don't forget the construction for which decorator syntax is a shorthand:",
                "Decorators are just syntactical sugar.Thisexpands to",
                "And of course you can return lambdas as well from a decorator function:",
                "Python decorators add extra functionality to another functionAn italics decorator could be likeNote that a function is defined inside a function.\nWhat it basically does is replace a function with the newly defined one. For example, I have this classNow say, I want both functions to print \"---\" after and before they are done.\nI could add a print \"---\" before and after each print statement.\nBut because I don't like repeating myself, I will make a decoratorSo now I can change my class toFor more on decorators, check\nhttp://www.ibm.com/developerworks/linux/library/l-cpdecor.html",
                "You could make two separate decorators that do what you want as illustrated directly below. Note the use of *args, **kwargs in the declaration of the wrapped() function which supports the decorated function having multiple arguments (which isn't really necessary for the example say() function, but is included for generality).For similar reasons, the functools.wraps decorator is used to change the meta attributes of the wrapped function to be those of the one being decorated. This makes error messages and embedded function documentation (func.__doc__) be those of the decorated function instead of wrapped()'s.As you can see there's a lot of duplicate code in these two decorators. Given this similarity it would be better for you to instead make a generic one that was actually a decorator factory\u2014in other words, a decorator function that makes other decorators. That way there would be less code repetition\u2014and allow the DRY principle to be followed.To make the code more readable, you can assign a more descriptive name to the factory-generated decorators:or even combine them like this:While the above examples do all work, the code generated involves a fair amount of overhead in the form of extraneous function calls when multiple decorators are applied at once. This may not matter, depending the exact usage (which might be I/O-bound, for instance).If speed of the decorated function is important, the overhead can be kept to a single extra function call by writing a slightly different decorator factory-function which implements adding all the tags at once, so it can generate code that avoids the addtional function calls incurred by using separate decorators for each tag.This requires more code in the decorator itself, but this only runs when it's being applied to function definitions, not later when they themselves are called. This also applies when creating more readable names by using lambda functions as previously illustrated. Sample:",
                "Another way of doing the same thing:Or, more flexibly:",
                "You want the following function, when called:To return:To most simply do this, make decorators that return lambdas (anonymous functions) that close over the function (closures) and call it:Now use them as desired:and now:But we seem to have nearly lost the original function.To find it, we'd need to dig into the closure of each lambda, one of which is buried in the other:So if we put documentation on this function, or wanted to be able to decorate functions that take more than one argument, or we just wanted to know what function we were looking at in a debugging session, we need to do a bit more with our wrapper.We have the decorator wraps from the functools module in the standard library!It is unfortunate that there's still some boilerplate, but this is about as simple as we can make it.In Python 3, you also get __qualname__ and __annotations__ assigned by default.So now:And now:So we see that wraps makes the wrapping function do almost everything except tell us exactly what the function takes as arguments.There are other modules that may attempt to tackle the problem, but the solution is not yet in the standard library.",
                "A decorator takes the function definition and creates a new function that executes this function and transforms the result.is equivalent to:Thisis equivalent to this65 <=> 'a'To understand the decorator, it is important to notice, that decorator created a new function do which is inner that executes function and transforms the result.",
                "This answer has long been answered, but I thought I would share my Decorator class which makes writing new decorators easy and compact.For one I think this makes the behavior of decorators very clear, but it also makes it easy to define new decorators very concisely. For the example listed above, you could then solve it as:You could also use it to do more complex tasks, like for instance a decorator which automatically makes the function get applied recursively to all arguments in an iterator:Which prints:Notice that this example didn't include the list type in the instantiation of the decorator, so in the final print statement the method gets applied to the list itself, not the elements of the list.",
                "You can also write decorator in Class",
                "Here is a simple example of chaining decorators.  Note the last line - it shows what is going on under the covers.The output looks like:",
                "Speaking of the counter example - as given above, the counter will be shared between all functions that use the decorator:That way, your decorator can be reused for different functions (or used to decorate the same function multiple times: func_counter1 = counter(func); func_counter2 = counter(func)), and the counter variable will remain private to each.",
                "Result:",
                "Paolo Bergantino's answer has the great advantage of only using the stdlib, and works for this simple example where there are no decorator arguments nor decorated function arguments.However it has 3 major limitations if you want to tackle more general cases:I wrote decopatch to solve the first issue, and wrote makefun.wraps to solve the other two. Note that makefun leverages the same trick than the famous decorator lib.This is how you would create a decorator with arguments, returning truly signature-preserving wrappers:decopatch provides you with two other development styles that hide or show the various python concepts, depending on your preferences. The most compact style is the following:In both cases you can check that the decorator works as expected:Please refer to the documentation for details.",
                "I add a case when you need to add custom parameters in decorator, pass it to final function and then work it with.the very decorators:and the final function:",
                "Yet another example of nested decorators for plotting an image:Now, let's show a color image first without axis labels using the nested decorators:Next, let's show a gray scale image without axis labels using the nested decorators remove_axis and plot_gray (we need to cmap='gray', otherwise the default colormap is viridis, so a grayscale image is by default not displayed in black and white shades, unless explicitly specified)The above function call reduces down to the following nested call",
                "With make_bold() and make_italic() below:You can use them as decorators with say() as shown below:Output:And of course, you can directly use make_bold() and make_italic() without decorators as shown below:In short:Output:",
                "Consider the following decorator, note that we are returning the wrapper() function as an objectSo Thisevaluates to thisNote that x is not the say() but the wrapper object that calls say() internally. That is how decorator works. It always returns the wrapper object which calls the actual function.\nIn case of chaining thisgets converted to thisBelow is the complete codeThe above code will returnHope this helps"
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I change the size of figures drawn with Matplotlib?",
                "How do I change the size of figure drawn with Matplotlib?"
            ],
            "url": "https://stackoverflow.com/questions/332289",
            "answer": [
                "figure tells you the call signature:figure(figsize=(1,1)) would create an inch-by-inch image, which would be 80-by-80 pixels unless you also give a different dpi argument.",
                "If you've already got the figure created, you can use figure.set_size_inches to adjust the figure size:To propagate the size change to an existing GUI window, add forward=True:Additionally as Erik Shilts mentioned in the comments you can also use figure.set_dpi to \"[s]et the resolution of the figure in dots-per-inch\"",
                "There is also this workaround in case you want to change the size without using the figure environment. So in case you are using plt.plot() for example, you can set a tuple with width and height.This is very useful when you plot inline (e.g., with IPython Notebook). As asmaier noticed, it is preferable to not put this statement in the same cell of the imports statements.To reset the global figure size back to default for subsequent plots:The figsize tuple accepts inches, so if you want to set it in centimetres you have to divide them by 2.54. Have a look at this question.",
                "Deprecation note:\nAs per the official Matplotlib guide, usage of the pylab module is no longer recommended. Please consider using the matplotlib.pyplot module instead, as described by this other answer.The following seems to work:This makes the figure's width 5 inches, and its height 10 inches.The Figure class then uses this as the default value for one of its arguments.",
                "In case you're looking for a way to change the figure size in Pandas, you could do:where df is a Pandas dataframe. Or, to use an existing figure or axes:If you want to change the default settings, you could do the following:For more details, check out the docs: pd.DataFrame.plot.",
                "The first link in Google for 'matplotlib figure size' is AdjustingImageSize (Google cache of the page).Here's a test script from the above page. It creates test[1-3].png files of different sizes of the same image:Output:Two notes:The module comments and the actual output differ.This answer allows easily to combine all three images in one image file to see the difference in sizes.",
                "You can simply use (from matplotlib.figure.Figure):As of Matplotlib 2.0.0, changes to your canvas will be visible immediately, as the forward keyword defaults to True.If you want to just change the width or height instead of both, you can usefig.set_figwidth(val) or fig.set_figheight(val)These will also immediately update your canvas, but only in Matplotlib 2.2.0 and newer.You need to specify forward=True explicitly in order to live-update your canvas in versions older than what is specified above. Note that the set_figwidth and set_figheight functions don\u2019t support the forward parameter in versions older than Matplotlib 1.5.0.",
                "Try commenting out the fig = ... line",
                "This works well for me:This forum post might also help: Resizing figure windows",
                "Comparison of different approaches to set exact image sizes in pixelsThis answer will focus on:Here is a quick comparison of some of the approaches I've tried with images showing what the give.Summary of current status: things are messy, and I am not sure if it is a fundamental limitation, or if the use case just didn't get enough attention from developers. I couldn't easily find an upstream discussion about this.Baseline example without trying to set the image dimensionsJust to have a comparison point:Run:Outputs:My best approach so far: plt.savefig(dpi=h/fig.get_size_inches()[1] height-only controlI think this is what I'll go with most of the time, as it is simple and scales:Run:Outputs:andOutputs:I tend to set just the height because I'm usually most concerned about how much vertical space the image is going to take up in the middle of my text.plt.savefig(bbox_inches='tight' changes image sizeI always feel that there is too much white space around images, and tended to add bbox_inches='tight' from:\nRemoving white space around a saved imageHowever, that works by cropping the image, and you won't get the desired sizes with it.Instead, this other approach proposed in the same question seems to work well:which gives the exact desired height for height equals 431:Fixed height, set_aspect, automatically sized width and small marginsErmmm, set_aspect messes things up again and prevents plt.tight_layout from actually removing the margins... this is an important use case that I don't have a great solution for yet.Asked at: How to obtain a fixed height in pixels, fixed data x/y aspect ratio and automatically remove remove horizontal whitespace margin in Matplotlib?plt.savefig(dpi=h/fig.get_size_inches()[1] + width controlIf you really need a specific width in addition to height, this seems to work OK:Run:Output:and for a small width:Output:So it does seem that fonts are scaling correctly, we just get some trouble for very small widths with labels getting cut off, e.g. the 100 on the top left.I managed to work around those with Removing white space around a saved imagewhich gives:From this, we also see that tight_layout removes a lot of the empty space at the top of the image, so I just generally always use it.Fixed magic base height, dpi on fig.set_size_inches and plt.savefig(dpi= scalingI believe that this is equivalent to the approach mentioned at: https://stackoverflow.com/a/13714720/895245Run:Outputs:And to see if it scales nicely:Outputs:So we see that this approach also does work well. The only problem I have with it is that you have to set that magic_height parameter or equivalent.Fixed DPI + set_size_inchesThis approach gave a slightly wrong pixel size, and it makes it is hard to scale everything seamlessly.Run:Outputs:So the height is slightly off, and the image:The pixel sizes are also correct if I make it 3 times larger:Outputs:We understand from this however that for this approach to scale nicely, you need to make every DPI-dependant setting proportional to the size in inches.In the previous example, we only made the \"Hello\" text proportional, and it did retain its height between 60 and 80 as we'd expect. But everything for which we didn't do that, looks tiny, including:SVGI could not find how to set it for SVG images, my approaches only worked for PNG, e.g.:Run:And the generated output contains:And identify says:And if I open it in Chromium 86 the browser debug tools mouse image hover confirm that height as 460.79.But of course, since SVG is a vector format, everything should in theory scale, so you can just convert to any fixed sized format without loss of resolution, e.g.:gives the exact height:I use Inkscape instead of ImageMagick's convert here because you need to mess with -density as well to get sharp SVG resizes with ImageMagick:And setting <img height=\"\" on the HTML should also just work for the browser.It was tested on matplotlib 3.2.2.",
                "Generalizing and simplifying psihodelia's answer:If you want to change the current size of the figure by a factor sizefactor:After changing the current size, it might occur that you have to fine tune the subplot layout. You can do that in the figure window GUI, or by means of the command subplots_adjustFor example,",
                "This resizes the figure immediately even after the figure has been drawn (at least using Qt4Agg/TkAgg - but not Mac\u00a0OS\u00a0X - with Matplotlib 1.4.0):",
                "I always use the following pattern:With this example you are able to set figure dimensions in inches or in millimetres. When setting constrained_layout to True, plots fill your figure without borders."
            ]
        },
        {
            "tag": "python",
            "question": [
                "Manually raising (throwing) an exception in Python",
                "How do I raise an exception in Python so that it can later be caught via an except block?"
            ],
            "url": "https://stackoverflow.com/questions/2052390",
            "answer": [
                "Use the most specific Exception constructor that semantically fits your issue.Be specific in your message, e.g.:Avoid raising a generic Exception. To catch it, you'll have to catch all other more specific exceptions that subclass it.For example:And more specific catches won't catch the general exception:Instead, use the most specific Exception constructor that semantically fits your issue.which also handily allows an arbitrary number of arguments to be passed to the constructor:These arguments are accessed by the args attribute on the Exception object. For example:printsIn Python 2.5, an actual message attribute was added to BaseException in favor of encouraging users to subclass Exceptions and stop using args, but the introduction of message and the original deprecation of args has been retracted.When inside an except clause, you might want to, for example, log that a specific type of error happened, and then re-raise. The best way to do this while preserving the stack trace is to use a bare raise statement. For example:You can preserve the stacktrace (and error value) with sys.exc_info(), but this is way more error prone and has compatibility problems between Python 2 and 3, prefer to use a bare raise to re-raise.To explain - the sys.exc_info() returns the type, value, and traceback.This is the syntax in Python 2 - note this is not compatible with Python 3:If you want to, you can modify what happens with your new raise - e.g. setting new args for the instance:And we have preserved the whole traceback while modifying the args. Note that this is not a best practice and it is invalid syntax in Python 3 (making keeping compatibility much harder to work around).In Python 3:Again: avoid manually manipulating tracebacks. It's less efficient and more error prone. And if you're using threading and sys.exc_info you may even get the wrong traceback (especially if you're using exception handling for control flow - which I'd personally tend to avoid.)In Python 3, you can chain Exceptions, which preserve tracebacks:Be aware:These can easily hide and even get into production code. You want to raise an exception, and doing them will raise an exception, but not the one intended!Valid in Python 2, but not in Python 3 is the following:Only valid in much older versions of Python (2.4 and lower), you may still see people raising strings:In all modern versions, this will actually raise a TypeError, because you're not raising a BaseException type. If you're not checking for the right exception and don't have a reviewer that's aware of the issue, it could get into production.I raise Exceptions to warn consumers of my API if they're using it incorrectly:\"I want to make an error on purpose, so that it would go into the except\"You can create your own error types, if you want to indicate something specific is wrong with your application, just subclass the appropriate point in the exception hierarchy:and usage:",
                "Don't do this. Raising a bare Exception is absolutely not the right thing to do; see Aaron Hall's excellent answer instead.It can't get much more Pythonic than this:Replace Exception with the specific type of exception you want to throw.See the raise statement documentation for Python if you'd like more information.",
                "In Python 3 there are four different syntaxes for raising exceptions:If you use raise exception (args) to raise an exception then the args will be printed when you print the exception object - as shown in the example below.The raise statement without any arguments re-raises the last exception.This is useful if you need to perform some actions after catching the exception and then want to re-raise it. But if there wasn't any exception before, the raise statement raises  a TypeError Exception.This statement is used to create exception chaining in which an exception that is raised in response to another exception can contain the details of the original exception - as shown in the example below.Output:",
                "For the common case where you need to throw an exception in response to some unexpected conditions, and that you never intend to catch, but simply to fail fast to enable you to debug from there if it ever happens \u2014 the most logical one seems to be AssertionError:",
                "Read the existing answers first, this is just an addendum.Notice that you can raise exceptions with or without arguments.Example:exits the program, but you might want to know what happened. So you can use this.This will print \"program exited\" to standard error before closing the program.",
                "Just to note: there are times when you do want to handle generic exceptions. If you're processing a bunch of files and logging your errors, you might want to catch any error that occurs for a file, log it, and continue processing the rest of the files. In that case, ablock is a good way to do it. You'll still want to raise specific exceptions so you know what they mean, though.",
                "Another way to throw an exception is using assert. You can use assert to verify a condition is being fulfilled. If not, then it will raise AssertionError. For more details have a look here.",
                "You might also want to raise custom exceptions. For example, if you're writing a library, it's a very good practice to make a base exception class for your module, and then have custom sub-exceptions to be more specific.You can achieve that like this:If you're not interested in having a custom base class, you can just inherit your custom exception classes from an ordinary exception class like Exception, TypeError, ValueError, etc.",
                "If you don't care about which error to raise, you could use assert to raise an AssertionError:The assert keyword raises an AssertionError if the condition is False. In this case, we specified False directly, so it raises the error, but to have it have a text we want it to raise to, we add a comma and specify the error text we want. In this case, I wrote Manually raised error and this raises it with that text.",
                "You should learn the raise statement of Python for that.It should be kept inside the try block.Example -",
                "If you don\u2019t care about the raised exception, do:The good old division by 0."
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I print colored text to the terminal?",
                "How do I output colored text to the terminal in Python?"
            ],
            "url": "https://stackoverflow.com/questions/287871",
            "answer": [
                "This somewhat depends on what platform you are on. The most common way to do this is by printing ANSI escape sequences. For a simple example, here's some Python code from the Blender build scripts:To use code like this, you can do something like:Or, with Python 3.6+:This will work on unixes including OS X, Linux and Windows (provided you use ANSICON, or in Windows 10 provided you enable VT100 emulation). There are ANSI codes for setting the color, moving the cursor, and more.If you are going to get complicated with this (and it sounds like you are if you are writing a game), you should look into the \"curses\" module, which handles a lot of the complicated parts of this for you. The Python Curses HowTO is a good introduction.If you are not using extended ASCII (i.e., not on a PC), you are stuck with the ASCII characters below 127, and '#' or '@' is probably your best bet for a block. If you can ensure your terminal is using a IBM extended ASCII character set, you have many more options. Characters 176, 177, 178 and 219 are the \"block characters\".Some modern text-based programs, such as \"Dwarf Fortress\", emulate text mode in a graphical mode, and use images of the classic PC font. You can find some of these bitmaps that you can use on the Dwarf Fortress Wiki see (user-made tilesets).The Text Mode Demo Contest has more resources for doing graphics in text mode.",
                "There is also the Python termcolor module. Usage is pretty simple:Or in Python 3:It may not be sophisticated enough, however, for game programming and the \"colored blocks\" that you want to do...To get the ANSI codes working on windows, first run",
                "The answer is Colorama for all cross-platform coloring in Python.It supports Python 3.5+ as well as Python 2.7.And as of January 2021 it is maintained.Example Code:Example Screenshot:",
                "Print a string that starts a color/style, then the string, and then end the color/style change with '\\x1b[0m':Get a table of format options for shell text with the following code:Reference: https://en.wikipedia.org/wiki/ANSI_escape_code#Colors",
                "Define a string that starts a color and a string that ends the color. Then print your text with the start string at the front and the end string at the end.This produces the following in Bash, in urxvt with a Zenburn-style color scheme:Through experimentation, we can get more colors:Note: \\33[5m and \\33[6m are blinking.This way we can create a full color collection:Here is the code to generate the test:",
                "Here's a solution that works on Windows 10 natively.Using a system call, such as os.system(\"\"), allows colours to be printed in Command Prompt and Powershell natively:Note: Windows does not fully support ANSI codes, whether through system calls or modules. Not all text decoration is supported, and although the bright colours display, they are identical to the regular colours.Thanks to @j-l for finding an even shorter method.tl;dr: Add os.system(\"\")",
                "You want to learn about ANSI escape sequences. Here's a brief example:For more information, see ANSI escape code.For a block character, try a Unicode character like \\u2588:Putting it all together:",
                "sty is similar to colorama, but it's less verbose, supports 8-bit and 24-bit (RGB) colors, supports all effects (bold, underline, etc.), allows you to register your own styles, is fully typed and high performant, supports muting, is not messing with globals such as sys.stdout, is really flexible, well documented and more...Examples:prints:Demo:",
                "Rich is a relatively new Python library for working with color in the terminal.There are a few ways of working with color in Rich. The quickest way to get started would be the rich print method which renders a BBCode-like syntax in to ANSI control codes:There are other ways of applying color with Rich (regex, syntax) and related formatting features.",
                "My favorite way is with the Blessings library (full disclosure: I wrote it). For example:To print colored bricks, the most reliable way is to print spaces with background colors. I use this technique to draw the progress bar in nose-progressive:You can print in specific locations as well:If you have to muck with other terminal capabilities in the course of your game, you can do that as well. You can use Python's standard string formatting to keep it readable:The nice thing about Blessings is that it does its best to work on all sorts of terminals, not just the (overwhelmingly common) ANSI-color ones. It also keeps unreadable escape sequences out of your code while remaining concise to use. Have fun!",
                "I generated a class with all the colors using a for loop to iterate every combination of color up to 100, and then wrote a class with Python colors. Copy and paste as you will, GPLv2 by me:",
                "This is, in my opinion, the easiest method. As long as you have the RGB values of the color you want, this should work:An example of printing red text:Multi-colored text",
                "Try this simple codePython 3 Example",
                "Try it online",
                "I have a library called colorit. It is super simple.Here are some examples:This gives you:It's also worth noting that this is cross platform and has been tested on Mac, Linux, and Windows.You might want to try it out: https://github.com/SuperMaZingCoder/coloritcolorit is now available to be installed with PyPi! You can install it with pip install color-it on Windows and pip3 install color-it on macOS and Linux.",
                "On Windows you can use module 'win32console' (available in some Python distributions) or module 'ctypes' (Python 2.5 and up) to access the Win32 API.To see complete code that supports both ways, see the color console reporting code from Testoob.ctypes example:",
                "I have wrapped joeld's answer into a module with global functions that I can use anywhere in my code.File: log.pyUse as follows:",
                "Try online",
                "Here is my modern (2021) solution: yachalkIt is one of the few libraries that properly supports nested styles:Apart from that yachalk is auto-complete-friendly, has 256/truecolor support, comes with terminal-capability detection, and is fully typed.Here are some design decision you may consider for choosing your solution.Many answers to this question demonstrate how to ANSI escape codes directly, or suggest low-level libraries that require manual style enabling/disabling.These approaches have subtle issues: Inserting on/off styles manually isTherefore if compatibility with many terminals is a goal, it's best to use a high-level library that offers automatic handling of style resets. This allows the library to take care of all edge cases by inserting the \"spurious\" ANSI escape codes where needed.In JavaScript the de-facto standard library for the task is chalk, and after using it for a while in JS projects, the solutions available in the Python world were lacking in comparison. Not only is the chalk API more convenient to use (fully auto-complete compatible), it also gets all the edge cases right.The idea of yachalk is to bring the same convenience to the Python ecosystem. If you're interested in a comparison to other libraries I've started feature comparison on the projects page. In addition, here is a long (but still incomplete) list of alternatives that came up during my research -- a lot to choose from :)",
                "I ended up doing this, and I felt it was cleanest:",
                "For Windows you cannot print to console with colors unless you're using the Win32 API.For Linux it's as simple as using print, with the escape sequences outlined here:ColorsFor the character to print like a box, it really depends on what font you are using for the console window. The pound symbol works well, but it depends on the font:",
                "Stupidly simple, based on joeld's answer:Then just",
                "Building on joeld's answer, using https://pypi.python.org/pypi/lazyme \npip install -U lazyme:Screenshot:Some updates to the color_print with new formatters, e.g.:Note: italic, fast blinking, and strikethrough may not work on all terminals, and they don't work on Mac and Ubuntu.E.g.,Screenshot:",
                "Note how well the with keyword mixes with modifiers like these that need to be reset (using Python 3 and Colorama):",
                "You could use Clint:",
                "You can use the Python implementation of the curses library:\ncurses \u2014 Terminal handling for character-cell displaysAlso, run this and you'll find your box:",
                "You can use colors for text as others mentioned in their answers to have colorful text with a background or foreground color.But you can use emojis instead! for example, you can use\u26a0\ufe0f for warning messages and \ud83d\uded1 for error messages.Or simply use these notebooks as a color:This method also helps you to quickly scan and find logs directly in the source code.But some operating systems (including some Linux distributions in some version with some window managers) default emoji font is not colorful by default and you may want to make them colorful, first.mac os: control + command + spacewindows: win + .linux: control + . or  control + ;",
                "If you are programming a game perhaps you would like to change the background color and use only spaces? For example:",
                "An easier option would be to use the cprint function from the termcolor package.It also supports %s, %d format of printing:Results can be terminal dependant, so review the Terminal Properties section of the package documentation.",
                "While I find this answer useful, I modified it a bit. This GitHub Gist is the resultIn addition, you can wrap common usages:"
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I split a list into equally-sized chunks?",
                "How do I split a list of arbitrary length into equal sized chunks?\n\nSee How to iterate over a list in chunks if the data result will be used directly for a loop, and does not need to be stored.\nFor ..."
            ],
            "url": "https://stackoverflow.com/questions/312443",
            "answer": [
                "Here's a generator that yields evenly-sized chunks:For Python 2, using xrange instead of range:Below is a list comprehension one-liner. The method above is preferable, though, since using named functions makes code easier to understand. For Python 3:For Python 2:",
                "Something super simple:For Python 2, use xrange() instead of range().",
                "I know this is kind of old but nobody yet mentioned numpy.array_split:Result:",
                "Directly from the (old) Python documentation (recipes for itertools):The current version, as suggested by J.F.Sebastian:I guess Guido's time machine works\u2014worked\u2014will work\u2014will have worked\u2014was working again.These solutions work because [iter(iterable)]*n (or the equivalent in the earlier version) creates one iterator, repeated n times in the list. izip_longest then effectively performs a round-robin of \"each\" iterator; because this is the same iterator, it is advanced by each such call, resulting in each such zip-roundrobin generating one tuple of n items.",
                "I'm surprised nobody has thought of using iter's two-argument form:Demo:This works with any iterable and produces output lazily. It returns tuples rather than iterators, but I think it has a certain elegance nonetheless. It also doesn't pad; if you want padding, a simple variation on the above will suffice:Demo:Like the izip_longest-based solutions, the above always pads. As far as I know, there's no one- or two-line itertools recipe for a function that optionally pads. By combining the above two approaches, this one comes pretty close:Demo:I believe this is the shortest chunker proposed that offers optional padding.As Tomasz Gandor observed, the two padding chunkers will stop unexpectedly if they encounter a long sequence of pad values. Here's a final variation that works around that problem in a reasonable way:Demo:",
                "Here is a generator that work on arbitrary iterables:Example:",
                "Simple yet elegantor if you prefer:",
                "Don't reinvent the wheel.UPDATE: The upcoming Python 3.12 introduces itertools.batched, which solves this problem at last.  See below.GivenCodeitertools.batched++more_itertools+(or DIY, if you want)The Standard LibraryReferences+ A third-party library that implements itertools recipes and more. > pip install more_itertools++Included in Python Standard Library 3.12+.  batched is similar to more_itertools.chunked.",
                "\"Evenly sized chunks\", to me, implies that they are all the same length, or barring that option, at minimal variance in length. E.g. 5 baskets for 21 items could have the following results:A practical reason to prefer the latter result: if you were using these functions to distribute work, you've built-in the prospect of one likely finishing well before the others, so it would sit around doing nothing while the others continued working hard.When I originally wrote this answer, none of the other answers were evenly sized chunks - they all leave a runt chunk at the end, so they're not well balanced, and have a higher than necessary variance of lengths.For example, the current top answer ends with:Others, like list(grouper(3, range(7))), and chunk(range(7), 3) both return: [(0, 1, 2), (3, 4, 5), (6, None, None)]. The None's are just padding, and rather inelegant in my opinion. They are NOT evenly chunking the iterables.Why can't we divide these better?A high-level balanced solution using itertools.cycle, which is the way I might do it today. Here's the setup:Now we need our lists into which to populate the elements:Finally, we zip the elements we're going to allocate together with a cycle of the baskets until we run out of elements, which, semantically, it exactly what we want:Here's the result:To productionize this solution, we write a function, and provide the type annotations:In the above, we take our list of items, and the max number of baskets. We create a list of empty lists, in which to append each element, in a round-robin style.Another elegant solution is to use slices - specifically the less-commonly used step argument to slices. i.e.:This is especially elegant in that slices don't care how long the data are - the result, our first basket, is only as long as it needs to be. We'll only need to increment the starting point for each basket.In fact this could be a one-liner, but we'll go multiline for readability and to avoid an overlong line of code:And islice from the itertools module will provide a lazily iterating approach, like that which was originally asked for in the question.I don't expect most use-cases to benefit very much, as the original data is already fully materialized in a list, but for large datasets, it could save nearly half the memory usage.View results with:Here's another balanced solution, adapted from a function I've used in production in the past, that uses the modulo operator:And I created a generator that does the same if you put it into a list:And finally, since I see that all of the above functions return elements in a contiguous order (as they were given):To test them out:Which prints out:Notice that the contiguous generator provide chunks in the same length patterns as the other two, but the items are all in order, and they are as evenly divided as one may divide a list of discrete elements.",
                "If you know list size:If you don't (an iterator):In the latter case, it can be rephrased in a more beautiful way if you can be sure that the sequence always contains a whole number of chunks of given size (i.e. there is no incomplete last chunk).",
                "I saw the most awesome Python-ish answer in a duplicate of this question:You can create n-tuple for any n. If a = range(1, 15), then the result will be:If the list is divided evenly, then you can replace zip_longest with zip, otherwise the triplet (13, 14, None) would be lost. Python 3 is used above. For Python 2, use izip_longest.",
                "Where AA is array, SS is chunk size. For example:To expand the ranges in py3 do",
                "With Assignment Expressions in Python 3.8 it becomes quite nice:This works on an arbitrary iterable, not just a list.UPDATEStarting with Python 3.12, this exact implementation is available as itertools.batched",
                "If you had a chunk size of 3 for example, you could do:source:\nhttp://code.activestate.com/recipes/303060-group-a-list-into-sequential-n-tuples/I would use this when my chunk size is fixed number I can type, e.g. '3', and would never change.",
                "The toolz library has the partition function for this:",
                "I was curious about the performance of different approaches and here it is:Tested on Python 3.5.1Results:",
                "You may also use get_chunks function of utilspie library as:You can install utilspie via pip:Disclaimer: I am the creator of utilspie library.",
                "I like the Python doc's version proposed by tzot and J.F.Sebastian a lot,\n but it has two shortcomings:I'm using this one a lot in my code:UPDATE: A lazy chunks version:",
                "code:result:",
                "heh, one line version",
                "Another more explicit version.",
                "At this point, I think we need a recursive generator, just in case...In python 2:In python 3:Also, in case of massive Alien invasion, a decorated recursive generator might become handy:",
                "Without calling len() which is good for large lists:And this is for iterables:The functional flavour of the above:OR:OR:",
                "usage:",
                "See this referencePython3",
                "Since everybody here talking about iterators. boltons has perfect method for that, called iterutils.chunked_iter.Output:But if you don't want to be mercy on memory, you can use old-way and store the full list in the first place with iterutils.chunked.",
                "Consider using matplotlib.cbook piecesfor example:"
            ]
        },
        {
            "tag": "python",
            "question": [
                "How can I access environment variables in Python?",
                "How can I get the value of an environment variable in Python?"
            ],
            "url": "https://stackoverflow.com/questions/4906977",
            "answer": [
                "Environment variables are accessed through os.environ:To see a list of all environment variables:If a key is not present, attempting to access it will raise a KeyError. To avoid this:",
                "To check if the key exists (returns True or False)You can also use get() when printing the key; useful if you want to use a default.where /home/username/ is the default",
                "Actually it can be done this way:Or simply:For viewing the value in the parameter:Or:To set the value:",
                "Here's how to check if $FOO is set:",
                "You can access the environment variables usingTry to see the content of the PYTHONPATH or PYTHONHOME environment variables. Maybe this will be helpful for your second question.",
                "As for the environment variables:",
                "That will print all of the environment variables along with their values.",
                "Import the os module:To get an environment variable:To set an environment variable:",
                "If you are planning to use the code in a production web application code, using any web framework like Django and Flask, use projects like envparse. Using it, you can read the value as your defined type.NOTE: kennethreitz's autoenv is a recommended tool for making project-specific environment variables. For those who are using autoenv, please note to keep the .env file private (inaccessible to public).",
                "There are also a number of great libraries. Envs, for example, will allow you to parse objects out of your environment variables, which is rad. For example:",
                "You can also try this:First, install python-decoupleImport it in your fileThen get the environment variableRead more about the Python library here.",
                "Edited - October 2021Following @Peter's comment, here's how you can test it:main.pyIf this is true ... It's 1500x faster to use a dict() instead of accessing environ directly.A performance-driven approach - calling environ is expensive, so it's better to call it once and save it to a dictionary. Full example:P.S- if you worry about exposing private environment variables, then sanitize env_dict after the assignment.",
                "For Django, see Django-environ.",
                "You should first import os usingand then actually print the environment variable valueof course, replace yourvariable as the variable you want to access.",
                "The tricky part of using nested for-loops in one-liners is that you have to use list comprehension. So in order to print all your environment variables, without having to import a foreign library, you can use:"
            ]
        },
        {
            "tag": "python",
            "question": [
                "Convert string \"Jun 1 2005 1:33PM\" into datetime",
                "How do I convert the following string to a datetime object?\n\"Jun 1 2005  1:33PM\""
            ],
            "url": "https://stackoverflow.com/questions/466345",
            "answer": [
                "datetime.strptime parses an input string in the user-specified format into a timezone-naive datetime object:To obtain a date object using an existing datetime object, convert it using .date():Links:strptime docs: Python 2, Python 3strptime/strftime format string docs: Python 2, Python 3strftime.org format string cheatsheetNotes:",
                "Use the third-party dateutil library:It can handle most date formats and is more convenient than strptime since it usually guesses the correct format. It is also very useful for writing tests, where readability is more important than performance.Install it with:",
                "Check out strptime in the time module.  It is the inverse of strftime.",
                "To convert a YYYY-MM-DD string to a datetime object, datetime.fromisoformat could be used.Caution from the documentation:This does not support parsing arbitrary ISO 8601 strings - it is only intended as the inverse operation of datetime.isoformat(). A more full-featured ISO 8601 parser, dateutil.parser.isoparse is available in the third-party package dateutil.",
                "I have put together a project that can convert some really neat expressions. Check out timestring.",
                "Remember this and you didn't need to get confused in datetime conversion again.String to datetime object = strptimedatetime object to other formats = strftimeJun 1 2005  1:33PMis equals to%b %d %Y %I:%M%p%b    Month as locale\u2019s abbreviated name(Jun)%d    Day of the month as a zero-padded decimal number(1)%Y    Year with century as a decimal number(2015)%I    Hour (12-hour clock) as a zero-padded decimal number(01)%M    Minute as a zero-padded decimal number(33)%p    Locale\u2019s equivalent of either AM or PM(PM)so you need strptime i-e converting string toOutputWhat if you have different format of dates you can use panda or dateutil.parseOutPut",
                "Many timestamps have an implied timezone. To ensure that your code will work in every timezone, you should use UTC internally and attach a timezone each time a foreign object enters the system.Python 3.2+:This assumes you know the offset. If you don't, but you know e.g. the location, you can use the pytz package to query the IANA time zone database for the offset. I'll use Tehran here as an example because it has a half-hour offset:As you can see, pytz has determined that the offset was +3:30 at that particular date. You can now convert this to UTC time, and it will apply the offset:Note that dates before the adoption of timezones will give you weird offsets. This is because the IANA has decided to use Local Mean Time:The weird \"7 hours and 34 minutes\" are derived from the longitude of Chicago. I used this timestamp because it is right before standardized time was adopted in Chicago.",
                "If your string is in ISO 8601 format and you have Python 3.7+, you can use the following simple code:for dates andfor strings containing date and time. If timestamps are included, the function datetime.datetime.isoformat() supports the following format:Where * matches any single character. See also here and here.",
                "Here are two solutions using Pandas to convert dates formatted as strings into datetime.date objects.TimingsAnd here is how to convert the OP's original date-time examples:There are many options for converting from the strings to Pandas Timestamps using to_datetime, so check the docs if you need anything special.Likewise, Timestamps have many properties and methods that can be accessed in addition to .date",
                "I personally like the solution using the parser module, which is the second answer to this question and is beautiful, as you don't have to construct any string literals to get it working. But, one downside is that it is 90% slower than the accepted answer with strptime.Output:10.70296801342902 \n1.3627995655316933As long as you are not doing this a million times over and over again, I still think the parser method is more convenient and will handle most of the time formats automatically.",
                "Something that isn't mentioned here and is useful: adding a suffix to the day. I decoupled the suffix logic so you can use it for any number you like, not just dates.",
                "Django Timezone aware datetime object example.This conversion is very important for Django and Python when you have USE_TZ = True:",
                "Create a small utility function like:This is versatile enough:",
                "This would be helpful for converting a string to datetime and also with a time zone:",
                "arrow offers many useful functions for dates and times. This bit of code provides an answer to the question and shows that arrow is also capable of formatting dates easily and displaying information for other locales.See http://arrow.readthedocs.io/en/latest/ for more.",
                "You can also check out dateparser:dateparser provides modules to easily parse localized dates in almost\nany string formats commonly found on web pages.Install:This is, I think, the easiest way you can parse dates.The most straightforward way is to use the dateparser.parse function,\nthat wraps around most of the functionality in the module.Sample code:Output:",
                "You can use easy_date to make it easy:",
                "If you want only date format then you can manually convert it by passing your individual fields like:You can pass your split string values to convert it into date type like:You will get the resulting value in date format.",
                "Similar to Javed's answer, I just wanted date from string - so combining Simon's and Javed's logic, we get:Outputdatetime.date(2021, 3, 4)",
                "It seems using pandas Timestamp is the fastest:If the string is an ISO\u00a08601 string, please use csio8601:",
                "If you don't want to explicitly specify which format your string is in with respect to the date time format, you can use this hack to by pass that step:If you want to convert it into some other datetime format, just modify the last line with the format you like for example something like date.strftime('%Y/%m/%d %H:%M:%S.%f'):Try running the above snippet to have a better clarity.",
                "See my answer.In real-world data this is a real problem: multiple, mismatched, incomplete, inconsistent and multilanguage/region date formats, often mixed freely in one dataset. It's not ok for production code to fail, let alone go exception-happy like a fox.We need to try...catch multiple datetime formats fmt1,fmt2,...,fmtn and suppress/handle the exceptions (from strptime()) for all those that mismatch (and in particular, avoid needing a yukky n-deep indented ladder of try..catch clauses). From my solution",
                "A short sample mapping a yyyy-mm-dd date string to a datetime.date object:",
                "Use:It shows \"Start Date Time\" Column and \"Last Login Time\" both are \"object = strings\" in data-frame:By using the parse_dates option in read_csv mention, you can convert your string datetime into the pandas datetime format.Output:"
            ]
        },
        {
            "tag": "python",
            "question": [
                "Why is \"1000000000000000 in range(1000000000000001)\" so fast in Python 3?",
                "It is my understanding that the range() function, which is actually an object type in Python 3, generates its contents on the fly, similar to a generator.\nThis being the case, I would have expected ..."
            ],
            "url": "https://stackoverflow.com/questions/30081275",
            "answer": [
                "The Python 3 range() object doesn't produce numbers immediately; it is a smart sequence object that produces numbers on demand. All it contains is your start, stop and step values, then as you iterate over the object the next integer is calculated each iteration.The object also implements the object.__contains__ hook, and calculates if your number is part of its range. Calculating is a (near) constant time operation *. There is never a need to scan through all possible integers in the range.From the range() object documentation:The advantage of the range type over a regular list or tuple is that a range object will always take the same (small) amount of memory, no matter the size of the range it represents (as it only stores the start, stop and step values, calculating individual items and subranges as needed).So at a minimum, your range() object would do:This is still missing several things that a real range() supports (such as the .index() or .count() methods, hashing, equality testing, or slicing), but should give you an idea.I also simplified the __contains__ implementation to only focus on integer tests; if you give a real range() object a non-integer value (including subclasses of int), a slow scan is initiated to see if there is a match, just as if you use a containment test against a list of all the contained values. This was done to continue to support other numeric types that just happen to support equality testing with integers but are not expected to support integer arithmetic as well. See the original Python issue that implemented the containment test.* Near constant time because Python integers are unbounded and so math operations also grow in time as N grows, making this a O(log N) operation. Since it\u2019s all executed in optimised C code and Python stores integer values in 30-bit chunks, you\u2019d run out of memory before you saw any performance impact due to the size of the integers involved here.",
                "The fundamental misunderstanding here is in thinking that range is a generator. It's not. In fact, it's not any kind of iterator.You can tell this pretty easily:If it were a generator, iterating it once would exhaust it:What range actually is, is a sequence, just like a list. You can even test this:This means it has to follow all the rules of being a sequence:The difference between a range and a list is that a range is a lazy or dynamic sequence; it doesn't remember all of its values, it just remembers its start, stop, and step, and creates the values on demand on __getitem__.(As a side note, if you print(iter(a)), you'll notice that range uses the same listiterator type as list. How does that work? A listiterator doesn't use anything special about list except for the fact that it provides a C implementation of __getitem__, so it works fine for range too.)Now, there's nothing that says that Sequence.__contains__ has to be constant time\u2014in fact, for obvious examples of sequences like list, it isn't. But there's nothing that says it can't be. And it's easier to implement range.__contains__ to just check it mathematically ((val - start) % step, but with some extra complexity to deal with negative steps) than to actually generate and test all the values, so why shouldn't it do it the better way?But there doesn't seem to be anything in the language that guarantees this will happen. As Ashwini Chaudhari points out, if you give it a non-integral value, instead of converting to integer and doing the mathematical test, it will fall back to iterating all the values and comparing them one by one. And just because CPython 3.2+ and PyPy 3.x versions happen to contain this optimization, and it's an obvious good idea and easy to do, there's no reason that IronPython or NewKickAssPython 3.x couldn't leave it out. (And in fact, CPython 3.0-3.1 didn't include it.)If range actually were a generator, like my_crappy_range, then it wouldn't make sense to test __contains__ this way, or at least the way it makes sense wouldn't be obvious. If you'd already iterated the first 3 values, is 1 still in the generator? Should testing for 1 cause it to iterate and consume all the values up to 1 (or up to the first value >= 1)?",
                "Use the source, Luke!In CPython, range(...).__contains__ (a method wrapper) will eventually delegate to a simple calculation which checks if the value can possibly be in the range.  The reason for the speed here is we're using mathematical reasoning about the bounds, rather than a direct iteration of the range object.  To explain the logic used:For example, 994 is in range(4, 1000, 2) because:The full C code is included below, which is a bit more verbose because of memory management and reference counting details, but the basic idea is there:The \"meat\" of the idea is mentioned in the comment lines:As a final note - look at the range_contains function at the bottom of the code snippet.  If the exact type check fails then we don't use the clever algorithm described, instead falling back to a dumb iteration search of the range using _PySequence_IterSearch!  You can check this behaviour in the interpreter (I'm using v3.5.0 here):",
                "To add to Martijn\u2019s answer, this is the relevant part of the source (in C, as the range object is written in native code):So for PyLong objects (which is int in Python 3), it will use the range_contains_long function to determine the result. And that function essentially checks if ob is in the specified range (although it looks a bit more complex in C).If it\u2019s not an int object, it falls back to iterating until it finds the value (or not).The whole logic could be translated to pseudo-Python like this:",
                "If you're wondering why this optimization was added to range.__contains__, and why it wasn't added to xrange.__contains__ in 2.7:First, as Ashwini Chaudhary discovered, issue 1766304 was opened explicitly to optimize [x]range.__contains__. A patch for this was accepted and checked in for 3.2, but not backported to 2.7 because \"xrange has behaved like this for such a long time that I don't see what it buys us to commit the patch this late.\" (2.7 was nearly out at that point.)Meanwhile:Originally, xrange was a not-quite-sequence object. As the 3.1 docs say:Range objects have very little behavior: they only support indexing, iteration, and the len function.This wasn't quite true; an xrange object actually supported a few other things that come automatically with indexing and len,* including __contains__ (via linear search). But nobody thought it was worth making them full sequences at the time.Then, as part of implementing the Abstract Base Classes PEP, it was important to figure out which builtin types should be marked as implementing which ABCs, and xrange/range claimed to implement collections.Sequence, even though it still only handled the same \"very little behavior\". Nobody noticed that problem until issue 9213. The patch for that issue not only added index and count to 3.2's range, it also re-worked the optimized __contains__ (which shares the same math with index, and is directly used by count).** This change went in for 3.2 as well, and was not backported to 2.x, because \"it's a bugfix that adds new methods\". (At this point, 2.7 was already past rc status.)So, there were two chances to get this optimization backported to 2.7, but they were both rejected.* In fact, you even get iteration for free with indexing alone, but in 2.3 xrange objects got a custom iterator.** The first version actually reimplemented it, and got the details wrong\u2014e.g., it would give you MyIntSubclass(2) in range(5) == False. But Daniel Stutzbach's updated version of the patch restored most of the previous code, including the fallback to the generic, slow _PySequence_IterSearch that pre-3.2 range.__contains__ was implicitly using when the optimization doesn't apply.",
                "The other answers explained it well already, but I'd like to offer another experiment illustrating the nature of range objects:As you can see, a range object is an object that remembers its range and can be used many times (even while iterating over it), not just a one-time generator.",
                "It's all about a lazy approach to the evaluation and some extra optimization of range.\nValues in ranges don't need to be computed until real use, or even further due to extra optimization.By the way, your integer is not such big, consider sys.maxsizesys.maxsize in range(sys.maxsize) is pretty fastdue to optimization - it's easy to compare given integers just with min and max of range.but:Decimal(sys.maxsize) in range(sys.maxsize) is pretty slow.(in this case, there is no optimization in range, so if python receives unexpected Decimal, python will compare all numbers)You should be aware of an implementation detail but should not be relied upon, because this may change in the future.",
                "The object returned by range() is actually a range object. This object implements the iterator interface so you can iterate over its values sequentially, just like a generator, list, or tuple.But it also implements the __contains__ interface which is actually what gets called when an object appears on the right-hand side of the in operator. The __contains__() method returns a bool of whether or not the item on the left-hand side of the in is in the object. Since range objects know their bounds and stride, this is very easy to implement in O(1).",
                "Take an example, 997 is in range(4, 1000, 3) because:4 <= 997 < 1000, and (997 - 4) % 3 == 0.",
                "Try x-1 in (i for i in range(x)) for large x values, which uses a generator comprehension to avoid invoking the range.__contains__ optimisation.",
                "TLDR;\nthe range is an arithmetic series so it can very easily calculate whether the object is there. It could even get the index of it if it were list like really quickly.",
                "__contains__ method compares directly with the start and end of the range"
            ]
        },
        {
            "tag": "python",
            "question": [
                "Find the current directory and file's directory [duplicate]",
                "How do I determine:\n\nthe current directory (where I was in the shell when I ran the Python script), and\nwhere the Python file I am executing is?"
            ],
            "url": "https://stackoverflow.com/questions/5137497",
            "answer": [
                "To get the full path to the directory a Python file is contained in, write this in that file:(Note that the incantation above won't work if you've already used os.chdir() to change your current working directory, since the value of the __file__ constant is relative to the current working directory and is not changed by an os.chdir() call.)To get the current working directory useDocumentation references for the modules, constants and functions used above:",
                "Current working directory:  os.getcwd()And the __file__ attribute can help you find out where the file you are executing is located. This Stack\u00a0Overflow post explains everything:  How do I get the path of the current executed file in Python?",
                "You may find this useful as a reference:",
                "The pathlib module, introduced in Python 3.4 (PEP 428 \u2014 The pathlib module \u2014 object-oriented filesystem paths), makes the path-related experience much much better.In order to get the current working directory, use Path.cwd():To get an absolute path to your script file, use the Path.resolve() method:And to get the path of a directory where your script is located, access .parent (it is recommended to call .resolve() before .parent):Remember that __file__ is not reliable in some situations: How do I get the path of the current executed file in Python?.Please note, that Path.cwd(), Path.resolve() and other Path methods return path objects (PosixPath in my case), not strings. In Python 3.4 and 3.5 that caused some pain, because open built-in function could only work with string or bytes objects, and did not support Path objects, so you had to convert Path objects to strings or use the Path.open() method, but the latter option required you to change old code:As you can see, open(p) does not work with Python 3.5.PEP 519 \u2014 Adding a file system path protocol, implemented in Python 3.6, adds support of PathLike objects to the open function, so now you can pass Path objects to the open function directly:",
                "To get the current directory full pathOutput: \"C :\\Users\\admin\\myfolder\"To get the current directory folder name aloneOutput: \"myfolder\"",
                "Pathlib can be used this way to get the directory containing the current script:",
                "If you are trying to find the current directory of the file you are currently in:OS agnostic way:",
                "If you're using Python 3.4, there is the brand new higher-level pathlib module which allows you to conveniently call pathlib.Path.cwd() to get a Path object representing your current working directory, along with many other new features.More info on this new API can be found here.",
                "To get the current directory full path:",
                "Answer to #1:If you want the current directory, do this:If you want just any folder name and you have the path to that folder, do this:Answer to #2:",
                "I think the most succinct way to find just the name of your current execution context would be:",
                "If you're searching for the location of the currently executed script, you can use sys.argv[0] to get the full path.",
                "For question 1, use os.getcwd() # Get working directory and os.chdir(r'D:\\Steam\\steamapps\\common') # Set working directoryI recommend using sys.argv[0] for question 2 because sys.argv is immutable and therefore always returns the current file (module object path) and not affected by os.chdir(). Also you can do like this:But that snippet and sys.argv[0] will not work or will work weird when compiled by PyInstaller, because magic properties are not set in __main__ level and sys.argv[0] is the way your executable was called (it means that it becomes affected by the working directory)."
            ]
        },
        {
            "tag": "python",
            "question": [
                "Renaming column names in Pandas",
                "I want to change the column labels of a Pandas DataFrame from\n['$a', '$b', '$c', '$d', '$e']\n\nto\n['a', 'b', 'c', 'd', 'e']"
            ],
            "url": "https://stackoverflow.com/questions/11346283",
            "answer": [
                "Use the df.rename() function and refer the columns to be renamed. Not all the columns have to be renamed:Minimal Code ExampleThe following methods all work and produce the same output:Remember to assign the result back, as the modification is not-inplace. Alternatively, specify inplace=True:From v0.25, you can also specify errors='raise' to raise errors if an invalid column-to-rename is specified. See v0.25 rename() docs.Use df.set_axis() with axis=1 and inplace=False (to return a copy).This returns a copy, but you can modify the DataFrame in-place by setting inplace=True (this is the default behaviour for versions <=0.24 but is likely to change in the future).You can also assign headers directly:",
                "Just assign it to the .columns attribute:",
                "The rename method can take a function, for example:",
                "As documented in Working with text data:",
                "There have been some significant updates to column renaming in version 0.21.Construct sample DataFrame:orBoth result in the following:It is still possible to use the old method signature:The rename function also accepts functions that will be applied to each column name.orYou can supply a list to the set_axis method that is equal in length to the number of columns (or index). Currently, inplace defaults to True, but inplace will be defaulted to False in future releases.orThere is nothing wrong with assigning columns directly like this. It is a perfectly good solution.The advantage of using set_axis is that it can be used as part of a method chain and that it returns a new copy of the DataFrame. Without it, you would have to store your intermediate steps of the chain to another variable before reassigning the columns.",
                "Since you only want to remove the $ sign in all column names, you could just do:OR",
                "Renaming columns in Pandas is an easy task.",
                "It will replace the existing names with the names you provide, in the order you provide.",
                "Use:This way you can manually edit the new_names as you wish. It works great when you need to rename only a few columns to correct misspellings, accents, remove special characters, etc.",
                "I'll focus on two things:OP clearly statesI have the edited column names stored it in a list, but I don't know how to replace the column names.I do not want to solve the problem of how to replace '$' or strip the first character off of each column header.  OP has already done this step.  Instead I want to focus on replacing the existing columns object with a new one given a list of replacement column names.df.columns = new where new is the list of new columns names is as simple as it gets.  The drawback of this approach is that it requires editing the existing dataframe's columns attribute and it isn't done inline.  I'll show a few ways to perform this via pipelining without editing the existing dataframe.Setup 1\nTo focus on the need to rename of replace column names with a pre-existing list, I'll create a new sample dataframe df with initial column names and unrelated new column names.Solution 1\npd.DataFrame.renameIt has been said already that if you had a dictionary mapping the old column names to new column names, you could use pd.DataFrame.rename.However, you can easily create that dictionary and include it in the call to rename.  The following takes advantage of the fact that when iterating over df, we iterate over each column name.This works great if your original column names are unique.  But if they are not, then this breaks down.Setup 2\nNon-unique columnsSolution 2\npd.concat using the keys argumentFirst, notice what happens when we attempt to use solution 1:We didn't map the new list as the column names.  We ended up repeating y765.  Instead, we can use the keys argument of the pd.concat function while iterating through the columns of df.Solution 3\nReconstruct.  This should only be used if you have a single dtype for all columns.  Otherwise, you'll end up with dtype object for all columns and converting them back requires more dictionary work.Single dtypeMixed dtypeSolution 4\nThis is a gimmicky trick with transpose and set_index.  pd.DataFrame.set_index allows us to set an index inline, but there is no corresponding set_columns.  So we can transpose, then set_index, and transpose back.  However, the same single dtype versus mixed dtype caveat from solution 3 applies here.Single dtypeMixed dtypeSolution 5\nUse a lambda in pd.DataFrame.rename that cycles through each element of new.\nIn this solution, we pass a lambda that takes x but then ignores it.  It also takes a y but doesn't expect it.  Instead, an iterator is given as a default value and I can then use that to cycle through one at a time without regard to what the value of x is.And as pointed out to me by the folks in sopython chat, if I add a * in between x and y, I can protect my y variable.  Though, in this context I don't believe it needs protecting.  It is still worth mentioning.",
                "I would like to explain a bit what happens behind the scenes.Dataframes are a set of Series.Series in turn are an extension of a numpy.array.numpy.arrays have a property .name.This is the name of the series. It is seldom that Pandas respects this attribute, but it lingers in places and can be used to hack some Pandas behaviors.A lot of answers here talks about the df.columns attribute being a list when in fact it is a Series. This means it has a .name attribute.This is what happens if you decide to fill in the name of the columns Series:Note that the name of the index always comes one column lower.The .name attribute lingers on sometimes. If you set df.columns = ['one', 'two'] then the df.one.name will be 'one'.If you set df.one.name = 'three' then df.columns will still give you ['one', 'two'], and df.one.name will give you 'three'.pd.DataFrame(df.one) will returnBecause Pandas reuses the .name of the already defined Series.Pandas has ways of doing multi-layered column names. There is not so much magic involved, but I wanted to cover this in my answer too since I don't see anyone picking up on this here.This is easily achievable by setting columns to lists, like this:",
                "Let's understand renaming by a small example...Renaming columns using mapping:Renaming index/Row_Name using mapping:",
                "Many of pandas functions have an inplace parameter. When setting it True, the transformation applies directly to the dataframe that you are calling it on. For example:Alternatively, there are cases where you want to preserve the original dataframe. I have often seen people fall into this case if creating the dataframe is an expensive task. For example, if creating the dataframe required querying a snowflake database. In this case, just make sure the the inplace parameter is set to False.If these types of transformations are something that you do often, you could also look into a number of different pandas GUI tools. I'm the creator of one called Mito. It\u2019s a spreadsheet that automatically converts your edits to python code.",
                "Suppose your dataset name is df, and df has.So, to rename these, we would simply do.",
                "Let's say this is your dataframe.You can rename the columns using two methods.Using dataframe.columns=[#list]The limitation of this method is that if one column has to be changed, full column list has to be passed. Also, this method is not applicable on index labels.\nFor example, if you passed this:This will throw an error. Length mismatch: Expected axis has 5 elements, new values have 4 elements.Another method is the Pandas rename() method which is used to rename any index, column or rowSimilarly, you can change any rows or columns.",
                "If you've got the dataframe, df.columns dumps everything into a list you can manipulate and then reassign into your dataframe as the names of columns...Best way? I don't know. A way - yes.A better way of evaluating all the main techniques put forward in the answers to the question is below using cProfile to gage memory and execution time. @kadee, @kaitlyn, and @eumiro had the functions with the fastest execution times - though these functions are so fast we're comparing the rounding of 0.000 and 0.001 seconds for all the answers. Moral: my answer above likely isn't the 'best' way.",
                "If your new list of columns is in the same order as the existing columns, the assignment is simple:If you had a dictionary keyed on old column names to new column names, you could do the following:If you don't have a list or dictionary mapping, you could strip the leading $ symbol via a list comprehension:",
                "pandas.DataFrame.rename",
                "If you already have a list for the new column names, you can try this:",
                "Another way we could replace the original column labels is by stripping the unwanted characters (here '$') from the original column labels.This could have been done by running a for loop over df.columns and appending the stripped columns to df.columns.Instead, we can do this neatly in a single statement by using list comprehension like below:(strip method in Python strips the given character from beginning and end of the string.)",
                "It is real simple. Just use:And it will assign the column names by the order you put them in.",
                "You could use str.slice for that:",
                "Another option is to rename using a regular expression:",
                "My method is generic wherein you can add additional delimiters by comma separating delimiters= variable and future-proof it.Working Code:Output:",
                "Note that the approaches in previous answers do not work for a MultiIndex. For a MultiIndex, you need to do something like the following:",
                "If you have to deal with loads of columns named by the providing system out of your control, I came up with the following approach that is a combination of a general approach and specific replacements in one go.First create a dictionary from the dataframe column names using regular expressions in order to throw away certain appendixes of column names and then add specific replacements to the dictionary to name core columns as expected later in the receiving database.This is then applied to the dataframe in one go.",
                "If you just want to remove the '$' sign then use the below code",
                "In addition to the solution already provided, you can replace all the columns while you are reading the file. We can use names and header=0 to do that.First, we create a list of the names that we like to use as our column names:In this case, all the column names will be replaced with the names you have in your list.",
                "Here's a nifty little function I like to use to cut down on typing:Here is an example of how it works:"
            ]
        },
        {
            "tag": "python",
            "question": [
                "How can I remove a key from a Python dictionary?",
                "Is there a one-line way of deleting a key from a dictionary without raising a KeyError?\nif 'key' in my_dict:\n    del my_dict['key']"
            ],
            "url": "https://stackoverflow.com/questions/11277432",
            "answer": [
                "To delete a key regardless of whether it is in the dictionary, use the two-argument form of dict.pop():This will return my_dict[key] if key exists in the dictionary, and None otherwise. If the second parameter is not specified (i.e. my_dict.pop('key')) and key does not exist, a KeyError is raised.To delete a key that is guaranteed to exist, you can also use:This will raise a KeyError if the key is not in the dictionary.",
                "Specifically to answer \"is there a one line way of doing this?\"...well, you asked ;-)You should consider, though, that this way of deleting an object from a dict is not atomic\u2014it is possible that 'key' may be in my_dict during the if statement, but may be deleted before del is executed, in which case del will fail with a KeyError.  Given this, it would be safest to either use dict.pop or something along the lines ofwhich, of course, is definitely not a one-liner.",
                "It took me some time to figure out what exactly my_dict.pop(\"key\", None) is doing. So I'll add this as an answer to save others googling time:If key is in the dictionary, remove it and return its value, else\nreturn default. If default is not given and key is not in the\ndictionary, a KeyError is raised.Documentation",
                "del my_dict[key] is slightly faster than my_dict.pop(key) for removing a key from a dictionary when the key existsBut when the key doesn't exist if key in my_dict: del my_dict[key] is slightly faster than my_dict.pop(key, None). Both are at least three times faster than del in a try/except statement:",
                "If you need to remove a lot of keys from a dictionary in one line of code, I think using map() is quite succinct and Pythonic readable:And if you need to catch errors where you pop a value that isn't in the dictionary, use lambda inside map() like this:or in python3, you must use a list comprehension instead:It works. And 'e' did not cause an error, even though myDict did not have an 'e' key.",
                "You can use a dictionary comprehension to create a new dictionary with that key removed:You can delete by conditions. No error if key doesn't exist.",
                "We can delete a key from a Python dictionary by the some of the following approaches.Using the del keyword; it's almost the same approach like you did though -OrWe can do like the following:But one should keep in mind that, in this process actually it won't delete any key from the dictionary rather than making a specific key excluded from that dictionary. In addition, I observed that it returned a dictionary which was not ordered the same as myDict.If we run it in the shell, it'll execute something like {'five': 500, 'four': 400, 'three': 300, 'two': 200} - notice that it's not the same ordered as myDict. Again if we try to print myDict, then we can see all keys including which we excluded from the dictionary by this approach. However, we can make a new dictionary by assigning the following statement into a variable:Now if we try to print it, then it'll follow the parent order:OrUsing the pop() method.The difference between del and pop is that, using pop() method, we can actually store the key's value if needed, like the following:Fork this gist for future reference, if you find this useful.",
                "You can use exception handling if you want to be very verbose:This is slower, however, than the pop() method, if the key doesn't exist.It won't matter for a few keys, but if you're doing this repeatedly, then the latter method is a better bet.The fastest approach is this:But this method is dangerous because if 'key' is removed in between the two lines, a KeyError will be raised.",
                "I prefer the immutable version",
                "Another way is by using items() + dict comprehension.items() coupled with dict comprehension can also help us achieve the task of key-value pair deletion, but it has the drawback of not being an in place dict technique. Actually a new dict if created except for the key we don\u2019t wish to include.Output:",
                "If you want to do that without KeyError, you can declare a temporary class and set it as default value in dict.get, if the value is equal to that class if means that key does not exist"
            ]
        },
        {
            "tag": "python",
            "question": [
                "Check if a given key already exists in a dictionary",
                "I wanted to test if a key exists in a dictionary before updating the value for the key.\nI wrote the following code:\n\nif 'key1' in dict.keys():\n  print \"blah\"\nelse:\n  print \"boo\"\r\nI think this is not ..."
            ],
            "url": "https://stackoverflow.com/questions/1602934",
            "answer": [
                "in tests for the existence of a key in a dict:Use dict.get() to provide a default value when the key does not exist:To provide a default value for every key, either use dict.setdefault() on each assignment:or use defaultdict from the collections module:",
                "Use key in my_dict directly instead of key in my_dict.keys():That will be much faster as it uses the dictionary's O(1) hashing as opposed to doing an O(n) linear search on a list of keys.",
                "You can test for the presence of a key in a dictionary, using the in keyword:A common use for checking the existence of a key in a dictionary before mutating it is to default-initialize the value (e.g. if your values are lists, for example, and you want to ensure that there is an empty list to which you can append when inserting the first value for a key). In cases such as those, you may find the collections.defaultdict() type to be of interest.In older code, you may also find some uses of has_key(), a deprecated method for checking the existence of keys in dictionaries (just use key_name in dict_name, instead).",
                "You can shorten your code to this:However, this is at best a cosmetic improvement. Why do you believe this is not the best way?",
                "For additional information on speed execution of the accepted answer's proposed methods (10\u00a0million loops):Therefore using in or defaultdict are recommended against get.",
                "I would recommend using the setdefault method instead.  It sounds like it will do everything you want.",
                "A dictionary in Python has a get('key', default) method. So you can just set a default value in case there isn't any key.",
                "Using the Python ternary operator:",
                "Use EAFP (easier to ask forgiveness than permission):See other Stack Overflow posts:",
                "Check if a given key already exists in a dictionaryTo get the idea how to do that we first inspect what methods we can call on dictionary.Here are the methods:The brutal method to check if the key already exists may be the get() method:The other two interesting methods items() and keys() sounds like too much of work. So let's examine if get() is the right method for us. We have our dict d:Printing shows the key we don't have will return None:We use that to get the information if the key is present or no.\nBut consider this if we create a dict with a single key:None:Leading that get() method is not reliable in case some values may be None.This story should have a happier ending. If we use the in comparator:We get the correct results.We may examine the Python byte code:This shows that in compare operator is not just more reliable, but even faster than get().",
                "The ways in which you can get the results are:Which is better is dependent on 3 things:Read More: http://paltman.com/try-except-performance-in-python-a-simple-test/Use of try/block instead of 'in' or 'if':",
                "You can use the has_key() method:",
                "Just an FYI adding to Chris. B's (best) answer:Works as well; the reason is that calling int() returns 0 which is what defaultdict does behind the scenes (when constructing a dictionary), hence the name \"Factory Function\" in the documentation.",
                "A Python dictionary has the method called __contains__. This method will return True if the dictionary has the key, else it returns False.",
                "Another way of checking if a key exists using Boolean operators:This returnsExplanationFirst, you should know that in Python, 0, None, or objects with zero length evaluate to False. Everything else evaluates to True. Boolean operations are evaluated left to right and return the operand not True or False.Let's see an example:Since 'Some string' evaluates to True, the rest of the or is not evaluated and there is no division by zero error raised.But if we switch the order 1/0 is evaluated first and raises an exception:We can use this for pattern for checking if a key exists.does the same asThis already returns the correct result if the key exists, but we want it to print 'boo' when it doesn't. So, we take the result and or it with 'boo'",
                "You can use a for loop to iterate over the dictionary and get the name of key you want to find in the dictionary. After that, check if it exist or not using if condition:"
            ]
        },
        {
            "tag": "python",
            "question": [
                "How do I parse a string to a float or int?",
                "How can I convert a str to float?\n\"545.2222\"  \u2192  545.2222\r\nHow can I convert a str to int?\n\"31\"        \u2192  31\r\nFor the reverse, see Convert integer to string in Python and ..."
            ],
            "url": "https://stackoverflow.com/questions/379906",
            "answer": [
                "For the Python3 version of is_float see: Checking if a string can be converted to float in PythonA longer and more accurate name for this function could be: is_convertible_to_float(value)The below unit tests were done using python2.  Check it that Python3 has different behavior for what strings are convertable to float.  One confounding difference is that any number of interior underscores are now allowed:  (float(\"1_3.4\") == float(13.4)) is TrueYou think you know what numbers are? You are not so good as you think! Not big surprise.Catching broad exceptions this way, killing canaries and gobbling the exception creates a tiny chance that a valid float as string will return false.  The float(...) line of code can failed for any of a thousand reasons that have nothing to do with the contents of the string.  But if you're writing life-critical software in a duck-typing prototype language like Python, then you've got much larger problems.",
                "This is another method which deserves to be mentioned here, ast.literal_eval:This can be used for safely evaluating strings containing Python expressions from untrusted sources without the need to parse the values oneself.That is, a safe 'eval'",
                "You should consider the possibility of commas in the string representation of a number, for cases like  float(\"545,545.2222\") which throws an exception. Instead, use methods in locale to convert the strings to numbers and interpret commas correctly. The locale.atof method converts to a float in one step once the locale has been set for the desired number convention.Example 1 -- United States number conventionsIn the United States and the UK, commas can be used as a thousands separator.  In this example with American locale, the comma is handled properly as a separator:Example 2 -- European number conventionsIn the majority of countries of the world,  commas are used for decimal marks instead of periods.  In this example with French locale, the comma is correctly handled as a decimal mark:The method locale.atoi is also available, but the argument should be an integer.",
                "If you aren't averse to third-party modules, you could check out the fastnumbers module. It provides a function called fast_real that does exactly what this question is asking for and does it faster than a pure-Python implementation:",
                "Users codelogic and harley are correct, but keep in mind if you know the string is an integer (for example, 545) you can call int(\"545\") without first casting to float.If your strings are in a list, you could use the map function as well.It is only good if they're all the same type.",
                "In Python, how can I parse a numeric string like \"545.2222\" to its corresponding float value, 542.2222? Or parse the string \"31\" to an integer, 31?\n  I just want to know how to parse a float string to a float, and (separately) an int string to an int.It's good that you ask to do these separately. If you're mixing them, you may be setting yourself up for problems later. The simple answer is:\"545.2222\" to float:\"31\" to an integer:Conversions from various bases, and you should know the base in advance (10 is the default). Note you can prefix them with what Python expects for its literals (see below) or remove the prefix:If you don't know the base in advance, but you do know they will have the correct prefix, Python can infer this for you if you pass 0 as the base:If your motivation is to have your own code clearly represent hard-coded specific values, however, you may not need to convert from the bases - you can let Python do it for you automatically with the correct syntax.You can use the apropos prefixes to get automatic conversion to integers with the following literals. These are valid for Python 2 and 3:Binary, prefix 0bOctal, prefix 0oHexadecimal, prefix 0xThis can be useful when describing binary flags, file permissions in code, or hex values for colors - for example, note no quotes:If you see an integer that starts with a 0, in Python 2, this is (deprecated) octal syntax.It is bad because it looks like the value should be 37. So in Python 3, it now raises a SyntaxError:Convert your Python 2 octals to octals that work in both 2 and 3 with the 0o prefix:",
                "The question seems a little bit old. But let me suggest a function, parseStr, which makes something similar, that is, returns integer or float and if a given ASCII string cannot be converted to none of them it returns it untouched. The code of course might be adjusted to do only what you want:",
                "float(\"545.2222\") and int(float(\"545.2222\"))",
                "The YAML parser can help you figure out what datatype your string is. Use yaml.load(), and then you can use type(result) to test for type:",
                "I use this function for thatIt will convert the string to its type",
                "You could use json.loads:As you can see it becomes a type of float.",
                "You need to take into account rounding to do this properly.i.e. - int(5.1) => 5\nint(5.6) => 5  -- wrong, should be 6 so we do int(5.6 + 0.5) => 6",
                "To typecast in Python use the constructor functions of the type, passing the string (or whatever value you are trying to cast) as a parameter.For example:Behind the scenes, Python is calling the objects __float__ method, which should return a float representation of the parameter. This is especially powerful, as you can define your own types (using classes) with a __float__ method so that it can be casted into a float using float(myobject).",
                "Handles hex, octal, binary, decimal, and floatThis solution will handle all of the string conventions for numbers (all that I know about).This test case output illustrates what I'm talking about.Here is the test:",
                "Pass your string to this function:It will return int, float or string depending on what was passed.",
                "There is also regex, because sometimes string must be prepared and normalized before casting to a number:Usage:And by the way, something to verify you have a number:",
                "This is a corrected version of Totoro's answer.This will try to parse a string and return either int or float depending on what the string represents. It might rise parsing exceptions or have some unexpected behaviour.",
                "If you are dealing with mixed integers and floats and want a consistent way to deal with your mixed data, here is my solution with the proper docstring:Output:",
                "Use:This is the most Pythonic way I could come up with.",
                "You can simply do this byFor more information on parsing of data types check on python documentation!",
                "This is a function which will convert any object (not just str) to int or float, based on if the actual string supplied looks like int or float. Further if it's an object which has both __float and __int__ methods, it defaults to using __float__",
                "By using int and float methods we can convert a string to integer and floats.",
                "For numbers and characters together:First import re:For easy model:",
                "If you don't want to use third party modules the following might be the most robust solution:It might not be the fastest, but it handles correctly literal numbers where many other solutions fail, such as:"
            ]
        }
    ]
}