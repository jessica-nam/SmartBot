postID,question,views,votes,answers,answer,url
231767,"What does the ""yield"" keyword do?",3.1m,12447,51,"To understand what yield does, you must understand what generators are. And before you can understand generators, you must understand iterables.When you create a list, you can read its items one by one. Reading its items one by one is called iteration:mylist is an iterable. When you use a list comprehension, you create a list, and so an iterable:Everything you can use ""for... in..."" on is an iterable; lists, strings, files...These iterables are handy because you can read them as much as you wish, but you store all the values in memory and this is not always what you want when you have a lot of values.Generators are iterators, a kind of iterable you can only iterate over once. Generators do not store all the values in memory, they generate the values on the fly:It is just the same except you used () instead of []. BUT, you cannot perform for i in mygenerator a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end calculating 4, one by one.yield is a keyword that is used like return, except the function will return a generator.Here it's a useless example, but it's handy when you know your function will return a huge set of values that you will only need to read once.To master yield, you must understand that when you call the function, the code you have written in the function body does not run. The function only returns the generator object, this is a bit tricky.Then, your code will continue from where it left off each time for uses the generator.Now the hard part:The first time the for calls the generator object created from your function, it will run the code in your function from the beginning until it hits yield, then it'll return the first value of the loop. Then, each subsequent call will run another iteration of the loop you have written in the function and return the next value. This will continue until the generator is considered empty, which happens when the function runs without hitting yield. That can be because the loop has come to an end, or because you no longer satisfy an ""if/else"".Generator:Caller:This code contains several smart parts:The loop iterates on a list, but the list expands while the loop is being iterated. It's a concise way to go through all these nested data even if it's a bit dangerous since you can end up with an infinite loop. In this case, candidates.extend(node._get_child_candidates(distance, min_dist, max_dist)) exhausts all the values of the generator, but while keeps creating new generator objects which will produce different values from the previous ones since it's not applied on the same node.The extend() method is a list object method that expects an iterable and adds its values to the list.Usually, we pass a list to it:But in your code, it gets a generator, which is good because:And it works because Python does not care if the argument of a method is a list or not. Python expects iterables so it will work with strings, lists, tuples, and generators! This is called duck typing and is one of the reasons why Python is so cool. But this is another story, for another question...You can stop here, or read a little bit to see an advanced use of a generator:Note: For Python 3, useprint(corner_street_atm.__next__()) or print(next(corner_street_atm))It can be useful for various things like controlling access to a resource.The itertools module contains special functions to manipulate iterables. Ever wish to duplicate a generator?
Chain two generators? Group values in a nested list with a one-liner? Map / Zip without creating another list?Then just import itertools.An example? Let's see the possible orders of arrival for a four-horse race:Iteration is a process implying iterables (implementing the __iter__() method) and iterators (implementing the __next__() method).
Iterables are any objects you can get an iterator from. Iterators are objects that let you iterate on iterables.There is more about it in this article about how for loops work.",https://stackoverflow.com/questions/231767
419163,"What does if __name__ == ""__main__"": do?",4.3m,7867,43,"It's boilerplate code that protects users from accidentally invoking the script when they didn't intend to. Here are some common problems when the guard is omitted from a script:If you import the guardless script in another script (e.g. import my_script_without_a_name_eq_main_guard), then the latter script will trigger the former to run at import time and using the second script's command line arguments. This is almost always a mistake.If you have a custom class in the guardless script and save it to a pickle file, then unpickling it in another script will trigger an import of the guardless script, with the same problems outlined in the previous bullet.To better understand why and how this matters, we need to take a step back to understand how Python initializes scripts and how this interacts with its module import mechanism.Whenever the Python interpreter reads a source file, it does two things:it sets a few special variables like __name__, and thenit executes all of the code found in the file.Let's see how this works and how it relates to your question about the __name__ checks we always see in Python scripts.Let's use a slightly different code sample to explore how imports and scripts work.  Suppose the following is in a file called foo.py.When the Python interpreter reads a source file, it first defines a few special variables. In this case, we care about the __name__ variable.When Your Module Is the Main ProgramIf you are running your module (the source file) as the main program, e.g.the interpreter will assign the hard-coded string ""__main__"" to the __name__ variable, i.e.When Your Module Is Imported By AnotherOn the other hand, suppose some other module is the main program and it imports your module. This means there's a statement like this in the main program, or in some other module the main program imports:The interpreter will search for your foo.py file (along with searching for a few other variants), and prior to executing that module, it will assign the name ""foo"" from the import statement to the __name__ variable, i.e.After the special variables are set up, the interpreter executes all the code in the module, one statement at a time. You may want to open another window on the side with the code sample so you can follow along with this explanation.AlwaysIt prints the string ""before import"" (without quotes).It loads the math module and assigns it to a variable called math. This is equivalent to replacing import math with the following (note that __import__ is a low-level function in Python that takes a string and triggers the actual import):It prints the string ""before function_a"".It executes the def block, creating a function object, then assigning that function object to a variable called function_a.It prints the string ""before function_b"".It executes the second def block, creating another function object, then assigning it to a variable called function_b.It prints the string ""before __name__ guard"".Only When Your Module Is the Main ProgramOnly When Your Module Is Imported by AnotherAlwaysSummaryIn summary, here's what'd be printed in the two cases:You might naturally wonder why anybody would want this.  Well, sometimes you want to write a .py file that can be both used by other programs and/or modules as a module, and can also be run as the main program itself.  Examples:Your module is a library, but you want to have a script mode where it runs some unit tests or a demo.Your module is only used as a main program, but it has some unit tests, and the testing framework works by importing .py files like your script and running special test functions. You don't want it to try running the script just because it's importing the module.Your module is mostly used as a main program, but it also provides a programmer-friendly API for advanced users.Beyond those examples, it's elegant that running a script in Python is just setting up a few magic variables and importing the script. ""Running"" the script is a side effect of importing the script's module.Question: Can I have multiple __name__ checking blocks?  Answer: it's strange to do so, but the language won't stop you.Suppose the following is in foo2.py.  What happens if you say python foo2.py on the command-line? Why?",https://stackoverflow.com/questions/419163
394809,Does Python have a ternary conditional operator?,2.7m,7586,30,"Yes, it was added in version 2.5. The expression syntax is:First condition is evaluated, then exactly one of either a or b is evaluated and returned based on the Boolean value of condition. If condition evaluates to True, then a is evaluated and returned but b is ignored, or else when b is evaluated and returned but a is ignored.This allows short-circuiting because when condition is true only a is evaluated and b is not evaluated at all, but when condition is false only b is evaluated and a is not evaluated at all.For example:Note that conditionals are an expression, not a statement. This means you can't use statements such as pass, or assignments with = (or ""augmented"" assignments like +=), within a conditional expression:(In 3.8 and above, the := ""walrus"" operator allows simple assignment of values as an expression, which is then compatible with this syntax. But please don't write code like that; it will quickly become very difficult to understand.)Similarly, because it is an expression, the else part is mandatory:You can, however, use conditional expressions to assign a variable like so:Or for example to return a value:Think of the conditional expression as switching between two values. We can use it when we are in a 'one value or another' situation, where we will do the same thing with the result, regardless of whether the condition is met. We use the expression to compute the value, and then do something with it. If you need to do something different depending on the condition, then use a normal if statement instead.Keep in mind that it's frowned upon by some Pythonistas for several reasons:If you're having trouble remembering the order, then remember that when read aloud, you (almost) say what you mean. For example, x = 4 if b > 8 else 9 is read aloud as x will be 4 if b is greater than 8 otherwise 9.Official documentation:",https://stackoverflow.com/questions/394809
100003,What are metaclasses in Python?,1.1m,7075,23,"Before understanding metaclasses, you need to master classes in Python. And Python has a very peculiar idea of what classes are, borrowed from the Smalltalk language.In most languages, classes are just pieces of code that describe how to produce an object. That's kinda true in Python too:But classes are more than that in Python. Classes are objects too.Yes, objects.As soon as you use the keyword class, Python executes it and creates
an object. The instructioncreates in memory an object with the name ObjectCreator.This object (the class) is itself capable of creating objects (the instances),
and this is why it's a class.But still, it's an object, and therefore:e.g.:Since classes are objects, you can create them on the fly, like any object.First, you can create a class in a function using class:But it's not so dynamic, since you still have to write the whole class yourself.Since classes are objects, they must be generated by something.When you use the class keyword, Python creates this object automatically. But as
with most things in Python, it gives you a way to do it manually.Remember the function type? The good old function that lets you know what
type an object is:Well, type has also a completely different ability: it can create classes on the fly. type can take the description of a class as parameters,
and return a class.(I  know, it's silly that the same function can have two completely different uses according to the parameters you pass to it. It's an issue due to backward
compatibility in Python)type works this way:Where:e.g.:can be created manually this way:You'll notice that we use MyShinyClass as the name of the class
and as the variable to hold the class reference. They can be different,
but there is no reason to complicate things.type accepts a dictionary to define the attributes of the class. So:Can be translated to:And used as a normal class:And of course, you can inherit from it, so:would be:Eventually, you'll want to add methods to your class. Just define a function
with the proper signature and assign it as an attribute.And you can add even more methods after you dynamically create the class, just like adding methods to a normally created class object.You see where we are going: in Python, classes are objects, and you can create a class on the fly, dynamically.This is what Python does when you use the keyword class, and it does so by using a metaclass.Metaclasses are the 'stuff' that creates classes.You define classes in order to create objects, right?But we learned that Python classes are objects.Well, metaclasses are what create these objects. They are the classes' classes,
you can picture them this way:You've seen that type lets you do something like this:It's because the function type is in fact a metaclass. type is the
metaclass Python uses to create all classes behind the scenes.Now you wonder ""why the heck is it written in lowercase, and not Type?""Well, I guess it's a matter of consistency with str, the class that creates
strings objects, and int the class that creates integer objects. type is
just the class that creates class objects.You see that by checking the __class__ attribute.Everything, and I mean everything, is an object in Python. That includes integers,
strings, functions and classes. All of them are objects. And all of them have
been created from a class:Now, what is the __class__ of any __class__ ?So, a metaclass is just the stuff that creates class objects.You can call it a 'class factory' if you wish.type is the built-in metaclass Python uses, but of course, you can create your
own metaclass.In Python 2, you can add a __metaclass__ attribute when you write a class (see next section for the Python 3 syntax):If you do so, Python will use the metaclass to create the class Foo.Careful, it's tricky.You write class Foo(object) first, but the class object Foo is not created
in memory yet.Python will look for __metaclass__ in the class definition. If it finds it,
it will use it to create the object class Foo. If it doesn't, it will use
type to create the class.Read that several times.When you do:Python does the following:Is there a __metaclass__ attribute in Foo?If yes, create in-memory a class object (I said a class object, stay with me here), with the name Foo by using what is in __metaclass__.If Python can't find __metaclass__, it will look for a __metaclass__ at the MODULE level, and try to do the same (but only for classes that don't inherit anything, basically old-style classes).Then if it can't find any __metaclass__ at all, it will use the Bar's (the first parent) own metaclass (which might be the default type) to create the class object.Be careful here that the __metaclass__ attribute will not be inherited, the metaclass of the parent (Bar.__class__) will be. If Bar used a __metaclass__ attribute that created Bar with type() (and not type.__new__()), the subclasses will not inherit that behavior.Now the big question is, what can you put in __metaclass__?The answer is something that can create a class.And what can create a class? type, or anything that subclasses or uses it.The syntax to set the metaclass has been changed in Python 3:i.e. the __metaclass__ attribute is no longer used, in favor of a keyword argument in the list of base classes.The behavior of metaclasses however stays largely the same.One thing added to metaclasses in Python 3 is that you can also pass attributes as keyword-arguments into a metaclass, like so:Read the section below for how Python handles this.The main purpose of a metaclass is to change the class automatically,
when it's created.You usually do this for APIs, where you want to create classes matching the
current context.Imagine a stupid example, where you decide that all classes in your module
should have their attributes written in uppercase. There are several ways to
do this, but one way is to set __metaclass__ at the module level.This way, all classes of this module will be created using this metaclass,
and we just have to tell the metaclass to turn all attributes to uppercase.Luckily, __metaclass__ can actually be any callable, it doesn't need to be a
formal class (I know, something with 'class' in its name doesn't need to be
a class, go figure... but it's helpful).So we will start with a simple example, by using a function.Let's check:Now, let's do exactly the same, but using a real class for a metaclass:Let's rewrite the above, but with shorter and more realistic variable names now that we know what they mean:You may have noticed the extra argument cls. There is
nothing special about it: __new__ always receives the class it's defined in, as the first parameter. Just like you have self for ordinary methods which receive the instance as the first parameter, or the defining class for class methods.But this is not proper OOP. We are calling type directly and we aren't overriding or calling the parent's __new__. Let's do that instead:We can make it even cleaner by using super, which will ease inheritance (because yes, you can have metaclasses, inheriting from metaclasses, inheriting from type):Oh, and in Python 3 if you do this call with keyword arguments, like this:It translates to this in the metaclass to use it:That's it. There is really nothing more about metaclasses.The reason behind the complexity of the code using metaclasses is not because
of metaclasses, it's because you usually use metaclasses to do twisted stuff
relying on introspection, manipulating inheritance, vars such as __dict__, etc.Indeed, metaclasses are especially useful to do black magic, and therefore
complicated stuff. But by themselves, they are simple:Since __metaclass__ can accept any callable, why would you use a class
since it's obviously more complicated?There are several reasons to do so:Now the big question. Why would you use some obscure error-prone feature?Well, usually you don't:Metaclasses are deeper magic that
99% of users should never worry about it.
If you wonder whether you need them,
you don't (the people who actually
need them know with certainty that
they need them, and don't need an
explanation about why).Python Guru Tim PetersThe main use case for a metaclass is creating an API. A typical example of this is the Django ORM. It allows you to define something like this:But if you do this:It won't return an IntegerField object. It will return an int, and can even take it directly from the database.This is possible because models.Model defines __metaclass__ and
it uses some magic that will turn the Person you just defined with simple statements
into a complex hook to a database field.Django makes something complex look simple by exposing a simple API
and using metaclasses, recreating code from this API to do the real job
behind the scenes.First, you know that classes are objects that can create instances.Well, in fact, classes are themselves instances. Of metaclasses.Everything is an object in Python, and they are all either instance of classes
or instances of metaclasses.Except for type.type is actually its own metaclass. This is not something you could
reproduce in pure Python, and is done by cheating a little bit at the implementation
level.Secondly, metaclasses are complicated. You may not want to use them for
very simple class alterations. You can change classes by using two different techniques:99% of the time you need class alteration, you are better off using these.But 98% of the time, you don't need class alteration at all.",https://stackoverflow.com/questions/100003
82831,How do I check whether a file exists without exceptions?,5.1m,6861,40,"If the reason you're checking is so you can do something like if file_exists: open_it(), it's safer to use a try around the attempt to open it. Checking and then opening risks the file being deleted or moved or something between when you check and when you try to open it.If you're not planning to open the file immediately, you can use os.path.isfileReturn True if path is an existing regular file. This follows symbolic links, so both islink() and isfile() can be true for the same path.if you need to be sure it's a file.Starting with Python 3.4, the pathlib module offers an object-oriented approach (backported to pathlib2 in Python 2.7):To check a directory, do:To check whether a Path object exists independently of whether is it a file or directory, use exists():You can also use resolve(strict=True) in a try block:",https://stackoverflow.com/questions/82831
38987,How do I merge two dictionaries in a single expression?,3.0m,6564,43,"For dictionaries x and y, their shallowly-merged dictionary z takes values from y, replacing those from x.In Python 3.9.0 or greater (released 17 October 2020, PEP-584, discussed here):In Python 3.5 or greater:In Python 2, (or 3.4 or lower) write a function:and now:Say you have two dictionaries and you want to merge them into a new dictionary without altering the original dictionaries:The desired result is to get a new dictionary (z) with the values merged, and the second dictionary's values overwriting those from the first.A new syntax for this, proposed in PEP 448 and available as of Python 3.5, isAnd it is indeed a single expression.Note that we can merge in with literal notation as well:and now:It is now showing as implemented in the release schedule for 3.5, PEP 478, and it has now made its way into the What's New in Python 3.5 document.However, since many organizations are still on Python 2, you may wish to do this in a backward-compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process:In both approaches, y will come second and its values will replace x's values, thus b will point to 3 in our final result.If you are not yet on Python 3.5 or need to write backward-compatible code, and you want this in a single expression, the most performant while the correct approach is to put it in a function:and then you have a single expression:You can also make a function to merge an arbitrary number of dictionaries, from zero to a very large number:This function will work in Python 2 and 3 for all dictionaries. e.g. given dictionaries a to g:and key-value pairs in g will take precedence over dictionaries a to f, and so on.Don't use what you see in the formerly accepted answer:In Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict. In Python 3, this will fail because you're adding two dict_items objects together, not two lists -and you would have to explicitly create them as lists, e.g. z = dict(list(x.items()) + list(y.items())). This is a waste of resources and computation power.Similarly, taking the union of items() in Python 3 (viewitems() in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable, since sets are semantically unordered, the behavior is undefined in regards to precedence. So don't do this:This example demonstrates what happens when values are unhashable:Here's an example where y should have precedence, but instead the value from x is retained due to the arbitrary order of sets:Another hack you should not use:This uses the dict constructor and is very fast and memory-efficient (even slightly more so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic.Here's an example of the usage being remediated in django.Dictionaries are intended to take hashable keys (e.g. frozensets or tuples), but this method fails in Python 3 when keys are not strings.From the mailing list, Guido van Rossum, the creator of the language, wrote:I am fine with
declaring dict({}, **{1:3}) illegal, since after all it is abuse of
the ** mechanism.andApparently dict(x, **y) is going around as ""cool hack"" for ""call
x.update(y) and return x"". Personally, I find it more despicable than
cool.It is my understanding (as well as the understanding of the creator of the language) that the intended usage for dict(**y) is for creating dictionaries for readability purposes, e.g.:instead ofDespite what Guido says, dict(x, **y) is in line with the dict specification, which btw. works for both Python 2 and 3. The fact that this only works for string keys is a direct consequence of how keyword parameters work and not a short-coming of dict. Nor is using the ** operator in this place an abuse of the mechanism, in fact, ** was designed precisely to pass dictionaries as keywords.Again, it doesn't work for 3 when keys are not strings. The implicit calling contract is that namespaces take ordinary dictionaries, while users must only pass keyword arguments that are strings. All other callables enforced it. dict broke this consistency in Python 2:This inconsistency was bad given other implementations of Python (PyPy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change.I submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints.More comments:dict(x.items() + y.items()) is still the most readable solution for Python 2. Readability counts.My response: merge_two_dicts(x, y) actually seems much clearer to me, if we're actually concerned about readability. And it is not forward compatible, as Python 2 is increasingly deprecated.{**x, **y} does not seem to handle nested dictionaries. the contents of nested keys are simply overwritten, not merged [...] I ended up being burnt by these answers that do not merge recursively and I was surprised no one mentioned it. In my interpretation of the word ""merging"" these answers describe ""updating one dict with another"", and not merging.Yes. I must refer you back to the question, which is asking for a shallow merge of two dictionaries, with the first's values being overwritten by the second's - in a single expression.Assuming two dictionaries of dictionaries, one might recursively merge them in a single function, but you should be careful not to modify the dictionaries from either source, and the surest way to avoid that is to make a copy when assigning values. As keys must be hashable and are usually therefore immutable, it is pointless to copy them:Usage:Coming up with contingencies for other value types is far beyond the scope of this question, so I will point you at my answer to the canonical question on a ""Dictionaries of dictionaries merge"".These approaches are less performant, but they will provide correct behavior.
They will be much less performant than copy and update or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they do respect the order of precedence (latter dictionaries have precedence)You can also chain the dictionaries manually inside a dict comprehension:or in Python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced):itertools.chain will chain the iterators over the key-value pairs in the correct order:I'm only going to do the performance analysis of the usages known to behave correctly. (Self-contained so you can copy and paste yourself.)In Python 3.8.1, NixOS:",https://stackoverflow.com/questions/38987
89228,How do I execute a program or call a system command?,4.2m,5871,64,"Use the subprocess module in the standard library:The advantage of subprocess.run over os.system is that it is more flexible (you can get the stdout, stderr, the ""real"" status code, better error handling, etc...).Even the documentation for os.system recommends using subprocess instead:The subprocess module provides more powerful facilities for spawning new processes and retrieving their results; using that module is preferable to using this function. See the Replacing Older Functions with the subprocess Module section in the subprocess documentation for some helpful recipes.On Python 3.4 and earlier, use subprocess.call instead of .run:",https://stackoverflow.com/questions/89228
273192,How can I safely create a nested directory?,3.5m,5406,28,"On Python ≥ 3.5, use pathlib.Path.mkdir:For older versions of Python, I see two answers with good qualities, each with a small flaw, so I will give my take on it:Try os.path.exists, and consider os.makedirs for the creation.As noted in comments and elsewhere, there's a race condition – if the directory is created between the os.path.exists and the os.makedirs calls, the os.makedirs will fail with an OSError. Unfortunately, blanket-catching OSError and continuing is not foolproof, as it will ignore a failure to create the directory due to other factors, such as insufficient permissions, full disk, etc.One option would be to trap the OSError and examine the embedded error code (see Is there a cross-platform way of getting information from Python’s OSError):Alternatively, there could be a second os.path.exists, but suppose another created the directory after the first check, then removed it before the second one – we could still be fooled.Depending on the application, the danger of concurrent operations may be more or less than the danger posed by other factors such as file permissions. The developer would have to know more about the particular application being developed and its expected environment before choosing an implementation.Modern versions of Python improve this code quite a bit, both by exposing FileExistsError (in 3.3+)......and by allowing a keyword argument to os.makedirs called exist_ok (in 3.2+).",https://stackoverflow.com/questions/273192
522563,Accessing the index in 'for' loops,3.6m,4979,26,Use the built-in function enumerate():It is non-pythonic to manually index via for i in range(len(xs)): x = xs[i] or manually manage an additional state variable.Check out PEP 279 for more.,https://stackoverflow.com/questions/522563
952914,How do I make a flat list out of a list of lists?,3.7m,4967,34,"Given a list of lists l,which means:is faster than the shortcuts posted so far. (l is the list to flatten.)Here is the corresponding function:As evidence, you can use the timeit module in the standard library:Explanation: the shortcuts based on + (including the implied use in sum) are, of necessity, O(L**2) when there are L sublists -- as the intermediate result list keeps getting longer, at each step a new intermediate result list object gets allocated, and all the items in the previous intermediate result must be copied over (as well as a few new ones added at the end). So, for simplicity and without actual loss of generality, say you have L sublists of I items each: the first I items are copied back and forth L-1 times, the second I items L-2 times, and so on; total number of copies is I times the sum of x for x from 1 to L excluded, i.e., I * (L**2)/2.The list comprehension just generates one list, once, and copies each item over (from its original place of residence to the result list) also exactly once.",https://stackoverflow.com/questions/952914
136097,Difference between @staticmethod and @classmethod,1.0m,4462,35,"Maybe a bit of example code will help: Notice the difference in the call signatures of foo, class_foo and static_foo:Below is the usual way an object instance calls a method. The object instance, a, is implicitly passed as the first argument.With classmethods, the class of the object instance is implicitly passed as the first argument instead of self.You can also call class_foo using the class. In fact, if you define something to be
a classmethod, it is probably because you intend to call it from the class rather than from a class instance. A.foo(1) would have raised a TypeError, but A.class_foo(1) works just fine:One use people have found for class methods is to create inheritable alternative constructors.With staticmethods, neither self (the object instance) nor  cls (the class) is implicitly passed as the first argument. They behave like plain functions except that you can call them from an instance or the class:Staticmethods are used to group functions which have some logical connection with a class to the class.foo is just a function, but when you call a.foo you don't just get the function,
you get a ""partially applied"" version of the function with the object instance a bound as the first argument to the function. foo expects 2 arguments, while a.foo only expects 1 argument.a is bound to foo. That is what is meant by the term ""bound"" below:With a.class_foo, a is not bound to class_foo, rather the class A is bound to class_foo.Here, with a staticmethod, even though it is a method, a.static_foo just returns
a good 'ole function with no arguments bound. static_foo expects 1 argument, and
a.static_foo expects 1 argument too.And of course the same thing happens when you call static_foo with the class A instead.",https://stackoverflow.com/questions/136097
509211,Understanding slicing,2.8m,4409,36,"The syntax is:There is also the step value, which can be used with any of the above:The key point to remember is that the :stop value represents the first value that is not in the selected slice. So, the difference between stop and start is the number of elements selected (if step is 1, the default).The other feature is that start or stop may be a negative number, which means it counts from the end of the array instead of the beginning. So:Similarly, step may be a negative number:Python is kind to the programmer if there are fewer items than you ask for. For example, if you ask for a[:-2] and a only contains one element, you get an empty list instead of an error. Sometimes you would prefer the error, so you have to be aware that this may happen.A slice object can represent a slicing operation, i.e.:is equivalent to:Slice objects also behave slightly differently depending on the number of arguments, similarly to range(), i.e. both slice(stop) and slice(start, stop[, step]) are supported.
To skip specifying a given argument, one might use None, so that e.g. a[start:] is equivalent to a[slice(start, None)] or a[::-1] is equivalent to a[slice(None, None, -1)].While the :-based notation is very helpful for simple slicing, the explicit use of slice() objects simplifies the programmatic generation of slicing.",https://stackoverflow.com/questions/509211
176918,Finding the index of an item in a list,5.7m,4215,42,"The simplest case is handled by the built-in .index method of the list:Return zero-based index in the list of the first item whose value is equal to x. Raises a ValueError if there is no such item.The optional arguments start and end are interpreted as in the slice notation and are used to limit the search to a particular subsequence of the list. The returned index is computed relative to the beginning of the full sequence rather than the start argument.Thus, we can do:An index call checks every element of the list in order, until it finds a match. If the list is long, and if there is no guarantee that the value will be near the beginning, this can slow down the code.This problem can only be completely avoided by using a different data structure. However, if the element is known to be within a certain part of the list, the start and end parameters can be used to narrow the search.For example:The second call is orders of magnitude faster, because it only has to search through 10 elements, rather than all 1 million.A call to index searches through the list in order until it finds a match, and stops there. If there could be more than one occurrence of the value, and all indices are needed, index cannot solve the problem:Instead, use a list comprehension or generator expression to do the search, with enumerate to get indices:The list comprehension and generator expression techniques still work if there is only one match, and are more generalizable.As noted in the documentation above, using .index will raise an exception if the searched-for value is not in the list:If this is a concern, either explicitly check first using item in my_list, or handle the exception with try/except as appropriate.The explicit check is simple and readable, but it must iterate the list a second time. See What is the EAFP principle in Python? for more guidance on this choice.",https://stackoverflow.com/questions/176918
3294889,Iterating over dictionaries using 'for' loops,5.4m,4067,15,"key is just a variable name.will simply loop over the keys in the dictionary, rather than the keys and values.  To loop over both key and value you can use the following:For Python 3.x:For Python 2.x:To test for yourself, change the word key to poop.In Python 3.x, iteritems() was replaced with simply items(), which returns a set-like view backed by the dict, like iteritems() but even better. 
This is also available in 2.7 as viewitems().The operation items() will work for both 2 and 3, but in 2 it will return a list of the dictionary's (key, value) pairs, which will not reflect changes to the dict that happen after the items() call. If you want the 2.x behavior in 3.x, you can call list(d.items()).",https://stackoverflow.com/questions/3294889
423379,Using global variables in a function,3.9m,3798,25,"You can use a global variable within other functions by declaring it as global within each function that assigns a value to it:Since it's unclear whether globvar = 1 is creating a local variable or changing a global variable, Python defaults to creating a local variable, and makes you explicitly choose the other behavior with the global keyword.See other answers if you want to share a global variable across modules.",https://stackoverflow.com/questions/423379
16476924,How to iterate over rows in a DataFrame in Pandas,6.0m,3713,31,DataFrame.iterrows is a generator which yields both the index and row (as a Series):,https://stackoverflow.com/questions/16476924
415511,How do I get the current time?,4.0m,3655,53,"Use datetime:For just the clock time without the date:To save typing, you can import the datetime object from the datetime module:Then remove the prefix datetime. from all of the above.",https://stackoverflow.com/questions/415511
6470428,Catch multiple exceptions in one line (except block),1.3m,3633,6,"From Python Documentation:An except clause may name multiple exceptions as a parenthesized tuple, for exampleOr, for Python 2 only:Separating the exception from the variable with a comma will still work in Python 2.6 and 2.7, but is now deprecated and does not work in Python 3; now you should be using as.",https://stackoverflow.com/questions/6470428
3437059,Does Python have a string 'contains' substring method?,6.3m,3588,10,Use the in operator:,https://stackoverflow.com/questions/3437059
1436703,What is the difference between __str__ and __repr__?,909k,3530,28,"Alex summarized well but, surprisingly, was too succinct.First, let me reiterate the main points in Alex’s post:Default implementation is uselessThis is mostly a surprise because Python’s defaults tend to be fairly useful. However, in this case, having a default for __repr__ which would act like:would have been too dangerous (for example, too easy to get into infinite recursion if objects reference each other). So Python cops out. Note that there is one default which is true: if __repr__ is defined, and __str__ is not, the object will behave as though __str__=__repr__.This means, in simple terms: almost every object you implement should have a functional __repr__ that’s usable for understanding the object. Implementing __str__ is optional: do that if you need a “pretty print” functionality (for example, used by a report generator).The goal of __repr__ is to be unambiguousLet me come right out and say it — I do not believe in debuggers. I don’t really know how to use any debugger, and have never used one seriously. Furthermore, I believe that the big fault in debuggers is their basic nature — most failures I debug happened a long long time ago, in a galaxy far far away. This means that I do believe, with religious fervor, in logging. Logging is the lifeblood of any decent fire-and-forget server system. Python makes it easy to log: with maybe some project specific wrappers, all you need is aBut you have to do the last step — make sure every object you implement has a useful repr, so code like that can just work. This is why the “eval” thing comes up: if you have enough information so eval(repr(c))==c, that means you know everything there is to know about c. If that’s easy enough, at least in a fuzzy way, do it. If not, make sure you have enough information about c anyway. I usually use an eval-like format: ""MyClass(this=%r,that=%r)"" % (self.this,self.that). It does not mean that you can actually construct MyClass, or that those are the right constructor arguments — but it is a useful form to express “this is everything you need to know about this instance”.Note: I used %r above, not %s. You always want to use repr() [or %r formatting character, equivalently] inside __repr__ implementation, or you’re defeating the goal of repr. You want to be able to differentiate MyClass(3) and MyClass(""3"").The goal of __str__ is to be readableSpecifically, it is not intended to be unambiguous — notice that str(3)==str(""3""). Likewise, if you implement an IP abstraction, having the str of it look like 192.168.1.1 is just fine. When implementing a date/time abstraction, the str can be ""2010/4/12 15:35:22"", etc. The goal is to represent it in a way that a user, not a programmer, would want to read it. Chop off useless digits, pretend to be some other class — as long is it supports readability, it is an improvement.Container’s __str__ uses contained objects’ __repr__This seems surprising, doesn’t it? It is a little, but how readable would it be if it used their __str__?Not very. Specifically, the strings in a container would find it way too easy to disturb its string representation. In the face of ambiguity, remember, Python resists the temptation to guess. If you want the above behavior when you’re printing a list, just(you can probably also figure out what to do about dictionaries.SummaryImplement __repr__ for any class you implement. This should be second nature. Implement __str__ if you think it would be useful to have a string version which errs on the side of readability.",https://stackoverflow.com/questions/1436703
606191,Convert bytes to a string,4.5m,3527,23,"Decode the bytes object to produce a string:The above example assumes that the bytes object is in UTF-8, because it is a common encoding. However, you should use the encoding your data is actually in!",https://stackoverflow.com/questions/606191
123198,How to copy files,3.1m,3494,25,"shutil has many methods you can use. One of which is:Another shutil method to look at is shutil.copy2(). It's similar but preserves more metadata (e.g. time stamps).If you use os.path operations, use copy rather than copyfile. copyfile will only accept strings.",https://stackoverflow.com/questions/123198
3207219,How do I list all files of a directory?,7.4m,3467,21,"os.listdir() returns everything inside a directory -- including both files and directories.os.path's isfile() can be used to only list files:Alternatively, os.walk() yields two lists for each directory it visits -- one for files and one for dirs. If you only want the top directory you can break the first time it yields:or, shorter:",https://stackoverflow.com/questions/3207219
448271,What is __init__.py for?,2.0m,3424,14,"It used to be a required part of a package (old, pre-3.3 ""regular package"", not newer 3.3+ ""namespace package"").Here's the documentation.Python defines two types of packages, regular packages and namespace packages. Regular packages are traditional packages as they existed in Python 3.2 and earlier. A regular package is typically implemented as a directory containing an __init__.py file. When a regular package is imported, this __init__.py file is implicitly executed, and the objects it defines are bound to names in the package’s namespace. The __init__.py file can contain the same Python code that any other module can contain, and Python will add some additional attributes to the module when it is imported.But just click the link, it contains an example, more information, and an explanation of namespace packages, the kind of packages without __init__.py.",https://stackoverflow.com/questions/448271
613183,How do I sort a dictionary by value?,4.9m,3416,34,"Dicts preserve insertion order in Python 3.7+. Same in CPython 3.6, but it's an implementation detail.orIt is not possible to sort a dictionary, only to get a representation of a dictionary that is sorted. Dictionaries are inherently orderless, but other types, such as lists and tuples, are not. So you need an ordered data type to represent sorted values, which will be a list—probably a list of tuples.For instance,sorted_x will be a list of tuples sorted by the second element in each tuple. dict(sorted_x) == x.And for those wishing to sort on keys instead of values:In Python3 since unpacking is not allowed we can useIf you want the output as a dict, you can use collections.OrderedDict:",https://stackoverflow.com/questions/613183
1024847,How can I add new keys to a dictionary?,5.1m,3411,19,"You create a new key/value pair on a dictionary by assigning a value to that keyIf the key doesn't exist, it's added and points to that value. If it exists, the current value it points to is overwritten.",https://stackoverflow.com/questions/1024847
1132941,"""Least Astonishment"" and the Mutable Default Argument",236k,3258,32,"Actually, this is not a design flaw, and it is not because of internals or performance. It comes simply from the fact that functions in Python are first-class objects, and not only a piece of code.As soon as you think of it this way, then it completely makes sense: a function is an object being evaluated on its definition; default parameters are kind of ""member data"" and therefore their state may change from one call to the other - exactly as in any other object.In any case, the effbot (Fredrik Lundh) has a very nice explanation of the reasons for this behavior in Default Parameter Values in Python.
I found it very clear, and I really suggest reading it for a better knowledge of how function objects work.",https://stackoverflow.com/questions/1132941
1720421,How do I concatenate two lists in Python?,4.0m,3245,31,Use the + operator to combine the lists:Output:,https://stackoverflow.com/questions/1720421
17071871,How do I select rows from a DataFrame based on column values?,5.5m,3234,16,"To select rows whose column value equals a scalar, some_value, use ==:To select rows whose column value is in an iterable, some_values, use isin:Combine multiple conditions with &:Note the parentheses. Due to Python's operator precedence rules, & binds more tightly than <= and >=. Thus, the parentheses in the last example are necessary. Without the parenthesesis parsed aswhich results in a Truth value of a Series is ambiguous error.To select rows whose column value does not equal some_value, use !=:isin returns a boolean Series, so to select rows whose value is not in some_values, negate the boolean Series using ~:For example,yieldsIf you have multiple values you want to include, put them in a
list (or more generally, any iterable) and use isin:yieldsNote, however, that if you wish to do this many times, it is more efficient to
make an index first, and then use df.loc:yieldsor, to include multiple values from the index use df.index.isin:yields",https://stackoverflow.com/questions/17071871
53513,How do I check if a list is empty?,4.4m,3229,27,Using the implicit booleanness of the empty list is quite Pythonic.,https://stackoverflow.com/questions/53513
36901,What does ** (double star/asterisk) and * (star/asterisk) do for parameters?,1.2m,3199,25,"The *args and **kwargs is a common idiom to allow arbitrary number of arguments to functions as described in the section more on defining functions in the Python documentation.The *args will give you all function parameters as a tuple:The **kwargs will give you all
keyword arguments except for those corresponding to a formal parameter as a dictionary.Both idioms can be mixed with normal arguments to allow a set of fixed and some variable arguments:It is also possible to use this the other way around:Another usage of the *l idiom is to unpack argument lists when calling a function.In Python 3 it is possible to use *l on the left side of an assignment (Extended Iterable Unpacking), though it gives a list instead of a tuple in this context:Also Python 3 adds new semantic (refer PEP 3102):For example the following works in python 3 but not python 2:Such function accepts only 3 positional arguments, and everything after * can only be passed as keyword arguments.",https://stackoverflow.com/questions/36901
986006,How do I pass a variable by reference?,1.9m,3180,39,"Arguments are passed by assignment. The rationale behind this is twofold:So:If you pass a mutable object into a method, the method gets a reference to that same object and you can mutate it to your heart's delight, but if you rebind the reference in the method, the outer scope will know nothing about it, and after you're done, the outer reference will still point at the original object.If you pass an immutable object to a method, you still can't rebind the outer reference, and you can't even mutate the object.To make it even more clear, let's have some examples.Let's try to modify the list that was passed to a method:Output:Since the parameter passed in is a reference to outer_list, not a copy of it, we can use the mutating list methods to change it and have the changes reflected in the outer scope.Now let's see what happens when we try to change the reference that was passed in as a parameter:Output:Since the the_list parameter was passed by value, assigning a new list to it had no effect that the code outside the method could see. The the_list was a copy of the outer_list reference, and we had the_list point to a new list, but there was no way to change where outer_list pointed.It's immutable, so there's nothing we can do to change the contents of the stringNow, let's try to change the referenceOutput:Again, since the the_string parameter was passed by value, assigning a new string to it had no effect that the code outside the method could see. The the_string was a copy of the outer_string reference, and we had the_string point to a new string, but there was no way to change where outer_string pointed.I hope this clears things up a little.EDIT: It's been noted that this doesn't answer the question that @David originally asked, ""Is there something I can do to pass the variable by actual reference?"". Let's work on that.As @Andrea's answer shows, you could return the new value. This doesn't change the way things are passed in, but does let you get the information you want back out:If you really wanted to avoid using a return value, you could create a class to hold your value and pass it into the function or use an existing class, like a list:Although this seems a little cumbersome.",https://stackoverflow.com/questions/986006
2612802,How do I clone a list so that it doesn't change unexpectedly after assignment?,2.1m,3173,23,"new_list = my_list doesn't actually create a second list. The assignment just copies the reference to the list, not the actual list, so both new_list and my_list refer to the same list after the assignment.To actually copy the list, you have several options:You can use the builtin list.copy() method (available since Python 3.3):You can slice it:Alex Martelli's opinion (at least back in 2007) about this is, that it is a weird syntax and it does not make sense to use it ever. ;) (In his opinion, the next one is more readable).You can use the built in list() constructor:You can use generic copy.copy():This is a little slower than list() because it has to find out the datatype of old_list first.If you need to copy the elements of the list as well, use generic copy.deepcopy():Obviously the slowest and most memory-needing method, but sometimes unavoidable. This operates recursively; it will handle any number of levels of nested lists (or other containers).Example:Result:",https://stackoverflow.com/questions/2612802
510348,How do I make a time delay? [duplicate],3.6m,3134,13,This delays for 2.5 seconds:Here is another example where something is run approximately once a minute:,https://stackoverflow.com/questions/510348
6996603,How can I delete a file or folder in Python?,3.0m,3117,15,os.remove() removes a file.os.rmdir() removes an empty directory.shutil.rmtree() deletes a directory and all its contents.Path objects from the Python 3.4+ pathlib module also expose these instance methods:pathlib.Path.unlink() removes a file or symbolic link.pathlib.Path.rmdir() removes an empty directory.,https://stackoverflow.com/questions/6996603
252703,What is the difference between Python's list methods append and extend?,3.2m,3113,20,append appends a specified object at the end of the list:extend extends the list by appending elements from the specified iterable:,https://stackoverflow.com/questions/252703
576169,Understanding Python super() with __init__() methods [duplicate],2.4m,3108,7,"super() lets you avoid referring to the base class explicitly, which can be nice. But the main advantage comes with multiple inheritance, where all sorts of fun stuff can happen. See the standard docs on super if you haven't already.Note that the syntax changed in Python 3.0: you can just say super().__init__() instead of super(ChildB, self).__init__() which IMO is quite a bit nicer. The standard docs also refer to a guide to using super() which is quite explanatory.",https://stackoverflow.com/questions/576169
739654,How to make function decorators and chain them together?,625k,3086,20,"If you are not into long explanations, see Paolo Bergantino’s answer.To understand decorators, you must first understand that functions are objects in Python. This has important consequences. Let’s see why with a simple example :Keep this in mind. We’ll circle back to it shortly.Another interesting property of Python functions is they can be defined inside another function!Okay, still here? Now the fun part...You’ve seen that functions are objects. Therefore, functions:That means that a function can return another function.There’s more!If you can return a function, you can pass one as a parameter:Well, you just have everything needed to understand decorators. You see, decorators are “wrappers”, which means that they let you execute code before and after the function they decorate without modifying the function itself.How you’d do it manually:Now, you probably want that every time you call a_stand_alone_function, a_stand_alone_function_decorated is called instead. That’s easy, just overwrite a_stand_alone_function with the function returned by my_shiny_new_decorator:The previous example, using the decorator syntax:Yes, that’s all, it’s that simple. @decorator is just a shortcut to:Decorators are just a pythonic variant of the decorator design pattern. There are several classic design patterns embedded in Python to ease development (like iterators).Of course, you can accumulate decorators:Using the Python decorator syntax:The order you set the decorators MATTERS:As a conclusion, you can easily see how to answer the question:You can now just leave happy, or burn your brain a little bit more and see advanced uses of decorators.One nifty thing about Python is that methods and functions are really the same.  The only difference is that methods expect that their first argument is a reference to the current object (self).That means you can build a decorator for methods the same way! Just remember to take self into consideration:If you’re making general-purpose decorator--one you’ll apply to any function or method, no matter its arguments--then just use *args, **kwargs:Great, now what would you say about passing arguments to the decorator itself?This can get somewhat twisted, since a decorator must accept a function as an argument. Therefore, you cannot pass the decorated function’s arguments directly to the decorator.Before rushing to the solution, let’s write a little reminder:It’s exactly the same. ""my_decorator"" is called. So when you @my_decorator, you are telling Python to call the function 'labelled by the variable ""my_decorator""'.This is important! The label you give can point directly to the decorator—or not.Let’s get evil. ☺No surprise here.Let’s do EXACTLY the same thing, but skip all the pesky intermediate variables:Let’s make it even shorter:Hey, did you see that? We used a function call with the ""@"" syntax! :-)So, back to decorators with arguments. If we can use functions to generate the decorator on the fly, we can pass arguments to that function, right?Here it is: a decorator with arguments. Arguments can be set as variable:As you can see, you can pass arguments to the decorator like any function using this trick. You can even use *args, **kwargs if you wish. But remember decorators are called only once. Just when Python imports the script. You can't dynamically set the arguments afterwards. When you do ""import x"", the function is already decorated, so you can't
change anything.Okay, as a bonus, I'll give you a snippet to make any decorator accept generically any argument. After all, in order to accept arguments, we created our decorator using another function.We wrapped the decorator.Anything else we saw recently that wrapped function?Oh yes, decorators!Let’s have some fun and write a decorator for the decorators:It can be used as follows:I know, the last time you had this feeling, it was after listening a guy saying: ""before understanding recursion, you must first understand recursion"". But now, don't you feel good about mastering this?The functools module was introduced in Python 2.5. It includes the function functools.wraps(), which copies the name, module, and docstring of the decorated function to its wrapper.(Fun fact: functools.wraps() is a decorator! ☺)Now the big question: What can I use decorators for?Seem cool and powerful, but a practical example would be great. Well, there are 1000 possibilities. Classic uses are extending a function behavior from an external lib (you can't modify it), or for debugging (you don't want to modify it because it’s temporary).You can use them to extend several functions in a DRY’s way, like so:Of course the good thing with decorators is that you can use them right away on almost anything without rewriting. DRY, I said:Python itself provides several decorators: property, staticmethod, etc.This really is a large playground.",https://stackoverflow.com/questions/739654
332289,How do I change the size of figures drawn with Matplotlib?,5.5m,3063,13,"figure tells you the call signature:figure(figsize=(1,1)) would create an inch-by-inch image, which would be 80-by-80 pixels unless you also give a different dpi argument.",https://stackoverflow.com/questions/332289
2052390,Manually raising (throwing) an exception in Python,2.7m,3025,11,"Use the most specific Exception constructor that semantically fits your issue.Be specific in your message, e.g.:Avoid raising a generic Exception. To catch it, you'll have to catch all other more specific exceptions that subclass it.For example:And more specific catches won't catch the general exception:Instead, use the most specific Exception constructor that semantically fits your issue.which also handily allows an arbitrary number of arguments to be passed to the constructor:These arguments are accessed by the args attribute on the Exception object. For example:printsIn Python 2.5, an actual message attribute was added to BaseException in favor of encouraging users to subclass Exceptions and stop using args, but the introduction of message and the original deprecation of args has been retracted.When inside an except clause, you might want to, for example, log that a specific type of error happened, and then re-raise. The best way to do this while preserving the stack trace is to use a bare raise statement. For example:You can preserve the stacktrace (and error value) with sys.exc_info(), but this is way more error prone and has compatibility problems between Python 2 and 3, prefer to use a bare raise to re-raise.To explain - the sys.exc_info() returns the type, value, and traceback.This is the syntax in Python 2 - note this is not compatible with Python 3:If you want to, you can modify what happens with your new raise - e.g. setting new args for the instance:And we have preserved the whole traceback while modifying the args. Note that this is not a best practice and it is invalid syntax in Python 3 (making keeping compatibility much harder to work around).In Python 3:Again: avoid manually manipulating tracebacks. It's less efficient and more error prone. And if you're using threading and sys.exc_info you may even get the wrong traceback (especially if you're using exception handling for control flow - which I'd personally tend to avoid.)In Python 3, you can chain Exceptions, which preserve tracebacks:Be aware:These can easily hide and even get into production code. You want to raise an exception, and doing them will raise an exception, but not the one intended!Valid in Python 2, but not in Python 3 is the following:Only valid in much older versions of Python (2.4 and lower), you may still see people raising strings:In all modern versions, this will actually raise a TypeError, because you're not raising a BaseException type. If you're not checking for the right exception and don't have a reviewer that's aware of the issue, it could get into production.I raise Exceptions to warn consumers of my API if they're using it incorrectly:""I want to make an error on purpose, so that it would go into the except""You can create your own error types, if you want to indicate something specific is wrong with your application, just subclass the appropriate point in the exception hierarchy:and usage:",https://stackoverflow.com/questions/2052390
287871,How do I print colored text to the terminal?,2.1m,2970,63,"This somewhat depends on what platform you are on. The most common way to do this is by printing ANSI escape sequences. For a simple example, here's some Python code from the Blender build scripts:To use code like this, you can do something like:Or, with Python 3.6+:This will work on unixes including OS X, Linux and Windows (provided you use ANSICON, or in Windows 10 provided you enable VT100 emulation). There are ANSI codes for setting the color, moving the cursor, and more.If you are going to get complicated with this (and it sounds like you are if you are writing a game), you should look into the ""curses"" module, which handles a lot of the complicated parts of this for you. The Python Curses HowTO is a good introduction.If you are not using extended ASCII (i.e., not on a PC), you are stuck with the ASCII characters below 127, and '#' or '@' is probably your best bet for a block. If you can ensure your terminal is using a IBM extended ASCII character set, you have many more options. Characters 176, 177, 178 and 219 are the ""block characters"".Some modern text-based programs, such as ""Dwarf Fortress"", emulate text mode in a graphical mode, and use images of the classic PC font. You can find some of these bitmaps that you can use on the Dwarf Fortress Wiki see (user-made tilesets).The Text Mode Demo Contest has more resources for doing graphics in text mode.",https://stackoverflow.com/questions/287871
312443,How do I split a list into equally-sized chunks?,1.5m,2961,72,"Here's a generator that yields evenly-sized chunks:For Python 2, using xrange instead of range:Below is a list comprehension one-liner. The method above is preferable, though, since using named functions makes code easier to understand. For Python 3:For Python 2:",https://stackoverflow.com/questions/312443
4906977,How can I access environment variables in Python?,2.6m,2951,15,"Environment variables are accessed through os.environ:To see a list of all environment variables:If a key is not present, attempting to access it will raise a KeyError. To avoid this:",https://stackoverflow.com/questions/4906977
466345,"Convert string ""Jun 1 2005 1:33PM"" into datetime",4.4m,2878,26,"datetime.strptime parses an input string in the user-specified format into a timezone-naive datetime object:To obtain a date object using an existing datetime object, convert it using .date():Links:strptime docs: Python 2, Python 3strptime/strftime format string docs: Python 2, Python 3strftime.org format string cheatsheetNotes:",https://stackoverflow.com/questions/466345
30081275,"Why is ""1000000000000000 in range(1000000000000001)"" so fast in Python 3?",330k,2854,12,"The Python 3 range() object doesn't produce numbers immediately; it is a smart sequence object that produces numbers on demand. All it contains is your start, stop and step values, then as you iterate over the object the next integer is calculated each iteration.The object also implements the object.__contains__ hook, and calculates if your number is part of its range. Calculating is a (near) constant time operation *. There is never a need to scan through all possible integers in the range.From the range() object documentation:The advantage of the range type over a regular list or tuple is that a range object will always take the same (small) amount of memory, no matter the size of the range it represents (as it only stores the start, stop and step values, calculating individual items and subranges as needed).So at a minimum, your range() object would do:This is still missing several things that a real range() supports (such as the .index() or .count() methods, hashing, equality testing, or slicing), but should give you an idea.I also simplified the __contains__ implementation to only focus on integer tests; if you give a real range() object a non-integer value (including subclasses of int), a slow scan is initiated to see if there is a match, just as if you use a containment test against a list of all the contained values. This was done to continue to support other numeric types that just happen to support equality testing with integers but are not expected to support integer arithmetic as well. See the original Python issue that implemented the containment test.* Near constant time because Python integers are unbounded and so math operations also grow in time as N grows, making this a O(log N) operation. Since it’s all executed in optimised C code and Python stores integer values in 30-bit chunks, you’d run out of memory before you saw any performance impact due to the size of the integers involved here.",https://stackoverflow.com/questions/30081275
5137497,Find the current directory and file's directory [duplicate],4.3m,2849,13,"To get the full path to the directory a Python file is contained in, write this in that file:(Note that the incantation above won't work if you've already used os.chdir() to change your current working directory, since the value of the __file__ constant is relative to the current working directory and is not changed by an os.chdir() call.)To get the current working directory useDocumentation references for the modules, constants and functions used above:",https://stackoverflow.com/questions/5137497
11346283,Renaming column names in Pandas,5.4m,2747,35,"Use the df.rename() function and refer the columns to be renamed. Not all the columns have to be renamed:Minimal Code ExampleThe following methods all work and produce the same output:Remember to assign the result back, as the modification is not-inplace. Alternatively, specify inplace=True:From v0.25, you can also specify errors='raise' to raise errors if an invalid column-to-rename is specified. See v0.25 rename() docs.Use df.set_axis() with axis=1 and inplace=False (to return a copy).This returns a copy, but you can modify the DataFrame in-place by setting inplace=True (this is the default behaviour for versions <=0.24 but is likely to change in the future).You can also assign headers directly:",https://stackoverflow.com/questions/11346283
11277432,How can I remove a key from a Python dictionary?,2.5m,2706,11,"To delete a key regardless of whether it is in the dictionary, use the two-argument form of dict.pop():This will return my_dict[key] if key exists in the dictionary, and None otherwise. If the second parameter is not specified (i.e. my_dict.pop('key')) and key does not exist, a KeyError is raised.To delete a key that is guaranteed to exist, you can also use:This will raise a KeyError if the key is not in the dictionary.",https://stackoverflow.com/questions/11277432
1602934,Check if a given key already exists in a dictionary,5.8m,2679,16,"in tests for the existence of a key in a dict:Use dict.get() to provide a default value when the key does not exist:To provide a default value for every key, either use dict.setdefault() on each assignment:or use defaultdict from the collections module:",https://stackoverflow.com/questions/1602934
379906,How do I parse a string to a float or int?,4.6m,2668,32,,https://stackoverflow.com/questions/379906
